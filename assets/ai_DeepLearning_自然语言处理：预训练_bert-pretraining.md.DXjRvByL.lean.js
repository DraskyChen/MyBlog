import{_ as l,c as h,o as t,ag as a,j as i,a as n}from"./chunks/framework.C2Gjomh7.js";const C=JSON.parse('{"title":"预训练BERT","description":"","frontmatter":{},"headers":[],"relativePath":"ai/DeepLearning/自然语言处理：预训练/bert-pretraining.md","filePath":"ai/DeepLearning/自然语言处理：预训练/bert-pretraining.md","lastUpdated":1756829839000}'),k={name:"ai/DeepLearning/自然语言处理：预训练/bert-pretraining.md"},p={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},e={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.381ex"},xmlns:"http://www.w3.org/2000/svg",width:"10.94ex",height:"1.926ex",role:"img",focusable:"false",viewBox:"0 -683 4835.7 851.2","aria-hidden":"true"},E={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},d={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.381ex"},xmlns:"http://www.w3.org/2000/svg",width:"12.351ex",height:"1.926ex",role:"img",focusable:"false",viewBox:"0 -683 5459.3 851.2","aria-hidden":"true"},r={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},g={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.381ex"},xmlns:"http://www.w3.org/2000/svg",width:"12.351ex",height:"1.926ex",role:"img",focusable:"false",viewBox:"0 -683 5459.3 851.2","aria-hidden":"true"};function y(F,s,o,c,_,T){return t(),h("div",null,[s[14]||(s[14]=a("",10)),i("p",null,[s[4]||(s[4]=n("原始BERT :cite:",-1)),s[5]||(s[5]=i("code",null,"Devlin.Chang.Lee.ea.2018",-1)),s[6]||(s[6]=n("有两个不同模型尺寸的版本。基本模型（",-1)),i("mjx-container",p,[(t(),h("svg",e,[...s[0]||(s[0]=[a("",1)])])),s[1]||(s[1]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("msub",null,[i("mtext",null,"BERT"),i("mrow",{"data-mjx-texclass":"ORD"},[i("mtext",null,"BASE")])])])],-1))]),s[7]||(s[7]=n("）使用12层（Transformer编码器块），768个隐藏单元（隐藏大小）和12个自注意头。大模型（",-1)),i("mjx-container",E,[(t(),h("svg",d,[...s[2]||(s[2]=[a("",1)])])),s[3]||(s[3]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("msub",null,[i("mtext",null,"BERT"),i("mrow",{"data-mjx-texclass":"ORD"},[i("mtext",null,"LARGE")])])])],-1))]),s[8]||(s[8]=n("）使用24层，1024个隐藏单元和16个自注意头。值得注意的是，前者有1.1亿个参数，后者有3.4亿个参数。为了便于演示，我们定义了一个小的BERT，使用了2层、128个隐藏单元和2个自注意头。",-1))]),s[15]||(s[15]=a("",26)),i("ol",null,[s[13]||(s[13]=i("li",null,"在实验中，我们可以看到遮蔽语言模型损失明显高于下一句预测损失。为什么？",-1)),i("li",null,[s[11]||(s[11]=n("将BERT输入序列的最大长度设置为512（与原始BERT模型相同）。使用原始BERT模型的配置，如",-1)),i("mjx-container",r,[(t(),h("svg",g,[...s[9]||(s[9]=[a("",1)])])),s[10]||(s[10]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("msub",null,[i("mtext",null,"BERT"),i("mrow",{"data-mjx-texclass":"ORD"},[i("mtext",null,"LARGE")])])])],-1))]),s[12]||(s[12]=n("。运行此部分时是否遇到错误？为什么？",-1))])]),s[16]||(s[16]=a("",3))])}const Q=l(k,[["render",y]]);export{C as __pageData,Q as default};
