import{_ as t,c as h,o as k,j as i,ag as n,a}from"./chunks/framework.C2Gjomh7.js";const l="/MyBlog/assets/lenet.CwrnyfBP.svg",p="/MyBlog/assets/lenet-vert.CZdUoAV8.svg",v=JSON.parse('{"title":"卷积神经网络（LeNet）","description":"","frontmatter":{},"headers":[],"relativePath":"ai/DeepLearning/卷积神经网络/lenet.md","filePath":"ai/DeepLearning/卷积神经网络/lenet.md","lastUpdated":1756829839000}'),e={name:"ai/DeepLearning/卷积神经网络/lenet.md"},E={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},r={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.05ex"},xmlns:"http://www.w3.org/2000/svg",width:"7.291ex",height:"1.557ex",role:"img",focusable:"false",viewBox:"0 -666 3222.4 688","aria-hidden":"true"},d={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},g={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.05ex"},xmlns:"http://www.w3.org/2000/svg",width:"5.028ex",height:"1.557ex",role:"img",focusable:"false",viewBox:"0 -666 2222.4 688","aria-hidden":"true"},y={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},F={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"0"},xmlns:"http://www.w3.org/2000/svg",width:"5.028ex",height:"1.507ex",role:"img",focusable:"false",viewBox:"0 -666 2222.4 666","aria-hidden":"true"},o={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},c={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.05ex"},xmlns:"http://www.w3.org/2000/svg",width:"7.291ex",height:"1.557ex",role:"img",focusable:"false",viewBox:"0 -666 3222.4 688","aria-hidden":"true"},C={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},A={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.05ex"},xmlns:"http://www.w3.org/2000/svg",width:"5.028ex",height:"1.557ex",role:"img",focusable:"false",viewBox:"0 -666 2222.4 688","aria-hidden":"true"};function B(D,s,m,T,u,_){return k(),h("div",null,[s[27]||(s[27]=i("h1",{id:"卷积神经网络-lenet",tabindex:"-1"},[a("卷积神经网络（LeNet） "),i("a",{class:"header-anchor",href:"#卷积神经网络-lenet","aria-label":'Permalink to "卷积神经网络（LeNet）"'},"​")],-1)),s[28]||(s[28]=i("p",null,[a("🏷️"),i("code",null,"sec_lenet")],-1)),i("p",null,[s[2]||(s[2]=a("通过之前几节，我们学习了构建一个完整卷积神经网络的所需组件。 回想一下，之前我们将softmax回归模型（ :numref:",-1)),s[3]||(s[3]=i("code",null,"sec_softmax_scratch",-1)),s[4]||(s[4]=a("）和多层感知机模型（ :numref:",-1)),s[5]||(s[5]=i("code",null,"sec_mlp_scratch",-1)),s[6]||(s[6]=a("）应用于Fashion-MNIST数据集中的服装图片。 为了能够应用softmax回归和多层感知机，我们首先将每个大小为",-1)),i("mjx-container",E,[(k(),h("svg",r,[...s[0]||(s[0]=[n("",1)])])),s[1]||(s[1]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mn",null,"28"),i("mo",null,"×"),i("mn",null,"28")])],-1))]),s[7]||(s[7]=a("的图像展平为一个784维的固定长度的一维向量，然后用全连接层对其进行处理。 而现在，我们已经掌握了卷积层的处理方法，我们可以在图像中保留空间结构。 同时，用卷积层代替全连接层的另一个好处是：模型更简洁、所需的参数更少。",-1))]),s[29]||(s[29]=n("",7)),i("p",null,[s[12]||(s[12]=a("每个卷积块中的基本单元是一个卷积层、一个sigmoid激活函数和平均汇聚层。请注意，虽然ReLU和最大汇聚层更有效，但它们在20世纪90年代还没有出现。每个卷积层使用",-1)),i("mjx-container",d,[(k(),h("svg",g,[...s[8]||(s[8]=[n("",1)])])),s[9]||(s[9]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mn",null,"5"),i("mo",null,"×"),i("mn",null,"5")])],-1))]),s[13]||(s[13]=a("卷积核和一个sigmoid激活函数。这些层将输入映射到多个二维特征输出，通常同时增加通道的数量。第一卷积层有6个输出通道，而第二个卷积层有16个输出通道。每个",-1)),i("mjx-container",y,[(k(),h("svg",F,[...s[10]||(s[10]=[n("",1)])])),s[11]||(s[11]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mn",null,"2"),i("mo",null,"×"),i("mn",null,"2")])],-1))]),s[14]||(s[14]=a("池操作（步幅2）通过空间下采样将维数减少4倍。卷积的输出形状由批量大小、通道数、高度、宽度决定。",-1))]),s[30]||(s[30]=n("",7)),i("p",null,[s[17]||(s[17]=a("下面，我们将一个大小为",-1)),i("mjx-container",o,[(k(),h("svg",c,[...s[15]||(s[15]=[n("",1)])])),s[16]||(s[16]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mn",null,"28"),i("mo",null,"×"),i("mn",null,"28")])],-1))]),s[18]||(s[18]=a("的单通道（黑白）图像通过LeNet。通过在每一层打印输出的形状，我们可以[",-1)),s[19]||(s[19]=i("strong",null,"检查模型",-1)),s[20]||(s[20]=a("]，以确保其操作与我们期望的 :numref:",-1)),s[21]||(s[21]=i("code",null,"img_lenet_vert",-1)),s[22]||(s[22]=a("一致。",-1))]),s[31]||(s[31]=n("",5)),i("p",null,[s[25]||(s[25]=a("请注意，在整个卷积块中，与上一层相比，每一层特征的高度和宽度都减小了。 第一个卷积层使用2个像素的填充，来补偿",-1)),i("mjx-container",C,[(k(),h("svg",A,[...s[23]||(s[23]=[n("",1)])])),s[24]||(s[24]=i("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[i("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[i("mn",null,"5"),i("mo",null,"×"),i("mn",null,"5")])],-1))]),s[26]||(s[26]=a("卷积核导致的特征减少。 相反，第二个卷积层没有填充，因此高度和宽度都减少了4个像素。 随着层叠的上升，通道的数量从输入时的1个，增加到第一个卷积层之后的6个，再到第二个卷积层之后的16个。 同时，每个汇聚层的高度和宽度都减半。最后，每个全连接层减少维数，最终输出一个维数与结果分类数相匹配的输出。",-1))]),s[32]||(s[32]=n("",24))])}const f=t(e,[["render",B]]);export{v as __pageData,f as default};
