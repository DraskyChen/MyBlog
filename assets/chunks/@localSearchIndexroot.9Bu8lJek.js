const e='{"documentCount":1551,"nextId":1551,"documentIds":{"0":"/MyBlog/Examples/api-examples.html#runtime-api-examples","1":"/MyBlog/Examples/api-examples.html#results","2":"/MyBlog/Examples/api-examples.html#theme-data","3":"/MyBlog/Examples/api-examples.html#page-data","4":"/MyBlog/Examples/api-examples.html#page-frontmatter","5":"/MyBlog/Examples/api-examples.html#more","6":"/MyBlog/Examples/markdown-examples.html#markdown-extension-examples","7":"/MyBlog/Examples/markdown-examples.html#syntax-highlighting","8":"/MyBlog/Examples/markdown-examples.html#custom-containers","9":"/MyBlog/Examples/markdown-examples.html#more","10":"/MyBlog/README.html#mypress","11":"/MyBlog/README.html#功能","12":"/MyBlog/README.html#技术栈","13":"/MyBlog/README.html#安装","14":"/MyBlog/README.html#使用","15":"/MyBlog/README.html#开发模式","16":"/MyBlog/README.html#构建","17":"/MyBlog/README.html#预览","18":"/MyBlog/README.html#许可证","19":"/MyBlog/ai/DeepLearning/优化算法/adadelta.html#adadelta","20":"/MyBlog/ai/DeepLearning/优化算法/adadelta.html#adadelta算法","21":"/MyBlog/ai/DeepLearning/优化算法/adadelta.html#代码实现","22":"/MyBlog/ai/DeepLearning/优化算法/adadelta.html#小结","23":"/MyBlog/ai/DeepLearning/优化算法/adadelta.html#练习","24":"/MyBlog/ai/DeepLearning/优化算法/adagrad.html#adagrad算法","25":"/MyBlog/ai/DeepLearning/优化算法/adagrad.html#稀疏特征和学习率","26":"/MyBlog/ai/DeepLearning/优化算法/adagrad.html#预处理","27":"/MyBlog/ai/DeepLearning/优化算法/adagrad.html#算法","28":"/MyBlog/ai/DeepLearning/优化算法/adagrad.html#从零开始实现","29":"/MyBlog/ai/DeepLearning/优化算法/adagrad.html#简洁实现","30":"/MyBlog/ai/DeepLearning/优化算法/adagrad.html#小结","31":"/MyBlog/ai/DeepLearning/优化算法/adagrad.html#练习","32":"/MyBlog/ai/DeepLearning/优化算法/adam.html#adam算法","33":"/MyBlog/ai/DeepLearning/优化算法/adam.html#算法","34":"/MyBlog/ai/DeepLearning/优化算法/adam.html#实现","35":"/MyBlog/ai/DeepLearning/优化算法/adam.html#yogi","36":"/MyBlog/ai/DeepLearning/优化算法/adam.html#小结","37":"/MyBlog/ai/DeepLearning/优化算法/adam.html#练习","38":"/MyBlog/ai/DeepLearning/优化算法/convexity.html#凸性","39":"/MyBlog/ai/DeepLearning/优化算法/convexity.html#定义","40":"/MyBlog/ai/DeepLearning/优化算法/convexity.html#凸集","41":"/MyBlog/ai/DeepLearning/优化算法/convexity.html#凸函数","42":"/MyBlog/ai/DeepLearning/优化算法/convexity.html#詹森不等式","43":"/MyBlog/ai/DeepLearning/优化算法/convexity.html#性质","44":"/MyBlog/ai/DeepLearning/优化算法/convexity.html#局部极小值是全局极小值","45":"/MyBlog/ai/DeepLearning/优化算法/convexity.html#凸函数的下水平集是凸的","46":"/MyBlog/ai/DeepLearning/优化算法/convexity.html#凸性和二阶导数","47":"/MyBlog/ai/DeepLearning/优化算法/convexity.html#约束","48":"/MyBlog/ai/DeepLearning/优化算法/convexity.html#拉格朗日函数","49":"/MyBlog/ai/DeepLearning/优化算法/convexity.html#惩罚","50":"/MyBlog/ai/DeepLearning/优化算法/convexity.html#投影","51":"/MyBlog/ai/DeepLearning/优化算法/convexity.html#小结","52":"/MyBlog/ai/DeepLearning/优化算法/convexity.html#练习","53":"/MyBlog/ai/DeepLearning/优化算法/gd.html#梯度下降","54":"/MyBlog/ai/DeepLearning/优化算法/gd.html#一维梯度下降","55":"/MyBlog/ai/DeepLearning/优化算法/gd.html#学习率","56":"/MyBlog/ai/DeepLearning/优化算法/gd.html#局部最小值","57":"/MyBlog/ai/DeepLearning/优化算法/gd.html#多元梯度下降","58":"/MyBlog/ai/DeepLearning/优化算法/gd.html#自适应方法","59":"/MyBlog/ai/DeepLearning/优化算法/gd.html#牛顿法","60":"/MyBlog/ai/DeepLearning/优化算法/gd.html#收敛性分析","61":"/MyBlog/ai/DeepLearning/优化算法/gd.html#预处理","62":"/MyBlog/ai/DeepLearning/优化算法/gd.html#梯度下降和线搜索","63":"/MyBlog/ai/DeepLearning/优化算法/gd.html#小结","64":"/MyBlog/ai/DeepLearning/优化算法/gd.html#练习","65":"/MyBlog/ai/DeepLearning/优化算法/#优化算法","66":"/MyBlog/ai/DeepLearning/优化算法/lr-scheduler.html#学习率调度器","67":"/MyBlog/ai/DeepLearning/优化算法/lr-scheduler.html#一个简单的问题","68":"/MyBlog/ai/DeepLearning/优化算法/lr-scheduler.html#学习率调度器-1","69":"/MyBlog/ai/DeepLearning/优化算法/lr-scheduler.html#策略","70":"/MyBlog/ai/DeepLearning/优化算法/lr-scheduler.html#单因子调度器","71":"/MyBlog/ai/DeepLearning/优化算法/lr-scheduler.html#多因子调度器","72":"/MyBlog/ai/DeepLearning/优化算法/lr-scheduler.html#余弦调度器","73":"/MyBlog/ai/DeepLearning/优化算法/lr-scheduler.html#预热","74":"/MyBlog/ai/DeepLearning/优化算法/lr-scheduler.html#小结","75":"/MyBlog/ai/DeepLearning/优化算法/lr-scheduler.html#练习","76":"/MyBlog/ai/DeepLearning/优化算法/minibatch-sgd.html#小批量随机梯度下降","77":"/MyBlog/ai/DeepLearning/优化算法/minibatch-sgd.html#向量化和缓存","78":"/MyBlog/ai/DeepLearning/优化算法/minibatch-sgd.html#小批量","79":"/MyBlog/ai/DeepLearning/优化算法/minibatch-sgd.html#读取数据集","80":"/MyBlog/ai/DeepLearning/优化算法/minibatch-sgd.html#从零开始实现","81":"/MyBlog/ai/DeepLearning/优化算法/minibatch-sgd.html#简洁实现","82":"/MyBlog/ai/DeepLearning/优化算法/minibatch-sgd.html#小结","83":"/MyBlog/ai/DeepLearning/优化算法/minibatch-sgd.html#练习","84":"/MyBlog/ai/DeepLearning/优化算法/momentum.html#动量法","85":"/MyBlog/ai/DeepLearning/优化算法/momentum.html#基础","86":"/MyBlog/ai/DeepLearning/优化算法/momentum.html#泄漏平均值","87":"/MyBlog/ai/DeepLearning/优化算法/momentum.html#条件不佳的问题","88":"/MyBlog/ai/DeepLearning/优化算法/momentum.html#动量法-1","89":"/MyBlog/ai/DeepLearning/优化算法/momentum.html#有效样本权重","90":"/MyBlog/ai/DeepLearning/优化算法/momentum.html#实际实验","91":"/MyBlog/ai/DeepLearning/优化算法/momentum.html#从零开始实现","92":"/MyBlog/ai/DeepLearning/优化算法/momentum.html#简洁实现","93":"/MyBlog/ai/DeepLearning/优化算法/momentum.html#理论分析","94":"/MyBlog/ai/DeepLearning/优化算法/momentum.html#二次凸函数","95":"/MyBlog/ai/DeepLearning/优化算法/momentum.html#标量函数","96":"/MyBlog/ai/DeepLearning/优化算法/momentum.html#小结","97":"/MyBlog/ai/DeepLearning/优化算法/momentum.html#练习","98":"/MyBlog/ai/DeepLearning/优化算法/optimization-intro.html#优化和深度学习","99":"/MyBlog/ai/DeepLearning/优化算法/optimization-intro.html#优化的目标","100":"/MyBlog/ai/DeepLearning/优化算法/optimization-intro.html#深度学习中的优化挑战","101":"/MyBlog/ai/DeepLearning/优化算法/optimization-intro.html#局部最小值","102":"/MyBlog/ai/DeepLearning/优化算法/optimization-intro.html#鞍点","103":"/MyBlog/ai/DeepLearning/优化算法/optimization-intro.html#梯度消失","104":"/MyBlog/ai/DeepLearning/优化算法/optimization-intro.html#小结","105":"/MyBlog/ai/DeepLearning/优化算法/optimization-intro.html#练习","106":"/MyBlog/ai/DeepLearning/优化算法/rmsprop.html#rmsprop算法","107":"/MyBlog/ai/DeepLearning/优化算法/rmsprop.html#算法","108":"/MyBlog/ai/DeepLearning/优化算法/rmsprop.html#从零开始实现","109":"/MyBlog/ai/DeepLearning/优化算法/rmsprop.html#简洁实现","110":"/MyBlog/ai/DeepLearning/优化算法/rmsprop.html#小结","111":"/MyBlog/ai/DeepLearning/优化算法/rmsprop.html#练习","112":"/MyBlog/ai/DeepLearning/优化算法/sgd.html#随机梯度下降","113":"/MyBlog/ai/DeepLearning/优化算法/sgd.html#随机梯度更新","114":"/MyBlog/ai/DeepLearning/优化算法/sgd.html#动态学习率","115":"/MyBlog/ai/DeepLearning/优化算法/sgd.html#凸目标的收敛性分析","116":"/MyBlog/ai/DeepLearning/优化算法/sgd.html#随机梯度和有限样本","117":"/MyBlog/ai/DeepLearning/优化算法/sgd.html#小结","118":"/MyBlog/ai/DeepLearning/优化算法/sgd.html#练习","119":"/MyBlog/ai/DeepLearning/卷积神经网络/channels.html#多输入多输出通道","120":"/MyBlog/ai/DeepLearning/卷积神经网络/channels.html#多输入通道","121":"/MyBlog/ai/DeepLearning/卷积神经网络/channels.html#多输出通道","122":"/MyBlog/ai/DeepLearning/卷积神经网络/channels.html#卷积层","123":"/MyBlog/ai/DeepLearning/卷积神经网络/channels.html#小结","124":"/MyBlog/ai/DeepLearning/卷积神经网络/channels.html#练习","125":"/MyBlog/ai/DeepLearning/卷积神经网络/conv-layer.html#图像卷积","126":"/MyBlog/ai/DeepLearning/卷积神经网络/conv-layer.html#互相关运算","127":"/MyBlog/ai/DeepLearning/卷积神经网络/conv-layer.html#卷积层","128":"/MyBlog/ai/DeepLearning/卷积神经网络/conv-layer.html#图像中目标的边缘检测","129":"/MyBlog/ai/DeepLearning/卷积神经网络/conv-layer.html#学习卷积核","130":"/MyBlog/ai/DeepLearning/卷积神经网络/conv-layer.html#互相关和卷积","131":"/MyBlog/ai/DeepLearning/卷积神经网络/conv-layer.html#特征映射和感受野","132":"/MyBlog/ai/DeepLearning/卷积神经网络/conv-layer.html#小结","133":"/MyBlog/ai/DeepLearning/卷积神经网络/conv-layer.html#练习","134":"/MyBlog/ai/DeepLearning/卷积神经网络/#卷积神经网络","135":"/MyBlog/ai/DeepLearning/卷积神经网络/lenet.html#卷积神经网络-lenet","136":"/MyBlog/ai/DeepLearning/卷积神经网络/lenet.html#lenet","137":"/MyBlog/ai/DeepLearning/卷积神经网络/lenet.html#模型训练","138":"/MyBlog/ai/DeepLearning/卷积神经网络/lenet.html#小结","139":"/MyBlog/ai/DeepLearning/卷积神经网络/lenet.html#练习","140":"/MyBlog/ai/DeepLearning/卷积神经网络/padding-and-strides.html#填充和步幅","141":"/MyBlog/ai/DeepLearning/卷积神经网络/padding-and-strides.html#填充","142":"/MyBlog/ai/DeepLearning/卷积神经网络/padding-and-strides.html#步幅","143":"/MyBlog/ai/DeepLearning/卷积神经网络/padding-and-strides.html#小结","144":"/MyBlog/ai/DeepLearning/卷积神经网络/padding-and-strides.html#练习","145":"/MyBlog/ai/DeepLearning/卷积神经网络/pooling.html#汇聚层","146":"/MyBlog/ai/DeepLearning/卷积神经网络/pooling.html#最大汇聚层和平均汇聚层","147":"/MyBlog/ai/DeepLearning/卷积神经网络/pooling.html#填充和步幅","148":"/MyBlog/ai/DeepLearning/卷积神经网络/pooling.html#多个通道","149":"/MyBlog/ai/DeepLearning/卷积神经网络/pooling.html#小结","150":"/MyBlog/ai/DeepLearning/卷积神经网络/pooling.html#练习","151":"/MyBlog/ai/DeepLearning/卷积神经网络/why-conv.html#从全连接层到卷积","152":"/MyBlog/ai/DeepLearning/卷积神经网络/why-conv.html#不变性","153":"/MyBlog/ai/DeepLearning/卷积神经网络/why-conv.html#多层感知机的限制","154":"/MyBlog/ai/DeepLearning/卷积神经网络/why-conv.html#平移不变性","155":"/MyBlog/ai/DeepLearning/卷积神经网络/why-conv.html#局部性","156":"/MyBlog/ai/DeepLearning/卷积神经网络/why-conv.html#卷积","157":"/MyBlog/ai/DeepLearning/卷积神经网络/why-conv.html#沃尔多在哪里-回顾","158":"/MyBlog/ai/DeepLearning/卷积神经网络/why-conv.html#通道","159":"/MyBlog/ai/DeepLearning/卷积神经网络/why-conv.html#小结","160":"/MyBlog/ai/DeepLearning/卷积神经网络/why-conv.html#练习","161":"/MyBlog/ai/DeepLearning/多层感知机/backprop.html#前向传播、反向传播和计算图","162":"/MyBlog/ai/DeepLearning/多层感知机/backprop.html#前向传播","163":"/MyBlog/ai/DeepLearning/多层感知机/backprop.html#前向传播计算图","164":"/MyBlog/ai/DeepLearning/多层感知机/backprop.html#反向传播","165":"/MyBlog/ai/DeepLearning/多层感知机/backprop.html#训练神经网络","166":"/MyBlog/ai/DeepLearning/多层感知机/backprop.html#小结","167":"/MyBlog/ai/DeepLearning/多层感知机/backprop.html#练习","168":"/MyBlog/ai/DeepLearning/多层感知机/dropout.html#暂退法-dropout","169":"/MyBlog/ai/DeepLearning/多层感知机/dropout.html#重新审视过拟合","170":"/MyBlog/ai/DeepLearning/多层感知机/dropout.html#扰动的稳健性","171":"/MyBlog/ai/DeepLearning/多层感知机/dropout.html#实践中的暂退法","172":"/MyBlog/ai/DeepLearning/多层感知机/dropout.html#从零开始实现","173":"/MyBlog/ai/DeepLearning/多层感知机/dropout.html#定义模型参数","174":"/MyBlog/ai/DeepLearning/多层感知机/dropout.html#定义模型","175":"/MyBlog/ai/DeepLearning/多层感知机/dropout.html#训练和测试","176":"/MyBlog/ai/DeepLearning/多层感知机/dropout.html#简洁实现","177":"/MyBlog/ai/DeepLearning/多层感知机/dropout.html#小结","178":"/MyBlog/ai/DeepLearning/多层感知机/dropout.html#练习","179":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#环境和分布偏移","180":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#分布偏移的类型","181":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#协变量偏移","182":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#标签偏移","183":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#概念偏移","184":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#分布偏移示例","185":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#医学诊断","186":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#自动驾驶汽车","187":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#非平稳分布","188":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#更多轶事","189":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#分布偏移纠正","190":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#经验风险与实际风险","191":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#协变量偏移纠正","192":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#标签偏移纠正","193":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#概念偏移纠正","194":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#学习问题的分类法","195":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#批量学习","196":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#在线学习","197":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#老虎机","198":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#控制","199":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#强化学习","200":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#考虑到环境","201":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#机器学习中的公平、责任和透明度","202":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#小结","203":"/MyBlog/ai/DeepLearning/多层感知机/environment.html#练习","204":"/MyBlog/ai/DeepLearning/多层感知机/#多层感知机","205":"/MyBlog/ai/DeepLearning/多层感知机/kaggle-house-price.html#实战kaggle比赛-预测房价","206":"/MyBlog/ai/DeepLearning/多层感知机/kaggle-house-price.html#下载和缓存数据集","207":"/MyBlog/ai/DeepLearning/多层感知机/kaggle-house-price.html#kaggle","208":"/MyBlog/ai/DeepLearning/多层感知机/kaggle-house-price.html#访问和读取数据集","209":"/MyBlog/ai/DeepLearning/多层感知机/kaggle-house-price.html#数据预处理","210":"/MyBlog/ai/DeepLearning/多层感知机/kaggle-house-price.html#训练","211":"/MyBlog/ai/DeepLearning/多层感知机/kaggle-house-price.html#折交叉验证","212":"/MyBlog/ai/DeepLearning/多层感知机/kaggle-house-price.html#模型选择","213":"/MyBlog/ai/DeepLearning/多层感知机/kaggle-house-price.html#提交kaggle预测","214":"/MyBlog/ai/DeepLearning/多层感知机/kaggle-house-price.html#小结","215":"/MyBlog/ai/DeepLearning/多层感知机/kaggle-house-price.html#练习","216":"/MyBlog/ai/DeepLearning/多层感知机/mlp-scratch.html#多层感知机的从零开始实现","217":"/MyBlog/ai/DeepLearning/多层感知机/mlp-scratch.html#初始化模型参数","218":"/MyBlog/ai/DeepLearning/多层感知机/mlp-scratch.html#激活函数","219":"/MyBlog/ai/DeepLearning/多层感知机/mlp-scratch.html#模型","220":"/MyBlog/ai/DeepLearning/多层感知机/mlp-scratch.html#损失函数","221":"/MyBlog/ai/DeepLearning/多层感知机/mlp-scratch.html#训练","222":"/MyBlog/ai/DeepLearning/多层感知机/mlp-scratch.html#小结","223":"/MyBlog/ai/DeepLearning/多层感知机/mlp-scratch.html#练习","224":"/MyBlog/ai/DeepLearning/多层感知机/mlp-concise.html#多层感知机的简洁实现","225":"/MyBlog/ai/DeepLearning/多层感知机/mlp-concise.html#模型","226":"/MyBlog/ai/DeepLearning/多层感知机/mlp-concise.html#小结","227":"/MyBlog/ai/DeepLearning/多层感知机/mlp-concise.html#练习","228":"/MyBlog/ai/DeepLearning/多层感知机/mlp.html#多层感知机","229":"/MyBlog/ai/DeepLearning/多层感知机/mlp.html#隐藏层","230":"/MyBlog/ai/DeepLearning/多层感知机/mlp.html#线性模型可能会出错","231":"/MyBlog/ai/DeepLearning/多层感知机/mlp.html#在网络中加入隐藏层","232":"/MyBlog/ai/DeepLearning/多层感知机/mlp.html#从线性到非线性","233":"/MyBlog/ai/DeepLearning/多层感知机/mlp.html#通用近似定理","234":"/MyBlog/ai/DeepLearning/多层感知机/mlp.html#激活函数","235":"/MyBlog/ai/DeepLearning/多层感知机/mlp.html#relu函数","236":"/MyBlog/ai/DeepLearning/多层感知机/mlp.html#sigmoid函数","237":"/MyBlog/ai/DeepLearning/多层感知机/mlp.html#tanh函数","238":"/MyBlog/ai/DeepLearning/多层感知机/mlp.html#小结","239":"/MyBlog/ai/DeepLearning/多层感知机/mlp.html#练习","240":"/MyBlog/ai/DeepLearning/多层感知机/numerical-stability-and-init.html#数值稳定性和模型初始化","241":"/MyBlog/ai/DeepLearning/多层感知机/numerical-stability-and-init.html#梯度消失和梯度爆炸","242":"/MyBlog/ai/DeepLearning/多层感知机/numerical-stability-and-init.html#梯度消失","243":"/MyBlog/ai/DeepLearning/多层感知机/numerical-stability-and-init.html#梯度爆炸","244":"/MyBlog/ai/DeepLearning/多层感知机/numerical-stability-and-init.html#打破对称性","245":"/MyBlog/ai/DeepLearning/多层感知机/numerical-stability-and-init.html#参数初始化","246":"/MyBlog/ai/DeepLearning/多层感知机/numerical-stability-and-init.html#默认初始化","247":"/MyBlog/ai/DeepLearning/多层感知机/numerical-stability-and-init.html#xavier初始化","248":"/MyBlog/ai/DeepLearning/多层感知机/numerical-stability-and-init.html#额外阅读","249":"/MyBlog/ai/DeepLearning/多层感知机/numerical-stability-and-init.html#小结","250":"/MyBlog/ai/DeepLearning/多层感知机/numerical-stability-and-init.html#练习","251":"/MyBlog/ai/DeepLearning/多层感知机/underfit-overfit.html#模型选择、欠拟合和过拟合","252":"/MyBlog/ai/DeepLearning/多层感知机/underfit-overfit.html#训练误差和泛化误差","253":"/MyBlog/ai/DeepLearning/多层感知机/underfit-overfit.html#统计学习理论","254":"/MyBlog/ai/DeepLearning/多层感知机/underfit-overfit.html#模型复杂性","255":"/MyBlog/ai/DeepLearning/多层感知机/underfit-overfit.html#模型选择","256":"/MyBlog/ai/DeepLearning/多层感知机/underfit-overfit.html#验证集","257":"/MyBlog/ai/DeepLearning/多层感知机/underfit-overfit.html#折交叉验证","258":"/MyBlog/ai/DeepLearning/多层感知机/underfit-overfit.html#欠拟合还是过拟合","259":"/MyBlog/ai/DeepLearning/多层感知机/underfit-overfit.html#模型复杂性-1","260":"/MyBlog/ai/DeepLearning/多层感知机/underfit-overfit.html#数据集大小","261":"/MyBlog/ai/DeepLearning/多层感知机/underfit-overfit.html#多项式回归","262":"/MyBlog/ai/DeepLearning/多层感知机/underfit-overfit.html#生成数据集","263":"/MyBlog/ai/DeepLearning/多层感知机/underfit-overfit.html#对模型进行训练和测试","264":"/MyBlog/ai/DeepLearning/多层感知机/underfit-overfit.html#三阶多项式函数拟合-正常","265":"/MyBlog/ai/DeepLearning/多层感知机/underfit-overfit.html#线性函数拟合-欠拟合","266":"/MyBlog/ai/DeepLearning/多层感知机/underfit-overfit.html#高阶多项式函数拟合-过拟合","267":"/MyBlog/ai/DeepLearning/多层感知机/underfit-overfit.html#小结","268":"/MyBlog/ai/DeepLearning/多层感知机/underfit-overfit.html#练习","269":"/MyBlog/ai/DeepLearning/多层感知机/weight-decay.html#权重衰减","270":"/MyBlog/ai/DeepLearning/多层感知机/weight-decay.html#范数与权重衰减","271":"/MyBlog/ai/DeepLearning/多层感知机/weight-decay.html#高维线性回归","272":"/MyBlog/ai/DeepLearning/多层感知机/weight-decay.html#从零开始实现","273":"/MyBlog/ai/DeepLearning/多层感知机/weight-decay.html#初始化模型参数","274":"/MyBlog/ai/DeepLearning/多层感知机/weight-decay.html#定义范数惩罚","275":"/MyBlog/ai/DeepLearning/多层感知机/weight-decay.html#定义训练代码实现","276":"/MyBlog/ai/DeepLearning/多层感知机/weight-decay.html#忽略正则化直接训练","277":"/MyBlog/ai/DeepLearning/多层感知机/weight-decay.html#使用权重衰减","278":"/MyBlog/ai/DeepLearning/多层感知机/weight-decay.html#简洁实现","279":"/MyBlog/ai/DeepLearning/多层感知机/weight-decay.html#小结","280":"/MyBlog/ai/DeepLearning/多层感知机/weight-decay.html#练习","281":"/MyBlog/ai/DeepLearning/引言.html#引言","282":"/MyBlog/ai/DeepLearning/引言.html#日常生活中的机器学习","283":"/MyBlog/ai/DeepLearning/引言.html#机器学习中的关键组件","284":"/MyBlog/ai/DeepLearning/引言.html#数据","285":"/MyBlog/ai/DeepLearning/引言.html#模型","286":"/MyBlog/ai/DeepLearning/引言.html#目标函数","287":"/MyBlog/ai/DeepLearning/引言.html#优化算法","288":"/MyBlog/ai/DeepLearning/引言.html#各种机器学习问题","289":"/MyBlog/ai/DeepLearning/引言.html#监督学习","290":"/MyBlog/ai/DeepLearning/引言.html#回归","291":"/MyBlog/ai/DeepLearning/引言.html#分类","292":"/MyBlog/ai/DeepLearning/引言.html#标记问题","293":"/MyBlog/ai/DeepLearning/引言.html#搜索","294":"/MyBlog/ai/DeepLearning/引言.html#推荐系统","295":"/MyBlog/ai/DeepLearning/引言.html#序列学习","296":"/MyBlog/ai/DeepLearning/引言.html#无监督学习","297":"/MyBlog/ai/DeepLearning/引言.html#与环境互动","298":"/MyBlog/ai/DeepLearning/引言.html#强化学习","299":"/MyBlog/ai/DeepLearning/引言.html#起源","300":"/MyBlog/ai/DeepLearning/引言.html#深度学习的发展","301":"/MyBlog/ai/DeepLearning/引言.html#深度学习的成功案例","302":"/MyBlog/ai/DeepLearning/引言.html#特点","303":"/MyBlog/ai/DeepLearning/引言.html#小结","304":"/MyBlog/ai/DeepLearning/引言.html#练习","305":"/MyBlog/ai/DeepLearning/循环神经网络/#循环神经网络","306":"/MyBlog/ai/DeepLearning/循环神经网络/bptt.html#通过时间反向传播","307":"/MyBlog/ai/DeepLearning/循环神经网络/bptt.html#循环神经网络的梯度分析","308":"/MyBlog/ai/DeepLearning/循环神经网络/bptt.html#完全计算","309":"/MyBlog/ai/DeepLearning/循环神经网络/bptt.html#截断时间步","310":"/MyBlog/ai/DeepLearning/循环神经网络/bptt.html#随机截断","311":"/MyBlog/ai/DeepLearning/循环神经网络/bptt.html#比较策略","312":"/MyBlog/ai/DeepLearning/循环神经网络/bptt.html#通过时间反向传播的细节","313":"/MyBlog/ai/DeepLearning/循环神经网络/bptt.html#小结","314":"/MyBlog/ai/DeepLearning/循环神经网络/bptt.html#练习","315":"/MyBlog/ai/DeepLearning/循环神经网络/language-models-and-dataset.html#语言模型和数据集","316":"/MyBlog/ai/DeepLearning/循环神经网络/language-models-and-dataset.html#学习语言模型","317":"/MyBlog/ai/DeepLearning/循环神经网络/language-models-and-dataset.html#马尔可夫模型与元语法","318":"/MyBlog/ai/DeepLearning/循环神经网络/language-models-and-dataset.html#自然语言统计","319":"/MyBlog/ai/DeepLearning/循环神经网络/language-models-and-dataset.html#读取长序列数据","320":"/MyBlog/ai/DeepLearning/循环神经网络/language-models-and-dataset.html#随机采样","321":"/MyBlog/ai/DeepLearning/循环神经网络/language-models-and-dataset.html#顺序分区","322":"/MyBlog/ai/DeepLearning/循环神经网络/language-models-and-dataset.html#小结","323":"/MyBlog/ai/DeepLearning/循环神经网络/language-models-and-dataset.html#练习","324":"/MyBlog/ai/DeepLearning/循环神经网络/rnn-concise.html#循环神经网络的简洁实现","325":"/MyBlog/ai/DeepLearning/循环神经网络/rnn-concise.html#定义模型","326":"/MyBlog/ai/DeepLearning/循环神经网络/rnn-concise.html#训练与预测","327":"/MyBlog/ai/DeepLearning/循环神经网络/rnn-concise.html#小结","328":"/MyBlog/ai/DeepLearning/循环神经网络/rnn-concise.html#练习","329":"/MyBlog/ai/DeepLearning/循环神经网络/rnn-scratch.html#循环神经网络的从零开始实现","330":"/MyBlog/ai/DeepLearning/循环神经网络/rnn-scratch.html#独热编码","331":"/MyBlog/ai/DeepLearning/循环神经网络/rnn-scratch.html#初始化模型参数","332":"/MyBlog/ai/DeepLearning/循环神经网络/rnn-scratch.html#循环神经网络模型","333":"/MyBlog/ai/DeepLearning/循环神经网络/rnn-scratch.html#预测","334":"/MyBlog/ai/DeepLearning/循环神经网络/rnn-scratch.html#梯度裁剪","335":"/MyBlog/ai/DeepLearning/循环神经网络/rnn-scratch.html#训练","336":"/MyBlog/ai/DeepLearning/循环神经网络/rnn-scratch.html#小结","337":"/MyBlog/ai/DeepLearning/循环神经网络/rnn-scratch.html#练习","338":"/MyBlog/ai/DeepLearning/循环神经网络/rnn.html#循环神经网络","339":"/MyBlog/ai/DeepLearning/循环神经网络/rnn.html#无隐状态的神经网络","340":"/MyBlog/ai/DeepLearning/循环神经网络/rnn.html#有隐状态的循环神经网络","341":"/MyBlog/ai/DeepLearning/循环神经网络/rnn.html#基于循环神经网络的字符级语言模型","342":"/MyBlog/ai/DeepLearning/循环神经网络/rnn.html#困惑度-perplexity","343":"/MyBlog/ai/DeepLearning/循环神经网络/rnn.html#小结","344":"/MyBlog/ai/DeepLearning/循环神经网络/rnn.html#练习","345":"/MyBlog/ai/DeepLearning/循环神经网络/sequence.html#序列模型","346":"/MyBlog/ai/DeepLearning/循环神经网络/sequence.html#统计工具","347":"/MyBlog/ai/DeepLearning/循环神经网络/sequence.html#自回归模型","348":"/MyBlog/ai/DeepLearning/循环神经网络/sequence.html#马尔可夫模型","349":"/MyBlog/ai/DeepLearning/循环神经网络/sequence.html#因果关系","350":"/MyBlog/ai/DeepLearning/循环神经网络/sequence.html#训练","351":"/MyBlog/ai/DeepLearning/循环神经网络/sequence.html#预测","352":"/MyBlog/ai/DeepLearning/循环神经网络/sequence.html#小结","353":"/MyBlog/ai/DeepLearning/循环神经网络/sequence.html#练习","354":"/MyBlog/ai/DeepLearning/注意力机制/attention-cues.html#注意力提示","355":"/MyBlog/ai/DeepLearning/注意力机制/attention-cues.html#生物学中的注意力提示","356":"/MyBlog/ai/DeepLearning/注意力机制/attention-cues.html#查询、键和值","357":"/MyBlog/ai/DeepLearning/注意力机制/attention-cues.html#注意力的可视化","358":"/MyBlog/ai/DeepLearning/注意力机制/attention-cues.html#小结","359":"/MyBlog/ai/DeepLearning/注意力机制/attention-cues.html#练习","360":"/MyBlog/ai/DeepLearning/循环神经网络/text-preprocessing.html#文本预处理","361":"/MyBlog/ai/DeepLearning/循环神经网络/text-preprocessing.html#读取数据集","362":"/MyBlog/ai/DeepLearning/循环神经网络/text-preprocessing.html#词元化","363":"/MyBlog/ai/DeepLearning/循环神经网络/text-preprocessing.html#词表","364":"/MyBlog/ai/DeepLearning/循环神经网络/text-preprocessing.html#整合所有功能","365":"/MyBlog/ai/DeepLearning/循环神经网络/text-preprocessing.html#小结","366":"/MyBlog/ai/DeepLearning/循环神经网络/text-preprocessing.html#练习","367":"/MyBlog/ai/DeepLearning/注意力机制/attention-scoring-functions.html#注意力评分函数","368":"/MyBlog/ai/DeepLearning/注意力机制/attention-scoring-functions.html#掩蔽softmax操作","369":"/MyBlog/ai/DeepLearning/注意力机制/attention-scoring-functions.html#加性注意力","370":"/MyBlog/ai/DeepLearning/注意力机制/attention-scoring-functions.html#缩放点积注意力","371":"/MyBlog/ai/DeepLearning/注意力机制/attention-scoring-functions.html#小结","372":"/MyBlog/ai/DeepLearning/注意力机制/attention-scoring-functions.html#练习","373":"/MyBlog/ai/DeepLearning/注意力机制/bahdanau-attention.html#bahdanau-注意力","374":"/MyBlog/ai/DeepLearning/注意力机制/bahdanau-attention.html#模型","375":"/MyBlog/ai/DeepLearning/注意力机制/bahdanau-attention.html#定义注意力解码器","376":"/MyBlog/ai/DeepLearning/注意力机制/bahdanau-attention.html#训练","377":"/MyBlog/ai/DeepLearning/注意力机制/bahdanau-attention.html#小结","378":"/MyBlog/ai/DeepLearning/注意力机制/bahdanau-attention.html#练习","379":"/MyBlog/ai/DeepLearning/注意力机制/#注意力机制","380":"/MyBlog/ai/DeepLearning/注意力机制/multihead-attention.html#多头注意力","381":"/MyBlog/ai/DeepLearning/注意力机制/multihead-attention.html#模型","382":"/MyBlog/ai/DeepLearning/注意力机制/multihead-attention.html#实现","383":"/MyBlog/ai/DeepLearning/注意力机制/multihead-attention.html#小结","384":"/MyBlog/ai/DeepLearning/注意力机制/multihead-attention.html#练习","385":"/MyBlog/ai/DeepLearning/注意力机制/nadaraya-waston.html#注意力汇聚-nadaraya-watson-核回归","386":"/MyBlog/ai/DeepLearning/注意力机制/nadaraya-waston.html#生成数据集","387":"/MyBlog/ai/DeepLearning/注意力机制/nadaraya-waston.html#平均汇聚","388":"/MyBlog/ai/DeepLearning/注意力机制/nadaraya-waston.html#非参数注意力汇聚","389":"/MyBlog/ai/DeepLearning/注意力机制/nadaraya-waston.html#带参数注意力汇聚","390":"/MyBlog/ai/DeepLearning/注意力机制/nadaraya-waston.html#批量矩阵乘法","391":"/MyBlog/ai/DeepLearning/注意力机制/nadaraya-waston.html#定义模型","392":"/MyBlog/ai/DeepLearning/注意力机制/nadaraya-waston.html#训练","393":"/MyBlog/ai/DeepLearning/注意力机制/nadaraya-waston.html#小结","394":"/MyBlog/ai/DeepLearning/注意力机制/nadaraya-waston.html#练习","395":"/MyBlog/ai/DeepLearning/注意力机制/self-attention-and-positional-encoding.html#自注意力和位置编码","396":"/MyBlog/ai/DeepLearning/注意力机制/self-attention-and-positional-encoding.html#自注意力","397":"/MyBlog/ai/DeepLearning/注意力机制/self-attention-and-positional-encoding.html#比较卷积神经网络、循环神经网络和自注意力","398":"/MyBlog/ai/DeepLearning/注意力机制/self-attention-and-positional-encoding.html#位置编码","399":"/MyBlog/ai/DeepLearning/注意力机制/self-attention-and-positional-encoding.html#绝对位置信息","400":"/MyBlog/ai/DeepLearning/注意力机制/self-attention-and-positional-encoding.html#相对位置信息","401":"/MyBlog/ai/DeepLearning/注意力机制/self-attention-and-positional-encoding.html#小结","402":"/MyBlog/ai/DeepLearning/注意力机制/self-attention-and-positional-encoding.html#练习","403":"/MyBlog/ai/DeepLearning/注意力机制/transformer.html#transformer","404":"/MyBlog/ai/DeepLearning/注意力机制/transformer.html#模型","405":"/MyBlog/ai/DeepLearning/注意力机制/transformer.html#基于位置的前馈网络","406":"/MyBlog/ai/DeepLearning/注意力机制/transformer.html#残差连接和层规范化","407":"/MyBlog/ai/DeepLearning/注意力机制/transformer.html#编码器","408":"/MyBlog/ai/DeepLearning/注意力机制/transformer.html#解码器","409":"/MyBlog/ai/DeepLearning/注意力机制/transformer.html#训练","410":"/MyBlog/ai/DeepLearning/注意力机制/transformer.html#小结","411":"/MyBlog/ai/DeepLearning/注意力机制/transformer.html#练习","412":"/MyBlog/ai/DeepLearning/深度学习计算/custom-layer.html#自定义层","413":"/MyBlog/ai/DeepLearning/深度学习计算/custom-layer.html#不带参数的层","414":"/MyBlog/ai/DeepLearning/深度学习计算/custom-layer.html#带参数的层","415":"/MyBlog/ai/DeepLearning/深度学习计算/custom-layer.html#小结","416":"/MyBlog/ai/DeepLearning/深度学习计算/custom-layer.html#练习","417":"/MyBlog/ai/DeepLearning/深度学习计算/deferred-init.html#延后初始化","418":"/MyBlog/ai/DeepLearning/深度学习计算/deferred-init.html#实例化网络","419":"/MyBlog/ai/DeepLearning/深度学习计算/deferred-init.html#小结","420":"/MyBlog/ai/DeepLearning/深度学习计算/deferred-init.html#练习","421":"/MyBlog/ai/DeepLearning/深度学习计算/#深度学习计算","422":"/MyBlog/ai/DeepLearning/深度学习计算/model-construction.html#层和块","423":"/MyBlog/ai/DeepLearning/深度学习计算/model-construction.html#自定义块","424":"/MyBlog/ai/DeepLearning/深度学习计算/model-construction.html#顺序块","425":"/MyBlog/ai/DeepLearning/深度学习计算/model-construction.html#在前向传播函数中执行代码","426":"/MyBlog/ai/DeepLearning/深度学习计算/model-construction.html#效率","427":"/MyBlog/ai/DeepLearning/深度学习计算/model-construction.html#小结","428":"/MyBlog/ai/DeepLearning/深度学习计算/model-construction.html#练习","429":"/MyBlog/ai/DeepLearning/深度学习计算/parameters.html#参数管理","430":"/MyBlog/ai/DeepLearning/深度学习计算/parameters.html#参数访问","431":"/MyBlog/ai/DeepLearning/深度学习计算/parameters.html#目标参数","432":"/MyBlog/ai/DeepLearning/深度学习计算/parameters.html#一次性访问所有参数","433":"/MyBlog/ai/DeepLearning/深度学习计算/parameters.html#从嵌套块收集参数","434":"/MyBlog/ai/DeepLearning/深度学习计算/parameters.html#参数初始化","435":"/MyBlog/ai/DeepLearning/深度学习计算/parameters.html#内置初始化","436":"/MyBlog/ai/DeepLearning/深度学习计算/parameters.html#自定义初始化","437":"/MyBlog/ai/DeepLearning/深度学习计算/parameters.html#参数绑定","438":"/MyBlog/ai/DeepLearning/深度学习计算/parameters.html#小结","439":"/MyBlog/ai/DeepLearning/深度学习计算/parameters.html#练习","440":"/MyBlog/ai/DeepLearning/深度学习计算/read-write.html#读写文件","441":"/MyBlog/ai/DeepLearning/深度学习计算/read-write.html#加载和保存张量","442":"/MyBlog/ai/DeepLearning/深度学习计算/read-write.html#加载和保存模型参数","443":"/MyBlog/ai/DeepLearning/深度学习计算/read-write.html#小结","444":"/MyBlog/ai/DeepLearning/深度学习计算/read-write.html#练习","445":"/MyBlog/ai/DeepLearning/深度学习计算/use-gpu.html#gpu","446":"/MyBlog/ai/DeepLearning/深度学习计算/use-gpu.html#计算设备","447":"/MyBlog/ai/DeepLearning/深度学习计算/use-gpu.html#张量与gpu","448":"/MyBlog/ai/DeepLearning/深度学习计算/use-gpu.html#存储在gpu上","449":"/MyBlog/ai/DeepLearning/深度学习计算/use-gpu.html#复制","450":"/MyBlog/ai/DeepLearning/深度学习计算/use-gpu.html#旁注","451":"/MyBlog/ai/DeepLearning/深度学习计算/use-gpu.html#神经网络与gpu","452":"/MyBlog/ai/DeepLearning/深度学习计算/use-gpu.html#小结","453":"/MyBlog/ai/DeepLearning/深度学习计算/use-gpu.html#练习","454":"/MyBlog/ai/DeepLearning/现代卷积神经网络/alexnet.html#深度卷积神经网络-alexnet","455":"/MyBlog/ai/DeepLearning/现代卷积神经网络/alexnet.html#学习表征","456":"/MyBlog/ai/DeepLearning/现代卷积神经网络/alexnet.html#缺少的成分-数据","457":"/MyBlog/ai/DeepLearning/现代卷积神经网络/alexnet.html#缺少的成分-硬件","458":"/MyBlog/ai/DeepLearning/现代卷积神经网络/alexnet.html#alexnet","459":"/MyBlog/ai/DeepLearning/现代卷积神经网络/alexnet.html#模型设计","460":"/MyBlog/ai/DeepLearning/现代卷积神经网络/alexnet.html#激活函数","461":"/MyBlog/ai/DeepLearning/现代卷积神经网络/alexnet.html#容量控制和预处理","462":"/MyBlog/ai/DeepLearning/现代卷积神经网络/alexnet.html#读取数据集","463":"/MyBlog/ai/DeepLearning/现代卷积神经网络/alexnet.html#训练alexnet","464":"/MyBlog/ai/DeepLearning/现代卷积神经网络/alexnet.html#小结","465":"/MyBlog/ai/DeepLearning/现代卷积神经网络/alexnet.html#练习","466":"/MyBlog/ai/DeepLearning/现代卷积神经网络/batch-norm.html#批量规范化","467":"/MyBlog/ai/DeepLearning/现代卷积神经网络/batch-norm.html#训练深层网络","468":"/MyBlog/ai/DeepLearning/现代卷积神经网络/batch-norm.html#批量规范化层","469":"/MyBlog/ai/DeepLearning/现代卷积神经网络/batch-norm.html#全连接层","470":"/MyBlog/ai/DeepLearning/现代卷积神经网络/batch-norm.html#卷积层","471":"/MyBlog/ai/DeepLearning/现代卷积神经网络/batch-norm.html#预测过程中的批量规范化","472":"/MyBlog/ai/DeepLearning/现代卷积神经网络/batch-norm.html#从零实现","473":"/MyBlog/ai/DeepLearning/现代卷积神经网络/batch-norm.html#使用批量规范化层的-lenet","474":"/MyBlog/ai/DeepLearning/现代卷积神经网络/batch-norm.html#简明实现","475":"/MyBlog/ai/DeepLearning/现代卷积神经网络/batch-norm.html#争议","476":"/MyBlog/ai/DeepLearning/现代卷积神经网络/batch-norm.html#小结","477":"/MyBlog/ai/DeepLearning/现代卷积神经网络/batch-norm.html#练习","478":"/MyBlog/ai/DeepLearning/现代卷积神经网络/densenet.html#稠密连接网络-densenet","479":"/MyBlog/ai/DeepLearning/现代卷积神经网络/densenet.html#从resnet到densenet","480":"/MyBlog/ai/DeepLearning/现代卷积神经网络/densenet.html#稠密块体","481":"/MyBlog/ai/DeepLearning/现代卷积神经网络/densenet.html#过渡层","482":"/MyBlog/ai/DeepLearning/现代卷积神经网络/densenet.html#densenet模型","483":"/MyBlog/ai/DeepLearning/现代卷积神经网络/densenet.html#训练模型","484":"/MyBlog/ai/DeepLearning/现代卷积神经网络/densenet.html#小结","485":"/MyBlog/ai/DeepLearning/现代卷积神经网络/densenet.html#练习","486":"/MyBlog/ai/DeepLearning/现代卷积神经网络/googlenet.html#含并行连结的网络-googlenet","487":"/MyBlog/ai/DeepLearning/现代卷积神经网络/googlenet.html#inception块","488":"/MyBlog/ai/DeepLearning/现代卷积神经网络/googlenet.html#googlenet模型","489":"/MyBlog/ai/DeepLearning/现代卷积神经网络/googlenet.html#训练模型","490":"/MyBlog/ai/DeepLearning/现代卷积神经网络/googlenet.html#小结","491":"/MyBlog/ai/DeepLearning/现代卷积神经网络/googlenet.html#练习","492":"/MyBlog/ai/DeepLearning/现代卷积神经网络/#现代卷积神经网络","493":"/MyBlog/ai/DeepLearning/现代卷积神经网络/nin.html#网络中的网络-nin","494":"/MyBlog/ai/DeepLearning/现代卷积神经网络/nin.html#nin块","495":"/MyBlog/ai/DeepLearning/现代卷积神经网络/nin.html#nin模型","496":"/MyBlog/ai/DeepLearning/现代卷积神经网络/nin.html#训练模型","497":"/MyBlog/ai/DeepLearning/现代卷积神经网络/nin.html#小结","498":"/MyBlog/ai/DeepLearning/现代卷积神经网络/nin.html#练习","499":"/MyBlog/ai/DeepLearning/现代卷积神经网络/resnet.html#残差网络-resnet","500":"/MyBlog/ai/DeepLearning/现代卷积神经网络/resnet.html#函数类","501":"/MyBlog/ai/DeepLearning/现代卷积神经网络/resnet.html#残差块","502":"/MyBlog/ai/DeepLearning/现代卷积神经网络/resnet.html#resnet模型","503":"/MyBlog/ai/DeepLearning/现代卷积神经网络/resnet.html#训练模型","504":"/MyBlog/ai/DeepLearning/现代卷积神经网络/resnet.html#小结","505":"/MyBlog/ai/DeepLearning/现代卷积神经网络/resnet.html#练习","506":"/MyBlog/ai/DeepLearning/现代卷积神经网络/vgg.html#使用块的网络-vgg","507":"/MyBlog/ai/DeepLearning/现代卷积神经网络/vgg.html#vgg块","508":"/MyBlog/ai/DeepLearning/现代卷积神经网络/vgg.html#vgg网络","509":"/MyBlog/ai/DeepLearning/现代卷积神经网络/vgg.html#训练模型","510":"/MyBlog/ai/DeepLearning/现代卷积神经网络/vgg.html#小结","511":"/MyBlog/ai/DeepLearning/现代卷积神经网络/vgg.html#练习","512":"/MyBlog/ai/DeepLearning/现代循环神经网络/beam-search.html#束搜索","513":"/MyBlog/ai/DeepLearning/现代循环神经网络/beam-search.html#贪心搜索","514":"/MyBlog/ai/DeepLearning/现代循环神经网络/beam-search.html#穷举搜索","515":"/MyBlog/ai/DeepLearning/现代循环神经网络/beam-search.html#束搜索-1","516":"/MyBlog/ai/DeepLearning/现代循环神经网络/beam-search.html#小结","517":"/MyBlog/ai/DeepLearning/现代循环神经网络/beam-search.html#练习","518":"/MyBlog/ai/DeepLearning/现代循环神经网络/bi-rnn.html#双向循环神经网络","519":"/MyBlog/ai/DeepLearning/现代循环神经网络/bi-rnn.html#隐马尔可夫模型中的动态规划","520":"/MyBlog/ai/DeepLearning/现代循环神经网络/bi-rnn.html#双向模型","521":"/MyBlog/ai/DeepLearning/现代循环神经网络/bi-rnn.html#定义","522":"/MyBlog/ai/DeepLearning/现代循环神经网络/bi-rnn.html#模型的计算代价及其应用","523":"/MyBlog/ai/DeepLearning/现代循环神经网络/bi-rnn.html#双向循环神经网络的错误应用","524":"/MyBlog/ai/DeepLearning/现代循环神经网络/bi-rnn.html#小结","525":"/MyBlog/ai/DeepLearning/现代循环神经网络/bi-rnn.html#练习","526":"/MyBlog/ai/DeepLearning/现代循环神经网络/deep-rnn.html#深度循环神经网络","527":"/MyBlog/ai/DeepLearning/现代循环神经网络/deep-rnn.html#函数依赖关系","528":"/MyBlog/ai/DeepLearning/现代循环神经网络/deep-rnn.html#简洁实现","529":"/MyBlog/ai/DeepLearning/现代循环神经网络/deep-rnn.html#训练-与预测","530":"/MyBlog/ai/DeepLearning/现代循环神经网络/deep-rnn.html#小结","531":"/MyBlog/ai/DeepLearning/现代循环神经网络/deep-rnn.html#练习","532":"/MyBlog/ai/DeepLearning/现代循环神经网络/encoder-decoder.html#编码器-解码器架构","533":"/MyBlog/ai/DeepLearning/现代循环神经网络/encoder-decoder.html#编码器","534":"/MyBlog/ai/DeepLearning/现代循环神经网络/encoder-decoder.html#解码器","535":"/MyBlog/ai/DeepLearning/现代循环神经网络/encoder-decoder.html#合并编码器和解码器","536":"/MyBlog/ai/DeepLearning/现代循环神经网络/encoder-decoder.html#小结","537":"/MyBlog/ai/DeepLearning/现代循环神经网络/encoder-decoder.html#练习","538":"/MyBlog/ai/DeepLearning/现代循环神经网络/gru.html#门控循环单元-gru","539":"/MyBlog/ai/DeepLearning/现代循环神经网络/gru.html#门控隐状态","540":"/MyBlog/ai/DeepLearning/现代循环神经网络/gru.html#重置门和更新门","541":"/MyBlog/ai/DeepLearning/现代循环神经网络/gru.html#候选隐状态","542":"/MyBlog/ai/DeepLearning/现代循环神经网络/gru.html#隐状态","543":"/MyBlog/ai/DeepLearning/现代循环神经网络/gru.html#从零开始实现","544":"/MyBlog/ai/DeepLearning/现代循环神经网络/gru.html#初始化模型参数","545":"/MyBlog/ai/DeepLearning/现代循环神经网络/gru.html#定义模型","546":"/MyBlog/ai/DeepLearning/现代循环神经网络/gru.html#训练-与预测","547":"/MyBlog/ai/DeepLearning/现代循环神经网络/gru.html#简洁实现","548":"/MyBlog/ai/DeepLearning/现代循环神经网络/gru.html#小结","549":"/MyBlog/ai/DeepLearning/现代循环神经网络/gru.html#练习","550":"/MyBlog/ai/DeepLearning/现代循环神经网络/#现代循环神经网络","551":"/MyBlog/ai/DeepLearning/现代循环神经网络/lstm.html#长短期记忆网络-lstm","552":"/MyBlog/ai/DeepLearning/现代循环神经网络/lstm.html#门控记忆元","553":"/MyBlog/ai/DeepLearning/现代循环神经网络/lstm.html#输入门、忘记门和输出门","554":"/MyBlog/ai/DeepLearning/现代循环神经网络/lstm.html#候选记忆元","555":"/MyBlog/ai/DeepLearning/现代循环神经网络/lstm.html#记忆元","556":"/MyBlog/ai/DeepLearning/现代循环神经网络/lstm.html#隐状态","557":"/MyBlog/ai/DeepLearning/现代循环神经网络/lstm.html#从零开始实现","558":"/MyBlog/ai/DeepLearning/现代循环神经网络/lstm.html#初始化模型参数","559":"/MyBlog/ai/DeepLearning/现代循环神经网络/lstm.html#定义模型","560":"/MyBlog/ai/DeepLearning/现代循环神经网络/lstm.html#训练-和预测","561":"/MyBlog/ai/DeepLearning/现代循环神经网络/lstm.html#简洁实现","562":"/MyBlog/ai/DeepLearning/现代循环神经网络/lstm.html#小结","563":"/MyBlog/ai/DeepLearning/现代循环神经网络/lstm.html#练习","564":"/MyBlog/ai/DeepLearning/现代循环神经网络/machine-translation-and-dataset.html#机器翻译与数据集","565":"/MyBlog/ai/DeepLearning/现代循环神经网络/machine-translation-and-dataset.html#下载和预处理数据集","566":"/MyBlog/ai/DeepLearning/现代循环神经网络/machine-translation-and-dataset.html#词元化","567":"/MyBlog/ai/DeepLearning/现代循环神经网络/machine-translation-and-dataset.html#词表","568":"/MyBlog/ai/DeepLearning/现代循环神经网络/machine-translation-and-dataset.html#加载数据集","569":"/MyBlog/ai/DeepLearning/现代循环神经网络/machine-translation-and-dataset.html#训练模型","570":"/MyBlog/ai/DeepLearning/现代循环神经网络/machine-translation-and-dataset.html#小结","571":"/MyBlog/ai/DeepLearning/现代循环神经网络/machine-translation-and-dataset.html#练习","572":"/MyBlog/ai/DeepLearning/现代循环神经网络/seq2seq.html#序列到序列学习-seq2seq","573":"/MyBlog/ai/DeepLearning/现代循环神经网络/seq2seq.html#编码器","574":"/MyBlog/ai/DeepLearning/现代循环神经网络/seq2seq.html#解码器","575":"/MyBlog/ai/DeepLearning/现代循环神经网络/seq2seq.html#损失函数","576":"/MyBlog/ai/DeepLearning/现代循环神经网络/seq2seq.html#训练","577":"/MyBlog/ai/DeepLearning/现代循环神经网络/seq2seq.html#预测","578":"/MyBlog/ai/DeepLearning/现代循环神经网络/seq2seq.html#预测序列的评估","579":"/MyBlog/ai/DeepLearning/现代循环神经网络/seq2seq.html#小结","580":"/MyBlog/ai/DeepLearning/现代循环神经网络/seq2seq.html#练习","581":"/MyBlog/ai/DeepLearning/线性神经网络/image-classification-dataset.html#图像分类数据集","582":"/MyBlog/ai/DeepLearning/线性神经网络/image-classification-dataset.html#读取数据集","583":"/MyBlog/ai/DeepLearning/线性神经网络/image-classification-dataset.html#读取小批量","584":"/MyBlog/ai/DeepLearning/线性神经网络/image-classification-dataset.html#整合所有组件","585":"/MyBlog/ai/DeepLearning/线性神经网络/image-classification-dataset.html#小结","586":"/MyBlog/ai/DeepLearning/线性神经网络/image-classification-dataset.html#练习","587":"/MyBlog/ai/DeepLearning/线性神经网络/#线性神经网络","588":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-concise.html#线性回归的简洁实现","589":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-concise.html#生成数据集","590":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-concise.html#读取数据集","591":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-concise.html#定义模型","592":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-concise.html#初始化模型参数","593":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-concise.html#定义损失函数","594":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-concise.html#定义优化算法","595":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-concise.html#训练","596":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-concise.html#小结","597":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-concise.html#练习","598":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-scratch.html#线性回归的从零开始实现","599":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-scratch.html#生成数据集","600":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-scratch.html#读取数据集","601":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-scratch.html#初始化模型参数","602":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-scratch.html#定义模型","603":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-scratch.html#定义损失函数","604":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-scratch.html#定义优化算法","605":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-scratch.html#训练","606":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-scratch.html#小结","607":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression-scratch.html#练习","608":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression.html#线性回归","609":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression.html#线性回归的基本元素","610":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression.html#线性模型","611":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression.html#损失函数","612":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression.html#解析解","613":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression.html#随机梯度下降","614":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression.html#用模型进行预测","615":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression.html#矢量化加速","616":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression.html#正态分布与平方损失","617":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression.html#从线性回归到深度网络","618":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression.html#神经网络图","619":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression.html#生物学","620":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression.html#小结","621":"/MyBlog/ai/DeepLearning/线性神经网络/linear-regression.html#练习","622":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression-concise.html#softmax回归的简洁实现","623":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression-concise.html#初始化模型参数","624":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression-concise.html#重新审视softmax的实现","625":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression-concise.html#优化算法","626":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression-concise.html#训练","627":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression-concise.html#小结","628":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression-concise.html#练习","629":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression-scratch.html#softmax回归的从零开始实现","630":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression-scratch.html#初始化模型参数","631":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression-scratch.html#定义softmax操作","632":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression-scratch.html#定义模型","633":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression-scratch.html#定义损失函数","634":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression-scratch.html#分类精度","635":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression-scratch.html#训练","636":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression-scratch.html#预测","637":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression-scratch.html#小结","638":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression-scratch.html#练习","639":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression.html#softmax回归","640":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression.html#分类问题","641":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression.html#网络架构","642":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression.html#全连接层的参数开销","643":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression.html#softmax运算","644":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression.html#小批量样本的矢量化","645":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression.html#损失函数","646":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression.html#对数似然","647":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression.html#softmax及其导数","648":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression.html#交叉熵损失","649":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression.html#信息论基础","650":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression.html#熵","651":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression.html#信息量","652":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression.html#重新审视交叉熵","653":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression.html#模型预测和评估","654":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression.html#小结","655":"/MyBlog/ai/DeepLearning/线性神经网络/softmax-regression.html#练习","656":"/MyBlog/ai/DeepLearning/自然语言处理：应用/finetuning-bert.html#针对序列级和词元级应用微调bert","657":"/MyBlog/ai/DeepLearning/自然语言处理：应用/finetuning-bert.html#单文本分类","658":"/MyBlog/ai/DeepLearning/自然语言处理：应用/finetuning-bert.html#文本对分类或回归","659":"/MyBlog/ai/DeepLearning/自然语言处理：应用/finetuning-bert.html#文本标注","660":"/MyBlog/ai/DeepLearning/自然语言处理：应用/finetuning-bert.html#问答","661":"/MyBlog/ai/DeepLearning/自然语言处理：应用/finetuning-bert.html#小结","662":"/MyBlog/ai/DeepLearning/自然语言处理：应用/finetuning-bert.html#练习","663":"/MyBlog/ai/DeepLearning/自然语言处理：应用/#自然语言处理-应用","664":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-and-dataset.html#自然语言推断与数据集","665":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-and-dataset.html#自然语言推断","666":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-and-dataset.html#斯坦福自然语言推断-snli-数据集","667":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-and-dataset.html#读取数据集","668":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-and-dataset.html#定义用于加载数据集的类","669":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-and-dataset.html#整合代码","670":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-and-dataset.html#小结","671":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-and-dataset.html#练习","672":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-attention.html#自然语言推断-使用注意力","673":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-attention.html#模型","674":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-attention.html#注意-attending","675":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-attention.html#比较","676":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-attention.html#聚合","677":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-attention.html#整合代码","678":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-attention.html#训练和评估模型","679":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-attention.html#读取数据集","680":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-attention.html#创建模型","681":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-attention.html#训练和评估模型-1","682":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-attention.html#使用模型","683":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-attention.html#小结","684":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-attention.html#练习","685":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-bert.html#自然语言推断-微调bert","686":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-bert.html#加载预训练的bert","687":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-bert.html#微调bert的数据集","688":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-bert.html#微调bert","689":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-bert.html#小结","690":"/MyBlog/ai/DeepLearning/自然语言处理：应用/natural-language-inference-bert.html#练习","691":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-and-dataset.html#情感分析及数据集","692":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-and-dataset.html#读取数据集","693":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-and-dataset.html#预处理数据集","694":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-and-dataset.html#创建数据迭代器","695":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-and-dataset.html#整合代码","696":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-and-dataset.html#小结","697":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-and-dataset.html#练习","698":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-cnn.html#情感分析-使用卷积神经网络","699":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-cnn.html#一维卷积","700":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-cnn.html#最大时间汇聚层","701":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-cnn.html#textcnn模型","702":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-cnn.html#定义模型","703":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-cnn.html#加载预训练词向量","704":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-cnn.html#训练和评估模型","705":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-cnn.html#小结","706":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-cnn.html#练习","707":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/approx-training.html#近似训练","708":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/approx-training.html#负采样","709":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/approx-training.html#层序softmax","710":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/approx-training.html#小结","711":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/approx-training.html#练习","712":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-rnn.html#情感分析-使用循环神经网络","713":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-rnn.html#使用循环神经网络表示单个文本","714":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-rnn.html#加载预训练的词向量","715":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-rnn.html#训练和评估模型","716":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-rnn.html#小结","717":"/MyBlog/ai/DeepLearning/自然语言处理：应用/sentiment-analysis-rnn.html#练习","718":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert-dataset.html#用于预训练bert的数据集","719":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert-dataset.html#为预训练任务定义辅助函数","720":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert-dataset.html#生成下一句预测任务的数据","721":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert-dataset.html#生成遮蔽语言模型任务的数据","722":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert-dataset.html#将文本转换为预训练数据集","723":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert-dataset.html#小结","724":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert-dataset.html#练习","725":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert-pretraining.html#预训练bert","726":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert-pretraining.html#预训练bert-1","727":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert-pretraining.html#用bert表示文本","728":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert-pretraining.html#小结","729":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert-pretraining.html#练习","730":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert.html#来自transformers的双向编码器表示-bert","731":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert.html#从上下文无关到上下文敏感","732":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert.html#从特定于任务到不可知任务","733":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert.html#bert-把两个最好的结合起来","734":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert.html#输入表示","735":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert.html#预训练任务","736":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert.html#掩蔽语言模型-masked-language-modeling","737":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert.html#下一句预测-next-sentence-prediction","738":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert.html#整合代码","739":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert.html#小结","740":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/bert.html#练习","741":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/glove.html#全局向量的词嵌入-glove","742":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/glove.html#带全局语料统计的跳元模型","743":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/glove.html#glove模型","744":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/glove.html#从条件概率比值理解glove模型","745":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/glove.html#小结","746":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/glove.html#练习","747":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/similarity-analogy.html#词的相似性和类比任务","748":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/similarity-analogy.html#加载预训练词向量","749":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/similarity-analogy.html#应用预训练词向量","750":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/similarity-analogy.html#词相似度","751":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/similarity-analogy.html#词类比","752":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/similarity-analogy.html#小结","753":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/similarity-analogy.html#练习","754":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/#自然语言处理-预训练","755":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/subword-embedding.html#子词嵌入","756":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/subword-embedding.html#fasttext模型","757":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/subword-embedding.html#字节对编码-byte-pair-encoding","758":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/subword-embedding.html#小结","759":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/subword-embedding.html#练习","760":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec-pretraining.html#预训练word2vec","761":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec-pretraining.html#跳元模型","762":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec-pretraining.html#嵌入层","763":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec-pretraining.html#定义前向传播","764":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec-pretraining.html#训练","765":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec-pretraining.html#二元交叉熵损失","766":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec-pretraining.html#初始化模型参数","767":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec-pretraining.html#定义训练阶段代码","768":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec-pretraining.html#应用词嵌入","769":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec-pretraining.html#小结","770":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec-pretraining.html#练习","771":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word-embedding-dataset.html#用于预训练词嵌入的数据集","772":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word-embedding-dataset.html#读取数据集","773":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word-embedding-dataset.html#下采样","774":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word-embedding-dataset.html#中心词和上下文词的提取","775":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word-embedding-dataset.html#负采样","776":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word-embedding-dataset.html#小批量加载训练实例","777":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word-embedding-dataset.html#整合代码","778":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word-embedding-dataset.html#小结","779":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word-embedding-dataset.html#练习","780":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec.html#词嵌入-word2vec","781":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec.html#为何独热向量是一个糟糕的选择","782":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec.html#自监督的word2vec","783":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec.html#跳元模型-skip-gram","784":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec.html#训练","785":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec.html#连续词袋-cbow-模型","786":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec.html#训练-1","787":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec.html#小结","788":"/MyBlog/ai/DeepLearning/自然语言处理：预训练/word2vec.html#练习","789":"/MyBlog/ai/DeepLearning/计算性能/async-computation.html#异步计算","790":"/MyBlog/ai/DeepLearning/计算性能/async-computation.html#通过后端异步处理","791":"/MyBlog/ai/DeepLearning/计算性能/async-computation.html#障碍器与阻塞器","792":"/MyBlog/ai/DeepLearning/计算性能/async-computation.html#改进计算","793":"/MyBlog/ai/DeepLearning/计算性能/async-computation.html#小结","794":"/MyBlog/ai/DeepLearning/计算性能/async-computation.html#练习","795":"/MyBlog/ai/DeepLearning/计算性能/auto-parallelism.html#自动并行","796":"/MyBlog/ai/DeepLearning/计算性能/auto-parallelism.html#基于gpu的并行计算","797":"/MyBlog/ai/DeepLearning/计算性能/auto-parallelism.html#并行计算与通信","798":"/MyBlog/ai/DeepLearning/计算性能/auto-parallelism.html#小结","799":"/MyBlog/ai/DeepLearning/计算性能/auto-parallelism.html#练习","800":"/MyBlog/ai/DeepLearning/计算性能/hardware.html#硬件","801":"/MyBlog/ai/DeepLearning/计算性能/hardware.html#计算机","802":"/MyBlog/ai/DeepLearning/计算性能/hardware.html#内存","803":"/MyBlog/ai/DeepLearning/计算性能/hardware.html#存储器","804":"/MyBlog/ai/DeepLearning/计算性能/hardware.html#硬盘驱动器","805":"/MyBlog/ai/DeepLearning/计算性能/hardware.html#固态驱动器","806":"/MyBlog/ai/DeepLearning/计算性能/hardware.html#云存储","807":"/MyBlog/ai/DeepLearning/计算性能/hardware.html#cpu","808":"/MyBlog/ai/DeepLearning/计算性能/hardware.html#微体系结构","809":"/MyBlog/ai/DeepLearning/计算性能/hardware.html#矢量化","810":"/MyBlog/ai/DeepLearning/计算性能/hardware.html#缓存","811":"/MyBlog/ai/DeepLearning/计算性能/hardware.html#gpu和其他加速卡","812":"/MyBlog/ai/DeepLearning/计算性能/hardware.html#网络和总线","813":"/MyBlog/ai/DeepLearning/计算性能/hardware.html#更多延迟","814":"/MyBlog/ai/DeepLearning/计算性能/hardware.html#小结","815":"/MyBlog/ai/DeepLearning/计算性能/hardware.html#练习","816":"/MyBlog/ai/DeepLearning/计算性能/hybridize.html#编译器和解释器","817":"/MyBlog/ai/DeepLearning/计算性能/hybridize.html#符号式编程","818":"/MyBlog/ai/DeepLearning/计算性能/hybridize.html#混合式编程","819":"/MyBlog/ai/DeepLearning/计算性能/hybridize.html#sequential的混合式编程","820":"/MyBlog/ai/DeepLearning/计算性能/hybridize.html#通过混合式编程加速","821":"/MyBlog/ai/DeepLearning/计算性能/hybridize.html#序列化","822":"/MyBlog/ai/DeepLearning/计算性能/hybridize.html#小结","823":"/MyBlog/ai/DeepLearning/计算性能/hybridize.html#练习","824":"/MyBlog/ai/DeepLearning/计算性能/#计算性能","825":"/MyBlog/ai/DeepLearning/计算性能/multiple-gpus-concise.html#多gpu的简洁实现","826":"/MyBlog/ai/DeepLearning/计算性能/multiple-gpus-concise.html#简单网络","827":"/MyBlog/ai/DeepLearning/计算性能/multiple-gpus-concise.html#网络初始化","828":"/MyBlog/ai/DeepLearning/计算性能/multiple-gpus-concise.html#训练","829":"/MyBlog/ai/DeepLearning/计算性能/multiple-gpus-concise.html#小结","830":"/MyBlog/ai/DeepLearning/计算性能/multiple-gpus-concise.html#练习","831":"/MyBlog/ai/DeepLearning/计算性能/multiple-gpus.html#多gpu训练","832":"/MyBlog/ai/DeepLearning/计算性能/multiple-gpus.html#问题拆分","833":"/MyBlog/ai/DeepLearning/计算性能/multiple-gpus.html#数据并行性","834":"/MyBlog/ai/DeepLearning/计算性能/multiple-gpus.html#简单网络","835":"/MyBlog/ai/DeepLearning/计算性能/multiple-gpus.html#数据同步","836":"/MyBlog/ai/DeepLearning/计算性能/multiple-gpus.html#数据分发","837":"/MyBlog/ai/DeepLearning/计算性能/multiple-gpus.html#训练","838":"/MyBlog/ai/DeepLearning/计算性能/multiple-gpus.html#小结","839":"/MyBlog/ai/DeepLearning/计算性能/multiple-gpus.html#练习","840":"/MyBlog/ai/DeepLearning/计算性能/parameterserver.html#参数服务器","841":"/MyBlog/ai/DeepLearning/计算性能/parameterserver.html#数据并行训练","842":"/MyBlog/ai/DeepLearning/计算性能/parameterserver.html#环同步-ring-synchronization","843":"/MyBlog/ai/DeepLearning/计算性能/parameterserver.html#多机训练","844":"/MyBlog/ai/DeepLearning/计算性能/parameterserver.html#键值存储","845":"/MyBlog/ai/DeepLearning/计算性能/parameterserver.html#小结","846":"/MyBlog/ai/DeepLearning/计算性能/parameterserver.html#练习","847":"/MyBlog/ai/DeepLearning/计算机视觉/anchor.html#锚框","848":"/MyBlog/ai/DeepLearning/计算机视觉/anchor.html#生成多个锚框","849":"/MyBlog/ai/DeepLearning/计算机视觉/anchor.html#交并比-iou","850":"/MyBlog/ai/DeepLearning/计算机视觉/anchor.html#在训练数据中标注锚框","851":"/MyBlog/ai/DeepLearning/计算机视觉/anchor.html#将真实边界框分配给锚框","852":"/MyBlog/ai/DeepLearning/计算机视觉/anchor.html#标记类别和偏移量","853":"/MyBlog/ai/DeepLearning/计算机视觉/anchor.html#一个例子","854":"/MyBlog/ai/DeepLearning/计算机视觉/anchor.html#使用非极大值抑制预测边界框","855":"/MyBlog/ai/DeepLearning/计算机视觉/anchor.html#小结","856":"/MyBlog/ai/DeepLearning/计算机视觉/anchor.html#练习","857":"/MyBlog/ai/DeepLearning/计算机视觉/bounding-box.html#目标检测和边界框","858":"/MyBlog/ai/DeepLearning/计算机视觉/bounding-box.html#边界框","859":"/MyBlog/ai/DeepLearning/计算机视觉/bounding-box.html#小结","860":"/MyBlog/ai/DeepLearning/计算机视觉/bounding-box.html#练习","861":"/MyBlog/ai/DeepLearning/计算机视觉/fcn.html#全卷积网络","862":"/MyBlog/ai/DeepLearning/计算机视觉/fcn.html#构造模型","863":"/MyBlog/ai/DeepLearning/计算机视觉/fcn.html#初始化转置卷积层","864":"/MyBlog/ai/DeepLearning/计算机视觉/fcn.html#读取数据集","865":"/MyBlog/ai/DeepLearning/计算机视觉/fcn.html#训练","866":"/MyBlog/ai/DeepLearning/计算机视觉/fcn.html#预测","867":"/MyBlog/ai/DeepLearning/计算机视觉/fcn.html#小结","868":"/MyBlog/ai/DeepLearning/计算机视觉/fcn.html#练习","869":"/MyBlog/ai/DeepLearning/计算机视觉/fine-tuning.html#微调","870":"/MyBlog/ai/DeepLearning/计算机视觉/fine-tuning.html#步骤","871":"/MyBlog/ai/DeepLearning/计算机视觉/fine-tuning.html#热狗识别","872":"/MyBlog/ai/DeepLearning/计算机视觉/fine-tuning.html#获取数据集","873":"/MyBlog/ai/DeepLearning/计算机视觉/fine-tuning.html#定义和初始化模型","874":"/MyBlog/ai/DeepLearning/计算机视觉/fine-tuning.html#微调模型","875":"/MyBlog/ai/DeepLearning/计算机视觉/fine-tuning.html#小结","876":"/MyBlog/ai/DeepLearning/计算机视觉/fine-tuning.html#练习","877":"/MyBlog/ai/DeepLearning/计算机视觉/image-augmentation.html#图像增广","878":"/MyBlog/ai/DeepLearning/计算机视觉/image-augmentation.html#常用的图像增广方法","879":"/MyBlog/ai/DeepLearning/计算机视觉/image-augmentation.html#翻转和裁剪","880":"/MyBlog/ai/DeepLearning/计算机视觉/image-augmentation.html#改变颜色","881":"/MyBlog/ai/DeepLearning/计算机视觉/image-augmentation.html#结合多种图像增广方法","882":"/MyBlog/ai/DeepLearning/计算机视觉/image-augmentation.html#使用图像增广进行训练","883":"/MyBlog/ai/DeepLearning/计算机视觉/image-augmentation.html#多gpu训练","884":"/MyBlog/ai/DeepLearning/计算机视觉/image-augmentation.html#小结","885":"/MyBlog/ai/DeepLearning/计算机视觉/image-augmentation.html#练习","886":"/MyBlog/ai/DeepLearning/计算机视觉/#计算机视觉","887":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-cifar10.html#实战-kaggle-比赛-图像分类-cifar-10","888":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-cifar10.html#获取并组织数据集","889":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-cifar10.html#下载数据集","890":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-cifar10.html#整理数据集","891":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-cifar10.html#图像增广","892":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-cifar10.html#读取数据集","893":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-cifar10.html#定义-模型","894":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-cifar10.html#定义-训练函数","895":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-cifar10.html#训练和验证模型","896":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-cifar10.html#在-kaggle-上-对测试集进行分类并提交结果","897":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-cifar10.html#小结","898":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-cifar10.html#练习","899":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-dog.html#实战kaggle比赛-狗的品种识别-imagenet-dogs","900":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-dog.html#获取和整理数据集","901":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-dog.html#下载数据集","902":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-dog.html#整理数据集","903":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-dog.html#图像增广","904":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-dog.html#读取数据集","905":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-dog.html#微调预训练模型","906":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-dog.html#定义-训练函数","907":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-dog.html#训练和验证模型","908":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-dog.html#对测试集分类-并在kaggle提交结果","909":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-dog.html#小结","910":"/MyBlog/ai/DeepLearning/计算机视觉/kaggle-dog.html#练习","911":"/MyBlog/ai/DeepLearning/计算机视觉/multiscale-object-detection.html#多尺度目标检测","912":"/MyBlog/ai/DeepLearning/计算机视觉/multiscale-object-detection.html#多尺度锚框","913":"/MyBlog/ai/DeepLearning/计算机视觉/multiscale-object-detection.html#多尺度检测","914":"/MyBlog/ai/DeepLearning/计算机视觉/multiscale-object-detection.html#小结","915":"/MyBlog/ai/DeepLearning/计算机视觉/multiscale-object-detection.html#练习","916":"/MyBlog/ai/DeepLearning/计算机视觉/neural-style.html#风格迁移","917":"/MyBlog/ai/DeepLearning/计算机视觉/neural-style.html#方法","918":"/MyBlog/ai/DeepLearning/计算机视觉/neural-style.html#阅读内容和风格图像","919":"/MyBlog/ai/DeepLearning/计算机视觉/neural-style.html#预处理和后处理","920":"/MyBlog/ai/DeepLearning/计算机视觉/neural-style.html#抽取图像特征","921":"/MyBlog/ai/DeepLearning/计算机视觉/neural-style.html#定义损失函数","922":"/MyBlog/ai/DeepLearning/计算机视觉/neural-style.html#内容损失","923":"/MyBlog/ai/DeepLearning/计算机视觉/neural-style.html#风格损失","924":"/MyBlog/ai/DeepLearning/计算机视觉/neural-style.html#全变分损失","925":"/MyBlog/ai/DeepLearning/计算机视觉/neural-style.html#损失函数","926":"/MyBlog/ai/DeepLearning/计算机视觉/neural-style.html#初始化合成图像","927":"/MyBlog/ai/DeepLearning/计算机视觉/neural-style.html#训练模型","928":"/MyBlog/ai/DeepLearning/计算机视觉/neural-style.html#小结","929":"/MyBlog/ai/DeepLearning/计算机视觉/neural-style.html#练习","930":"/MyBlog/ai/DeepLearning/计算机视觉/object-detection-dataset.html#目标检测数据集","931":"/MyBlog/ai/DeepLearning/计算机视觉/object-detection-dataset.html#下载数据集","932":"/MyBlog/ai/DeepLearning/计算机视觉/object-detection-dataset.html#读取数据集","933":"/MyBlog/ai/DeepLearning/计算机视觉/object-detection-dataset.html#演示","934":"/MyBlog/ai/DeepLearning/计算机视觉/object-detection-dataset.html#小结","935":"/MyBlog/ai/DeepLearning/计算机视觉/object-detection-dataset.html#练习","936":"/MyBlog/ai/DeepLearning/计算机视觉/rcnn.html#区域卷积神经网络-r-cnn-系列","937":"/MyBlog/ai/DeepLearning/计算机视觉/rcnn.html#r-cnn","938":"/MyBlog/ai/DeepLearning/计算机视觉/rcnn.html#fast-r-cnn","939":"/MyBlog/ai/DeepLearning/计算机视觉/rcnn.html#faster-r-cnn","940":"/MyBlog/ai/DeepLearning/计算机视觉/rcnn.html#mask-r-cnn","941":"/MyBlog/ai/DeepLearning/计算机视觉/rcnn.html#小结","942":"/MyBlog/ai/DeepLearning/计算机视觉/rcnn.html#练习","943":"/MyBlog/ai/DeepLearning/计算机视觉/semantic-segmentation-and-dataset.html#语义分割和数据集","944":"/MyBlog/ai/DeepLearning/计算机视觉/semantic-segmentation-and-dataset.html#图像分割和实例分割","945":"/MyBlog/ai/DeepLearning/计算机视觉/semantic-segmentation-and-dataset.html#pascal-voc2012-语义分割数据集","946":"/MyBlog/ai/DeepLearning/计算机视觉/semantic-segmentation-and-dataset.html#预处理数据","947":"/MyBlog/ai/DeepLearning/计算机视觉/semantic-segmentation-and-dataset.html#自定义语义分割数据集类","948":"/MyBlog/ai/DeepLearning/计算机视觉/semantic-segmentation-and-dataset.html#读取数据集","949":"/MyBlog/ai/DeepLearning/计算机视觉/semantic-segmentation-and-dataset.html#整合所有组件","950":"/MyBlog/ai/DeepLearning/计算机视觉/semantic-segmentation-and-dataset.html#小结","951":"/MyBlog/ai/DeepLearning/计算机视觉/semantic-segmentation-and-dataset.html#练习","952":"/MyBlog/ai/DeepLearning/计算机视觉/ssd.html#单发多框检测-ssd","953":"/MyBlog/ai/DeepLearning/计算机视觉/ssd.html#模型","954":"/MyBlog/ai/DeepLearning/计算机视觉/ssd.html#类别预测层","955":"/MyBlog/ai/DeepLearning/计算机视觉/ssd.html#边界框预测层","956":"/MyBlog/ai/DeepLearning/计算机视觉/ssd.html#连结多尺度的预测","957":"/MyBlog/ai/DeepLearning/计算机视觉/ssd.html#高和宽减半块","958":"/MyBlog/ai/DeepLearning/计算机视觉/ssd.html#基本网络块","959":"/MyBlog/ai/DeepLearning/计算机视觉/ssd.html#完整的模型","960":"/MyBlog/ai/DeepLearning/计算机视觉/ssd.html#训练模型","961":"/MyBlog/ai/DeepLearning/计算机视觉/ssd.html#读取数据集和初始化","962":"/MyBlog/ai/DeepLearning/计算机视觉/ssd.html#定义损失函数和评价函数","963":"/MyBlog/ai/DeepLearning/计算机视觉/ssd.html#训练模型-1","964":"/MyBlog/ai/DeepLearning/计算机视觉/ssd.html#预测目标","965":"/MyBlog/ai/DeepLearning/计算机视觉/ssd.html#小结","966":"/MyBlog/ai/DeepLearning/计算机视觉/ssd.html#练习","967":"/MyBlog/ai/DeepLearning/计算机视觉/transposed-conv.html#转置卷积","968":"/MyBlog/ai/DeepLearning/计算机视觉/transposed-conv.html#基本操作","969":"/MyBlog/ai/DeepLearning/计算机视觉/transposed-conv.html#填充、步幅和多通道","970":"/MyBlog/ai/DeepLearning/计算机视觉/transposed-conv.html#与矩阵变换的联系","971":"/MyBlog/ai/DeepLearning/计算机视觉/transposed-conv.html#小结","972":"/MyBlog/ai/DeepLearning/计算机视觉/transposed-conv.html#练习","973":"/MyBlog/ai/DeepLearning/预备知识/autograd.html#自动微分","974":"/MyBlog/ai/DeepLearning/预备知识/autograd.html#一个简单的例子","975":"/MyBlog/ai/DeepLearning/预备知识/autograd.html#非标量变量的反向传播","976":"/MyBlog/ai/DeepLearning/预备知识/autograd.html#分离计算","977":"/MyBlog/ai/DeepLearning/预备知识/autograd.html#python控制流的梯度计算","978":"/MyBlog/ai/DeepLearning/预备知识/autograd.html#小结","979":"/MyBlog/ai/DeepLearning/预备知识/autograd.html#练习","980":"/MyBlog/ai/DeepLearning/预备知识/calculus.html#微积分","981":"/MyBlog/ai/DeepLearning/预备知识/calculus.html#导数和微分","982":"/MyBlog/ai/DeepLearning/预备知识/calculus.html#偏导数","983":"/MyBlog/ai/DeepLearning/预备知识/calculus.html#梯度","984":"/MyBlog/ai/DeepLearning/预备知识/calculus.html#链式法则","985":"/MyBlog/ai/DeepLearning/预备知识/calculus.html#小结","986":"/MyBlog/ai/DeepLearning/预备知识/calculus.html#练习","987":"/MyBlog/ai/DeepLearning/预备知识/#预备知识","988":"/MyBlog/ai/DeepLearning/预备知识/linear-algebra.html#线性代数","989":"/MyBlog/ai/DeepLearning/预备知识/linear-algebra.html#标量","990":"/MyBlog/ai/DeepLearning/预备知识/linear-algebra.html#向量","991":"/MyBlog/ai/DeepLearning/预备知识/linear-algebra.html#长度、维度和形状","992":"/MyBlog/ai/DeepLearning/预备知识/linear-algebra.html#矩阵","993":"/MyBlog/ai/DeepLearning/预备知识/linear-algebra.html#张量","994":"/MyBlog/ai/DeepLearning/预备知识/linear-algebra.html#张量算法的基本性质","995":"/MyBlog/ai/DeepLearning/预备知识/linear-algebra.html#降维","996":"/MyBlog/ai/DeepLearning/预备知识/linear-algebra.html#非降维求和","997":"/MyBlog/ai/DeepLearning/预备知识/linear-algebra.html#点积-dot-product","998":"/MyBlog/ai/DeepLearning/预备知识/linear-algebra.html#矩阵-向量积","999":"/MyBlog/ai/DeepLearning/预备知识/linear-algebra.html#矩阵-矩阵乘法","1000":"/MyBlog/ai/DeepLearning/预备知识/linear-algebra.html#范数","1001":"/MyBlog/ai/DeepLearning/预备知识/linear-algebra.html#范数和目标","1002":"/MyBlog/ai/DeepLearning/预备知识/linear-algebra.html#关于线性代数的更多信息","1003":"/MyBlog/ai/DeepLearning/预备知识/linear-algebra.html#小结","1004":"/MyBlog/ai/DeepLearning/预备知识/linear-algebra.html#练习","1005":"/MyBlog/ai/DeepLearning/预备知识/lookup-api.html#查阅文档","1006":"/MyBlog/ai/DeepLearning/预备知识/lookup-api.html#查找模块中的所有函数和类","1007":"/MyBlog/ai/DeepLearning/预备知识/lookup-api.html#查找特定函数和类的用法","1008":"/MyBlog/ai/DeepLearning/预备知识/lookup-api.html#小结","1009":"/MyBlog/ai/DeepLearning/预备知识/lookup-api.html#练习","1010":"/MyBlog/ai/DeepLearning/预备知识/pandas.html#数据预处理","1011":"/MyBlog/ai/DeepLearning/预备知识/pandas.html#读取数据集","1012":"/MyBlog/ai/DeepLearning/预备知识/pandas.html#处理缺失值","1013":"/MyBlog/ai/DeepLearning/预备知识/pandas.html#转换为张量格式","1014":"/MyBlog/ai/DeepLearning/预备知识/pandas.html#小结","1015":"/MyBlog/ai/DeepLearning/预备知识/pandas.html#练习","1016":"/MyBlog/ai/DeepLearning/预备知识/ndarray.html#数据操作","1017":"/MyBlog/ai/DeepLearning/预备知识/ndarray.html#入门","1018":"/MyBlog/ai/DeepLearning/预备知识/ndarray.html#运算符","1019":"/MyBlog/ai/DeepLearning/预备知识/ndarray.html#广播机制","1020":"/MyBlog/ai/DeepLearning/预备知识/ndarray.html#索引和切片","1021":"/MyBlog/ai/DeepLearning/预备知识/ndarray.html#节省内存","1022":"/MyBlog/ai/DeepLearning/预备知识/ndarray.html#转换为其他python对象","1023":"/MyBlog/ai/DeepLearning/预备知识/ndarray.html#小结","1024":"/MyBlog/ai/DeepLearning/预备知识/ndarray.html#练习","1025":"/MyBlog/ai/DeepLearning/预备知识/probability.html#概率","1026":"/MyBlog/ai/DeepLearning/预备知识/probability.html#基本概率论","1027":"/MyBlog/ai/DeepLearning/预备知识/probability.html#概率论公理","1028":"/MyBlog/ai/DeepLearning/预备知识/probability.html#随机变量","1029":"/MyBlog/ai/DeepLearning/预备知识/probability.html#处理多个随机变量","1030":"/MyBlog/ai/DeepLearning/预备知识/probability.html#联合概率","1031":"/MyBlog/ai/DeepLearning/预备知识/probability.html#条件概率","1032":"/MyBlog/ai/DeepLearning/预备知识/probability.html#贝叶斯定理","1033":"/MyBlog/ai/DeepLearning/预备知识/probability.html#边际化","1034":"/MyBlog/ai/DeepLearning/预备知识/probability.html#独立性","1035":"/MyBlog/ai/DeepLearning/预备知识/probability.html#应用","1036":"/MyBlog/ai/DeepLearning/预备知识/probability.html#期望和方差","1037":"/MyBlog/ai/DeepLearning/预备知识/probability.html#小结","1038":"/MyBlog/ai/DeepLearning/预备知识/probability.html#练习","1039":"/MyBlog/ai/LLM/Agent/3.MCP通信协议.html#mcp-model-context-protocol-通信协议与使用指南笔记","1040":"/MyBlog/ai/LLM/Agent/3.MCP通信协议.html#一、mcp-概述","1041":"/MyBlog/ai/LLM/Agent/3.MCP通信协议.html#为什么选择-mcp","1042":"/MyBlog/ai/LLM/Agent/3.MCP通信协议.html#通用架构","1043":"/MyBlog/ai/LLM/Agent/3.MCP通信协议.html#二、通信机制","1044":"/MyBlog/ai/LLM/Agent/3.MCP通信协议.html#消息格式","1045":"/MyBlog/ai/LLM/Agent/3.MCP通信协议.html#请求","1046":"/MyBlog/ai/LLM/Agent/3.MCP通信协议.html#响应","1047":"/MyBlog/ai/LLM/Agent/3.MCP通信协议.html#通知","1048":"/MyBlog/ai/LLM/Agent/3.MCP通信协议.html#三、官方-sdk-应用示例","1049":"/MyBlog/ai/LLM/Agent/#🤖-ai-agent-简介-从模型到智能体的跃迁","1050":"/MyBlog/ai/LLM/Agent/#🧠-什么是-ai-agent","1051":"/MyBlog/ai/LLM/Agent/#🚀-为什么-ai-agent-值得关注","1052":"/MyBlog/ai/LLM/Agent/#🛠️-ai-agent-的核心能力模块","1053":"/MyBlog/ai/LLM/Agent/#🧪-常见-agent-应用场景","1054":"/MyBlog/ai/LLM/Agent/#💡-我的探索方向","1055":"/MyBlog/ai/LLM/Agent/#📚-推荐阅读与工具资源","1056":"/MyBlog/ai/LLM/Agent/#✍️-博主的话","1057":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#第1周","1058":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#_1-1-欢迎","1059":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#_1-2-机器学习是什么","1060":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#_1-3-监督学习","1061":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#_1-4-无监督学习","1062":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#二、单变量线性回归-linear-regression-with-one-variable","1063":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#_2-1-模型表示","1064":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#_2-2-代价函数","1065":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#_2-3-代价函数的直观理解i","1066":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#_2-4-代价函数的直观理解ii","1067":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#_2-5-梯度下降","1068":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#_2-6-梯度下降的直观理解","1069":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#_2-7-梯度下降的线性回归","1070":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#_2-8-接下来的内容","1071":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#三、线性代数回顾-linear-algebra-review","1072":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#_3-1-矩阵和向量","1073":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#_3-2-加法和标量乘法","1074":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#_3-3-矩阵向量乘法","1075":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#_3-4-矩阵乘法","1076":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#_3-5-矩阵乘法的性质","1077":"/MyBlog/ai/MachineLearning/1.引言、单变量线性回归、线性代数.html#_3-6-逆、转置","1078":"/MyBlog/ai/MachineLearning/2.多变量线性回归.html#第2周","1079":"/MyBlog/ai/MachineLearning/2.多变量线性回归.html#四、多变量线性回归-linear-regression-with-multiple-variables","1080":"/MyBlog/ai/MachineLearning/2.多变量线性回归.html#_4-1-多维特征","1081":"/MyBlog/ai/MachineLearning/2.多变量线性回归.html#_4-2-多变量梯度下降","1082":"/MyBlog/ai/MachineLearning/2.多变量线性回归.html#_4-3-梯度下降法实践1-特征缩放","1083":"/MyBlog/ai/MachineLearning/2.多变量线性回归.html#_4-4-梯度下降法实践2-学习率","1084":"/MyBlog/ai/MachineLearning/2.多变量线性回归.html#_4-5-特征和多项式回归","1085":"/MyBlog/ai/MachineLearning/2.多变量线性回归.html#_4-6-正规方程","1086":"/MyBlog/ai/MachineLearning/2.多变量线性回归.html#_4-7-正规方程及不可逆性-可选","1087":"/MyBlog/ai/MachineLearning/2.多变量线性回归.html#五、octave教程-octave-tutorial","1088":"/MyBlog/ai/MachineLearning/2.多变量线性回归.html#_5-1-基本操作","1089":"/MyBlog/ai/MachineLearning/2.多变量线性回归.html#_5-2-移动数据","1090":"/MyBlog/ai/MachineLearning/2.多变量线性回归.html#_5-3-计算数据","1091":"/MyBlog/ai/MachineLearning/2.多变量线性回归.html#_5-4-绘图数据","1092":"/MyBlog/ai/MachineLearning/2.多变量线性回归.html#_5-5-控制语句-for-while-if语句","1093":"/MyBlog/ai/MachineLearning/2.多变量线性回归.html#_5-6-向量化","1094":"/MyBlog/ai/MachineLearning/2.多变量线性回归.html#_5-7-工作和提交的编程练习","1095":"/MyBlog/ai/MachineLearning/4.神经网络、表述.html#第4周","1096":"/MyBlog/ai/MachineLearning/4.神经网络、表述.html#第八、神经网络-表述-neural-networks-representation","1097":"/MyBlog/ai/MachineLearning/4.神经网络、表述.html#_8-1-非线性假设","1098":"/MyBlog/ai/MachineLearning/4.神经网络、表述.html#_8-2-神经元和大脑","1099":"/MyBlog/ai/MachineLearning/4.神经网络、表述.html#_8-3-模型表示1","1100":"/MyBlog/ai/MachineLearning/4.神经网络、表述.html#_8-4-模型表示2","1101":"/MyBlog/ai/MachineLearning/4.神经网络、表述.html#_8-5-特征和直观理解1","1102":"/MyBlog/ai/MachineLearning/4.神经网络、表述.html#_8-6-样本和直观理解ii","1103":"/MyBlog/ai/MachineLearning/4.神经网络、表述.html#_8-7-多类分类","1104":"/MyBlog/ai/MachineLearning/3.逻辑回归、正则化.html#第3周","1105":"/MyBlog/ai/MachineLearning/3.逻辑回归、正则化.html#六、逻辑回归-logistic-regression","1106":"/MyBlog/ai/MachineLearning/3.逻辑回归、正则化.html#_6-1-分类问题","1107":"/MyBlog/ai/MachineLearning/3.逻辑回归、正则化.html#_6-2-假说表示","1108":"/MyBlog/ai/MachineLearning/3.逻辑回归、正则化.html#_6-3-判定边界","1109":"/MyBlog/ai/MachineLearning/3.逻辑回归、正则化.html#_6-4-代价函数","1110":"/MyBlog/ai/MachineLearning/3.逻辑回归、正则化.html#_6-5-简化的成本函数和梯度下降","1111":"/MyBlog/ai/MachineLearning/3.逻辑回归、正则化.html#_6-6-高级优化","1112":"/MyBlog/ai/MachineLearning/3.逻辑回归、正则化.html#_6-7-多类别分类-一对多","1113":"/MyBlog/ai/MachineLearning/3.逻辑回归、正则化.html#七、正则化-regularization","1114":"/MyBlog/ai/MachineLearning/3.逻辑回归、正则化.html#_7-1-过拟合的问题","1115":"/MyBlog/ai/MachineLearning/3.逻辑回归、正则化.html#_7-2-代价函数","1116":"/MyBlog/ai/MachineLearning/3.逻辑回归、正则化.html#_7-3-正则化线性回归","1117":"/MyBlog/ai/MachineLearning/3.逻辑回归、正则化.html#_7-4-正则化的逻辑回归模型","1118":"/MyBlog/ai/MachineLearning/5.神经网络的学习.html#第5周","1119":"/MyBlog/ai/MachineLearning/5.神经网络的学习.html#九、神经网络的学习-neural-networks-learning","1120":"/MyBlog/ai/MachineLearning/5.神经网络的学习.html#_9-1-代价函数","1121":"/MyBlog/ai/MachineLearning/5.神经网络的学习.html#_9-2-反向传播算法","1122":"/MyBlog/ai/MachineLearning/5.神经网络的学习.html#_9-3-反向传播算法的直观理解","1123":"/MyBlog/ai/MachineLearning/5.神经网络的学习.html#_9-4-实现注意-展开参数","1124":"/MyBlog/ai/MachineLearning/5.神经网络的学习.html#_9-5-梯度检验","1125":"/MyBlog/ai/MachineLearning/5.神经网络的学习.html#_9-6-随机初始化","1126":"/MyBlog/ai/MachineLearning/5.神经网络的学习.html#_9-7-综合起来","1127":"/MyBlog/ai/MachineLearning/5.神经网络的学习.html#_9-8-自主驾驶","1128":"/MyBlog/ai/MachineLearning/6.学习建议、系统设计.html#第6周","1129":"/MyBlog/ai/MachineLearning/6.学习建议、系统设计.html#_10-1-决定下一步做什么","1130":"/MyBlog/ai/MachineLearning/6.学习建议、系统设计.html#_10-2-评估一个假设","1131":"/MyBlog/ai/MachineLearning/6.学习建议、系统设计.html#_10-3-模型选择和交叉验证集","1132":"/MyBlog/ai/MachineLearning/6.学习建议、系统设计.html#_10-4-诊断偏差和方差","1133":"/MyBlog/ai/MachineLearning/6.学习建议、系统设计.html#_10-5-正则化和偏差-方差","1134":"/MyBlog/ai/MachineLearning/6.学习建议、系统设计.html#_10-6-学习曲线","1135":"/MyBlog/ai/MachineLearning/6.学习建议、系统设计.html#_10-7-决定下一步做什么","1136":"/MyBlog/ai/MachineLearning/6.学习建议、系统设计.html#十一、机器学习系统的设计-machine-learning-system-design","1137":"/MyBlog/ai/MachineLearning/6.学习建议、系统设计.html#_11-1-首先要做什么","1138":"/MyBlog/ai/MachineLearning/6.学习建议、系统设计.html#_11-2-误差分析","1139":"/MyBlog/ai/MachineLearning/6.学习建议、系统设计.html#_11-3-类偏斜的误差度量","1140":"/MyBlog/ai/MachineLearning/6.学习建议、系统设计.html#_11-4-查准率和查全率之间的权衡","1141":"/MyBlog/ai/MachineLearning/6.学习建议、系统设计.html#_11-5-机器学习的数据","1142":"/MyBlog/ai/MachineLearning/7.支持向量机.html#第7周","1143":"/MyBlog/ai/MachineLearning/7.支持向量机.html#_12-1-优化目标","1144":"/MyBlog/ai/MachineLearning/7.支持向量机.html#_12-2-大边界的直观理解","1145":"/MyBlog/ai/MachineLearning/7.支持向量机.html#_12-3-大边界分类背后的数学-选修","1146":"/MyBlog/ai/MachineLearning/7.支持向量机.html#_12-4-核函数1","1147":"/MyBlog/ai/MachineLearning/7.支持向量机.html#_12-5-核函数2","1148":"/MyBlog/ai/MachineLearning/7.支持向量机.html#_12-6-使用支持向量机","1149":"/MyBlog/ai/MachineLearning/8.聚类、降维.html#第8周","1150":"/MyBlog/ai/MachineLearning/8.聚类、降维.html#_13-1-无监督学习-简介","1151":"/MyBlog/ai/MachineLearning/8.聚类、降维.html#_13-2-k-均值算法","1152":"/MyBlog/ai/MachineLearning/8.聚类、降维.html#_13-3-优化目标","1153":"/MyBlog/ai/MachineLearning/8.聚类、降维.html#_13-4-随机初始化","1154":"/MyBlog/ai/MachineLearning/8.聚类、降维.html#_13-5-选择聚类数","1155":"/MyBlog/ai/MachineLearning/8.聚类、降维.html#十四、降维-dimensionality-reduction","1156":"/MyBlog/ai/MachineLearning/8.聚类、降维.html#_14-1-动机一-数据压缩","1157":"/MyBlog/ai/MachineLearning/8.聚类、降维.html#_14-2-动机二-数据可视化","1158":"/MyBlog/ai/MachineLearning/8.聚类、降维.html#_14-3-主成分分析问题","1159":"/MyBlog/ai/MachineLearning/8.聚类、降维.html#_14-4-主成分分析算法","1160":"/MyBlog/ai/MachineLearning/8.聚类、降维.html#_14-5-选择主成分的数量","1161":"/MyBlog/ai/MachineLearning/8.聚类、降维.html#_14-6-重建的压缩表示","1162":"/MyBlog/ai/MachineLearning/8.聚类、降维.html#_14-7-主成分分析法的应用建议","1163":"/MyBlog/ai/MachineLearning/X.大规模机器学习、Photo OCR、总结.html#第10周","1164":"/MyBlog/ai/MachineLearning/X.大规模机器学习、Photo OCR、总结.html#_17-1-大型数据集的学习","1165":"/MyBlog/ai/MachineLearning/X.大规模机器学习、Photo OCR、总结.html#_17-2-随机梯度下降法","1166":"/MyBlog/ai/MachineLearning/X.大规模机器学习、Photo OCR、总结.html#_17-3-小批量梯度下降","1167":"/MyBlog/ai/MachineLearning/X.大规模机器学习、Photo OCR、总结.html#_17-4-随机梯度下降收敛","1168":"/MyBlog/ai/MachineLearning/X.大规模机器学习、Photo OCR、总结.html#_17-5-在线学习","1169":"/MyBlog/ai/MachineLearning/X.大规模机器学习、Photo OCR、总结.html#_17-6-映射化简和数据并行","1170":"/MyBlog/ai/MachineLearning/X.大规模机器学习、Photo OCR、总结.html#十八、应用实例-图片文字识别-application-example-photo-ocr","1171":"/MyBlog/ai/MachineLearning/X.大规模机器学习、Photo OCR、总结.html#_18-1-问题描述和流程图","1172":"/MyBlog/ai/MachineLearning/X.大规模机器学习、Photo OCR、总结.html#_18-2-滑动窗口","1173":"/MyBlog/ai/MachineLearning/X.大规模机器学习、Photo OCR、总结.html#_18-3-获取大量数据和人工数据","1174":"/MyBlog/ai/MachineLearning/X.大规模机器学习、Photo OCR、总结.html#_18-4-上限分析-哪部分管道的接下去做","1175":"/MyBlog/ai/MachineLearning/X.大规模机器学习、Photo OCR、总结.html#十九、总结-conclusion","1176":"/MyBlog/ai/MachineLearning/X.大规模机器学习、Photo OCR、总结.html#_19-1-总结和致谢","1177":"/MyBlog/ai/MachineLearning/9.异常检测、推荐系统.html#第9周","1178":"/MyBlog/ai/MachineLearning/9.异常检测、推荐系统.html#_15-1-问题的动机","1179":"/MyBlog/ai/MachineLearning/9.异常检测、推荐系统.html#_15-2-高斯分布","1180":"/MyBlog/ai/MachineLearning/9.异常检测、推荐系统.html#_15-3-算法","1181":"/MyBlog/ai/MachineLearning/9.异常检测、推荐系统.html#_15-4-开发和评价一个异常检测系统","1182":"/MyBlog/ai/MachineLearning/9.异常检测、推荐系统.html#_15-5-异常检测与监督学习对比","1183":"/MyBlog/ai/MachineLearning/9.异常检测、推荐系统.html#_15-6-选择特征","1184":"/MyBlog/ai/MachineLearning/9.异常检测、推荐系统.html#_15-7-多元高斯分布-选修","1185":"/MyBlog/ai/MachineLearning/9.异常检测、推荐系统.html#_15-8-使用多元高斯分布进行异常检测-可选","1186":"/MyBlog/ai/MachineLearning/9.异常检测、推荐系统.html#十六、推荐系统-recommender-systems","1187":"/MyBlog/ai/MachineLearning/9.异常检测、推荐系统.html#_16-1-问题形式化","1188":"/MyBlog/ai/MachineLearning/9.异常检测、推荐系统.html#_16-2-基于内容的推荐系统","1189":"/MyBlog/ai/MachineLearning/9.异常检测、推荐系统.html#_16-3-协同过滤","1190":"/MyBlog/ai/MachineLearning/9.异常检测、推荐系统.html#_16-4-协同过滤算法","1191":"/MyBlog/ai/MachineLearning/9.异常检测、推荐系统.html#_16-5-向量化-低秩矩阵分解","1192":"/MyBlog/ai/MachineLearning/9.异常检测、推荐系统.html#_16-6-推行工作上的细节-均值归一化","1193":"/MyBlog/ai/MachineLearning/#斯坦福大学-2014-机器学习教程中文笔记目录","1194":"/MyBlog/backend/NoSQL/MongoDB技术解析.html#mongodb-技术解析-从单机到分布式的存储引擎与架构设计","1195":"/MyBlog/backend/NoSQL/MongoDB技术解析.html#🟢-基础概念","1196":"/MyBlog/backend/NoSQL/MongoDB技术解析.html#📄-文档-document-与集合-collection","1197":"/MyBlog/backend/NoSQL/MongoDB技术解析.html#🗂️-bson-编码","1198":"/MyBlog/backend/NoSQL/MongoDB技术解析.html#💾-数据页结构与-wt-文件","1199":"/MyBlog/backend/NoSQL/MongoDB技术解析.html#🌳-变种-b-树索引","1200":"/MyBlog/backend/NoSQL/MongoDB技术解析.html#🔄-并发控制-写时复制-copy-on-write","1201":"/MyBlog/backend/NoSQL/MongoDB技术解析.html#🧩-缓存策略-cache-lru-淘汰","1202":"/MyBlog/backend/NoSQL/MongoDB技术解析.html#📝-持久化保障","1203":"/MyBlog/backend/NoSQL/MongoDB技术解析.html#⚙️-wiredtiger-与-server-层关系","1204":"/MyBlog/backend/NoSQL/MongoDB技术解析.html#🔑-存储引擎的定位与接口","1205":"/MyBlog/backend/NoSQL/MongoDB技术解析.html#🏗️-单机-mongodb-的本质-对比-mysql","1206":"/MyBlog/backend/NoSQL/MongoDB技术解析.html#📡-分片集群-sharding","1207":"/MyBlog/backend/NoSQL/MongoDB技术解析.html#分片逻辑","1208":"/MyBlog/backend/NoSQL/MongoDB技术解析.html#🧭-路由服务与配置中心","1209":"/MyBlog/backend/NoSQL/MongoDB技术解析.html#🧩-副本集-replica-set","1210":"/MyBlog/backend/NoSQL/MongoDB技术解析.html#🌍-分布式-mongodb-集群","1211":"/MyBlog/backend/NoSQL/MongoDB技术解析.html#✅-总结","1212":"/MyBlog/backend/Python/1.Python基础语法.html#python基础语法学习笔记","1213":"/MyBlog/backend/Python/1.Python基础语法.html#一、变量与数据类型","1214":"/MyBlog/backend/Python/1.Python基础语法.html#_1-变量的定义与命名","1215":"/MyBlog/backend/Python/1.Python基础语法.html#命名规范建议-符合-pep8","1216":"/MyBlog/backend/Python/1.Python基础语法.html#_2-常见数据类型与说明","1217":"/MyBlog/backend/Python/1.Python基础语法.html#二、运算符","1218":"/MyBlog/backend/Python/1.Python基础语法.html#_1-算术运算符","1219":"/MyBlog/backend/Python/1.Python基础语法.html#_2-比较运算符-返回布尔值","1220":"/MyBlog/backend/Python/1.Python基础语法.html#_3-逻辑运算符","1221":"/MyBlog/backend/Python/1.Python基础语法.html#_4-成员运算符","1222":"/MyBlog/backend/Python/1.Python基础语法.html#三、流程控制语句","1223":"/MyBlog/backend/Python/1.Python基础语法.html#_1-条件语句-if-elif-else","1224":"/MyBlog/backend/Python/1.Python基础语法.html#_2-循环语句-for-和-while","1225":"/MyBlog/backend/Python/1.Python基础语法.html#for-循环-适合遍历列表、字符串、range","1226":"/MyBlog/backend/Python/1.Python基础语法.html#while-循环-条件满足就继续执行","1227":"/MyBlog/backend/Python/1.Python基础语法.html#_3-循环控制语句","1228":"/MyBlog/backend/Python/1.Python基础语法.html#四、函数定义与使用","1229":"/MyBlog/backend/Python/1.Python基础语法.html#_1-定义函数","1230":"/MyBlog/backend/Python/1.Python基础语法.html#_2-参数类型","1231":"/MyBlog/backend/Python/1.Python基础语法.html#五、常用内建函数与输入输出","1232":"/MyBlog/backend/Python/1.Python基础语法.html#常用函数","1233":"/MyBlog/backend/Python/1.Python基础语法.html#示例","1234":"/MyBlog/backend/Python/1.Python基础语法.html#六、模块与导入","1235":"/MyBlog/backend/Python/1.Python基础语法.html#导入模块的方式","1236":"/MyBlog/backend/Python/1.Python基础语法.html#七、异常处理机制","1237":"/MyBlog/backend/Python/2.python进阶.html#🧠-python进阶语法与编程技巧","1238":"/MyBlog/backend/Python/2.python进阶.html#一、函数式编程技巧","1239":"/MyBlog/backend/Python/2.python进阶.html#_1-lambda-匿名函数","1240":"/MyBlog/backend/Python/2.python进阶.html#_2-map-filter-reduce","1241":"/MyBlog/backend/Python/2.python进阶.html#二、列表-字典推导式","1242":"/MyBlog/backend/Python/2.python进阶.html#列表推导式","1243":"/MyBlog/backend/Python/2.python进阶.html#字典推导式","1244":"/MyBlog/backend/Python/2.python进阶.html#三、装饰器-decorator","1245":"/MyBlog/backend/Python/2.python进阶.html#四、生成器与迭代器","1246":"/MyBlog/backend/Python/2.python进阶.html#_1-生成器函数-yield","1247":"/MyBlog/backend/Python/2.python进阶.html#_2-生成器表达式","1248":"/MyBlog/backend/Python/2.python进阶.html#五、异常处理进阶","1249":"/MyBlog/backend/Python/2.python进阶.html#自定义异常类","1250":"/MyBlog/backend/Python/2.python进阶.html#多种异常捕获","1251":"/MyBlog/backend/Python/2.python进阶.html#六、上下文管理器-with-语句","1252":"/MyBlog/backend/Python/2.python进阶.html#文件读写的标准方式","1253":"/MyBlog/backend/Python/2.python进阶.html#七、类与对象进阶-oop","1254":"/MyBlog/backend/Python/2.python进阶.html#_1-类方法与静态方法","1255":"/MyBlog/backend/Python/2.python进阶.html#_2-属性装饰器","1256":"/MyBlog/backend/Python/2.python进阶.html#八、模块与包管理","1257":"/MyBlog/backend/Python/2.python进阶.html#自定义模块与导入","1258":"/MyBlog/backend/Python/2.python进阶.html#包结构与-init-py","1259":"/MyBlog/backend/Python/2.python进阶.html#九、类型注解-python-3-5","1260":"/MyBlog/backend/Python/2.python进阶.html#十、代码性能与调试","1261":"/MyBlog/backend/Python/2.python进阶.html#_1-简易性能测试","1262":"/MyBlog/backend/Python/2.python进阶.html#_2-使用-timeit-模块","1263":"/MyBlog/backend/Python/2.python进阶.html#十一、常见标准库","1264":"/MyBlog/backend/Python/2.python进阶.html#十二、建议写法与风格规范","1265":"/MyBlog/backend/Python/3.Python项目管理.html#🚀-python项目管理工具全景总结——从pip到uv-含入门教程","1266":"/MyBlog/backend/Python/3.Python项目管理.html#_1-pip-requirements-txt","1267":"/MyBlog/backend/Python/3.Python项目管理.html#介绍","1268":"/MyBlog/backend/Python/3.Python项目管理.html#安装","1269":"/MyBlog/backend/Python/3.Python项目管理.html#入门示例","1270":"/MyBlog/backend/Python/3.Python项目管理.html#_2-venv-virtualenv","1271":"/MyBlog/backend/Python/3.Python项目管理.html#介绍-1","1272":"/MyBlog/backend/Python/3.Python项目管理.html#安装-1","1273":"/MyBlog/backend/Python/3.Python项目管理.html#入门示例-1","1274":"/MyBlog/backend/Python/3.Python项目管理.html#_3-conda","1275":"/MyBlog/backend/Python/3.Python项目管理.html#介绍-2","1276":"/MyBlog/backend/Python/3.Python项目管理.html#安装-2","1277":"/MyBlog/backend/Python/3.Python项目管理.html#入门示例-2","1278":"/MyBlog/backend/Python/3.Python项目管理.html#_4-pipenv","1279":"/MyBlog/backend/Python/3.Python项目管理.html#介绍-3","1280":"/MyBlog/backend/Python/3.Python项目管理.html#安装-3","1281":"/MyBlog/backend/Python/3.Python项目管理.html#入门示例-3","1282":"/MyBlog/backend/Python/3.Python项目管理.html#_5-poetry","1283":"/MyBlog/backend/Python/3.Python项目管理.html#介绍-4","1284":"/MyBlog/backend/Python/3.Python项目管理.html#安装-4","1285":"/MyBlog/backend/Python/3.Python项目管理.html#入门示例-4","1286":"/MyBlog/backend/Python/3.Python项目管理.html#_6-pdm","1287":"/MyBlog/backend/Python/3.Python项目管理.html#介绍-5","1288":"/MyBlog/backend/Python/3.Python项目管理.html#安装-5","1289":"/MyBlog/backend/Python/3.Python项目管理.html#入门示例-5","1290":"/MyBlog/backend/Python/3.Python项目管理.html#_7-uv","1291":"/MyBlog/backend/Python/3.Python项目管理.html#介绍-6","1292":"/MyBlog/backend/Python/3.Python项目管理.html#安装-6","1293":"/MyBlog/backend/Python/3.Python项目管理.html#入门示例-6","1294":"/MyBlog/backend/Python/3.Python项目管理.html#总结","1295":"/MyBlog/backend/Python/#🐍-python语言介绍-为何它成为-万能胶水语言","1296":"/MyBlog/backend/Python/#🔍-一、什么是-python","1297":"/MyBlog/backend/Python/#🛠-二、python-可以做什么","1298":"/MyBlog/backend/Python/#🌱-三、为什么初学者适合学习-python","1299":"/MyBlog/backend/Python/#✅-上手容易","1300":"/MyBlog/backend/Python/#✅-社区活跃","1301":"/MyBlog/backend/Python/#✅-可做项目多","1302":"/MyBlog/backend/Python/#⚙️-四、python-的基本特性","1303":"/MyBlog/backend/Python/#📈-五、python-的发展现状","1304":"/MyBlog/backend/Python/#🚀-六、如何开始学习-python","1305":"/MyBlog/backend/Python/#🎯-结语-python-是开启编程世界的一把钥匙","1306":"/MyBlog/backend/Python/#📚-推荐资源","1307":"/MyBlog/devops/CI_CD/GitHub Action详解.html#深入-github-actions-核心机制深入解读与实战示例","1308":"/MyBlog/devops/CI_CD/GitHub Action详解.html#一、核心概念深入解构","1309":"/MyBlog/devops/CI_CD/GitHub Action详解.html#_1-workflow-工作流","1310":"/MyBlog/devops/CI_CD/GitHub Action详解.html#_2-job-作业","1311":"/MyBlog/devops/CI_CD/GitHub Action详解.html#_3-step-步骤-与-action-动作","1312":"/MyBlog/devops/CI_CD/GitHub Action详解.html#_4-runner-运行器","1313":"/MyBlog/devops/CI_CD/GitHub Action详解.html#_5-matrix-矩阵策略","1314":"/MyBlog/devops/CI_CD/GitHub Action详解.html#_6-注释机制","1315":"/MyBlog/devops/CI_CD/GitHub Action详解.html#二、带注释的完整-ci-矩阵-发布-workflow-示例","1316":"/MyBlog/devops/Git/Git学习笔记.html#git-学习笔记","1317":"/MyBlog/devops/Git/Git学习笔记.html#_1-git-基础概念","1318":"/MyBlog/devops/Git/Git学习笔记.html#_1-1-什么是-git","1319":"/MyBlog/devops/Git/Git学习笔记.html#_1-2-git-的四个核心区域","1320":"/MyBlog/devops/Git/Git学习笔记.html#_1-3-git-对象模型","1321":"/MyBlog/devops/Git/Git学习笔记.html#_1-4-提交-commit","1322":"/MyBlog/devops/Git/Git学习笔记.html#_1-5-分支-branch","1323":"/MyBlog/devops/Git/Git学习笔记.html#_1-6-head-指针","1324":"/MyBlog/devops/Git/Git学习笔记.html#_1-7-远程仓库-remote","1325":"/MyBlog/devops/Git/Git学习笔记.html#_1-8-git-工作流","1326":"/MyBlog/devops/Git/Git学习笔记.html#_2-git-常用命令","1327":"/MyBlog/devops/Git/Git学习笔记.html#_2-1-初始化与克隆","1328":"/MyBlog/devops/Git/Git学习笔记.html#_2-2-基本操作","1329":"/MyBlog/devops/Git/Git学习笔记.html#_2-3-分支管理","1330":"/MyBlog/devops/Git/Git学习笔记.html#_2-4-远程仓库操作","1331":"/MyBlog/devops/Git/Git学习笔记.html#_3-git-进阶操作","1332":"/MyBlog/devops/Git/Git学习笔记.html#_3-1-暂存修改","1333":"/MyBlog/devops/Git/Git学习笔记.html#_3-2-回退与撤销","1334":"/MyBlog/devops/Git/Git学习笔记.html#_3-3-rebase-变基","1335":"/MyBlog/devops/Git/Git学习笔记.html#_3-4-tag-标签","1336":"/MyBlog/devops/Git/Git学习笔记.html#_4-git-实用技巧","1337":"/MyBlog/devops/Git/Git学习笔记.html#_5-常见问题与解决方法","1338":"/MyBlog/devops/container/docker基础.html#🐳-docker-学习笔记","1339":"/MyBlog/devops/container/docker基础.html#_1-docker-是什么","1340":"/MyBlog/devops/container/docker基础.html#_2-docker-架构原理","1341":"/MyBlog/devops/container/docker基础.html#_3-docker-命令基础","1342":"/MyBlog/devops/container/docker基础.html#镜像相关","1343":"/MyBlog/devops/container/docker基础.html#容器相关","1344":"/MyBlog/devops/container/docker基础.html#日志与进入容器","1345":"/MyBlog/devops/container/docker基础.html#数据卷与网络","1346":"/MyBlog/devops/container/docker基础.html#_4-docker-容器和虚拟机的区别","1347":"/MyBlog/devops/container/docker基础.html#_5-docker-compose-是什么","1348":"/MyBlog/devops/container/docker基础.html#_6-docker-swarm-是什么","1349":"/MyBlog/devops/container/docker基础.html#_7-docker-compose-和-docker-swarm-的区别","1350":"/MyBlog/devops/container/docker基础.html#_8-docker-和-kubernetes-k8s-的关系","1351":"/MyBlog/devops/container/docker基础.html#_9-docker-swarm-和-kubernetes-k8s-的差异","1352":"/MyBlog/devops/container/#容器化与分布式集群","1353":"/MyBlog/devops/container/#从虚拟机到容器","1354":"/MyBlog/devops/container/#容器化的意义","1355":"/MyBlog/devops/container/#分布式集群的演进","1356":"/MyBlog/devops/container/#容器化与集群化的关系","1357":"/MyBlog/devops/container/#展望","1358":"/MyBlog/devops/server/Nginx详解.html#nginx-技术博客","1359":"/MyBlog/devops/server/Nginx详解.html#一、nginx-简介","1360":"/MyBlog/devops/server/Nginx详解.html#二、核心概念","1361":"/MyBlog/devops/server/Nginx详解.html#_1-正向代理与反向代理","1362":"/MyBlog/devops/server/Nginx详解.html#_2-负载均衡","1363":"/MyBlog/devops/server/Nginx详解.html#_3-静态资源服务","1364":"/MyBlog/devops/server/Nginx详解.html#三、nginx-配置文件结构","1365":"/MyBlog/devops/server/Nginx详解.html#配置解析","1366":"/MyBlog/devops/server/Nginx详解.html#四、常见应用场景","1367":"/MyBlog/devops/server/Nginx详解.html#_1-静态资源服务器","1368":"/MyBlog/devops/server/Nginx详解.html#_2-反向代理","1369":"/MyBlog/devops/server/Nginx详解.html#_3-负载均衡","1370":"/MyBlog/devops/server/Nginx详解.html#_4-https-配置-ssl-证书","1371":"/MyBlog/devops/server/Nginx详解.html#五、性能优化实践","1372":"/MyBlog/devops/server/Nginx详解.html#六、nginx-与-devops","1373":"/MyBlog/devops/container/k8s简介.html#kubernetes-学习笔记","1374":"/MyBlog/devops/container/k8s简介.html#_1-什么是-kubernetes","1375":"/MyBlog/devops/container/k8s简介.html#_2-kubernetes-架构原理","1376":"/MyBlog/devops/container/k8s简介.html#_2-1-控制平面-control-plane","1377":"/MyBlog/devops/container/k8s简介.html#_2-2-工作节点-worker-node","1378":"/MyBlog/devops/container/k8s简介.html#_2-3-架构图-简化","1379":"/MyBlog/devops/container/k8s简介.html#_3-kubernetes-核心概念","1380":"/MyBlog/devops/container/k8s简介.html#_3-1-pod","1381":"/MyBlog/devops/container/k8s简介.html#_3-2-cluster","1382":"/MyBlog/devops/container/k8s简介.html#_3-3-replicaset","1383":"/MyBlog/devops/container/k8s简介.html#_3-4-deployment","1384":"/MyBlog/devops/container/k8s简介.html#_3-5-service","1385":"/MyBlog/devops/container/k8s简介.html#_3-6-configmap-secret","1386":"/MyBlog/devops/container/k8s简介.html#_3-7-volume","1387":"/MyBlog/devops/container/k8s简介.html#_3-8-namespace","1388":"/MyBlog/devops/container/k8s简介.html#_4-kubernetes-yaml-配置","1389":"/MyBlog/devops/container/k8s简介.html#_4-1-pod-示例","1390":"/MyBlog/devops/container/k8s简介.html#_4-2-deployment-示例","1391":"/MyBlog/devops/container/k8s简介.html#_4-3-service-示例","1392":"/MyBlog/devops/container/k8s简介.html#_5-kubernetes-常用命令","1393":"/MyBlog/devops/container/k8s简介.html#_6-kubernetes-部署方式","1394":"/MyBlog/devops/container/k8s简介.html#_7-kubernetes-与-docker-的关系","1395":"/MyBlog/devops/container/k8s简介.html#_8-kubernetes-与-docker-swarm-的区别","1396":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#typescript-学习笔记","1397":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#_1-类型声明","1398":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#基本语法","1399":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#类型断言","1400":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#_2-类型推断","1401":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#自动类型推断","1402":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#上下文类型推断","1403":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#_3-类型总览","1404":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#基础类型分类","1405":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#复合类型","1406":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#_4-常用类型","1407":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#联合类型-union-types","1408":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#交叉类型-intersection-types","1409":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#条件类型","1410":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#映射类型","1411":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#_5-自定义类型","1412":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#类型别名-type-aliases","1413":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#枚举-enums","1414":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#字面量类型","1415":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#_6-抽象类","1416":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#基本抽象类","1417":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#抽象类的高级用法","1418":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#_7-接口","1419":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#基本接口","1420":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#函数接口","1421":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#可索引接口","1422":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#类接口","1423":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#接口继承","1424":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#_8-属性修饰符","1425":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#访问修饰符","1426":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#readonly-修饰符","1427":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#可选修饰符","1428":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#参数属性","1429":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#_9-泛型","1430":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#基本泛型函数","1431":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#泛型接口","1432":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#泛型类","1433":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#泛型约束","1434":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#条件类型与泛型","1435":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#映射类型与泛型","1436":"/MyBlog/frontend/TypeScript/TypeScript学习笔记.html#学习建议","1437":"/MyBlog/frontend/Vue/1.Vue3简介.html#_1-vue3简介","1438":"/MyBlog/frontend/Vue/1.Vue3简介.html#_1-1-【性能的提升】","1439":"/MyBlog/frontend/Vue/1.Vue3简介.html#_1-2-【-源码的升级】","1440":"/MyBlog/frontend/Vue/1.Vue3简介.html#_1-3-【拥抱typescript】","1441":"/MyBlog/frontend/Vue/1.Vue3简介.html#_1-4-【新的特性】","1442":"/MyBlog/frontend/Vue/2.创建Vue3工程.html#_2-创建vue3工程","1443":"/MyBlog/frontend/Vue/2.创建Vue3工程.html#_2-1-【基于-vue-cli-创建】","1444":"/MyBlog/frontend/Vue/2.创建Vue3工程.html#_2-2-【基于-vite-创建】-推荐","1445":"/MyBlog/frontend/Vue/2.创建Vue3工程.html#_2-3-【一个简单的效果】","1446":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#_3-vue3核心语法","1447":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#_3-1-【optionsapi-与-compositionapi】","1448":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#options-api-的弊端","1449":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#composition-api-的优势","1450":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#_3-2-【拉开序幕的-setup】","1451":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#setup-概述","1452":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#setup-的返回值","1453":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#setup-与-options-api-的关系","1454":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#setup-语法糖","1455":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#_3-3-【ref-创建-基本类型的响应式数据】","1456":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#_3-4-【reactive-创建-对象类型的响应式数据】","1457":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#_3-5-【ref-创建-对象类型的响应式数据】","1458":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#_3-6-【ref-对比-reactive】","1459":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#_3-7-【torefs-与-toref】","1460":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#_3-8-【computed】","1461":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#_3-9-【watch】","1462":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#情况一","1463":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#情况二","1464":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#情况三","1465":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#情况四","1466":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#情况五","1467":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#_3-10-【watcheffect】","1468":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#_3-11-【标签的-ref-属性】","1469":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#_3-12-【props】","1470":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#_3-13-【生命周期】","1471":"/MyBlog/frontend/Vue/3.Vue3核心语法.html#_3-14-【自定义hook】","1472":"/MyBlog/frontend/Vue/4.路由.html#_4-路由","1473":"/MyBlog/frontend/Vue/4.路由.html#_4-1-【对路由的理解】","1474":"/MyBlog/frontend/Vue/4.路由.html#_4-2-【基本切换效果】","1475":"/MyBlog/frontend/Vue/4.路由.html#_4-3-【两个注意点】","1476":"/MyBlog/frontend/Vue/4.路由.html#_4-4-【路由器工作模式】","1477":"/MyBlog/frontend/Vue/4.路由.html#_4-5-【to的两种写法】","1478":"/MyBlog/frontend/Vue/4.路由.html#_4-6-【命名路由】","1479":"/MyBlog/frontend/Vue/4.路由.html#_4-7-【嵌套路由】","1480":"/MyBlog/frontend/Vue/4.路由.html#_4-8-【路由传参】","1481":"/MyBlog/frontend/Vue/4.路由.html#query参数","1482":"/MyBlog/frontend/Vue/4.路由.html#params参数","1483":"/MyBlog/frontend/Vue/4.路由.html#_4-9-【路由的props配置】","1484":"/MyBlog/frontend/Vue/4.路由.html#_4-10-【-replace属性】","1485":"/MyBlog/frontend/Vue/4.路由.html#_4-11-【编程式导航】","1486":"/MyBlog/frontend/Vue/4.路由.html#_4-12-【重定向】","1487":"/MyBlog/frontend/Vue/5.pinia.html#_5-pinia","1488":"/MyBlog/frontend/Vue/5.pinia.html#_5-1【准备一个效果】","1489":"/MyBlog/frontend/Vue/5.pinia.html#_5-2【搭建-pinia-环境】","1490":"/MyBlog/frontend/Vue/5.pinia.html#_5-3【存储-读取数据】","1491":"/MyBlog/frontend/Vue/5.pinia.html#_5-4-【修改数据】-三种方式","1492":"/MyBlog/frontend/Vue/5.pinia.html#_5-5-【storetorefs】","1493":"/MyBlog/frontend/Vue/5.pinia.html#_5-6-【getters】","1494":"/MyBlog/frontend/Vue/5.pinia.html#_5-7-【-subscribe】","1495":"/MyBlog/frontend/Vue/5.pinia.html#_5-8-【store组合式写法】","1496":"/MyBlog/frontend/Vue/6.组件通信.html#_6-组件通信","1497":"/MyBlog/frontend/Vue/6.组件通信.html#_6-1-【props】","1498":"/MyBlog/frontend/Vue/6.组件通信.html#_6-2-【自定义事件】","1499":"/MyBlog/frontend/Vue/6.组件通信.html#_6-3-【mitt】","1500":"/MyBlog/frontend/Vue/6.组件通信.html#_6-4-【v-model】","1501":"/MyBlog/frontend/Vue/6.组件通信.html#_6-5-【-attrs-】","1502":"/MyBlog/frontend/Vue/6.组件通信.html#_6-6-【parent】","1503":"/MyBlog/frontend/Vue/6.组件通信.html#_6-7-【provide、inject】","1504":"/MyBlog/frontend/Vue/6.组件通信.html#_6-8-【pinia】","1505":"/MyBlog/frontend/Vue/6.组件通信.html#_6-9-【slot】","1506":"/MyBlog/frontend/Vue/6.组件通信.html#_1-默认插槽","1507":"/MyBlog/frontend/Vue/6.组件通信.html#_2-具名插槽","1508":"/MyBlog/frontend/Vue/6.组件通信.html#_3-作用域插槽","1509":"/MyBlog/frontend/Vue/7.其他API.html#_7-其它-api","1510":"/MyBlog/frontend/Vue/7.其他API.html#_7-1-【shallowref-与-shallowreactive-】","1511":"/MyBlog/frontend/Vue/7.其他API.html#shallowref","1512":"/MyBlog/frontend/Vue/7.其他API.html#shallowreactive","1513":"/MyBlog/frontend/Vue/7.其他API.html#总结","1514":"/MyBlog/frontend/Vue/7.其他API.html#_7-2-【readonly-与-shallowreadonly】","1515":"/MyBlog/frontend/Vue/7.其他API.html#readonly","1516":"/MyBlog/frontend/Vue/7.其他API.html#shallowreadonly","1517":"/MyBlog/frontend/Vue/7.其他API.html#_7-3-【toraw-与-markraw】","1518":"/MyBlog/frontend/Vue/7.其他API.html#toraw","1519":"/MyBlog/frontend/Vue/7.其他API.html#markraw","1520":"/MyBlog/frontend/Vue/7.其他API.html#_7-4-【customref】","1521":"/MyBlog/frontend/Vue/8.Vue3新组件.html#_8-vue3新组件","1522":"/MyBlog/frontend/Vue/8.Vue3新组件.html#_8-1-【teleport】","1523":"/MyBlog/frontend/Vue/8.Vue3新组件.html#_8-2-【suspense】","1524":"/MyBlog/frontend/Vue/8.Vue3新组件.html#_8-3-【全局api转移到应用对象】","1525":"/MyBlog/frontend/Vue/8.Vue3新组件.html#_8-4-【其他】","1526":"/MyBlog/frontend/Vue/#🌿-vue-js-简介","1527":"/MyBlog/frontend/Vue/#🚩-核心特性","1528":"/MyBlog/frontend/Vue/#🌐-vue-技术生态","1529":"/MyBlog/frontend/Vue/#🧭-适用场景","1530":"/MyBlog/frontend/Vue/#🔍-与其他框架对比","1531":"/MyBlog/frontend/Vue/#❤️-总结","1532":"/MyBlog/frontend/#🌟-前端开发-打造网页魔法师的奇妙世界","1533":"/MyBlog/frontend/#什么是前端开发","1534":"/MyBlog/frontend/#为什么说前端开发很有趣","1535":"/MyBlog/frontend/#_1-立刻见效的成就感","1536":"/MyBlog/frontend/#_2-无限创意空间","1537":"/MyBlog/frontend/#_3-技术与设计的交叉","1538":"/MyBlog/frontend/#_4-巨大的社区和生态","1539":"/MyBlog/frontend/#前端开发的核心三剑客","1540":"/MyBlog/frontend/#未来的前端-值得期待","1541":"/MyBlog/frontend/#小结","1542":"/MyBlog/self-intro.html#嗨-欢迎来到我的小站-👋","1543":"/MyBlog/self-intro.html#我最近在折腾啥-🛠️","1544":"/MyBlog/self-intro.html#我的技术口味-🍜","1545":"/MyBlog/self-intro.html#为什么写博客-✍️","1546":"/MyBlog/self-intro.html#你会在这里看到-📚","1547":"/MyBlog/self-intro.html#小目标与进行中-✅","1548":"/MyBlog/self-intro.html#本站怎么逛-🧭","1549":"/MyBlog/self-intro.html#技术之外-🌿","1550":"/MyBlog/self-intro.html#找到我-📬"},"fieldIds":{"title":0,"titles":1,"text":2},"fieldLength":{"0":[3,1,51],"1":[1,3,1],"2":[2,4,2],"3":[2,4,2],"4":[2,4,2],"5":[1,3,11],"6":[3,1,14],"7":[2,3,26],"8":[2,3,21],"9":[1,3,11],"10":[1,1,5],"11":[1,1,8],"12":[1,1,6],"13":[1,1,12],"14":[1,1,1],"15":[1,2,6],"16":[1,2,6],"17":[1,2,6],"18":[1,1,3],"19":[1,1,15],"20":[1,1,43],"21":[1,1,94],"22":[1,1,6],"23":[1,1,17],"24":[1,1,4],"25":[1,1,64],"26":[1,1,119],"27":[1,1,109],"28":[1,1,67],"29":[1,1,29],"30":[1,1,19],"31":[1,1,41],"32":[1,1,44],"33":[1,1,51],"34":[1,1,98],"35":[1,1,90],"36":[1,1,10],"37":[1,1,15],"38":[1,1,43],"39":[1,1,7],"40":[1,2,68],"41":[1,2,73],"42":[1,2,46],"43":[1,1,2],"44":[1,2,75],"45":[1,2,31],"46":[1,2,130],"47":[1,1,28],"48":[1,2,54],"49":[1,2,33],"50":[1,2,49],"51":[1,1,18],"52":[1,1,56],"53":[1,1,18],"54":[1,1,121],"55":[1,2,47],"56":[1,2,36],"57":[1,1,138],"58":[1,1,23],"59":[1,2,133],"60":[1,2,73],"61":[1,2,26],"62":[1,2,23],"63":[1,1,13],"64":[1,1,40],"65":[1,1,51],"66":[1,1,71],"67":[1,1,224],"68":[1,1,110],"69":[1,1,8],"70":[1,2,47],"71":[1,2,94],"72":[1,2,107],"73":[1,2,89],"74":[1,1,16],"75":[1,1,27],"76":[1,1,21],"77":[1,1,171],"78":[1,1,105],"79":[1,1,56],"80":[1,1,208],"81":[1,1,146],"82":[1,1,19],"83":[1,1,19],"84":[1,1,16],"85":[1,1,3],"86":[1,2,89],"87":[1,2,77],"88":[1,2,64],"89":[1,2,38],"90":[1,1,4],"91":[1,2,77],"92":[1,2,33],"93":[1,1,8],"94":[1,2,54],"95":[1,2,90],"96":[1,1,13],"97":[1,1,23],"98":[1,1,13],"99":[1,1,105],"100":[1,1,18],"101":[1,2,56],"102":[1,2,93],"103":[1,2,54],"104":[1,1,8],"105":[1,1,49],"106":[1,1,41],"107":[1,1,72],"108":[1,1,97],"109":[1,1,34],"110":[1,1,9],"111":[1,1,28],"112":[1,1,36],"113":[1,1,120],"114":[1,1,98],"115":[1,1,143],"116":[1,1,65],"117":[1,1,21],"118":[1,1,42],"119":[1,1,23],"120":[1,1,94],"121":[1,1,68],"122":[2,1,81],"123":[1,1,5],"124":[1,1,38],"125":[1,1,8],"126":[1,1,130],"127":[1,1,68],"128":[1,1,61],"129":[1,1,116],"130":[1,1,46],"131":[1,1,36],"132":[1,1,12],"133":[1,1,22],"134":[1,1,73],"135":[3,1,58],"136":[1,3,166],"137":[1,3,248],"138":[1,3,14],"139":[1,3,27],"140":[1,1,42],"141":[1,1,155],"142":[1,1,110],"143":[1,1,8],"144":[1,1,17],"145":[1,1,47],"146":[1,1,129],"147":[2,1,79],"148":[1,1,57],"149":[1,1,10],"150":[1,1,28],"151":[1,1,42],"152":[1,1,56],"153":[1,1,50],"154":[1,2,35],"155":[1,2,61],"156":[1,1,64],"157":[3,1,20],"158":[1,3,72],"159":[1,1,12],"160":[1,1,19],"161":[2,1,24],"162":[1,2,57],"163":[1,2,12],"164":[1,2,105],"165":[1,2,45],"166":[1,2,9],"167":[1,2,17],"168":[3,1,18],"169":[1,3,55],"170":[1,3,110],"171":[1,3,29],"172":[1,3,88],"173":[1,3,45],"174":[1,3,84],"175":[2,3,55],"176":[2,3,91],"177":[1,3,7],"178":[1,3,39],"179":[1,1,53],"180":[1,1,39],"181":[1,2,36],"182":[1,2,33],"183":[1,2,36],"184":[1,1,3],"185":[1,2,33],"186":[1,2,29],"187":[1,2,20],"188":[1,2,14],"189":[1,1,15],"190":[1,2,54],"191":[1,2,150],"192":[1,2,99],"193":[1,2,32],"194":[1,1,3],"195":[1,2,23],"196":[1,2,42],"197":[1,2,17],"198":[1,2,32],"199":[1,2,16],"200":[1,2,14],"201":[2,1,55],"202":[1,1,21],"203":[1,1,11],"204":[1,1,47],"205":[2,1,29],"206":[1,2,124],"207":[1,2,43],"208":[1,2,123],"209":[1,2,109],"210":[2,2,167],"211":[1,2,85],"212":[2,2,48],"213":[2,2,101],"214":[1,2,10],"215":[1,2,25],"216":[1,1,48],"217":[1,1,69],"218":[1,1,26],"219":[1,1,35],"220":[1,1,39],"221":[1,1,56],"222":[1,1,6],"223":[1,1,31],"224":[1,1,28],"225":[1,1,110],"226":[1,1,5],"227":[1,1,16],"228":[1,1,23],"229":[1,1,17],"230":[1,2,52],"231":[1,2,45],"232":[1,2,96],"233":[1,2,26],"234":[1,1,33],"235":[1,2,113],"236":[1,2,101],"237":[1,2,77],"238":[1,1,5],"239":[1,1,20],"240":[1,1,20],"241":[1,1,70],"242":[2,2,92],"243":[2,2,42],"244":[1,2,41],"245":[1,1,5],"246":[1,2,12],"247":[1,2,82],"248":[1,2,25],"249":[1,1,12],"250":[1,1,22],"251":[2,1,60],"252":[1,2,73],"253":[1,3,64],"254":[1,3,54],"255":[1,2,17],"256":[1,2,36],"257":[1,2,13],"258":[2,2,32],"259":[1,4,30],"260":[1,4,24],"261":[1,2,26],"262":[1,3,93],"263":[1,3,125],"264":[3,3,26],"265":[3,3,20],"266":[3,3,25],"267":[1,2,11],"268":[1,2,27],"269":[1,1,51],"270":[1,1,132],"271":[1,1,79],"272":[1,1,3],"273":[2,2,38],"274":[2,2,19],"275":[2,2,92],"276":[2,2,13],"277":[2,2,12],"278":[2,1,195],"279":[1,1,9],"280":[1,1,42],"281":[1,1,83],"282":[1,1,174],"283":[1,1,14],"284":[1,2,127],"285":[1,2,17],"286":[1,2,83],"287":[1,2,18],"288":[1,1,10],"289":[1,2,84],"290":[1,3,86],"291":[1,3,130],"292":[1,3,74],"293":[1,3,39],"294":[1,3,67],"295":[1,3,147],"296":[1,2,90],"297":[1,2,61],"298":[1,2,130],"299":[1,1,161],"300":[1,1,259],"301":[1,1,165],"302":[1,1,103],"303":[1,1,20],"304":[1,1,21],"305":[1,1,79],"306":[1,1,54],"307":[1,1,115],"308":[1,2,23],"309":[1,2,29],"310":[1,2,44],"311":[1,2,30],"312":[1,1,178],"313":[1,1,10],"314":[1,1,16],"315":[1,1,69],"316":[1,1,125],"317":[1,1,37],"318":[1,1,140],"319":[1,1,62],"320":[1,2,85],"321":[1,2,94],"322":[1,1,13],"323":[1,1,24],"324":[1,1,49],"325":[2,1,166],"326":[1,1,61],"327":[1,1,6],"328":[1,1,17],"329":[1,1,60],"330":[2,1,69],"331":[1,1,70],"332":[1,1,138],"333":[1,1,86],"334":[2,1,148],"335":[1,1,251],"336":[1,1,15],"337":[1,1,46],"338":[1,1,71],"339":[1,1,47],"340":[1,1,153],"341":[1,1,63],"342":[3,1,115],"343":[1,1,7],"344":[1,1,16],"345":[1,1,98],"346":[1,1,28],"347":[1,2,82],"348":[1,2,50],"349":[1,2,51],"350":[1,1,199],"351":[1,1,134],"352":[1,1,19],"353":[1,1,26],"354":[1,1,47],"355":[1,1,52],"356":[2,1,59],"357":[1,1,103],"358":[1,1,17],"359":[1,1,14],"360":[1,1,39],"361":[1,1,56],"362":[1,1,43],"363":[1,1,105],"364":[1,1,50],"365":[1,1,6],"366":[1,1,16],"367":[1,1,92],"368":[2,1,92],"369":[2,1,182],"370":[2,1,134],"371":[1,1,10],"372":[1,1,20],"373":[2,1,43],"374":[1,2,67],"375":[1,2,158],"376":[2,2,124],"377":[1,2,10],"378":[1,2,11],"379":[1,1,58],"380":[1,1,49],"381":[1,1,62],"382":[1,1,141],"383":[1,1,6],"384":[1,1,12],"385":[4,1,48],"386":[2,4,87],"387":[1,4,39],"388":[2,4,155],"389":[2,4,35],"390":[1,6,66],"391":[1,6,104],"392":[1,6,151],"393":[1,4,7],"394":[1,4,18],"395":[1,1,72],"396":[2,1,57],"397":[2,1,82],"398":[2,1,124],"399":[1,3,60],"400":[1,3,34],"401":[1,1,11],"402":[1,1,12],"403":[1,1,42],"404":[1,1,127],"405":[2,1,70],"406":[1,1,99],"407":[1,1,133],"408":[1,1,201],"409":[2,1,207],"410":[1,1,10],"411":[1,1,34],"412":[1,1,12],"413":[1,1,97],"414":[2,1,116],"415":[1,1,8],"416":[1,1,13],"417":[1,1,29],"418":[1,1,101],"419":[1,1,6],"420":[1,1,18],"421":[1,1,50],"422":[1,1,210],"423":[2,1,134],"424":[2,1,132],"425":[2,1,140],"426":[1,1,36],"427":[1,1,7],"428":[1,1,20],"429":[1,1,72],"430":[2,1,32],"431":[2,3,50],"432":[2,3,42],"433":[2,3,73],"434":[1,1,38],"435":[2,2,79],"436":[2,2,121],"437":[2,1,77],"438":[1,1,4],"439":[1,1,21],"440":[1,1,16],"441":[2,1,59],"442":[2,1,105],"443":[1,1,5],"444":[1,1,17],"445":[1,1,110],"446":[2,1,111],"447":[1,1,34],"448":[2,2,45],"449":[1,2,69],"450":[1,2,30],"451":[2,1,56],"452":[1,1,19],"453":[1,1,21],"454":[3,1,83],"455":[1,3,90],"456":[2,3,32],"457":[2,3,96],"458":[1,3,25],"459":[1,2,25],"460":[1,2,18],"461":[1,2,137],"462":[1,3,35],"463":[2,3,28],"464":[1,3,12],"465":[1,3,28],"466":[1,1,19],"467":[1,1,141],"468":[1,1,8],"469":[1,2,17],"470":[1,2,24],"471":[1,2,14],"472":[2,1,211],"473":[2,1,103],"474":[2,1,75],"475":[1,1,77],"476":[1,1,13],"477":[1,1,29],"478":[3,1,13],"479":[1,3,65],"480":[2,3,123],"481":[2,3,70],"482":[2,3,97],"483":[2,3,29],"484":[1,3,10],"485":[1,3,33],"486":[3,1,23],"487":[2,3,132],"488":[2,3,178],"489":[2,3,32],"490":[1,3,11],"491":[1,3,39],"492":[1,1,60],"493":[3,1,22],"494":[2,3,80],"495":[2,3,102],"496":[2,3,32],"497":[1,3,14],"498":[1,3,21],"499":[3,1,12],"500":[1,3,97],"501":[2,3,152],"502":[2,3,170],"503":[2,3,30],"504":[1,3,20],"505":[1,3,41],"506":[3,1,20],"507":[2,3,90],"508":[2,3,109],"509":[1,3,62],"510":[1,3,11],"511":[1,3,28],"512":[1,1,47],"513":[1,1,95],"514":[1,1,22],"515":[1,1,103],"516":[1,1,9],"517":[1,1,15],"518":[1,1,44],"519":[1,1,174],"520":[1,1,31],"521":[1,2,58],"522":[1,2,38],"523":[2,1,78],"524":[1,1,10],"525":[1,1,29],"526":[1,1,35],"527":[1,1,65],"528":[1,1,74],"529":[3,1,21],"530":[1,1,13],"531":[1,1,21],"532":[2,1,42],"533":[2,2,42],"534":[2,2,52],"535":[2,2,48],"536":[1,2,8],"537":[1,2,16],"538":[3,1,64],"539":[1,3,15],"540":[1,3,55],"541":[1,3,48],"542":[1,3,37],"543":[1,3,46],"544":[2,3,78],"545":[1,3,84],"546":[3,3,53],"547":[2,3,57],"548":[1,3,8],"549":[1,3,24],"550":[1,1,65],"551":[3,1,23],"552":[1,3,26],"553":[2,3,44],"554":[1,3,23],"555":[1,3,24],"556":[1,3,23],"557":[1,3,46],"558":[2,3,82],"559":[1,3,88],"560":[3,3,48],"561":[2,3,73],"562":[1,3,11],"563":[1,3,23],"564":[1,1,76],"565":[2,1,93],"566":[2,1,89],"567":[2,1,39],"568":[1,1,102],"569":[2,1,65],"570":[1,1,9],"571":[1,1,20],"572":[3,1,114],"573":[1,3,191],"574":[2,3,179],"575":[1,3,160],"576":[2,3,201],"577":[2,3,121],"578":[1,3,164],"579":[1,3,17],"580":[1,3,19],"581":[1,1,45],"582":[1,1,158],"583":[1,1,81],"584":[1,1,109],"585":[1,1,12],"586":[1,1,18],"587":[1,1,26],"588":[1,1,27],"589":[1,1,45],"590":[1,1,68],"591":[1,1,101],"592":[2,1,95],"593":[1,1,29],"594":[1,1,53],"595":[1,1,99],"596":[1,1,25],"597":[1,1,27],"598":[1,1,42],"599":[1,1,82],"600":[1,1,86],"601":[1,1,57],"602":[1,1,31],"603":[2,1,26],"604":[2,1,57],"605":[1,1,132],"606":[1,1,8],"607":[1,1,24],"608":[1,1,25],"609":[1,1,61],"610":[1,2,102],"611":[1,2,61],"612":[1,2,23],"613":[1,2,109],"614":[1,2,18],"615":[1,1,99],"616":[1,1,124],"617":[1,1,10],"618":[1,2,45],"619":[1,2,72],"620":[1,1,9],"621":[1,1,45],"622":[1,1,54],"623":[1,1,64],"624":[1,1,106],"625":[1,1,37],"626":[1,1,27],"627":[1,1,9],"628":[1,1,16],"629":[1,1,49],"630":[1,1,54],"631":[1,1,92],"632":[1,1,25],"633":[1,1,66],"634":[1,1,150],"635":[1,1,235],"636":[1,1,50],"637":[1,1,8],"638":[1,1,25],"639":[1,1,43],"640":[1,1,54],"641":[1,1,45],"642":[1,1,30],"643":[1,1,79],"644":[1,1,40],"645":[1,1,13],"646":[1,2,57],"647":[1,2,43],"648":[1,2,28],"649":[1,1,10],"650":[1,2,29],"651":[1,2,42],"652":[1,2,22],"653":[1,1,14],"654":[1,1,6],"655":[1,1,43],"656":[1,1,48],"657":[1,1,52],"658":[1,1,72],"659":[1,1,46],"660":[1,1,84],"661":[1,1,15],"662":[1,1,20],"663":[2,1,86],"664":[1,1,20],"665":[1,1,62],"666":[3,1,55],"667":[2,4,89],"668":[2,4,82],"669":[2,4,77],"670":[1,1,13],"671":[1,1,11],"672":[2,1,32],"673":[1,2,40],"674":[3,3,165],"675":[1,3,96],"676":[1,3,68],"677":[1,3,57],"678":[1,2,4],"679":[1,3,54],"680":[1,3,51],"681":[1,3,76],"682":[1,3,49],"683":[1,2,14],"684":[1,2,16],"685":[2,1,53],"686":[2,2,127],"687":[2,2,146],"688":[1,2,132],"689":[1,2,6],"690":[1,2,35],"691":[1,1,59],"692":[1,1,82],"693":[1,1,61],"694":[1,1,30],"695":[1,1,57],"696":[1,1,6],"697":[1,1,11],"698":[2,1,61],"699":[1,2,97],"700":[1,2,15],"701":[1,2,33],"702":[1,3,139],"703":[1,3,47],"704":[1,3,55],"705":[1,2,6],"706":[1,2,19],"707":[1,1,33],"708":[1,1,90],"709":[1,1,84],"710":[1,1,6],"711":[1,1,11],"712":[2,1,60],"713":[1,2,136],"714":[1,2,44],"715":[1,2,83],"716":[1,2,5],"717":[1,2,46],"718":[1,1,116],"719":[1,1,5],"720":[1,2,62],"721":[1,2,105],"722":[1,1,185],"723":[1,1,10],"724":[1,1,36],"725":[1,1,81],"726":[1,1,217],"727":[1,1,97],"728":[1,1,12],"729":[1,1,16],"730":[3,1,10],"731":[1,3,88],"732":[1,3,50],"733":[2,3,78],"734":[1,3,192],"735":[1,3,16],"736":[5,3,150],"737":[5,3,95],"738":[1,3,89],"739":[1,3,24],"740":[1,3,27],"741":[3,1,29],"742":[1,3,82],"743":[1,3,79],"744":[1,3,125],"745":[1,3,10],"746":[1,3,15],"747":[1,1,37],"748":[1,1,109],"749":[1,1,3],"750":[1,2,81],"751":[1,2,88],"752":[1,1,4],"753":[1,1,14],"754":[2,1,92],"755":[1,1,29],"756":[1,1,56],"757":[5,1,199],"758":[1,1,9],"759":[1,1,27],"760":[1,1,51],"761":[1,1,4],"762":[1,2,57],"763":[1,2,63],"764":[1,1,3],"765":[1,2,80],"766":[1,2,27],"767":[1,2,129],"768":[1,1,67],"769":[1,1,3],"770":[1,1,18],"771":[1,1,34],"772":[1,1,72],"773":[1,1,118],"774":[1,1,75],"775":[1,1,97],"776":[1,1,81],"777":[1,1,81],"778":[1,1,8],"779":[1,1,14],"780":[3,1,12],"781":[1,3,32],"782":[1,3,24],"783":[4,3,65],"784":[1,6,58],"785":[3,3,76],"786":[1,5,39],"787":[1,3,8],"788":[1,3,24],"789":[1,1,61],"790":[1,1,125],"791":[1,1,57],"792":[1,1,53],"793":[1,1,20],"794":[1,1,21],"795":[1,1,58],"796":[1,1,90],"797":[1,1,99],"798":[1,1,13],"799":[1,1,20],"800":[1,1,47],"801":[1,1,77],"802":[1,1,86],"803":[1,1,9],"804":[1,2,42],"805":[1,2,47],"806":[1,2,8],"807":[1,1,40],"808":[1,2,29],"809":[1,2,38],"810":[1,2,100],"811":[1,1,122],"812":[1,1,83],"813":[1,1,190],"814":[1,1,33],"815":[1,1,48],"816":[1,1,72],"817":[1,1,73],"818":[1,1,59],"819":[1,1,138],"820":[1,2,103],"821":[1,2,135],"822":[1,1,16],"823":[1,1,21],"824":[1,1,32],"825":[1,1,35],"826":[2,1,101],"827":[1,1,127],"828":[2,1,166],"829":[1,1,16],"830":[1,1,29],"831":[1,1,27],"832":[1,1,126],"833":[1,1,62],"834":[2,1,101],"835":[1,1,85],"836":[1,1,72],"837":[1,1,156],"838":[1,1,15],"839":[1,1,16],"840":[1,1,35],"841":[1,1,102],"842":[4,1,88],"843":[1,1,63],"844":[1,1,60],"845":[1,1,8],"846":[1,1,10],"847":[1,1,49],"848":[1,1,259],"849":[3,1,89],"850":[1,1,25],"851":[2,2,140],"852":[1,2,143],"853":[1,2,121],"854":[1,1,270],"855":[1,1,15],"856":[1,1,40],"857":[1,1,68],"858":[1,1,113],"859":[1,1,12],"860":[1,1,17],"861":[1,1,57],"862":[1,1,121],"863":[2,1,155],"864":[2,1,56],"865":[2,1,68],"866":[2,1,114],"867":[1,1,6],"868":[1,1,20],"869":[1,1,41],"870":[1,1,34],"871":[1,1,32],"872":[1,2,107],"873":[2,2,82],"874":[2,2,138],"875":[1,1,11],"876":[1,1,66],"877":[1,1,48],"878":[1,1,44],"879":[1,2,72],"880":[1,2,52],"881":[2,2,27],"882":[2,1,112],"883":[1,3,200],"884":[1,1,8],"885":[1,1,22],"886":[1,1,66],"887":[7,1,65],"888":[1,7,26],"889":[1,7,63],"890":[2,7,131],"891":[2,7,52],"892":[1,7,60],"893":[3,7,110],"894":[3,7,117],"895":[2,7,43],"896":[5,7,80],"897":[1,7,12],"898":[1,7,27],"899":[5,1,52],"900":[1,5,14],"901":[1,5,64],"902":[2,5,40],"903":[2,5,69],"904":[2,5,56],"905":[2,5,126],"906":[3,5,134],"907":[2,5,41],"908":[3,5,84],"909":[1,5,7],"910":[1,5,30],"911":[1,1,20],"912":[1,1,155],"913":[1,1,54],"914":[1,1,9],"915":[1,1,33],"916":[1,1,31],"917":[1,1,41],"918":[2,1,44],"919":[2,1,65],"920":[2,1,107],"921":[2,1,4],"922":[1,3,24],"923":[1,3,60],"924":[1,3,36],"925":[1,3,36],"926":[2,1,80],"927":[2,1,119],"928":[1,1,11],"929":[1,1,23],"930":[1,1,16],"931":[2,1,39],"932":[1,1,164],"933":[2,1,39],"934":[1,1,7],"935":[1,1,16],"936":[4,1,37],"937":[2,4,53],"938":[3,4,167],"939":[3,4,56],"940":[3,4,34],"941":[1,4,19],"942":[1,4,24],"943":[1,1,22],"944":[1,1,30],"945":[3,1,191],"946":[1,4,72],"947":[2,4,99],"948":[2,4,57],"949":[2,4,55],"950":[1,1,7],"951":[1,1,16],"952":[3,1,26],"953":[1,3,46],"954":[2,3,81],"955":[2,3,24],"956":[2,3,87],"957":[2,3,73],"958":[2,3,46],"959":[1,3,168],"960":[1,3,3],"961":[1,3,65],"962":[2,3,78],"963":[2,3,101],"964":[2,3,113],"965":[1,3,7],"966":[1,3,120],"967":[1,1,47],"968":[1,1,103],"969":[3,1,83],"970":[2,1,72],"971":[1,1,13],"972":[1,1,19],"973":[1,1,30],"974":[1,1,98],"975":[1,1,53],"976":[1,1,59],"977":[1,1,76],"978":[1,1,6],"979":[1,1,27],"980":[1,1,71],"981":[1,1,243],"982":[1,1,33],"983":[1,1,44],"984":[1,1,35],"985":[1,1,8],"986":[1,1,25],"987":[1,1,54],"988":[1,1,10],"989":[1,1,76],"990":[1,1,62],"991":[2,2,47],"992":[1,1,121],"993":[1,1,49],"994":[1,1,72],"995":[1,1,76],"996":[1,2,38],"997":[4,1,59],"998":[2,1,64],"999":[2,1,60],"1000":[1,1,120],"1001":[1,2,18],"1002":[1,1,26],"1003":[1,1,18],"1004":[1,1,50],"1005":[1,1,17],"1006":[1,1,44],"1007":[1,1,38],"1008":[1,1,5],"1009":[1,1,11],"1010":[1,1,13],"1011":[1,1,62],"1012":[1,1,53],"1013":[1,1,36],"1014":[1,1,5],"1015":[1,1,12],"1016":[1,1,31],"1017":[1,1,168],"1018":[1,1,142],"1019":[1,1,47],"1020":[1,1,58],"1021":[1,1,101],"1022":[1,1,46],"1023":[1,1,9],"1024":[1,1,22],"1025":[1,1,93],"1026":[1,1,160],"1027":[1,2,70],"1028":[1,2,84],"1029":[1,1,30],"1030":[1,2,20],"1031":[1,2,15],"1032":[1,2,32],"1033":[1,2,18],"1034":[1,2,38],"1035":[1,2,104],"1036":[1,1,35],"1037":[1,1,7],"1038":[1,1,42],"1039":[5,1,1],"1040":[3,5,36],"1041":[3,7,15],"1042":[1,7,41],"1043":[2,5,13],"1044":[1,7,17],"1045":[1,8,12],"1046":[1,8,16],"1047":[1,8,80],"1048":[4,5,106],"1049":[5,1,13],"1050":[5,5,33],"1051":[6,5,27],"1052":[4,5,45],"1053":[4,5,28],"1054":[2,5,27],"1055":[2,5,10],"1056":[2,5,18],"1057":[1,1,5],"1058":[2,1,141],"1059":[4,1,185],"1060":[3,1,203],"1061":[3,1,299],"1062":[8,1,1],"1063":[3,9,114],"1064":[2,9,65],"1065":[3,9,16],"1066":[3,9,48],"1067":[3,9,105],"1068":[3,9,144],"1069":[3,9,95],"1070":[3,9,50],"1071":[6,1,1],"1072":[3,7,36],"1073":[3,7,17],"1074":[2,7,13],"1075":[3,7,15],"1076":[3,7,40],"1077":[4,7,77],"1078":[1,1,2],"1079":[8,1,1],"1080":[3,9,67],"1081":[3,9,66],"1082":[4,9,37],"1083":[3,9,36],"1084":[3,9,47],"1085":[3,9,111],"1086":[5,9,187],"1087":[5,1,1],"1088":[3,6,251],"1089":[3,6,371],"1090":[3,6,312],"1091":[3,6,186],"1092":[5,6,307],"1093":[3,6,251],"1094":[3,6,71],"1095":[1,1,2],"1096":[7,1,1],"1097":[3,8,58],"1098":[3,8,164],"1099":[3,8,147],"1100":[3,8,73],"1101":[3,8,61],"1102":[3,8,55],"1103":[3,8,37],"1104":[1,1,2],"1105":[5,1,1],"1106":[3,6,69],"1107":[3,6,99],"1108":[3,6,62],"1109":[3,6,198],"1110":[3,6,172],"1111":[2,6,256],"1112":[4,6,171],"1113":[4,1,1],"1114":[3,5,63],"1115":[3,5,90],"1116":[3,5,58],"1117":[3,5,111],"1118":[1,1,2],"1119":[6,1,1],"1120":[3,7,100],"1121":[3,7,157],"1122":[3,7,89],"1123":[4,7,17],"1124":[3,7,72],"1125":[3,7,28],"1126":[3,7,30],"1127":[3,7,118],"1128":[1,1,10],"1129":[3,1,153],"1130":[3,1,63],"1131":[3,1,52],"1132":[3,1,78],"1133":[4,1,53],"1134":[3,1,44],"1135":[3,1,66],"1136":[7,1,1],"1137":[3,8,68],"1138":[3,8,164],"1139":[3,8,80],"1140":[3,8,67],"1141":[3,8,209],"1142":[1,1,8],"1143":[3,1,352],"1144":[3,1,244],"1145":[5,1,364],"1146":[3,1,100],"1147":[3,1,90],"1148":[3,1,200],"1149":[1,1,6],"1150":[4,1,97],"1151":[4,1,73],"1152":[3,1,44],"1153":[3,1,36],"1154":[3,1,191],"1155":[5,1,1],"1156":[4,6,93],"1157":[4,6,25],"1158":[3,6,72],"1159":[3,6,58],"1160":[3,6,71],"1161":[3,6,62],"1162":[3,6,42],"1163":[1,1,9],"1164":[3,1,22],"1165":[3,1,58],"1166":[3,1,44],"1167":[3,1,70],"1168":[3,1,136],"1169":[3,1,36],"1170":[8,1,1],"1171":[3,9,29],"1172":[3,9,45],"1173":[3,9,38],"1174":[4,9,46],"1175":[4,1,1],"1176":[3,5,123],"1177":[1,1,7],"1178":[3,1,99],"1179":[3,1,46],"1180":[3,1,69],"1181":[3,1,48],"1182":[3,1,54],"1183":[3,1,74],"1184":[5,1,120],"1185":[5,1,82],"1186":[5,1,1],"1187":[3,6,113],"1188":[3,6,78],"1189":[3,6,72],"1190":[3,6,37],"1191":[4,6,94],"1192":[4,6,34],"1193":[3,1,218],"1194":[3,1,15],"1195":[2,3,21],"1196":[6,3,25],"1197":[3,3,16],"1198":[4,3,25],"1199":[4,3,21],"1200":[7,3,13],"1201":[7,3,13],"1202":[2,3,18],"1203":[5,3,18],"1204":[2,3,14],"1205":[7,3,24],"1206":[4,3,4],"1207":[1,7,18],"1208":[2,3,18],"1209":[4,3,16],"1210":[4,3,23],"1211":[2,3,21],"1212":[1,1,1],"1213":[2,1,1],"1214":[2,3,13],"1215":[4,5,17],"1216":[2,3,44],"1217":[2,1,7],"1218":[2,3,21],"1219":[4,3,12],"1220":[2,3,11],"1221":[2,3,12],"1222":[2,1,3],"1223":[5,3,20],"1224":[5,3,1],"1225":[6,8,10],"1226":[4,8,11],"1227":[2,3,10],"1228":[2,1,3],"1229":[2,3,7],"1230":[2,3,20],"1231":[2,1,1],"1232":[2,3,17],"1233":[2,3,9],"1234":[2,1,5],"1235":[1,3,23],"1236":[2,1,19],"1237":[2,1,7],"1238":[2,2,1],"1239":[3,4,18],"1240":[4,4,26],"1241":[3,2,1],"1242":[1,5,9],"1243":[1,5,11],"1244":[4,2,25],"1245":[2,2,1],"1246":[4,4,13],"1247":[2,4,9],"1248":[2,2,1],"1249":[1,4,7],"1250":[1,4,9],"1251":[5,2,1],"1252":[2,7,28],"1253":[4,2,1],"1254":[2,6,12],"1255":[2,6,14],"1256":[2,2,1],"1257":[1,4,10],"1258":[3,4,8],"1259":[6,2,13],"1260":[2,2,1],"1261":[2,4,9],"1262":[4,4,8],"1263":[2,2,15],"1264":[2,2,10],"1265":[5,1,1],"1266":[5,5,1],"1267":[1,9,3],"1268":[1,9,3],"1269":[1,9,12],"1270":[3,5,1],"1271":[1,7,3],"1272":[1,7,7],"1273":[1,7,18],"1274":[2,5,1],"1275":[1,6,3],"1276":[1,6,2],"1277":[1,6,23],"1278":[2,5,1],"1279":[1,6,3],"1280":[1,6,4],"1281":[1,6,13],"1282":[2,5,1],"1283":[1,6,2],"1284":[1,6,12],"1285":[1,6,15],"1286":[2,5,1],"1287":[1,6,4],"1288":[1,6,4],"1289":[1,6,10],"1290":[2,5,1],"1291":[1,6,3],"1292":[1,6,4],"1293":[1,6,12],"1294":[1,5,28],"1295":[5,1,11],"1296":[5,5,33],"1297":[5,5,54],"1298":[5,5,1],"1299":[2,9,11],"1300":[2,9,8],"1301":[2,9,8],"1302":[4,5,19],"1303":[4,5,22],"1304":[5,5,25],"1305":[4,5,15],"1306":[2,5,20],"1307":[4,1,1],"1308":[2,4,1],"1309":[4,6,28],"1310":[4,6,16],"1311":[7,6,18],"1312":[4,6,13],"1313":[4,6,22],"1314":[2,6,17],"1315":[8,4,134],"1316":[2,1,1],"1317":[3,2,1],"1318":[4,4,24],"1319":[4,4,32],"1320":[4,4,14],"1321":[5,4,17],"1322":[5,4,11],"1323":[4,4,12],"1324":[5,4,17],"1325":[4,4,20],"1326":[3,2,1],"1327":[3,4,12],"1328":[2,4,19],"1329":[3,4,19],"1330":[3,4,18],"1331":[3,2,1],"1332":[3,4,12],"1333":[3,4,13],"1334":[4,4,12],"1335":[5,4,15],"1336":[3,2,30],"1337":[2,2,19],"1338":[3,1,1],"1339":[4,3,23],"1340":[3,3,34],"1341":[3,3,1],"1342":[1,5,13],"1343":[1,5,19],"1344":[1,5,12],"1345":[1,5,8],"1346":[3,3,30],"1347":[5,3,21],"1348":[5,3,16],"1349":[6,3,19],"1350":[6,3,19],"1351":[7,3,26],"1352":[1,1,14],"1353":[1,1,17],"1354":[1,1,18],"1355":[1,1,25],"1356":[1,1,11],"1357":[1,1,18],"1358":[2,1,1],"1359":[3,2,30],"1360":[2,2,3],"1361":[2,4,9],"1362":[2,4,14],"1363":[2,4,13],"1364":[3,2,49],"1365":[2,4,21],"1366":[2,2,1],"1367":[2,4,15],"1368":[2,4,19],"1369":[2,4,16],"1370":[6,4,20],"1371":[2,2,67],"1372":[4,2,14],"1373":[2,1,1],"1374":[4,2,22],"1375":[3,2,7],"1376":[6,4,22],"1377":[5,4,20],"1378":[5,4,17],"1379":[3,2,1],"1380":[3,4,6],"1381":[3,4,23],"1382":[2,4,7],"1383":[3,4,5],"1384":[3,4,15],"1385":[5,4,9],"1386":[3,4,11],"1387":[3,4,3],"1388":[4,2,7],"1389":[4,5,21],"1390":[4,5,28],"1391":[4,5,25],"1392":[3,2,44],"1393":[3,2,24],"1394":[5,2,23],"1395":[6,2,14],"1396":[2,1,1],"1397":[2,2,7],"1398":[1,4,46],"1399":[1,4,22],"1400":[2,2,4],"1401":[1,4,35],"1402":[1,4,26],"1403":[2,2,5],"1404":[1,4,42],"1405":[1,4,30],"1406":[2,2,1],"1407":[4,4,27],"1408":[4,4,19],"1409":[1,4,16],"1410":[1,4,24],"1411":[2,2,1],"1412":[4,4,30],"1413":[3,4,33],"1414":[1,4,21],"1415":[2,2,3],"1416":[1,4,47],"1417":[1,4,38],"1418":[2,2,5],"1419":[1,4,25],"1420":[1,4,19],"1421":[1,4,20],"1422":[1,4,36],"1423":[1,4,15],"1424":[2,2,3],"1425":[1,4,46],"1426":[2,4,33],"1427":[1,4,24],"1428":[1,4,27],"1429":[2,2,3],"1430":[1,4,28],"1431":[1,4,49],"1432":[1,4,57],"1433":[1,4,54],"1434":[1,4,37],"1435":[1,4,33],"1436":[1,2,24],"1437":[2,1,24],"1438":[3,2,5],"1439":[4,2,4],"1440":[4,2,2],"1441":[4,2,19],"1442":[2,1,1],"1443":[7,2,50],"1444":[6,2,126],"1445":[4,2,46],"1446":[2,1,1],"1447":[6,2,6],"1448":[3,7,14],"1449":[3,7,7],"1450":[5,2,1],"1451":[2,6,76],"1452":[2,6,14],"1453":[5,6,11],"1454":[2,6,84],"1455":[5,2,74],"1456":[6,2,89],"1457":[6,2,81],"1458":[6,2,23],"1459":[6,2,61],"1460":[4,2,67],"1461":[4,2,13],"1462":[2,5,57],"1463":[2,5,86],"1464":[2,5,74],"1465":[2,5,99],"1466":[2,5,72],"1467":[4,2,93],"1468":[6,2,80],"1469":[4,2,79],"1470":[4,2,85],"1471":[4,2,106],"1472":[2,1,1],"1473":[4,2,1],"1474":[4,2,64],"1475":[4,2,11],"1476":[3,2,24],"1477":[4,2,18],"1478":[4,2,34],"1479":[4,2,59],"1480":[4,2,1],"1481":[1,5,39],"1482":[1,5,42],"1483":[4,2,33],"1484":[4,2,15],"1485":[4,2,18],"1486":[4,2,9],"1487":[2,1,1],"1488":[4,2,1],"1489":[6,2,26],"1490":[4,2,82],"1491":[5,2,46],"1492":[3,2,37],"1493":[4,2,44],"1494":[4,2,21],"1495":[4,2,52],"1496":[2,1,12],"1497":[4,2,61],"1498":[4,2,44],"1499":[4,2,64],"1500":[5,2,71],"1501":[4,2,82],"1502":[4,2,14],"1503":[5,2,75],"1504":[4,2,2],"1505":[4,2,1],"1506":[2,5,29],"1507":[2,5,39],"1508":[2,5,60],"1509":[3,1,1],"1510":[6,3,1],"1511":[1,8,13],"1512":[1,8,13],"1513":[1,8,13],"1514":[6,3,1],"1515":[1,8,19],"1516":[1,8,18],"1517":[6,3,1],"1518":[1,8,52],"1519":[1,8,29],"1520":[4,3,36],"1521":[2,1,1],"1522":[4,2,28],"1523":[4,2,34],"1524":[4,2,8],"1525":[4,2,29],"1526":[4,1,25],"1527":[2,4,40],"1528":[3,4,31],"1529":[2,4,21],"1530":[2,4,43],"1531":[2,4,21],"1532":[3,1,6],"1533":[2,3,25],"1534":[2,3,1],"1535":[2,5,5],"1536":[2,5,5],"1537":[2,5,3],"1538":[2,5,7],"1539":[1,3,18],"1540":[2,3,12],"1541":[1,3,12],"1542":[3,1,16],"1543":[2,3,41],"1544":[2,3,26],"1545":[2,3,16],"1546":[2,3,30],"1547":[2,3,21],"1548":[2,3,20],"1549":[2,3,13],"1550":[2,3,3]},"averageFieldLength":[1.8278529980657645,2.4029658284977438,51.996131528046405],"storedFields":{"0":{"title":"Runtime API Examples","titles":[]},"1":{"title":"Results","titles":["Runtime API Examples"]},"2":{"title":"Theme Data","titles":["Runtime API Examples","Results"]},"3":{"title":"Page Data","titles":["Runtime API Examples","Results"]},"4":{"title":"Page Frontmatter","titles":["Runtime API Examples","Results"]},"5":{"title":"More","titles":["Runtime API Examples"]},"6":{"title":"Markdown Extension Examples","titles":[]},"7":{"title":"Syntax Highlighting","titles":["Markdown Extension Examples"]},"8":{"title":"Custom Containers","titles":["Markdown Extension Examples"]},"9":{"title":"More","titles":["Markdown Extension Examples"]},"10":{"title":"MyPress","titles":[]},"11":{"title":"功能","titles":["MyPress"]},"12":{"title":"技术栈","titles":["MyPress"]},"13":{"title":"安装","titles":["MyPress"]},"14":{"title":"使用","titles":["MyPress"]},"15":{"title":"开发模式","titles":["MyPress","使用"]},"16":{"title":"构建","titles":["MyPress","使用"]},"17":{"title":"预览","titles":["MyPress","使用"]},"18":{"title":"许可证","titles":["MyPress"]},"19":{"title":"Adadelta","titles":[]},"20":{"title":"Adadelta算法","titles":["Adadelta"]},"21":{"title":"代码实现","titles":["Adadelta"]},"22":{"title":"小结","titles":["Adadelta"]},"23":{"title":"练习","titles":["Adadelta"]},"24":{"title":"AdaGrad算法","titles":[]},"25":{"title":"稀疏特征和学习率","titles":["AdaGrad算法"]},"26":{"title":"预处理","titles":["AdaGrad算法"]},"27":{"title":"算法","titles":["AdaGrad算法"]},"28":{"title":"从零开始实现","titles":["AdaGrad算法"]},"29":{"title":"简洁实现","titles":["AdaGrad算法"]},"30":{"title":"小结","titles":["AdaGrad算法"]},"31":{"title":"练习","titles":["AdaGrad算法"]},"32":{"title":"Adam算法","titles":[]},"33":{"title":"算法","titles":["Adam算法"]},"34":{"title":"实现","titles":["Adam算法"]},"35":{"title":"Yogi","titles":["Adam算法"]},"36":{"title":"小结","titles":["Adam算法"]},"37":{"title":"练习","titles":["Adam算法"]},"38":{"title":"凸性","titles":[]},"39":{"title":"定义","titles":["凸性"]},"40":{"title":"凸集","titles":["凸性","定义"]},"41":{"title":"凸函数","titles":["凸性","定义"]},"42":{"title":"詹森不等式","titles":["凸性","定义"]},"43":{"title":"性质","titles":["凸性"]},"44":{"title":"局部极小值是全局极小值","titles":["凸性","性质"]},"45":{"title":"凸函数的下水平集是凸的","titles":["凸性","性质"]},"46":{"title":"凸性和二阶导数","titles":["凸性","性质"]},"47":{"title":"约束","titles":["凸性"]},"48":{"title":"拉格朗日函数","titles":["凸性","约束"]},"49":{"title":"惩罚","titles":["凸性","约束"]},"50":{"title":"投影","titles":["凸性","约束"]},"51":{"title":"小结","titles":["凸性"]},"52":{"title":"练习","titles":["凸性"]},"53":{"title":"梯度下降","titles":[]},"54":{"title":"一维梯度下降","titles":["梯度下降"]},"55":{"title":"学习率","titles":["梯度下降","一维梯度下降"]},"56":{"title":"局部最小值","titles":["梯度下降","一维梯度下降"]},"57":{"title":"多元梯度下降","titles":["梯度下降"]},"58":{"title":"自适应方法","titles":["梯度下降"]},"59":{"title":"牛顿法","titles":["梯度下降","自适应方法"]},"60":{"title":"收敛性分析","titles":["梯度下降","自适应方法"]},"61":{"title":"预处理","titles":["梯度下降","自适应方法"]},"62":{"title":"梯度下降和线搜索","titles":["梯度下降","自适应方法"]},"63":{"title":"小结","titles":["梯度下降"]},"64":{"title":"练习","titles":["梯度下降"]},"65":{"title":"优化算法","titles":[]},"66":{"title":"学习率调度器","titles":[]},"67":{"title":"一个简单的问题","titles":["学习率调度器"]},"68":{"title":"学习率调度器","titles":["学习率调度器"]},"69":{"title":"策略","titles":["学习率调度器"]},"70":{"title":"单因子调度器","titles":["学习率调度器","策略"]},"71":{"title":"多因子调度器","titles":["学习率调度器","策略"]},"72":{"title":"余弦调度器","titles":["学习率调度器","策略"]},"73":{"title":"预热","titles":["学习率调度器","策略"]},"74":{"title":"小结","titles":["学习率调度器"]},"75":{"title":"练习","titles":["学习率调度器"]},"76":{"title":"小批量随机梯度下降","titles":[]},"77":{"title":"向量化和缓存","titles":["小批量随机梯度下降"]},"78":{"title":"小批量","titles":["小批量随机梯度下降"]},"79":{"title":"读取数据集","titles":["小批量随机梯度下降"]},"80":{"title":"从零开始实现","titles":["小批量随机梯度下降"]},"81":{"title":"简洁实现","titles":["小批量随机梯度下降"]},"82":{"title":"小结","titles":["小批量随机梯度下降"]},"83":{"title":"练习","titles":["小批量随机梯度下降"]},"84":{"title":"动量法","titles":[]},"85":{"title":"基础","titles":["动量法"]},"86":{"title":"泄漏平均值","titles":["动量法","基础"]},"87":{"title":"条件不佳的问题","titles":["动量法","基础"]},"88":{"title":"动量法","titles":["动量法","基础"]},"89":{"title":"有效样本权重","titles":["动量法","基础"]},"90":{"title":"实际实验","titles":["动量法"]},"91":{"title":"从零开始实现","titles":["动量法","实际实验"]},"92":{"title":"简洁实现","titles":["动量法","实际实验"]},"93":{"title":"理论分析","titles":["动量法"]},"94":{"title":"二次凸函数","titles":["动量法","理论分析"]},"95":{"title":"标量函数","titles":["动量法","理论分析"]},"96":{"title":"小结","titles":["动量法"]},"97":{"title":"练习","titles":["动量法"]},"98":{"title":"优化和深度学习","titles":[]},"99":{"title":"优化的目标","titles":["优化和深度学习"]},"100":{"title":"深度学习中的优化挑战","titles":["优化和深度学习"]},"101":{"title":"局部最小值","titles":["优化和深度学习","深度学习中的优化挑战"]},"102":{"title":"鞍点","titles":["优化和深度学习","深度学习中的优化挑战"]},"103":{"title":"梯度消失","titles":["优化和深度学习","深度学习中的优化挑战"]},"104":{"title":"小结","titles":["优化和深度学习"]},"105":{"title":"练习","titles":["优化和深度学习"]},"106":{"title":"RMSProp算法","titles":[]},"107":{"title":"算法","titles":["RMSProp算法"]},"108":{"title":"从零开始实现","titles":["RMSProp算法"]},"109":{"title":"简洁实现","titles":["RMSProp算法"]},"110":{"title":"小结","titles":["RMSProp算法"]},"111":{"title":"练习","titles":["RMSProp算法"]},"112":{"title":"随机梯度下降","titles":[]},"113":{"title":"随机梯度更新","titles":["随机梯度下降"]},"114":{"title":"动态学习率","titles":["随机梯度下降"]},"115":{"title":"凸目标的收敛性分析","titles":["随机梯度下降"]},"116":{"title":"随机梯度和有限样本","titles":["随机梯度下降"]},"117":{"title":"小结","titles":["随机梯度下降"]},"118":{"title":"练习","titles":["随机梯度下降"]},"119":{"title":"多输入多输出通道","titles":[]},"120":{"title":"多输入通道","titles":["多输入多输出通道"]},"121":{"title":"多输出通道","titles":["多输入多输出通道"]},"122":{"title":"1×1 卷积层","titles":["多输入多输出通道"]},"123":{"title":"小结","titles":["多输入多输出通道"]},"124":{"title":"练习","titles":["多输入多输出通道"]},"125":{"title":"图像卷积","titles":[]},"126":{"title":"互相关运算","titles":["图像卷积"]},"127":{"title":"卷积层","titles":["图像卷积"]},"128":{"title":"图像中目标的边缘检测","titles":["图像卷积"]},"129":{"title":"学习卷积核","titles":["图像卷积"]},"130":{"title":"互相关和卷积","titles":["图像卷积"]},"131":{"title":"特征映射和感受野","titles":["图像卷积"]},"132":{"title":"小结","titles":["图像卷积"]},"133":{"title":"练习","titles":["图像卷积"]},"134":{"title":"卷积神经网络","titles":[]},"135":{"title":"卷积神经网络（LeNet）","titles":[]},"136":{"title":"LeNet","titles":["卷积神经网络（LeNet）"]},"137":{"title":"模型训练","titles":["卷积神经网络（LeNet）"]},"138":{"title":"小结","titles":["卷积神经网络（LeNet）"]},"139":{"title":"练习","titles":["卷积神经网络（LeNet）"]},"140":{"title":"填充和步幅","titles":[]},"141":{"title":"填充","titles":["填充和步幅"]},"142":{"title":"步幅","titles":["填充和步幅"]},"143":{"title":"小结","titles":["填充和步幅"]},"144":{"title":"练习","titles":["填充和步幅"]},"145":{"title":"汇聚层","titles":[]},"146":{"title":"最大汇聚层和平均汇聚层","titles":["汇聚层"]},"147":{"title":"[填充和步幅]","titles":["汇聚层"]},"148":{"title":"多个通道","titles":["汇聚层"]},"149":{"title":"小结","titles":["汇聚层"]},"150":{"title":"练习","titles":["汇聚层"]},"151":{"title":"从全连接层到卷积","titles":[]},"152":{"title":"不变性","titles":["从全连接层到卷积"]},"153":{"title":"多层感知机的限制","titles":["从全连接层到卷积"]},"154":{"title":"平移不变性","titles":["从全连接层到卷积","多层感知机的限制"]},"155":{"title":"局部性","titles":["从全连接层到卷积","多层感知机的限制"]},"156":{"title":"卷积","titles":["从全连接层到卷积"]},"157":{"title":"“沃尔多在哪里”回顾","titles":["从全连接层到卷积"]},"158":{"title":"通道","titles":["从全连接层到卷积","“沃尔多在哪里”回顾"]},"159":{"title":"小结","titles":["从全连接层到卷积"]},"160":{"title":"练习","titles":["从全连接层到卷积"]},"161":{"title":"前向传播、反向传播和计算图","titles":[]},"162":{"title":"前向传播","titles":["前向传播、反向传播和计算图"]},"163":{"title":"前向传播计算图","titles":["前向传播、反向传播和计算图"]},"164":{"title":"反向传播","titles":["前向传播、反向传播和计算图"]},"165":{"title":"训练神经网络","titles":["前向传播、反向传播和计算图"]},"166":{"title":"小结","titles":["前向传播、反向传播和计算图"]},"167":{"title":"练习","titles":["前向传播、反向传播和计算图"]},"168":{"title":"暂退法（Dropout）","titles":[]},"169":{"title":"重新审视过拟合","titles":["暂退法（Dropout）"]},"170":{"title":"扰动的稳健性","titles":["暂退法（Dropout）"]},"171":{"title":"实践中的暂退法","titles":["暂退法（Dropout）"]},"172":{"title":"从零开始实现","titles":["暂退法（Dropout）"]},"173":{"title":"定义模型参数","titles":["暂退法（Dropout）","从零开始实现"]},"174":{"title":"定义模型","titles":["暂退法（Dropout）","从零开始实现"]},"175":{"title":"[训练和测试]","titles":["暂退法（Dropout）","从零开始实现"]},"176":{"title":"[简洁实现]","titles":["暂退法（Dropout）"]},"177":{"title":"小结","titles":["暂退法（Dropout）"]},"178":{"title":"练习","titles":["暂退法（Dropout）"]},"179":{"title":"环境和分布偏移","titles":[]},"180":{"title":"分布偏移的类型","titles":["环境和分布偏移"]},"181":{"title":"协变量偏移","titles":["环境和分布偏移","分布偏移的类型"]},"182":{"title":"标签偏移","titles":["环境和分布偏移","分布偏移的类型"]},"183":{"title":"概念偏移","titles":["环境和分布偏移","分布偏移的类型"]},"184":{"title":"分布偏移示例","titles":["环境和分布偏移"]},"185":{"title":"医学诊断","titles":["环境和分布偏移","分布偏移示例"]},"186":{"title":"自动驾驶汽车","titles":["环境和分布偏移","分布偏移示例"]},"187":{"title":"非平稳分布","titles":["环境和分布偏移","分布偏移示例"]},"188":{"title":"更多轶事","titles":["环境和分布偏移","分布偏移示例"]},"189":{"title":"分布偏移纠正","titles":["环境和分布偏移"]},"190":{"title":"经验风险与实际风险","titles":["环境和分布偏移","分布偏移纠正"]},"191":{"title":"协变量偏移纠正","titles":["环境和分布偏移","分布偏移纠正"]},"192":{"title":"标签偏移纠正","titles":["环境和分布偏移","分布偏移纠正"]},"193":{"title":"概念偏移纠正","titles":["环境和分布偏移","分布偏移纠正"]},"194":{"title":"学习问题的分类法","titles":["环境和分布偏移"]},"195":{"title":"批量学习","titles":["环境和分布偏移","学习问题的分类法"]},"196":{"title":"在线学习","titles":["环境和分布偏移","学习问题的分类法"]},"197":{"title":"老虎机","titles":["环境和分布偏移","学习问题的分类法"]},"198":{"title":"控制","titles":["环境和分布偏移","学习问题的分类法"]},"199":{"title":"强化学习","titles":["环境和分布偏移","学习问题的分类法"]},"200":{"title":"考虑到环境","titles":["环境和分布偏移","学习问题的分类法"]},"201":{"title":"机器学习中的公平、责任和透明度","titles":["环境和分布偏移"]},"202":{"title":"小结","titles":["环境和分布偏移"]},"203":{"title":"练习","titles":["环境和分布偏移"]},"204":{"title":"多层感知机","titles":[]},"205":{"title":"实战Kaggle比赛：预测房价","titles":[]},"206":{"title":"下载和缓存数据集","titles":["实战Kaggle比赛：预测房价"]},"207":{"title":"Kaggle","titles":["实战Kaggle比赛：预测房价"]},"208":{"title":"访问和读取数据集","titles":["实战Kaggle比赛：预测房价"]},"209":{"title":"数据预处理","titles":["实战Kaggle比赛：预测房价"]},"210":{"title":"[训练]","titles":["实战Kaggle比赛：预测房价"]},"211":{"title":"K折交叉验证","titles":["实战Kaggle比赛：预测房价"]},"212":{"title":"[模型选择]","titles":["实战Kaggle比赛：预测房价"]},"213":{"title":"[提交Kaggle预测]","titles":["实战Kaggle比赛：预测房价"]},"214":{"title":"小结","titles":["实战Kaggle比赛：预测房价"]},"215":{"title":"练习","titles":["实战Kaggle比赛：预测房价"]},"216":{"title":"多层感知机的从零开始实现","titles":[]},"217":{"title":"初始化模型参数","titles":["多层感知机的从零开始实现"]},"218":{"title":"激活函数","titles":["多层感知机的从零开始实现"]},"219":{"title":"模型","titles":["多层感知机的从零开始实现"]},"220":{"title":"损失函数","titles":["多层感知机的从零开始实现"]},"221":{"title":"训练","titles":["多层感知机的从零开始实现"]},"222":{"title":"小结","titles":["多层感知机的从零开始实现"]},"223":{"title":"练习","titles":["多层感知机的从零开始实现"]},"224":{"title":"多层感知机的简洁实现","titles":[]},"225":{"title":"模型","titles":["多层感知机的简洁实现"]},"226":{"title":"小结","titles":["多层感知机的简洁实现"]},"227":{"title":"练习","titles":["多层感知机的简洁实现"]},"228":{"title":"多层感知机","titles":[]},"229":{"title":"隐藏层","titles":["多层感知机"]},"230":{"title":"线性模型可能会出错","titles":["多层感知机","隐藏层"]},"231":{"title":"在网络中加入隐藏层","titles":["多层感知机","隐藏层"]},"232":{"title":"从线性到非线性","titles":["多层感知机","隐藏层"]},"233":{"title":"通用近似定理","titles":["多层感知机","隐藏层"]},"234":{"title":"激活函数","titles":["多层感知机"]},"235":{"title":"ReLU函数","titles":["多层感知机","激活函数"]},"236":{"title":"sigmoid函数","titles":["多层感知机","激活函数"]},"237":{"title":"tanh函数","titles":["多层感知机","激活函数"]},"238":{"title":"小结","titles":["多层感知机"]},"239":{"title":"练习","titles":["多层感知机"]},"240":{"title":"数值稳定性和模型初始化","titles":[]},"241":{"title":"梯度消失和梯度爆炸","titles":["数值稳定性和模型初始化"]},"242":{"title":"(梯度消失)","titles":["数值稳定性和模型初始化","梯度消失和梯度爆炸"]},"243":{"title":"[梯度爆炸]","titles":["数值稳定性和模型初始化","梯度消失和梯度爆炸"]},"244":{"title":"打破对称性","titles":["数值稳定性和模型初始化","梯度消失和梯度爆炸"]},"245":{"title":"参数初始化","titles":["数值稳定性和模型初始化"]},"246":{"title":"默认初始化","titles":["数值稳定性和模型初始化","参数初始化"]},"247":{"title":"Xavier初始化","titles":["数值稳定性和模型初始化","参数初始化"]},"248":{"title":"额外阅读","titles":["数值稳定性和模型初始化","参数初始化"]},"249":{"title":"小结","titles":["数值稳定性和模型初始化"]},"250":{"title":"练习","titles":["数值稳定性和模型初始化"]},"251":{"title":"模型选择、欠拟合和过拟合","titles":[]},"252":{"title":"训练误差和泛化误差","titles":["模型选择、欠拟合和过拟合"]},"253":{"title":"统计学习理论","titles":["模型选择、欠拟合和过拟合","训练误差和泛化误差"]},"254":{"title":"模型复杂性","titles":["模型选择、欠拟合和过拟合","训练误差和泛化误差"]},"255":{"title":"模型选择","titles":["模型选择、欠拟合和过拟合"]},"256":{"title":"验证集","titles":["模型选择、欠拟合和过拟合","模型选择"]},"257":{"title":"K折交叉验证","titles":["模型选择、欠拟合和过拟合","模型选择"]},"258":{"title":"欠拟合还是过拟合？","titles":["模型选择、欠拟合和过拟合"]},"259":{"title":"模型复杂性","titles":["模型选择、欠拟合和过拟合","欠拟合还是过拟合？"]},"260":{"title":"数据集大小","titles":["模型选择、欠拟合和过拟合","欠拟合还是过拟合？"]},"261":{"title":"多项式回归","titles":["模型选择、欠拟合和过拟合"]},"262":{"title":"生成数据集","titles":["模型选择、欠拟合和过拟合","多项式回归"]},"263":{"title":"对模型进行训练和测试","titles":["模型选择、欠拟合和过拟合","多项式回归"]},"264":{"title":"[三阶多项式函数拟合(正常)]","titles":["模型选择、欠拟合和过拟合","多项式回归"]},"265":{"title":"[线性函数拟合(欠拟合)]","titles":["模型选择、欠拟合和过拟合","多项式回归"]},"266":{"title":"[高阶多项式函数拟合(过拟合)]","titles":["模型选择、欠拟合和过拟合","多项式回归"]},"267":{"title":"小结","titles":["模型选择、欠拟合和过拟合"]},"268":{"title":"练习","titles":["模型选择、欠拟合和过拟合"]},"269":{"title":"权重衰减","titles":[]},"270":{"title":"范数与权重衰减","titles":["权重衰减"]},"271":{"title":"高维线性回归","titles":["权重衰减"]},"272":{"title":"从零开始实现","titles":["权重衰减"]},"273":{"title":"[初始化模型参数]","titles":["权重衰减","从零开始实现"]},"274":{"title":"(定义L2范数惩罚)","titles":["权重衰减","从零开始实现"]},"275":{"title":"[定义训练代码实现]","titles":["权重衰减","从零开始实现"]},"276":{"title":"[忽略正则化直接训练]","titles":["权重衰减","从零开始实现"]},"277":{"title":"[使用权重衰减]","titles":["权重衰减","从零开始实现"]},"278":{"title":"[简洁实现]","titles":["权重衰减"]},"279":{"title":"小结","titles":["权重衰减"]},"280":{"title":"练习","titles":["权重衰减"]},"281":{"title":"引言","titles":[]},"282":{"title":"日常生活中的机器学习","titles":["引言"]},"283":{"title":"机器学习中的关键组件","titles":["引言"]},"284":{"title":"数据","titles":["引言","机器学习中的关键组件"]},"285":{"title":"模型","titles":["引言","机器学习中的关键组件"]},"286":{"title":"目标函数","titles":["引言","机器学习中的关键组件"]},"287":{"title":"优化算法","titles":["引言","机器学习中的关键组件"]},"288":{"title":"各种机器学习问题","titles":["引言"]},"289":{"title":"监督学习","titles":["引言","各种机器学习问题"]},"290":{"title":"回归","titles":["引言","各种机器学习问题","监督学习"]},"291":{"title":"分类","titles":["引言","各种机器学习问题","监督学习"]},"292":{"title":"标记问题","titles":["引言","各种机器学习问题","监督学习"]},"293":{"title":"搜索","titles":["引言","各种机器学习问题","监督学习"]},"294":{"title":"推荐系统","titles":["引言","各种机器学习问题","监督学习"]},"295":{"title":"序列学习","titles":["引言","各种机器学习问题","监督学习"]},"296":{"title":"无监督学习","titles":["引言","各种机器学习问题"]},"297":{"title":"与环境互动","titles":["引言","各种机器学习问题"]},"298":{"title":"强化学习","titles":["引言","各种机器学习问题"]},"299":{"title":"起源","titles":["引言"]},"300":{"title":"深度学习的发展","titles":["引言"]},"301":{"title":"深度学习的成功案例","titles":["引言"]},"302":{"title":"特点","titles":["引言"]},"303":{"title":"小结","titles":["引言"]},"304":{"title":"练习","titles":["引言"]},"305":{"title":"循环神经网络","titles":[]},"306":{"title":"通过时间反向传播","titles":[]},"307":{"title":"循环神经网络的梯度分析","titles":["通过时间反向传播"]},"308":{"title":"完全计算","titles":["通过时间反向传播","循环神经网络的梯度分析"]},"309":{"title":"截断时间步","titles":["通过时间反向传播","循环神经网络的梯度分析"]},"310":{"title":"随机截断","titles":["通过时间反向传播","循环神经网络的梯度分析"]},"311":{"title":"比较策略","titles":["通过时间反向传播","循环神经网络的梯度分析"]},"312":{"title":"通过时间反向传播的细节","titles":["通过时间反向传播"]},"313":{"title":"小结","titles":["通过时间反向传播"]},"314":{"title":"练习","titles":["通过时间反向传播"]},"315":{"title":"语言模型和数据集","titles":[]},"316":{"title":"学习语言模型","titles":["语言模型和数据集"]},"317":{"title":"马尔可夫模型与n元语法","titles":["语言模型和数据集"]},"318":{"title":"自然语言统计","titles":["语言模型和数据集"]},"319":{"title":"读取长序列数据","titles":["语言模型和数据集"]},"320":{"title":"随机采样","titles":["语言模型和数据集","读取长序列数据"]},"321":{"title":"顺序分区","titles":["语言模型和数据集","读取长序列数据"]},"322":{"title":"小结","titles":["语言模型和数据集"]},"323":{"title":"练习","titles":["语言模型和数据集"]},"324":{"title":"循环神经网络的简洁实现","titles":[]},"325":{"title":"[定义模型]","titles":["循环神经网络的简洁实现"]},"326":{"title":"训练与预测","titles":["循环神经网络的简洁实现"]},"327":{"title":"小结","titles":["循环神经网络的简洁实现"]},"328":{"title":"练习","titles":["循环神经网络的简洁实现"]},"329":{"title":"循环神经网络的从零开始实现","titles":[]},"330":{"title":"[独热编码]","titles":["循环神经网络的从零开始实现"]},"331":{"title":"初始化模型参数","titles":["循环神经网络的从零开始实现"]},"332":{"title":"循环神经网络模型","titles":["循环神经网络的从零开始实现"]},"333":{"title":"预测","titles":["循环神经网络的从零开始实现"]},"334":{"title":"[梯度裁剪]","titles":["循环神经网络的从零开始实现"]},"335":{"title":"训练","titles":["循环神经网络的从零开始实现"]},"336":{"title":"小结","titles":["循环神经网络的从零开始实现"]},"337":{"title":"练习","titles":["循环神经网络的从零开始实现"]},"338":{"title":"循环神经网络","titles":[]},"339":{"title":"无隐状态的神经网络","titles":["循环神经网络"]},"340":{"title":"有隐状态的循环神经网络","titles":["循环神经网络"]},"341":{"title":"基于循环神经网络的字符级语言模型","titles":["循环神经网络"]},"342":{"title":"困惑度（Perplexity）","titles":["循环神经网络"]},"343":{"title":"小结","titles":["循环神经网络"]},"344":{"title":"练习","titles":["循环神经网络"]},"345":{"title":"序列模型","titles":[]},"346":{"title":"统计工具","titles":["序列模型"]},"347":{"title":"自回归模型","titles":["序列模型","统计工具"]},"348":{"title":"马尔可夫模型","titles":["序列模型","统计工具"]},"349":{"title":"因果关系","titles":["序列模型","统计工具"]},"350":{"title":"训练","titles":["序列模型"]},"351":{"title":"预测","titles":["序列模型"]},"352":{"title":"小结","titles":["序列模型"]},"353":{"title":"练习","titles":["序列模型"]},"354":{"title":"注意力提示","titles":[]},"355":{"title":"生物学中的注意力提示","titles":["注意力提示"]},"356":{"title":"查询、键和值","titles":["注意力提示"]},"357":{"title":"注意力的可视化","titles":["注意力提示"]},"358":{"title":"小结","titles":["注意力提示"]},"359":{"title":"练习","titles":["注意力提示"]},"360":{"title":"文本预处理","titles":[]},"361":{"title":"读取数据集","titles":["文本预处理"]},"362":{"title":"词元化","titles":["文本预处理"]},"363":{"title":"词表","titles":["文本预处理"]},"364":{"title":"整合所有功能","titles":["文本预处理"]},"365":{"title":"小结","titles":["文本预处理"]},"366":{"title":"练习","titles":["文本预处理"]},"367":{"title":"注意力评分函数","titles":[]},"368":{"title":"[掩蔽softmax操作]","titles":["注意力评分函数"]},"369":{"title":"[加性注意力]","titles":["注意力评分函数"]},"370":{"title":"[缩放点积注意力]","titles":["注意力评分函数"]},"371":{"title":"小结","titles":["注意力评分函数"]},"372":{"title":"练习","titles":["注意力评分函数"]},"373":{"title":"Bahdanau 注意力","titles":[]},"374":{"title":"模型","titles":["Bahdanau 注意力"]},"375":{"title":"定义注意力解码器","titles":["Bahdanau 注意力"]},"376":{"title":"[训练]","titles":["Bahdanau 注意力"]},"377":{"title":"小结","titles":["Bahdanau 注意力"]},"378":{"title":"练习","titles":["Bahdanau 注意力"]},"379":{"title":"注意力机制","titles":[]},"380":{"title":"多头注意力","titles":[]},"381":{"title":"模型","titles":["多头注意力"]},"382":{"title":"实现","titles":["多头注意力"]},"383":{"title":"小结","titles":["多头注意力"]},"384":{"title":"练习","titles":["多头注意力"]},"385":{"title":"注意力汇聚：Nadaraya-Watson 核回归","titles":[]},"386":{"title":"[生成数据集]","titles":["注意力汇聚：Nadaraya-Watson 核回归"]},"387":{"title":"平均汇聚","titles":["注意力汇聚：Nadaraya-Watson 核回归"]},"388":{"title":"[非参数注意力汇聚]","titles":["注意力汇聚：Nadaraya-Watson 核回归"]},"389":{"title":"[带参数注意力汇聚]","titles":["注意力汇聚：Nadaraya-Watson 核回归"]},"390":{"title":"批量矩阵乘法","titles":["注意力汇聚：Nadaraya-Watson 核回归","[带参数注意力汇聚]"]},"391":{"title":"定义模型","titles":["注意力汇聚：Nadaraya-Watson 核回归","[带参数注意力汇聚]"]},"392":{"title":"训练","titles":["注意力汇聚：Nadaraya-Watson 核回归","[带参数注意力汇聚]"]},"393":{"title":"小结","titles":["注意力汇聚：Nadaraya-Watson 核回归"]},"394":{"title":"练习","titles":["注意力汇聚：Nadaraya-Watson 核回归"]},"395":{"title":"自注意力和位置编码","titles":[]},"396":{"title":"[自注意力]","titles":["自注意力和位置编码"]},"397":{"title":"比较卷积神经网络、循环神经网络和自注意力","titles":["自注意力和位置编码"]},"398":{"title":"[位置编码]","titles":["自注意力和位置编码"]},"399":{"title":"绝对位置信息","titles":["自注意力和位置编码","[位置编码]"]},"400":{"title":"相对位置信息","titles":["自注意力和位置编码","[位置编码]"]},"401":{"title":"小结","titles":["自注意力和位置编码"]},"402":{"title":"练习","titles":["自注意力和位置编码"]},"403":{"title":"Transformer","titles":[]},"404":{"title":"模型","titles":["Transformer"]},"405":{"title":"[基于位置的前馈网络]","titles":["Transformer"]},"406":{"title":"残差连接和层规范化","titles":["Transformer"]},"407":{"title":"编码器","titles":["Transformer"]},"408":{"title":"解码器","titles":["Transformer"]},"409":{"title":"[训练]","titles":["Transformer"]},"410":{"title":"小结","titles":["Transformer"]},"411":{"title":"练习","titles":["Transformer"]},"412":{"title":"自定义层","titles":[]},"413":{"title":"不带参数的层","titles":["自定义层"]},"414":{"title":"[带参数的层]","titles":["自定义层"]},"415":{"title":"小结","titles":["自定义层"]},"416":{"title":"练习","titles":["自定义层"]},"417":{"title":"延后初始化","titles":[]},"418":{"title":"实例化网络","titles":["延后初始化"]},"419":{"title":"小结","titles":["延后初始化"]},"420":{"title":"练习","titles":["延后初始化"]},"421":{"title":"深度学习计算","titles":[]},"422":{"title":"层和块","titles":[]},"423":{"title":"[自定义块]","titles":["层和块"]},"424":{"title":"[顺序块]","titles":["层和块"]},"425":{"title":"[在前向传播函数中执行代码]","titles":["层和块"]},"426":{"title":"效率","titles":["层和块"]},"427":{"title":"小结","titles":["层和块"]},"428":{"title":"练习","titles":["层和块"]},"429":{"title":"参数管理","titles":[]},"430":{"title":"[参数访问]","titles":["参数管理"]},"431":{"title":"[目标参数]","titles":["参数管理","[参数访问]"]},"432":{"title":"[一次性访问所有参数]","titles":["参数管理","[参数访问]"]},"433":{"title":"[从嵌套块收集参数]","titles":["参数管理","[参数访问]"]},"434":{"title":"参数初始化","titles":["参数管理"]},"435":{"title":"[内置初始化]","titles":["参数管理","参数初始化"]},"436":{"title":"[自定义初始化]","titles":["参数管理","参数初始化"]},"437":{"title":"[参数绑定]","titles":["参数管理"]},"438":{"title":"小结","titles":["参数管理"]},"439":{"title":"练习","titles":["参数管理"]},"440":{"title":"读写文件","titles":[]},"441":{"title":"(加载和保存张量)","titles":["读写文件"]},"442":{"title":"[加载和保存模型参数]","titles":["读写文件"]},"443":{"title":"小结","titles":["读写文件"]},"444":{"title":"练习","titles":["读写文件"]},"445":{"title":"GPU","titles":[]},"446":{"title":"[计算设备]","titles":["GPU"]},"447":{"title":"张量与GPU","titles":["GPU"]},"448":{"title":"[存储在GPU上]","titles":["GPU","张量与GPU"]},"449":{"title":"复制","titles":["GPU","张量与GPU"]},"450":{"title":"旁注","titles":["GPU","张量与GPU"]},"451":{"title":"[神经网络与GPU]","titles":["GPU"]},"452":{"title":"小结","titles":["GPU"]},"453":{"title":"练习","titles":["GPU"]},"454":{"title":"深度卷积神经网络（AlexNet）","titles":[]},"455":{"title":"学习表征","titles":["深度卷积神经网络（AlexNet）"]},"456":{"title":"缺少的成分：数据","titles":["深度卷积神经网络（AlexNet）","学习表征"]},"457":{"title":"缺少的成分：硬件","titles":["深度卷积神经网络（AlexNet）","学习表征"]},"458":{"title":"AlexNet","titles":["深度卷积神经网络（AlexNet）"]},"459":{"title":"模型设计","titles":["深度卷积神经网络（AlexNet）","AlexNet"]},"460":{"title":"激活函数","titles":["深度卷积神经网络（AlexNet）","AlexNet"]},"461":{"title":"容量控制和预处理","titles":["深度卷积神经网络（AlexNet）","AlexNet"]},"462":{"title":"读取数据集","titles":["深度卷积神经网络（AlexNet）"]},"463":{"title":"[训练AlexNet]","titles":["深度卷积神经网络（AlexNet）"]},"464":{"title":"小结","titles":["深度卷积神经网络（AlexNet）"]},"465":{"title":"练习","titles":["深度卷积神经网络（AlexNet）"]},"466":{"title":"批量规范化","titles":[]},"467":{"title":"训练深层网络","titles":["批量规范化"]},"468":{"title":"批量规范化层","titles":["批量规范化"]},"469":{"title":"全连接层","titles":["批量规范化","批量规范化层"]},"470":{"title":"卷积层","titles":["批量规范化","批量规范化层"]},"471":{"title":"预测过程中的批量规范化","titles":["批量规范化","批量规范化层"]},"472":{"title":"(从零实现)","titles":["批量规范化"]},"473":{"title":"使用批量规范化层的 LeNet","titles":["批量规范化"]},"474":{"title":"[简明实现]","titles":["批量规范化"]},"475":{"title":"争议","titles":["批量规范化"]},"476":{"title":"小结","titles":["批量规范化"]},"477":{"title":"练习","titles":["批量规范化"]},"478":{"title":"稠密连接网络（DenseNet）","titles":[]},"479":{"title":"从ResNet到DenseNet","titles":["稠密连接网络（DenseNet）"]},"480":{"title":"(稠密块体)","titles":["稠密连接网络（DenseNet）"]},"481":{"title":"[过渡层]","titles":["稠密连接网络（DenseNet）"]},"482":{"title":"[DenseNet模型]","titles":["稠密连接网络（DenseNet）"]},"483":{"title":"[训练模型]","titles":["稠密连接网络（DenseNet）"]},"484":{"title":"小结","titles":["稠密连接网络（DenseNet）"]},"485":{"title":"练习","titles":["稠密连接网络（DenseNet）"]},"486":{"title":"含并行连结的网络（GoogLeNet）","titles":[]},"487":{"title":"(Inception块)","titles":["含并行连结的网络（GoogLeNet）"]},"488":{"title":"[GoogLeNet模型]","titles":["含并行连结的网络（GoogLeNet）"]},"489":{"title":"[训练模型]","titles":["含并行连结的网络（GoogLeNet）"]},"490":{"title":"小结","titles":["含并行连结的网络（GoogLeNet）"]},"491":{"title":"练习","titles":["含并行连结的网络（GoogLeNet）"]},"492":{"title":"现代卷积神经网络","titles":[]},"493":{"title":"网络中的网络（NiN）","titles":[]},"494":{"title":"(NiN块)","titles":["网络中的网络（NiN）"]},"495":{"title":"[NiN模型]","titles":["网络中的网络（NiN）"]},"496":{"title":"[训练模型]","titles":["网络中的网络（NiN）"]},"497":{"title":"小结","titles":["网络中的网络（NiN）"]},"498":{"title":"练习","titles":["网络中的网络（NiN）"]},"499":{"title":"残差网络（ResNet）","titles":[]},"500":{"title":"函数类","titles":["残差网络（ResNet）"]},"501":{"title":"(残差块)","titles":["残差网络（ResNet）"]},"502":{"title":"[ResNet模型]","titles":["残差网络（ResNet）"]},"503":{"title":"[训练模型]","titles":["残差网络（ResNet）"]},"504":{"title":"小结","titles":["残差网络（ResNet）"]},"505":{"title":"练习","titles":["残差网络（ResNet）"]},"506":{"title":"使用块的网络（VGG）","titles":[]},"507":{"title":"(VGG块)","titles":["使用块的网络（VGG）"]},"508":{"title":"[VGG网络]","titles":["使用块的网络（VGG）"]},"509":{"title":"训练模型","titles":["使用块的网络（VGG）"]},"510":{"title":"小结","titles":["使用块的网络（VGG）"]},"511":{"title":"练习","titles":["使用块的网络（VGG）"]},"512":{"title":"束搜索","titles":[]},"513":{"title":"贪心搜索","titles":["束搜索"]},"514":{"title":"穷举搜索","titles":["束搜索"]},"515":{"title":"束搜索","titles":["束搜索"]},"516":{"title":"小结","titles":["束搜索"]},"517":{"title":"练习","titles":["束搜索"]},"518":{"title":"双向循环神经网络","titles":[]},"519":{"title":"隐马尔可夫模型中的动态规划","titles":["双向循环神经网络"]},"520":{"title":"双向模型","titles":["双向循环神经网络"]},"521":{"title":"定义","titles":["双向循环神经网络","双向模型"]},"522":{"title":"模型的计算代价及其应用","titles":["双向循环神经网络","双向模型"]},"523":{"title":"(双向循环神经网络的错误应用)","titles":["双向循环神经网络"]},"524":{"title":"小结","titles":["双向循环神经网络"]},"525":{"title":"练习","titles":["双向循环神经网络"]},"526":{"title":"深度循环神经网络","titles":[]},"527":{"title":"函数依赖关系","titles":["深度循环神经网络"]},"528":{"title":"简洁实现","titles":["深度循环神经网络"]},"529":{"title":"[训练]与预测","titles":["深度循环神经网络"]},"530":{"title":"小结","titles":["深度循环神经网络"]},"531":{"title":"练习","titles":["深度循环神经网络"]},"532":{"title":"编码器-解码器架构","titles":[]},"533":{"title":"(编码器)","titles":["编码器-解码器架构"]},"534":{"title":"[解码器]","titles":["编码器-解码器架构"]},"535":{"title":"[合并编码器和解码器]","titles":["编码器-解码器架构"]},"536":{"title":"小结","titles":["编码器-解码器架构"]},"537":{"title":"练习","titles":["编码器-解码器架构"]},"538":{"title":"门控循环单元（GRU）","titles":[]},"539":{"title":"门控隐状态","titles":["门控循环单元（GRU）"]},"540":{"title":"重置门和更新门","titles":["门控循环单元（GRU）","门控隐状态"]},"541":{"title":"候选隐状态","titles":["门控循环单元（GRU）","门控隐状态"]},"542":{"title":"隐状态","titles":["门控循环单元（GRU）","门控隐状态"]},"543":{"title":"从零开始实现","titles":["门控循环单元（GRU）"]},"544":{"title":"[初始化模型参数]","titles":["门控循环单元（GRU）","从零开始实现"]},"545":{"title":"定义模型","titles":["门控循环单元（GRU）","从零开始实现"]},"546":{"title":"[训练]与预测","titles":["门控循环单元（GRU）","从零开始实现"]},"547":{"title":"[简洁实现]","titles":["门控循环单元（GRU）"]},"548":{"title":"小结","titles":["门控循环单元（GRU）"]},"549":{"title":"练习","titles":["门控循环单元（GRU）"]},"550":{"title":"现代循环神经网络","titles":[]},"551":{"title":"长短期记忆网络（LSTM）","titles":[]},"552":{"title":"门控记忆元","titles":["长短期记忆网络（LSTM）"]},"553":{"title":"输入门、忘记门和输出门","titles":["长短期记忆网络（LSTM）","门控记忆元"]},"554":{"title":"候选记忆元","titles":["长短期记忆网络（LSTM）","门控记忆元"]},"555":{"title":"记忆元","titles":["长短期记忆网络（LSTM）","门控记忆元"]},"556":{"title":"隐状态","titles":["长短期记忆网络（LSTM）","门控记忆元"]},"557":{"title":"从零开始实现","titles":["长短期记忆网络（LSTM）"]},"558":{"title":"[初始化模型参数]","titles":["长短期记忆网络（LSTM）","从零开始实现"]},"559":{"title":"定义模型","titles":["长短期记忆网络（LSTM）","从零开始实现"]},"560":{"title":"[训练]和预测","titles":["长短期记忆网络（LSTM）","从零开始实现"]},"561":{"title":"[简洁实现]","titles":["长短期记忆网络（LSTM）"]},"562":{"title":"小结","titles":["长短期记忆网络（LSTM）"]},"563":{"title":"练习","titles":["长短期记忆网络（LSTM）"]},"564":{"title":"机器翻译与数据集","titles":[]},"565":{"title":"[下载和预处理数据集]","titles":["机器翻译与数据集"]},"566":{"title":"[词元化]","titles":["机器翻译与数据集"]},"567":{"title":"[词表]","titles":["机器翻译与数据集"]},"568":{"title":"加载数据集","titles":["机器翻译与数据集"]},"569":{"title":"[训练模型]","titles":["机器翻译与数据集"]},"570":{"title":"小结","titles":["机器翻译与数据集"]},"571":{"title":"练习","titles":["机器翻译与数据集"]},"572":{"title":"序列到序列学习（seq2seq）","titles":[]},"573":{"title":"编码器","titles":["序列到序列学习（seq2seq）"]},"574":{"title":"[解码器]","titles":["序列到序列学习（seq2seq）"]},"575":{"title":"损失函数","titles":["序列到序列学习（seq2seq）"]},"576":{"title":"[训练]","titles":["序列到序列学习（seq2seq）"]},"577":{"title":"[预测]","titles":["序列到序列学习（seq2seq）"]},"578":{"title":"预测序列的评估","titles":["序列到序列学习（seq2seq）"]},"579":{"title":"小结","titles":["序列到序列学习（seq2seq）"]},"580":{"title":"练习","titles":["序列到序列学习（seq2seq）"]},"581":{"title":"图像分类数据集","titles":[]},"582":{"title":"读取数据集","titles":["图像分类数据集"]},"583":{"title":"读取小批量","titles":["图像分类数据集"]},"584":{"title":"整合所有组件","titles":["图像分类数据集"]},"585":{"title":"小结","titles":["图像分类数据集"]},"586":{"title":"练习","titles":["图像分类数据集"]},"587":{"title":"线性神经网络","titles":[]},"588":{"title":"线性回归的简洁实现","titles":[]},"589":{"title":"生成数据集","titles":["线性回归的简洁实现"]},"590":{"title":"读取数据集","titles":["线性回归的简洁实现"]},"591":{"title":"定义模型","titles":["线性回归的简洁实现"]},"592":{"title":"(初始化模型参数)","titles":["线性回归的简洁实现"]},"593":{"title":"定义损失函数","titles":["线性回归的简洁实现"]},"594":{"title":"定义优化算法","titles":["线性回归的简洁实现"]},"595":{"title":"训练","titles":["线性回归的简洁实现"]},"596":{"title":"小结","titles":["线性回归的简洁实现"]},"597":{"title":"练习","titles":["线性回归的简洁实现"]},"598":{"title":"线性回归的从零开始实现","titles":[]},"599":{"title":"生成数据集","titles":["线性回归的从零开始实现"]},"600":{"title":"读取数据集","titles":["线性回归的从零开始实现"]},"601":{"title":"初始化模型参数","titles":["线性回归的从零开始实现"]},"602":{"title":"定义模型","titles":["线性回归的从零开始实现"]},"603":{"title":"[定义损失函数]","titles":["线性回归的从零开始实现"]},"604":{"title":"(定义优化算法)","titles":["线性回归的从零开始实现"]},"605":{"title":"训练","titles":["线性回归的从零开始实现"]},"606":{"title":"小结","titles":["线性回归的从零开始实现"]},"607":{"title":"练习","titles":["线性回归的从零开始实现"]},"608":{"title":"线性回归","titles":[]},"609":{"title":"线性回归的基本元素","titles":["线性回归"]},"610":{"title":"线性模型","titles":["线性回归","线性回归的基本元素"]},"611":{"title":"损失函数","titles":["线性回归","线性回归的基本元素"]},"612":{"title":"解析解","titles":["线性回归","线性回归的基本元素"]},"613":{"title":"随机梯度下降","titles":["线性回归","线性回归的基本元素"]},"614":{"title":"用模型进行预测","titles":["线性回归","线性回归的基本元素"]},"615":{"title":"矢量化加速","titles":["线性回归"]},"616":{"title":"正态分布与平方损失","titles":["线性回归"]},"617":{"title":"从线性回归到深度网络","titles":["线性回归"]},"618":{"title":"神经网络图","titles":["线性回归","从线性回归到深度网络"]},"619":{"title":"生物学","titles":["线性回归","从线性回归到深度网络"]},"620":{"title":"小结","titles":["线性回归"]},"621":{"title":"练习","titles":["线性回归"]},"622":{"title":"softmax回归的简洁实现","titles":[]},"623":{"title":"初始化模型参数","titles":["softmax回归的简洁实现"]},"624":{"title":"重新审视Softmax的实现","titles":["softmax回归的简洁实现"]},"625":{"title":"优化算法","titles":["softmax回归的简洁实现"]},"626":{"title":"训练","titles":["softmax回归的简洁实现"]},"627":{"title":"小结","titles":["softmax回归的简洁实现"]},"628":{"title":"练习","titles":["softmax回归的简洁实现"]},"629":{"title":"softmax回归的从零开始实现","titles":[]},"630":{"title":"初始化模型参数","titles":["softmax回归的从零开始实现"]},"631":{"title":"定义softmax操作","titles":["softmax回归的从零开始实现"]},"632":{"title":"定义模型","titles":["softmax回归的从零开始实现"]},"633":{"title":"定义损失函数","titles":["softmax回归的从零开始实现"]},"634":{"title":"分类精度","titles":["softmax回归的从零开始实现"]},"635":{"title":"训练","titles":["softmax回归的从零开始实现"]},"636":{"title":"预测","titles":["softmax回归的从零开始实现"]},"637":{"title":"小结","titles":["softmax回归的从零开始实现"]},"638":{"title":"练习","titles":["softmax回归的从零开始实现"]},"639":{"title":"softmax回归","titles":[]},"640":{"title":"分类问题","titles":["softmax回归"]},"641":{"title":"网络架构","titles":["softmax回归"]},"642":{"title":"全连接层的参数开销","titles":["softmax回归"]},"643":{"title":"softmax运算","titles":["softmax回归"]},"644":{"title":"小批量样本的矢量化","titles":["softmax回归"]},"645":{"title":"损失函数","titles":["softmax回归"]},"646":{"title":"对数似然","titles":["softmax回归","损失函数"]},"647":{"title":"softmax及其导数","titles":["softmax回归","损失函数"]},"648":{"title":"交叉熵损失","titles":["softmax回归","损失函数"]},"649":{"title":"信息论基础","titles":["softmax回归"]},"650":{"title":"熵","titles":["softmax回归","信息论基础"]},"651":{"title":"信息量","titles":["softmax回归","信息论基础"]},"652":{"title":"重新审视交叉熵","titles":["softmax回归","信息论基础"]},"653":{"title":"模型预测和评估","titles":["softmax回归"]},"654":{"title":"小结","titles":["softmax回归"]},"655":{"title":"练习","titles":["softmax回归"]},"656":{"title":"针对序列级和词元级应用微调BERT","titles":[]},"657":{"title":"单文本分类","titles":["针对序列级和词元级应用微调BERT"]},"658":{"title":"文本对分类或回归","titles":["针对序列级和词元级应用微调BERT"]},"659":{"title":"文本标注","titles":["针对序列级和词元级应用微调BERT"]},"660":{"title":"问答","titles":["针对序列级和词元级应用微调BERT"]},"661":{"title":"小结","titles":["针对序列级和词元级应用微调BERT"]},"662":{"title":"练习","titles":["针对序列级和词元级应用微调BERT"]},"663":{"title":"自然语言处理：应用","titles":[]},"664":{"title":"自然语言推断与数据集","titles":[]},"665":{"title":"自然语言推断","titles":["自然语言推断与数据集"]},"666":{"title":"斯坦福自然语言推断（SNLI）数据集","titles":["自然语言推断与数据集"]},"667":{"title":"[读取数据集]","titles":["自然语言推断与数据集","斯坦福自然语言推断（SNLI）数据集"]},"668":{"title":"[定义用于加载数据集的类]","titles":["自然语言推断与数据集","斯坦福自然语言推断（SNLI）数据集"]},"669":{"title":"[整合代码]","titles":["自然语言推断与数据集","斯坦福自然语言推断（SNLI）数据集"]},"670":{"title":"小结","titles":["自然语言推断与数据集"]},"671":{"title":"练习","titles":["自然语言推断与数据集"]},"672":{"title":"自然语言推断：使用注意力","titles":[]},"673":{"title":"模型","titles":["自然语言推断：使用注意力"]},"674":{"title":"注意（Attending）","titles":["自然语言推断：使用注意力","模型"]},"675":{"title":"比较","titles":["自然语言推断：使用注意力","模型"]},"676":{"title":"聚合","titles":["自然语言推断：使用注意力","模型"]},"677":{"title":"整合代码","titles":["自然语言推断：使用注意力","模型"]},"678":{"title":"训练和评估模型","titles":["自然语言推断：使用注意力"]},"679":{"title":"读取数据集","titles":["自然语言推断：使用注意力","训练和评估模型"]},"680":{"title":"创建模型","titles":["自然语言推断：使用注意力","训练和评估模型"]},"681":{"title":"训练和评估模型","titles":["自然语言推断：使用注意力","训练和评估模型"]},"682":{"title":"使用模型","titles":["自然语言推断：使用注意力","训练和评估模型"]},"683":{"title":"小结","titles":["自然语言推断：使用注意力"]},"684":{"title":"练习","titles":["自然语言推断：使用注意力"]},"685":{"title":"自然语言推断：微调BERT","titles":[]},"686":{"title":"[加载预训练的BERT]","titles":["自然语言推断：微调BERT"]},"687":{"title":"[微调BERT的数据集]","titles":["自然语言推断：微调BERT"]},"688":{"title":"微调BERT","titles":["自然语言推断：微调BERT"]},"689":{"title":"小结","titles":["自然语言推断：微调BERT"]},"690":{"title":"练习","titles":["自然语言推断：微调BERT"]},"691":{"title":"情感分析及数据集","titles":[]},"692":{"title":"读取数据集","titles":["情感分析及数据集"]},"693":{"title":"预处理数据集","titles":["情感分析及数据集"]},"694":{"title":"创建数据迭代器","titles":["情感分析及数据集"]},"695":{"title":"整合代码","titles":["情感分析及数据集"]},"696":{"title":"小结","titles":["情感分析及数据集"]},"697":{"title":"练习","titles":["情感分析及数据集"]},"698":{"title":"情感分析：使用卷积神经网络","titles":[]},"699":{"title":"一维卷积","titles":["情感分析：使用卷积神经网络"]},"700":{"title":"最大时间汇聚层","titles":["情感分析：使用卷积神经网络"]},"701":{"title":"textCNN模型","titles":["情感分析：使用卷积神经网络"]},"702":{"title":"定义模型","titles":["情感分析：使用卷积神经网络","textCNN模型"]},"703":{"title":"加载预训练词向量","titles":["情感分析：使用卷积神经网络","textCNN模型"]},"704":{"title":"训练和评估模型","titles":["情感分析：使用卷积神经网络","textCNN模型"]},"705":{"title":"小结","titles":["情感分析：使用卷积神经网络"]},"706":{"title":"练习","titles":["情感分析：使用卷积神经网络"]},"707":{"title":"近似训练","titles":[]},"708":{"title":"负采样","titles":["近似训练"]},"709":{"title":"层序Softmax","titles":["近似训练"]},"710":{"title":"小结","titles":["近似训练"]},"711":{"title":"练习","titles":["近似训练"]},"712":{"title":"情感分析：使用循环神经网络","titles":[]},"713":{"title":"使用循环神经网络表示单个文本","titles":["情感分析：使用循环神经网络"]},"714":{"title":"加载预训练的词向量","titles":["情感分析：使用循环神经网络"]},"715":{"title":"训练和评估模型","titles":["情感分析：使用循环神经网络"]},"716":{"title":"小结","titles":["情感分析：使用循环神经网络"]},"717":{"title":"练习","titles":["情感分析：使用循环神经网络"]},"718":{"title":"用于预训练BERT的数据集","titles":[]},"719":{"title":"为预训练任务定义辅助函数","titles":["用于预训练BERT的数据集"]},"720":{"title":"生成下一句预测任务的数据","titles":["用于预训练BERT的数据集","为预训练任务定义辅助函数"]},"721":{"title":"生成遮蔽语言模型任务的数据","titles":["用于预训练BERT的数据集","为预训练任务定义辅助函数"]},"722":{"title":"将文本转换为预训练数据集","titles":["用于预训练BERT的数据集"]},"723":{"title":"小结","titles":["用于预训练BERT的数据集"]},"724":{"title":"练习","titles":["用于预训练BERT的数据集"]},"725":{"title":"预训练BERT","titles":[]},"726":{"title":"预训练BERT","titles":["预训练BERT"]},"727":{"title":"用BERT表示文本","titles":["预训练BERT"]},"728":{"title":"小结","titles":["预训练BERT"]},"729":{"title":"练习","titles":["预训练BERT"]},"730":{"title":"来自Transformers的双向编码器表示（BERT）","titles":[]},"731":{"title":"从上下文无关到上下文敏感","titles":["来自Transformers的双向编码器表示（BERT）"]},"732":{"title":"从特定于任务到不可知任务","titles":["来自Transformers的双向编码器表示（BERT）"]},"733":{"title":"BERT：把两个最好的结合起来","titles":["来自Transformers的双向编码器表示（BERT）"]},"734":{"title":"输入表示","titles":["来自Transformers的双向编码器表示（BERT）"]},"735":{"title":"预训练任务","titles":["来自Transformers的双向编码器表示（BERT）"]},"736":{"title":"掩蔽语言模型（Masked Language Modeling）","titles":["来自Transformers的双向编码器表示（BERT）","预训练任务"]},"737":{"title":"下一句预测（Next Sentence Prediction）","titles":["来自Transformers的双向编码器表示（BERT）","预训练任务"]},"738":{"title":"整合代码","titles":["来自Transformers的双向编码器表示（BERT）"]},"739":{"title":"小结","titles":["来自Transformers的双向编码器表示（BERT）"]},"740":{"title":"练习","titles":["来自Transformers的双向编码器表示（BERT）"]},"741":{"title":"全局向量的词嵌入（GloVe）","titles":[]},"742":{"title":"带全局语料统计的跳元模型","titles":["全局向量的词嵌入（GloVe）"]},"743":{"title":"GloVe模型","titles":["全局向量的词嵌入（GloVe）"]},"744":{"title":"从条件概率比值理解GloVe模型","titles":["全局向量的词嵌入（GloVe）"]},"745":{"title":"小结","titles":["全局向量的词嵌入（GloVe）"]},"746":{"title":"练习","titles":["全局向量的词嵌入（GloVe）"]},"747":{"title":"词的相似性和类比任务","titles":[]},"748":{"title":"加载预训练词向量","titles":["词的相似性和类比任务"]},"749":{"title":"应用预训练词向量","titles":["词的相似性和类比任务"]},"750":{"title":"词相似度","titles":["词的相似性和类比任务","应用预训练词向量"]},"751":{"title":"词类比","titles":["词的相似性和类比任务","应用预训练词向量"]},"752":{"title":"小结","titles":["词的相似性和类比任务"]},"753":{"title":"练习","titles":["词的相似性和类比任务"]},"754":{"title":"自然语言处理：预训练","titles":[]},"755":{"title":"子词嵌入","titles":[]},"756":{"title":"fastText模型","titles":["子词嵌入"]},"757":{"title":"字节对编码（Byte Pair Encoding）","titles":["子词嵌入"]},"758":{"title":"小结","titles":["子词嵌入"]},"759":{"title":"练习","titles":["子词嵌入"]},"760":{"title":"预训练word2vec","titles":[]},"761":{"title":"跳元模型","titles":["预训练word2vec"]},"762":{"title":"嵌入层","titles":["预训练word2vec","跳元模型"]},"763":{"title":"定义前向传播","titles":["预训练word2vec","跳元模型"]},"764":{"title":"训练","titles":["预训练word2vec"]},"765":{"title":"二元交叉熵损失","titles":["预训练word2vec","训练"]},"766":{"title":"初始化模型参数","titles":["预训练word2vec","训练"]},"767":{"title":"定义训练阶段代码","titles":["预训练word2vec","训练"]},"768":{"title":"应用词嵌入","titles":["预训练word2vec"]},"769":{"title":"小结","titles":["预训练word2vec"]},"770":{"title":"练习","titles":["预训练word2vec"]},"771":{"title":"用于预训练词嵌入的数据集","titles":[]},"772":{"title":"读取数据集","titles":["用于预训练词嵌入的数据集"]},"773":{"title":"下采样","titles":["用于预训练词嵌入的数据集"]},"774":{"title":"中心词和上下文词的提取","titles":["用于预训练词嵌入的数据集"]},"775":{"title":"负采样","titles":["用于预训练词嵌入的数据集"]},"776":{"title":"小批量加载训练实例","titles":["用于预训练词嵌入的数据集"]},"777":{"title":"整合代码","titles":["用于预训练词嵌入的数据集"]},"778":{"title":"小结","titles":["用于预训练词嵌入的数据集"]},"779":{"title":"练习","titles":["用于预训练词嵌入的数据集"]},"780":{"title":"词嵌入（word2vec）","titles":[]},"781":{"title":"为何独热向量是一个糟糕的选择","titles":["词嵌入（word2vec）"]},"782":{"title":"自监督的word2vec","titles":["词嵌入（word2vec）"]},"783":{"title":"跳元模型（Skip-Gram）","titles":["词嵌入（word2vec）"]},"784":{"title":"训练","titles":["词嵌入（word2vec）","跳元模型（Skip-Gram）"]},"785":{"title":"连续词袋（CBOW）模型","titles":["词嵌入（word2vec）"]},"786":{"title":"训练","titles":["词嵌入（word2vec）","连续词袋（CBOW）模型"]},"787":{"title":"小结","titles":["词嵌入（word2vec）"]},"788":{"title":"练习","titles":["词嵌入（word2vec）"]},"789":{"title":"异步计算","titles":[]},"790":{"title":"通过后端异步处理","titles":["异步计算"]},"791":{"title":"障碍器与阻塞器","titles":["异步计算"]},"792":{"title":"改进计算","titles":["异步计算"]},"793":{"title":"小结","titles":["异步计算"]},"794":{"title":"练习","titles":["异步计算"]},"795":{"title":"自动并行","titles":[]},"796":{"title":"基于GPU的并行计算","titles":["自动并行"]},"797":{"title":"并行计算与通信","titles":["自动并行"]},"798":{"title":"小结","titles":["自动并行"]},"799":{"title":"练习","titles":["自动并行"]},"800":{"title":"硬件","titles":[]},"801":{"title":"计算机","titles":["硬件"]},"802":{"title":"内存","titles":["硬件"]},"803":{"title":"存储器","titles":["硬件"]},"804":{"title":"硬盘驱动器","titles":["硬件","存储器"]},"805":{"title":"固态驱动器","titles":["硬件","存储器"]},"806":{"title":"云存储","titles":["硬件","存储器"]},"807":{"title":"CPU","titles":["硬件"]},"808":{"title":"微体系结构","titles":["硬件","CPU"]},"809":{"title":"矢量化","titles":["硬件","CPU"]},"810":{"title":"缓存","titles":["硬件","CPU"]},"811":{"title":"GPU和其他加速卡","titles":["硬件"]},"812":{"title":"网络和总线","titles":["硬件"]},"813":{"title":"更多延迟","titles":["硬件"]},"814":{"title":"小结","titles":["硬件"]},"815":{"title":"练习","titles":["硬件"]},"816":{"title":"编译器和解释器","titles":[]},"817":{"title":"符号式编程","titles":["编译器和解释器"]},"818":{"title":"混合式编程","titles":["编译器和解释器"]},"819":{"title":"Sequential的混合式编程","titles":["编译器和解释器"]},"820":{"title":"通过混合式编程加速","titles":["编译器和解释器","Sequential的混合式编程"]},"821":{"title":"序列化","titles":["编译器和解释器","Sequential的混合式编程"]},"822":{"title":"小结","titles":["编译器和解释器"]},"823":{"title":"练习","titles":["编译器和解释器"]},"824":{"title":"计算性能","titles":[]},"825":{"title":"多GPU的简洁实现","titles":[]},"826":{"title":"[简单网络]","titles":["多GPU的简洁实现"]},"827":{"title":"网络初始化","titles":["多GPU的简洁实现"]},"828":{"title":"[训练]","titles":["多GPU的简洁实现"]},"829":{"title":"小结","titles":["多GPU的简洁实现"]},"830":{"title":"练习","titles":["多GPU的简洁实现"]},"831":{"title":"多GPU训练","titles":[]},"832":{"title":"问题拆分","titles":["多GPU训练"]},"833":{"title":"数据并行性","titles":["多GPU训练"]},"834":{"title":"[简单网络]","titles":["多GPU训练"]},"835":{"title":"数据同步","titles":["多GPU训练"]},"836":{"title":"数据分发","titles":["多GPU训练"]},"837":{"title":"训练","titles":["多GPU训练"]},"838":{"title":"小结","titles":["多GPU训练"]},"839":{"title":"练习","titles":["多GPU训练"]},"840":{"title":"参数服务器","titles":[]},"841":{"title":"数据并行训练","titles":["参数服务器"]},"842":{"title":"环同步（Ring Synchronization）","titles":["参数服务器"]},"843":{"title":"多机训练","titles":["参数服务器"]},"844":{"title":"键值存储","titles":["参数服务器"]},"845":{"title":"小结","titles":["参数服务器"]},"846":{"title":"练习","titles":["参数服务器"]},"847":{"title":"锚框","titles":[]},"848":{"title":"生成多个锚框","titles":["锚框"]},"849":{"title":"[交并比（IoU）]","titles":["锚框"]},"850":{"title":"在训练数据中标注锚框","titles":["锚框"]},"851":{"title":"[将真实边界框分配给锚框]","titles":["锚框","在训练数据中标注锚框"]},"852":{"title":"标记类别和偏移量","titles":["锚框","在训练数据中标注锚框"]},"853":{"title":"一个例子","titles":["锚框","在训练数据中标注锚框"]},"854":{"title":"使用非极大值抑制预测边界框","titles":["锚框"]},"855":{"title":"小结","titles":["锚框"]},"856":{"title":"练习","titles":["锚框"]},"857":{"title":"目标检测和边界框","titles":[]},"858":{"title":"边界框","titles":["目标检测和边界框"]},"859":{"title":"小结","titles":["目标检测和边界框"]},"860":{"title":"练习","titles":["目标检测和边界框"]},"861":{"title":"全卷积网络","titles":[]},"862":{"title":"构造模型","titles":["全卷积网络"]},"863":{"title":"[初始化转置卷积层]","titles":["全卷积网络"]},"864":{"title":"[读取数据集]","titles":["全卷积网络"]},"865":{"title":"[训练]","titles":["全卷积网络"]},"866":{"title":"[预测]","titles":["全卷积网络"]},"867":{"title":"小结","titles":["全卷积网络"]},"868":{"title":"练习","titles":["全卷积网络"]},"869":{"title":"微调","titles":[]},"870":{"title":"步骤","titles":["微调"]},"871":{"title":"热狗识别","titles":["微调"]},"872":{"title":"获取数据集","titles":["微调","热狗识别"]},"873":{"title":"[定义和初始化模型]","titles":["微调","热狗识别"]},"874":{"title":"[微调模型]","titles":["微调","热狗识别"]},"875":{"title":"小结","titles":["微调"]},"876":{"title":"练习","titles":["微调"]},"877":{"title":"图像增广","titles":[]},"878":{"title":"常用的图像增广方法","titles":["图像增广"]},"879":{"title":"翻转和裁剪","titles":["图像增广","常用的图像增广方法"]},"880":{"title":"改变颜色","titles":["图像增广","常用的图像增广方法"]},"881":{"title":"[结合多种图像增广方法]","titles":["图像增广","常用的图像增广方法"]},"882":{"title":"[使用图像增广进行训练]","titles":["图像增广"]},"883":{"title":"多GPU训练","titles":["图像增广","[使用图像增广进行训练]"]},"884":{"title":"小结","titles":["图像增广"]},"885":{"title":"练习","titles":["图像增广"]},"886":{"title":"计算机视觉","titles":[]},"887":{"title":"实战 Kaggle 比赛：图像分类 (CIFAR-10)","titles":[]},"888":{"title":"获取并组织数据集","titles":["实战 Kaggle 比赛：图像分类 (CIFAR-10)"]},"889":{"title":"下载数据集","titles":["实战 Kaggle 比赛：图像分类 (CIFAR-10)","获取并组织数据集"]},"890":{"title":"[整理数据集]","titles":["实战 Kaggle 比赛：图像分类 (CIFAR-10)","获取并组织数据集"]},"891":{"title":"[图像增广]","titles":["实战 Kaggle 比赛：图像分类 (CIFAR-10)"]},"892":{"title":"读取数据集","titles":["实战 Kaggle 比赛：图像分类 (CIFAR-10)"]},"893":{"title":"定义[模型]","titles":["实战 Kaggle 比赛：图像分类 (CIFAR-10)"]},"894":{"title":"定义[训练函数]","titles":["实战 Kaggle 比赛：图像分类 (CIFAR-10)"]},"895":{"title":"[训练和验证模型]","titles":["实战 Kaggle 比赛：图像分类 (CIFAR-10)"]},"896":{"title":"在 Kaggle 上[对测试集进行分类并提交结果]","titles":["实战 Kaggle 比赛：图像分类 (CIFAR-10)"]},"897":{"title":"小结","titles":["实战 Kaggle 比赛：图像分类 (CIFAR-10)"]},"898":{"title":"练习","titles":["实战 Kaggle 比赛：图像分类 (CIFAR-10)"]},"899":{"title":"实战Kaggle比赛：狗的品种识别（ImageNet Dogs）","titles":[]},"900":{"title":"获取和整理数据集","titles":["实战Kaggle比赛：狗的品种识别（ImageNet Dogs）"]},"901":{"title":"下载数据集","titles":["实战Kaggle比赛：狗的品种识别（ImageNet Dogs）","获取和整理数据集"]},"902":{"title":"[整理数据集]","titles":["实战Kaggle比赛：狗的品种识别（ImageNet Dogs）","获取和整理数据集"]},"903":{"title":"[图像增广]","titles":["实战Kaggle比赛：狗的品种识别（ImageNet Dogs）"]},"904":{"title":"[读取数据集]","titles":["实战Kaggle比赛：狗的品种识别（ImageNet Dogs）"]},"905":{"title":"[微调预训练模型]","titles":["实战Kaggle比赛：狗的品种识别（ImageNet Dogs）"]},"906":{"title":"定义[训练函数]","titles":["实战Kaggle比赛：狗的品种识别（ImageNet Dogs）"]},"907":{"title":"[训练和验证模型]","titles":["实战Kaggle比赛：狗的品种识别（ImageNet Dogs）"]},"908":{"title":"[对测试集分类]并在Kaggle提交结果","titles":["实战Kaggle比赛：狗的品种识别（ImageNet Dogs）"]},"909":{"title":"小结","titles":["实战Kaggle比赛：狗的品种识别（ImageNet Dogs）"]},"910":{"title":"练习","titles":["实战Kaggle比赛：狗的品种识别（ImageNet Dogs）"]},"911":{"title":"多尺度目标检测","titles":[]},"912":{"title":"多尺度锚框","titles":["多尺度目标检测"]},"913":{"title":"多尺度检测","titles":["多尺度目标检测"]},"914":{"title":"小结","titles":["多尺度目标检测"]},"915":{"title":"练习","titles":["多尺度目标检测"]},"916":{"title":"风格迁移","titles":[]},"917":{"title":"方法","titles":["风格迁移"]},"918":{"title":"[阅读内容和风格图像]","titles":["风格迁移"]},"919":{"title":"[预处理和后处理]","titles":["风格迁移"]},"920":{"title":"[抽取图像特征]","titles":["风格迁移"]},"921":{"title":"[定义损失函数]","titles":["风格迁移"]},"922":{"title":"内容损失","titles":["风格迁移","[定义损失函数]"]},"923":{"title":"风格损失","titles":["风格迁移","[定义损失函数]"]},"924":{"title":"全变分损失","titles":["风格迁移","[定义损失函数]"]},"925":{"title":"损失函数","titles":["风格迁移","[定义损失函数]"]},"926":{"title":"[初始化合成图像]","titles":["风格迁移"]},"927":{"title":"[训练模型]","titles":["风格迁移"]},"928":{"title":"小结","titles":["风格迁移"]},"929":{"title":"练习","titles":["风格迁移"]},"930":{"title":"目标检测数据集","titles":[]},"931":{"title":"[下载数据集]","titles":["目标检测数据集"]},"932":{"title":"读取数据集","titles":["目标检测数据集"]},"933":{"title":"[演示]","titles":["目标检测数据集"]},"934":{"title":"小结","titles":["目标检测数据集"]},"935":{"title":"练习","titles":["目标检测数据集"]},"936":{"title":"区域卷积神经网络（R-CNN）系列","titles":[]},"937":{"title":"R-CNN","titles":["区域卷积神经网络（R-CNN）系列"]},"938":{"title":"Fast R-CNN","titles":["区域卷积神经网络（R-CNN）系列"]},"939":{"title":"Faster R-CNN","titles":["区域卷积神经网络（R-CNN）系列"]},"940":{"title":"Mask R-CNN","titles":["区域卷积神经网络（R-CNN）系列"]},"941":{"title":"小结","titles":["区域卷积神经网络（R-CNN）系列"]},"942":{"title":"练习","titles":["区域卷积神经网络（R-CNN）系列"]},"943":{"title":"语义分割和数据集","titles":[]},"944":{"title":"图像分割和实例分割","titles":["语义分割和数据集"]},"945":{"title":"Pascal VOC2012 语义分割数据集","titles":["语义分割和数据集"]},"946":{"title":"预处理数据","titles":["语义分割和数据集","Pascal VOC2012 语义分割数据集"]},"947":{"title":"[自定义语义分割数据集类]","titles":["语义分割和数据集","Pascal VOC2012 语义分割数据集"]},"948":{"title":"[读取数据集]","titles":["语义分割和数据集","Pascal VOC2012 语义分割数据集"]},"949":{"title":"[整合所有组件]","titles":["语义分割和数据集","Pascal VOC2012 语义分割数据集"]},"950":{"title":"小结","titles":["语义分割和数据集"]},"951":{"title":"练习","titles":["语义分割和数据集"]},"952":{"title":"单发多框检测（SSD）","titles":[]},"953":{"title":"模型","titles":["单发多框检测（SSD）"]},"954":{"title":"[类别预测层]","titles":["单发多框检测（SSD）","模型"]},"955":{"title":"(边界框预测层)","titles":["单发多框检测（SSD）","模型"]},"956":{"title":"[连结多尺度的预测]","titles":["单发多框检测（SSD）","模型"]},"957":{"title":"[高和宽减半块]","titles":["单发多框检测（SSD）","模型"]},"958":{"title":"[基本网络块]","titles":["单发多框检测（SSD）","模型"]},"959":{"title":"完整的模型","titles":["单发多框检测（SSD）","模型"]},"960":{"title":"训练模型","titles":["单发多框检测（SSD）"]},"961":{"title":"读取数据集和初始化","titles":["单发多框检测（SSD）","训练模型"]},"962":{"title":"[定义损失函数和评价函数]","titles":["单发多框检测（SSD）","训练模型"]},"963":{"title":"[训练模型]","titles":["单发多框检测（SSD）","训练模型"]},"964":{"title":"[预测目标]","titles":["单发多框检测（SSD）"]},"965":{"title":"小结","titles":["单发多框检测（SSD）"]},"966":{"title":"练习","titles":["单发多框检测（SSD）"]},"967":{"title":"转置卷积","titles":[]},"968":{"title":"基本操作","titles":["转置卷积"]},"969":{"title":"[填充、步幅和多通道]","titles":["转置卷积"]},"970":{"title":"[与矩阵变换的联系]","titles":["转置卷积"]},"971":{"title":"小结","titles":["转置卷积"]},"972":{"title":"练习","titles":["转置卷积"]},"973":{"title":"自动微分","titles":[]},"974":{"title":"一个简单的例子","titles":["自动微分"]},"975":{"title":"非标量变量的反向传播","titles":["自动微分"]},"976":{"title":"分离计算","titles":["自动微分"]},"977":{"title":"Python控制流的梯度计算","titles":["自动微分"]},"978":{"title":"小结","titles":["自动微分"]},"979":{"title":"练习","titles":["自动微分"]},"980":{"title":"微积分","titles":[]},"981":{"title":"导数和微分","titles":["微积分"]},"982":{"title":"偏导数","titles":["微积分"]},"983":{"title":"梯度","titles":["微积分"]},"984":{"title":"链式法则","titles":["微积分"]},"985":{"title":"小结","titles":["微积分"]},"986":{"title":"练习","titles":["微积分"]},"987":{"title":"预备知识","titles":[]},"988":{"title":"线性代数","titles":[]},"989":{"title":"标量","titles":["线性代数"]},"990":{"title":"向量","titles":["线性代数"]},"991":{"title":"长度、维度和形状","titles":["线性代数","向量"]},"992":{"title":"矩阵","titles":["线性代数"]},"993":{"title":"张量","titles":["线性代数"]},"994":{"title":"张量算法的基本性质","titles":["线性代数"]},"995":{"title":"降维","titles":["线性代数"]},"996":{"title":"非降维求和","titles":["线性代数","降维"]},"997":{"title":"点积（Dot Product）","titles":["线性代数"]},"998":{"title":"矩阵-向量积","titles":["线性代数"]},"999":{"title":"矩阵-矩阵乘法","titles":["线性代数"]},"1000":{"title":"范数","titles":["线性代数"]},"1001":{"title":"范数和目标","titles":["线性代数","范数"]},"1002":{"title":"关于线性代数的更多信息","titles":["线性代数"]},"1003":{"title":"小结","titles":["线性代数"]},"1004":{"title":"练习","titles":["线性代数"]},"1005":{"title":"查阅文档","titles":[]},"1006":{"title":"查找模块中的所有函数和类","titles":["查阅文档"]},"1007":{"title":"查找特定函数和类的用法","titles":["查阅文档"]},"1008":{"title":"小结","titles":["查阅文档"]},"1009":{"title":"练习","titles":["查阅文档"]},"1010":{"title":"数据预处理","titles":[]},"1011":{"title":"读取数据集","titles":["数据预处理"]},"1012":{"title":"处理缺失值","titles":["数据预处理"]},"1013":{"title":"转换为张量格式","titles":["数据预处理"]},"1014":{"title":"小结","titles":["数据预处理"]},"1015":{"title":"练习","titles":["数据预处理"]},"1016":{"title":"数据操作","titles":[]},"1017":{"title":"入门","titles":["数据操作"]},"1018":{"title":"运算符","titles":["数据操作"]},"1019":{"title":"广播机制","titles":["数据操作"]},"1020":{"title":"索引和切片","titles":["数据操作"]},"1021":{"title":"节省内存","titles":["数据操作"]},"1022":{"title":"转换为其他Python对象","titles":["数据操作"]},"1023":{"title":"小结","titles":["数据操作"]},"1024":{"title":"练习","titles":["数据操作"]},"1025":{"title":"概率","titles":[]},"1026":{"title":"基本概率论","titles":["概率"]},"1027":{"title":"概率论公理","titles":["概率","基本概率论"]},"1028":{"title":"随机变量","titles":["概率","基本概率论"]},"1029":{"title":"处理多个随机变量","titles":["概率"]},"1030":{"title":"联合概率","titles":["概率","处理多个随机变量"]},"1031":{"title":"条件概率","titles":["概率","处理多个随机变量"]},"1032":{"title":"贝叶斯定理","titles":["概率","处理多个随机变量"]},"1033":{"title":"边际化","titles":["概率","处理多个随机变量"]},"1034":{"title":"独立性","titles":["概率","处理多个随机变量"]},"1035":{"title":"应用","titles":["概率","处理多个随机变量"]},"1036":{"title":"期望和方差","titles":["概率"]},"1037":{"title":"小结","titles":["概率"]},"1038":{"title":"练习","titles":["概率"]},"1039":{"title":"MCP（Model Context Protocol）通信协议与使用指南笔记","titles":[]},"1040":{"title":"一、MCP 概述","titles":["MCP（Model Context Protocol）通信协议与使用指南笔记"]},"1041":{"title":"为什么选择 MCP？","titles":["MCP（Model Context Protocol）通信协议与使用指南笔记","一、MCP 概述"]},"1042":{"title":"通用架构","titles":["MCP（Model Context Protocol）通信协议与使用指南笔记","一、MCP 概述"]},"1043":{"title":"二、通信机制","titles":["MCP（Model Context Protocol）通信协议与使用指南笔记"]},"1044":{"title":"消息格式","titles":["MCP（Model Context Protocol）通信协议与使用指南笔记","二、通信机制"]},"1045":{"title":"请求","titles":["MCP（Model Context Protocol）通信协议与使用指南笔记","二、通信机制","消息格式"]},"1046":{"title":"响应","titles":["MCP（Model Context Protocol）通信协议与使用指南笔记","二、通信机制","消息格式"]},"1047":{"title":"通知","titles":["MCP（Model Context Protocol）通信协议与使用指南笔记","二、通信机制","消息格式"]},"1048":{"title":"三、官方 SDK 应用示例","titles":["MCP（Model Context Protocol）通信协议与使用指南笔记"]},"1049":{"title":"🤖 AI Agent 简介：从模型到智能体的跃迁","titles":[]},"1050":{"title":"🧠 什么是 AI Agent？","titles":["🤖 AI Agent 简介：从模型到智能体的跃迁"]},"1051":{"title":"🚀 为什么 AI Agent 值得关注？","titles":["🤖 AI Agent 简介：从模型到智能体的跃迁"]},"1052":{"title":"🛠️ AI Agent 的核心能力模块","titles":["🤖 AI Agent 简介：从模型到智能体的跃迁"]},"1053":{"title":"🧪 常见 Agent 应用场景","titles":["🤖 AI Agent 简介：从模型到智能体的跃迁"]},"1054":{"title":"💡 我的探索方向","titles":["🤖 AI Agent 简介：从模型到智能体的跃迁"]},"1055":{"title":"📚 推荐阅读与工具资源","titles":["🤖 AI Agent 简介：从模型到智能体的跃迁"]},"1056":{"title":"✍️ 博主的话","titles":["🤖 AI Agent 简介：从模型到智能体的跃迁"]},"1057":{"title":"第1周","titles":[]},"1058":{"title":"1.1 欢迎","titles":["第1周"]},"1059":{"title":"1.2 机器学习是什么？","titles":["第1周"]},"1060":{"title":"1.3 监督学习","titles":["第1周"]},"1061":{"title":"1.4 无监督学习","titles":["第1周"]},"1062":{"title":"二、单变量线性回归(Linear Regression with One Variable)","titles":["第1周"]},"1063":{"title":"2.1 模型表示","titles":["第1周","二、单变量线性回归(Linear Regression with One Variable)"]},"1064":{"title":"2.2 代价函数","titles":["第1周","二、单变量线性回归(Linear Regression with One Variable)"]},"1065":{"title":"2.3 代价函数的直观理解I","titles":["第1周","二、单变量线性回归(Linear Regression with One Variable)"]},"1066":{"title":"2.4 代价函数的直观理解II","titles":["第1周","二、单变量线性回归(Linear Regression with One Variable)"]},"1067":{"title":"2.5 梯度下降","titles":["第1周","二、单变量线性回归(Linear Regression with One Variable)"]},"1068":{"title":"2.6 梯度下降的直观理解","titles":["第1周","二、单变量线性回归(Linear Regression with One Variable)"]},"1069":{"title":"2.7 梯度下降的线性回归","titles":["第1周","二、单变量线性回归(Linear Regression with One Variable)"]},"1070":{"title":"2.8 接下来的内容","titles":["第1周","二、单变量线性回归(Linear Regression with One Variable)"]},"1071":{"title":"三、线性代数回顾(Linear Algebra Review)","titles":["第1周"]},"1072":{"title":"3.1 矩阵和向量","titles":["第1周","三、线性代数回顾(Linear Algebra Review)"]},"1073":{"title":"3.2 加法和标量乘法","titles":["第1周","三、线性代数回顾(Linear Algebra Review)"]},"1074":{"title":"3.3 矩阵向量乘法","titles":["第1周","三、线性代数回顾(Linear Algebra Review)"]},"1075":{"title":"3.4 矩阵乘法","titles":["第1周","三、线性代数回顾(Linear Algebra Review)"]},"1076":{"title":"3.5 矩阵乘法的性质","titles":["第1周","三、线性代数回顾(Linear Algebra Review)"]},"1077":{"title":"3.6 逆、转置","titles":["第1周","三、线性代数回顾(Linear Algebra Review)"]},"1078":{"title":"第2周","titles":[]},"1079":{"title":"四、多变量线性回归(Linear Regression with Multiple Variables)","titles":["第2周"]},"1080":{"title":"4.1 多维特征","titles":["第2周","四、多变量线性回归(Linear Regression with Multiple Variables)"]},"1081":{"title":"4.2 多变量梯度下降","titles":["第2周","四、多变量线性回归(Linear Regression with Multiple Variables)"]},"1082":{"title":"4.3 梯度下降法实践1-特征缩放","titles":["第2周","四、多变量线性回归(Linear Regression with Multiple Variables)"]},"1083":{"title":"4.4 梯度下降法实践2-学习率","titles":["第2周","四、多变量线性回归(Linear Regression with Multiple Variables)"]},"1084":{"title":"4.5 特征和多项式回归","titles":["第2周","四、多变量线性回归(Linear Regression with Multiple Variables)"]},"1085":{"title":"4.6 正规方程","titles":["第2周","四、多变量线性回归(Linear Regression with Multiple Variables)"]},"1086":{"title":"4.7 正规方程及不可逆性（可选）","titles":["第2周","四、多变量线性回归(Linear Regression with Multiple Variables)"]},"1087":{"title":"五、Octave教程(Octave Tutorial)","titles":["第2周"]},"1088":{"title":"5.1 基本操作","titles":["第2周","五、Octave教程(Octave Tutorial)"]},"1089":{"title":"5.2 移动数据","titles":["第2周","五、Octave教程(Octave Tutorial)"]},"1090":{"title":"5.3 计算数据","titles":["第2周","五、Octave教程(Octave Tutorial)"]},"1091":{"title":"5.4 绘图数据","titles":["第2周","五、Octave教程(Octave Tutorial)"]},"1092":{"title":"5.5 控制语句：for，while，if语句","titles":["第2周","五、Octave教程(Octave Tutorial)"]},"1093":{"title":"5.6 向量化","titles":["第2周","五、Octave教程(Octave Tutorial)"]},"1094":{"title":"5.7 工作和提交的编程练习","titles":["第2周","五、Octave教程(Octave Tutorial)"]},"1095":{"title":"第4周","titles":[]},"1096":{"title":"第八、神经网络：表述(Neural Networks: Representation)","titles":["第4周"]},"1097":{"title":"8.1 非线性假设","titles":["第4周","第八、神经网络：表述(Neural Networks: Representation)"]},"1098":{"title":"8.2 神经元和大脑","titles":["第4周","第八、神经网络：表述(Neural Networks: Representation)"]},"1099":{"title":"8.3 模型表示1","titles":["第4周","第八、神经网络：表述(Neural Networks: Representation)"]},"1100":{"title":"8.4 模型表示2","titles":["第4周","第八、神经网络：表述(Neural Networks: Representation)"]},"1101":{"title":"8.5 特征和直观理解1","titles":["第4周","第八、神经网络：表述(Neural Networks: Representation)"]},"1102":{"title":"8.6 样本和直观理解II","titles":["第4周","第八、神经网络：表述(Neural Networks: Representation)"]},"1103":{"title":"8.7 多类分类","titles":["第4周","第八、神经网络：表述(Neural Networks: Representation)"]},"1104":{"title":"第3周","titles":[]},"1105":{"title":"六、逻辑回归(Logistic Regression)","titles":["第3周"]},"1106":{"title":"6.1 分类问题","titles":["第3周","六、逻辑回归(Logistic Regression)"]},"1107":{"title":"6.2 假说表示","titles":["第3周","六、逻辑回归(Logistic Regression)"]},"1108":{"title":"6.3 判定边界","titles":["第3周","六、逻辑回归(Logistic Regression)"]},"1109":{"title":"6.4 代价函数","titles":["第3周","六、逻辑回归(Logistic Regression)"]},"1110":{"title":"6.5 简化的成本函数和梯度下降","titles":["第3周","六、逻辑回归(Logistic Regression)"]},"1111":{"title":"6.6 高级优化","titles":["第3周","六、逻辑回归(Logistic Regression)"]},"1112":{"title":"6.7 多类别分类：一对多","titles":["第3周","六、逻辑回归(Logistic Regression)"]},"1113":{"title":"七、正则化(Regularization)","titles":["第3周"]},"1114":{"title":"7.1 过拟合的问题","titles":["第3周","七、正则化(Regularization)"]},"1115":{"title":"7.2 代价函数","titles":["第3周","七、正则化(Regularization)"]},"1116":{"title":"7.3 正则化线性回归","titles":["第3周","七、正则化(Regularization)"]},"1117":{"title":"7.4 正则化的逻辑回归模型","titles":["第3周","七、正则化(Regularization)"]},"1118":{"title":"第5周","titles":[]},"1119":{"title":"九、神经网络的学习(Neural Networks: Learning)","titles":["第5周"]},"1120":{"title":"9.1 代价函数","titles":["第5周","九、神经网络的学习(Neural Networks: Learning)"]},"1121":{"title":"9.2 反向传播算法","titles":["第5周","九、神经网络的学习(Neural Networks: Learning)"]},"1122":{"title":"9.3 反向传播算法的直观理解","titles":["第5周","九、神经网络的学习(Neural Networks: Learning)"]},"1123":{"title":"9.4 实现注意：展开参数","titles":["第5周","九、神经网络的学习(Neural Networks: Learning)"]},"1124":{"title":"9.5 梯度检验","titles":["第5周","九、神经网络的学习(Neural Networks: Learning)"]},"1125":{"title":"9.6 随机初始化","titles":["第5周","九、神经网络的学习(Neural Networks: Learning)"]},"1126":{"title":"9.7 综合起来","titles":["第5周","九、神经网络的学习(Neural Networks: Learning)"]},"1127":{"title":"9.8 自主驾驶","titles":["第5周","九、神经网络的学习(Neural Networks: Learning)"]},"1128":{"title":"第6周","titles":[]},"1129":{"title":"10.1 决定下一步做什么","titles":["第6周"]},"1130":{"title":"10.2 评估一个假设","titles":["第6周"]},"1131":{"title":"10.3 模型选择和交叉验证集","titles":["第6周"]},"1132":{"title":"10.4 诊断偏差和方差","titles":["第6周"]},"1133":{"title":"10.5 正则化和偏差/方差","titles":["第6周"]},"1134":{"title":"10.6 学习曲线","titles":["第6周"]},"1135":{"title":"10.7 决定下一步做什么","titles":["第6周"]},"1136":{"title":"十一、机器学习系统的设计(Machine Learning System Design)","titles":["第6周"]},"1137":{"title":"11.1 首先要做什么","titles":["第6周","十一、机器学习系统的设计(Machine Learning System Design)"]},"1138":{"title":"11.2 误差分析","titles":["第6周","十一、机器学习系统的设计(Machine Learning System Design)"]},"1139":{"title":"11.3 类偏斜的误差度量","titles":["第6周","十一、机器学习系统的设计(Machine Learning System Design)"]},"1140":{"title":"11.4 查准率和查全率之间的权衡","titles":["第6周","十一、机器学习系统的设计(Machine Learning System Design)"]},"1141":{"title":"11.5 机器学习的数据","titles":["第6周","十一、机器学习系统的设计(Machine Learning System Design)"]},"1142":{"title":"第7周","titles":[]},"1143":{"title":"12.1 优化目标","titles":["第7周"]},"1144":{"title":"12.2 大边界的直观理解","titles":["第7周"]},"1145":{"title":"12.3 大边界分类背后的数学（选修）","titles":["第7周"]},"1146":{"title":"12.4 核函数1","titles":["第7周"]},"1147":{"title":"12.5 核函数2","titles":["第7周"]},"1148":{"title":"12.6 使用支持向量机","titles":["第7周"]},"1149":{"title":"第8周","titles":[]},"1150":{"title":"13.1 无监督学习：简介","titles":["第8周"]},"1151":{"title":"13.2 K-均值算法","titles":["第8周"]},"1152":{"title":"13.3 优化目标","titles":["第8周"]},"1153":{"title":"13.4 随机初始化","titles":["第8周"]},"1154":{"title":"13.5 选择聚类数","titles":["第8周"]},"1155":{"title":"十四、降维(Dimensionality Reduction)","titles":["第8周"]},"1156":{"title":"14.1 动机一：数据压缩","titles":["第8周","十四、降维(Dimensionality Reduction)"]},"1157":{"title":"14.2 动机二：数据可视化","titles":["第8周","十四、降维(Dimensionality Reduction)"]},"1158":{"title":"14.3 主成分分析问题","titles":["第8周","十四、降维(Dimensionality Reduction)"]},"1159":{"title":"14.4 主成分分析算法","titles":["第8周","十四、降维(Dimensionality Reduction)"]},"1160":{"title":"14.5 选择主成分的数量","titles":["第8周","十四、降维(Dimensionality Reduction)"]},"1161":{"title":"14.6 重建的压缩表示","titles":["第8周","十四、降维(Dimensionality Reduction)"]},"1162":{"title":"14.7 主成分分析法的应用建议","titles":["第8周","十四、降维(Dimensionality Reduction)"]},"1163":{"title":"第10周","titles":[]},"1164":{"title":"17.1 大型数据集的学习","titles":["第10周"]},"1165":{"title":"17.2 随机梯度下降法","titles":["第10周"]},"1166":{"title":"17.3 小批量梯度下降","titles":["第10周"]},"1167":{"title":"17.4 随机梯度下降收敛","titles":["第10周"]},"1168":{"title":"17.5 在线学习","titles":["第10周"]},"1169":{"title":"17.6 映射化简和数据并行","titles":["第10周"]},"1170":{"title":"十八、应用实例：图片文字识别(Application Example: Photo OCR)","titles":["第10周"]},"1171":{"title":"18.1 问题描述和流程图","titles":["第10周","十八、应用实例：图片文字识别(Application Example: Photo OCR)"]},"1172":{"title":"18.2 滑动窗口","titles":["第10周","十八、应用实例：图片文字识别(Application Example: Photo OCR)"]},"1173":{"title":"18.3 获取大量数据和人工数据","titles":["第10周","十八、应用实例：图片文字识别(Application Example: Photo OCR)"]},"1174":{"title":"18.4 上限分析：哪部分管道的接下去做","titles":["第10周","十八、应用实例：图片文字识别(Application Example: Photo OCR)"]},"1175":{"title":"十九、总结(Conclusion)","titles":["第10周"]},"1176":{"title":"19.1 总结和致谢","titles":["第10周","十九、总结(Conclusion)"]},"1177":{"title":"第9周","titles":[]},"1178":{"title":"15.1 问题的动机","titles":["第9周"]},"1179":{"title":"15.2 高斯分布","titles":["第9周"]},"1180":{"title":"15.3 算法","titles":["第9周"]},"1181":{"title":"15.4 开发和评价一个异常检测系统","titles":["第9周"]},"1182":{"title":"15.5 异常检测与监督学习对比","titles":["第9周"]},"1183":{"title":"15.6 选择特征","titles":["第9周"]},"1184":{"title":"15.7 多元高斯分布（选修）","titles":["第9周"]},"1185":{"title":"15.8 使用多元高斯分布进行异常检测（可选）","titles":["第9周"]},"1186":{"title":"十六、推荐系统(Recommender Systems)","titles":["第9周"]},"1187":{"title":"16.1 问题形式化","titles":["第9周","十六、推荐系统(Recommender Systems)"]},"1188":{"title":"16.2 基于内容的推荐系统","titles":["第9周","十六、推荐系统(Recommender Systems)"]},"1189":{"title":"16.3 协同过滤","titles":["第9周","十六、推荐系统(Recommender Systems)"]},"1190":{"title":"16.4 协同过滤算法","titles":["第9周","十六、推荐系统(Recommender Systems)"]},"1191":{"title":"16.5 向量化：低秩矩阵分解","titles":["第9周","十六、推荐系统(Recommender Systems)"]},"1192":{"title":"16.6 推行工作上的细节：均值归一化","titles":["第9周","十六、推荐系统(Recommender Systems)"]},"1193":{"title":"斯坦福大学 2014 机器学习教程中文笔记目录","titles":[]},"1194":{"title":"MongoDB 技术解析：从单机到分布式的存储引擎与架构设计","titles":[]},"1195":{"title":"🟢 基础概念","titles":["MongoDB 技术解析：从单机到分布式的存储引擎与架构设计"]},"1196":{"title":"📄 文档（Document）与集合（Collection）","titles":["MongoDB 技术解析：从单机到分布式的存储引擎与架构设计"]},"1197":{"title":"🗂️ BSON 编码","titles":["MongoDB 技术解析：从单机到分布式的存储引擎与架构设计"]},"1198":{"title":"💾 数据页结构与 .wt 文件","titles":["MongoDB 技术解析：从单机到分布式的存储引擎与架构设计"]},"1199":{"title":"🌳 变种 B+ 树索引","titles":["MongoDB 技术解析：从单机到分布式的存储引擎与架构设计"]},"1200":{"title":"🔄 并发控制：写时复制 (Copy On Write)","titles":["MongoDB 技术解析：从单机到分布式的存储引擎与架构设计"]},"1201":{"title":"🧩 缓存策略（Cache + LRU 淘汰）","titles":["MongoDB 技术解析：从单机到分布式的存储引擎与架构设计"]},"1202":{"title":"📝 持久化保障","titles":["MongoDB 技术解析：从单机到分布式的存储引擎与架构设计"]},"1203":{"title":"⚙️ WiredTiger 与 Server 层关系","titles":["MongoDB 技术解析：从单机到分布式的存储引擎与架构设计"]},"1204":{"title":"🔑 存储引擎的定位与接口","titles":["MongoDB 技术解析：从单机到分布式的存储引擎与架构设计"]},"1205":{"title":"🏗️ 单机 MongoDB 的本质（对比 MySQL）","titles":["MongoDB 技术解析：从单机到分布式的存储引擎与架构设计"]},"1206":{"title":"📡 分片集群 (Sharding)","titles":["MongoDB 技术解析：从单机到分布式的存储引擎与架构设计"]},"1207":{"title":"分片逻辑","titles":["MongoDB 技术解析：从单机到分布式的存储引擎与架构设计","📡 分片集群 (Sharding)"]},"1208":{"title":"🧭 路由服务与配置中心","titles":["MongoDB 技术解析：从单机到分布式的存储引擎与架构设计"]},"1209":{"title":"🧩 副本集 Replica Set","titles":["MongoDB 技术解析：从单机到分布式的存储引擎与架构设计"]},"1210":{"title":"🌍 分布式 MongoDB 集群","titles":["MongoDB 技术解析：从单机到分布式的存储引擎与架构设计"]},"1211":{"title":"✅ 总结","titles":["MongoDB 技术解析：从单机到分布式的存储引擎与架构设计"]},"1212":{"title":"Python基础语法学习笔记","titles":[]},"1213":{"title":"一、变量与数据类型","titles":["Python基础语法学习笔记"]},"1214":{"title":"1. 变量的定义与命名","titles":["Python基础语法学习笔记","一、变量与数据类型"]},"1215":{"title":"命名规范建议（符合 PEP8）：","titles":["Python基础语法学习笔记","一、变量与数据类型","1. 变量的定义与命名"]},"1216":{"title":"2. 常见数据类型与说明","titles":["Python基础语法学习笔记","一、变量与数据类型"]},"1217":{"title":"二、运算符","titles":["Python基础语法学习笔记"]},"1218":{"title":"1. 算术运算符","titles":["Python基础语法学习笔记","二、运算符"]},"1219":{"title":"2. 比较运算符（返回布尔值）","titles":["Python基础语法学习笔记","二、运算符"]},"1220":{"title":"3. 逻辑运算符","titles":["Python基础语法学习笔记","二、运算符"]},"1221":{"title":"4. 成员运算符","titles":["Python基础语法学习笔记","二、运算符"]},"1222":{"title":"三、流程控制语句","titles":["Python基础语法学习笔记"]},"1223":{"title":"1. 条件语句 if / elif / else","titles":["Python基础语法学习笔记","三、流程控制语句"]},"1224":{"title":"2. 循环语句 for 和 while","titles":["Python基础语法学习笔记","三、流程控制语句"]},"1225":{"title":"for 循环（适合遍历列表、字符串、range）","titles":["Python基础语法学习笔记","三、流程控制语句","2. 循环语句 for 和 while"]},"1226":{"title":"while 循环（条件满足就继续执行）","titles":["Python基础语法学习笔记","三、流程控制语句","2. 循环语句 for 和 while"]},"1227":{"title":"3. 循环控制语句","titles":["Python基础语法学习笔记","三、流程控制语句"]},"1228":{"title":"四、函数定义与使用","titles":["Python基础语法学习笔记"]},"1229":{"title":"1. 定义函数","titles":["Python基础语法学习笔记","四、函数定义与使用"]},"1230":{"title":"2. 参数类型","titles":["Python基础语法学习笔记","四、函数定义与使用"]},"1231":{"title":"五、常用内建函数与输入输出","titles":["Python基础语法学习笔记"]},"1232":{"title":"常用函数：","titles":["Python基础语法学习笔记","五、常用内建函数与输入输出"]},"1233":{"title":"示例：","titles":["Python基础语法学习笔记","五、常用内建函数与输入输出"]},"1234":{"title":"六、模块与导入","titles":["Python基础语法学习笔记"]},"1235":{"title":"导入模块的方式","titles":["Python基础语法学习笔记","六、模块与导入"]},"1236":{"title":"七、异常处理机制","titles":["Python基础语法学习笔记"]},"1237":{"title":"🧠 Python进阶语法与编程技巧","titles":[]},"1238":{"title":"一、函数式编程技巧","titles":["🧠 Python进阶语法与编程技巧"]},"1239":{"title":"1. lambda 匿名函数","titles":["🧠 Python进阶语法与编程技巧","一、函数式编程技巧"]},"1240":{"title":"2. map / filter / reduce","titles":["🧠 Python进阶语法与编程技巧","一、函数式编程技巧"]},"1241":{"title":"二、列表/字典推导式","titles":["🧠 Python进阶语法与编程技巧"]},"1242":{"title":"列表推导式","titles":["🧠 Python进阶语法与编程技巧","二、列表/字典推导式"]},"1243":{"title":"字典推导式","titles":["🧠 Python进阶语法与编程技巧","二、列表/字典推导式"]},"1244":{"title":"三、装饰器（Decorator）","titles":["🧠 Python进阶语法与编程技巧"]},"1245":{"title":"四、生成器与迭代器","titles":["🧠 Python进阶语法与编程技巧"]},"1246":{"title":"1. 生成器函数（yield）","titles":["🧠 Python进阶语法与编程技巧","四、生成器与迭代器"]},"1247":{"title":"2. 生成器表达式","titles":["🧠 Python进阶语法与编程技巧","四、生成器与迭代器"]},"1248":{"title":"五、异常处理进阶","titles":["🧠 Python进阶语法与编程技巧"]},"1249":{"title":"自定义异常类","titles":["🧠 Python进阶语法与编程技巧","五、异常处理进阶"]},"1250":{"title":"多种异常捕获","titles":["🧠 Python进阶语法与编程技巧","五、异常处理进阶"]},"1251":{"title":"六、上下文管理器（with 语句）","titles":["🧠 Python进阶语法与编程技巧"]},"1252":{"title":"文件读写的标准方式：","titles":["🧠 Python进阶语法与编程技巧","六、上下文管理器（with 语句）"]},"1253":{"title":"七、类与对象进阶（OOP）","titles":["🧠 Python进阶语法与编程技巧"]},"1254":{"title":"1. 类方法与静态方法","titles":["🧠 Python进阶语法与编程技巧","七、类与对象进阶（OOP）"]},"1255":{"title":"2. 属性装饰器","titles":["🧠 Python进阶语法与编程技巧","七、类与对象进阶（OOP）"]},"1256":{"title":"八、模块与包管理","titles":["🧠 Python进阶语法与编程技巧"]},"1257":{"title":"自定义模块与导入","titles":["🧠 Python进阶语法与编程技巧","八、模块与包管理"]},"1258":{"title":"包结构与 __init__.py","titles":["🧠 Python进阶语法与编程技巧","八、模块与包管理"]},"1259":{"title":"九、类型注解（Python 3.5+）","titles":["🧠 Python进阶语法与编程技巧"]},"1260":{"title":"十、代码性能与调试","titles":["🧠 Python进阶语法与编程技巧"]},"1261":{"title":"1. 简易性能测试","titles":["🧠 Python进阶语法与编程技巧","十、代码性能与调试"]},"1262":{"title":"2. 使用 timeit 模块","titles":["🧠 Python进阶语法与编程技巧","十、代码性能与调试"]},"1263":{"title":"十一、常见标准库","titles":["🧠 Python进阶语法与编程技巧"]},"1264":{"title":"十二、建议写法与风格规范","titles":["🧠 Python进阶语法与编程技巧"]},"1265":{"title":"🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","titles":[]},"1266":{"title":"1. pip + requirements.txt","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）"]},"1267":{"title":"介绍","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","1. pip + requirements.txt"]},"1268":{"title":"安装","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","1. pip + requirements.txt"]},"1269":{"title":"入门示例","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","1. pip + requirements.txt"]},"1270":{"title":"2. venv / virtualenv","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）"]},"1271":{"title":"介绍","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","2. venv / virtualenv"]},"1272":{"title":"安装","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","2. venv / virtualenv"]},"1273":{"title":"入门示例","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","2. venv / virtualenv"]},"1274":{"title":"3. conda","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）"]},"1275":{"title":"介绍","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","3. conda"]},"1276":{"title":"安装","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","3. conda"]},"1277":{"title":"入门示例","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","3. conda"]},"1278":{"title":"4. pipenv","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）"]},"1279":{"title":"介绍","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","4. pipenv"]},"1280":{"title":"安装","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","4. pipenv"]},"1281":{"title":"入门示例","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","4. pipenv"]},"1282":{"title":"5. Poetry","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）"]},"1283":{"title":"介绍","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","5. Poetry"]},"1284":{"title":"安装","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","5. Poetry"]},"1285":{"title":"入门示例","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","5. Poetry"]},"1286":{"title":"6. PDM","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）"]},"1287":{"title":"介绍","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","6. PDM"]},"1288":{"title":"安装","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","6. PDM"]},"1289":{"title":"入门示例","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","6. PDM"]},"1290":{"title":"7. uv","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）"]},"1291":{"title":"介绍","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","7. uv"]},"1292":{"title":"安装","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","7. uv"]},"1293":{"title":"入门示例","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）","7. uv"]},"1294":{"title":"总结","titles":["🚀 Python项目管理工具全景总结——从pip到uv（含入门教程）"]},"1295":{"title":"🐍 Python语言介绍：为何它成为“万能胶水语言”？","titles":[]},"1296":{"title":"🔍 一、什么是 Python？","titles":["🐍 Python语言介绍：为何它成为“万能胶水语言”？"]},"1297":{"title":"🛠 二、Python 可以做什么？","titles":["🐍 Python语言介绍：为何它成为“万能胶水语言”？"]},"1298":{"title":"🌱 三、为什么初学者适合学习 Python？","titles":["🐍 Python语言介绍：为何它成为“万能胶水语言”？"]},"1299":{"title":"✅ 上手容易","titles":["🐍 Python语言介绍：为何它成为“万能胶水语言”？","🌱 三、为什么初学者适合学习 Python？"]},"1300":{"title":"✅ 社区活跃","titles":["🐍 Python语言介绍：为何它成为“万能胶水语言”？","🌱 三、为什么初学者适合学习 Python？"]},"1301":{"title":"✅ 可做项目多","titles":["🐍 Python语言介绍：为何它成为“万能胶水语言”？","🌱 三、为什么初学者适合学习 Python？"]},"1302":{"title":"⚙️ 四、Python 的基本特性","titles":["🐍 Python语言介绍：为何它成为“万能胶水语言”？"]},"1303":{"title":"📈 五、Python 的发展现状","titles":["🐍 Python语言介绍：为何它成为“万能胶水语言”？"]},"1304":{"title":"🚀 六、如何开始学习 Python？","titles":["🐍 Python语言介绍：为何它成为“万能胶水语言”？"]},"1305":{"title":"🎯 结语：Python 是开启编程世界的一把钥匙","titles":["🐍 Python语言介绍：为何它成为“万能胶水语言”？"]},"1306":{"title":"📚 推荐资源","titles":["🐍 Python语言介绍：为何它成为“万能胶水语言”？"]},"1307":{"title":"深入 GitHub Actions：核心机制深入解读与实战示例","titles":[]},"1308":{"title":"一、核心概念深入解构","titles":["深入 GitHub Actions：核心机制深入解读与实战示例"]},"1309":{"title":"1. Workflow（工作流）","titles":["深入 GitHub Actions：核心机制深入解读与实战示例","一、核心概念深入解构"]},"1310":{"title":"2. Job（作业）","titles":["深入 GitHub Actions：核心机制深入解读与实战示例","一、核心概念深入解构"]},"1311":{"title":"3. Step（步骤）与 Action（动作）","titles":["深入 GitHub Actions：核心机制深入解读与实战示例","一、核心概念深入解构"]},"1312":{"title":"4. Runner（运行器）","titles":["深入 GitHub Actions：核心机制深入解读与实战示例","一、核心概念深入解构"]},"1313":{"title":"5. Matrix（矩阵策略）","titles":["深入 GitHub Actions：核心机制深入解读与实战示例","一、核心概念深入解构"]},"1314":{"title":"6. 注释机制","titles":["深入 GitHub Actions：核心机制深入解读与实战示例","一、核心概念深入解构"]},"1315":{"title":"二、带注释的完整 CI + 矩阵 + 发布 Workflow 示例","titles":["深入 GitHub Actions：核心机制深入解读与实战示例"]},"1316":{"title":"Git 学习笔记","titles":[]},"1317":{"title":"1. Git 基础概念","titles":["Git 学习笔记"]},"1318":{"title":"1.1 什么是 Git？","titles":["Git 学习笔记","1. Git 基础概念"]},"1319":{"title":"1.2 Git 的四个核心区域","titles":["Git 学习笔记","1. Git 基础概念"]},"1320":{"title":"1.3 Git 对象模型","titles":["Git 学习笔记","1. Git 基础概念"]},"1321":{"title":"1.4 提交（Commit）","titles":["Git 学习笔记","1. Git 基础概念"]},"1322":{"title":"1.5 分支（Branch）","titles":["Git 学习笔记","1. Git 基础概念"]},"1323":{"title":"1.6 HEAD 指针","titles":["Git 学习笔记","1. Git 基础概念"]},"1324":{"title":"1.7 远程仓库（Remote）","titles":["Git 学习笔记","1. Git 基础概念"]},"1325":{"title":"1.8 Git 工作流","titles":["Git 学习笔记","1. Git 基础概念"]},"1326":{"title":"2. Git 常用命令","titles":["Git 学习笔记"]},"1327":{"title":"2.1 初始化与克隆","titles":["Git 学习笔记","2. Git 常用命令"]},"1328":{"title":"2.2 基本操作","titles":["Git 学习笔记","2. Git 常用命令"]},"1329":{"title":"2.3 分支管理","titles":["Git 学习笔记","2. Git 常用命令"]},"1330":{"title":"2.4 远程仓库操作","titles":["Git 学习笔记","2. Git 常用命令"]},"1331":{"title":"3. Git 进阶操作","titles":["Git 学习笔记"]},"1332":{"title":"3.1 暂存修改","titles":["Git 学习笔记","3. Git 进阶操作"]},"1333":{"title":"3.2 回退与撤销","titles":["Git 学习笔记","3. Git 进阶操作"]},"1334":{"title":"3.3 Rebase（变基）","titles":["Git 学习笔记","3. Git 进阶操作"]},"1335":{"title":"3.4 Tag（标签）","titles":["Git 学习笔记","3. Git 进阶操作"]},"1336":{"title":"4. Git 实用技巧","titles":["Git 学习笔记"]},"1337":{"title":"5. 常见问题与解决方法","titles":["Git 学习笔记"]},"1338":{"title":"🐳 Docker 学习笔记","titles":[]},"1339":{"title":"1. Docker 是什么？","titles":["🐳 Docker 学习笔记"]},"1340":{"title":"2. Docker 架构原理","titles":["🐳 Docker 学习笔记"]},"1341":{"title":"3. Docker 命令基础","titles":["🐳 Docker 学习笔记"]},"1342":{"title":"镜像相关","titles":["🐳 Docker 学习笔记","3. Docker 命令基础"]},"1343":{"title":"容器相关","titles":["🐳 Docker 学习笔记","3. Docker 命令基础"]},"1344":{"title":"日志与进入容器","titles":["🐳 Docker 学习笔记","3. Docker 命令基础"]},"1345":{"title":"数据卷与网络","titles":["🐳 Docker 学习笔记","3. Docker 命令基础"]},"1346":{"title":"4. Docker 容器和虚拟机的区别","titles":["🐳 Docker 学习笔记"]},"1347":{"title":"5. Docker Compose 是什么？","titles":["🐳 Docker 学习笔记"]},"1348":{"title":"6. Docker Swarm 是什么？","titles":["🐳 Docker 学习笔记"]},"1349":{"title":"7. Docker Compose 和 Docker Swarm 的区别","titles":["🐳 Docker 学习笔记"]},"1350":{"title":"8. Docker 和 Kubernetes (k8s) 的关系","titles":["🐳 Docker 学习笔记"]},"1351":{"title":"9. Docker Swarm 和 Kubernetes (k8s) 的差异","titles":["🐳 Docker 学习笔记"]},"1352":{"title":"容器化与分布式集群","titles":[]},"1353":{"title":"从虚拟机到容器","titles":["容器化与分布式集群"]},"1354":{"title":"容器化的意义","titles":["容器化与分布式集群"]},"1355":{"title":"分布式集群的演进","titles":["容器化与分布式集群"]},"1356":{"title":"容器化与集群化的关系","titles":["容器化与分布式集群"]},"1357":{"title":"展望","titles":["容器化与分布式集群"]},"1358":{"title":"Nginx 技术博客","titles":[]},"1359":{"title":"一、Nginx 简介","titles":["Nginx 技术博客"]},"1360":{"title":"二、核心概念","titles":["Nginx 技术博客"]},"1361":{"title":"1. 正向代理与反向代理","titles":["Nginx 技术博客","二、核心概念"]},"1362":{"title":"2. 负载均衡","titles":["Nginx 技术博客","二、核心概念"]},"1363":{"title":"3. 静态资源服务","titles":["Nginx 技术博客","二、核心概念"]},"1364":{"title":"三、Nginx 配置文件结构","titles":["Nginx 技术博客"]},"1365":{"title":"配置解析：","titles":["Nginx 技术博客","三、Nginx 配置文件结构"]},"1366":{"title":"四、常见应用场景","titles":["Nginx 技术博客"]},"1367":{"title":"1. 静态资源服务器","titles":["Nginx 技术博客","四、常见应用场景"]},"1368":{"title":"2. 反向代理","titles":["Nginx 技术博客","四、常见应用场景"]},"1369":{"title":"3. 负载均衡","titles":["Nginx 技术博客","四、常见应用场景"]},"1370":{"title":"4. HTTPS 配置（SSL 证书）","titles":["Nginx 技术博客","四、常见应用场景"]},"1371":{"title":"五、性能优化实践","titles":["Nginx 技术博客"]},"1372":{"title":"六、Nginx 与 DevOps","titles":["Nginx 技术博客"]},"1373":{"title":"Kubernetes 学习笔记","titles":[]},"1374":{"title":"1. 什么是 Kubernetes？","titles":["Kubernetes 学习笔记"]},"1375":{"title":"2. Kubernetes 架构原理","titles":["Kubernetes 学习笔记"]},"1376":{"title":"2.1 控制平面（Control Plane）","titles":["Kubernetes 学习笔记","2. Kubernetes 架构原理"]},"1377":{"title":"2.2 工作节点（Worker Node）","titles":["Kubernetes 学习笔记","2. Kubernetes 架构原理"]},"1378":{"title":"2.3 架构图（简化）","titles":["Kubernetes 学习笔记","2. Kubernetes 架构原理"]},"1379":{"title":"3. Kubernetes 核心概念","titles":["Kubernetes 学习笔记"]},"1380":{"title":"3.1 Pod","titles":["Kubernetes 学习笔记","3. Kubernetes 核心概念"]},"1381":{"title":"3.2 Cluster","titles":["Kubernetes 学习笔记","3. Kubernetes 核心概念"]},"1382":{"title":"3.3 ReplicaSet","titles":["Kubernetes 学习笔记","3. Kubernetes 核心概念"]},"1383":{"title":"3.4 Deployment","titles":["Kubernetes 学习笔记","3. Kubernetes 核心概念"]},"1384":{"title":"3.5 Service","titles":["Kubernetes 学习笔记","3. Kubernetes 核心概念"]},"1385":{"title":"3.6 ConfigMap &amp; Secret","titles":["Kubernetes 学习笔记","3. Kubernetes 核心概念"]},"1386":{"title":"3.7 Volume","titles":["Kubernetes 学习笔记","3. Kubernetes 核心概念"]},"1387":{"title":"3.8 Namespace","titles":["Kubernetes 学习笔记","3. Kubernetes 核心概念"]},"1388":{"title":"4. Kubernetes YAML 配置","titles":["Kubernetes 学习笔记"]},"1389":{"title":"4.1 Pod 示例","titles":["Kubernetes 学习笔记","4. Kubernetes YAML 配置"]},"1390":{"title":"4.2 Deployment 示例","titles":["Kubernetes 学习笔记","4. Kubernetes YAML 配置"]},"1391":{"title":"4.3 Service 示例","titles":["Kubernetes 学习笔记","4. Kubernetes YAML 配置"]},"1392":{"title":"5. Kubernetes 常用命令","titles":["Kubernetes 学习笔记"]},"1393":{"title":"6. Kubernetes 部署方式","titles":["Kubernetes 学习笔记"]},"1394":{"title":"7. Kubernetes 与 Docker 的关系","titles":["Kubernetes 学习笔记"]},"1395":{"title":"8. Kubernetes 与 Docker Swarm 的区别","titles":["Kubernetes 学习笔记"]},"1396":{"title":"TypeScript 学习笔记","titles":[]},"1397":{"title":"1. 类型声明","titles":["TypeScript 学习笔记"]},"1398":{"title":"基本语法","titles":["TypeScript 学习笔记","1. 类型声明"]},"1399":{"title":"类型断言","titles":["TypeScript 学习笔记","1. 类型声明"]},"1400":{"title":"2. 类型推断","titles":["TypeScript 学习笔记"]},"1401":{"title":"自动类型推断","titles":["TypeScript 学习笔记","2. 类型推断"]},"1402":{"title":"上下文类型推断","titles":["TypeScript 学习笔记","2. 类型推断"]},"1403":{"title":"3. 类型总览","titles":["TypeScript 学习笔记"]},"1404":{"title":"基础类型分类","titles":["TypeScript 学习笔记","3. 类型总览"]},"1405":{"title":"复合类型","titles":["TypeScript 学习笔记","3. 类型总览"]},"1406":{"title":"4. 常用类型","titles":["TypeScript 学习笔记"]},"1407":{"title":"联合类型（Union Types）","titles":["TypeScript 学习笔记","4. 常用类型"]},"1408":{"title":"交叉类型（Intersection Types）","titles":["TypeScript 学习笔记","4. 常用类型"]},"1409":{"title":"条件类型","titles":["TypeScript 学习笔记","4. 常用类型"]},"1410":{"title":"映射类型","titles":["TypeScript 学习笔记","4. 常用类型"]},"1411":{"title":"5. 自定义类型","titles":["TypeScript 学习笔记"]},"1412":{"title":"类型别名（Type Aliases）","titles":["TypeScript 学习笔记","5. 自定义类型"]},"1413":{"title":"枚举（Enums）","titles":["TypeScript 学习笔记","5. 自定义类型"]},"1414":{"title":"字面量类型","titles":["TypeScript 学习笔记","5. 自定义类型"]},"1415":{"title":"6. 抽象类","titles":["TypeScript 学习笔记"]},"1416":{"title":"基本抽象类","titles":["TypeScript 学习笔记","6. 抽象类"]},"1417":{"title":"抽象类的高级用法","titles":["TypeScript 学习笔记","6. 抽象类"]},"1418":{"title":"7. 接口","titles":["TypeScript 学习笔记"]},"1419":{"title":"基本接口","titles":["TypeScript 学习笔记","7. 接口"]},"1420":{"title":"函数接口","titles":["TypeScript 学习笔记","7. 接口"]},"1421":{"title":"可索引接口","titles":["TypeScript 学习笔记","7. 接口"]},"1422":{"title":"类接口","titles":["TypeScript 学习笔记","7. 接口"]},"1423":{"title":"接口继承","titles":["TypeScript 学习笔记","7. 接口"]},"1424":{"title":"8. 属性修饰符","titles":["TypeScript 学习笔记"]},"1425":{"title":"访问修饰符","titles":["TypeScript 学习笔记","8. 属性修饰符"]},"1426":{"title":"readonly 修饰符","titles":["TypeScript 学习笔记","8. 属性修饰符"]},"1427":{"title":"可选修饰符","titles":["TypeScript 学习笔记","8. 属性修饰符"]},"1428":{"title":"参数属性","titles":["TypeScript 学习笔记","8. 属性修饰符"]},"1429":{"title":"9. 泛型","titles":["TypeScript 学习笔记"]},"1430":{"title":"基本泛型函数","titles":["TypeScript 学习笔记","9. 泛型"]},"1431":{"title":"泛型接口","titles":["TypeScript 学习笔记","9. 泛型"]},"1432":{"title":"泛型类","titles":["TypeScript 学习笔记","9. 泛型"]},"1433":{"title":"泛型约束","titles":["TypeScript 学习笔记","9. 泛型"]},"1434":{"title":"条件类型与泛型","titles":["TypeScript 学习笔记","9. 泛型"]},"1435":{"title":"映射类型与泛型","titles":["TypeScript 学习笔记","9. 泛型"]},"1436":{"title":"学习建议","titles":["TypeScript 学习笔记"]},"1437":{"title":"1. Vue3简介","titles":[]},"1438":{"title":"1.1. 【性能的提升】","titles":["1. Vue3简介"]},"1439":{"title":"1.2.【 源码的升级】","titles":["1. Vue3简介"]},"1440":{"title":"1.3. 【拥抱TypeScript】","titles":["1. Vue3简介"]},"1441":{"title":"1.4. 【新的特性】","titles":["1. Vue3简介"]},"1442":{"title":"2. 创建Vue3工程","titles":[]},"1443":{"title":"2.1. 【基于 vue-cli 创建】","titles":["2. 创建Vue3工程"]},"1444":{"title":"2.2. 【基于 vite 创建】(推荐)","titles":["2. 创建Vue3工程"]},"1445":{"title":"2.3. 【一个简单的效果】","titles":["2. 创建Vue3工程"]},"1446":{"title":"3. Vue3核心语法","titles":[]},"1447":{"title":"3.1.  【OptionsAPI 与 CompositionAPI】","titles":["3. Vue3核心语法"]},"1448":{"title":"Options API 的弊端","titles":["3. Vue3核心语法","3.1.  【OptionsAPI 与 CompositionAPI】"]},"1449":{"title":"Composition API 的优势","titles":["3. Vue3核心语法","3.1.  【OptionsAPI 与 CompositionAPI】"]},"1450":{"title":"3.2. 【拉开序幕的 setup】","titles":["3. Vue3核心语法"]},"1451":{"title":"setup 概述","titles":["3. Vue3核心语法","3.2. 【拉开序幕的 setup】"]},"1452":{"title":"setup 的返回值","titles":["3. Vue3核心语法","3.2. 【拉开序幕的 setup】"]},"1453":{"title":"setup 与 Options API 的关系","titles":["3. Vue3核心语法","3.2. 【拉开序幕的 setup】"]},"1454":{"title":"setup 语法糖","titles":["3. Vue3核心语法","3.2. 【拉开序幕的 setup】"]},"1455":{"title":"3.3. 【ref 创建：基本类型的响应式数据】","titles":["3. Vue3核心语法"]},"1456":{"title":"3.4. 【reactive 创建：对象类型的响应式数据】","titles":["3. Vue3核心语法"]},"1457":{"title":"3.5. 【ref 创建：对象类型的响应式数据】","titles":["3. Vue3核心语法"]},"1458":{"title":"3.6. 【ref 对比 reactive】","titles":["3. Vue3核心语法"]},"1459":{"title":"3.7. 【toRefs 与 toRef】","titles":["3. Vue3核心语法"]},"1460":{"title":"3.8. 【computed】","titles":["3. Vue3核心语法"]},"1461":{"title":"3.9.【watch】","titles":["3. Vue3核心语法"]},"1462":{"title":"* 情况一","titles":["3. Vue3核心语法","3.9.【watch】"]},"1463":{"title":"* 情况二","titles":["3. Vue3核心语法","3.9.【watch】"]},"1464":{"title":"*  情况三","titles":["3. Vue3核心语法","3.9.【watch】"]},"1465":{"title":"* 情况四","titles":["3. Vue3核心语法","3.9.【watch】"]},"1466":{"title":"* 情况五","titles":["3. Vue3核心语法","3.9.【watch】"]},"1467":{"title":"3.10. 【watchEffect】","titles":["3. Vue3核心语法"]},"1468":{"title":"3.11. 【标签的 ref 属性】","titles":["3. Vue3核心语法"]},"1469":{"title":"3.12. 【props】","titles":["3. Vue3核心语法"]},"1470":{"title":"3.13. 【生命周期】","titles":["3. Vue3核心语法"]},"1471":{"title":"3.14. 【自定义hook】","titles":["3. Vue3核心语法"]},"1472":{"title":"4. 路由","titles":[]},"1473":{"title":"4.1. 【对路由的理解】","titles":["4. 路由"]},"1474":{"title":"4.2. 【基本切换效果】","titles":["4. 路由"]},"1475":{"title":"4.3. 【两个注意点】","titles":["4. 路由"]},"1476":{"title":"4.4.【路由器工作模式】","titles":["4. 路由"]},"1477":{"title":"4.5. 【to的两种写法】","titles":["4. 路由"]},"1478":{"title":"4.6. 【命名路由】","titles":["4. 路由"]},"1479":{"title":"4.7. 【嵌套路由】","titles":["4. 路由"]},"1480":{"title":"4.8. 【路由传参】","titles":["4. 路由"]},"1481":{"title":"query参数","titles":["4. 路由","4.8. 【路由传参】"]},"1482":{"title":"params参数","titles":["4. 路由","4.8. 【路由传参】"]},"1483":{"title":"4.9. 【路由的props配置】","titles":["4. 路由"]},"1484":{"title":"4.10. 【 replace属性】","titles":["4. 路由"]},"1485":{"title":"4.11. 【编程式导航】","titles":["4. 路由"]},"1486":{"title":"4.12. 【重定向】","titles":["4. 路由"]},"1487":{"title":"5. pinia","titles":[]},"1488":{"title":"5.1【准备一个效果】","titles":["5. pinia"]},"1489":{"title":"5.2【搭建 pinia 环境】","titles":["5. pinia"]},"1490":{"title":"5.3【存储+读取数据】","titles":["5. pinia"]},"1491":{"title":"5.4.【修改数据】(三种方式)","titles":["5. pinia"]},"1492":{"title":"5.5.【storeToRefs】","titles":["5. pinia"]},"1493":{"title":"5.6.【getters】","titles":["5. pinia"]},"1494":{"title":"5.7.【$subscribe】","titles":["5. pinia"]},"1495":{"title":"5.8. 【store组合式写法】","titles":["5. pinia"]},"1496":{"title":"6. 组件通信","titles":[]},"1497":{"title":"6.1. 【props】","titles":["6. 组件通信"]},"1498":{"title":"6.2. 【自定义事件】","titles":["6. 组件通信"]},"1499":{"title":"6.3. 【mitt】","titles":["6. 组件通信"]},"1500":{"title":"6.4.【v-model】","titles":["6. 组件通信"]},"1501":{"title":"6.5.【$attrs 】","titles":["6. 组件通信"]},"1502":{"title":"6.6. 【、refs、parent】","titles":["6. 组件通信"]},"1503":{"title":"6.7. 【provide、inject】","titles":["6. 组件通信"]},"1504":{"title":"6.8. 【pinia】","titles":["6. 组件通信"]},"1505":{"title":"6.9. 【slot】","titles":["6. 组件通信"]},"1506":{"title":"1. 默认插槽","titles":["6. 组件通信","6.9. 【slot】"]},"1507":{"title":"2. 具名插槽","titles":["6. 组件通信","6.9. 【slot】"]},"1508":{"title":"3. 作用域插槽","titles":["6. 组件通信","6.9. 【slot】"]},"1509":{"title":"7. 其它 API","titles":[]},"1510":{"title":"7.1.【shallowRef 与 shallowReactive 】","titles":["7. 其它 API"]},"1511":{"title":"shallowRef","titles":["7. 其它 API","7.1.【shallowRef 与 shallowReactive 】"]},"1512":{"title":"shallowReactive","titles":["7. 其它 API","7.1.【shallowRef 与 shallowReactive 】"]},"1513":{"title":"总结","titles":["7. 其它 API","7.1.【shallowRef 与 shallowReactive 】"]},"1514":{"title":"7.2.【readonly 与 shallowReadonly】","titles":["7. 其它 API"]},"1515":{"title":"readonly","titles":["7. 其它 API","7.2.【readonly 与 shallowReadonly】"]},"1516":{"title":"shallowReadonly","titles":["7. 其它 API","7.2.【readonly 与 shallowReadonly】"]},"1517":{"title":"7.3.【toRaw 与 markRaw】","titles":["7. 其它 API"]},"1518":{"title":"toRaw","titles":["7. 其它 API","7.3.【toRaw 与 markRaw】"]},"1519":{"title":"markRaw","titles":["7. 其它 API","7.3.【toRaw 与 markRaw】"]},"1520":{"title":"7.4.【customRef】","titles":["7. 其它 API"]},"1521":{"title":"8. Vue3新组件","titles":[]},"1522":{"title":"8.1. 【Teleport】","titles":["8. Vue3新组件"]},"1523":{"title":"8.2. 【Suspense】","titles":["8. Vue3新组件"]},"1524":{"title":"8.3.【全局API转移到应用对象】","titles":["8. Vue3新组件"]},"1525":{"title":"8.4.【其他】","titles":["8. Vue3新组件"]},"1526":{"title":"🌿 Vue.js 简介","titles":[]},"1527":{"title":"🚩 核心特性","titles":["🌿 Vue.js 简介"]},"1528":{"title":"🌐 Vue 技术生态","titles":["🌿 Vue.js 简介"]},"1529":{"title":"🧭 适用场景","titles":["🌿 Vue.js 简介"]},"1530":{"title":"🔍 与其他框架对比","titles":["🌿 Vue.js 简介"]},"1531":{"title":"❤️ 总结","titles":["🌿 Vue.js 简介"]},"1532":{"title":"🌟 前端开发：打造网页魔法师的奇妙世界","titles":[]},"1533":{"title":"什么是前端开发？","titles":["🌟 前端开发：打造网页魔法师的奇妙世界"]},"1534":{"title":"为什么说前端开发很有趣？","titles":["🌟 前端开发：打造网页魔法师的奇妙世界"]},"1535":{"title":"1. 立刻见效的成就感","titles":["🌟 前端开发：打造网页魔法师的奇妙世界","为什么说前端开发很有趣？"]},"1536":{"title":"2. 无限创意空间","titles":["🌟 前端开发：打造网页魔法师的奇妙世界","为什么说前端开发很有趣？"]},"1537":{"title":"3. 技术与设计的交叉","titles":["🌟 前端开发：打造网页魔法师的奇妙世界","为什么说前端开发很有趣？"]},"1538":{"title":"4. 巨大的社区和生态","titles":["🌟 前端开发：打造网页魔法师的奇妙世界","为什么说前端开发很有趣？"]},"1539":{"title":"前端开发的核心三剑客","titles":["🌟 前端开发：打造网页魔法师的奇妙世界"]},"1540":{"title":"未来的前端，值得期待","titles":["🌟 前端开发：打造网页魔法师的奇妙世界"]},"1541":{"title":"小结","titles":["🌟 前端开发：打造网页魔法师的奇妙世界"]},"1542":{"title":"嗨，欢迎来到我的小站 👋","titles":[]},"1543":{"title":"我最近在折腾啥？🛠️","titles":["嗨，欢迎来到我的小站 👋"]},"1544":{"title":"我的技术口味 🍜","titles":["嗨，欢迎来到我的小站 👋"]},"1545":{"title":"为什么写博客？✍️","titles":["嗨，欢迎来到我的小站 👋"]},"1546":{"title":"你会在这里看到 📚","titles":["嗨，欢迎来到我的小站 👋"]},"1547":{"title":"小目标与进行中 ✅","titles":["嗨，欢迎来到我的小站 👋"]},"1548":{"title":"本站怎么逛 🧭","titles":["嗨，欢迎来到我的小站 👋"]},"1549":{"title":"技术之外 🌿","titles":["嗨，欢迎来到我的小站 👋"]},"1550":{"title":"找到我 📬","titles":["嗨，欢迎来到我的小站 👋"]}},"dirtCount":0,"index":[["偶尔写点随笔",{"2":{"1549":1}}],["偶尔碰",{"2":{"1543":1}}],["爱把复杂问题拆小",{"2":{"1549":1}}],["爱玛",{"2":{"1465":1,"1466":1}}],["永远比十段文字有用",{"2":{"1548":1}}],["永不返回",{"2":{"1404":1}}],["鉴权",{"2":{"1547":1}}],["鉴于该算法的强大和受欢迎度",{"2":{"1143":1}}],["鉴于存在两次阳性检测",{"2":{"1035":1}}],["鉴于数据集内不同的框的位置和大小不同",{"2":{"852":1}}],["鉴于许多模型都是基于复杂而深度的架构",{"2":{"672":1}}],["鉴于上面所提框架在",{"2":{"356":1}}],["鉴于上述结果",{"2":{"95":1}}],["鉴于我们还没有训练网络",{"2":{"333":1}}],["鉴于这种扩展",{"2":{"107":1}}],["鉴于管理学习率需要很多细节",{"2":{"66":1}}],["鉴于此",{"2":{"40":1}}],["鉴于学习率下降",{"2":{"25":1}}],["鉴于参数du",{"2":{"20":1}}],["踩坑与复盘",{"2":{"1546":1}}],["踩对的点记录下来",{"2":{"1545":1}}],["刚好够用",{"2":{"1546":1}}],["刚好与函数相切于这一点",{"2":{"1068":1}}],["逼自己把",{"2":{"1545":1}}],["逼近法就是积分",{"2":{"980":1}}],["灰度回滚",{"2":{"1544":1}}],["灰等等颜色",{"2":{"1061":1}}],["玩过",{"2":{"1543":1}}],["玩西洋棋的水平超过了samuel",{"2":{"1059":1}}],["搭接口",{"2":{"1543":1}}],["搭建网页结构",{"2":{"1539":1}}],["搭建网站和接口",{"2":{"1297":1}}],["搭建",{"0":{"1489":1}}],["嗨",{"0":{"1542":1},"1":{"1543":1,"1544":1,"1545":1,"1546":1,"1547":1,"1548":1,"1549":1,"1550":1}}],["聊天机器人直接跑在网页上",{"2":{"1540":1}}],["聊天应用",{"2":{"754":1}}],["布局和动画",{"2":{"1539":1}}],["布尔字面量类型",{"2":{"1414":1}}],["布尔类型",{"2":{"1216":1}}],["布尔值is",{"2":{"590":1}}],["趣味点",{"2":{"1539":1}}],["技能",{"2":{"1539":1}}],["技术之外",{"0":{"1549":1}}],["技术与设计的交叉",{"0":{"1537":1}}],["技术文档站",{"2":{"1529":1}}],["技术生态",{"0":{"1528":1}}],["技术博客",{"0":{"1358":1},"1":{"1359":1,"1360":1,"1361":1,"1362":1,"1363":1,"1364":1,"1365":1,"1366":1,"1367":1,"1368":1,"1369":1,"1370":1,"1371":1,"1372":1}}],["技术诞生了",{"2":{"1355":1}}],["技术解析",{"0":{"1194":1},"1":{"1195":1,"1196":1,"1197":1,"1198":1,"1199":1,"1200":1,"1201":1,"1202":1,"1203":1,"1204":1,"1205":1,"1206":1,"1207":1,"1208":1,"1209":1,"1210":1,"1211":1}}],["技术上",{"2":{"1061":1}}],["技术爱好者",{"2":{"1054":1}}],["技术问答",{"2":{"1053":1}}],["技术细节请参考",{"2":{"843":1}}],["技术",{"2":{"292":1}}],["技术栈",{"0":{"12":1}}],["巨大的社区和生态",{"0":{"1538":1}}],["页面立马变样",{"2":{"1535":1}}],["刷新浏览器",{"2":{"1535":1}}],["涂颜色",{"2":{"1533":1}}],["❤️",{"0":{"1531":1}}],["易上手",{"2":{"1530":1}}],["易于阅读",{"2":{"1296":1}}],["⭐⭐⭐⭐",{"2":{"1530":1}}],["⭐⭐⭐",{"2":{"1530":1}}],["⭐⭐",{"2":{"1530":1}}],["友好",{"2":{"1528":1}}],["团队打造的新一代前端构建工具",{"2":{"1528":1}}],["团队协作使用",{"2":{"1319":1}}],["热更新",{"2":{"1527":1}}],["热狗",{"2":{"876":1}}],["热狗数据集来源于网络",{"2":{"872":1}}],["热狗识别",{"0":{"871":1},"1":{"872":1,"873":1,"874":1},"2":{"871":1}}],["✨",{"2":{"1527":1}}],["⚡",{"2":{"1527":1}}],["渐进增强",{"2":{"1526":1}}],["渐进式网页应用",{"2":{"1540":1}}],["渐进式框架设计",{"2":{"1527":1}}],["渐进式",{"2":{"1526":1}}],["天津",{"2":{"1518":1,"1519":1}}],["天气预报",{"2":{"1182":1}}],["何时使用",{"2":{"1518":1}}],["何恺明等人提出了残差网络",{"2":{"500":1}}],["浅层式",{"2":{"1513":1}}],["斗罗大陆",{"2":{"1508":1}}],["今日热门游戏",{"2":{"1506":1,"1507":1}}],["今天的svm包会工作得很好",{"2":{"1148":1}}],["今天的计算机是高度并行的系统",{"2":{"789":1}}],["今天",{"2":{"464":1,"1168":1}}],["孙组件中使用inject配置项接受数据",{"2":{"1503":1}}],["孙组件",{"2":{"1501":1}}],["祖→孙",{"2":{"1501":1}}],["＋",{"2":{"1500":1}}],["绑定事件",{"2":{"1499":3}}],["触发input事件时",{"2":{"1500":1}}],["触发事件",{"2":{"1498":1,"1499":2}}],["触发时机",{"2":{"1309":1}}],["↔",{"2":{"1497":1}}],["父→子",{"2":{"1502":1}}],["父↔子",{"2":{"1500":1}}],["父组件中",{"2":{"1503":1}}],["父组件",{"2":{"1497":1,"1501":1}}],["父组件app",{"2":{"1468":1}}],["父传子",{"2":{"1497":1}}],["父",{"2":{"1497":1,"1498":1}}],["追加getters配置",{"2":{"1493":1}}],["追溯到1873年亚历山大",{"2":{"299":1}}],["蔓越莓",{"2":{"1490":1}}],["草莓",{"2":{"1490":1}}],["草叶等等",{"2":{"455":1}}],["怪好看的",{"2":{"1490":1}}],["浏览器的历史记录有两种写入方式",{"2":{"1484":1}}],["兼容性更好",{"2":{"1476":1}}],["卸载完毕",{"2":{"1470":1}}],["卸载之前",{"2":{"1470":2}}],["卸载阶段",{"2":{"1470":1}}],["销毁阶段",{"2":{"1470":1}}],["销毁",{"2":{"1470":1}}],["销售价格",{"2":{"290":1}}],["挂载钩子",{"2":{"1471":1}}],["挂载之前",{"2":{"1470":1}}],["挂载完毕",{"2":{"1470":2}}],["挂载阶段",{"2":{"1470":2}}],["挂载",{"2":{"1470":1}}],["联系服务器",{"2":{"1467":2}}],["联合类型",{"0":{"1407":1}}],["联合概率的不等式带给我们一个有趣的比率",{"2":{"1031":1}}],["联合概率可以回答",{"2":{"1030":1}}],["联合概率",{"0":{"1030":1}}],["立刻见效的成就感",{"0":{"1535":1}}],["立刻联系服务器",{"2":{"1467":2}}],["立即运行一个函数",{"2":{"1467":1}}],["立即再次运行它",{"2":{"979":1}}],["室温达到50℃",{"2":{"1467":2}}],["水温达到100",{"2":{"1467":1}}],["水温达到50℃",{"2":{"1467":1}}],["水平扩展",{"2":{"1207":1}}],["水平步幅为sw时",{"2":{"142":1}}],["水平步幅为2的二维互相关运算",{"2":{"142":1}}],["奥特曼",{"2":{"1497":1}}],["奥迪",{"2":{"1465":1,"1466":1}}],["奥斯卡颁奖后",{"2":{"345":1}}],["宝马",{"2":{"1465":1,"1466":1}}],["姓",{"2":{"1460":1}}],["女",{"2":{"1459":1}}],["男",{"2":{"1459":1}}],["宏观角度看",{"2":{"1458":1}}],["王者荣耀",{"2":{"1456":1,"1457":1,"1508":1}}],["王五",{"2":{"1408":1,"1469":1}}],["奔驰",{"2":{"1456":1,"1457":1,"1465":1,"1466":1,"1497":1,"1503":1}}],["万",{"2":{"1456":1,"1457":1}}],["万能",{"2":{"1305":1}}],["万能胶水语言",{"0":{"1295":1},"1":{"1296":1,"1297":1,"1298":1,"1299":1,"1300":1,"1301":1,"1302":1,"1303":1,"1304":1,"1305":1,"1306":1},"2":{"1297":1}}],["价值",{"2":{"1456":1,"1457":1}}],["领先",{"2":{"1451":1}}],["领域",{"2":{"1297":1}}],["监视上述的多个数据",{"2":{"1466":3}}],["监视响应式对象中的某个属性",{"2":{"1465":2}}],["监视ref或reactive定义的",{"2":{"1465":1}}],["监视ref定义的",{"2":{"1462":1,"1463":1}}],["监视reactive定义的",{"2":{"1464":1}}],["监视的要是对象里的属性",{"2":{"1465":1}}],["监视的回调",{"2":{"1463":1}}],["监视的是对象的地址值",{"2":{"1463":1}}],["监视的是对象的",{"2":{"1463":1}}],["监视的是其value值的改变",{"2":{"1462":1}}],["监视数据的变化",{"2":{"1461":1}}],["监视",{"2":{"1451":1,"1462":3,"1463":3,"1464":3,"1465":3,"1466":1}}],["监督学习指的就是我们给学习算法一个数据集",{"2":{"1060":1}}],["监督学习这个想法是指",{"2":{"1059":1}}],["监督学习的训练目标就像最大化真实值的开始和结束位置的对数似然一样简单",{"2":{"660":1}}],["监督学习的学习过程一般可以分为三大步骤",{"2":{"289":1}}],["监督学习也可以采取多种形式的模型",{"2":{"289":1}}],["监督学习之所以能发挥作用",{"2":{"289":1}}],["监督学习",{"0":{"289":1,"1060":1},"1":{"290":1,"291":1,"292":1,"293":1,"294":1,"295":1},"2":{"289":1,"296":1,"1182":1,"1193":1}}],["√",{"2":{"1444":9}}],["官网描述",{"2":{"1518":1}}],["官网",{"2":{"1467":1}}],["官网地址",{"2":{"1444":1}}],["官方路由解决方案",{"2":{"1528":1}}],["官方推荐基于",{"2":{"1443":1}}],["官方发版地址",{"2":{"1437":1}}],["官方宣布移除",{"2":{"1394":1}}],["官方集群方案",{"2":{"1355":1}}],["官方支持逐渐减少",{"2":{"1351":1}}],["官方有",{"2":{"1340":1}}],["官方文档",{"2":{"1306":1,"1531":1}}],["官方文档提供了本书之外的大量描述和示例",{"2":{"987":1,"1008":1}}],["官方提供了多种语言的",{"2":{"1048":1}}],["官方",{"0":{"1048":1}}],["初次渲染快55",{"2":{"1438":1}}],["初始值",{"2":{"1455":1}}],["初始",{"2":{"1189":1}}],["初始化本地仓库",{"2":{"1327":1}}],["初始化与克隆",{"0":{"1327":1}}],["初始化项目",{"2":{"1285":1,"1289":1,"1293":1}}],["初始化为0",{"2":{"968":1}}],["初始化为none",{"2":{"408":4}}],["初始化其参数并定义优化算法",{"2":{"961":1}}],["初始化合成图像",{"0":{"926":1}}],["初始化输出网络",{"2":{"905":1}}],["初始化转置卷积层",{"0":{"863":1}}],["初始化网络的所有参数",{"2":{"827":1}}],["初始化网络权重的函数",{"2":{"350":1}}],["初始化它的参数",{"2":{"680":1}}],["初始化参数",{"2":{"605":1}}],["初始化参数不足以得到良好的解",{"2":{"73":1}}],["初始化实际上是推迟",{"2":{"592":2}}],["初始化函数",{"2":{"559":1}}],["初始化ρt",{"2":{"519":1}}],["初始化和绑定模型参数",{"2":{"438":1}}],["初始化和轮数",{"2":{"139":1}}],["初始化解码器的状态",{"2":{"375":1}}],["初始化",{"2":{"335":3,"414":1}}],["初始化循环神经网络模型的模型参数",{"2":{"331":1}}],["初始化隐状态是简单的",{"2":{"325":1}}],["初始化方案的选择在神经网络学习中起着举足轻重的作用",{"2":{"240":1}}],["初始化方案的选择并不是特别重要",{"2":{"240":1}}],["初始化模型参数的值",{"2":{"613":1}}],["初始化模型参数",{"0":{"217":1,"273":1,"331":1,"544":1,"558":1,"592":1,"601":1,"623":1,"630":1,"766":1},"2":{"834":3}}],["初始化模型",{"2":{"80":4,"81":4}}],["掌握这些概念后",{"2":{"1436":1}}],["掌握了数据的一些特征",{"2":{"1158":1}}],["善用工具",{"2":{"1436":1}}],["循序渐进",{"2":{"1436":1}}],["循环控制语句",{"0":{"1227":1}}],["循环语句",{"0":{"1224":1},"1":{"1225":1,"1226":1}}],["循环i则循环所有的列",{"2":{"1120":1}}],["循环对",{"2":{"1093":1}}],["循环和",{"2":{"1092":1}}],["循环是如何工作的",{"2":{"1092":1}}],["循环最后写上",{"2":{"1092":1}}],["循环",{"0":{"1225":1,"1226":1},"2":{"1092":4,"1093":4,"1304":1}}],["循环或任意函数调用",{"2":{"977":1}}],["循环层返回变量的说明可以参考",{"2":{"573":1}}],["循环神经网络和注意力",{"2":{"663":1}}],["循环神经网络和自注意力这几个架构的计算复杂性",{"2":{"397":1}}],["循环神经网络和自注意力",{"0":{"397":1}}],["循环神经网络将来自上一时间步的输出yt",{"2":{"574":1}}],["循环神经网络将词元xt的输入特征向量",{"2":{"573":1}}],["循环神经网络编码器使用长度可变的序列作为输入",{"2":{"572":1}}],["循环神经网络编码器将长度可变的序列转换为固定形状的上下文变量",{"2":{"373":1}}],["循环神经网络在实践中一个常见问题是数值不稳定性",{"2":{"550":1}}],["循环神经网络是逐个的重复地处理词元的",{"2":{"398":1}}],["循环神经网络也总是使用这些模型参数",{"2":{"340":1}}],["循环神经网络模型的参数数量不会随着时间步的增加而增加",{"2":{"343":1}}],["循环神经网络模型的训练函数既支持从零开始实现",{"2":{"335":1}}],["循环神经网络模型在训练以前需要初始化状态",{"2":{"336":1}}],["循环神经网络模型和输出生成",{"2":{"336":1}}],["循环神经网络模型往往需要额外的方式来支持稳定训练",{"2":{"334":1}}],["循环神经网络模型通过inputs最外层的维度实现循环",{"2":{"332":1}}],["循环神经网络模型",{"0":{"332":1},"2":{"325":3}}],["循环神经网络的隐状态可以捕获直到当前时间步序列的历史信息",{"2":{"343":1}}],["循环神经网络的参数开销不会随着时间步的增加而增加",{"2":{"340":1}}],["循环神经网络的参数包括隐藏层的权重",{"2":{"340":1}}],["循环神经网络的从零开始实现",{"0":{"329":1},"1":{"330":1,"331":1,"332":1,"333":1,"334":1,"335":1,"336":1,"337":1}}],["循环神经网络的简洁实现",{"0":{"324":1},"1":{"325":1,"326":1,"327":1,"328":1}}],["循环神经网络的梯度分析",{"0":{"307":1},"1":{"308":1,"309":1,"310":1,"311":1}}],["循环神经网络中的前向传播相对简单",{"2":{"306":1}}],["循环神经网络通过引入状态变量存储过去的信息和当前的输入",{"2":{"305":1}}],["循环神经网络",{"0":{"305":1,"338":1},"1":{"339":1,"340":1,"341":1,"342":1,"343":1,"344":1},"2":{"338":1,"340":1,"403":1,"663":1}}],["鼠标",{"2":{"1432":1}}],["笔记本电脑",{"2":{"1432":1}}],["泛型约束",{"0":{"1433":1}}],["泛型类",{"0":{"1432":1}}],["泛型接口",{"0":{"1431":1},"2":{"1431":1}}],["泛型箭头函数",{"2":{"1430":1}}],["泛型函数",{"2":{"1430":1}}],["泛型允许我们创建可重用的组件",{"2":{"1429":1}}],["泛型",{"0":{"1429":1},"1":{"1430":1,"1431":1,"1432":1,"1433":1,"1434":1,"1435":1}}],["泛化",{"2":{"980":1}}],["泛化性和灵活性之间的这种基本权衡被描述为偏差",{"2":{"169":1}}],["泛化误差可能为零吗",{"2":{"268":1}}],["泛化误差通常会减小",{"2":{"260":1}}],["泛化误差始终是12",{"2":{"252":1}}],["泛化误差",{"2":{"99":1,"252":1}}],["私有的",{"2":{"1425":1}}],["私人助理",{"2":{"1053":1}}],["北京",{"2":{"1421":1,"1433":1,"1518":1,"1519":1}}],["北京的温度为52∘f",{"2":{"989":1}}],["枚举",{"0":{"1413":1}}],["李四",{"2":{"1398":1,"1454":1,"1455":1,"1463":1,"1464":1,"1469":1}}],["李沐对siri说道",{"2":{"282":1}}],["仓库",{"2":{"1392":1}}],["端口",{"2":{"1391":1}}],["稳定的网络访问入口",{"2":{"1384":1}}],["滚动更新等",{"2":{"1395":1}}],["滚动更新",{"2":{"1383":1}}],["滚动升级等全面功能",{"2":{"1351":1}}],["崩溃",{"2":{"1382":1}}],["崩溃恢复时",{"2":{"1202":1}}],["副本数",{"2":{"1390":1}}],["副本数始终保持在预期数量",{"2":{"1382":1}}],["副本集",{"0":{"1209":1},"2":{"1210":1,"1211":1}}],["副本集提供冗余和自动故障转移",{"2":{"1195":1}}],["管理",{"2":{"1381":1}}],["管理容器生命周期",{"2":{"1377":1}}],["管理上下文的",{"2":{"1050":1}}],["证书",{"0":{"1370":1},"2":{"1385":1}}],["证明方式是非常类似的",{"2":{"1145":1}}],["证明",{"2":{"1004":1}}],["证明一个矩阵a的转置的转置是a",{"2":{"1004":1}}],["证明一个仅使用relu",{"2":{"239":1}}],["证明λ−1realsoftmax",{"2":{"655":1}}],["证明realsoftmax",{"2":{"655":1}}],["证明mk拥有特征值λik",{"2":{"314":1}}],["证明min",{"2":{"52":1}}],["证明是更为优越的",{"2":{"299":1}}],["证明tanh",{"2":{"239":1}}],["证明在",{"2":{"160":1}}],["证明在线性子空间b=0的情况下",{"2":{"52":1}}],["证明卷积内核为每组通道独立地实现一个全连接层",{"2":{"160":1}}],["证明运算可以用单次卷积来表示",{"2":{"124":1}}],["证明特征值的分布也是对称的",{"2":{"105":1}}],["证明对于λ→∞",{"2":{"655":1}}],["证明对于一个随机向量x∈rn",{"2":{"314":1}}],["证明对于函数f",{"2":{"118":1}}],["证明对于任何局部最小值",{"2":{"105":1}}],["证明对于凸二次可微函数f",{"2":{"52":1}}],["证明对于正交矩阵u和向量c",{"2":{"31":1}}],["证明线性子空间x=",{"2":{"52":1}}],["证明softmax函数的规范化是凸的",{"2":{"52":1}}],["证明bp",{"2":{"52":1}}],["证明只检查集合的顶点是充分的",{"2":{"52":1}}],["证明只检查边界上的点是充分的",{"2":{"52":1}}],["证明格什戈林圆盘定理",{"2":{"31":1}}],["邮件代理服务器",{"2":{"1359":1}}],["邮件过滤器",{"2":{"1182":1}}],["➝",{"2":{"1353":1}}],["资源利用率高",{"2":{"1353":1}}],["资源占用",{"2":{"1346":1}}],["企业级集群管理",{"2":{"1351":1}}],["企业可以自建私有仓库",{"2":{"1340":1}}],["统一调度容器",{"2":{"1348":1}}],["统计长度时排除了填充词元",{"2":{"568":1}}],["统计词元的频率",{"2":{"363":1}}],["统计工具",{"0":{"346":1},"1":{"347":1,"348":1,"349":1}}],["统计模型和经过训练的开源神经网络",{"2":{"302":1}}],["统计建模人员构建更好的神经网络",{"2":{"300":1}}],["统计数据真正实现了腾飞",{"2":{"299":1}}],["统计学和计算机科学",{"2":{"619":1}}],["统计学方法在这一领域一直占据主导地位",{"2":{"564":1}}],["统计学家通常将这一点表述为a⊥b",{"2":{"1034":1}}],["统计学家很早以前就发明了一种表示分类数据的简单方法",{"2":{"640":1}}],["统计学家认为",{"2":{"254":1}}],["统计学家称不变的动力学为静止的",{"2":{"347":1}}],["统计学家称",{"2":{"190":1}}],["统计学家称之为协变量偏移",{"2":{"181":1}}],["统计学习理论",{"0":{"253":1}}],["统计推断",{"2":{"99":1}}],["统计效率",{"2":{"82":1}}],["隔离",{"2":{"1346":1}}],["隔离性",{"2":{"1346":1}}],["隔离项目依赖",{"2":{"1271":1}}],["级",{"2":{"1346":2}}],["镜像相关",{"0":{"1342":1}}],["镜像仓库",{"2":{"1340":1}}],["守护进程",{"2":{"1340":1}}],["服务治理",{"2":{"1543":1}}],["服务发现",{"2":{"1351":1,"1395":1}}],["服务扩缩容",{"2":{"1348":1}}],["服务端",{"2":{"1340":1}}],["服务器块",{"2":{"1364":1}}],["服务器",{"2":{"1359":1}}],["服务器保存历史",{"2":{"1318":1}}],["服务器通过",{"2":{"1047":1}}],["服务器可连接的互联网上的外部系统",{"2":{"1042":1}}],["服务器可安全访问的计算机文件",{"2":{"1042":1}}],["服务器架构",{"2":{"1042":1}}],["服务器gpu",{"2":{"812":1}}],["服务器最多有8个加速卡",{"2":{"801":1}}],["清晰的接口定义",{"2":{"1544":1}}],["清理事件",{"2":{"1499":1}}],["清理了",{"2":{"1467":1}}],["清理未跟踪文件",{"2":{"1336":1}}],["清除一幅图像",{"2":{"1091":1}}],["清除以前的梯度",{"2":{"236":2,"237":2}}],["⚠️",{"2":{"1334":1}}],["撤销工作区修改",{"2":{"1333":1}}],["恢复最近一次",{"2":{"1332":1}}],["恢复单词序列",{"2":{"757":1}}],["游离",{"2":{"1323":1}}],["游戏开发",{"2":{"1297":1}}],["游戏曾经是人类智慧的堡垒",{"2":{"301":1}}],["游戏",{"2":{"157":1,"1297":1}}],["始终指向当前所在分支",{"2":{"1323":1}}],["始终比所有其他梯度都大",{"2":{"118":1}}],["章拉出新分支写不同结局",{"2":{"1322":1}}],["临时存放",{"2":{"1319":1}}],["临街宽度",{"2":{"1084":1}}],["暂存当前修改",{"2":{"1332":1}}],["暂存修改",{"0":{"1332":1}}],["暂存区",{"2":{"1319":2}}],["暂退概率分别为0",{"2":{"172":1}}],["暂退法也被作为正则化方法使用",{"2":{"406":1}}],["暂退法等",{"2":{"205":1}}],["暂退法仅在训练期间使用",{"2":{"177":1}}],["暂退法将活性值h替换为具有期望值h的随机变量",{"2":{"177":1}}],["暂退法可以避免过拟合",{"2":{"177":1}}],["暂退法会破坏共适应性",{"2":{"170":1}}],["暂退法的原始论文提到了一个关于有性繁殖的类比",{"2":{"170":1}}],["暂退法在前向传播过程中",{"2":{"170":1,"177":1}}],["暂退法",{"0":{"168":1},"1":{"169":1,"170":1,"171":1,"172":1,"173":1,"174":1,"175":1,"176":1,"177":1,"178":1}}],["版本与环境管理",{"2":{"1546":1}}],["版本",{"2":{"1315":2,"1335":1}}],["版本上测试",{"2":{"1313":1}}],["筛选组合",{"2":{"1313":1}}],["筛选所有置信度不低于0",{"2":{"964":1}}],["托管于",{"2":{"1311":1}}],["菜鸟教程",{"2":{"1306":1}}],["丰富的标准库",{"2":{"1302":1}}],["遇到问题基本都能在",{"2":{"1300":1}}],["遇到了梯度爆炸的问题",{"2":{"306":1}}],["爬虫",{"2":{"1297":1}}],["库",{"2":{"1528":1}}],["库名",{"2":{"1263":1}}],["库图斯使用有效的结构化策略超过了人类的表现",{"2":{"301":1}}],["耗时",{"2":{"1261":1}}],["耗时颇多",{"2":{"269":1}}],["├──",{"2":{"1258":3}}],["静态资源服务器",{"0":{"1367":1}}],["静态资源服务",{"0":{"1363":1}}],["静态方法",{"2":{"1254":1}}],["静态问答模型",{"2":{"1049":1}}],["退出上下文",{"2":{"1252":1}}],["装饰器",{"0":{"1244":1},"2":{"1530":1}}],["装在一辆改装版军用悍马",{"2":{"1127":1}}],["匿名函数",{"0":{"1239":1}}],["普通参数",{"2":{"1230":1}}],["普通的逻辑回归模型",{"2":{"1097":1}}],["占位语句",{"2":{"1227":1}}],["占用空间也更小",{"2":{"1089":1}}],["幂",{"2":{"1218":1}}],["幂律",{"2":{"981":1}}],["浮点数",{"2":{"1216":1}}],["示例先行",{"2":{"1548":1}}],["示例代码",{"2":{"1467":1,"1470":1,"1471":1}}],["示例",{"0":{"1233":1,"1315":1,"1389":1,"1390":1,"1391":1},"2":{"1216":1,"1240":3,"1315":1,"1498":1}}],["示例文档",{"2":{"1196":1}}],["故障时",{"2":{"1209":1}}],["故障模块可能无法激活",{"2":{"811":1}}],["节点端口",{"2":{"1391":1}}],["节点管理等",{"2":{"1376":1}}],["节点",{"2":{"1209":2,"1381":3}}],["节省大量的时间",{"2":{"1137":1}}],["节省了几个月的时间",{"2":{"1129":1}}],["节省内存",{"0":{"1021":1},"2":{"1246":1}}],["路由组件的两个重要的属性",{"2":{"1485":1}}],["路由组件通常存放在pages",{"2":{"1475":1}}],["路由的props配置",{"0":{"1483":1}}],["路由传参",{"0":{"1480":1},"1":{"1481":1,"1482":1}}],["路由器工作模式",{"0":{"1476":1}}],["路由配置文件代码如下",{"2":{"1474":1}}],["路由",{"0":{"1472":1},"1":{"1473":1,"1474":1,"1475":1,"1476":1,"1477":1,"1478":1,"1479":1,"1480":1,"1481":1,"1482":1,"1483":1,"1484":1,"1485":1,"1486":1}}],["路由与元数据管理",{"2":{"1210":1}}],["路由服务与配置中心",{"0":{"1208":1}}],["路沿被渲染成一种非常简单的纹理",{"2":{"186":1}}],["路沿检测器很快就学习到了这个",{"2":{"186":1}}],["路沿检测器",{"2":{"186":1}}],["哈哈",{"2":{"1508":1}}],["哈希值",{"2":{"1321":1}}],["哈希",{"2":{"1207":1}}],["哈希分片",{"2":{"1207":1}}],["哈士奇",{"2":{"900":1}}],["弱",{"2":{"1205":1}}],["→",{"2":{"1205":2,"1208":1,"1209":2,"1210":2,"1318":1,"1319":6,"1323":2,"1324":2,"1325":4,"1546":4}}],["→max",{"2":{"655":1}}],["差异",{"2":{"1205":1}}],["日志",{"2":{"1365":1,"1547":1}}],["日志路径等",{"2":{"1365":1}}],["日志与进入容器",{"0":{"1344":1}}],["日志与恢复",{"2":{"1204":1}}],["日志打印等",{"2":{"1244":1}}],["日常生活中的机器学习",{"0":{"282":1}}],["⚙️",{"0":{"1203":1,"1302":1}}],["补全",{"2":{"1202":1}}],["周期性将内存页写入磁盘",{"2":{"1202":1}}],["周围像素的值",{"2":{"230":1}}],["淘汰最近最少使用的数据页",{"2":{"1201":1}}],["淘汰",{"0":{"1201":1}}],["叶子节点链表",{"2":{"1199":1}}],["树变体",{"2":{"1199":1}}],["树索引",{"0":{"1199":1}}],["树突",{"2":{"1099":1}}],["树突中接收到来自其他神经元",{"2":{"619":1}}],["八",{"0":{"1256":1},"1":{"1257":1,"1258":1},"2":{"1193":1}}],["⁡12∑i=1nm∑jr",{"2":{"1189":1}}],["似乎更倾向与动作片",{"2":{"1187":1}}],["似乎如果你想要模仿它",{"2":{"1098":1}}],["部署一条龙",{"2":{"1547":1}}],["部署方式",{"0":{"1393":1}}],["部署",{"2":{"1374":1}}],["部署后流量调度的核心组件",{"2":{"1372":1}}],["部署与管理应用的核心基石",{"2":{"1352":1}}],["部电影和",{"2":{"1187":1}}],["部分了",{"2":{"605":1}}],["部分或完全",{"2":{"201":1}}],["洋红色的线",{"2":{"1184":1}}],["欺诈行为检测",{"2":{"1182":1}}],["足够用于训练",{"2":{"1182":1}}],["足够用于训练fashion",{"2":{"509":1}}],["少量的正向类数据来训练算法",{"2":{"1182":1}}],["少有观众喜欢在八月看圣诞老人的电影",{"2":{"345":1}}],["符合",{"0":{"1215":1}}],["符合高斯分布",{"2":{"1179":1}}],["符号表示指向我们刚刚定义的costfunction",{"2":{"1111":1}}],["符号表示逻辑与",{"2":{"1088":1}}],["符号表示y的估计值",{"2":{"610":1}}],["符号∈称为",{"2":{"989":1}}],["符号c和f称为变量",{"2":{"989":1}}],["符号编程",{"2":{"824":1}}],["符号式编程要求我们先定义并且编译程序",{"2":{"822":1}}],["符号式编程技术和计算图仍然存在于tensorflow中",{"2":{"818":1}}],["符号式编程更容易在编译期间优化代码",{"2":{"817":1}}],["符号式编程运行效率更高",{"2":{"817":1}}],["符号式编程",{"0":{"817":1}}],["符号与跳元模型中相反",{"2":{"785":1}}],["符号来重写这个模型",{"2":{"617":1}}],["符号⊙是hadamard积",{"2":{"541":1}}],["符号简化",{"2":{"519":1}}],["ε",{"2":{"1181":2}}],["ε时预测数据为正常数据",{"2":{"1180":1}}],["ε时",{"2":{"1180":1}}],["ε检测非正常用户",{"2":{"1178":1}}],["εanomaly",{"2":{"1178":1}}],["质量优先",{"2":{"1548":1}}],["质量控制测试",{"2":{"1178":1}}],["质量仍然不那么好",{"2":{"113":1}}],["谢谢大家",{"2":{"1176":1}}],["谢林顿的模型",{"2":{"299":1}}],["召回率以及f1分数",{"2":{"1176":1}}],["课的最后一段视频",{"2":{"1176":1}}],["众包",{"2":{"1173":1}}],["众所周知",{"2":{"258":1}}],["滑动窗口技术也被用于文字识别",{"2":{"1172":1}}],["滑动窗口是一项用来从图像中抽取对象的技术",{"2":{"1172":1}}],["滑动窗口",{"0":{"1172":1},"2":{"1193":1}}],["起来",{"2":{"1533":1}}],["起始地点",{"2":{"1168":1}}],["起源",{"0":{"299":1}}],["簇间不相似度",{"2":{"1154":1}}],["簇内不相似度",{"2":{"1154":1}}],["杰卡德相似系数",{"2":{"1154":1}}],["杰卡德系数",{"2":{"849":1}}],["闵可夫斯基距离minkowski",{"2":{"1154":1}}],["恤是否能较好地适合我们的客户",{"2":{"1154":1}}],["恤制造例子中",{"2":{"1154":1}}],["恤衫的三种尺寸",{"2":{"1151":1}}],["畸变值下降得很快",{"2":{"1154":1}}],["畸变值就下降的非常慢",{"2":{"1154":1}}],["肘关节",{"2":{"1154":1}}],["肘部法则",{"2":{"1154":5}}],["快去为我们找找这个数据的内在结构给定数据",{"2":{"1150":1}}],["快速搭建",{"2":{"1351":1}}],["快速部署",{"2":{"1339":1,"1346":1}}],["快速地发现你尝试的这些想法是否能够提高算法的表现",{"2":{"1138":1}}],["快速地实现这些学习算法",{"2":{"1061":1}}],["快速且被广泛使用",{"2":{"952":1}}],["快速的r",{"2":{"936":1}}],["快速的",{"2":{"819":1}}],["达最大值",{"2":{"1146":1}}],["达到6",{"2":{"1092":1}}],["达到性能度量值p",{"2":{"1059":1}}],["垂直于红线投影",{"2":{"1158":1}}],["垂直于横轴投影",{"2":{"1158":1}}],["垂直坐标",{"2":{"1146":1}}],["垂直线是决策界",{"2":{"1145":1}}],["垂直读取输出会产生与其他实现相同的输出",{"2":{"148":1}}],["终点位置在这个训练样本点的向量",{"2":{"1145":1}}],["申明一点",{"2":{"1145":1}}],["趋近于1时",{"2":{"1143":1}}],["趋近1",{"2":{"1143":1}}],["劣等的",{"2":{"1141":1}}],["吸收什么误差分析可以帮助我们系统化地选择该做什么",{"2":{"1138":1}}],["花费大量的时间在构造算法上",{"2":{"1138":1}}],["异常",{"2":{"1304":1}}],["异常处理进阶",{"0":{"1248":1},"1":{"1249":1,"1250":1}}],["异常处理可以保证程序不会因为某个错误而崩溃",{"2":{"1236":1}}],["异常处理机制",{"0":{"1236":1}}],["异常数据的该特征值异常地大或小",{"2":{"1183":1}}],["异常数据",{"2":{"1182":1}}],["异常或正常",{"2":{"1181":1}}],["异常检测误差分析",{"2":{"1183":1}}],["异常检测假设特征符合高斯分布",{"2":{"1183":1}}],["异常检测与监督学习对比",{"0":{"1182":1},"2":{"1193":1}}],["异常检测算法也能够工作",{"2":{"1183":1}}],["异常检测算法是一个非监督学习算法",{"2":{"1181":1}}],["异常检测算法",{"2":{"1180":1}}],["异常检测主要用来识别欺骗",{"2":{"1178":1}}],["异常检测问题可以定义如下",{"2":{"1178":1}}],["异常检测",{"2":{"1177":1,"1182":1,"1193":1}}],["异常的邮件路由情况出现了多少次等等",{"2":{"1138":1}}],["异步引入组件",{"2":{"1523":1}}],["异步地使用它们",{"2":{"798":1}}],["异步产生了一个相当灵活的前端",{"2":{"793":1}}],["异步计算",{"0":{"789":1},"1":{"790":1,"791":1,"792":1,"793":1,"794":1},"2":{"824":1}}],["思考怎样能改进分类器",{"2":{"1138":1}}],["思想是",{"2":{"1134":1}}],["凭直觉得出的东西一般总是错误的",{"2":{"1138":1}}],["凭借它",{"2":{"500":1}}],["坦白的说",{"2":{"1138":1}}],["坦率地说",{"2":{"1117":1}}],["头脑风暴",{"2":{"1137":1}}],["头脑正常的机器学习研究人员都不会用它来构建服务器集群",{"2":{"812":1}}],["往训练集增加更多数据可以提高模型的效果",{"2":{"1134":1}}],["往往是我获得想法来改进算法的重要部分",{"2":{"1091":1}}],["往往几个简单的图",{"2":{"1091":1}}],["搞清楚这一点非常重要",{"2":{"1132":1}}],["误删分支或回退历史",{"2":{"1337":1}}],["误分类的比率",{"2":{"1130":1}}],["误差项和正则项应该都是乘以1",{"2":{"1188":1}}],["误差的大小是不能视为评判算法效果的依据的",{"2":{"1139":1}}],["误差是变大还是变小了",{"2":{"1138":1}}],["误差是激活单元的预测",{"2":{"1121":1}}],["误差分析不能帮助我们做出这类判断",{"2":{"1138":1}}],["误差分析并不总能帮助我们判断应该采取怎样的行动",{"2":{"1138":1}}],["误差分析要做的既是检验交叉验证集中我们的算法产生错误预测的所有邮件",{"2":{"1138":1}}],["误差分析",{"0":{"1138":1},"2":{"1183":1,"1193":1}}],["误差呈现先减小后增大的趋势",{"2":{"1132":1}}],["误差减小",{"2":{"1132":1}}],["误差较大",{"2":{"1132":2}}],["误差",{"2":{"1122":1}}],["误差已经降到足够低",{"2":{"129":1}}],["洗牌",{"2":{"1130":1,"1165":1}}],["诊断",{"2":{"1140":1}}],["诊断偏差和方差",{"0":{"1132":1},"2":{"1193":1}}],["诊断法",{"2":{"1129":1}}],["诊断和可视化",{"2":{"429":1}}],["噢",{"2":{"1129":1}}],["十六",{"0":{"1186":1},"1":{"1187":1,"1188":1,"1189":1,"1190":1,"1191":1,"1192":1},"2":{"1193":1}}],["十五",{"2":{"1177":1,"1193":1}}],["十九",{"0":{"1175":1},"1":{"1176":1},"2":{"1193":1}}],["十八",{"0":{"1170":1},"1":{"1171":1,"1172":1,"1173":1,"1174":1},"2":{"1193":1}}],["十七",{"2":{"1163":1,"1193":1}}],["十四",{"0":{"1155":1},"1":{"1156":1,"1157":1,"1158":1,"1159":1,"1160":1,"1161":1,"1162":1},"2":{"1193":1}}],["十三",{"2":{"1149":1,"1193":1}}],["十二",{"0":{"1264":1},"2":{"1142":1,"1193":1}}],["十一",{"0":{"1136":1,"1263":1},"1":{"1137":1,"1138":1,"1139":1,"1140":1,"1141":1},"2":{"1193":1}}],["十",{"0":{"1260":1},"1":{"1261":1,"1262":1},"2":{"1128":1,"1193":1}}],["欧洲等一些国家和地区",{"2":{"1127":1}}],["欧几里得距离是一个l2范数",{"2":{"1000":1}}],["欧几里得距离和毕达哥拉斯定理中的非负性概念和三角不等式可能会给出一些启发",{"2":{"1000":1}}],["车辆将被安全地引导进入双车道路",{"2":{"1127":1}}],["车辆前方突然出现了一个交叉十字路口",{"2":{"1127":1}}],["车辆便开始行驶了",{"2":{"1127":1}}],["车辆的自动驾驶",{"2":{"301":1}}],["朝左延伸了一点",{"2":{"1127":1}}],["朝着减少损失的方向更新我们的参数",{"2":{"604":1}}],["综合起来",{"0":{"1126":1},"2":{"1193":1}}],["综上所述",{"2":{"44":1,"158":1,"191":1,"286":1,"289":1,"294":1,"832":1}}],["太热了",{"2":{"1299":1}}],["太多复杂的步骤",{"2":{"1122":1}}],["太好了",{"2":{"253":1}}],["巩固了反向传播算法具体是如何实现的",{"2":{"1122":1}}],["九",{"0":{"1119":1,"1259":1},"1":{"1120":1,"1121":1,"1122":1,"1123":1,"1124":1,"1125":1,"1126":1,"1127":1},"2":{"1193":1}}],["尽可能地让所有有可能是恶性肿瘤的病人都得到进一步地检查",{"2":{"1140":1}}],["尽可能的小",{"2":{"1115":1}}],["尽管你不去写你自己的svm的优化软件",{"2":{"1148":1}}],["尽管我没有将其真的看做向量",{"2":{"1145":1}}],["尽管我们在此之前没有展示",{"2":{"1148":1}}],["尽管我们希望有很多参数",{"2":{"1141":1}}],["尽管我们知道标签应该取值0",{"2":{"1106":1}}],["尽管我们知道x=0时f",{"2":{"54":1}}],["尽管我们要计算指数函数",{"2":{"624":1}}],["尽管我们已经应用了梯度裁剪等技巧来缓解这个问题",{"2":{"550":1}}],["尽管我们已经创建了b1",{"2":{"502":1}}],["尽管从技术上讲",{"2":{"1144":1}}],["尽管编写者自己是个菜鸟",{"2":{"1059":1}}],["尽管第二次检验比第一次检验的准确性要低得多",{"2":{"1035":1}}],["尽管使用了非常准确的测试",{"2":{"1035":1}}],["尽管单个向量的默认方向是列向量",{"2":{"992":1}}],["尽管y1和y2在通道数",{"2":{"956":1}}],["尽管r",{"2":{"937":1}}],["尽管imagenet数据集中的大多数图像与椅子无关",{"2":{"869":1}}],["尽管目前的数据收集成本已大幅降低",{"2":{"869":1}}],["尽管命令式编程很方便",{"2":{"816":1}}],["尽管有while循环",{"2":{"1092":1}}],["尽管有一些明显的例外",{"2":{"811":1}}],["尽管有了算法",{"2":{"805":1}}],["尽管掩蔽语言建模能够编码双向上下文来表示单词",{"2":{"737":1}}],["尽管elmo显著改进了各种自然语言处理任务的解决方案",{"2":{"732":1}}],["尽管可能具有不同的注意力权重",{"2":{"675":1}}],["尽管softmax是一个非线性函数",{"2":{"643":1}}],["尽管神经网络涵盖了更多更为丰富的模型",{"2":{"617":1}}],["尽管线性回归有解析解",{"2":{"604":1}}],["尽管p1=p2=1",{"2":{"578":1}}],["尽管模型产出的困惑度是合理的",{"2":{"523":1}}],["尽管模拟考试考得很好",{"2":{"286":1}}],["尽管这只是一个假设",{"2":{"1098":1}}],["尽管这只是其中一种目标检测模型",{"2":{"952":1}}],["尽管这个椅子数据集可能大于fashion",{"2":{"869":1}}],["尽管这些锚框可能会覆盖所有真实边界框",{"2":{"848":1}}],["尽管这是相对低效的",{"2":{"837":1}}],["尽管这是一个极端情况",{"2":{"504":1}}],["尽管这9个通道的宽度不同",{"2":{"701":1}}],["尽管这会更慢",{"2":{"114":1}}],["尽管alexnet的代码只比lenet多出几行",{"2":{"464":1}}],["尽管原文中alexnet是在imagenet上进行训练的",{"2":{"462":1}}],["尽管一直有一群执着的研究者不断钻研",{"2":{"455":1}}],["尽管transformer架构是为了序列到序列的学习而提出的",{"2":{"409":1}}],["尽管transformer最初是应用于在文本数据上的序列到序列学习",{"2":{"403":1}}],["尽管批量规范化在计算机视觉中被广泛应用",{"2":{"406":1}}],["尽管加性注意力包含了可学习的参数",{"2":{"369":1}}],["尽管组成两句话的字完全相同",{"2":{"345":1}}],["尽管两者都只是估计一个数字",{"2":{"345":1}}],["尽管两个例子在一个迭代轮数内都处理了1500个样本",{"2":{"80":1}}],["尽管公式",{"2":{"318":1}}],["尽管常常以牺牲可解释性为代价",{"2":{"302":1}}],["尽管推荐系统具有巨大的应用价值",{"2":{"294":1}}],["尽管在",{"2":{"663":1}}],["尽管在实际情况中编码器或解码器可以单独使用",{"2":{"410":1}}],["尽管在许多情况下",{"2":{"302":1}}],["尽管在上述数学推理中",{"2":{"247":1}}],["尽管在处理的样本数方面",{"2":{"80":1}}],["尽管梯度是从更靠近输出的层传播的",{"2":{"247":1}}],["尽管梯度下降",{"2":{"53":1}}],["尽管实际中学习该函数是很困难的",{"2":{"233":1}}],["尽管沃尔多的装扮很有特点",{"2":{"152":1}}],["尽管严格地说",{"2":{"130":1}}],["尽管不是太快",{"2":{"117":1}}],["尽管它有不同的含义",{"2":{"732":1}}],["尽管它还是原来那部电影",{"2":{"345":1}}],["尽管它经常隐藏在视线之外",{"2":{"301":1}}],["尽管它不是最小值",{"2":{"102":1}}],["尽管它的目标函数明显不那么令人愉快",{"2":{"87":1}}],["尽管优化提供了一种最大限度地减少深度学习损失函数的方法",{"2":{"99":1}}],["尽管学习率与我们以前使用的相同",{"2":{"88":1}}],["尽管如此",{"2":{"65":1,"88":1,"102":1,"122":1,"252":1,"291":1,"292":1,"315":1,"318":1,"342":1,"389":1,"811":1,"821":1,"837":1}}],["尽管经过了10个步骤",{"2":{"55":1}}],["造成欠拟合",{"2":{"1115":1}}],["七",{"0":{"1113":1,"1236":1,"1253":1},"1":{"1114":1,"1115":1,"1116":1,"1117":1,"1254":1,"1255":1},"2":{"1193":1}}],["圆形的值为0",{"2":{"1112":1}}],["圆圈表示操作符",{"2":{"163":1}}],["伪",{"2":{"1112":1}}],["叉叉表示",{"2":{"1112":1}}],["谨慎",{"2":{"1112":1}}],["谨慎是有道理的",{"2":{"291":1}}],["雨天",{"2":{"1112":1}}],["判定边界",{"0":{"1108":1},"2":{"1193":1}}],["判断",{"2":{"1304":1}}],["判断一次金融交易是否是欺诈",{"2":{"1106":1}}],["判断一封电子邮件是否是垃圾邮件",{"2":{"1106":1}}],["判断回归问题的一个很好的经验法则是",{"2":{"290":1}}],["六",{"0":{"1105":1,"1234":1,"1251":1,"1304":1,"1372":1},"1":{"1106":1,"1107":1,"1108":1,"1109":1,"1110":1,"1111":1,"1112":1,"1235":1,"1252":1},"2":{"1193":1}}],["摩托车和卡车",{"2":{"1103":1}}],["摩尔定律",{"2":{"300":1}}],["逻辑运算符",{"0":{"1220":1}}],["逻辑",{"2":{"1217":1}}],["逻辑回归或不带核函数的svm另一个也很有可能很有效",{"2":{"1148":1}}],["逻辑回归和不带核函数的支持向量机它们都是非常相似的算法",{"2":{"1148":1}}],["逻辑回归做了类似的事情",{"2":{"1144":1}}],["逻辑回归的代价函数",{"2":{"1110":1}}],["逻辑回归模型的假设是",{"2":{"1107":1}}],["逻辑回归算法是分类算法",{"2":{"1106":1}}],["逻辑回归",{"0":{"1105":1},"1":{"1106":1,"1107":1,"1108":1,"1109":1,"1110":1,"1111":1,"1112":1},"2":{"1107":1,"1176":1,"1193":1}}],["逻辑与",{"2":{"1101":1}}],["逻辑或",{"2":{"1101":1}}],["∼a3",{"2":{"1100":1}}],["蜂鸣器会响",{"2":{"1098":1}}],["东西",{"2":{"1098":1}}],["听起来很高大上",{"2":{"1532":1}}],["听起来像是两份录音被叠加到一起",{"2":{"1061":1}}],["听了这节课",{"2":{"1110":1}}],["听觉和触觉",{"2":{"1098":1}}],["声明式渲染",{"2":{"1527":1}}],["声明式管理",{"2":{"1388":1}}],["声明事件",{"2":{"1500":2}}],["声明资源对象",{"2":{"1388":1}}],["声或触觉信号",{"2":{"1098":1}}],["声音彼此重叠",{"2":{"1061":1}}],["声音通常以8khz或16khz采样",{"2":{"295":1}}],["耳朵接收到声音信号",{"2":{"1098":1}}],["恭喜您",{"2":{"1094":1}}],["教程合集",{"2":{"1531":1}}],["教程",{"2":{"1193":1}}],["教程视频里",{"2":{"1092":1}}],["教这门课对我来讲是一种享受",{"2":{"1176":1}}],["教育和工资的人口统计数据",{"2":{"296":1}}],["里我们可以利用奇异值分解",{"2":{"1159":1}}],["里面充满了复杂的步骤",{"2":{"1122":1}}],["里面有一个巧妙的数学技巧",{"2":{"1060":1}}],["里什么样",{"2":{"1111":1}}],["里无约束最小化函数",{"2":{"1111":1}}],["里运行时",{"2":{"1092":1}}],["里",{"2":{"1092":2}}],["里定义函数",{"2":{"1092":1}}],["停止容器",{"2":{"1343":1}}],["停止循环",{"2":{"1092":1}}],["停止计时器并将时间记录在列表中",{"2":{"615":1}}],["递增",{"2":{"1092":1}}],["递归被初始化为π1",{"2":{"519":1}}],["递归计算终止在这个t时间步",{"2":{"310":1}}],["竖轴的范围为",{"2":{"1091":1}}],["删掉这个图像",{"2":{"1091":1}}],["删除资源",{"2":{"1392":1}}],["删除容器",{"2":{"1343":1}}],["删除镜像",{"2":{"1342":1}}],["删除某个",{"2":{"1332":1}}],["删除分支",{"2":{"1329":1}}],["删除缺失值最多的列",{"2":{"1015":1}}],["删除",{"2":{"854":1}}],["删除这两个部分之间的waitall以模拟这个场景",{"2":{"797":1}}],["删除输入词",{"2":{"768":3}}],["删除未知词",{"2":{"751":1}}],["删除最后一个维度并沿通道维度连结",{"2":{"702":3}}],["删除我们不会使用的信息",{"2":{"667":1}}],["删除其中一个",{"2":{"498":1}}],["删除了h2和h5",{"2":{"171":1}}],["横轴是t变量",{"2":{"1091":1}}],["横轴表示z",{"2":{"1144":1}}],["横轴表示肿瘤的大小",{"2":{"1060":1}}],["横轴表示房子的面积",{"2":{"1060":1}}],["绘图与数据呈现",{"2":{"1297":1}}],["绘图数据",{"0":{"1091":1},"2":{"1193":1}}],["绘制图表",{"2":{"1167":1}}],["绘制图像列表",{"2":{"582":3}}],["绘制学习曲线",{"2":{"1138":1}}],["绘制学习算法等",{"2":{"1091":1}}],["绘制了变量t",{"2":{"1091":2}}],["绘制数据或学习算法所有输出",{"2":{"1091":1}}],["绘制数据点",{"2":{"981":1}}],["绘制单位矩阵",{"2":{"1088":1}}],["绘制代价函数的等高线图能",{"2":{"1082":1}}],["绘制函数y=f",{"2":{"986":1}}],["绘制函数u=f",{"2":{"981":1}}],["绘制f",{"2":{"979":1}}],["绘制前5个输入图像及其标签",{"2":{"945":1}}],["绘制锚框时",{"2":{"848":1}}],["绘制列表长度对的直方图",{"2":{"566":1}}],["绘制每个文本序列所包含的词元数量的直方图",{"2":{"566":1}}],["绘制训练和测试准确度的提高",{"2":{"477":1}}],["绘制训练和测试精度关于λ的函数",{"2":{"280":1}}],["绘制训练损失与模型复杂度",{"2":{"268":1}}],["绘制一个曲线图",{"2":{"178":1}}],["绘制计算图有助于我们可视化计算中操作符和变量的依赖关系",{"2":{"163":1}}],["绘制出x的值在初始化xi=1时如何下降",{"2":{"97":1}}],["魔方阵具有的特性是每行每列和对角线的求和都是相等的",{"2":{"1090":1}}],["赋予积木生命",{"2":{"1533":1}}],["赋给了它",{"2":{"1089":1}}],["赋值",{"2":{"1068":1}}],["冒号表示的是取这两行的每一列元素",{"2":{"1089":1}}],["冒号表示该行或该列的所有元素",{"2":{"1089":1}}],["码存成文本文档",{"2":{"1089":1}}],["窗口",{"2":{"1089":1,"1094":1}}],["敲入回车后",{"2":{"1088":1}}],["貌似国内学生喜欢用收费的matlab",{"2":{"1088":1}}],["据我所知",{"2":{"1088":1}}],["据我所见",{"2":{"1088":1}}],["据推测",{"2":{"475":1}}],["剩下的事情",{"2":{"1088":1}}],["剩余的3层信息去哪了",{"2":{"511":1}}],["剩余的所有单词大致遵循双对数坐标图上的一条直线",{"2":{"318":1}}],["五",{"0":{"1087":1,"1231":1,"1248":1,"1303":1,"1371":1},"1":{"1088":1,"1089":1,"1090":1,"1091":1,"1092":1,"1093":1,"1094":1,"1232":1,"1233":1,"1249":1,"1250":1},"2":{"1193":1}}],["五个卷积层",{"2":{"458":1}}],["备注2",{"2":{"1482":1}}],["备注1",{"2":{"1482":1}}],["备注",{"2":{"1086":1,"1443":1,"1459":1}}],["纵向深度",{"2":{"1084":1}}],["纵轴是y1",{"2":{"1091":1}}],["纵轴上",{"2":{"1060":1}}],["纵轴表示房价",{"2":{"1060":1}}],["度对角线作镜面反转",{"2":{"1077":1}}],["阶矩阵",{"2":{"1077":2}}],["阶数越高",{"2":{"317":1}}],["阶数为d的项的个数为",{"2":{"269":1}}],["逆",{"0":{"1077":1},"2":{"1193":1}}],["逆转transpose",{"2":{"382":4}}],["讲义中的向量一般都是列向量",{"2":{"1072":1}}],["谈谈如何加",{"2":{"1070":1}}],["告诉vue数据msg很重要",{"2":{"1520":1}}],["告诉你泛化的梯度下降算法",{"2":{"1069":1}}],["告诉我们",{"2":{"1026":1}}],["祝贺大家成功学会你的第一个机器学习算法",{"2":{"1069":1}}],["祝你好运",{"2":{"1059":1}}],["型的",{"2":{"1069":1}}],["批",{"2":{"1069":1}}],["批量修改",{"2":{"1491":1}}],["批量梯度下降法这个名字说明了我们需要考虑所有这一",{"2":{"1069":1}}],["批量梯度下降",{"2":{"1067":1,"1069":1}}],["批量数据",{"2":{"843":1}}],["批量的标签形状与batch",{"2":{"600":1}}],["批量规范化有许多有益的副作用",{"2":{"476":1}}],["批量规范化在全连接层和卷积层的使用略有不同",{"2":{"476":1}}],["批量规范化在训练模式和预测模式下的行为通常不同",{"2":{"471":1}}],["批量规范化利用小批量的均值和标准差",{"2":{"476":1}}],["批量规范化已经被证明是一种不可或缺的方法",{"2":{"475":1}}],["批量规范化被认为可以使优化更加平滑",{"2":{"475":1}}],["批量规范化是在卷积层或全连接层之后",{"2":{"473":1}}],["批量规范化的表现出与原始论文",{"2":{"475":1}}],["批量规范化的运算符为bn",{"2":{"469":1}}],["批量规范化的发明者非正式地假设",{"2":{"467":1}}],["批量规范化和其他层之间的一个关键区别是",{"2":{"468":1}}],["批量规范化层和激活层",{"2":{"505":1}}],["批量规范化层和暂退层一样",{"2":{"476":1}}],["批量规范化层",{"0":{"468":1},"1":{"469":1,"470":1,"471":1},"2":{"505":1}}],["批量规范化层在训练模式和预测模式下的计算结果也是不一样的",{"2":{"471":1}}],["批量规范化层在",{"2":{"467":1}}],["批量规范化bn根据以下表达式转换x",{"2":{"467":1}}],["批量规范化这种方法才是有效且稳定的",{"2":{"467":1}}],["批量规范化应用于单个可选层",{"2":{"467":1}}],["批量规范化使得研究人员能够训练100层以上的网络",{"2":{"466":1}}],["批量规范化",{"0":{"466":1},"1":{"467":1,"468":1,"469":1,"470":1,"471":1,"472":1,"473":1,"474":1,"475":1,"476":1,"477":1},"2":{"480":1}}],["批量规范化通常不如层规范化的效果好",{"2":{"406":1}}],["批量矩阵乘法",{"0":{"390":1}}],["批量中的文本序列为",{"2":{"341":1}}],["批量",{"2":{"196":1,"1069":1}}],["批量学习",{"0":{"195":1}}],["批量和通道",{"2":{"141":1}}],["批量大小是512",{"2":{"725":1}}],["批量大小是1",{"2":{"573":1}}],["批量大小和学习率",{"2":{"830":2}}],["批量大小和学习率的值通常是手动预先指定",{"2":{"613":1}}],["批量大小和序列长度分别设置为256和50",{"2":{"679":1}}],["批量大小和通道",{"2":{"141":3}}],["批量大小为4",{"2":{"573":1}}],["批量大小为n",{"2":{"553":1,"644":1}}],["批量大小的选择可能比没有批量规范化时更重要",{"2":{"467":1}}],["批量大小",{"2":{"129":4,"136":2,"325":8,"330":2,"332":10,"369":2,"396":1,"405":2,"407":1,"495":4,"545":1,"559":1,"573":2,"574":1,"674":15,"702":6,"713":12,"734":3,"763":3,"848":1,"853":1,"854":1,"882":1,"910":1,"932":2,"956":2}}],["站立在你想象的公园这座红色山上",{"2":{"1067":1}}],["喂给了神经网络",{"2":{"1099":1}}],["喂",{"2":{"1063":1}}],["良性",{"2":{"1061":1}}],["良性的肿瘤改成用",{"2":{"1060":1}}],["坏肿瘤",{"2":{"1061":1}}],["坏的方面",{"2":{"334":1}}],["糖尿病",{"2":{"1061":1}}],["奇异值分解",{"2":{"1061":1}}],["盗版",{"2":{"1061":1}}],["盗梦空间",{"2":{"487":1}}],["离线也能用",{"2":{"1540":1}}],["离线几乎无法操作",{"2":{"1318":1}}],["离",{"2":{"1146":2}}],["离说话人的距离不同每个麦克风记录下不同的声音",{"2":{"1061":1}}],["离散",{"2":{"1028":1}}],["嗯",{"2":{"1061":1}}],["谁在二号市场",{"2":{"1061":1}}],["谁说n95口罩可以预防病毒",{"2":{"660":1}}],["认为单词的长度通常比高度要大",{"2":{"1172":1}}],["认为作为函数返回值只能是一个值",{"2":{"1092":1}}],["认为要求百万像素的分辨率可能不是必要的",{"2":{"151":1}}],["认识组里的所有人",{"2":{"1061":1}}],["圈子的朋友",{"2":{"1061":1}}],["别的都不知道",{"2":{"1061":1}}],["别无妙方",{"2":{"193":1}}],["叫做在线学习机制",{"2":{"1168":1}}],["叫做分类问题",{"2":{"1063":1}}],["叫做无监督学习",{"2":{"1061":1}}],["叫支持向量机",{"2":{"1060":1}}],["肿瘤分类",{"2":{"1182":1}}],["肿瘤为恶性",{"2":{"1140":1}}],["肿瘤细胞尺寸的一致性和形状的一致性等等",{"2":{"1060":1}}],["肿瘤图像",{"2":{"289":1}}],["恶性肿瘤",{"2":{"1061":1}}],["恶性肿瘤有害并且十分危险",{"2":{"1060":1}}],["恶性的继续用",{"2":{"1060":1}}],["拟合程度提高",{"2":{"1132":1}}],["拟合的越好",{"2":{"1114":1}}],["拟合一条直线",{"2":{"1060":1}}],["拟合如此多的参数还需要收集大量的数据",{"2":{"151":1}}],["哎呀",{"2":{"1059":1}}],["锯子",{"2":{"1059":1}}],["您现在知道如何应用pca",{"2":{"1161":1}}],["您还可以继续使用此提交密码",{"2":{"1094":1}}],["您可以使用鼠标",{"2":{"1059":1}}],["您的电子邮件程序能更好地学习如何过滤垃圾邮件",{"2":{"1059":1}}],["您能通过调优超参数来改进结果吗",{"2":{"770":1}}],["报表",{"2":{"1301":1}}],["报表生成",{"2":{"1053":1}}],["报告某些email为垃圾邮件",{"2":{"1059":1}}],["垃圾邮件",{"2":{"1059":1}}],["垃圾邮件发送者们变得聪明起来",{"2":{"187":1}}],["顶部是tom",{"2":{"1059":1}}],["曹操到",{"2":{"1059":1}}],["说明",{"2":{"1232":1,"1449":1,"1502":1,"1528":1}}],["说明你没有完全答对",{"2":{"1094":1}}],["说明了这个估计器是如何工作的",{"2":{"299":1}}],["说这是锤子",{"2":{"1059":1}}],["说曹操",{"2":{"1059":1}}],["赢得比赛的概率",{"2":{"1059":1}}],["棋盘位置",{"2":{"1059":1}}],["招聘人员联系我",{"2":{"1058":1}}],["梦想",{"2":{"1058":1}}],["仔细想一想",{"2":{"1058":1}}],["硅谷和世界各地最优秀的人是怎样做的",{"2":{"1059":1}}],["硅谷中大量的问题都收到机器学习的影响",{"2":{"1058":1}}],["硅片的数量大约增加了四倍",{"2":{"815":1}}],["照片标记",{"2":{"1058":1}}],["照片的实际标签分布显然是不均匀的",{"2":{"188":1}}],["必应搜索到你需要的内容",{"2":{"1058":1}}],["必须使用name配置项",{"2":{"1482":1}}],["必须使用ref",{"2":{"1458":1}}],["必须在子类中实现",{"2":{"1416":1}}],["必须包含",{"2":{"1408":1}}],["必须要有",{"2":{"1184":1}}],["必须与x的维数",{"2":{"998":3}}],["必须是一个将被传递给",{"2":{"488":1}}],["必须构建自定义层",{"2":{"412":1}}],["欢迎关注",{"2":{"1305":1}}],["欢迎来到我的小站",{"0":{"1542":1},"1":{"1543":1,"1544":1,"1545":1,"1546":1,"1547":1,"1548":1,"1549":1,"1550":1}}],["欢迎来到",{"2":{"1176":1}}],["欢迎",{"0":{"1058":1},"2":{"1193":1}}],["欢迎交流学习",{"2":{"1056":1}}],["博主的话",{"0":{"1056":1}}],["博客写作",{"2":{"1054":1}}],["博客评论和论坛讨论等",{"2":{"691":1}}],["博客文章管理",{"2":{"11":1}}],["✍️",{"0":{"1056":1,"1545":1}}],["集成让开发更高效",{"2":{"1527":1}}],["集成pip和virtualenv",{"2":{"1279":1}}],["集成搜索引擎",{"2":{"1054":1}}],["集群交互",{"2":{"1392":1}}],["集群的逻辑隔离单位",{"2":{"1387":1}}],["集群的入口",{"2":{"1376":1}}],["集群内部访问",{"2":{"1384":1}}],["集群管理",{"2":{"1374":1}}],["集群管理和编排工具",{"2":{"1348":1}}],["集群化",{"2":{"1356":1}}],["集群环境下的容器编排",{"2":{"1349":1}}],["集群由以下部分组成",{"2":{"1210":1}}],["集群",{"0":{"1210":1},"2":{"1381":1,"1393":1}}],["集合分布",{"2":{"1208":1}}],["集合",{"2":{"1196":1,"1216":1}}],["集内的顺序有时却很重要",{"2":{"293":1}}],["辅助写代码",{"2":{"1053":1}}],["拆解目标为可执行子任务",{"2":{"1052":1}}],["拆分验证集并整理训练集",{"2":{"902":1}}],["拆分可以在层之间",{"2":{"838":1}}],["拆分层内的工作",{"2":{"832":1}}],["拆分到多个设备",{"2":{"681":1}}],["知识问答",{"2":{"1051":1}}],["知道如何对一个文本序列进行分类是不够的",{"2":{"664":1}}],["知道真实概率的人所经历的惊异程度",{"2":{"652":1}}],["知道未来数据何时可用对隐马尔可夫模型是有益的",{"2":{"519":1}}],["知道了如何访问参数后",{"2":{"434":1}}],["📬",{"0":{"1550":1}}],["😄",{"2":{"1543":1}}],["👋",{"0":{"1542":1},"1":{"1543":1,"1544":1,"1545":1,"1546":1,"1547":1,"1548":1,"1549":1,"1550":1}}],["📱",{"2":{"1529":1}}],["🛍️",{"2":{"1529":1}}],["🚩",{"0":{"1527":1}}],["🐳",{"0":{"1338":1},"1":{"1339":1,"1340":1,"1341":1,"1342":1,"1343":1,"1344":1,"1345":1,"1346":1,"1347":1,"1348":1,"1349":1,"1350":1,"1351":1}}],["📈",{"0":{"1303":1}}],["🛠",{"0":{"1297":1}}],["🛠️",{"0":{"1052":1,"1543":1},"2":{"1527":1}}],["🔍",{"0":{"1296":1,"1530":1}}],["🐍",{"0":{"1295":1},"1":{"1296":1,"1297":1,"1298":1,"1299":1,"1300":1,"1301":1,"1302":1,"1303":1,"1304":1,"1305":1,"1306":1}}],["📡",{"0":{"1206":1},"1":{"1207":1}}],["🔑",{"0":{"1204":1}}],["📝",{"0":{"1202":1},"2":{"1529":1}}],["🔄",{"0":{"1200":1}}],["💾",{"0":{"1198":1}}],["🗂️",{"0":{"1197":1}}],["📄",{"0":{"1196":1}}],["🟢",{"0":{"1195":1}}],["📚",{"0":{"1055":1,"1306":1,"1546":1},"2":{"1531":1}}],["💡",{"0":{"1054":1}}],["🕹️",{"2":{"1053":1}}],["📊",{"2":{"1053":1,"1529":1}}],["🚀",{"0":{"1051":1,"1265":1,"1304":1},"1":{"1266":1,"1267":1,"1268":1,"1269":1,"1270":1,"1271":1,"1272":1,"1273":1,"1274":1,"1275":1,"1276":1,"1277":1,"1278":1,"1279":1,"1280":1,"1281":1,"1282":1,"1283":1,"1284":1,"1285":1,"1286":1,"1287":1,"1288":1,"1289":1,"1290":1,"1291":1,"1292":1,"1293":1,"1294":1}}],["🔁",{"2":{"1050":1,"1052":1}}],["🔧",{"2":{"1050":1,"1052":1,"1527":1}}],["🍜",{"0":{"1544":1}}],["🌟",{"0":{"1532":1},"1":{"1533":1,"1534":1,"1535":1,"1536":1,"1537":1,"1538":1,"1539":1,"1540":1,"1541":1}}],["🎮",{"2":{"1529":1}}],["🌿",{"0":{"1526":1,"1549":1},"1":{"1527":1,"1528":1,"1529":1,"1530":1,"1531":1}}],["🌱",{"0":{"1298":1},"1":{"1299":1,"1300":1,"1301":1}}],["🌍",{"0":{"1210":1}}],["🏗️",{"0":{"1205":1}}],["🌳",{"0":{"1199":1}}],["🌐",{"0":{"1528":1},"2":{"1053":1}}],["🎯",{"0":{"1305":1},"2":{"1050":1,"1052":1}}],["🏷️conditional",{"2":{"1035":2}}],["🏷️chap",{"2":{"65":1,"134":1,"204":1,"281":1,"305":1,"379":1,"421":1,"492":1,"550":1,"587":1,"663":1,"754":1,"824":1,"886":1,"987":1}}],["🏷️lstm",{"2":{"553":1,"554":1,"555":1,"556":1}}],["🏷️table",{"2":{"813":2}}],["🏷️tab",{"2":{"300":1,"744":1}}],["🏷️img",{"2":{"136":2,"141":1,"142":1,"152":1}}],["🏷️subseq",{"2":{"995":1,"996":1}}],["🏷️subsec",{"2":{"55":1,"158":1,"190":1,"191":1,"234":1,"247":1,"294":1,"307":1,"340":1,"342":1,"369":1,"390":1,"397":1,"398":1,"568":1,"610":1,"616":1,"624":1,"640":1,"642":1,"643":1,"644":1,"647":1,"649":1,"708":1,"721":1,"734":1,"735":1,"736":1,"737":1,"742":1,"757":1,"768":1,"776":1,"783":1,"850":1,"854":1,"912":1,"970":1,"983":1,"1000":1,"1001":1,"1019":1,"1035":1}}],["🏷️sec",{"2":{"19":1,"24":1,"32":1,"38":1,"53":1,"66":1,"76":1,"78":1,"84":1,"106":1,"112":1,"119":1,"125":1,"135":1,"140":1,"145":1,"151":1,"161":1,"168":1,"205":1,"216":1,"224":1,"228":1,"240":1,"251":1,"269":1,"306":1,"315":1,"324":1,"329":1,"338":1,"345":1,"354":1,"360":1,"367":1,"373":1,"380":1,"385":1,"395":1,"403":1,"417":1,"422":1,"445":1,"454":1,"466":1,"486":1,"493":1,"499":1,"506":1,"512":1,"518":1,"526":1,"532":1,"538":1,"551":1,"564":1,"572":1,"574":1,"576":1,"581":1,"588":1,"598":1,"608":1,"622":1,"629":1,"639":1,"656":1,"664":1,"672":1,"685":1,"691":1,"698":1,"707":1,"712":1,"718":1,"725":1,"730":1,"741":1,"747":1,"755":1,"760":1,"771":1,"780":1,"789":1,"795":1,"800":1,"816":1,"825":1,"831":1,"840":1,"847":1,"857":1,"861":1,"869":1,"877":1,"887":1,"911":1,"930":1,"936":1,"943":1,"952":1,"967":1,"973":1,"980":1,"988":1,"1010":1,"1016":1,"1025":1}}],["🏷️fig",{"2":{"40":3,"50":1,"120":1,"122":1,"126":1,"146":1,"157":1,"163":1,"171":1,"181":2,"183":1,"207":2,"213":1,"231":1,"259":1,"282":2,"289":1,"291":1,"292":1,"294":1,"295":1,"297":1,"298":1,"299":1,"311":1,"312":1,"319":1,"340":1,"341":1,"346":1,"347":1,"355":2,"356":1,"367":1,"374":1,"380":1,"397":1,"404":1,"422":1,"449":1,"455":1,"458":1,"479":2,"487":1,"488":1,"494":1,"500":1,"501":2,"502":1,"508":1,"513":2,"515":1,"519":1,"520":1,"526":1,"532":1,"540":1,"541":1,"542":1,"572":1,"574":1,"577":1,"611":1,"618":1,"619":1,"641":1,"657":1,"658":1,"659":1,"660":1,"663":1,"672":1,"673":1,"685":1,"698":1,"699":3,"701":1,"709":1,"712":1,"733":1,"734":1,"754":1,"783":1,"785":1,"790":3,"797":1,"800":1,"801":1,"807":1,"808":1,"809":1,"810":1,"811":3,"816":1,"832":2,"833":1,"841":3,"842":3,"843":2,"849":1,"851":1,"862":1,"870":1,"887":1,"899":1,"916":1,"917":1,"937":1,"938":2,"939":1,"940":1,"943":1,"953":1,"968":1,"969":1,"980":1,"1025":1}}],["🧭",{"0":{"1208":1,"1529":1,"1548":1},"2":{"1053":1}}],["🤝",{"2":{"1053":1}}],["🧪",{"0":{"1053":1}}],["🧮",{"2":{"1052":1}}],["🧩",{"0":{"1201":1,"1209":1},"2":{"1050":1,"1527":1}}],["🧠",{"0":{"1050":1,"1237":1},"1":{"1238":1,"1239":1,"1240":1,"1241":1,"1242":1,"1243":1,"1244":1,"1245":1,"1246":1,"1247":1,"1248":1,"1249":1,"1250":1,"1251":1,"1252":1,"1253":1,"1254":1,"1255":1,"1256":1,"1257":1,"1258":1,"1259":1,"1260":1,"1261":1,"1262":1,"1263":1,"1264":1},"2":{"1052":1}}],["🤖",{"0":{"1049":1},"1":{"1050":1,"1051":1,"1052":1,"1053":1,"1054":1,"1055":1,"1056":1}}],["$once",{"2":{"1525":1}}],["$off",{"2":{"1525":1}}],["$parent",{"2":{"1502":1}}],["$parent用于",{"2":{"1502":1}}],["$patch",{"2":{"1491":1}}],["$emit",{"2":{"1498":1}}],["$event",{"2":{"1498":2,"1500":4}}],["$children被砍掉了",{"2":{"1496":1}}],["$subscribe",{"0":{"1494":1},"2":{"1494":2}}],["$refs",{"2":{"1502":1}}],["$refs用于",{"2":{"1502":1}}],["$remote",{"2":{"1368":1}}],["$route和$router变成了两个hooks",{"2":{"1485":1}}],["$矩阵进行均值归一化处理",{"2":{"1192":1}}],["$中",{"2":{"1143":1}}],["$是一个非常小的值",{"2":{"1124":1}}],["$值减少了一个额外的值",{"2":{"1116":1}}],["$host",{"2":{"1368":1}}],["$h",{"2":{"1101":1}}],["$乘以",{"2":{"1093":1}}],["$设为a",{"2":{"1089":1}}],["$attrs会自动排除props中声明的属性",{"2":{"1501":1}}],["$attrs是一个对象",{"2":{"1501":1}}],["$attrs用于实现当前组件的父组件",{"2":{"1501":1}}],["$attrs",{"0":{"1501":1},"2":{"1501":1}}],["$a",{"2":{"1089":1}}],["$的值减小呢",{"2":{"1115":1}}],["$的值",{"2":{"1110":1}}],["$的值等于",{"2":{"1092":1}}],["$的对角线元素的和",{"2":{"1090":1}}],["$的前10个元素存入",{"2":{"1089":1}}],["$的替代方法",{"2":{"1085":1}}],["$y",{"2":{"1089":1,"1192":1}}],["$",{"2":{"1048":4,"1101":1,"1110":6,"1112":1,"1115":4,"1120":2,"1121":6,"1124":4,"1141":1,"1143":1,"1166":2,"1181":1,"1184":1,"1315":6,"1371":1,"1398":1,"1417":3,"1422":3,"1425":4}}],["$$cost",{"2":{"1165":1}}],["$$x^",{"2":{"1160":1}}],["$$|",{"2":{"1000":3}}],["$$f",{"2":{"981":1}}],["$$y",{"2":{"262":1,"271":1}}],["$$",{"2":{"235":2,"236":2,"237":2,"262":1,"271":1,"334":2,"981":1,"1000":3,"1160":2,"1165":1,"1167":1}}],["✅",{"0":{"1211":1,"1299":1,"1300":1,"1301":1,"1547":1},"2":{"1048":2,"1054":4}}],["脚本",{"2":{"1047":1,"1544":1}}],["客户端",{"2":{"1340":2}}],["客户端请求",{"2":{"1208":1}}],["客户端访问入口",{"2":{"1208":1}}],["客户端通过事件源",{"2":{"1047":1}}],["客户端通过启动一个子进程",{"2":{"1047":1}}],["客户会提供隐性反馈",{"2":{"294":1}}],["客户会提供明确反馈",{"2":{"294":1}}],["响应式系统",{"2":{"1527":1}}],["响应式对象",{"2":{"1456":1,"1518":1}}],["响应式对象=",{"2":{"1456":1}}],["响应",{"0":{"1046":1}}],["响尾蛇和乌梢蛇血缘上可能很接近",{"2":{"291":1}}],["​\\t\\t\\t\\t\\t\\t\\t$$",{"2":{"1167":1}}],["​这样一项",{"2":{"1143":1}}],["​不同所以还是有很大差别",{"2":{"1117":1}}],["​的神经元以及表示",{"2":{"1102":1}}],["​部分的神经元",{"2":{"1102":1}}],["​",{"2":{"1044":1,"1069":3,"1086":3,"1102":1,"1116":5,"1117":5,"1144":1,"1145":3,"1165":4,"1166":4,"1168":2}}],["协同过滤优化目标",{"2":{"1190":1}}],["协同过滤算法",{"0":{"1190":1},"2":{"1193":1}}],["协同过滤算法使用步骤如下",{"2":{"1189":1}}],["协同过滤算法可以同时学习这两者",{"2":{"1189":1}}],["协同过滤",{"0":{"1189":1},"2":{"1193":1}}],["协方差矩阵σ为",{"2":{"1185":1}}],["协议向客户端推送事件",{"2":{"1047":1}}],["协议消息",{"2":{"1044":1}}],["协议消息转换为",{"2":{"1044":1}}],["协变量偏移纠正",{"0":{"191":1}}],["协变量偏移假设也会得到满足",{"2":{"182":1}}],["协变量偏移是一种自然假设",{"2":{"181":1}}],["协变量偏移可能是最为广泛研究的",{"2":{"181":1}}],["协变量偏移",{"0":{"181":1}}],["轻量快速的热重载",{"2":{"1444":1}}],["轻量易上手",{"2":{"1355":1}}],["轻量高效",{"2":{"1354":1}}],["轻量化",{"2":{"1339":1}}],["轻量现代项目",{"2":{"1294":1}}],["轻量多版本python环境和依赖管理工具",{"2":{"1291":1}}],["轻量级现代python项目管理工具",{"2":{"1287":1}}],["轻量级程序",{"2":{"1042":1}}],["轻松应对海量数据",{"2":{"1195":1}}],["轻度认知障碍",{"2":{"251":1}}],["旨在规范大型语言模型",{"2":{"1040":1}}],["月推出的开放标准",{"2":{"1040":1}}],["吗",{"2":{"1038":1}}],["灯开关的位置和房间的亮度并不是",{"2":{"1034":1}}],["边缘化和独立性假设来分析多个随机变量",{"2":{"1037":1}}],["边际化结果的概率或分布称为边际概率",{"2":{"1033":1}}],["边际化",{"0":{"1033":1}}],["边界框预测层的设计与类别预测层的设计类似",{"2":{"955":1}}],["边界框预测层",{"0":{"955":1}}],["边界框少于m的图像将被非法边界框填充",{"2":{"932":1}}],["边界框是矩形的",{"2":{"858":1}}],["边界框",{"0":{"858":1}}],["边界由x¯而不是xt表示",{"2":{"115":1}}],["贝叶斯定理",{"0":{"1032":1}}],["贝恩和1890年詹姆斯",{"2":{"299":1}}],["焦距",{"2":{"1029":1}}],["光圈",{"2":{"1029":1}}],["光学字符识别",{"2":{"300":1}}],["咳嗽",{"2":{"1029":1}}],["询问某人的身高是否落入给定的区间",{"2":{"1028":1}}],["∅",{"2":{"1027":1}}],["⋃i=1∞ai",{"2":{"1027":1}}],["笼统来说",{"2":{"1026":1}}],["职业",{"2":{"1025":1}}],["切换分支",{"2":{"1318":1,"1329":1}}],["切片",{"2":{"1023":1}}],["切线的斜率",{"2":{"981":1}}],["入门关键命令",{"2":{"1294":1}}],["入门示例",{"0":{"1269":1,"1273":1,"1277":1,"1281":1,"1285":1,"1289":1,"1293":1}}],["入门",{"0":{"1017":1},"2":{"1294":1}}],["典型的方法包括插值法和删除法",{"2":{"1012":1}}],["典型的硬盘是多少",{"2":{"815":1}}],["巷子类型为",{"2":{"1012":1}}],["巷子类型",{"2":{"1011":1,"1012":1}}],["逗号分隔值",{"2":{"1011":1}}],["∀i",{"2":{"1000":1}}],["曾经使用过电子表格软件或已阅读过",{"2":{"992":1}}],["曾经sigmoid函数1",{"2":{"242":1}}],["元素15对应的索引值为2",{"2":{"1090":1}}],["元素都为2",{"2":{"1088":1}}],["元素",{"2":{"1017":3,"1089":1}}],["元素xi是一个标量",{"2":{"990":1}}],["元组类型",{"2":{"1405":1}}],["元组",{"2":{"759":1,"1216":1}}],["胆固醇水平",{"2":{"990":1}}],["属于",{"2":{"989":1}}],["属性值是函数",{"2":{"1497":1}}],["属性值是非函数",{"2":{"1497":1}}],["属性的类型",{"2":{"1433":1}}],["属性修饰符",{"0":{"1424":1},"1":{"1425":1,"1426":1,"1427":1,"1428":1}}],["属性装饰器",{"0":{"1255":1}}],["属性访问它",{"2":{"974":1}}],["属性",{"0":{"1468":1},"2":{"404":1,"1433":2,"1452":1,"1502":1}}],["华氏度",{"2":{"989":1}}],["华尔街日报",{"2":{"772":1}}],["链式法则可以用来微分复合函数",{"2":{"985":1}}],["链式法则可以被用来微分复合函数",{"2":{"984":1}}],["链式法则给出",{"2":{"984":1}}],["链式法则",{"0":{"984":1}}],["链条",{"2":{"424":1}}],["∇x∥x∥2=∇xx⊤x=2x",{"2":{"983":1}}],["∇xf",{"2":{"983":1}}],["∇f",{"2":{"57":1,"59":1,"113":1}}],["古希腊人在这样的形状上刻内接多边形",{"2":{"980":1}}],["古希腊人把一个多边形分成三角形",{"2":{"980":1}}],["古登堡计划",{"2":{"316":1}}],["γlog⁡pj",{"2":{"966":1}}],["γ和β是需要与其他模型参数一起学习的参数",{"2":{"467":1}}],["γ和偏移参数",{"2":{"467":1}}],["做过的实验",{"2":{"1545":1}}],["做过编程练习的同学应该可以感受到这些练习或多或少能帮助你",{"2":{"1122":1}}],["做数据存储",{"2":{"1543":1}}],["做动画",{"2":{"1539":1}}],["做更精准的预测",{"2":{"1100":1}}],["做法如下",{"2":{"1093":1}}],["做一个视觉艺术家",{"2":{"1536":1}}],["做一个调查或做这些不同飞行员的测试",{"2":{"1156":1}}],["做一个中止循环的命令",{"2":{"1092":1}}],["做一些计算",{"2":{"1099":1}}],["做一两次是有益的",{"2":{"591":1}}],["做运算",{"2":{"1090":1}}],["做哪些事",{"2":{"1089":1}}],["做为最终输出",{"2":{"964":1}}],["绝对误差的和中的示例数",{"2":{"963":3}}],["绝对误差的和",{"2":{"963":3}}],["绝对位置信息",{"0":{"399":1}}],["白色和黑色分别表示边框和背景",{"2":{"945":1}}],["兴趣区域对齐层的输出包含了所有与兴趣区域的形状相同的特征图",{"2":{"940":1}}],["兴趣区域对齐层",{"2":{"940":1}}],["兴趣区域汇聚层可从形状各异的兴趣区域中均抽取出形状相同的特征",{"2":{"938":1}}],["坐标轴上的两种和右边的3种",{"2":{"1060":1}}],["坐标为中心生成的所有锚框的类别预测",{"2":{"954":1}}],["坐标的通道里包含了以输入特征图",{"2":{"954":1}}],["坐标",{"2":{"938":1}}],["坐标值",{"2":{"932":1}}],["坐标之间进行转换",{"2":{"859":1}}],["迁移方便",{"2":{"1353":1}}],["迁移风格以及去噪三方面的相对重要性",{"2":{"925":1}}],["迁移学习将从源数据集中学到的知识迁移到目标数据集",{"2":{"875":1}}],["越到外面的圈的范围越小",{"2":{"1185":1}}],["越接近",{"2":{"1154":1}}],["越高越好",{"2":{"1139":2,"1140":2}}],["越过一次",{"2":{"1068":1}}],["越来越大的数据集",{"2":{"1058":1}}],["越容易抽取图像的细节信息",{"2":{"920":1}}],["越靠近输入层",{"2":{"920":1}}],["虚拟主机等",{"2":{"1365":1}}],["虚拟机",{"2":{"1346":1,"1353":1}}],["虚拟机的存储在数量和速度上都能根据用户需要进行动态分配",{"2":{"806":1}}],["虚线箭头方向",{"2":{"917":1}}],["风格的",{"2":{"1447":2}}],["风格数据",{"2":{"1211":1}}],["风格图像在各个风格层的格拉姆矩阵styles",{"2":{"926":1}}],["风格转移的损失函数是内容损失",{"2":{"925":1}}],["风格损失令合成图像与风格图像在风格特征上接近",{"2":{"928":1}}],["风格损失和全变分损失",{"2":{"925":1}}],["风格损失和全变分损失3部分组成",{"2":{"921":1}}],["风格损失和总变化损失的加权和",{"2":{"925":1}}],["风格损失的平方误差函数的两个格拉姆矩阵输入分别基于合成图像与风格图像的风格层输出",{"2":{"923":1}}],["风格损失与内容损失类似",{"2":{"923":1}}],["风格损失",{"0":{"923":1}}],["风格损失使合成图像与风格图像在风格特征上接近",{"2":{"917":1}}],["风格迁移常用的损失函数由3部分组成",{"2":{"917":1,"928":1}}],["风格迁移",{"0":{"916":1},"1":{"917":1,"918":1,"919":1,"920":1,"921":1,"922":1,"923":1,"924":1,"925":1,"926":1,"927":1,"928":1,"929":1}}],["风险函数f和经验风险函数g",{"2":{"99":1}}],["探讨何时使用二者",{"2":{"1059":1}}],["探讨如何做出最好的实践类型决策",{"2":{"1059":1}}],["探测小目标",{"2":{"912":1}}],["探索各种选择来改进它",{"2":{"586":1}}],["冻结参数",{"2":{"905":2}}],["冻结了预训练的双向lstm模型中的所有权重",{"2":{"731":1}}],["吉娃娃和约克夏等",{"2":{"900":1}}],["萨摩耶",{"2":{"900":1}}],["腊肠",{"2":{"900":1}}],["彩色",{"2":{"900":1}}],["张三",{"2":{"1398":1,"1419":1,"1421":1,"1433":1,"1445":1,"1451":1,"1454":1,"1455":2,"1459":1,"1463":1,"1464":1,"1465":1,"1466":1,"1468":1,"1469":1}}],["张图像",{"2":{"890":1}}],["张量中的元素可以通过索引访问",{"2":{"1020":1}}],["张量中的每个值都称为张量的",{"2":{"1017":3}}],["张量表示一个由数值组成的数组",{"2":{"1017":1}}],["张量类支持自动微分",{"2":{"1016":1}}],["张量算法的基本性质",{"0":{"994":1}}],["张量将变得更加重要",{"2":{"993":1}}],["张量用特殊字体的大写字母表示",{"2":{"993":1}}],["张量",{"0":{"993":1},"2":{"993":2,"994":1,"1017":3}}],["张量可以具有任意长度",{"2":{"990":1}}],["张量是在cpu上创建的",{"2":{"447":1}}],["张量是在内存中创建的",{"2":{"446":1}}],["张量与gpu",{"0":{"447":1},"1":{"448":1,"449":1,"450":1}}],["张量的大小不会改变",{"2":{"1017":1}}],["张量的某个轴的维数就是这个轴的长度",{"2":{"991":1}}],["张量的维度用来表示张量具有的轴数",{"2":{"991":1}}],["张量的值全部为零",{"2":{"545":1}}],["张量的每个轴分别对应样本",{"2":{"494":1}}],["张量的形状为",{"2":{"396":1}}],["张量的最后一个维度等于词表大小",{"2":{"330":1}}],["张量全用0填充",{"2":{"332":1}}],["登录kaggle后",{"2":{"889":1,"901":1}}],["登录kaggle网站",{"2":{"213":1}}],["船和卡车",{"2":{"888":1}}],["鹿",{"2":{"888":1}}],["鸟类",{"2":{"888":1}}],["鸟类学并不是航空创新的主要驱动力",{"2":{"619":1}}],["汽车和鸟类的一些图像",{"2":{"888":1}}],["汽车",{"2":{"888":1,"1103":1,"1456":1,"1457":1}}],["继而展示如何使用完全卷积网络对图像进行语义分割",{"2":{"886":1}}],["继续使用之前的简化",{"2":{"1145":1}}],["继续使用fashion",{"2":{"622":1}}],["继续沿用刚才预测肿瘤性质的例子",{"2":{"1140":1}}],["继续提高finetune",{"2":{"876":1}}],["秉承计算机视觉中利用分层表示的关键思想",{"2":{"886":1}}],["摄影爱好者也许接触过滤波器",{"2":{"916":1}}],["摄像头监控",{"2":{"886":1}}],["摄取照片并预测笑脸",{"2":{"285":1}}],["储存训练损失",{"2":{"883":3}}],["饱和度或亮度",{"2":{"1097":1}}],["饱和度",{"2":{"880":1}}],["饱和度和色调",{"2":{"880":1}}],["亮度",{"2":{"880":1}}],["颜色等因素来降低模型对颜色的敏感度",{"2":{"877":1}}],["颜色通道",{"2":{"872":1}}],["颜色和纹理",{"2":{"455":1}}],["红尘滚滚",{"2":{"1295":1}}],["红",{"2":{"872":1,"1061":1}}],["红色警戒",{"2":{"1508":1}}],["红色封闭曲线表示的范围",{"2":{"1146":1}}],["红色",{"2":{"50":1,"158":1,"993":1}}],["含入门教程",{"0":{"1265":1},"1":{"1266":1,"1267":1,"1268":1,"1269":1,"1270":1,"1271":1,"1272":1,"1273":1,"1274":1,"1275":1,"1276":1,"1277":1,"1278":1,"1279":1,"1280":1,"1281":1,"1282":1,"1283":1,"1284":1,"1285":1,"1286":1,"1287":1,"1288":1,"1289":1,"1290":1,"1291":1,"1292":1,"1293":1,"1294":1}}],["含义就是你希望决策界不通过原点",{"2":{"1145":1}}],["含目标还是背景",{"2":{"939":1}}],["含着两个类别的1000张图片用于训练",{"2":{"872":1}}],["含并行连结的网络",{"0":{"486":1},"1":{"487":1,"488":1,"489":1,"490":1,"491":1},"2":{"492":1}}],["纹理",{"2":{"869":1}}],["映射类型与泛型",{"0":{"1435":1}}],["映射类型",{"0":{"1410":1}}],["映射化简和数据并行对于大规模机器学习问题而言是非常重要的概念",{"2":{"1169":1}}],["映射化简和数据并行",{"0":{"1169":1},"2":{"1193":1}}],["映射到备份到一个近似你原有的高维数据",{"2":{"1161":1}}],["映射到另一个实数",{"2":{"1018":1}}],["映射到输入图像的坐标",{"2":{"863":1}}],["映射后的x",{"2":{"863":1}}],["映射成当前时间步的输出词元",{"2":{"534":1}}],["转折点是我们的模型开始过拟合训练数据集的时候",{"2":{"1132":1}}],["转置两次",{"2":{"1090":1}}],["转置",{"0":{"1077":1},"2":{"1193":1}}],["转置卷积为何以矩阵变换命名呢",{"2":{"970":1}}],["转置卷积与常规卷积以相同方式运作",{"2":{"969":1}}],["转置卷积的输出中将删除第一和最后的行与列",{"2":{"969":1}}],["转置卷积通过卷积核广播输入元素",{"2":{"971":1}}],["转置卷积通过卷积核",{"2":{"968":1}}],["转置卷积",{"0":{"967":1},"1":{"968":1,"969":1,"970":1,"971":1,"972":1},"2":{"967":1}}],["转置卷积层能够交换卷积层的正向传播函数和反向传播函数",{"2":{"970":1,"971":1}}],["转置卷积层输出的高或宽会与输入图像的尺寸有偏差",{"2":{"866":1}}],["转置卷积层将图像的高和宽分别放大了2倍",{"2":{"863":1}}],["转置卷积核会将输入的高和宽分别放大s倍",{"2":{"862":1}}],["转换后的结果不共享内存",{"2":{"1022":1}}],["转换到",{"2":{"858":2}}],["转换成小批量数据集用于训练",{"2":{"568":1}}],["转换",{"2":{"477":1}}],["转换为ref对象",{"2":{"1459":1}}],["转换为numpy张量",{"2":{"1022":2}}],["转换为numpy类型的变量和通过z",{"2":{"791":1}}],["转换为其他python对象",{"0":{"1022":1}}],["转换为张量格式",{"0":{"1013":1}}],["转换为标量也是阻塞器",{"2":{"791":1}}],["转换为ht",{"2":{"573":1}}],["转换为编码后的状态",{"2":{"534":1}}],["转换为e−δ≤y^y≤eδ",{"2":{"210":1}}],["转换为形状为",{"2":{"136":1}}],["采用基于",{"2":{"1527":1}}],["采用",{"2":{"1196":1,"1340":1}}],["采用之前学习而来的ureduce将输入的特征x转换成特征向量z",{"2":{"1162":1}}],["采用的不是原始特征",{"2":{"1146":1}}],["采用卷积神经网络实现了从图像像素到像素类别的变换",{"2":{"861":1}}],["采纳一些特征作为输出",{"2":{"1099":1}}],["采样概率为p",{"2":{"775":1}}],["采样分布通过变量sampling",{"2":{"775":1}}],["采样噪声添加到输入x",{"2":{"170":1}}],["画在纵轴这里",{"2":{"1145":1}}],["画之前",{"2":{"858":1}}],["画出我的数据集",{"2":{"1063":1}}],["画出的词频图",{"2":{"318":1}}],["画出相应的计算图",{"2":{"167":1}}],["安防领域则需要检测异常目标",{"2":{"857":1}}],["安装mitt",{"2":{"1499":1}}],["安装官方推荐的vscode插件",{"2":{"1444":1}}],["安装或者升级你的",{"2":{"1443":1}}],["安装指定版本依赖",{"2":{"1281":1}}],["安装包",{"2":{"1277":1}}],["安装支持cuda10",{"2":{"445":1}}],["安装依赖",{"2":{"13":1,"1273":1,"1285":1,"1289":1,"1293":1,"1315":1}}],["安装",{"0":{"13":1,"1268":1,"1272":1,"1276":1,"1280":1,"1284":1,"1288":1,"1292":1},"2":{"1235":1,"1304":1}}],["道路和障碍物的位置来规划行进线路",{"2":{"857":1}}],["马上就能同样得到p",{"2":{"1034":1}}],["马上用一个具体的例子来展示它是如何工作的",{"2":{"854":1}}],["马",{"2":{"888":1}}],["马尔可夫模型",{"0":{"348":1}}],["马尔可夫模型与n元语法",{"0":{"317":1}}],["负载均衡器",{"2":{"1359":1}}],["负载均衡",{"0":{"1362":1,"1369":1},"2":{"1351":1}}],["负责调度",{"2":{"1381":1}}],["负责和",{"2":{"1377":1}}],["负责运行实际应用",{"2":{"1377":1}}],["负责",{"2":{"1376":1,"1394":2}}],["负责控制器逻辑",{"2":{"1376":1}}],["负责整个集群的调度与管理",{"2":{"1376":1}}],["负责镜像构建",{"2":{"1340":1}}],["负责查询路由",{"2":{"1208":1}}],["负责查询解析",{"2":{"1203":1}}],["负责数据存储",{"2":{"1203":1}}],["负类",{"2":{"872":1}}],["负类锚框的偏移量被标记为零",{"2":{"853":1}}],["负类的偏移量不应影响目标函数",{"2":{"853":1}}],["负采样通过考虑相互独立的事件来构造损失函数",{"2":{"710":1}}],["负采样将",{"2":{"708":1}}],["负采样添加从预定义分布中采样的负样本",{"2":{"708":1}}],["负采样修改了原目标函数",{"2":{"708":1}}],["负采样",{"0":{"708":1,"775":1}}],["负采样和分层softmax",{"2":{"707":1}}],["范围分片",{"2":{"1207":1}}],["范围介于0和1之间",{"2":{"853":1,"854":1}}],["范数和目标",{"0":{"1001":1}}],["范数听起来很像距离的度量",{"2":{"1000":1}}],["范数",{"0":{"1000":1},"1":{"1001":1}}],["范数与权重衰减",{"0":{"270":1}}],["范数表示半径为r的球",{"2":{"52":1}}],["背景的预测概率",{"2":{"854":2}}],["背景",{"2":{"853":1,"854":1}}],["背景类别的锚框通常被称为负类锚框",{"2":{"852":1}}],["背景是一些树",{"2":{"292":1}}],["位于",{"2":{"1309":1}}],["位于第i行和第j列的元素x",{"2":{"851":3}}],["位置嵌入是可学习的",{"2":{"734":3}}],["位置嵌入被加入到输入序列的每个位置",{"2":{"734":1}}],["位置i的词元由相同的全连接层变换成标量分数ei",{"2":{"660":1}}],["位置i+δ处",{"2":{"400":1}}],["位置编码使用相同形状的位置嵌入矩阵",{"2":{"398":1}}],["位置编码可以通过学习得到也可以直接固定得到",{"2":{"398":1}}],["位置编码",{"0":{"398":1},"1":{"399":1,"400":1},"2":{"398":5}}],["丢弃一些不能帮助我们正确预测的特征",{"2":{"1114":1}}],["丢弃矩阵第5行和第4列中的所有元素",{"2":{"851":1}}],["丢弃矩阵第7行和第1列中的所有元素",{"2":{"851":1}}],["丢弃矩阵中i1th行和j1th列中的所有元素",{"2":{"851":1}}],["丢弃包括",{"2":{"515":1}}],["覆盖了图像中的狗",{"2":{"849":1}}],["覆盖的距离也要长得多",{"2":{"812":1}}],["次方",{"2":{"1092":1}}],["次",{"2":{"848":3,"1151":3}}],["尺寸为100×1",{"2":{"1137":1}}],["尺寸分别为",{"2":{"1121":1}}],["尺寸的值为",{"2":{"1082":1}}],["尺寸列表和宽高比列表",{"2":{"848":1}}],["尺度不变特征变换",{"2":{"454":1}}],["宽",{"2":{"858":1}}],["宽高比为r",{"2":{"848":1}}],["宽度分别为wa和wb",{"2":{"852":1}}],["宽度w像素图像的形状记为h×w或",{"2":{"582":1,"585":1}}],["宽度和颜色组成的三维张量",{"2":{"158":1}}],["宽度决定",{"2":{"136":1}}],["宽度",{"2":{"129":4,"136":2,"858":2,"859":1,"882":1,"932":1,"956":1,"993":1,"1017":1}}],["宽度为w",{"2":{"848":1}}],["宽度为3的卷积核",{"2":{"141":1}}],["宽度为3的二维张量",{"2":{"126":1}}],["宽度为2的卷积核k",{"2":{"128":1}}],["宽度为2",{"2":{"126":1,"146":1}}],["锚框有q+1个类别",{"2":{"954":1}}],["锚框数的四倍",{"2":{"853":1}}],["锚框a1和狗的真实边界框有最大的iou",{"2":{"853":1}}],["锚框a4与猫的真实边界框的iou是最大的",{"2":{"853":1}}],["锚框a的偏移量将根据b和a中心坐标的相对位置以及这两个框的相对大小进行标记",{"2":{"852":1}}],["锚框a的类别将被标记为与b相同",{"2":{"852":1}}],["锚框左上角的",{"2":{"848":1}}],["锚框的中心即是图像的中心",{"2":{"912":1}}],["锚框的尺度设置为0",{"2":{"912":1}}],["锚框的数量",{"2":{"848":1,"854":1}}],["锚框的宽度和高度分别是hsr和hs",{"2":{"848":1}}],["锚框",{"0":{"847":1},"1":{"848":1,"849":1,"850":1,"851":1,"852":1,"853":1,"854":1,"855":1,"856":1},"2":{"952":1}}],["锚定",{"2":{"345":1}}],["公共的",{"2":{"1425":1}}],["公共抽象即重新定义具有更新语义的键",{"2":{"844":1}}],["公式为",{"2":{"1107":1}}],["公式",{"2":{"307":1,"388":2,"613":1}}],["环同步对于p3和dgx",{"2":{"845":1}}],["环同步",{"0":{"842":1}}],["环境不一致",{"2":{"1354":1}}],["环境",{"0":{"1489":1},"2":{"1315":1}}],["环境配置",{"2":{"1304":1}}],["环境下写出正确的控制语句",{"2":{"1092":1}}],["环境下定义的函数",{"2":{"1092":1}}],["环境可以是完整观察到的",{"2":{"298":1}}],["环境可能会记住自动操作并以令人惊讶的方式做出响应",{"2":{"202":1}}],["环境甚至可能不会告诉是哪些行为导致了奖励",{"2":{"298":1}}],["环境是否变化",{"2":{"297":1}}],["环境是否重要",{"2":{"297":1}}],["环境是否想要打败模型",{"2":{"297":1}}],["环境是否有助于我们建模",{"2":{"297":1}}],["环境还记得我们以前做过什么吗",{"2":{"297":1}}],["环境变化的速度和方式在很大程度上决定了我们可以采用的算法类型",{"2":{"200":1}}],["环境会记住我们所做的事",{"2":{"198":1}}],["环境和分布偏移",{"0":{"179":1},"1":{"180":1,"181":1,"182":1,"183":1,"184":1,"185":1,"186":1,"187":1,"188":1,"189":1,"190":1,"191":1,"192":1,"193":1,"194":1,"195":1,"196":1,"197":1,"198":1,"199":1,"200":1,"201":1,"202":1,"203":1}}],["轮询",{"2":{"1362":1}}],["轮廓系数",{"2":{"1154":2}}],["轮",{"2":{"828":3,"837":3}}],["轮数",{"2":{"223":1}}],["跨平台",{"2":{"1302":1,"1339":1}}],["跨语言项目",{"2":{"1294":1}}],["跨语言环境和包管理工具",{"2":{"1275":1}}],["跨8个v100",{"2":{"842":1}}],["跨层或跨数据上实现",{"2":{"838":1}}],["跨多个gpu对数据进行拆分",{"2":{"832":1}}],["跨多个后续层对数据进行处理",{"2":{"832":1}}],["跨设备并行计算损失及其梯度",{"2":{"828":1}}],["跨同一层中的单元",{"2":{"467":1}}],["流水线",{"2":{"1544":1,"1546":1}}],["流畅",{"2":{"1540":1}}],["流星蝴蝶剑",{"2":{"1456":1,"1457":1}}],["流程",{"2":{"1543":1}}],["流程控制语句",{"0":{"1222":1},"1":{"1223":1,"1224":1,"1225":1,"1226":1,"1227":1}}],["流程图中每一部分的输出都是下一部分的输入",{"2":{"1174":1}}],["流感",{"2":{"1029":1}}],["流过网络的数据现在也转换为symbol类型",{"2":{"821":1}}],["流行的上下文敏感表示包括taglm",{"2":{"731":1}}],["瓶颈是单线程的python解释器",{"2":{"819":1}}],["历史上",{"2":{"818":1}}],["历史上物种飞速进化的时期",{"2":{"300":1}}],["磁盘的缓存大小能否测量",{"2":{"815":1}}],["μj",{"2":{"1180":1}}],["μj=1m∑i=1mxj",{"2":{"1180":1}}],["μ=1m∑i=1mx",{"2":{"1179":1,"1184":1,"1185":1}}],["μ",{"2":{"1179":2,"1180":2,"1184":1,"1185":8}}],["μ1",{"2":{"1152":1}}],["μk",{"2":{"1151":2,"1152":2}}],["μ2",{"2":{"1151":1,"1152":1}}],["μn是平均值",{"2":{"1082":1}}],["μx=μy=μw=μh=0",{"2":{"852":1}}],["μs",{"2":{"813":14}}],["μ^b=1|b|∑x∈bx",{"2":{"467":1}}],["μ^b是小批量b的样本均值",{"2":{"467":1}}],["适用场景",{"0":{"1529":1},"2":{"1346":1,"1349":1,"1351":1}}],["适用于只需保护对象顶层属性的场景",{"2":{"1516":1}}],["适用于训练集特征多",{"2":{"1147":1}}],["适用于各种类型的模型",{"2":{"1085":1}}],["适用于远程通信",{"2":{"1047":1}}],["适用于本地通信",{"2":{"1047":1}}],["适用于非常高带宽的互连",{"2":{"812":1}}],["适合各种规模项目的现代前端框架",{"2":{"1531":1}}],["适合学习",{"2":{"1393":1}}],["适合开发和小规模部署",{"2":{"1355":1}}],["适合人群",{"2":{"1294":1}}],["适合科研数据分析",{"2":{"1275":1}}],["适合有基础的开发者继续深入理解",{"2":{"1237":1}}],["适合遍历列表",{"0":{"1225":1}}],["适合",{"2":{"1199":1,"1315":1}}],["适合imagenet的复杂模型可能会在这个椅子数据集上过拟合",{"2":{"869":1}}],["适合于下一句预测",{"2":{"718":1}}],["距离计算方法总结",{"2":{"1154":1}}],["距离接近",{"2":{"1146":1}}],["距离和灵活性",{"2":{"812":1}}],["距离可能会增加",{"2":{"115":1}}],["充足的内存通道和二级缓存完善了配置",{"2":{"811":1}}],["毫不夸张地说",{"2":{"811":1}}],["毫不意外的是gpu的内存通常比cpu的内存小得多",{"2":{"802":1}}],["寄存器是cpu可以以时钟速度访问而没有延迟的存储位置",{"2":{"810":1}}],["寄存器",{"2":{"810":1}}],["汇编代码通常不是处理器执行的最低级别代码",{"2":{"808":1}}],["汇聚",{"2":{"404":1}}],["汇聚后输出通道的数量仍然是2",{"2":{"148":1}}],["汇聚操作称为p×q汇聚",{"2":{"146":1}}],["汇聚窗口形状为3×3",{"2":{"495":1}}],["汇聚窗口形状为p×q的汇聚层称为p×q汇聚层",{"2":{"146":1}}],["汇聚窗口从输入张量的左上角开始",{"2":{"146":1}}],["汇聚层不用于减少输入的高度和宽度",{"2":{"461":2}}],["汇聚层不包含参数",{"2":{"146":1}}],["汇聚层的输出通道数与输入通道数相同",{"2":{"149":1}}],["汇聚层的主要优点之一是减轻卷积层对位置的过度敏感",{"2":{"149":1}}],["汇聚层在每个输入通道上单独运算",{"2":{"148":1}}],["汇聚层也可以改变输出形状",{"2":{"147":1}}],["汇聚层始终输出y",{"2":{"146":1}}],["汇聚层输出为y",{"2":{"146":1}}],["汇聚层运算符由一个固定形状的窗口组成",{"2":{"146":1}}],["汇聚层",{"0":{"145":1},"1":{"146":1,"147":1,"148":1,"149":1,"150":1},"2":{"507":1}}],["汇聚层使用最大汇聚层而不是平均汇聚层",{"2":{"67":1}}],["蓝莓",{"2":{"1490":1}}],["蓝牙",{"2":{"807":1}}],["蓝通道的强度",{"2":{"284":1}}],["缓存配置",{"2":{"1371":1}}],["缓存控制",{"2":{"1244":1}}],["缓存管理",{"2":{"1204":1}}],["缓存策略",{"0":{"1201":1}}],["缓存未命中的代价可能会很昂贵",{"2":{"810":1}}],["缓存和一个连接四个核心的环总线",{"2":{"807":1}}],["缓存",{"0":{"810":1},"2":{"807":1,"1201":1,"1203":1}}],["缓存k个随机采样结果",{"2":{"775":1}}],["各种炫酷框架",{"2":{"1538":1}}],["各种机器学习问题",{"0":{"288":1},"1":{"289":1,"290":1,"291":1,"292":1,"293":1,"294":1,"295":1,"296":1,"297":1,"298":1}}],["各代产品和供应商之间的特定拓扑结构有明显不同",{"2":{"807":1}}],["云厂商提供的外部负载均衡",{"2":{"1384":1}}],["云原生平台",{"2":{"1393":1}}],["云原生",{"2":{"1357":1}}],["云原生标准",{"2":{"1351":1}}],["云存储提供了一系列可配置的性能",{"2":{"806":1}}],["云存储",{"0":{"806":1},"2":{"1386":1}}],["云计算",{"2":{"292":2}}],["磨损程度保护算法能够将退化平摊到许多单元",{"2":{"805":1}}],["队列",{"2":{"805":1}}],["四舍五入到两位小数",{"2":{"1086":1}}],["四",{"0":{"1079":1,"1228":1,"1245":1,"1302":1,"1366":1},"1":{"1080":1,"1081":1,"1082":1,"1083":1,"1084":1,"1085":1,"1086":1,"1229":1,"1230":1,"1246":1,"1247":1,"1367":1,"1368":1,"1369":1,"1370":1},"2":{"1193":1}}],["四个划分后的子窗口中分别含有元素0",{"2":{"938":1}}],["四个路径之间的输出通道数量比为128",{"2":{"488":1}}],["四个路径之间的输出通道数量比为64",{"2":{"488":1}}],["四层单元",{"2":{"805":1}}],["擦除",{"2":{"805":1}}],["延迟时间为个位数的微秒",{"2":{"812":1}}],["延迟",{"2":{"803":1}}],["延后初始化使框架能够自动推断参数形状",{"2":{"419":1}}],["延后初始化",{"0":{"417":1},"1":{"418":1,"419":1,"420":1}}],["持久化",{"2":{"1203":1}}],["持久化保障",{"0":{"1202":1}}],["持久性存储设备",{"2":{"801":1}}],["持续学习",{"2":{"1436":1}}],["持续增长的预构建集成列表",{"2":{"1041":1}}],["持续移除输入文本对中较长文本的最后一个标记",{"2":{"687":1}}],["借助storetorefs将store中的数据转为ref对象",{"2":{"1492":1}}],["借助softmax回归",{"2":{"637":1}}],["借助action修改",{"2":{"1491":1}}],["借助c++或java或python",{"2":{"1061":1}}],["借助自动并行化框架的便利性",{"2":{"795":1}}],["仍保持目标检测的精度",{"2":{"939":1}}],["仍然可以通过后端观察异步吗",{"2":{"794":1}}],["仍有许多问题亟待解决",{"2":{"158":1}}],["芯片供应商提供了复杂的性能分析工具",{"2":{"793":1}}],["频繁地将少量数据从mxnet的作用域复制到numpy",{"2":{"791":1}}],["频率最高的",{"2":{"318":1}}],["障碍器与阻塞器",{"0":{"791":1}}],["飞桨不支持在notebook上进行多gpu训练",{"2":{"883":1}}],["飞桨静态图符号式编程",{"2":{"820":1}}],["飞桨动态图命令式编程",{"2":{"820":1}}],["飞桨2",{"2":{"818":1}}],["飞桨是基于命令式编程并且使用动态计算图",{"2":{"818":1}}],["飞桨和pytorch",{"2":{"795":1}}],["飞桨程序的执行主要发生在c++实现的后端",{"2":{"790":1}}],["飞桨有一个用于与用户直接交互的前端",{"2":{"790":1}}],["飞桨的tensor是在gpu上定义的",{"2":{"790":1}}],["飞机头部区域的类别索引为1",{"2":{"945":1}}],["飞机",{"2":{"455":1,"888":1}}],["飞机通常不在水里游泳",{"2":{"152":1}}],["操作countstore中的sum",{"2":{"1491":1}}],["操作src",{"2":{"1489":1}}],["操作者就可按下运行按钮",{"2":{"1127":1}}],["操作和预处理数据",{"2":{"987":1}}],["操作",{"2":{"809":1,"1297":1,"1319":1}}],["操作会排队到特定的设备上",{"2":{"789":1}}],["操作是按照坐标顺序应用",{"2":{"27":1}}],["归根结底",{"2":{"789":1,"842":1}}],["条件类型与泛型",{"0":{"1434":1}}],["条件类型",{"0":{"1409":1},"2":{"1434":1}}],["条件满足就继续执行",{"0":{"1226":1}}],["条件语句",{"0":{"1223":1}}],["条件分布",{"2":{"1037":1}}],["条件概率为p",{"2":{"1035":2}}],["条件概率",{"0":{"1031":1},"2":{"1035":2}}],["条件概率可以被看作使用语料库中一些词来预测另一些单词",{"2":{"782":1}}],["条件",{"2":{"977":1}}],["条件不佳的问题",{"0":{"87":1}}],["低代码平台",{"2":{"1529":1}}],["低内存消耗",{"2":{"1359":1}}],["低秩矩阵分解",{"0":{"1191":1},"2":{"1193":1}}],["低偏差",{"2":{"1147":1}}],["低方差",{"2":{"1147":1}}],["低级服务器的典型带宽为1gbit",{"2":{"812":1}}],["低频词",{"2":{"773":1}}],["低于imagenet图像",{"2":{"462":1}}],["空下来会做做",{"2":{"1549":1}}],["空格是词中符号之间的分隔符",{"2":{"757":1}}],["空间来计算",{"2":{"26":1}}],["诸如此类",{"2":{"1156":1}}],["诸如此类的事",{"2":{"1143":1}}],["诸如",{"2":{"1092":1}}],["诸如任意长度的连续字符",{"2":{"757":1}}],["诸如词",{"2":{"745":1}}],["字面量类型",{"0":{"1414":1}}],["字面量联合类型",{"2":{"1407":1}}],["字典推导式",{"0":{"1241":1,"1243":1},"1":{"1242":1,"1243":1}}],["字典",{"2":{"1216":1}}],["字符串等有",{"2":{"1433":1}}],["字符串字面量类型",{"2":{"1414":1}}],["字符串枚举",{"2":{"1413":1}}],["字符串",{"0":{"1225":1},"2":{"1216":1,"1232":1}}],["字符串类型",{"2":{"1214":1}}],["字符串核函数",{"2":{"1148":1}}],["字符分类",{"2":{"1171":1}}],["字符切分",{"2":{"1171":1}}],["字符就是单词",{"2":{"781":1}}],["字符级语言模型",{"2":{"341":1}}],["字向量维度embed",{"2":{"766":1}}],["字节对编码迭代地合并最频繁的连续符号对",{"2":{"758":1}}],["字节对编码迭代地合并最频繁的连续符号对以产生新的更长的符号",{"2":{"757":1}}],["字节对编码的结果取决于正在使用的数据集",{"2":{"757":1}}],["字节对编码继续合并",{"2":{"757":1}}],["字节对编码将使用以下merge",{"2":{"757":1}}],["字节对编码及其变体已经用于诸如gpt",{"2":{"757":1}}],["字节对编码执行训练数据集的统计分析",{"2":{"757":1,"758":1}}],["字节对编码",{"0":{"757":1}}],["罕见词甚至词表外的词在fasttext中可能获得更好的向量表示",{"2":{"756":1}}],["产品或新闻文章",{"2":{"1001":1}}],["产品评论",{"2":{"754":1}}],["产生更好的直观理解",{"2":{"1145":1}}],["产生了我们现在的这些录音",{"2":{"1061":1}}],["产生了一个灵活的机制",{"2":{"526":1}}],["产生了更高的精确度",{"2":{"302":1}}],["产生相同的激活",{"2":{"244":1}}],["产生输出张量",{"2":{"126":1}}],["国家",{"2":{"751":1}}],["国际象棋有一个复杂得多的状态空间和一组动作",{"2":{"301":1}}],["国际象棋的计算机程序已经竞争了几十年",{"2":{"301":1}}],["国际象棋",{"2":{"199":1}}],["蒸汽",{"2":{"741":1}}],["冰",{"2":{"741":2}}],["气体",{"2":{"741":2}}],["固定分配",{"2":{"1362":1}}],["固定长度的序列",{"2":{"289":1}}],["固定长度的特征向量是一个方便的属性",{"2":{"284":1}}],["固定长度",{"2":{"284":3}}],["固态驱动器需要缓存吗",{"2":{"815":1}}],["固态驱动器中的存储单元磨损得比较快",{"2":{"805":1}}],["固态驱动器以块的方式",{"2":{"805":1}}],["固态驱动器",{"0":{"805":1},"2":{"801":1,"805":2,"814":1}}],["固体",{"2":{"741":1}}],["及格",{"2":{"1223":1}}],["及其变化",{"2":{"1494":1}}],["及其在x=1处的切线y=2x−3",{"2":{"981":1}}],["及其导数",{"2":{"27":1}}],["及",{"2":{"735":1}}],["插入特殊标记",{"2":{"727":1}}],["句号用作拆分句子的唯一分隔符",{"2":{"724":1}}],["句子相似性和分类等12项任务上进行了评估",{"2":{"732":1}}],["句子对的数量",{"2":{"726":3}}],["句子对的相似度得分是从0",{"2":{"658":1}}],["句子",{"2":{"659":1}}],["句子2",{"2":{"658":1}}],["句子1",{"2":{"658":1}}],["遮蔽语言模型损失的和",{"2":{"726":3}}],["遮蔽语言模型任务中预测15",{"2":{"721":1}}],["遮蔽语言模型和下一句预测",{"2":{"718":1,"722":1,"723":1}}],["掩蔽语言模型比从左到右的语言模型需要更多或更少的预训练步骤来收敛吗",{"2":{"740":1}}],["掩蔽语言模型预测mlm",{"2":{"738":1}}],["掩蔽语言模型",{"0":{"736":1}}],["掩蔽语言模型和下一句预测",{"2":{"735":1,"739":1}}],["掩蔽softmax操作",{"0":{"368":1}}],["掩码变量bbox",{"2":{"962":1}}],["掩码变量中的零将在计算目标函数之前过滤掉负类偏移量",{"2":{"853":1}}],["掩码变量中的元素与每个锚框的4个偏移量一一对应",{"2":{"853":1}}],["掩码",{"2":{"721":1}}],["求一下平均值",{"2":{"1167":1}}],["求出这x次对训练实例计算代价的平均值",{"2":{"1167":1}}],["求使得10×",{"2":{"1143":1}}],["求逆",{"2":{"1090":1}}],["求和及平均值",{"2":{"997":1}}],["求和的梯度的计算成本是巨大的",{"2":{"707":1}}],["求函数f",{"2":{"986":1}}],["求导后得到",{"2":{"1109":1,"1110":1}}],["求导数后得到",{"2":{"1081":1}}],["求导的目的",{"2":{"1068":1}}],["求导的结果可以是一个高阶张量",{"2":{"975":1}}],["求导是几乎所有深度学习优化算法的关键步骤",{"2":{"973":1}}],["求值",{"2":{"816":1}}],["求解其中一个条件变量",{"2":{"1032":1}}],["求解神经网络每一层所需的复杂计算",{"2":{"998":1}}],["求解矩阵方程来找到解析解",{"2":{"621":1}}],["求解一个有约束的优化问题是困难的",{"2":{"48":1}}],["跳转并携带params参数",{"2":{"1482":2}}],["跳转并携带query参数",{"2":{"1481":2}}],["跳转",{"2":{"1481":1}}],["跳转路由",{"2":{"1478":1,"1479":1}}],["跳元语法模型的输入包括形状为",{"2":{"763":1}}],["跳元模型中两个词向量的点积与余弦相似度之间有什么关系",{"2":{"788":1}}],["跳元模型假设一个单词可用于在文本序列中",{"2":{"787":1}}],["跳元模型假设一个词可以用来在文本序列中生成其周围的单词",{"2":{"783":1}}],["跳元模型参数是词表中每个词的中心词向量和上下文词向量",{"2":{"784":1}}],["跳元模型考虑生成上下文词",{"2":{"783":1}}],["跳元模型",{"0":{"761":1,"783":1},"1":{"762":1,"763":1,"784":1}}],["跳元模型的中心词向量通常用作词表示",{"2":{"784":1}}],["跳元模型的似然函数是在给定任何中心词的情况下生成所有上下文词的概率",{"2":{"783":1}}],["跳元模型的损失函数等价于",{"2":{"742":1}}],["跳元模型的主要思想是使用softmax运算来计算基于给定的中心词wc生成上下文字wo的条件概率",{"2":{"707":1}}],["跳过当前循环",{"2":{"1227":1}}],["跳过文件头行",{"2":{"890":1}}],["跳过标题信息",{"2":{"748":1}}],["跳过这2个卷积运算",{"2":{"501":1}}],["沿每个轴的长度",{"2":{"1017":1}}],["沿轴1的长度",{"2":{"998":3}}],["沿着行和列对矩阵求和",{"2":{"995":1}}],["沿着张量的最外轴",{"2":{"992":1}}],["沿着向量维度将两个嵌入层连结起来",{"2":{"702":3}}],["沿行",{"2":{"340":1}}],["遍历",{"2":{"699":1,"1092":1}}],["遍历的每个位置计算一个输出",{"2":{"146":1}}],["~=",{"2":{"1088":1}}],["~200mb",{"2":{"813":1}}],["~250μs",{"2":{"813":1}}],["~550mb",{"2":{"813":1}}],["~4",{"2":{"813":1}}],["~12gb",{"2":{"813":2}}],["~33gb",{"2":{"813":2}}],["~",{"2":{"813":4,"1371":1,"1459":1,"1463":1,"1464":1,"1465":1,"1466":1}}],["~amaas",{"2":{"692":1}}],["~mask",{"2":{"575":2}}],["消灭在提交前",{"2":{"1544":1}}],["消费",{"2":{"1501":1}}],["消费级的intel",{"2":{"841":1}}],["消费级设备",{"2":{"802":1}}],["消失",{"2":{"1475":1}}],["消失了",{"2":{"1089":1}}],["消息有三种类型",{"2":{"1044":1}}],["消息转换回",{"2":{"1044":1}}],["消息格式",{"0":{"1044":1},"1":{"1045":1,"1046":1,"1047":1}}],["消耗了原本可以用来提高处理能力的面积",{"2":{"810":1}}],["消耗巨大",{"2":{"78":1}}],["消极",{"2":{"691":1,"692":1,"713":1}}],["金融",{"2":{"691":1}}],["陈旧的",{"2":{"688":1}}],["片段嵌入和位置嵌入的和",{"2":{"734":1,"739":1}}],["片段索引用于区分bert输入序列中的前提和假设",{"2":{"687":1}}],["片段是否包含唤醒词",{"2":{"282":1}}],["`base",{"2":{"1425":1}}],["`manager",{"2":{"1425":1}}],["`duck",{"2":{"1422":2}}],["`drawing",{"2":{"1417":2}}],["`flying",{"2":{"1422":1}}],["`area",{"2":{"1417":1}}],["`$",{"2":{"1416":3,"1425":1}}],["`hello",{"2":{"1048":1,"1398":1}}],["`",{"2":{"1048":3,"1398":1,"1416":2,"1417":2,"1422":1,"1425":3,"1482":1}}],["`received",{"2":{"1048":2}}],["`subsec",{"2":{"725":1}}],["`sec",{"2":{"679":1,"864":1,"883":2,"945":2,"947":1}}],["```",{"2":{"7":1}}],["疲倦",{"2":{"675":1}}],["睡眠",{"2":{"674":2}}],["睡觉",{"2":{"665":1}}],["累积梯度也需要更高的精度",{"2":{"811":1}}],["累积丢失的像素数就多了",{"2":{"141":1}}],["累",{"2":{"674":2}}],["拥抱typescript",{"0":{"1440":1}}],["拥抱",{"2":{"665":1}}],["拥有易学易用",{"2":{"1526":1}}],["拥有一个固定的样本集的机器学习问题中",{"2":{"1168":1}}],["拥有更多的特征变量",{"2":{"1148":1}}],["拥有了这些定义后",{"2":{"1143":1}}],["拥有了这些技能hr绝对不会拒绝你",{"2":{"1058":1}}],["拥有多么复杂的变量",{"2":{"1138":1}}],["拥有越多数据的时候",{"2":{"284":1}}],["拥有二阶信息可以使我们在曲率较大时保持谨慎",{"2":{"59":1}}],["矛盾和中性",{"2":{"677":3,"688":1}}],["矛盾关系和中性关系",{"2":{"670":1}}],["矛盾",{"2":{"665":2,"667":2}}],["蕴涵",{"2":{"665":2,"667":2,"677":3,"688":1}}],["放到数组中",{"2":{"1495":1}}],["放回到原来式子这里",{"2":{"1110":1}}],["放入不同的下游自然语言处理任务",{"2":{"663":1}}],["放弃一些短期回报来换取知识",{"2":{"298":1}}],["冠状病毒爆发期间的石油行业",{"2":{"662":1}}],["情感分析研究人们在文本中的情感",{"2":{"696":1}}],["情感分析",{"0":{"698":1,"712":1},"1":{"699":1,"700":1,"701":1,"702":1,"703":1,"704":1,"705":1,"706":1,"713":1,"714":1,"715":1,"716":1,"717":1},"2":{"691":1,"731":1}}],["情感分析及数据集",{"0":{"691":1},"1":{"692":1,"693":1,"694":1,"695":1,"696":1,"697":1}}],["情感分析和自然语言推断",{"2":{"663":1}}],["情感分析和测试语言可接受性",{"2":{"661":1}}],["情况五",{"0":{"1466":1},"2":{"1466":1}}],["情况四",{"0":{"1465":1},"2":{"1465":2}}],["情况三",{"0":{"1464":1},"2":{"1464":1}}],["情况二",{"0":{"1463":1}}],["情况一",{"0":{"1462":1},"2":{"1462":1,"1463":1}}],["情况可能会变得特别复杂",{"2":{"432":1}}],["情况就完全不同了",{"2":{"340":1}}],["情况会变得更糟",{"2":{"316":1}}],["情况变得更加复杂",{"2":{"256":1}}],["情况通常并非如此",{"2":{"117":1}}],["情况并非如此",{"2":{"26":1}}],["口罩制造商",{"2":{"660":1}}],["口罩制造商坚持他们的产品",{"2":{"660":1}}],["答案应该是文章中的文本片段",{"2":{"660":1}}],["答案是一样的",{"2":{"1145":1}}],["答案是否定的",{"2":{"643":1}}],["答案是由于模型参数包含梯度",{"2":{"437":2}}],["斯科特的互动帖子",{"2":{"800":1}}],["斯坦福大学",{"0":{"1193":1}}],["斯坦福自然语言推断语料库",{"2":{"666":1}}],["斯坦福自然语言推断",{"0":{"666":1},"1":{"667":1,"668":1,"669":1},"2":{"670":1}}],["斯坦福问答数据集",{"2":{"660":1}}],["斯里瓦斯塔瓦等人",{"2":{"170":1}}],["问答反映阅读理解能力",{"2":{"660":1}}],["问答",{"0":{"660":1},"2":{"732":1,"733":1}}],["问题形式化",{"0":{"1187":1},"2":{"1193":1}}],["问题描述和流程图",{"0":{"1171":1},"2":{"1193":1}}],["问题就是给出3个类型的数据集",{"2":{"1112":1}}],["问题的动机",{"0":{"1178":1},"2":{"1193":1}}],["问题的重点在于x",{"2":{"1086":1}}],["问题的难度可能取决于图像的分辨率",{"2":{"1025":1}}],["问题二是一个分类问题",{"2":{"1060":1}}],["问题一是一个回归问题",{"2":{"1060":1}}],["问题拆分",{"0":{"832":1}}],["问题则有点棘手",{"2":{"307":1}}],["问题看似很难解决",{"2":{"282":1}}],["问题是要将n维数据降至k维",{"2":{"1158":1}}],["问题是如何有效地使用它",{"2":{"842":1}}],["问题是",{"2":{"252":1,"1114":1}}],["问题在于",{"2":{"106":1,"1173":1}}],["问题",{"2":{"47":1,"241":2,"291":2,"296":3,"298":1,"943":1,"1178":1,"1354":1,"1546":1}}],["专题合集",{"2":{"1548":1}}],["专注于前端视图层的构建",{"2":{"1526":1}}],["专业",{"2":{"1025":1}}],["专有单数",{"2":{"659":1}}],["专用硬件和高效搜索游戏树",{"2":{"301":1}}],["额外的全连接层",{"2":{"661":1}}],["额外层的参数是从零开始学习的",{"2":{"656":1,"661":1}}],["额外阅读",{"0":{"248":1}}],["惊异",{"2":{"651":1}}],["惊异和交叉熵",{"2":{"342":1}}],["压缩",{"2":{"1365":1,"1371":1}}],["压缩与预测有什么关系呢",{"2":{"651":1}}],["压力山大",{"2":{"201":1}}],["纳特",{"2":{"650":2}}],["熵",{"0":{"650":1}}],["卢斯于1959年在选择模型",{"2":{"643":1}}],["社区热度下降",{"2":{"1395":1}}],["社区活跃",{"0":{"1300":1},"2":{"1351":1}}],["社区流传很广的一句话",{"2":{"1295":1}}],["社会科学家邓肯",{"2":{"643":1}}],["社交媒体",{"2":{"754":1}}],["社交邮件",{"2":{"634":1}}],["社交网络分析",{"2":{"1150":1}}],["社交网络",{"2":{"300":1}}],["顾名思义",{"2":{"642":1,"780":1}}],["顾客就会理解并改变他们的行为",{"2":{"179":1}}],["青蛙也能学会使用那只眼睛",{"2":{"1098":1}}],["青蛙",{"2":{"888":1}}],["青年人",{"2":{"640":1}}],["青少年",{"2":{"640":1}}],["儿童",{"2":{"640":1}}],["鸡蛋",{"2":{"1141":1}}],["鸡尾酒算法的第一个输出结果是",{"2":{"1061":1}}],["鸡",{"2":{"640":3,"643":1}}],["软件能给这些自定制的建议的唯一方法是通过学习你的行为",{"2":{"1058":1}}],["软",{"2":{"674":1}}],["软性",{"2":{"639":1}}],["软饮",{"2":{"183":1}}],["硬盘读取数据所需的最短时间是多少",{"2":{"815":1}}],["硬盘的主要优点之一是相对便宜",{"2":{"804":1}}],["硬盘驱动器可以以大约100iops",{"2":{"804":1}}],["硬盘驱动器",{"0":{"804":1},"2":{"804":1}}],["硬",{"2":{"674":1}}],["硬性",{"2":{"639":1}}],["硬件",{"0":{"457":1,"800":1},"1":{"801":1,"802":1,"803":1,"804":1,"805":1,"806":1,"807":1,"808":1,"809":1,"810":1,"811":1,"812":1,"813":1,"814":1,"815":1}}],["增强函数的功能",{"2":{"1244":1}}],["增大时",{"2":{"1143":1}}],["增大γ可以有效地减少正类预测概率较大时",{"2":{"966":1}}],["增至",{"2":{"1090":1}}],["增量或说是步长为0",{"2":{"1088":1}}],["增量地绘制多条线",{"2":{"635":1}}],["增添更多特征后",{"2":{"1080":1}}],["增加两者之间的负相关性",{"2":{"1184":1}}],["增加两者之间的正相关性",{"2":{"1184":1}}],["增加这些新特征后获得的新算法能够帮助我们更好地进行异常检测",{"2":{"1183":1}}],["增加这里的一项",{"2":{"1143":1}}],["增加数据集的规模可以帮助你获得更好的结果",{"2":{"1164":1}}],["增加数据到训练集不一定能有帮助",{"2":{"1134":1}}],["增加更多的特征",{"2":{"1148":1}}],["增加更多数据到训练集可能可以提高算法效果",{"2":{"1134":1}}],["增加内容",{"2":{"1086":1}}],["增加batch",{"2":{"910":1}}],["增加为2个gpu",{"2":{"837":1}}],["增加iops的配置数",{"2":{"806":1}}],["增加1e",{"2":{"750":3,"768":3}}],["增加迭代轮数可以提高训练和测试的准确性吗",{"2":{"717":1}}],["增加迭代周期的数量",{"2":{"628":1}}],["增加方差将会分散分布",{"2":{"616":1}}],["增加输出通道数的同时",{"2":{"501":1}}],["增加的方差抵消了时间步数越多梯度越精确的事实",{"2":{"311":1}}],["增加训练数据的样本数量",{"2":{"394":1}}],["增加训练数据",{"2":{"280":1}}],["增加训练轮数",{"2":{"178":1}}],["增加了l2范数惩罚项",{"2":{"275":4}}],["增加位置",{"2":{"230":1}}],["增加到第一个卷积层之后的6个",{"2":{"136":1}}],["错",{"2":{"634":1}}],["错误否定",{"2":{"1139":1}}],["错误肯定",{"2":{"1139":1}}],["错误地使用同步会破坏程序性能",{"2":{"793":1}}],["错误的主要成分分析情况",{"2":{"1162":1}}],["错误的对齐",{"2":{"295":2}}],["错误的",{"2":{"191":1,"192":1}}],["错误",{"2":{"165":1,"362":1,"1416":1,"1419":1,"1426":2,"1433":2}}],["论文",{"2":{"1025":1}}],["论文中",{"2":{"35":1}}],["论文中建议我们重写adam算法更新如下",{"2":{"35":1}}],["论坛邮件",{"2":{"634":1}}],["配置路由规则",{"2":{"1479":1}}],["配置对象",{"2":{"1463":1}}],["配置项目名称",{"2":{"1444":1}}],["配置好",{"2":{"1436":1}}],["配置文件",{"2":{"1385":1}}],["配置文件结构",{"0":{"1364":1},"1":{"1365":1}}],["配置",{"0":{"1370":1,"1388":1},"1":{"1389":1,"1390":1,"1391":1},"2":{"1447":1,"1548":1}}],["配置解析",{"0":{"1365":1}}],["配置全局用户名和邮箱",{"2":{"1336":1}}],["配分函数",{"2":{"631":1}}],["配对",{"2":{"356":1}}],["诺维格在他们的经典人工智能教科书",{"2":{"619":1}}],["细分市场的例子",{"2":{"1061":1}}],["细节已被省略",{"2":{"821":1}}],["细节取决于所用内存芯片的特定定时系数",{"2":{"802":1}}],["细胞核",{"2":{"619":1}}],["细心的读者一定会发现",{"2":{"129":1}}],["皮茨开始开发人工神经元模型时",{"2":{"619":1}}],["麦库洛奇和沃尔特",{"2":{"619":1}}],["麦克风每秒钟将收集大约44000个样本",{"2":{"282":1}}],["噪声词不能是上下文词",{"2":{"775":1}}],["噪声词",{"2":{"775":1}}],["噪声正态分布如下式",{"2":{"616":1}}],["噪声项ϵ服从均值为0且标准差为0",{"2":{"262":1}}],["若",{"2":{"1497":2}}],["若使用to的对象写法",{"2":{"1482":1}}],["若是对象监视的是地址值",{"2":{"1465":1}}],["若该属性值是依然是",{"2":{"1465":1}}],["若该属性值不是",{"2":{"1465":1}}],["若修改整个ref定义的对象",{"2":{"1463":1}}],["若修改的是ref定义的对象中的属性",{"2":{"1463":1}}],["若想监视对象内部属性的变化",{"2":{"1463":1}}],["若想监视对象内部的数据",{"2":{"1463":1}}],["若想新增或者修改一个需求",{"2":{"1448":1}}],["若需要一个响应式对象",{"2":{"1458":2}}],["若需要一个基本类型的响应式数据",{"2":{"1458":1}}],["若ref接收的是对象类型",{"2":{"1457":1}}],["若返回一个函数",{"2":{"1452":1}}],["若返回一个对象",{"2":{"1452":1}}],["若给出一个新的值使之预测",{"2":{"1114":1}}],["若随机变量x具有均值μ和方差σ2",{"2":{"616":1}}],["若无法获得测试数据",{"2":{"209":1}}],["术语的误用经常导致一些误解",{"2":{"614":1}}],["弄清楚如何训练这些难以优化的模型是非常重要的",{"2":{"613":1}}],["尖角",{"2":{"610":1}}],["美化网页",{"2":{"1539":1}}],["美国食品和药物管理局",{"2":{"1098":1}}],["美国心理学之父",{"2":{"355":1}}],["美元",{"2":{"609":1,"1063":1}}],["年开源",{"2":{"1526":1}}],["年开发",{"2":{"1359":1}}],["年后",{"2":{"1394":1}}],["年正式发布",{"2":{"1296":1}}],["年",{"2":{"609":1,"1040":1}}],["年代",{"2":{"300":1}}],["零售销量等",{"2":{"608":1}}],["股票等",{"2":{"608":1}}],["←",{"2":{"605":1,"613":1}}],["介绍",{"0":{"1267":1,"1271":1,"1275":1,"1279":1,"1283":1,"1287":1,"1291":1}}],["介绍了评价矩阵",{"2":{"1176":1}}],["介绍了各种图像分类模型",{"2":{"857":1}}],["介绍了在单文本分类任务和文本对分类",{"2":{"656":1}}],["介绍更简洁的实现方式",{"2":{"598":1}}],["介绍神经网络的基础知识",{"2":{"587":1}}],["介绍的",{"2":{"572":1}}],["衬衫",{"2":{"582":1}}],["凉鞋",{"2":{"582":1}}],["外套",{"2":{"582":1}}],["外面下雨了",{"2":{"342":1}}],["连续解构赋值+重命名",{"2":{"1495":1}}],["连续随机变量的概率可以参考深度学习数学附录中随机变量",{"2":{"1028":1}}],["连续",{"2":{"989":1}}],["连续词袋模型通常使用上下文词向量作为词表示",{"2":{"786":1}}],["连续词袋模型的最大似然估计等价于最小化以下损失函数",{"2":{"786":1}}],["连续词袋模型的似然函数是在给定其上下文词的情况下生成所有中心词的概率",{"2":{"785":1}}],["连续词袋模型考虑基于上下文词",{"2":{"785":1}}],["连续词袋模型假设中心词是基于其在文本序列中的周围上下文词生成的",{"2":{"785":1}}],["连续词袋",{"0":{"785":1},"1":{"786":1},"2":{"785":1}}],["连结两个矩阵时",{"2":{"1018":1}}],["连结多尺度的预测",{"0":{"956":1}}],["连结初始和最终时间步的隐状态",{"2":{"713":3}}],["连结起来",{"2":{"702":3,"731":1}}],["连衣裙",{"2":{"582":1}}],["连接优化",{"2":{"1371":1}}],["连接计算机最常用的方式",{"2":{"812":1}}],["连接在一起",{"2":{"801":1}}],["连接的",{"2":{"642":1}}],["连接通道维度上每个块的输入和输出",{"2":{"480":3}}],["连接a和b的线段也位于x中",{"2":{"40":1}}],["套衫",{"2":{"582":1}}],["裤子",{"2":{"582":1}}],["≈40kb",{"2":{"1530":1}}],["≈20kb",{"2":{"1530":1}}],["≈",{"2":{"1205":2}}],["≈x1andx2",{"2":{"1101":1}}],["≈6ms",{"2":{"842":1}}],["≈αpij",{"2":{"744":1}}],["≈1",{"2":{"650":1}}],["≈0",{"2":{"578":1,"1146":1}}],["≈pijpik",{"2":{"744":2}}],["≈p",{"2":{"338":1}}],["\\thistory",{"2":{"1476":2}}],["\\t\\t\\t\\tjcv",{"2":{"1132":1}}],["\\t\\t\\t\\t",{"2":{"1132":1}}],["\\t",{"2":{"576":2,"1444":1,"1469":1,"1476":2}}],["需设定time",{"2":{"573":1}}],["需要经过处理后再使用时",{"2":{"1493":1}}],["需要提前在规则中占位",{"2":{"1482":1}}],["需要提醒一点",{"2":{"1145":1}}],["需要写完整的路径",{"2":{"1478":1}}],["需要写成函数形式",{"2":{"1465":1}}],["需要服务端配合处理路径问题",{"2":{"1476":1}}],["需要的时候再去挂载",{"2":{"1475":1}}],["需要的训练集由单个字符的图片和两个相连字符之间的图片来训练模型",{"2":{"1172":1}}],["需要明确的指出要监视",{"2":{"1467":1}}],["需要关注对象内部",{"2":{"1465":1}}],["需要手动开启深度监视",{"2":{"1463":1,"1465":1}}],["需要类型检查才能使用",{"2":{"1404":1}}],["需要解决的问题也随之而来",{"2":{"1355":1}}],["需要强隔离",{"2":{"1346":1}}],["需要强调的是",{"2":{"325":1}}],["需要完整操作系统",{"2":{"1346":1}}],["需要采取如下步骤",{"2":{"1171":1}}],["需要用到以下几个矩阵的求导法则",{"2":{"1086":1}}],["需要用启发式的初始化方法来确保初始梯度既不太大也不太小",{"2":{"249":1}}],["需要计算",{"2":{"1085":1}}],["需要多次迭代",{"2":{"1085":1}}],["需要多少合并操作",{"2":{"759":1}}],["需要多少个过去的观测结果",{"2":{"353":1}}],["需要多少阶的多项式才能将训练损失减少到0",{"2":{"268":1}}],["需要选择学习率α",{"2":{"1085":1}}],["需要简单的进程通信",{"2":{"1047":1}}],["需要设置偏移量",{"2":{"848":3}}],["需要一个地方来存储梯度",{"2":{"974":1}}],["需要一个kaggle账户才能提交结果",{"2":{"899":1}}],["需要一个allreduce函数",{"2":{"835":1}}],["需要一个更大的卷积窗口来捕获目标",{"2":{"459":1}}],["需要跨多个设备对参数求和",{"2":{"835":1}}],["需要扩大小批量的大小为k的倍数",{"2":{"833":1}}],["需要传输的数据量也可能比跨gpu拆分层时还要大",{"2":{"832":1}}],["需要等待碟片旋转到位",{"2":{"804":1}}],["需要先告诉内存模块在哪里可以找到信息",{"2":{"802":1}}],["需要先安装nltk",{"2":{"724":1}}],["需要确保每一步工作都能无缝链接",{"2":{"801":1}}],["需要将训练集特征矩阵进行转置",{"2":{"1100":1}}],["需要将训练样本进行排序",{"2":{"386":1}}],["需要将以下demo变量设置为false",{"2":{"889":1}}],["需要将数据转移到处理器上",{"2":{"801":1}}],["需要安装spacy",{"2":{"717":1}}],["需要与embed",{"2":{"714":1}}],["需要大量的计算资源才能进行微调",{"2":{"686":1}}],["需要睡眠",{"2":{"675":1}}],["需要",{"2":{"615":1,"674":1}}],["需要通过反复试验进行调整",{"2":{"605":1}}],["需要如何更改学习率",{"2":{"597":1}}],["需要改变框架么",{"2":{"485":1}}],["需要在所有设备上初始化网络参数",{"2":{"828":1}}],["需要在strategy",{"2":{"473":1}}],["需要在进入壁橱之前考虑它之前的观察结果",{"2":{"298":1}}],["需要对架构加上什么限制",{"2":{"444":1}}],["需要注意的就是p值",{"2":{"1145":1}}],["需要注意的一个重要细节是",{"2":{"442":1}}],["需要注意的是",{"2":{"78":1,"446":1,"447":1,"488":1,"618":2,"923":1}}],["需要格外小心",{"2":{"426":1}}],["需要做什么",{"2":{"420":1}}],["需要下面的输入",{"2":{"375":1}}],["需要定义一个show",{"2":{"357":1}}],["需要增加n",{"2":{"338":1}}],["需要考虑对话历史状态以及现实世界的知识",{"2":{"295":1}}],["需要数千或数百万次的计算",{"2":{"281":1}}],["需要进行比较的模型在本质上是完全不同的",{"2":{"255":1}}],["需要进行预处理",{"2":{"214":1}}],["需要目标分布",{"2":{"191":1}}],["需要说明的是",{"2":{"170":1}}],["需要使用按元素乘法运算符",{"2":{"164":1}}],["需要构造一个与输入数据具有相同输入通道数的卷积核",{"2":{"120":1}}],["需要调整γ吗",{"2":{"111":1}}],["需要更多的迭代",{"2":{"55":1}}],["需要保持在盒子内",{"2":{"48":1}}],["嵌套路由",{"0":{"1479":1}}],["嵌套块",{"2":{"432":1}}],["嵌入权重",{"2":{"703":1}}],["嵌入层返回具有形状",{"2":{"762":1}}],["嵌入层的输入是词元",{"2":{"762":1}}],["嵌入层的权重是一个矩阵",{"2":{"573":1}}],["嵌入层将词元的索引映射到其特征向量",{"2":{"762":1}}],["嵌入层",{"0":{"762":1},"2":{"573":4}}],["嵌入层获取权重矩阵的第i行",{"2":{"573":1}}],["独立性",{"0":{"1034":1}}],["独立的特征抽取会导致重复的计算",{"2":{"938":1}}],["独立的循环神经网络解码器是基于输入序列的编码信息",{"2":{"572":1}}],["独热编码是一个向量",{"2":{"640":1}}],["独热编码",{"0":{"330":1},"2":{"640":1}}],["载入",{"2":{"565":1}}],["翻译模型和语言模型等组成部分的统计分析",{"2":{"564":1}}],["翻转和裁剪",{"0":{"879":1}}],["翻转",{"2":{"156":1}}],["涉及中心词wc和上下文词wo的对数条件概率为",{"2":{"784":1}}],["涉及编码",{"2":{"649":1}}],["涉及了",{"2":{"564":1}}],["涉及一个",{"2":{"317":1}}],["候选记忆元参数",{"2":{"558":4}}],["候选记忆元的如",{"2":{"554":1}}],["候选记忆元",{"0":{"554":1}}],["候选隐状态参数",{"2":{"544":4}}],["候选隐状态和输出层相关的所有权重和偏置",{"2":{"544":1}}],["候选隐状态是以xt作为输入的多层感知机的结果",{"2":{"541":1}}],["候选隐状态",{"0":{"541":1}}],["遗忘门和输出门",{"2":{"562":1}}],["遗忘门和输出门的值",{"2":{"553":1}}],["遗忘门参数",{"2":{"558":4}}],["遗忘门是ft∈rn×h",{"2":{"553":1}}],["遗憾的是",{"2":{"26":2,"68":1,"106":1,"311":1,"1129":2}}],["却无法通过参数化等方法对处理过程进行干预",{"2":{"1158":1}}],["却没有标签",{"2":{"1150":1}}],["却没有对结果有要求",{"2":{"296":1}}],["却不知如何处理",{"2":{"1061":1}}],["却比门控循环单元早诞生了近20年",{"2":{"551":1}}],["⊙h~t",{"2":{"542":1}}],["门控记忆元",{"0":{"552":1},"1":{"553":1,"554":1,"555":1,"556":1}}],["门控循环神经网络可以更好地捕获时间步距离很长的序列上的依赖关系",{"2":{"548":1}}],["门控循环单元可以跳过子序列",{"2":{"548":1}}],["门控循环单元包含基本循环神经网络",{"2":{"548":1}}],["门控循环单元具有以下两个显著特征",{"2":{"542":1}}],["门控循环单元与普通的循环神经网络之间的关键区别在于",{"2":{"539":1}}],["门控循环单元",{"0":{"538":1},"1":{"539":1,"540":1,"541":1,"542":1,"543":1,"544":1,"545":1,"546":1,"547":1,"548":1,"549":1},"2":{"530":1,"538":1}}],["门控隐状态",{"0":{"539":1},"1":{"540":1,"541":1,"542":1}}],["书的章节之间可能会有过渡存在",{"2":{"538":1}}],["书中前几个字符的三种策略",{"2":{"311":1}}],["书中每次实验报告的准确度都是验证集准确度",{"2":{"256":1}}],["体积大小",{"2":{"1346":1}}],["体系架构中的术语状态",{"2":{"535":1}}],["体力活动",{"2":{"185":1}}],["合起来",{"2":{"1089":1,"1107":1}}],["合成图像具有与风格图像中一样的色彩块",{"2":{"927":1}}],["合成图像保留了内容图像的风景和物体",{"2":{"927":1}}],["合成的图像是训练期间唯一需要更新的变量",{"2":{"926":1}}],["合并到$attrs中了",{"2":{"1496":1}}],["合并分支",{"2":{"1329":1}}],["合并属于同一目标的类似的预测边界框",{"2":{"854":1}}],["合并",{"2":{"757":1,"1325":1}}],["合并方法是在包含所有参数的矩阵中附加一列",{"2":{"612":1}}],["合并编码器和解码器",{"0":{"535":1}}],["合理的假设是",{"2":{"152":1}}],["熊市或牛市",{"2":{"526":1}}],["∝∑hjπj",{"2":{"519":1}}],["∝p",{"2":{"280":1,"337":1}}],["ρxy=cov",{"2":{"1154":1}}],["ρj",{"2":{"519":1}}],["ρt",{"2":{"519":2}}],["ρt−1",{"2":{"519":2}}],["ρ1",{"2":{"519":1}}],["写界面",{"2":{"1543":1}}],["写小说时从第",{"2":{"1322":1}}],["写论文时保存了很多版本的文件",{"2":{"1318":1}}],["写操作",{"2":{"1209":1}}],["写前日志",{"2":{"1202":1}}],["写",{"2":{"1200":1}}],["写时复制",{"0":{"1200":1}}],["写一个函数",{"2":{"1111":1}}],["写到",{"2":{"1092":1}}],["写出协同过滤算法的预测情况",{"2":{"1191":1}}],["写出来就是",{"2":{"1092":1}}],["写出模型−log⁡p",{"2":{"621":1}}],["写控制语句",{"2":{"1091":1}}],["写成w4tch",{"2":{"1137":1}}],["写成",{"2":{"1089":1}}],["写下无限多个特征",{"2":{"1060":1}}],["写法简洁",{"2":{"1243":1}}],["写法",{"2":{"1048":1}}],["写入它",{"2":{"1490":1}}],["写入磁盘",{"2":{"1198":1}}],["写入速度仍然会比读取慢得多",{"2":{"805":1}}],["写入或读取从字符串映射到张量的字典",{"2":{"441":1}}],["写为",{"2":{"519":2}}],["传递params参数时",{"2":{"1482":2}}],["传递参数",{"2":{"1481":1,"1482":1}}],["传输通过标准输入和输出流进行通信",{"2":{"1047":1}}],["传输层负责将",{"2":{"1044":1}}],["传输层处理消息发送和接收的底层机制",{"2":{"1043":1}}],["传达了重要信息",{"2":{"518":1}}],["传统模型中",{"2":{"300":1}}],["饿了",{"2":{"518":2}}],["双重机制",{"2":{"1202":1}}],["双车道的网络",{"2":{"1127":1}}],["双车道网络的自信度便开始上升",{"2":{"1127":1}}],["双下划线",{"2":{"1006":1}}],["双线性插值放大的图像和在",{"2":{"863":1}}],["双线性插值的上采样实验",{"2":{"863":1}}],["双线性插值的上采样可以通过转置卷积层实现",{"2":{"863":1}}],["双线性插值",{"2":{"863":1}}],["双向长短期记忆网络在初始和最终时间步的隐状态",{"2":{"713":1}}],["双向层的使用在实践中非常少",{"2":{"522":1}}],["双向模型",{"0":{"520":1},"1":{"521":1,"522":1}}],["双向循环神经网络可以表示文本序列",{"2":{"716":1}}],["双向循环神经网络主要用于序列编码和给定双向上下文的观测估计",{"2":{"524":1}}],["双向循环神经网络与概率图模型中的",{"2":{"524":1}}],["双向循环神经网络的错误应用",{"0":{"523":1}}],["双向循环神经网络的计算速度非常慢",{"2":{"522":1}}],["双向循环神经网络的一个关键特性是",{"2":{"522":1}}],["双向循环神经网络是由",{"2":{"521":1}}],["双向循环神经网络没有这样容易理解的解释",{"2":{"520":1}}],["双向循环神经网络",{"0":{"518":1},"1":{"519":1,"520":1,"521":1,"522":1,"523":1,"524":1,"525":1},"2":{"520":1}}],["双曲正切",{"2":{"237":1}}],["束宽是如何影响预测的速度和结果的",{"2":{"517":1}}],["束搜索通过灵活选择束宽",{"2":{"516":1}}],["束搜索可以在正确率和计算代价之间进行权衡",{"2":{"515":1}}],["束搜索的计算量为o",{"2":{"515":1}}],["束搜索",{"0":{"512":1,"515":1},"1":{"513":1,"514":1,"515":1,"516":1,"517":1},"2":{"515":1}}],["名",{"2":{"1460":1}}],["名为hello",{"2":{"1089":1}}],["名为束宽",{"2":{"515":1}}],["名词最多可能有15种变形",{"2":{"755":1}}],["名词",{"2":{"659":2}}],["名称的分布发生了相当大的概念偏移",{"2":{"183":1}}],["名称如",{"2":{"65":1}}],["穷举地列举所有可能的输出序列及其条件概率",{"2":{"514":1}}],["穷举搜索所选取序列的精度最高",{"2":{"516":1}}],["穷举搜索和束搜索",{"2":{"516":1}}],["穷举搜索",{"0":{"514":1},"2":{"512":1}}],["∣",{"2":{"783":5,"785":1}}],["∣w",{"2":{"708":3,"783":1,"784":1,"785":1,"786":1}}],["∣y1",{"2":{"513":1,"515":1,"574":2}}],["∣x",{"2":{"316":2,"646":2}}],["∏k=1",{"2":{"708":1}}],["∏n=1kpn1",{"2":{"578":1}}],["∏t=1tp",{"2":{"785":1}}],["∏t=1t∏−m≤j≤m",{"2":{"708":2,"783":1}}],["∏t=4tp",{"2":{"519":1}}],["∏t=3tp",{"2":{"519":1}}],["∏t",{"2":{"513":1}}],["∏j=i+1t∂f",{"2":{"307":1}}],["∏j=i+1tcj",{"2":{"307":1}}],["贪心搜索所选取序列的计算量最小",{"2":{"516":1}}],["贪心搜索可以看作一种束宽为1的特殊类型的束搜索",{"2":{"515":1}}],["贪心搜索的计算量",{"2":{"514":1}}],["贪心搜索获得的输出序列",{"2":{"513":1}}],["贪心搜索无法保证得到最优序列",{"2":{"513":1}}],["贪心搜索选择具有最高条件概率的词元",{"2":{"513":1}}],["贪心搜索",{"0":{"513":1},"2":{"513":1}}],["送入全连接层处理",{"2":{"508":1}}],["极速热更新",{"2":{"1528":1}}],["极接近于恒等映射时",{"2":{"501":1}}],["极限条件下",{"2":{"89":1}}],["⊆f6",{"2":{"500":1}}],["∗prβ2∗p+r",{"2":{"1154":1}}],["∗g",{"2":{"1121":1}}],["∗",{"2":{"1116":1,"1121":1}}],["∗∗regularizationparameter∗∗",{"2":{"1115":1}}],["∗可能更糟",{"2":{"500":1}}],["∗比ff∗",{"2":{"500":1}}],["怎么回到你原来的表示x",{"2":{"1161":1}}],["怎么样设置效果最好",{"2":{"227":1}}],["怎样让算法工作地更加有效",{"2":{"1180":1}}],["怎样分配自己的时间来优化算法",{"2":{"1138":1}}],["怎样把你的参数从矩阵展开成向量",{"2":{"1123":1}}],["怎样把数据存入一个矩阵",{"2":{"1089":1}}],["怎样的模型才能适合呢",{"2":{"1108":1}}],["怎样取出矩阵",{"2":{"1089":1}}],["怎样才能将这个变量转换为锚框类别和偏移量",{"2":{"915":1}}],["怎样处理在长时间运行的计算过程中丢失了一台服务器这种问题",{"2":{"846":1}}],["怎样得到更近似真正f∗的函数呢",{"2":{"500":1}}],["移除了$children",{"2":{"1525":1}}],["移除了$on",{"2":{"1525":1}}],["移除了过滤器",{"2":{"1525":1}}],["移除事件总线",{"2":{"1496":1}}],["移除keycode支持作为",{"2":{"1441":1}}],["移除全连接层可减少过拟合",{"2":{"497":1}}],["移动端",{"2":{"1529":1}}],["移动数据",{"0":{"1089":1},"2":{"1193":1}}],["移动",{"2":{"126":1}}],["针对",{"2":{"1315":1}}],["针对用户",{"2":{"1188":1}}],["针对测试集进行预测",{"2":{"1181":1}}],["针对不同隐藏层层数的神经网络训练神经网络",{"2":{"1135":1}}],["针对逻辑回归问题",{"2":{"1117":1}}],["针对数据集",{"2":{"1061":1}}],["针对序列级和词元级应用微调bert",{"0":{"656":1},"1":{"657":1,"658":1,"659":1,"660":1,"661":1,"662":1}}],["针对住院病人等",{"2":{"608":1}}],["针对这一问题",{"2":{"500":1}}],["针对每个高度和宽度",{"2":{"494":1}}],["针对此类数据而设计特定模型",{"2":{"305":1}}],["帮助你更好地理解其设计思路",{"2":{"1194":1}}],["帮助你明白怎样进行选择",{"2":{"1129":1}}],["帮助你在",{"2":{"1041":1}}],["帮助读者快速掌握深度学习中常用的微分知识",{"2":{"980":1}}],["帮助培养对该领域发展的直觉",{"2":{"492":1}}],["帮助识别处理支票的数字",{"2":{"135":1}}],["残差映射可以更容易地学习同一函数",{"2":{"504":1}}],["残差映射也易于捕捉恒等映射的细微波动",{"2":{"501":1}}],["残差映射在现实中往往更容易优化",{"2":{"501":1}}],["残差块的实现如下",{"2":{"501":1}}],["残差块里首先有2个有相同输出通道数的3×3卷积层",{"2":{"501":1}}],["残差块",{"0":{"501":1},"2":{"500":1,"501":1}}],["残差网络的核心思想是",{"2":{"500":1}}],["残差网络",{"0":{"499":1},"1":{"500":1,"501":1,"502":1,"503":1,"504":1,"505":1},"2":{"492":1,"504":1}}],["残差连接",{"2":{"561":1}}],["残差连接要求两个输入的形状相同",{"2":{"406":1}}],["残差连接后进行层规范化",{"2":{"406":4}}],["残差连接和层规范化",{"0":{"406":1}}],["串联起来",{"2":{"490":1}}],["线路4",{"2":{"487":4}}],["线路3",{"2":{"487":4}}],["线路2",{"2":{"487":4}}],["线路1",{"2":{"487":4}}],["线性核函数",{"2":{"1147":1}}],["线性代数算法来计算两个向量θ以及x的内积",{"2":{"1093":1}}],["线性代数回顾",{"0":{"1071":1},"1":{"1072":1,"1073":1,"1074":1,"1075":1,"1076":1,"1077":1},"2":{"1193":1}}],["线性代数不仅仅在线性回归中应用广泛",{"2":{"1070":1}}],["线性代数还有很多",{"2":{"1002":1}}],["线性代数中最有用的一些运算符是范数",{"2":{"1000":1}}],["线性代数",{"0":{"988":1},"1":{"989":1,"990":1,"991":1,"992":1,"993":1,"994":1,"995":1,"996":1,"997":1,"998":1,"999":1,"1000":1,"1001":1,"1002":1,"1003":1,"1004":1}}],["线性代数为人们提供了一些用来处理表格数据的方法",{"2":{"987":1}}],["线性代数加速",{"2":{"819":1}}],["线性复杂度",{"2":{"674":1}}],["线性假设是指目标",{"2":{"610":1}}],["线性回归和逻辑回归是同一个算法吗",{"2":{"1110":1}}],["线性回归并不适用于所有数据",{"2":{"1084":1}}],["线性回归中的代价函数",{"2":{"1068":1}}],["线性回归发明的时间",{"2":{"619":1}}],["线性回归恰好是一个在整个域中只有一个最小值的学习问题",{"2":{"613":1}}],["线性回归刚好是一个很简单的优化问题",{"2":{"612":1}}],["线性回归基于几个简单的假设",{"2":{"609":1}}],["线性回归",{"0":{"608":1},"1":{"609":1,"610":1,"611":1,"612":1,"613":1,"614":1,"615":1,"616":1,"617":1,"618":1,"619":1,"620":1,"621":1},"2":{"609":1}}],["线性回归有解析解",{"2":{"604":1}}],["线性回归的目的是预测结果",{"2":{"1158":1}}],["线性回归的目标是找到一组权重向量w和偏置b",{"2":{"610":1}}],["线性回归的代价函数为",{"2":{"1109":1}}],["线性回归的解可以用一个公式简单地表达出来",{"2":{"612":1}}],["线性回归的基本元素",{"0":{"609":1},"1":{"610":1,"611":1,"612":1,"613":1,"614":1}}],["线性回归的从零开始实现",{"0":{"598":1},"1":{"599":1,"600":1,"601":1,"602":1,"603":1,"604":1,"605":1,"606":1,"607":1}}],["线性回归的简洁实现",{"0":{"588":1},"1":{"589":1,"590":1,"591":1,"592":1,"593":1,"594":1,"595":1,"596":1,"597":1}}],["线性回归模型也是一个简单的神经网络",{"2":{"620":1}}],["线性回归模型",{"2":{"588":1,"602":1,"1107":1}}],["线性神经网络开始",{"2":{"587":1}}],["线性神经网络",{"0":{"587":1}}],["线性而不是指数",{"2":{"519":1}}],["线性投影",{"2":{"380":1}}],["线性和非线性处理单元的交替",{"2":{"299":1}}],["线性网络和平方损失没有变化",{"2":{"275":1}}],["线性函数拟合",{"0":{"265":1}}],["线性意味着单调假设",{"2":{"230":1}}],["线性模型",{"0":{"610":1}}],["线性模型和核方法转移到了深度神经网络",{"2":{"300":1}}],["线性模型容易欠拟合",{"2":{"265":1}}],["线性模型可能会出错",{"0":{"230":1}}],["线性模型将作为基线",{"2":{"210":1}}],["线性模型有很高的偏差",{"2":{"169":1}}],["线性模型必须指定正的或负的权重",{"2":{"169":1}}],["线性模型没有考虑到特征之间的交互作用",{"2":{"169":1}}],["线性模型泛化的可靠性是有代价的",{"2":{"169":1}}],["线性模型往往会过拟合",{"2":{"169":1}}],["线性",{"2":{"60":1,"622":1}}],["架构图",{"0":{"1378":1}}],["架构原理",{"0":{"1340":1,"1375":1},"1":{"1376":1,"1377":1,"1378":1}}],["架构对比",{"2":{"1205":1}}],["架构和束搜索",{"2":{"550":1}}],["架构的设计",{"2":{"579":1}}],["架构的应用吗",{"2":{"537":1}}],["架构的序列转换模型",{"2":{"535":1}}],["架构可以将长度可变的序列作为输入和输出",{"2":{"536":1}}],["架构包含了一个编码器和一个解码器",{"2":{"535":1}}],["架构是形成后续章节中不同序列转换模型的基础",{"2":{"532":1}}],["架构将长度可变的输入序列编码成一个",{"2":{"532":1}}],["架构更改为",{"2":{"505":1}}],["架构来降低模型复杂性",{"2":{"505":1}}],["架构",{"2":{"480":1,"505":1,"532":1,"537":1,"572":1,"1194":1,"1340":1,"1375":1}}],["稠密",{"2":{"657":1}}],["稠密块里的卷积层通道数",{"2":{"482":1}}],["稠密块体",{"0":{"480":1}}],["稠密块",{"2":{"479":1}}],["稠密网络主要由2部分构成",{"2":{"479":1}}],["稠密连接如",{"2":{"479":1}}],["稠密连接",{"2":{"479":1}}],["稠密连接网络",{"0":{"478":1},"1":{"479":1,"480":1,"481":1,"482":1,"483":1,"484":1,"485":1},"2":{"478":1,"484":1,"492":1}}],["规律",{"2":{"1470":1}}],["规范中最新",{"2":{"1047":1}}],["规范化提交",{"2":{"1544":1}}],["规范化的损失数",{"2":{"767":3}}],["规范化的损失之和",{"2":{"767":3}}],["规范化qij的代价在于整个词表的求和",{"2":{"742":1}}],["规范化",{"2":{"477":1}}],["规则截断和随机截断",{"2":{"313":1}}],["争议",{"0":{"475":1}}],["于",{"2":{"1040":1,"1359":1}}],["于lenet模型",{"2":{"473":1}}],["于是我们介绍了一些诊断法",{"2":{"1176":1}}],["于是他们把诸如这样的机器学习问题",{"2":{"1141":1}}],["于是渐渐成为了比samuel更厉害的西洋棋手",{"2":{"1059":1}}],["于是就通过编程",{"2":{"1059":1}}],["于是就产生了飞桨2",{"2":{"818":1}}],["于是就产生了torchscript",{"2":{"818":1}}],["于是mxnet将自动确定这个参数",{"2":{"821":1}}],["于是得到了一个混合式编程模型",{"2":{"818":1}}],["于是网络和总线就派上了用场",{"2":{"812":1}}],["于是当前的时间步4基于前三个时间步的输出子序列",{"2":{"513":1}}],["于是nadaraya",{"2":{"388":1}}],["于是通过以下途径预测xt",{"2":{"346":1}}],["于是基于循环计算的隐状态神经网络被命名为",{"2":{"340":1}}],["于是任意长的序列可以被我们划分为具有相同时间步数的子序列",{"2":{"319":1}}],["于是",{"2":{"315":1,"351":1,"457":1,"500":1,"1188":1,"1355":1}}],["跟我一起走进这场网页魔法秀吧",{"2":{"1532":1}}],["跟线性回归的梯度下降实际上是两个完全不同的东西",{"2":{"1110":1}}],["跟刚才一样还是那个",{"2":{"1089":1}}],["跟踪开销",{"2":{"1518":1}}],["跟踪当前进度",{"2":{"1052":1}}],["跟踪移动平均线",{"2":{"472":1}}],["跟以前一样",{"2":{"217":1}}],["撇开算法细节",{"2":{"472":1}}],["均配置在setup中",{"2":{"1451":1}}],["均一性和完整性的加权平均",{"2":{"1154":1}}],["均一性",{"2":{"1154":1}}],["均值归一化",{"0":{"1192":1},"2":{"1193":1}}],["均值聚类",{"2":{"1176":1}}],["均值的结果",{"2":{"1153":1}}],["均值的一个问题在于",{"2":{"1153":1}}],["均值的代价函数",{"2":{"1152":1}}],["均值迭代算法",{"2":{"1152":1}}],["均值最小化问题",{"2":{"1152":1}}],["均值是一个迭代算法",{"2":{"1151":1}}],["均值是最普及的聚类算法",{"2":{"1151":1}}],["均值算法聚类的动机是什么",{"2":{"1154":1}}],["均值算法的之前",{"2":{"1153":1}}],["均值算法的伪代码如下",{"2":{"1151":1}}],["均值算法将数据分为三类",{"2":{"1151":1}}],["均值算法也可以很便利地用于将数据分为许多不同组",{"2":{"1151":1}}],["均值算法",{"0":{"1151":1},"2":{"1153":1,"1193":1}}],["均值和标准差对",{"2":{"616":1}}],["均值和方差是在应用变换的",{"2":{"469":1}}],["均为1或均为0",{"2":{"1102":1}}],["均有100个输出通道",{"2":{"702":1}}],["均方误差损失函数",{"2":{"616":1}}],["均方损失",{"2":{"603":1}}],["均在0～1之间",{"2":{"583":1}}],["均匀的注意力权重",{"2":{"370":1}}],["乍看起来",{"2":{"467":1}}],["乍一看",{"2":{"398":1}}],["拉开序幕的",{"0":{"1450":1},"1":{"1451":1,"1452":1,"1453":1,"1454":1}}],["拉取镜像",{"2":{"1342":1}}],["拉取远程更新",{"2":{"1330":1}}],["拉伸gamma和偏移beta",{"2":{"472":1}}],["拉伸参数gamma和偏移参数beta",{"2":{"473":1}}],["拉伸参数",{"2":{"467":1}}],["拉格朗日函数",{"0":{"48":1}}],["容器端口",{"2":{"1391":1}}],["容器技术将继续向着",{"2":{"1357":1}}],["容器与",{"2":{"1357":1}}],["容器和分布式集群不仅仅是技术工具",{"2":{"1357":1}}],["容器和虚拟机的区别",{"0":{"1346":1}}],["容器编排和集群管理",{"2":{"1394":1}}],["容器编排",{"2":{"1355":1}}],["容器编排系统",{"2":{"1350":1}}],["容器基于操作系统内核实现轻量级隔离",{"2":{"1353":1}}],["容器化是单个应用的交付方式",{"2":{"1356":1}}],["容器化与集群化的关系",{"0":{"1356":1}}],["容器化与分布式集群",{"0":{"1352":1},"1":{"1353":1,"1354":1,"1355":1,"1356":1,"1357":1}}],["容器化的意义",{"0":{"1354":1}}],["容器化",{"2":{"1352":1,"1356":1,"1543":1}}],["容器作为运行时",{"2":{"1350":1}}],["容器引擎",{"2":{"1350":1}}],["容器",{"2":{"1346":1,"1353":1}}],["容器相关",{"0":{"1343":1}}],["容器运行时",{"2":{"1377":1}}],["容器运行",{"2":{"1340":1}}],["容易导致高方差和过拟合",{"2":{"1135":1}}],["容易导致高偏差和欠拟合",{"2":{"1135":1}}],["容易阅读和获取",{"2":{"1093":1}}],["容易过拟合",{"2":{"467":1}}],["容量控制和预处理",{"0":{"461":1}}],["池化层不用于减少输入的高度和宽度",{"2":{"461":1}}],["池运算是确定性的",{"2":{"146":1}}],["功耗往往会随时钟频率呈二次方增长",{"2":{"457":1}}],["功能类似",{"2":{"1499":1}}],["功能有限",{"2":{"1395":1}}],["功能最强大",{"2":{"1355":1}}],["功能分支",{"2":{"1325":1}}],["功能强大",{"2":{"1296":1,"1351":1,"1395":1}}],["功能描述",{"2":{"1052":1}}],["功能",{"0":{"11":1},"2":{"295":1,"668":1,"819":1,"1102":1,"1227":1,"1351":1}}],["早饭我吃了",{"2":{"1141":1}}],["早餐我吃了2个鸡蛋",{"2":{"1141":1}}],["早餐我吃了",{"2":{"1141":1}}],["早于计算神经科学",{"2":{"619":1}}],["早期观测值对预测所有未来观测值具有非常重要的意义",{"2":{"538":1}}],["早期的一个例子是卡尔",{"2":{"291":1}}],["早年用来加速图形处理",{"2":{"457":1}}],["挑出具有最高条件概率的k个候选输出序列",{"2":{"515":1}}],["挑战研究人员确定哪些模型能够在更大的数据规模下表现最好",{"2":{"456":1}}],["挑选一些样本",{"2":{"116":1}}],["限于篇幅",{"2":{"863":1,"936":1}}],["限于早期计算机有限的存储和90年代有限的研究预算",{"2":{"456":1}}],["限制每个person对象的格式",{"2":{"1469":1}}],["限制并行数",{"2":{"1313":1}}],["限制变尺度法",{"2":{"1111":1}}],["限制特征的数量是缓解过拟合的一种常用技术",{"2":{"269":1}}],["限制行为生效可能需要很长时间",{"2":{"106":1}}],["缺点",{"2":{"1476":2}}],["缺少学习曲线",{"2":{"1138":1}}],["缺少巷子类型的行会将",{"2":{"1012":1}}],["缺少的成分",{"0":{"456":1,"457":1}}],["缺失值",{"2":{"209":1}}],["缺失值被简单地标记为",{"2":{"208":1}}],["突破可归因于两个关键因素",{"2":{"455":1}}],["突破性的深度q网络",{"2":{"298":1}}],["鼻子",{"2":{"455":1}}],["严谨且非常有用的领域",{"2":{"454":1}}],["严格来说不是缓存的一部分",{"2":{"810":1}}],["严格来说",{"2":{"126":1,"610":1,"989":1}}],["缩放图像以创建224x224的新图像",{"2":{"903":3}}],["缩放比为0",{"2":{"848":1}}],["缩放比为s∈",{"2":{"848":1}}],["缩放和移位",{"2":{"472":4}}],["缩放",{"2":{"454":1}}],["缩放点积注意力",{"0":{"370":1},"2":{"370":3}}],["咖啡已经准备好了",{"2":{"450":1}}],["咖啡锅炉控制器将根据之前是否加热锅炉来观测到不同的温度",{"2":{"198":1}}],["旁注",{"0":{"450":1}}],["阅读源码",{"2":{"1436":1}}],["阅读内容和风格图像",{"0":{"918":1}}],["阅读混合式编程部分",{"2":{"426":1}}],["阅读提出并分析每种启发式方法的论文",{"2":{"248":1}}],["效果如下",{"2":{"1099":1}}],["效果得有多好",{"2":{"837":1}}],["效果有提升吗",{"2":{"465":1}}],["效率也不高",{"2":{"1158":1}}],["效率",{"0":{"426":1}}],["效应",{"2":{"345":1}}],["省得二次掉坑",{"2":{"1545":1}}],["省去了重复编写模版代码的痛苦",{"2":{"423":1}}],["省略前两个维度",{"2":{"141":3}}],["块只能作为一个整体来写入",{"2":{"805":1}}],["块的使用导致网络定义的非常简洁",{"2":{"510":1}}],["块的一个主要优点是它的多功能性",{"2":{"423":1}}],["块工厂",{"2":{"433":1}}],["块负责大量的内部处理",{"2":{"427":1}}],["块可以包含代码",{"2":{"427":1}}],["块必须具有反向传播函数",{"2":{"422":1}}],["块由类",{"2":{"422":1}}],["块",{"2":{"422":1,"1365":4}}],["研究优秀开源项目的",{"2":{"1436":1}}],["研究论文和书籍中的丰富文本",{"2":{"754":1}}],["研究gelu与relu之间的差异",{"2":{"740":1}}],["研究人们在文本中",{"2":{"691":1}}],["研究人员花费了大量时间才最终实现这行代码",{"2":{"1061":1}}],["研究人员花费了数百万美元的研究资金",{"2":{"869":1}}],["研究人员开始从单个神经元的角度思考问题",{"2":{"506":1}}],["研究人员发明了专门用于处理图像",{"2":{"412":1}}],["研究人员通过使用只能被视为可学习的指针结构",{"2":{"300":1}}],["研究人员一直试图组装类似于相互作用的神经元网络的计算电路",{"2":{"299":1}}],["研究人员称之为",{"2":{"201":1}}],["研究思路",{"2":{"477":1}}],["研究讨论",{"2":{"422":1}}],["像一个人的肘部",{"2":{"1154":1}}],["像上图",{"2":{"1143":1}}],["像这样的结果",{"2":{"1141":1}}],["像这样输入warmupexercise",{"2":{"1094":1}}],["像这样",{"2":{"1092":1}}],["像这些x1和x2是线性相关的",{"2":{"1086":1}}],["像逻辑回归算法",{"2":{"1085":1}}],["像庞大的python生态系统中的许多其他扩展包一样",{"2":{"1010":1}}],["像素",{"2":{"912":1}}],["像线性回归这样的简单问题存在解析解",{"2":{"612":1}}],["像选择超参数这类架构决策也跟",{"2":{"528":1}}],["像往常一样",{"2":{"528":1}}],["像单个神经元一样",{"2":{"422":1}}],["像以前一样生成一些数据",{"2":{"271":1}}],["灵活高效",{"2":{"1526":1}}],["灵活查询",{"2":{"1195":1}}],["灵活存储",{"2":{"1195":1,"1211":1}}],["灵活切换不同的",{"2":{"1041":1}}],["灵活的开源工具使研究人员能够快速开发模型原型",{"2":{"421":1}}],["灵感来自前者",{"2":{"818":1}}],["灵长类动物的视觉系统接受了大量的感官输入",{"2":{"379":1}}],["优点",{"2":{"1476":2}}],["优点是隔离彻底",{"2":{"1353":1}}],["优秀",{"2":{"1223":1}}],["优秀的软件工具在深度学习的快速发展中发挥了不可或缺的作用",{"2":{"421":1}}],["优等算法",{"2":{"1141":1}}],["优雅的理论去证明各种模型的性质",{"2":{"454":1}}],["优化我们想给用户开出的价格",{"2":{"1168":1}}],["优化数据通信",{"2":{"1150":1}}],["优化目标",{"0":{"1143":1,"1152":1},"2":{"1193":2}}],["优化",{"2":{"980":1}}],["优化同步工具以获得高性能也是有好处的",{"2":{"825":1}}],["优化通常是说最小化而不是最大化",{"2":{"616":1}}],["优化器和神经网络层很常用",{"2":{"588":1}}],["优化中的各种噪声源通常会导致更快的训练和较少的过拟合",{"2":{"467":1}}],["优化凸目标的简单算法是研究人员的首选",{"2":{"457":1}}],["优化到它的最高点",{"2":{"286":1}}],["优化期间的注意和适当的正则化也可以进一步提高稳定性",{"2":{"245":1}}],["优化将会停滞很长一段时间",{"2":{"103":1}}],["优化的目标",{"0":{"99":1}}],["优化和深度学习的目标是根本不同的",{"2":{"99":1}}],["优化和深度学习",{"0":{"98":1},"1":{"99":1,"100":1,"101":1,"102":1,"103":1,"104":1,"105":1}}],["优化使用的是随机梯度下降",{"2":{"80":1}}],["优化在深度学习中有多种用途",{"2":{"74":1}}],["优化之前的预热期可以防止发散",{"2":{"74":1}}],["优化就会发散",{"2":{"66":1}}],["优化算法的学习速率将在每4个周期乘以0",{"2":{"895":1}}],["优化算法的性能直接影响模型的训练效率",{"2":{"65":1}}],["优化算法在多个gpu上自动聚合",{"2":{"829":2}}],["优化算法在训练的每一步衰减权重",{"2":{"270":1}}],["优化算法对于深度学习非常重要",{"2":{"65":1}}],["优化算法使我们能够继续更新模型参数",{"2":{"65":1}}],["优化算法",{"0":{"65":1,"287":1,"625":1},"2":{"620":1}}],["优化研究人员称之为",{"2":{"60":1}}],["优化问题可能有许多局部最小值",{"2":{"104":1}}],["优化问题可能会发散",{"2":{"53":1}}],["优化问题将会发散",{"2":{"95":1}}],["优化问题是以逐坐标顺序的方式进行的",{"2":{"94":1}}],["优化问题",{"2":{"48":1}}],["避免",{"2":{"1354":1}}],["避免使用",{"2":{"1215":1}}],["避免使用数量不足的训练样本",{"2":{"267":1}}],["避免热点问题",{"2":{"1207":1}}],["避免了对每一个内部属性做响应式所带来的性能成本",{"2":{"1513":1}}],["避免了任何潜在的与python解释器相关的性能问题",{"2":{"817":1}}],["避免了我们使用标准组件时的重复工作",{"2":{"421":1}}],["避免了一些常见的错误",{"2":{"419":1}}],["框架大小",{"2":{"1530":1}}],["框架",{"2":{"1526":1}}],["框架会首先将其复制到内存中",{"2":{"450":1}}],["框架就可以初始化参数",{"2":{"418":1}}],["框架处理第二层",{"2":{"418":1}}],["框架可以通过代入值20来识别第一层权重矩阵的形状",{"2":{"418":1}}],["框架尚未初始化任何参数",{"2":{"418":1}}],["框架才会动态地推断出每个层的大小",{"2":{"417":1}}],["框架将使用默认的随机初始化方法",{"2":{"246":1}}],["法",{"2":{"565":1,"566":1,"572":1}}],["法语是目标语言",{"2":{"565":1}}],["法语",{"2":{"409":1,"565":2,"566":1,"569":1}}],["法国",{"2":{"296":1}}],["堆叠了num",{"2":{"407":1}}],["组织数据集后",{"2":{"890":1}}],["组合api",{"2":{"1441":1}}],["组合算法也类似",{"2":{"1073":1}}],["组合",{"2":{"848":1,"1447":1}}],["组合来自所有工作节点的梯度",{"2":{"844":1}}],["组件化开发",{"2":{"1527":1}}],["组件标签上v",{"2":{"1500":1}}],["组件标签上使用v",{"2":{"1500":1}}],["组件标签上的v",{"2":{"1500":1}}],["组件通信",{"0":{"1496":1},"1":{"1497":1,"1498":1,"1499":1,"1500":1,"1501":1,"1502":1,"1503":1,"1504":1,"1505":1,"1506":1,"1507":1,"1508":1}}],["组件中使用",{"2":{"1520":1}}],["组件中使用state中的数据",{"2":{"1490":1}}],["组件中读取数据",{"2":{"1493":1}}],["组件中调用action即可",{"2":{"1491":1}}],["组件中具体使用",{"2":{"1471":1}}],["组件中所用到的",{"2":{"1451":1}}],["组件名",{"2":{"1444":1}}],["组件",{"2":{"406":1}}],["组成部分",{"2":{"1381":1}}],["组成更大的矩阵",{"2":{"1089":1}}],["组成有关联的新闻",{"2":{"1061":1}}],["组成的一个环",{"2":{"842":1}}],["组成的生物神经元图片",{"2":{"619":1}}],["组成的",{"2":{"565":1}}],["组成",{"2":{"284":1,"573":1,"646":1,"1060":1}}],["ωj",{"2":{"400":2}}],["曲线的形状根据数据的不同而不同",{"2":{"1140":1}}],["曲线在注意力权重较大的区域变得更不平滑",{"2":{"392":1}}],["曲线比以前更加平滑",{"2":{"68":1}}],["排排队",{"2":{"1533":1}}],["排序后的训练样本",{"2":{"386":3}}],["排除掉单子上的至少一半的方法",{"2":{"1129":1}}],["排除未知词元",{"2":{"773":1}}],["排除输入词和未知词元后",{"2":{"750":1}}],["排除输入词",{"2":{"750":1}}],["排除在注意力池中填充词元",{"2":{"375":1}}],["排除不关心的前两维",{"2":{"141":1}}],["核心功能轻量",{"2":{"1527":1}}],["核心特性",{"0":{"1527":1}}],["核心配置",{"2":{"1365":1}}],["核心概念",{"0":{"1360":1,"1379":1},"1":{"1361":1,"1362":1,"1363":1,"1380":1,"1381":1,"1382":1,"1383":1,"1384":1,"1385":1,"1386":1,"1387":1}}],["核心概念深入解构",{"0":{"1308":1},"1":{"1309":1,"1310":1,"1311":1,"1312":1,"1313":1,"1314":1}}],["核心服务",{"2":{"1340":1}}],["核心价值",{"2":{"1339":1}}],["核心机制深入解读与实战示例",{"0":{"1307":1},"1":{"1308":1,"1309":1,"1310":1,"1311":1,"1312":1,"1313":1,"1314":1,"1315":1}}],["核心扩展机制",{"2":{"1206":1}}],["核心接口",{"2":{"1204":1}}],["核心",{"2":{"1169":1}}],["核心采用客户端",{"2":{"1042":1}}],["核函数2",{"0":{"1147":1}}],["核函数",{"2":{"1146":1,"1193":2}}],["核函数1",{"0":{"1146":1}}],["核回归",{"0":{"385":1},"1":{"386":1,"387":1,"388":1,"389":1,"390":1,"391":1,"392":1,"393":1,"394":1}}],["核方法",{"2":{"299":1}}],["子→父",{"2":{"1502":1}}],["子组件中不用编写任何东西",{"2":{"1503":1}}],["子组件中",{"2":{"1498":1,"1506":1,"1507":1,"1508":1}}],["子组件",{"2":{"1497":1,"1501":1}}],["子组件person",{"2":{"1468":1}}],["子传父",{"2":{"1497":1}}],["子",{"2":{"1497":1,"1498":1}}],["子文件夹内都包含相应类的图像",{"2":{"872":1}}],["子词太多会有什么问题呢",{"2":{"759":1}}],["子词嵌入可以提高稀有词和词典外词的表示质量",{"2":{"758":1}}],["子词嵌入",{"0":{"755":1},"1":{"756":1,"757":1,"758":1,"759":1}}],["子层表示为sublayer",{"2":{"404":1}}],["子空间表示",{"2":{"380":1}}],["子序列对",{"2":{"320":1}}],["捕获并处理特定异常",{"2":{"1236":1}}],["捕获序列内各种范围的依赖关系",{"2":{"380":1}}],["捕捉到各种不同的异常情况",{"2":{"1183":1}}],["捕捉到需要填写的空白处周围的词语",{"2":{"1141":1}}],["捕捉到输入之间复杂的相互作用",{"2":{"233":1}}],["意思是在水平轴上取值为x1",{"2":{"1145":1}}],["意思是远远大于0",{"2":{"1143":1}}],["意思是product",{"2":{"1090":1}}],["意思是把",{"2":{"1089":1}}],["意思是双精度浮点型",{"2":{"1089":1}}],["意思是改变路径",{"2":{"1089":1}}],["意味着我们无法根据结果变量",{"2":{"1181":1}}],["意味着给予b更大的权重",{"2":{"1143":1}}],["意味着",{"2":{"1124":1}}],["意味着事件a的发生跟b事件的发生无关",{"2":{"1034":1}}],["意味着跟踪整个计算图",{"2":{"973":1}}],["意味着序列a被软对齐到序列b的每个词元",{"2":{"674":3}}],["意味着序列b被软对齐到序列a的每个词元",{"2":{"674":3}}],["意料之中",{"2":{"874":1}}],["意识的聚集和专注使灵长类动物能够在复杂的视觉环境中将注意力引向感兴趣的物体",{"2":{"379":1}}],["意大利",{"2":{"296":1}}],["源对象",{"2":{"1456":1}}],["源码的升级",{"0":{"1439":1}}],["源模型的成员变量output如下所示",{"2":{"873":1}}],["源",{"2":{"373":1,"404":1}}],["积极",{"2":{"691":1,"692":1,"713":1}}],["积极的和消极的",{"2":{"691":1}}],["积",{"2":{"371":1,"372":2,"397":1}}],["积分",{"2":{"198":1}}],["积分就变成求和",{"2":{"156":1}}],["积分的核的形式是什么",{"2":{"133":1}}],["评测对比",{"2":{"1546":1}}],["评过分的电影",{"2":{"1188":1}}],["评过分的电影的总数",{"2":{"1187":1}}],["评过分则",{"2":{"1187":1}}],["评论的长度各不相同",{"2":{"693":1}}],["评分函数为",{"2":{"370":1}}],["评估一个假设",{"0":{"1130":1},"2":{"1193":1}}],["评估模型",{"2":{"827":1}}],["评估了所需的统计工具和预测时面临的挑战",{"2":{"360":1}}],["评估输出ot和对应的标签yt之间的差异",{"2":{"307":1}}],["评估给定数据集上模型的损失",{"2":{"263":3}}],["点积表示它们夹角的余弦",{"2":{"997":1}}],["点积表示加权平均",{"2":{"997":1}}],["点积在很多场合都很有用",{"2":{"997":1}}],["点积是相同位置的按元素乘积的和",{"2":{"997":1}}],["点积",{"0":{"997":1}}],["点积的方差在不考虑向量长度的情况下仍然是1",{"2":{"370":1}}],["点对点连接",{"2":{"812":1}}],["点",{"2":{"371":1,"372":2,"397":1,"1143":1}}],["点击查看官方文档",{"2":{"1443":1,"1444":1}}],["点击页面底部的",{"2":{"213":1}}],["点击页面底部虚线框中的",{"2":{"213":1}}],["点击",{"2":{"213":1}}],["演示",{"0":{"933":1}}],["演示上述的dotproductattention类",{"2":{"370":1}}],["演示上面的additiveattention类",{"2":{"369":1}}],["演示此函数是如何工作",{"2":{"368":1}}],["整理",{"2":{"1547":1}}],["整理数据集",{"0":{"890":1,"902":1}}],["整除",{"2":{"1218":1}}],["整型",{"2":{"1216":1}}],["整数类型",{"2":{"1214":1}}],["整合代码",{"0":{"669":1,"677":1,"695":1,"738":1,"777":1},"2":{"743":1}}],["整合所有组件",{"0":{"584":1,"949":1}}],["整合所有功能",{"0":{"364":1}}],["整个样本空间的概率为1",{"2":{"1027":1}}],["整个模型",{"2":{"423":1}}],["整个模型接受原始输入",{"2":{"422":1}}],["整个模型及其组成层都是这种架构",{"2":{"422":1}}],["整个模型只有一个输出",{"2":{"422":1}}],["整个序列的估计值都将通过以下的方式获得",{"2":{"347":1}}],["整个系统优化是获得高性能的关键环节",{"2":{"303":1}}],["整个监督学习过程如",{"2":{"289":1}}],["整个训练数据上的平均损失",{"2":{"190":1}}],["^",{"2":{"1088":1,"1120":7,"1121":9,"1165":5}}],["^2+",{"2":{"1111":1}}],["^2",{"2":{"1000":1,"1090":1,"1111":1}}],["^n",{"2":{"1000":1}}],["^a",{"2":{"361":1}}],["^d",{"2":{"271":1}}],["键值数据库",{"2":{"1376":1}}],["键值对结构",{"2":{"1216":1}}],["键值存储",{"0":{"844":1}}],["键入plot",{"2":{"1091":1}}],["键入pinv",{"2":{"1090":1}}],["键入figure",{"2":{"1091":1}}],["键入sum",{"2":{"1090":2}}],["键入",{"2":{"1090":5}}],["键k∈rdk和",{"2":{"381":1}}],["键k∈rm×d和",{"2":{"370":1}}],["键k∈rk",{"2":{"369":1}}],["键",{"2":{"367":1,"369":12,"370":8,"382":24,"388":1,"391":9,"392":1,"409":2,"757":1,"844":1}}],["键的数目",{"2":{"357":1}}],["键和值都来自上一个解码器层的输出",{"2":{"404":1,"408":1}}],["键和值都来自前一个编码器层的输出",{"2":{"404":1}}],["键和值都来自同一组输入",{"2":{"401":1}}],["键和值都是n×d矩阵",{"2":{"397":1}}],["键和值来自同一组输入",{"2":{"395":1}}],["键和值将并行地送到注意力汇聚中",{"2":{"380":1}}],["键和值的线性变换的输出数量设置为",{"2":{"382":1}}],["键和值的不同的表示子空间来表示不同的注意力",{"2":{"409":1}}],["键和值的不同的子空间表示",{"2":{"383":1}}],["键和值的不同",{"2":{"380":1}}],["键和值的集合时",{"2":{"380":1}}],["键和值的形状为",{"2":{"369":1}}],["键和值是成对的",{"2":{"358":1}}],["键和值",{"0":{"356":1},"2":{"380":1,"395":1}}],["便有可能意味着该服务器是陷入了一些问题中",{"2":{"1183":1}}],["便更新一次参数",{"2":{"1166":1}}],["便能非常显著地降低模型中特征的维度了",{"2":{"1160":1}}],["便可以计算代价函数的偏导数了",{"2":{"1121":2}}],["便可产生具有参数",{"2":{"232":1}}],["便于快速扩容",{"2":{"1354":1}}],["便于之后编写机器学习算法和处理大量数据",{"2":{"1070":1}}],["便于下面的章节调用来评估各种分类算法",{"2":{"584":1}}],["便于给定的查询",{"2":{"356":1}}],["便诞生了",{"2":{"500":1}}],["喝咖啡后",{"2":{"355":1}}],["詹姆斯",{"2":{"355":1}}],["詹森不等式的一个常见应用",{"2":{"42":1}}],["詹森不等式",{"0":{"42":1}}],["找出的当前设备",{"2":{"796":2}}],["找出其他输入词在语义上相似的词",{"2":{"770":1}}],["找寻食物和伴侣",{"2":{"354":1}}],["找到我",{"0":{"1550":1}}],["找到答案",{"2":{"1300":1}}],["找到相关影片",{"2":{"1191":1}}],["找到另一张图像",{"2":{"860":1}}],["找到所有的non",{"2":{"854":3}}],["找到d",{"2":{"751":1}}],["找到最优值b的解析解",{"2":{"621":1}}],["找到了一个优雅的解决方案",{"2":{"300":1}}],["找到一组调优的超参数可能需要时间",{"2":{"212":1}}],["创建失败",{"2":{"1518":1,"1519":1}}],["创建不可变的状态快照",{"2":{"1515":1}}],["创建的状态只在其顶层是响应式的",{"2":{"1513":1}}],["创建并于",{"2":{"1526":1}}],["创建并暴露mitt",{"2":{"1499":1}}],["创建并切换",{"2":{"1329":1}}],["创建emitter",{"2":{"1499":1}}],["创建pinia",{"2":{"1489":1}}],["创建阶段",{"2":{"1470":2}}],["创建命令",{"2":{"1444":1}}],["创建项目",{"2":{"1443":1}}],["创建",{"0":{"1443":1,"1444":1,"1455":1,"1456":1,"1457":1},"2":{"1470":1}}],["创建vue3工程",{"0":{"1442":1},"1":{"1443":1,"1444":1,"1445":1}}],["创建标签",{"2":{"1335":1}}],["创建新分支",{"2":{"1329":1}}],["创建新分支就是新建一个指针指向某个提交",{"2":{"1322":1}}],["创建环境并指定python版本",{"2":{"1277":1}}],["创建虚拟环境",{"2":{"1273":1}}],["创建包含更多行和列的原始数据集",{"2":{"1015":1}}],["创建tokenembedding实例时",{"2":{"748":1}}],["创建多个一维卷积层",{"2":{"702":3}}],["创建数据迭代器",{"0":{"694":1}}],["创建模型",{"0":{"680":1}}],["创建和训练一个循环神经网络",{"2":{"576":1}}],["创建一个自定义的ref",{"2":{"1520":1}}],["创建一个自定义dataset实例",{"2":{"932":1}}],["创建一个浅层响应式对象",{"2":{"1512":1}}],["创建一个响应式数据",{"2":{"1511":1}}],["创建一个行向量",{"2":{"1017":3}}],["创建一个人工数据集",{"2":{"1011":1}}],["创建一个模型实例",{"2":{"959":1}}],["创建一个新的神经网络模型",{"2":{"870":1}}],["创建一个全卷积网络net",{"2":{"862":1}}],["创建一个数据样本y",{"2":{"633":1}}],["创建一个正确的batchnorm层",{"2":{"472":1}}],["创建一个两层的transformer编码器",{"2":{"407":1}}],["创建一个足够长的p",{"2":{"398":4}}],["创建一个类来包装这些函数",{"2":{"332":1}}],["创作一本好书",{"2":{"354":1}}],["全栈",{"2":{"1543":1,"1547":1,"1548":1}}],["全名",{"2":{"1460":1}}],["全球分布式部署",{"2":{"1210":1}}],["全文",{"2":{"1199":1}}],["全1",{"2":{"1017":1}}],["全变分损失",{"0":{"924":1}}],["全变分损失则有助于减少合成图像中的噪点",{"2":{"917":1,"928":1}}],["全部坐着",{"2":{"1061":1}}],["全部下载",{"2":{"901":1}}],["全部的注意力",{"2":{"354":1}}],["全卷积网络先使用卷积神经网络抽取图像特征",{"2":{"862":1,"867":1}}],["全卷积网络将中间层特征图的高和宽变换回输入图像的尺寸",{"2":{"861":1}}],["全卷积网络",{"0":{"861":1},"1":{"862":1,"863":1,"864":1,"865":1,"866":1,"867":1,"868":1},"2":{"861":1,"863":1}}],["全局api转移到应用对象",{"0":{"1524":1}}],["全局块",{"2":{"1365":1}}],["全局配置",{"2":{"1364":1}}],["全局向量的词嵌入",{"0":{"741":1},"1":{"742":1,"743":1,"744":1,"745":1,"746":1}}],["全局平均汇聚层将窗口形状自动设置成输入的高和宽",{"2":{"495":1}}],["全局平均汇聚层避免了在最后使用全连接层",{"2":{"488":1}}],["全连接模块则与alexnet中的相同",{"2":{"508":1}}],["全连接层转换为imagenet数据集的1000个类输出",{"2":{"873":1}}],["全连接层是",{"2":{"642":1}}],["全连接层无处不在",{"2":{"642":1}}],["全连接层的参数开销",{"0":{"642":1}}],["全连接层的输入和输出通常是分别对应于样本和特征的二维张量",{"2":{"494":1}}],["全连接层的输出数量是lenet中的好几倍",{"2":{"461":4}}],["全连接层的输出是当前时间步t的隐状态ht",{"2":{"340":1}}],["全连接层在linear类中定义",{"2":{"591":2}}],["全连接层在dense类中定义",{"2":{"591":2}}],["全连接层部分",{"2":{"508":4}}],["全连接层",{"0":{"469":1},"2":{"490":1}}],["全连接层和卷积层",{"2":{"468":1}}],["全连接层变换后",{"2":{"375":4}}],["全连接层首先将y的形状改为",{"2":{"325":3}}],["全连接层密集块",{"2":{"136":1}}],["全连接层中的矩阵乘法",{"2":{"122":1}}],["全秩协方差估计可以么",{"2":{"477":1}}],["感觉应该更快",{"2":{"1544":1}}],["感觉自己像魔术师一样瞬间变出东西",{"2":{"1535":1}}],["感兴趣",{"2":{"1191":1}}],["感知器",{"2":{"1141":1}}],["感知机包含一个隐藏层",{"2":{"369":1}}],["感悟",{"2":{"1122":1}}],["感官输入",{"2":{"356":1,"358":1,"385":1}}],["感谢读者对本书的关注",{"2":{"354":1}}],["感受野可能大于输入的实际大小",{"2":{"131":1}}],["内部其实也是调用了reactive函数",{"2":{"1457":1}}],["内部协变量偏移没有更值得批评",{"2":{"475":1}}],["内部协变量偏移的解释反复出现在技术文献的辩论",{"2":{"475":1}}],["内部协变量转移",{"2":{"475":1}}],["内置服务",{"2":{"1530":1}}],["内置在",{"2":{"1348":1}}],["内置工具众多",{"2":{"1302":1}}],["内置初始化",{"0":{"435":1}}],["内层的列表对应于轴1",{"2":{"1017":1}}],["内接多边形的等长边越多",{"2":{"980":1}}],["内含目标类别标签和位于左上角和右下角的真实边界框坐标",{"2":{"932":1}}],["内容001`",{"2":{"1482":1}}],["内容生成等多个领域的效率跃升",{"2":{"1051":1}}],["内容损失通过平方误差函数衡量合成图像与内容图像在内容特征上的差异",{"2":{"922":1}}],["内容损失",{"0":{"922":1}}],["内容损失使合成图像与内容图像在内容特征上接近",{"2":{"917":1,"928":1}}],["内容通常分为数据和指令",{"2":{"810":1}}],["内核由以下bilinear",{"2":{"863":1}}],["内核之间的缓存逻辑",{"2":{"457":1}}],["内轨和外轨有区别吗",{"2":{"815":1}}],["内的每对连续字符之间插入空格",{"2":{"757":1}}],["内",{"2":{"556":1}}],["内插法",{"2":{"352":1}}],["内存减少54",{"2":{"1438":1}}],["内存分配",{"2":{"1201":1}}],["内存使用情况",{"2":{"1178":1}}],["内存节省和转换其他python对象",{"2":{"1023":1}}],["内存占用和带宽",{"2":{"814":1}}],["内存占用是多少",{"2":{"124":1}}],["内存位置缓存在处理器0上",{"2":{"810":1}}],["内存直接连接到cpu",{"2":{"801":1}}],["内存接口",{"2":{"457":1}}],["内存接口通常为64位或更宽",{"2":{"77":1}}],["内存",{"0":{"802":1},"2":{"300":1,"801":1}}],["精简输出精度",{"2":{"847":3}}],["精度等",{"2":{"1156":1}}],["精度等于正确预测数与预测总数之间的比率",{"2":{"653":1}}],["精度就会迅速下降",{"2":{"351":1}}],["精神疾病的诊断标准",{"2":{"183":1}}],["了的路由组件",{"2":{"1475":1}}],["了",{"2":{"350":1,"1501":1}}],["了解一些天文学上的细节问题",{"2":{"1150":1}}],["了解一下你可以用哪些命令",{"2":{"1089":1}}],["了解设备的局限性是值得的",{"2":{"811":1}}],["了解gpu和其他加速卡",{"2":{"811":1}}],["了解异步编程是如何工作的",{"2":{"789":1}}],["了解更细致的工作原理将方便我们自定义模型",{"2":{"598":1}}],["了解有关如何重新缩放并计算适当项目",{"2":{"78":1}}],["了解不同优化算法的原则及其超参数的作用将使我们能够以有针对性的方式调整超参数",{"2":{"65":1}}],["准备一个效果",{"0":{"1488":1}}],["准备",{"2":{"350":1}}],["准确地告诉模型在每种情况下应该做什么",{"2":{"296":1}}],["准确解决优化问题就会很难",{"2":{"26":1}}],["彼得斯等人",{"2":{"349":1}}],["倒序展开也没什么问题",{"2":{"349":1}}],["τ时如此",{"2":{"347":1}}],["展望",{"0":{"1357":1}}],["展示区",{"2":{"1474":1}}],["展示了使用全连接层来实现可学习的线性变换的多头注意力",{"2":{"380":1}}],["展示如何在不使用gt",{"2":{"23":1}}],["展开参数",{"0":{"1123":1},"2":{"1193":1}}],["展开",{"2":{"347":1}}],["交互效果",{"2":{"1533":1}}],["交互式修改提交历史",{"2":{"1334":1}}],["交给模型进行判断",{"2":{"1172":1}}],["交给算法大量的数据",{"2":{"1061":1}}],["交叉类型包含所有属性",{"2":{"1408":1}}],["交叉类型",{"0":{"1408":1}}],["交叉验证集和测试集",{"2":{"1133":1,"1135":1,"1176":1}}],["交叉验证集误差远大于训练集误差时",{"2":{"1132":1}}],["交叉熵是一个衡量两个概率分布之间差异的很好的度量",{"2":{"654":1}}],["交叉熵达到最低",{"2":{"652":1}}],["交叉熵从p到q",{"2":{"652":1}}],["交叉熵损失为−log⁡pj",{"2":{"966":1}}],["交叉熵损失函数",{"2":{"834":3}}],["交叉熵损失可能不是衡量两种概率分布差异的好选择",{"2":{"745":1}}],["交叉熵损失",{"0":{"648":1}}],["交叉熵",{"2":{"635":1}}],["交叉熵采用真实标签的预测概率的负对数似然",{"2":{"633":1}}],["交并比的取值范围在0和1之间",{"2":{"849":1}}],["交并比",{"0":{"849":1},"2":{"855":1}}],["交换机并不是传统计算机网络所独有的",{"2":{"812":1}}],["交换机",{"2":{"812":1}}],["交易员可以使用回归模型",{"2":{"347":1}}],["交通摄像头的镜头会逐渐退化",{"2":{"193":1}}],["富时100指数",{"2":{"346":1}}],["远程仓库操作",{"0":{"1330":1}}],["远程仓库",{"0":{"1324":1},"2":{"1319":2,"1340":1}}],["远程",{"2":{"1309":1}}],["远程服务",{"2":{"1042":1}}],["远没有",{"2":{"345":1}}],["远远不可能记住每一个可能的输入所对应的答案",{"2":{"252":1}}],["先理解几个关键概念",{"2":{"1360":1}}],["先给你举一个样本",{"2":{"1143":1}}],["先别过多的考虑左边直线部分的斜率",{"2":{"1143":1}}],["先忽略",{"2":{"1143":1}}],["先看这样一些例子",{"2":{"1112":1}}],["先用",{"2":{"1092":1}}],["先读取数据",{"2":{"637":1}}],["先从所有ok中减去max",{"2":{"624":1}}],["先使用最简单的估计器来解决回归问题",{"2":{"387":1}}],["先见之明比事后诸葛亮难得多",{"2":{"345":1}}],["先遍历",{"2":{"120":2}}],["电商平台前端",{"2":{"1529":1}}],["电源故障",{"2":{"1034":1}}],["电子邮件",{"2":{"754":1}}],["电影",{"2":{"1188":1,"1191":1}}],["电影评分决不是固定不变的",{"2":{"345":1}}],["电影会由于导演或演员在制作中的不当行为变得不受欢迎",{"2":{"345":1}}],["电阻中电流和电压的欧姆定律可以用线性模型完美地描述",{"2":{"299":1}}],["季节性",{"2":{"345":1}}],["享乐适应",{"2":{"345":1}}],["受保护的",{"2":{"1425":1}}],["受",{"2":{"404":1}}],["受此框架中的注意力提示",{"2":{"379":1}}],["受学习对齐想法的启发",{"2":{"373":1}}],["受试者使用非自主性和自主性提示有选择性地引导注意力",{"2":{"358":1}}],["受试者的主观意愿推动",{"2":{"355":1}}],["受试者基于非自主性提示和自主性提示",{"2":{"355":1}}],["受到关注的电影的评分会上升",{"2":{"345":1}}],["受策略控制",{"2":{"298":1}}],["心里给你留了一块地",{"2":{"1490":1}}],["心理学家甚至对这些现象起了名字",{"2":{"345":1}}],["心脏病没有发作",{"2":{"289":1}}],["心脏病发作",{"2":{"289":1}}],["信息量",{"0":{"651":1}}],["信息论的基本定理之一指出",{"2":{"650":1}}],["信息论的核心思想是量化数据中的信息内容",{"2":{"650":1}}],["信息论",{"2":{"649":1}}],["信息论基础",{"0":{"649":1},"1":{"650":1,"651":1,"652":1}}],["信息论可以派上用场了",{"2":{"342":1}}],["信号处理学家将是否知道未来观测这两种情况区分为内插和外推",{"2":{"519":1}}],["信誉度的自动评估",{"2":{"301":1}}],["战争与和平",{"2":{"342":1}}],["冬天下雨了",{"2":{"342":1}}],["旧风格的c语言语法",{"2":{"1088":1}}],["旧金山下雨了",{"2":{"342":1}}],["旧产品变得不那么受欢迎了",{"2":{"193":1}}],["例",{"2":{"1073":1,"1077":1,"1139":2,"1140":2}}],["例3表明了训练不足的模型是无法正确地拟合数据的",{"2":{"342":1}}],["例2则要糟糕得多",{"2":{"342":1}}],["例1显然是最合乎情理",{"2":{"342":1}}],["例如改成abc",{"2":{"1500":2}}],["例如翻墙代理",{"2":{"1361":1}}],["例如说",{"2":{"1191":1}}],["例如使用mockjs时",{"2":{"1519":1}}],["例如使用对数函数",{"2":{"1183":1}}],["例如使用采样",{"2":{"337":1}}],["例如飞机引擎",{"2":{"1182":1}}],["例如令",{"2":{"1146":1,"1167":1}}],["例如记录下错误拼写出现了多少次",{"2":{"1138":1}}],["例如医药品垃圾邮件",{"2":{"1138":1}}],["例如神经网络",{"2":{"1124":1}}],["例如正确或错误",{"2":{"1106":1}}],["例如识别一张图片上是否是一辆汽车",{"2":{"1097":1}}],["例如大于100个变量",{"2":{"1097":1}}],["例如房间数楼层等",{"2":{"1080":1}}],["例如房屋的面积",{"2":{"290":1}}],["例如位置",{"2":{"1029":1}}],["例如三维张量",{"2":{"1024":1}}],["例如y",{"2":{"1021":1}}],["例如xijk和",{"2":{"993":1}}],["例如x",{"2":{"989":1}}],["例如卷积层",{"2":{"967":1}}],["例如单发多框检测论文",{"2":{"966":1}}],["例如单词或字符",{"2":{"315":1}}],["例如pca",{"2":{"1114":1}}],["例如pj",{"2":{"966":1}}],["例如print语句",{"2":{"821":1}}],["例如预测边界框和类别的概率",{"2":{"942":1}}],["例如预测每个词元与预测整个序列",{"2":{"733":1}}],["例如2000个",{"2":{"937":1}}],["例如随机裁剪",{"2":{"935":1}}],["例如将已有的字符图片进行一些扭曲",{"2":{"1173":1}}],["例如将1000维的特征降至100维",{"2":{"1156":1}}],["例如将代价函数的变化值与某个阀值",{"2":{"1083":1}}],["例如将其初始化为内容图像",{"2":{"917":1}}],["例如将权重层中的参数近似为零",{"2":{"504":1}}],["例如堆叠两个完全连接的图层",{"2":{"905":1}}],["例如目标检测",{"2":{"886":1}}],["例如imagenet数据集",{"2":{"870":1}}],["例如c++",{"2":{"821":1}}],["例如cpu或gpu",{"2":{"452":1}}],["例如计算机和交换机",{"2":{"812":1}}],["例如a",{"2":{"1028":1,"1038":1}}],["例如a2",{"2":{"992":1}}],["例如asnumpy",{"2":{"821":1}}],["例如amd的zen",{"2":{"802":1}}],["例如arste",{"2":{"800":1}}],["例如包括掩码变量",{"2":{"776":1}}],["例如3到6",{"2":{"757":1}}],["例如300维的glove嵌入",{"2":{"717":1}}],["例如facebook",{"2":{"1150":1}}],["例如fasttext中的首行",{"2":{"748":1}}],["例如f",{"2":{"744":1}}],["例如0",{"2":{"744":2,"1083":1}}],["例如wk=fashion",{"2":{"744":1}}],["例如wk=water",{"2":{"744":1}}],["例如wk=gas",{"2":{"744":1}}],["例如wk=solid",{"2":{"744":1}}],["例如8",{"2":{"744":1}}],["例如α=0",{"2":{"743":1}}],["例如glove",{"2":{"731":1}}],["例如gpu",{"2":{"137":1,"502":1}}],["例如一组情感极性中",{"2":{"664":1}}],["例如词性标签",{"2":{"659":1}}],["例如输出连续的标签值和使用均方损失",{"2":{"658":1}}],["例如输出的高和宽仅为输入的高和宽的1",{"2":{"143":1}}],["例如基于循环神经网络",{"2":{"656":1}}],["例如基于n个查询和m个键",{"2":{"370":1}}],["例如我们希望用算法来预测癌症是否是恶性的",{"2":{"1139":1}}],["例如我们要实现xnor",{"2":{"1102":1}}],["例如我们上面实现的",{"2":{"635":1}}],["例如我们之前讨论的案例",{"2":{"26":1}}],["例如批量大小",{"2":{"628":1}}],["例如肌肉",{"2":{"619":1}}],["例如空格",{"2":{"571":1}}],["例如中文和日语",{"2":{"571":1}}],["例如中间特征表示",{"2":{"356":1}}],["例如门控循环单元",{"2":{"561":1}}],["例如更深的含152层的resnet",{"2":{"502":1}}],["例如权重和偏置",{"2":{"500":1}}],["例如权重衰减和dropout",{"2":{"266":1}}],["例如线性模型或其它核方法",{"2":{"454":1}}],["例如居中",{"2":{"454":1}}],["例如n在1",{"2":{"1148":1}}],["例如n在",{"2":{"1148":1}}],["例如n元语法",{"2":{"698":1,"705":1}}],["例如net1和net2",{"2":{"428":1}}],["例如n个时间步",{"2":{"319":1}}],["例如模型参数`params`",{"2":{"423":1}}],["例如模型参数params",{"2":{"423":3}}],["例如用零填充被掩蔽住的注意力权重",{"2":{"409":1}}],["例如用于固定维度表示中的机器翻译",{"2":{"300":1}}],["例如语言",{"2":{"379":1,"403":1}}],["例如猎物和天敌",{"2":{"379":1}}],["例如可以用方阵的乘法来表示旋转",{"2":{"998":1}}],["例如可以通过xi来引用第i个元素",{"2":{"990":1}}],["例如可以使用aws",{"2":{"445":1}}],["例如可以设计一个不可微的注意力模型",{"2":{"356":1}}],["例如可能导致梯度爆炸或梯度消失",{"2":{"334":1}}],["例如发现天敌",{"2":{"354":1}}],["例如世界大战",{"2":{"337":1}}],["例如θ",{"2":{"334":1,"1099":1}}],["例如长",{"2":{"325":1}}],["例如整本",{"2":{"319":1}}],["例如通过python",{"2":{"790":3}}],["例如通过使用周围文本的其它部分来预测文本的隐藏部分",{"2":{"754":1}}],["例如通过将elmo的表示和现有模型中词元的原始表示",{"2":{"731":1}}],["例如通过连结初始和最终时间步的隐状态",{"2":{"716":1}}],["例如通过",{"2":{"316":1}}],["例如存储∂l",{"2":{"312":1}}],["例如从原始音频信号中学习",{"2":{"302":1}}],["例如每批32个图像的小批量大小相当于总计约32000个图像的小批量",{"2":{"300":1}}],["例如机器翻译和从语音中转录文本",{"2":{"295":1}}],["例如∥w∥2",{"2":{"270":1}}],["例如h",{"2":{"232":1}}],["例如测试时的分布",{"2":{"192":1}}],["例如训练时的分布",{"2":{"192":1}}],["例如训练imagenet数据集",{"2":{"75":1}}],["例如128",{"2":{"890":1}}],["例如1",{"2":{"141":1,"744":1}}],["例如10−5这样的小值",{"2":{"20":1}}],["例如毛衣和外套",{"2":{"139":1}}],["例如音频",{"2":{"134":1}}],["例如彩色图像具有标准的rgb通道来代表红",{"2":{"119":1}}],["例如λi=2−i",{"2":{"97":1}}],["例如具有动量的梯度",{"2":{"86":1}}],["例如s=",{"2":{"71":1}}],["例如设学习率为0",{"2":{"67":1}}],["例如在线采集而来的有关用户的数据",{"2":{"1178":1}}],["例如在之前的视频中",{"2":{"1091":1}}],["例如在训练中",{"2":{"891":1}}],["例如在分类精度和计算效率方面",{"2":{"706":1}}],["例如在snli数据集上进行自然语言推断",{"2":{"689":1}}],["例如在有10个类别情况下的精度为0",{"2":{"634":1}}],["例如在计算损失时",{"2":{"579":1}}],["例如在小批量时用于将序列填充到相同长度的填充词元",{"2":{"567":1}}],["例如在语音识别中将音频转换为文本",{"2":{"302":1}}],["例如在fashion",{"2":{"111":1}}],["例如在",{"2":{"50":1,"246":1,"309":1,"347":1}}],["例如第一个约束c1",{"2":{"47":1}}],["例如球的半径定义为且",{"2":{"40":1}}],["例如",{"2":{"25":1,"31":1,"40":1,"42":2,"44":2,"46":1,"48":1,"49":1,"53":1,"54":1,"55":2,"66":1,"68":1,"77":3,"86":2,"99":1,"101":1,"103":1,"114":2,"115":1,"119":1,"139":1,"140":1,"141":1,"145":3,"151":1,"156":1,"158":1,"169":1,"170":1,"182":2,"187":1,"191":1,"193":1,"195":1,"196":1,"197":1,"198":2,"199":1,"200":2,"201":2,"208":2,"209":1,"210":1,"215":1,"222":1,"230":4,"232":1,"233":1,"244":1,"247":1,"248":1,"251":1,"252":2,"254":2,"255":1,"269":1,"278":1,"282":1,"289":3,"290":2,"291":5,"292":1,"294":4,"295":3,"296":2,"297":3,"298":2,"299":3,"300":3,"301":2,"302":2,"305":2,"306":2,"312":1,"315":3,"316":3,"318":1,"325":1,"332":1,"333":1,"334":1,"335":1,"336":1,"337":1,"345":3,"348":1,"349":1,"351":1,"360":1,"363":1,"368":1,"380":1,"388":4,"389":1,"392":4,"397":1,"412":1,"422":1,"423":2,"425":2,"432":1,"435":1,"442":1,"445":6,"447":1,"448":1,"449":1,"456":1,"457":1,"467":1,"471":1,"492":1,"497":1,"500":1,"514":2,"515":1,"518":3,"522":3,"525":1,"526":1,"534":2,"538":2,"539":1,"542":1,"549":1,"550":1,"561":1,"565":1,"572":1,"575":1,"578":1,"591":2,"600":1,"638":1,"643":2,"646":2,"657":1,"658":1,"659":1,"660":1,"661":3,"662":1,"663":1,"665":1,"675":1,"684":1,"691":1,"699":3,"709":1,"717":1,"731":3,"734":1,"736":4,"741":1,"743":2,"751":1,"754":2,"756":1,"757":3,"759":1,"773":1,"775":1,"785":1,"788":1,"795":4,"797":4,"800":1,"801":2,"802":1,"806":1,"807":1,"808":2,"809":2,"810":2,"811":4,"812":2,"814":3,"817":1,"818":1,"824":1,"830":2,"832":2,"833":2,"836":1,"840":1,"841":2,"842":1,"844":2,"851":1,"854":1,"857":2,"863":1,"869":2,"877":1,"883":1,"895":1,"907":1,"912":1,"913":2,"916":1,"927":1,"938":1,"944":1,"945":1,"946":1,"966":1,"967":1,"968":1,"969":1,"976":1,"977":1,"981":1,"989":2,"990":2,"992":4,"993":2,"994":2,"995":1,"996":1,"997":1,"1002":1,"1006":1,"1007":2,"1017":5,"1020":1,"1021":1,"1025":1,"1027":2,"1028":1,"1035":1,"1058":1,"1063":1,"1085":1,"1086":2,"1088":3,"1099":1,"1103":1,"1107":1,"1137":1,"1138":1,"1141":1,"1143":1,"1146":2,"1154":1,"1168":1,"1169":1,"1176":1,"1181":1,"1182":2,"1183":1,"1189":1,"1207":1,"1215":1,"1340":1}}],["香蕉检测数据集中",{"2":{"961":1}}],["香蕉检测数据集",{"2":{"961":1}}],["香蕉树下雨了",{"2":{"342":1}}],["香农决定用信息量log⁡1p",{"2":{"651":1}}],["香农",{"2":{"299":1}}],["轴上的截距",{"2":{"1064":1}}],["轴",{"2":{"993":1,"1018":2}}],["轴坐标值",{"2":{"912":1}}],["轴坐标以及框的宽度和高度",{"2":{"858":1}}],["轴坐标",{"2":{"848":1,"853":1,"854":1}}],["轴坐标和右下角的",{"2":{"848":1}}],["轴突",{"2":{"619":1,"1099":1}}],["轴0",{"2":{"340":1,"631":1,"995":1}}],["轴1",{"2":{"340":1,"631":1,"995":1}}],["拼接在一起作为解码器的输入",{"2":{"576":1}}],["拼接矩阵w",{"2":{"340":1}}],["拼接矩阵x和h",{"2":{"340":1}}],["拼接当前时间步t的输入xt和前一时间步t−1的隐状态ht−1",{"2":{"340":1}}],["讨论一种新的大规模的机器学习机制",{"2":{"1168":1}}],["讨论一下机器学习系统设计中另一个重要的方面",{"2":{"1141":1}}],["讨论逆矩阵和转置矩阵的概念",{"2":{"1070":1}}],["讨论区",{"2":{"942":3}}],["讨论过的具有隐藏单元的隐藏层",{"2":{"338":1}}],["讨论线性模型的单项式函数时探讨了这一点",{"2":{"170":1}}],["秒级",{"2":{"1346":1}}],["秒级启动",{"2":{"1339":1,"1353":1}}],["秒",{"2":{"335":4,"828":3,"837":3}}],["困惑度和输出字符串的影响",{"2":{"549":1}}],["困惑度和输出顺序的影响",{"2":{"549":1,"563":1}}],["困惑度等于词表中唯一词元的数量",{"2":{"342":1}}],["困惑度是正无穷大",{"2":{"342":1}}],["困惑度的最好的理解是",{"2":{"342":1}}],["困惑度呢",{"2":{"337":1}}],["困惑度可以降到多少",{"2":{"337":1}}],["困惑度",{"0":{"342":1},"2":{"335":4}}],["困难在于",{"2":{"251":1}}],["裁剪输入图像和标签的相同区域",{"2":{"946":1}}],["裁剪梯度",{"2":{"334":4}}],["裁切和变色",{"2":{"461":1}}],["裁缝们已经开发出了一小部分参数",{"2":{"296":1}}],["尤其在不同语义的分割区域",{"2":{"946":1}}],["尤其当我们朝着错误的方向前进时",{"2":{"334":1}}],["尤其是在这样一个体系中",{"2":{"1148":1}}],["尤其是在空间维度被卷积神经网络层缩小后",{"2":{"967":1}}],["尤其是当你使用大间距分类器的时候",{"2":{"1144":1}}],["尤其是当标签词元保持不变时",{"2":{"736":1}}],["尤其是知道如何使用这些机器学习算法的",{"2":{"1059":1}}],["尤其是针对实验中常见的某些类型的优化问题",{"2":{"85":1}}],["尤其是",{"2":{"32":1}}],["期望和方差为概率分布的关键特征的概括提供了实用的度量形式",{"2":{"1037":1}}],["期望和方差",{"0":{"1036":1}}],["期",{"2":{"333":1}}],["形成一致性快照",{"2":{"1202":1}}],["形成一个n×m矩阵",{"2":{"999":1}}],["形函数的导数",{"2":{"1121":1}}],["形函数图像",{"2":{"1108":1}}],["形态学研究单词形成和词汇关系",{"2":{"755":1}}],["形容词最高级",{"2":{"751":1}}],["形容词",{"2":{"659":1,"751":1}}],["形容词和限定词",{"2":{"659":1}}],["形状的第二个元素",{"2":{"1018":1}}],["形状的第一个元素",{"2":{"1018":1}}],["形状只有一个元素",{"2":{"991":1}}],["形状",{"2":{"991":1}}],["形状和对象组合",{"2":{"869":1}}],["形状固定的上下文变量c",{"2":{"573":1}}],["形状为n×c×h2×w2",{"2":{"938":1}}],["形状为a×c",{"2":{"390":1}}],["形状为a×b",{"2":{"390":1}}],["形状为b×c",{"2":{"390":1}}],["形状为",{"2":{"332":1,"559":1,"853":1}}],["形式",{"2":{"399":1}}],["形式化这个证明过程",{"2":{"314":1}}],["形式上",{"2":{"232":1,"731":1}}],["附加梯度",{"2":{"331":3,"544":3,"558":4}}],["附近的像素",{"2":{"154":1}}],["索引存取",{"2":{"1204":1}}],["索引和聚合管道",{"2":{"1195":1}}],["索引和切片",{"0":{"1020":1}}],["索引从0开始",{"2":{"853":1}}],["索引0是词表中排除的未知标记",{"2":{"775":1}}],["索引为0",{"2":{"932":3}}],["索引为0和2的独热向量如下所示",{"2":{"330":1}}],["索引为1",{"2":{"775":1}}],["索引为2",{"2":{"634":2}}],["索引",{"2":{"363":1,"781":1,"1023":1,"1092":1}}],["索引a和b通过在正偏移和负偏移之间移动覆盖了整个图像",{"2":{"153":1}}],["短靴",{"2":{"582":1}}],["短距离依赖和长距离依赖关系",{"2":{"380":1}}],["短期记忆",{"2":{"325":1}}],["短期记忆网络",{"2":{"325":1}}],["短语标记",{"2":{"717":1}}],["短语",{"2":{"315":1}}],["列表推导式",{"0":{"1242":1}}],["列表",{"0":{"1241":1},"1":{"1242":1,"1243":1},"2":{"1216":1,"1232":1}}],["列表中的每个元素是一个文本序列",{"2":{"362":1}}],["列表中包含了初始隐状态用于小批量数据中的每个样本",{"2":{"325":1}}],["列的向量",{"2":{"1088":1}}],["列的元素是",{"2":{"1077":1}}],["列元素出发的右下方",{"2":{"1077":1}}],["列",{"2":{"1020":1,"1077":1,"1088":1}}],["列只接受两种类型的类别值",{"2":{"1012":1}}],["列出了张量沿每个轴的长度",{"2":{"991":1}}],["列出了给定单词",{"2":{"744":1}}],["列对应属性",{"2":{"987":1}}],["列对应特征",{"2":{"151":1}}],["列举rgb颜色值和类名",{"2":{"945":1}}],["列名",{"2":{"890":1,"1011":1}}],["列数等于每个标记的向量维数",{"2":{"762":1}}],["列代表位置编码的不同维度",{"2":{"398":1}}],["列i",{"2":{"351":6}}],["齐普夫定律支配着单词的分布",{"2":{"322":1}}],["顺便提一句θ0=0的简化仅仅意味着决策界必须通过原点",{"2":{"1145":1}}],["顺便一提的是",{"2":{"1112":1}}],["顺便说一下",{"2":{"1106":1}}],["顺便说一句",{"2":{"237":1,"1090":1,"1145":1}}],["顺便我要提醒一下",{"2":{"1093":1}}],["顺序块",{"0":{"424":1}}],["顺序操作会妨碍并行计算",{"2":{"397":1}}],["顺序操作和最大路径长度",{"2":{"397":1}}],["顺序分区",{"0":{"321":1},"2":{"319":1}}],["词典中的索引o",{"2":{"783":1}}],["词典中的索引c",{"2":{"783":1}}],["词典大小",{"2":{"781":1}}],["词典token",{"2":{"757":1}}],["词向量是用于表示单词意义的向量",{"2":{"780":1,"787":1}}],["词向量维度",{"2":{"713":3}}],["词是意义的基本单元",{"2":{"780":1}}],["词嵌入逐渐成为自然语言处理的基础知识",{"2":{"780":1}}],["词嵌入",{"0":{"780":1},"1":{"781":1,"782":1,"783":1,"784":1,"785":1,"786":1,"787":1,"788":1}}],["词嵌入的应用包括基于词向量的余弦相似度为给定词找到语义相似的词",{"2":{"769":1}}],["词wi才能被丢弃",{"2":{"773":1}}],["词wj也出现在词wi的上下文窗口",{"2":{"743":1}}],["词",{"2":{"762":1}}],["词类比任务可以定义为",{"2":{"751":1}}],["词类比",{"0":{"751":1}}],["词相似度",{"0":{"750":1}}],["词的相似性和类比任务",{"0":{"747":1},"1":{"748":1,"749":1,"750":1,"751":1,"752":1,"753":1}}],["词的表示依赖于它们的上下文",{"2":{"739":1}}],["词共现概率的比率来解释",{"2":{"745":1}}],["词共现概率及其比值",{"2":{"744":1}}],["词共现计数的全局语料库统计可以来解释跳元模型",{"2":{"745":1}}],["词量会有多大",{"2":{"724":1}}],["词性标记",{"2":{"661":1}}],["词性标注为每个单词分配词性标记",{"2":{"659":1}}],["词元替换",{"2":{"772":1}}],["词元x的上下文敏感表示是函数f",{"2":{"731":1}}],["词元附加到输入",{"2":{"722":1}}],["词元或随机词元替换",{"2":{"721":1}}],["词元和2个",{"2":{"720":1}}],["词元向量维度",{"2":{"702":3}}],["词元保留位置",{"2":{"687":3}}],["词元的标签",{"2":{"576":1}}],["词元的类型是字符串",{"2":{"363":1}}],["词元说明完成了序列输出工作",{"2":{"568":1}}],["词元添加到所有序列的末尾",{"2":{"568":1}}],["词元注释",{"2":{"522":1}}],["词元都对解码某个词元都有用",{"2":{"373":1}}],["词元索引列表",{"2":{"364":1}}],["词元索引的范围为0到n−1",{"2":{"330":1}}],["词元化是一个关键的预处理步骤",{"2":{"366":1}}],["词元化",{"0":{"362":1,"566":1},"2":{"566":1}}],["词元",{"2":{"335":4,"362":1,"567":1,"568":1,"688":1,"720":1,"721":1,"727":3,"736":1,"737":1,"748":1,"772":1}}],["词元数量",{"2":{"335":4,"576":4,"702":3}}],["词表是所有词的子词的集合",{"2":{"756":1}}],["词表包含400000个词",{"2":{"748":1}}],["词表示的发展",{"2":{"731":1}}],["词表",{"0":{"363":1,"567":1}}],["词表大小将明显大于使用字符级词元化时的词表大小",{"2":{"567":1}}],["词表大小",{"2":{"325":3,"330":1,"332":9,"574":1}}],["词表中n元组的数量并没有那么大",{"2":{"318":1}}],["词频以一种明确的方式迅速衰减",{"2":{"318":1}}],["指针",{"0":{"1323":1}}],["指针连接历史",{"2":{"1321":1}}],["指向的javascript",{"2":{"1444":1}}],["指向",{"2":{"1323":1}}],["指向前一次",{"2":{"1321":1}}],["指向一个",{"2":{"1320":1}}],["指向若干",{"2":{"1320":1}}],["指向另一个位置",{"2":{"1021":1}}],["指出如何设定新的特征变量和找出其他能决定你学习算法的变量等方面",{"2":{"1148":1}}],["指引着可以改进算法的最有效的方法和途径",{"2":{"1132":1}}],["指代数对象",{"2":{"993":1,"994":1}}],["指标包括",{"2":{"963":1}}],["指令在组件上的使用已经被重新设计",{"2":{"1525":1}}],["指令在另一个浏览器窗口中显示文档",{"2":{"1007":1}}],["指令几乎相同的内容",{"2":{"1007":1}}],["指令将创建与help",{"2":{"1007":1}}],["指令",{"2":{"810":1}}],["指数可能会造成数值稳定性问题",{"2":{"624":1}}],["指数的大小受序列长度的影响",{"2":{"318":1}}],["指定执行顺序",{"2":{"1310":1}}],["指定这些点的位置后他们被投射到这一个三维曲面",{"2":{"1161":1}}],["指定axis=1将通过汇总所有列的元素降维",{"2":{"995":1}}],["指定张量沿哪一个轴来通过求和降低维度",{"2":{"995":1}}],["指定每个区域输出的高和宽分别为h2和w2",{"2":{"938":1}}],["指定上面定义的所有图像增广操作",{"2":{"892":1}}],["指定随机裁剪的输出图像的形状为320×480",{"2":{"864":1}}],["指定损失函数和如何训练模型",{"2":{"587":1}}],["指定input的第一个维度为time",{"2":{"573":1}}],["指定transformer的编码器和解码器都是2层",{"2":{"409":1}}],["指的是在梯度下降的每一步中",{"2":{"1069":1}}],["指的是计算神经网络参数梯度的方法",{"2":{"164":1}}],["指的是",{"2":{"162":1,"518":1,"564":1}}],["稍微靠左的区段",{"2":{"1127":1}}],["稍加修改进行使用",{"2":{"1059":1}}],["稍加修改的",{"2":{"834":1}}],["稍加修改的resnet",{"2":{"826":3}}],["稍稍不太精确的",{"2":{"316":1}}],["稍后我们将使用这些运算操作来实现我们的学习算法",{"2":{"1090":1}}],["稍后我们将看到",{"2":{"1086":1}}],["稍后我们将给出的更正式定义",{"2":{"1026":1}}],["稍后我们将讨论如何选择学习算法",{"2":{"1060":1}}],["稍后我们将讨论基于这个策略引入的张量核",{"2":{"811":1}}],["稍后我们将讨论更高级的策略",{"2":{"114":1}}],["稍后讨论",{"2":{"577":3,"883":1}}],["稍后将介绍",{"2":{"423":4}}],["稍后将用他们来实现更复杂的注意力机制",{"2":{"367":1}}],["稍后将详细介绍",{"2":{"235":1}}],["稍后",{"2":{"126":1,"312":1}}],["奶奶",{"2":{"315":1}}],["出错了",{"2":{"1250":1}}],["出现了太多没见过的不同的异常类型",{"2":{"1182":1}}],["出现为1",{"2":{"1137":1}}],["出现的情况要么是欠拟合",{"2":{"1132":1}}],["出现的频率要高得多",{"2":{"315":1}}],["出现不可逆的问题不应该过多的关注xtx是不可逆的",{"2":{"1086":1}}],["出现不可逆矩阵的情况极少发生",{"2":{"1086":1}}],["出现次数",{"2":{"757":1}}],["出现次数少于5次的不频繁词元将被过滤掉",{"2":{"722":1}}],["出名",{"2":{"665":1}}],["出于人类这种基本需要",{"2":{"754":1}}],["出于对深度学习强烈的兴趣",{"2":{"588":1}}],["出于训练目的",{"2":{"300":1}}],["出于记号习惯的考量",{"2":{"232":1}}],["隐去了权重和偏置的值",{"2":{"618":1}}],["隐马尔可夫模型中的动态规划",{"0":{"519":1}}],["隐马尔可夫模型中的动态规划超出了本节的范围",{"2":{"348":1}}],["隐单元数或特征维度",{"2":{"405":1}}],["隐变量模型存在着长期信息保存和短期输入缺失的问题",{"2":{"551":1}}],["隐变量模型不是近似值",{"2":{"338":1}}],["隐变量和观测值与具体的函数形式的交互方式是相当随意的",{"2":{"526":1}}],["隐变量自回归模型",{"2":{"347":1}}],["隐状态st",{"2":{"574":1}}],["隐状态",{"0":{"542":1,"556":1},"2":{"562":1}}],["隐状态中",{"2":{"340":1}}],["隐状态使用的定义与前一个时间步中使用的定义相同",{"2":{"340":1}}],["隐状态的信息被传递到当前层的下一时间步和下一层的当前时间步",{"2":{"530":1}}],["隐状态的计算可以被视为",{"2":{"340":1}}],["隐状态的值通常比刚开始的初始值更适合预测",{"2":{"333":1}}],["隐状态的维数是否保持不变",{"2":{"332":1}}],["隐状态的梯度",{"2":{"312":1}}],["隐藏大小",{"2":{"726":1}}],["隐藏",{"2":{"691":1}}],["隐藏单元的数量",{"2":{"573":1}}],["隐藏单元的数量仍然是256",{"2":{"528":1}}],["隐藏单元个数",{"2":{"545":1}}],["隐藏单元个数h",{"2":{"540":1}}],["隐藏单元数num",{"2":{"331":1}}],["隐藏单元数",{"2":{"325":5,"332":2,"337":1,"527":1,"559":1,"573":1,"713":6,"734":1}}],["隐藏变量",{"2":{"247":1}}],["隐藏变量h也是一个中间变量",{"2":{"162":1}}],["隐藏层的数量",{"2":{"573":1}}],["隐藏层的行为就好像只有一个单元",{"2":{"244":1}}],["隐藏层是在从输入到输出的路径上",{"2":{"338":1}}],["隐藏层和隐状态指的是两个截然不同的概念",{"2":{"338":1}}],["隐藏层参数",{"2":{"331":4}}],["隐藏层",{"0":{"229":1},"1":{"230":1,"231":1,"232":1,"233":1},"2":{"225":1,"423":3}}],["隐藏层数目l和隐藏单元数目h都是超参数",{"2":{"527":1}}],["隐藏层数",{"2":{"223":1,"325":2}}],["隐藏层中维度为d和一个输出",{"2":{"105":1}}],["ϕ",{"2":{"312":1}}],["截止2023年10月",{"2":{"1437":1}}],["截止到目前",{"2":{"65":1}}],["截断",{"2":{"568":1}}],["截断或填充文本序列",{"2":{"568":2}}],["截断包括",{"2":{"313":1}}],["截断是计算方便性和数值稳定性的需要",{"2":{"313":1}}],["截断时间步",{"0":{"309":1}}],["完整",{"2":{"1346":1,"1528":1}}],["完整性",{"2":{"1154":1}}],["完整的",{"2":{"1210":1}}],["完整的单发多框检测模型由五个模块组成",{"2":{"959":1}}],["完整的模型",{"0":{"959":1}}],["完美预测时的损失为0",{"2":{"611":1}}],["完全",{"2":{"642":1}}],["完全等于w⊤x",{"2":{"610":1}}],["完全连接层的输出数量或卷积层的输出通道数",{"2":{"472":2}}],["完全计算",{"0":{"308":1}}],["完成这个音频处理似乎需要你去写大量的代码或链接到一堆的合成器java库",{"2":{"1061":1}}],["完成这项任务的一种选择是用泄漏平均值",{"2":{"86":1}}],["完成计算的梯度参数就可以开始交换",{"2":{"832":1}}],["完成的",{"2":{"300":1}}],["满足",{"2":{"1077":1}}],["满足以下属性",{"2":{"1027":1}}],["满足我们通过其他规则实现初始化权重",{"2":{"434":1}}],["满足at=bt+ctat−1",{"2":{"307":1}}],["满足约束条件的另一种策略是投影",{"2":{"50":1}}],["患者患有艾滋病的概率为",{"2":{"1035":1}}],["患者会要求医生进行另一次测试来确定病情",{"2":{"1035":1}}],["患者在收到这样可怕的消息后应该怎么办",{"2":{"1035":1}}],["患者实际上患有艾滋病的几率只有13",{"2":{"1035":1}}],["患者感染hiv的概率",{"2":{"1035":1}}],["患者的体温曲线或者赛车所需的加速度",{"2":{"305":1}}],["患者是否在下一年内康复",{"2":{"289":1}}],["视频等静态文件",{"2":{"1363":1}}],["视频和论坛可以查阅",{"2":{"1300":1}}],["视频中的图像帧",{"2":{"305":1}}],["视为一个类别",{"2":{"1012":1}}],["视为相同的未知",{"2":{"567":1}}],["视为有效的特征值",{"2":{"209":1}}],["视觉效果上",{"2":{"1475":1}}],["视觉",{"2":{"379":1,"403":1}}],["根本区别是什么",{"2":{"304":1}}],["根据原始对象citys去创建响应式对象citys2",{"2":{"1518":1,"1519":1}}],["根据已有数据计算出新数据",{"2":{"1460":1}}],["根据上下文推断参数类型",{"2":{"1402":1}}],["根据上面的图表",{"2":{"1132":1}}],["根据上面的算法",{"2":{"1124":1}}],["根据上面绘制出的",{"2":{"1108":1}}],["根据官方统计",{"2":{"1359":1}}],["根据浏览你过去买过什么书",{"2":{"1187":1}}],["根据ε的不同其范围可大可小",{"2":{"1184":1}}],["根据非常",{"2":{"1182":1}}],["根据f1值或者查准率与查全率的比例来选择",{"2":{"1181":1}}],["根据测试集数据",{"2":{"1181":1}}],["根据测试集的精度衡量",{"2":{"179":1}}],["根据模型计算",{"2":{"1180":1}}],["根据模型参数最小化损失",{"2":{"228":1}}],["根据图表来判断梯度下降是否收敛",{"2":{"1167":1}}],["根据需要取前面最重要的部分",{"2":{"1158":1}}],["根据需要初始化模型参数",{"2":{"423":2}}],["根据余弦定理",{"2":{"1154":1}}],["根据你的问题",{"2":{"1148":1}}],["根据你所使用的数值和线性代数库的使用细节的不同",{"2":{"1093":1}}],["根据线性代数的知识",{"2":{"1145":1}}],["根据线性回归模型我们只能预测连续的值",{"2":{"1107":1}}],["根据毕达哥拉斯定理",{"2":{"1145":1}}],["根据惯例",{"2":{"1115":2}}],["根据这些特征可以构建一个模型",{"2":{"1178":1}}],["根据这些词是否有在邮件中出现",{"2":{"1137":1}}],["根据这个代价函数",{"2":{"1110":1}}],["根据这条线我们可以推测出",{"2":{"1060":1}}],["根据选择的参数计算输出变量=1的可能性",{"2":{"1107":1}}],["根据具体的问题",{"2":{"1085":1}}],["根据函数图形特性",{"2":{"1084":1}}],["根据二次方程的曲线",{"2":{"1060":1}}],["根据贝叶斯定理",{"2":{"1034":1}}],["根据对称性",{"2":{"1032":1}}],["根据乘法法则",{"2":{"1032":1}}],["根据照片区分猫和狗",{"2":{"1025":1}}],["根据照片预测蘑菇是否有毒",{"2":{"291":1}}],["根据病人的临床病史",{"2":{"1025":1}}],["根据剩余的函数名或属性名",{"2":{"1006":1}}],["根据设计好的模型",{"2":{"973":1}}],["根据类别和偏移量的预测和标注值计算损失函数",{"2":{"963":3}}],["根据我们之前幻灯片的内容",{"2":{"1145":1}}],["根据我们的数据来说",{"2":{"1063":1}}],["根据我们在",{"2":{"915":1}}],["根据我们选择的学习率",{"2":{"56":1}}],["根据带有预测偏移量的锚框来预测边界框",{"2":{"854":1}}],["根据带有噪声的线性模型构造一个人造数据集",{"2":{"599":1}}],["根据狗和猫的真实边界框",{"2":{"853":1}}],["根据阈值",{"2":{"851":3}}],["根据预测的偏移量调整它们的位置以获得预测的边界框",{"2":{"850":1}}],["根据gpu数目计算分块大小",{"2":{"836":1}}],["根据架构设计和处理器大小的不同",{"2":{"810":1}}],["根据体系结构的选择",{"2":{"809":1}}],["根据word2vec论文中的建议",{"2":{"775":1}}],["根据n个采样权重在",{"2":{"775":1}}],["根据输入与输出的尺寸之比来映射",{"2":{"863":1}}],["根据输入序列学到的片段嵌入ea和eb分别被添加到第一序列和第二序列的词元嵌入中",{"2":{"734":1}}],["根据输入的",{"2":{"1063":1}}],["根据输入的不同",{"2":{"643":1}}],["根据输入的位置对输出yi进行加权",{"2":{"388":1}}],["根据任务的性质对模型架构进行最小的更改",{"2":{"733":1}}],["根据一维卷积层的输入格式",{"2":{"702":3}}],["根据一维情况",{"2":{"46":1}}],["根据单词在句子中的作用",{"2":{"659":1}}],["根据最大似然估计",{"2":{"646":1}}],["根据极大似然估计法选择的估计量称为极大似然估计量",{"2":{"616":1}}],["根据极大似然估计法",{"2":{"616":1}}],["根据可获得的信息量",{"2":{"518":1}}],["根据光学",{"2":{"454":1}}],["根据经验",{"2":{"450":1}}],["根据下面的非线性函数生成一个人工数据集",{"2":{"386":1}}],["根据用户提供的文本的前缀生成后续文本",{"2":{"336":1}}],["根据本月的财务报告数据",{"2":{"289":1}}],["根据计算机断层扫描",{"2":{"289":1}}],["根据业务逻辑设计自动化系统",{"2":{"281":1}}],["根据之前章节所讲的",{"2":{"270":1}}],["根据参数w",{"2":{"244":1}}],["根据独热编码",{"2":{"209":1}}],["根据所在的地理位置改变我们的数据来源",{"2":{"183":1}}],["根据链式法则",{"2":{"164":1,"312":1,"984":1}}],["根据l2正则化的定义",{"2":{"162":1}}],["根据",{"2":{"126":1,"307":1,"312":1,"318":1,"397":1,"519":1,"574":1,"578":1,"579":1,"720":1,"744":1,"765":1,"784":1,"913":1}}],["根据迭代次数的函数来绘制与最优解",{"2":{"118":1}}],["根据詹森不等式",{"2":{"51":1,"115":1}}],["根据中值定理",{"2":{"46":1}}],["根据凸性的性质",{"2":{"44":1}}],["希望这节课能让你明白一个学习问题的什么样的特征",{"2":{"1182":1}}],["希望在那时候关于如何处理参数的这种平衡会变得更加清晰",{"2":{"1144":1}}],["希望能让你更清楚",{"2":{"1129":1}}],["希望能近似最小化真实风险",{"2":{"190":1}}],["希望我们的分类器的输出值在0和1之间",{"2":{"1107":1}}],["希望我们能够给出实现梯度下降算法的所有知识",{"2":{"1067":1}}],["希望你通过这些方法",{"2":{"1183":1}}],["希望你现在也知道如何采取这些低维表示z",{"2":{"1161":1}}],["希望你现在掌握了怎样构建矩阵",{"2":{"1089":1}}],["希望你能知道",{"2":{"1191":1}}],["希望你能对它们有一个更深入的理解",{"2":{"1132":1}}],["希望你能通过上面的讲解",{"2":{"1088":1}}],["希望你们还记得垃圾邮件问题",{"2":{"1061":1}}],["希望通过",{"2":{"1042":1}}],["希望将y视为一个常数",{"2":{"976":1}}],["希望读者能从中受益",{"2":{"302":1}}],["靠近输入的层可以表示数据的低级细节",{"2":{"302":1}}],["农业机器人可能会降低有机农业的成本",{"2":{"301":1}}],["工业产生深远影响的重要学科",{"2":{"1176":1}}],["工业革命的这一阶段可能对社会的大部分地区产生深远的影响",{"2":{"301":1}}],["工程化与运维",{"2":{"1546":1}}],["工程化",{"2":{"1543":1,"1548":1}}],["工程化也爱折腾",{"2":{"1542":1}}],["工程方面",{"2":{"1058":1}}],["工程和计量经济学",{"2":{"304":1}}],["工作节点",{"0":{"1377":1},"2":{"1381":1}}],["工作区",{"2":{"1319":2}}],["工作流内可定义多个",{"2":{"1310":1}}],["工作流",{"0":{"1309":1,"1325":1}}],["工作流程",{"2":{"1208":1,"1340":1}}],["工作自动化",{"2":{"1305":1}}],["工作与提交的编程练习",{"2":{"1193":1}}],["工作和提交的编程练习",{"0":{"1094":1}}],["工作年限",{"2":{"990":1}}],["工作就越容易",{"2":{"284":1}}],["工具与最佳实践",{"2":{"1546":1}}],["工具集",{"2":{"1528":1}}],["工具链协同执行",{"2":{"1053":1}}],["工具调用",{"2":{"1052":2,"1547":1}}],["工具使用能力",{"2":{"1050":1}}],["工具和服务之间的交互方式",{"2":{"1040":1}}],["工具",{"2":{"301":1,"1042":1,"1294":1,"1528":1}}],["扩展",{"2":{"1454":1}}],["扩展和管理",{"2":{"1374":1}}],["扩展和改进自己的架构的",{"2":{"301":1}}],["扩展st定义可获得",{"2":{"107":1}}],["启动",{"2":{"1393":1,"1443":1}}],["启动慢",{"2":{"1353":1}}],["启动速度",{"2":{"1346":1}}],["启动交互式容器",{"2":{"1343":1}}],["启动octave",{"2":{"1088":1}}],["启动计时器",{"2":{"615":1}}],["启动开发服务器",{"2":{"15":1}}],["启发式和统计模型的结合",{"2":{"301":1}}],["面朝前",{"2":{"1098":1}}],["面积是2104平方英尺",{"2":{"1089":1}}],["面积",{"2":{"1084":1}}],["面积和房龄",{"2":{"609":2,"610":1}}],["面向过程",{"2":{"1302":1}}],["面向对象",{"2":{"1302":1}}],["面向文档",{"2":{"1195":1}}],["面向特定任务",{"2":{"1054":1}}],["面向目标的方式设计",{"2":{"301":1}}],["面对更多的积极因素",{"2":{"201":1}}],["保护全局状态或配置不被修改",{"2":{"1515":1}}],["保证高可用和数据冗余",{"2":{"1210":1}}],["保证数据安全",{"2":{"1202":1}}],["保证读写并行",{"2":{"1200":1}}],["保证一致性",{"2":{"1198":1}}],["保证两部电影的特征向量之间的距离x",{"2":{"1191":1}}],["保证两个相邻的小批量中的子序列在原始序列上也是相邻的",{"2":{"321":1}}],["保留字",{"2":{"1215":1}}],["保留所有的特征",{"2":{"1114":1}}],["保留预测边界框的指标",{"2":{"854":3}}],["保留至少有两句话的段落",{"2":{"718":1}}],["保留了原来的大小写和数字",{"2":{"718":1}}],["保留了原来的标点符号",{"2":{"718":1}}],["保存历史对话",{"2":{"1052":1}}],["保存",{"2":{"821":4}}],["保存注意力权重",{"2":{"577":4}}],["保存更新过的moving",{"2":{"472":3}}],["保存架构必须在代码中完成",{"2":{"443":1}}],["保存单个权重向量",{"2":{"442":1}}],["保存在",{"2":{"424":1}}],["保存和加载模型参数",{"2":{"414":1}}],["保释决定的自动准予等等",{"2":{"301":1}}],["保持批量大小和学习率不变",{"2":{"837":1}}],["保持词不变",{"2":{"721":1}}],["保持高度和宽度",{"2":{"507":1}}],["保持模型简单的一个特别的选择是使用l2惩罚的权重衰减",{"2":{"279":1}}],["保持模型架构和其他超参数",{"2":{"223":1}}],["保持方差不变的一种方法是设置ninσ2=1",{"2":{"247":1}}],["保持空间维度的同时",{"2":{"141":1}}],["保持所有其它部分不变就产生了rmsprop算法",{"2":{"106":1}}],["粒子物理学和天文学最近取得的一些突破性进展至少部分归功于机器学习",{"2":{"301":1}}],["物理",{"2":{"304":1}}],["物流",{"2":{"301":1}}],["物体识别同样也取得了长足的进步",{"2":{"301":1}}],["英雄联盟",{"2":{"1456":1,"1457":1,"1508":1}}],["英",{"2":{"565":1,"566":1,"572":1}}],["英伟达",{"2":{"301":1,"457":1}}],["英语中的一些固定短语由多个单词组成",{"2":{"788":1}}],["英语中大约有3×108种可能的6",{"2":{"759":1}}],["英语是源语言",{"2":{"565":1}}],["英语文本",{"2":{"315":1}}],["英语",{"2":{"295":1,"409":1,"565":2,"566":1,"569":1}}],["扑克中的挑战是状态空间很大",{"2":{"301":1}}],["难以比较的数字",{"2":{"342":1}}],["难度更大",{"2":{"301":1}}],["难道我们不能简单地通过扭曲空间来",{"2":{"26":1}}],["卡方核函数",{"2":{"1148":1}}],["卡车司机和店员完成的许多琐碎的工作很可能也将是自动化的",{"2":{"301":1}}],["卡斯帕罗夫",{"2":{"301":1}}],["卡住",{"2":{"44":1}}],["击败了加里",{"2":{"301":1}}],["到处运行",{"2":{"1339":1,"1354":1}}],["到x",{"2":{"1178":1}}],["到现在",{"2":{"1176":1}}],["到现在为止",{"2":{"1114":1}}],["到了这里已经非常接近逻辑回归中使用的代价函数了",{"2":{"1143":1}}],["到了新的红色点",{"2":{"1068":1}}],["到底是选择使用1",{"2":{"1179":1}}],["到底是否使用词干提取",{"2":{"1138":1}}],["到底是怎么用的",{"2":{"1090":1}}],["到底应该如何合在一起使用",{"2":{"1122":1}}],["到3",{"2":{"1112":1}}],["到n+1",{"2":{"1093":1}}],["到$",{"2":{"1093":1}}],["到150",{"2":{"880":1}}],["到100",{"2":{"879":1}}],["到磁盘",{"2":{"821":4}}],["到5",{"2":{"658":1}}],["到新序列词元",{"2":{"572":1}}],["到下一层的输入",{"2":{"422":1}}],["到",{"2":{"351":6,"1063":1,"1092":4,"1093":1,"1110":1,"1194":1,"1296":1}}],["到2017年",{"2":{"301":1}}],["到目前为止我们都是初始所有参数为0",{"2":{"1125":1}}],["到目前为止我们默认数据都来自于某种分布",{"2":{"305":1}}],["到目前为止",{"2":{"66":1,"76":1,"116":1,"121":1,"134":1,"142":1,"240":1,"278":1,"296":1,"297":1,"300":1,"302":1,"305":1,"306":1,"417":1,"422":4,"425":1,"440":1,"526":1,"573":1,"617":1,"831":1,"967":1,"982":1,"1085":1,"1129":1,"1143":1}}],["亚马逊推荐新书给你",{"2":{"1187":1}}],["亚马逊的alexa和谷歌助手",{"2":{"301":1}}],["亚马逊上的产品评级和评论",{"2":{"294":1}}],["苹果",{"2":{"301":1}}],["支持嵌套路由和懒加载",{"2":{"1528":1}}],["支持嵌套和数组",{"2":{"1197":1}}],["支持版本回滚",{"2":{"1383":1}}],["支持负载均衡",{"2":{"1348":1}}],["支持",{"2":{"1313":1,"1371":1,"1386":1,"1436":1,"1527":1,"1529":1}}],["支持pep",{"2":{"1287":1}}],["支持重复元素",{"2":{"1216":1}}],["支持比",{"2":{"1197":1}}],["支持丰富的查询语法",{"2":{"1195":1}}],["支持分片",{"2":{"1195":1}}],["支持多种方式",{"2":{"1309":1}}],["支持多种编程范式",{"2":{"1302":1}}],["支持多种索引",{"2":{"1199":1}}],["支持多种通信机制",{"2":{"1043":1}}],["支持多变量的假设",{"2":{"1080":1}}],["支持向量机等等一些监督学习算法",{"2":{"1176":1}}],["支持向量机或者逻辑回归算法训练一个分类器即可",{"2":{"1172":1}}],["支持向量机算法",{"2":{"1148":1}}],["支持向量机也可以不使用核函数",{"2":{"1147":1}}],["支持向量机也可以给出好的结果",{"2":{"1144":1}}],["支持向量机仍然会找到正样本和负样本之间的大间距分隔",{"2":{"1145":1}}],["支持向量机要做的事情都是优化这个目标函数对应着c值非常大的情况",{"2":{"1145":1}}],["支持向量机产生大间距分类器的结论",{"2":{"1145":1}}],["支持向量机最终可以找到一个较小的θ范数",{"2":{"1145":1}}],["支持向量机可以使参数θ的范数变小很多",{"2":{"1145":1}}],["支持向量机选择了这个决策界",{"2":{"1145":1}}],["支持向量机的两个重要参数",{"2":{"1147":1}}],["支持向量机的优化目标函数",{"2":{"1145":1}}],["支持向量机的要求更高",{"2":{"1144":1}}],["支持向量机现在要比这个大间距分类器所体现得更成熟",{"2":{"1144":1}}],["支持向量机将会选择这个黑色的决策边界",{"2":{"1144":1}}],["支持向量机所做的是它来直接预测y的值等于1",{"2":{"1143":1}}],["支持向量机",{"2":{"1061":1,"1142":1,"1143":1,"1148":2,"1193":1}}],["支持函数调用与插件调用的工作流",{"2":{"1054":1}}],["支持更复杂的行为决策",{"2":{"1050":1}}],["支持用户注册和登录功能",{"2":{"11":1}}],["支付宝",{"2":{"301":1}}],["系列",{"0":{"936":1},"1":{"937":1,"938":1,"939":1,"940":1,"941":1,"942":1}}],["系统参数与执行环境",{"2":{"1263":1}}],["系统梳理",{"2":{"1194":1}}],["系统的总体效果又提升了10",{"2":{"1174":1}}],["系统",{"2":{"1054":1}}],["系统会构建一个计算图",{"2":{"973":1}}],["系统会自动初始化",{"2":{"424":1}}],["系统会自动检查金融交易是否存在欺诈",{"2":{"301":1}}],["系统就可以在两个设备上自动实现并行计算",{"2":{"796":3}}],["系统可以在计算y",{"2":{"797":1}}],["系统可以选择并行执行它们",{"2":{"795":1}}],["系统可以了解所有依赖关系",{"2":{"795":1}}],["系统不同",{"2":{"454":1}}],["系统知道在",{"2":{"424":2}}],["系统将自动生成这些",{"2":{"423":1}}],["系统研究人员构建更好的工具",{"2":{"300":1}}],["系数γ决定了在调整每坐标比例时历史记录的时长",{"2":{"110":1}}],["允许用户定义更加直观的函数",{"2":{"818":1}}],["允许我们组合新的架构",{"2":{"425":1}}],["允许注意力机制组合使用查询",{"2":{"380":1}}],["允许轻松建模的第一代框架包括caffe",{"2":{"300":1}}],["允许在非线性环境中应用为线性函数引入的工具",{"2":{"278":1}}],["允许在不增加任何额外的计算开销的情况下向算法中添加权重衰减",{"2":{"278":1}}],["仿冒品垃圾邮件或者密码窃取邮件等",{"2":{"1138":1}}],["仿真提供了这样一条途径",{"2":{"300":1}}],["仿射变换由所选权重和偏置确定",{"2":{"610":1}}],["仿射变换的特点是通过加权和对特征进行线性变换",{"2":{"610":1}}],["仿射变换",{"2":{"610":1}}],["仿射变换中的线性是一个很强的假设",{"2":{"229":1}}],["仿射函数的仿射函数本身就是仿射函数",{"2":{"232":1}}],["奖励",{"2":{"300":1}}],["状态维护",{"2":{"1381":1}}],["状态管理和构建工具",{"2":{"1526":1}}],["状态管理",{"2":{"1052":1,"1530":1}}],["状态",{"2":{"300":1,"532":1,"1490":3,"1493":1}}],["星际争霸和物理模拟",{"2":{"300":1}}],["雅迪",{"2":{"1465":1,"1466":1}}],["雅达里游戏",{"2":{"300":1}}],["雅各布",{"2":{"299":1}}],["驰骋的斑马",{"2":{"300":1}}],["密度估计和生成模型的统计方法侧重于找到合适的概率分布",{"2":{"300":1}}],["长期霸榜编程语言排行榜",{"2":{"1303":1}}],["长期以来",{"2":{"86":1,"551":1}}],["长度",{"0":{"991":1},"2":{"1156":1}}],["长度为num",{"2":{"320":1}}],["长短期记忆",{"2":{"538":1}}],["长短期记忆网络和常规循环神经网络的计算成本",{"2":{"563":1}}],["长短期记忆网络可以缓解梯度消失和梯度爆炸",{"2":{"562":1}}],["长短期记忆网络有三种类型的门",{"2":{"562":1}}],["长短期记忆网络是典型的具有重要状态控制的隐变量自回归模型",{"2":{"561":1}}],["长短期记忆网络的隐藏层输出包括",{"2":{"562":1}}],["长短期记忆网络的隐状态需要返回一个额外的记忆元",{"2":{"559":1}}],["长短期记忆网络的设计灵感来自于计算机的逻辑门",{"2":{"552":1}}],["长短期记忆网络的设计比门控循环单元稍微复杂一些",{"2":{"551":1}}],["长短期记忆网络引入了记忆元",{"2":{"552":1}}],["长短期记忆网络",{"0":{"551":1},"1":{"552":1,"553":1,"554":1,"555":1,"556":1,"557":1,"558":1,"559":1,"560":1,"561":1,"562":1,"563":1},"2":{"300":1,"550":1}}],["长",{"2":{"325":1}}],["长序列存在一个问题",{"2":{"322":1}}],["长单词序列大部分是没出现过的",{"2":{"316":1}}],["算术运算符",{"0":{"1218":1}}],["算术和运算",{"2":{"988":1}}],["算出更多的正确答案",{"2":{"1060":1}}],["算力的突破来触发的",{"2":{"303":1}}],["算力的增长速度已经超过了现有数据的增长速度",{"2":{"300":1}}],["算法会自动学得",{"2":{"1189":1}}],["算法可以针对用户的当前行为不断地更新模型以适应该用户",{"2":{"1168":1}}],["算法运行太慢或者占用太多内存",{"2":{"1162":1}}],["算法分为两个步骤",{"2":{"1151":1}}],["算法接受一个未标记的数据集",{"2":{"1151":1}}],["算法为",{"2":{"1109":1}}],["算法举例",{"2":{"1074":1}}],["算法是相当低效的",{"2":{"842":1}}],["算法的公式为",{"2":{"1067":1}}],["算法的步骤如下",{"2":{"613":1}}],["算法的收敛速度有多快",{"2":{"64":1}}],["算法仍然有效吗",{"2":{"607":1}}],["算法具有相似性",{"2":{"524":1}}],["算法和计算的进步导致了算法被广泛应用",{"2":{"301":1}}],["算法",{"0":{"27":1,"33":1,"107":1,"1180":1},"2":{"270":1,"1111":1,"1141":1,"1182":1,"1193":1}}],["波士顿房价",{"2":{"300":1}}],["鸢尾花卉",{"2":{"300":1}}],["廉价的数据存储",{"2":{"300":1}}],["廉价又高质量的传感器",{"2":{"300":1}}],["廉价存储",{"2":{"260":1}}],["等生态模块",{"2":{"1527":1}}],["等支持开箱即用",{"2":{"1444":1}}],["等应用服务器",{"2":{"1363":1}}],["等方法",{"2":{"1183":1}}],["等高线图",{"2":{"1066":1}}],["等高频词",{"2":{"773":1}}],["等框架的发展",{"2":{"1051":1}}],["等价地",{"2":{"1028":1}}],["等价于传统写法",{"2":{"1428":1}}],["等价于p",{"2":{"1034":1}}],["等价于对矩阵的所有元素进行求和",{"2":{"995":1}}],["等价于y=tf",{"2":{"975":1}}],["等价于y=sum",{"2":{"975":1}}],["等价于y",{"2":{"975":1}}],["等价于x=torch",{"2":{"974":1}}],["等价于",{"2":{"318":1}}],["等于2",{"2":{"1093":1}}],["等于0的情况",{"2":{"1143":1}}],["等于0",{"2":{"1092":1}}],["等于999",{"2":{"1092":1}}],["等于6的时候",{"2":{"1092":1}}],["等于1",{"2":{"1025":1,"1092":1,"1093":1}}],["等于",{"2":{"1004":1,"1092":6,"1093":2,"1111":1}}],["等函数都允许显式的non",{"2":{"797":1}}],["等待异步组件时渲染一些额外内容",{"2":{"1523":1}}],["等待变量可用",{"2":{"791":1}}],["等待直到所有计算完成",{"2":{"791":1}}],["等单词都是同一个词",{"2":{"755":1}}],["等",{"2":{"751":1,"1303":1,"1309":1,"1350":1,"1393":1,"1543":1}}],["等领域",{"2":{"691":1}}],["等问题",{"2":{"472":1}}],["等到知道了所有的参数形状",{"2":{"418":1}}],["等强大的统计工具",{"2":{"299":1}}],["等等的值",{"2":{"1145":2}}],["等等",{"2":{"290":1,"1061":2,"1148":1,"1187":1,"1451":1}}],["赫布学习",{"2":{"299":1}}],["赫布",{"2":{"299":1}}],["费舍尔1932年的鸢尾花卉数据集是测试算法有效性的流行工具",{"2":{"299":1}}],["费舍尔在1936年发布的鸢尾花卉数据集",{"2":{"299":1}}],["费舍尔",{"2":{"299":1}}],["罗素和彼得",{"2":{"619":1}}],["罗纳德",{"2":{"299":1}}],["罗马",{"2":{"296":1}}],["至于这里给出的参考",{"2":{"1148":1}}],["至于稍后要介绍的某些模型",{"2":{"325":1}}],["至今仍被频繁使用",{"2":{"299":1}}],["至今仍用于解决从保险计算到医疗诊断的许多问题",{"2":{"299":1}}],["至少",{"2":{"1187":1}}],["至少是成立的",{"2":{"1092":1}}],["至少基于这里的",{"2":{"1092":1}}],["至少对于这个示例图像",{"2":{"879":1}}],["至少对底层硬件有一定的了解也是必不可少的",{"2":{"800":1}}],["至少在某种意义上",{"2":{"1191":1}}],["至少在学术界它占了很小的份额",{"2":{"1187":1}}],["至少在没有额外帮助的情况下不是好选择",{"2":{"789":1}}],["至少在t",{"2":{"347":1}}],["至少需要两个gpu",{"2":{"445":1}}],["至少该模型已经学会了如何拼写单词",{"2":{"342":1}}],["至少有",{"2":{"105":1}}],["至少部分特征值为负的可能性相当高",{"2":{"102":1}}],["至少最小化凸二次目标函数的情况下是如此",{"2":{"93":1}}],["发请求",{"2":{"1471":1,"1495":1}}],["发音",{"2":{"1359":1}}],["发展",{"2":{"1357":1}}],["发展到整个层",{"2":{"506":1}}],["发布",{"0":{"1315":1}}],["发布了许多优秀的算法库",{"2":{"302":1}}],["发邮件",{"2":{"1297":1}}],["发现系统的总体效果只提升了1",{"2":{"1174":1}}],["发现系统的总体效果从72",{"2":{"1174":1}}],["发现是否缺少某些特征",{"2":{"1138":1}}],["发现",{"2":{"1061":1}}],["发现的",{"2":{"299":1}}],["发送请求给",{"2":{"1340":1}}],["发送一段微弱电流给其他神经元",{"2":{"1099":1}}],["发送到ram",{"2":{"802":1}}],["发送以及尽可能简洁地处理信息或数据",{"2":{"649":1}}],["发生预测的词元索引以及这些预测的标签索引",{"2":{"721":1}}],["发生预测的词元索引和这些预测的标签",{"2":{"721":1}}],["发明的softmax函数正是这样做的",{"2":{"643":1}}],["发明另一种用于在每一层注入随机噪声的技术",{"2":{"178":1}}],["弗里德里希",{"2":{"299":1}}],["命令行",{"2":{"1548":1}}],["命令基础",{"0":{"1341":1},"1":{"1342":1,"1343":1,"1344":1,"1345":1}}],["命令别名",{"2":{"1336":1}}],["命令添加路径",{"2":{"1092":1}}],["命令跟",{"2":{"1089":1}}],["命令可以显示出octave",{"2":{"1089":1}}],["命令返回第二列",{"2":{"1089":1}}],["命令返回的是一个",{"2":{"1089":1}}],["命令返回3",{"2":{"1089":1}}],["命令返回矩阵的尺寸",{"2":{"1089":1}}],["命令",{"2":{"1088":1,"1089":8,"1090":1,"1091":1,"1311":1}}],["命令的六个小数",{"2":{"1088":1}}],["命令式编程",{"2":{"824":1}}],["命令式编程和符号式编程",{"2":{"822":1}}],["命令式编程使得新模型的设计变得容易",{"2":{"822":1}}],["命令式编程使用诸如print",{"2":{"816":1}}],["命令式编程现在是tensorflow2的默认选择",{"2":{"818":1}}],["命令式编程也更容易调试",{"2":{"817":1}}],["命令式编程的大部分代码都是简单易懂的",{"2":{"817":1}}],["命令式编程更容易使用",{"2":{"817":1}}],["命令式",{"2":{"817":1}}],["命名路由",{"0":{"1478":1}}],["命名规范建议",{"0":{"1215":1}}],["命名实体识别和问答",{"2":{"731":1}}],["命名的",{"2":{"299":1}}],["命中缓存",{"2":{"206":1}}],["伯努利",{"2":{"299":1}}],["伯努利分布是以雅各布",{"2":{"299":1}}],["人均gdp",{"2":{"1157":1}}],["人",{"2":{"1061":1}}],["人与人之间需要交流",{"2":{"754":1}}],["人造特殊词元",{"2":{"736":1}}],["人咬狗",{"2":{"315":1,"345":1}}],["人类的大脑呢",{"2":{"1098":1}}],["人类的注意力是有限的",{"2":{"358":1}}],["人类的祖先已经从经验",{"2":{"354":1}}],["人类之间的互动也是连续的",{"2":{"345":1}}],["人类通过特征工程所能完成的事情很少",{"2":{"302":1}}],["人类长期以来就有分析数据和预测未来结果的愿望",{"2":{"299":1}}],["人工数据合成",{"2":{"1173":1}}],["人工进行选择的",{"2":{"1154":1}}],["人工检查交叉验证集中我们算法中产生预测误差的样本",{"2":{"1138":1}}],["人工通用智能",{"2":{"301":1}}],["人工智能结合",{"2":{"1540":1}}],["人工智能",{"2":{"1297":1}}],["人工智能或自动化行业",{"2":{"1295":1}}],["人工智能的梦想就是",{"2":{"1098":1}}],["人工智能的最佳实践以及如何让它们工作",{"2":{"1059":1}}],["人工智能智能体",{"2":{"1049":1}}],["人工智能系统是以一种特定的",{"2":{"301":1}}],["人工智能已经直接影响到人类的生计",{"2":{"301":1}}],["人工智能进步的另一个迹象是自动驾驶汽车和卡车的出现",{"2":{"301":1}}],["人工智能才成为人们关注的焦点",{"2":{"301":1}}],["人工智能在交付结果方面有着悠久的历史",{"2":{"301":1}}],["人们有时将支持向量机看作是大间距分类器",{"2":{"1144":1}}],["人们使用最多的用于机器学习的原始语言是octave",{"2":{"1088":1}}],["人们使用gpu来进行机器学习",{"2":{"450":1}}],["人们不希望停下计算来等它",{"2":{"1022":1}}],["人们通过一维张量表示向量",{"2":{"990":1}}],["人们要么消耗注意力在游戏战斗中",{"2":{"354":1}}],["人们要么消耗注意力在广告上",{"2":{"354":1}}],["人们正处在",{"2":{"354":1}}],["人们正在经历从参数统计描述到完全非参数模型的转变",{"2":{"302":1}}],["人们会强烈期望下部电影会更好",{"2":{"345":1}}],["人们迅速接受并且适应一种更好或者更坏的情况",{"2":{"345":1}}],["人们对电影的看法会发生很大的变化",{"2":{"345":1}}],["人们需要依靠简化对现实的假设来获得有用的模型",{"2":{"302":1}}],["人们在技术博客上贴的标签",{"2":{"292":1}}],["人们宁愿错误地分入一个相关的类别",{"2":{"291":1}}],["人们与智能手机的日常互动就可以涉及几种机器学习模型",{"2":{"282":1}}],["人们常用的计算机程序几乎都是软件开发人员从零编写的",{"2":{"281":1}}],["解绑事件",{"2":{"1499":1}}],["解耦",{"2":{"1203":1}}],["解析",{"2":{"1444":1}}],["解析高效",{"2":{"1197":1}}],["解析解可以进行很好的数学分析",{"2":{"612":1}}],["解析解",{"0":{"612":1}}],["解压下载的数据集",{"2":{"872":1}}],["解码",{"2":{"649":1}}],["解码器预测了输出词元的概率分布",{"2":{"575":1}}],["解码器的输出形状变为",{"2":{"574":1}}],["解码器的自注意力权重和",{"2":{"409":1}}],["解码器的自注意力权重和编码器解码器注意力权重都被存储下来",{"2":{"408":1}}],["解码器将具有固定形状的编码状态映射为长度可变的序列",{"2":{"536":1}}],["解码器在每个时间步都会将输入",{"2":{"534":1}}],["解码器输出yt",{"2":{"512":1,"574":1}}],["解码器模型",{"2":{"409":1}}],["解码器自注意力权重",{"2":{"408":5}}],["解码器自注意力",{"2":{"408":1}}],["解码器注意力中",{"2":{"404":1}}],["解码器注意力",{"2":{"404":1,"408":3}}],["解码器还在这两个子层之间插入了第三个子层",{"2":{"404":1}}],["解码器中2个注意力层",{"2":{"408":1}}],["解码器中第i个块",{"2":{"408":4}}],["解码器中的每个位置只能考虑该位置之前的所有位置",{"2":{"404":1}}],["解码器中",{"2":{"377":1}}],["解码器会有选择地统计输入序列的不同部分",{"2":{"377":1}}],["解码器上一个时间步的最终层隐状态将用作查询",{"2":{"375":1}}],["解码器",{"0":{"408":1,"534":1,"574":1},"2":{"375":1,"408":6,"409":2,"532":3,"535":3,"536":1,"537":2,"550":1,"572":1,"574":1,"576":1,"578":1,"579":2}}],["解码器架构的设计原则",{"2":{"572":1}}],["解码器架构的基类",{"2":{"535":4}}],["解码器架构的基本解码器接口",{"2":{"534":4}}],["解码器架构的基本编码器接口",{"2":{"533":4}}],["解码器架构的一个实践",{"2":{"410":1}}],["解码器架构的一个实例",{"2":{"404":1}}],["解码器架构略有不同",{"2":{"374":1}}],["解码器架构",{"0":{"532":1},"1":{"533":1,"534":1,"535":1,"536":1,"537":1},"2":{"373":1}}],["解码时间步t",{"2":{"374":1}}],["解释执行",{"2":{"1302":1}}],["解释了星系是如何诞生的",{"2":{"1061":1}}],["解释为f",{"2":{"981":1}}],["解释型",{"2":{"817":1,"1296":1}}],["解释如何在视觉场景中展开注意力",{"2":{"379":1}}],["解释p",{"2":{"349":1}}],["解释器",{"2":{"300":1}}],["解释所有这些复杂性可能会对研究人员要求太高",{"2":{"298":1}}],["解决了",{"2":{"1374":1}}],["解决高偏差",{"2":{"1135":3}}],["解决高方差",{"2":{"1135":3}}],["解决的方法是尝试将所有特征的尺度都尽量缩放到",{"2":{"1082":1}}],["解决的问题相当有限",{"2":{"297":1}}],["解决任务t",{"2":{"1059":1}}],["解决方法是尽可能避免从内存中加载新数据",{"2":{"810":1}}],["解决方案是创造",{"2":{"1148":1}}],["解决方案",{"2":{"72":1}}],["解决此问题的常见做法是将我们的数据分成三份",{"2":{"256":1}}],["解决此问题的一种方法是按照计算方便的需要截断时间步长的尺寸",{"2":{"312":1}}],["解决此问题的一种方法是使用st",{"2":{"106":1}}],["解决此问题的一个方法是记录我们看到特定特征的次数",{"2":{"25":1}}],["解决",{"2":{"245":1,"1356":2,"1384":1}}],["解决一些棘手的",{"2":{"179":1}}],["解决这些问题有两种选择",{"2":{"802":1}}],["解决这些相互冲突的目标的唯一方法是在优化过程中动态降低学习率",{"2":{"113":1}}],["解决这一问题的最早方法之一是长短期存储器",{"2":{"551":1}}],["解决这一问题的简单方法是结合使用线搜索和梯度下降",{"2":{"62":1}}],["解决这个问题的一个技巧是",{"2":{"624":1}}],["解决这个问题的一种方法是用价格预测的对数来衡量差异",{"2":{"210":1}}],["解决这个问题的一种方法来自物理中相当简单的直觉",{"2":{"48":1}}],["解决这个问题的简单方法即为填充",{"2":{"141":1}}],["解决这种困境的一个相当简单的解决方法是使用预热期",{"2":{"73":1}}],["唯一一点不同的是p在这里是负的",{"2":{"1145":1}}],["唯一方法是让机器自己学习怎么来解决问题",{"2":{"1058":1}}],["唯一不同的是",{"2":{"955":1,"1120":1}}],["唯一合理的可能性是",{"2":{"500":1}}],["唯一真正的奖励信号出现在游戏结束时",{"2":{"298":1}}],["唯一的区别的是",{"2":{"1168":1}}],["唯一的区别在于",{"2":{"659":1}}],["唯一的区别是",{"2":{"528":1,"648":1}}],["唯一的区别是我们添加了2个全连接层",{"2":{"225":1}}],["唯一的差别是",{"2":{"347":1}}],["唯一的变化是损失现在包括了惩罚项",{"2":{"275":1}}],["唯一的变化是",{"2":{"88":1}}],["潜在的统计机制是检查真实和虚假数据是否相同的测试",{"2":{"296":1}}],["犯罪",{"2":{"296":1}}],["犯罪率高的社区会得到更多的巡逻",{"2":{"201":1}}],["污染",{"2":{"296":1}}],["巴黎",{"2":{"296":1}}],["主从",{"2":{"1375":1}}],["主机组成一个集群",{"2":{"1348":1}}],["主机应用可以连接多个服务器",{"2":{"1042":1}}],["主元",{"2":{"1158":1}}],["主观概率为q的观察者在看到根据概率p生成的数据时的预期惊异",{"2":{"652":1}}],["主观",{"2":{"651":1}}],["主成分分析法的应用建议",{"0":{"1162":1},"2":{"1193":1}}],["主成分分析算法",{"0":{"1159":1},"2":{"1193":1}}],["主成分分析最小化的是投射误差",{"2":{"1158":1}}],["主成分分析与线性回归是两种不同的算法",{"2":{"1158":1}}],["主成分分析与线性回顾的比较",{"2":{"1158":1}}],["主成分分析问题",{"0":{"1158":1},"2":{"1193":1}}],["主成分分析",{"2":{"296":1,"1158":1}}],["主要成分分析是减少投射的平均均方误差",{"2":{"1160":1}}],["主要的两种类型被我们称之为监督学习和无监督学习",{"2":{"1059":1}}],["主要取决于模型的复杂性",{"2":{"821":1}}],["主要研究",{"2":{"665":1}}],["主要邮件",{"2":{"634":1}}],["主要区别在于学习率大得多",{"2":{"473":1}}],["主要区别在于前者减少了学习率适应坐标的数量",{"2":{"19":1}}],["主要是对于现代机器学习应用",{"2":{"1098":1}}],["主要是正则化",{"2":{"476":1}}],["主要是因为解决了以前被认为难以解决的问题",{"2":{"301":1}}],["主要是因为这个问题经常被视为一个单独的学习问题的情景",{"2":{"197":1}}],["主要是为了方便本章后面介绍的其他优化算法也可以使用同样的输入",{"2":{"80":1}}],["主要针对一种影响老年男性的疾病",{"2":{"185":1}}],["主要用于传达对问题的更多直觉",{"2":{"115":1}}],["婴儿",{"2":{"296":1,"640":1}}],["老年人",{"2":{"640":1}}],["老板可能会给我们一大堆数据",{"2":{"296":1}}],["老板站在身后",{"2":{"296":1}}],["老虎机",{"0":{"197":1},"2":{"197":1}}],["打磨一套",{"2":{"1547":1}}],["打磨成",{"2":{"1545":1}}],["打造网页魔法师的奇妙世界",{"0":{"1532":1},"1":{"1533":1,"1534":1,"1535":1,"1536":1,"1537":1,"1538":1,"1539":1,"1540":1,"1541":1}}],["打包大小减少41",{"2":{"1438":1}}],["打乱后用于在遮蔽语言模型任务中获取15",{"2":{"721":1}}],["打印params参数",{"2":{"1482":1}}],["打印query参数",{"2":{"1481":1}}],["打印内容",{"2":{"1468":1}}],["打印第一个小批量的形状会发现",{"2":{"948":1}}],["打印变量就是一个阻塞器",{"2":{"791":1}}],["打印词表中所有词元向量的形状",{"2":{"714":1}}],["打印前3对",{"2":{"667":1}}],["打印层的尺寸时",{"2":{"511":1}}],["打头",{"2":{"409":1}}],["打趣一下",{"2":{"296":1}}],["打破对称性",{"0":{"244":1}}],["颠倒输入和输出的顺序非常重要",{"2":{"295":1}}],["记得去home组件中预留一个",{"2":{"1479":1}}],["记得要加完整路径",{"2":{"1479":1}}],["记录",{"2":{"1321":1}}],["记录多次运行时间",{"2":{"615":1}}],["记",{"2":{"1154":1}}],["记下这些特征出现的次数",{"2":{"1138":1}}],["记事本有时会把代码的间距弄得很乱",{"2":{"1092":1}}],["记作",{"2":{"1077":1}}],["记为h",{"2":{"652":1}}],["记住",{"2":{"295":1,"1436":1}}],["记忆元ct−1∈rn×h的内容",{"2":{"555":1}}],["记忆元",{"0":{"555":1},"2":{"562":1}}],["记忆",{"2":{"253":1,"295":1,"1050":1}}],["序列中任意一个事件发生的概率等于它们各自发生的概率之和",{"2":{"1027":1}}],["序列化",{"0":{"821":1}}],["序列",{"2":{"734":1}}],["序列长度",{"2":{"693":1}}],["序列b的词元数",{"2":{"674":6}}],["序列a的词元数",{"2":{"674":6}}],["序列a",{"2":{"674":6}}],["序列样本都有一个固定的长度",{"2":{"568":1}}],["序列对由英文文本序列和翻译后的法语文本序列组成",{"2":{"565":1}}],["序列转换模型在各类现代人工智能应用中发挥着至关重要的作用",{"2":{"564":1}}],["序列转换模型",{"2":{"564":1}}],["序列的各个部分之间存在逻辑中断",{"2":{"538":1}}],["序列的嵌入",{"2":{"404":1}}],["序列搜索策略包括贪心搜索",{"2":{"516":1}}],["序列和目标",{"2":{"404":1}}],["序列词元",{"2":{"373":1}}],["序列结束词元",{"2":{"363":1}}],["序列开始词元",{"2":{"363":1,"577":1}}],["序列数据和执行动态规划的层",{"2":{"412":1}}],["序列数据不仅仅是关于电影评分的",{"2":{"345":1}}],["序列数据的不同采样方法",{"2":{"335":1}}],["序列模型的估计需要专门的统计工具",{"2":{"352":1}}],["序列模型",{"0":{"345":1},"1":{"346":1,"347":1,"348":1,"349":1,"350":1,"351":1,"352":1,"353":1}}],["序列模型和其他情况的启发式算法",{"2":{"248":1}}],["序列预定义了0≤πt≤1",{"2":{"310":1}}],["序列满足a0=0且at=bt+ctat−1",{"2":{"307":1}}],["序列到序列模型的预测",{"2":{"577":4}}],["序列到序列学习",{"0":{"572":1},"1":{"573":1,"574":1,"575":1,"576":1,"577":1,"578":1,"579":1,"580":1}}],["序列到序列",{"2":{"295":1}}],["序列学习需要摄取输入序列或预测输出序列",{"2":{"295":1}}],["序列学习",{"0":{"295":1}}],["审查后的反馈",{"2":{"294":1}}],["某人教你如何成为一名木匠",{"2":{"1059":1}}],["某人接下来最有可能看哪部电影",{"2":{"639":1}}],["某种形式的加速器",{"2":{"801":1}}],["某个轴计算a元素的累积总和",{"2":{"996":1}}],["某个图像描绘的是驴",{"2":{"639":1}}],["某个用户可能注册或不注册订阅服务",{"2":{"639":1}}],["某个电子邮件是否属于垃圾邮件文件夹",{"2":{"639":1}}],["某个1000个字符的序列",{"2":{"306":1}}],["某用户跳过播放列表中的某些歌曲",{"2":{"294":1}}],["某些人喜欢电影",{"2":{"1191":1}}],["某些人群没有样本表示",{"2":{"284":1}}],["某些未知属性可能的值是多少",{"2":{"987":1}}],["某些参数的梯度将比其他参数的梯度更早可用",{"2":{"797":3}}],["某些语言",{"2":{"571":1}}],["某些文本序列被填充了没有意义的特殊词元",{"2":{"368":1}}],["某些信息仍然可以通过",{"2":{"235":1}}],["表演的舞台",{"2":{"1451":1}}],["表达如下",{"2":{"1178":1}}],["表达他们对特定产品的喜爱程度",{"2":{"294":1}}],["表现情况通常依赖于你的水平",{"2":{"1143":1}}],["表现得好与不太好是有差别的",{"2":{"1111":1}}],["表现形式为梯度消失或梯度爆炸",{"2":{"312":1}}],["表述",{"0":{"1096":1},"1":{"1097":1,"1098":1,"1099":1,"1100":1,"1101":1,"1102":1,"1103":1},"2":{"1193":1}}],["表白",{"2":{"665":1}}],["表格数据和图像数据",{"2":{"305":1}}],["表示所有条件都不满足时的默认分支",{"2":{"1223":1}}],["表示所有物理cpu和内存",{"2":{"446":1}}],["表示带小数的实数",{"2":{"1216":1}}],["表示整数",{"2":{"1216":1}}],["表示我们只计算那些用户",{"2":{"1188":1}}],["表示样本i应该在边界上",{"2":{"1154":1}}],["表示样本i应该分类到",{"2":{"1154":1}}],["表示u的范数",{"2":{"1145":1}}],["表示θtx",{"2":{"1143":2}}],["表示已经选出了明确的行驶方向",{"2":{"1127":1}}],["表示正向类",{"2":{"1106":1}}],["表示负向类",{"2":{"1106":1}}],["表示当前类",{"2":{"1103":1}}],["表示这两条曲线表示的内容",{"2":{"1091":1}}],["表示这是一个47维的向量",{"2":{"1089":1}}],["表示向上",{"2":{"1090":1}}],["表示向上四舍五入",{"2":{"1090":1}}],["表示是一个1×2的矩阵",{"2":{"1089":1}}],["表示账户曾经被盗过",{"2":{"1060":1}}],["表示第1类乳腺癌",{"2":{"1060":1}}],["表示第i块gpu",{"2":{"446":1}}],["表示它",{"2":{"1031":1}}],["表示随机变量x从",{"2":{"1028":1}}],["表示随机变量取值a的概率",{"2":{"1028":1}}],["表示事件",{"2":{"1028":1}}],["表示二元标量运算符",{"2":{"1018":1}}],["表示二叉树中表示字w的从根节点到叶节点的路径上的节点数",{"2":{"709":1}}],["表示矩阵的第i行",{"2":{"998":1}}],["表示任意形状张量的元素和",{"2":{"995":1}}],["表示微分操作",{"2":{"981":1}}],["表示特征图中锚框的相对位置",{"2":{"912":1}}],["表示词w的向量",{"2":{"751":1}}],["表示不同的情感极性",{"2":{"691":1}}],["表示前提和假设",{"2":{"674":1}}],["表示为随机变量x上的分布",{"2":{"1028":1}}],["表示为p",{"2":{"1025":1,"1027":1}}],["表示为w^",{"2":{"613":1}}],["表示为",{"2":{"610":1,"1028":1,"1036":1,"1080":1}}],["表示序列开始词元",{"2":{"572":1}}],["表示序列结束词元",{"2":{"572":1}}],["表示的是卡3",{"2":{"446":1}}],["表示",{"2":{"422":1,"446":3,"479":1,"665":1,"727":1,"1060":2,"1063":1,"1076":1,"1093":1,"1143":1,"1223":1}}],["表示将加上位置编码",{"2":{"404":1}}],["表示时间步t的词",{"2":{"708":1}}],["表示时间步t的隐藏变量",{"2":{"340":1}}],["表示时间步t处",{"2":{"312":1}}],["表示学习作为机器学习的一类",{"2":{"303":1}}],["表示该片段是否包含唤醒词",{"2":{"282":1}}],["表示批量大小和通道数都是1",{"2":{"141":4}}],["表示期望风险",{"2":{"115":1}}],["表示x在第kth次迭代时的值",{"2":{"60":1}}],["音乐家很有名",{"2":{"665":1}}],["音乐家们正在为我们表演",{"2":{"665":1}}],["音乐",{"2":{"345":1}}],["音乐和新闻推荐等等",{"2":{"294":1}}],["音频和文本之间没有1",{"2":{"295":1}}],["音频帧多得多",{"2":{"295":1}}],["音频片段以及对应的是或否标签",{"2":{"282":1}}],["科学家们一直致力于研究认知神经科学领域的注意力",{"2":{"379":1}}],["科学家们习惯于将特征工程的过程与建立机器学习模型的过程分开",{"2":{"302":1}}],["科学家们感兴趣的是对",{"2":{"236":1}}],["科幻迷和喜剧爱好者的推荐结果页面可能会有很大不同",{"2":{"294":1}}],["网站",{"2":{"1529":1,"1531":1}}],["网站希望能在不将数据存储到数据库中便顺利地进行算法学习",{"2":{"1168":1}}],["网飞公司试图推荐新电影给你",{"2":{"1187":1}}],["网上有各种d版可以下载",{"2":{"1088":1}}],["网页也能跑3a游戏了",{"2":{"1540":1}}],["网页变得像app一样快",{"2":{"1540":1}}],["网页交互和逻辑",{"2":{"1539":1}}],["网页的骨架",{"2":{"1533":1}}],["网页",{"2":{"293":1,"300":1}}],["网络数据采集",{"2":{"1297":1}}],["网络的通信量等",{"2":{"1178":1}}],["网络的输出为o1",{"2":{"618":1}}],["网络的输入可能有2维",{"2":{"592":2}}],["网络结构",{"2":{"1126":1}}],["网络对应的参数就会在有数据通过的设备上初始化",{"2":{"827":1}}],["网络实例自动使用适当的gpu来计算前向传播的值",{"2":{"827":1}}],["网络初始化",{"0":{"827":1}}],["网络将以tensorflow的mlir中间表示形式构建为一个计算图",{"2":{"819":1}}],["网络就将得到优化",{"2":{"819":3}}],["网络和存储管理",{"2":{"1340":1}}],["网络和gpu",{"2":{"814":1}}],["网络和总线",{"0":{"812":1}}],["网络",{"2":{"801":1}}],["网络架构",{"0":{"641":1}}],["网络中的网络",{"0":{"493":1},"1":{"494":1,"495":1,"496":1,"497":1,"498":1},"2":{"492":1,"493":1}}],["网络输出层的偏置项不会被正则化",{"2":{"270":1}}],["网络最初收敛得更好",{"2":{"73":1}}],["搜索路径",{"2":{"1092":1}}],["搜索引擎",{"2":{"1052":1}}],["搜索引擎使用机器学习和用户行为模型来获取网页相关性得分",{"2":{"293":1}}],["搜索将沿着缓存层次结构向下寻找",{"2":{"810":1}}],["搜索结果的排序也十分重要",{"2":{"293":1}}],["搜索",{"0":{"293":1}}],["近似地监测出随机梯度下降算法在最优化代价函数中的表现",{"2":{"1167":1}}],["近似为0",{"2":{"1154":1}}],["近似训练",{"0":{"707":1},"1":{"708":1,"709":1,"710":1,"711":1}}],["近的绿色点也预测",{"2":{"1146":1}}],["近几年来",{"2":{"292":1}}],["近年来",{"2":{"198":1,"780":1,"886":1}}],["运用滑动窗口技术识别字符",{"2":{"1172":1}}],["运用步骤3中选出模型对测试集计算得出推广误差",{"2":{"1133":1}}],["运用正规方程方法求解参数",{"2":{"1085":1}}],["运用最前沿的计算机视觉的算法",{"2":{"292":1}}],["运算",{"2":{"1018":1}}],["运算符功能的神经网络",{"2":{"1102":1}}],["运算符是求幂运算",{"2":{"1018":4}}],["运算符",{"0":{"1018":1,"1217":1},"1":{"1218":1,"1219":1,"1220":1,"1221":1},"2":{"541":1,"675":1}}],["运算符prod指代了所有的这些符号",{"2":{"164":1}}],["运行不同内核的系统",{"2":{"1346":1}}],["运行器",{"0":{"1312":1}}],["运行这个costfunction",{"2":{"1111":1}}],["运行imagesc",{"2":{"1091":1}}],["运行本节中的代码",{"2":{"1024":1}}],["运行y",{"2":{"1021":1}}],["运行一些操作可能会导致为新结果分配内存",{"2":{"1021":1}}],["运行一个快速测试",{"2":{"1007":1}}],["运行a",{"2":{"1004":1}}],["运行并分析结果",{"2":{"979":1}}],["运行速度也降低到100gbit",{"2":{"812":1}}],["运行在2ghz频率",{"2":{"810":1}}],["运行此部分时是否遇到错误",{"2":{"729":1}}],["运行编码示例",{"2":{"665":1}}],["运行时引擎不知道该怎么做",{"2":{"449":1}}],["运行时间会有变化吗",{"2":{"337":1}}],["运动鞋",{"2":{"582":1}}],["林奈",{"2":{"291":1}}],["食用蘑菇造成的损失为0",{"2":{"291":1}}],["承包商花了3小时清除污水管道中的污物",{"2":{"290":1}}],["浴室数量",{"2":{"290":1,"295":1}}],["浴室的数量以及到镇中心的步行距离",{"2":{"290":1}}],["卧室数量",{"2":{"290":1,"295":1}}],["卧室的数量",{"2":{"290":1}}],["房子实际的价格是多少",{"2":{"1063":1}}],["房屋的尺寸和房间的数量",{"2":{"1082":1}}],["房屋价格",{"2":{"610":1}}],["房屋",{"2":{"608":1}}],["房屋面积",{"2":{"290":1,"295":1}}],["房价中位数超过400万美元",{"2":{"210":1}}],["房价就像股票价格一样",{"2":{"210":1}}],["房价",{"2":{"208":1}}],["房价预测",{"2":{"204":1}}],["微服务网关",{"2":{"1372":1}}],["微服务化的基础",{"2":{"1354":1}}],["微服务",{"2":{"1346":1,"1357":1}}],["微积分的另一支",{"2":{"980":1}}],["微积分",{"0":{"980":1},"1":{"981":1,"982":1,"983":1,"984":1,"985":1,"986":1}}],["微调预训练模型",{"0":{"905":1}}],["微调参数使用较小的学习率",{"2":{"875":1}}],["微调是迁移学习的常见技巧",{"2":{"875":1}}],["微调模型往往表现更好",{"2":{"874":1}}],["微调模型",{"0":{"874":1}}],["微调有助于提高模型的泛化能力",{"2":{"870":1}}],["微调包括以下四个步骤",{"2":{"870":1}}],["微调",{"0":{"869":1},"1":{"870":1,"871":1,"872":1,"873":1,"874":1,"875":1,"876":1},"2":{"870":1}}],["微调bert中所需",{"2":{"883":2}}],["微调bert的数据集",{"0":{"687":1}}],["微调bert",{"0":{"685":1,"688":1},"1":{"686":1,"687":1,"688":1,"689":1,"690":1}}],["微体系结构",{"0":{"808":1}}],["微信",{"2":{"301":1}}],["微软或facebook的首席执行官",{"2":{"290":1}}],["微分和积分是微积分的两个分支",{"2":{"985":1}}],["微分",{"2":{"198":1,"980":1}}],["谷歌+",{"2":{"1061":1}}],["谷歌新闻每天都在",{"2":{"1061":1}}],["谷歌和微软实现了学习算法来排行网页每次",{"2":{"1058":1}}],["谷歌搜索引擎背后最初的秘密武器就是这种评分系统的早期例子",{"2":{"293":1}}],["谷歌",{"2":{"290":1}}],["已成功完成作业1第1部分",{"2":{"1094":1}}],["已知宽和高的锚框是确定的",{"2":{"848":1}}],["已知凸函数f和g表明max",{"2":{"52":1}}],["已经成为软件架构的默认基座",{"2":{"1357":1}}],["已经成为构建",{"2":{"1352":1}}],["已经成为世界上最受欢迎的编程语言之一",{"2":{"1295":1}}],["已经说过了",{"2":{"1148":1}}],["已经超过了本门课程的范围",{"2":{"1111":1}}],["已经经过高度优化",{"2":{"1093":1}}],["已经收敛到局部极小值",{"2":{"1068":1}}],["已经把英语的声音从录音中分离出来了",{"2":{"1061":1}}],["已经介绍了监督学习",{"2":{"1061":1}}],["已经被除以特征图",{"2":{"912":1}}],["已经使用了半个多世纪",{"2":{"804":1}}],["已经解决了一些回归问题",{"2":{"290":1}}],["已被广泛用于预训练文本表示",{"2":{"754":1}}],["已学习",{"2":{"614":1}}],["已完成学习的模型",{"2":{"289":2}}],["估计x",{"2":{"1190":1}}],["估计xt",{"2":{"347":1}}],["估计θ",{"2":{"1190":1}}],["估计他们是你设置",{"2":{"1185":1}}],["估计值y^",{"2":{"611":1}}],["估计值μ^b和σ^b通过使用平均值和方差的噪声",{"2":{"467":1}}],["估计来抵消缩放问题",{"2":{"467":1}}],["估计图片中的物体在2010年是一项相当具有挑战性的任务",{"2":{"301":1}}],["估计未知事物的概率",{"2":{"289":1}}],["估计给定输入特征的标签",{"2":{"289":1}}],["舒张压和收缩压等",{"2":{"289":1}}],["擅长在",{"2":{"289":1}}],["真正运行容器的地方",{"2":{"1381":1}}],["真正的按需编译",{"2":{"1444":1}}],["真正的softmax被定义为realsoftmax",{"2":{"655":1}}],["真正的考试不一定百发百中",{"2":{"286":1}}],["真的没有必要来保存一个固定的数据集",{"2":{"1168":1}}],["真的是这样吗",{"2":{"485":1}}],["真",{"2":{"500":1,"737":1}}],["真实边界框是b1",{"2":{"851":1}}],["真实参数和通过训练学到的参数确实非常接近",{"2":{"605":1}}],["真实函数f",{"2":{"387":1}}],["真实值需要是多少个",{"2":{"353":1}}],["真实数据通常混合了不同的数据类型",{"2":{"214":1}}],["真实标签为j",{"2":{"192":1}}],["真实",{"2":{"191":1}}],["真实风险是从真实分布中抽取的所有数据的总体损失的预期",{"2":{"202":1}}],["真实风险",{"2":{"190":1}}],["真实的",{"2":{"105":2}}],["什么工作才是接下来应该优先考虑的问题",{"2":{"1176":1}}],["什么时候是假呢",{"2":{"1141":1}}],["什么时候我们会希望获得更多数据",{"2":{"1141":1}}],["什么时候可能比使用随机梯度下降更好",{"2":{"621":1}}],["什么类型的邮件总是被错误分类",{"2":{"1138":1}}],["什么样的词",{"2":{"1141":1}}],["什么样的尝试",{"2":{"1129":1}}],["什么样是坏的布局",{"2":{"1059":1}}],["什么是前端开发",{"0":{"1533":1}}],["什么是teleport",{"2":{"1522":1}}],["什么是hook",{"2":{"1471":1}}],["什么是异常检测呢",{"2":{"1178":1}}],["什么是非监督学习呢",{"2":{"1150":1}}],["什么是无监督学习",{"2":{"1059":1}}],["什么是机器学习",{"2":{"1058":1}}],["什么是",{"0":{"1050":1,"1296":1,"1318":1,"1374":1}}],["什么才算真正的提高呢",{"2":{"286":1}}],["什么方法效果最好",{"2":{"227":1}}],["生命周期整体分为四个阶段",{"2":{"1470":1}}],["生命周期钩子",{"2":{"1470":2}}],["生命周期",{"0":{"1470":1}}],["生命周期短暂",{"2":{"1380":1}}],["生命体征和诊断",{"2":{"284":1}}],["生态导航",{"2":{"1531":1}}],["生态成熟",{"2":{"1531":1}}],["生态完善等诸多优点",{"2":{"1526":1}}],["生态",{"2":{"1351":1}}],["生产环境",{"2":{"1393":1,"1547":1}}],["生产环境的分布式集群部署",{"2":{"1349":1}}],["生产",{"2":{"1182":1}}],["生产网络的工厂模式",{"2":{"819":4}}],["生活中有很多很多事情要处理",{"2":{"1176":1}}],["生活中的许多问题都可归类为回归问题",{"2":{"290":1}}],["生物学家们收集的大量基因数据序列",{"2":{"1058":1}}],["生物学家",{"2":{"1058":1}}],["生物学",{"0":{"619":1}}],["生物学中的注意力提示",{"0":{"355":1}}],["生成pyproject",{"2":{"1285":1}}],["生成锁定文件",{"2":{"1281":1}}],["生成器表达式",{"0":{"1247":1}}],["生成器函数",{"0":{"1246":1}}],["生成器与迭代器",{"0":{"1245":1},"1":{"1246":1,"1247":1}}],["生成调用指令",{"2":{"1052":1}}],["生成多尺度的锚框",{"2":{"963":3}}],["生成多个不同大小和宽高比的锚框并标注它们",{"2":{"939":1}}],["生成多个锚框",{"0":{"848":1}}],["生成多个缩放比和宽高比",{"2":{"847":1}}],["生成可能重叠的均匀分布的锚框",{"2":{"915":1}}],["生成了多个锚框",{"2":{"911":1}}],["生成相似但不同的训练样本",{"2":{"877":1}}],["生成相应的输出",{"2":{"422":1}}],["生成相应的标量输出",{"2":{"422":1}}],["生成锚框的所有中心点",{"2":{"848":3}}],["生成以每个像素为中心具有不同形状的锚框",{"2":{"848":3}}],["生成其周围的单词",{"2":{"787":1}}],["生成任意中心词wc",{"2":{"785":1}}],["生成任何上下文词wo",{"2":{"783":1}}],["生成中心词",{"2":{"785":1}}],["生成式预训练",{"2":{"732":1}}],["生成式对抗性网络的关键创新是用具有可微参数的任意算法代替采样器",{"2":{"300":1}}],["生成遮蔽语言模型任务的数据",{"0":{"721":1}}],["生成下一句预测任务的数据",{"0":{"720":1}}],["生成训练和测试样本",{"2":{"687":1}}],["生成大小为batch",{"2":{"600":1}}],["生成y=xw+b+噪声",{"2":{"599":2}}],["生成预测并计算损失l",{"2":{"595":1}}],["生成",{"2":{"513":1,"848":3}}],["生成输出",{"2":{"422":2}}],["生成的锚框有什么变化",{"2":{"856":1}}],["生成的小批量的平均值为0和单位方差为1",{"2":{"467":1}}],["生成的",{"2":{"341":1,"568":1}}],["生成的输出表征的维数为2×2",{"2":{"140":1}}],["生成一个面积为原始图像面积0",{"2":{"891":3}}],["生成一个随机矩阵并将其相乘",{"2":{"790":2}}],["生成一个对数几率\\t",{"2":{"495":1}}],["生成一个从0到34的序列",{"2":{"320":1}}],["生成一个二元分类训练集",{"2":{"191":1}}],["生成对抗性网络",{"2":{"296":1}}],["生成公式如下",{"2":{"271":1}}],["生成同样的图",{"2":{"268":1}}],["生成数据集",{"0":{"262":1,"386":1,"589":1,"599":1},"2":{"589":1}}],["生成越来越粗糙的映射",{"2":{"145":1}}],["毋庸置疑",{"2":{"284":1,"302":1}}],["程序结束",{"2":{"1236":1}}],["程序运行时可能出现错误",{"2":{"1236":1}}],["程序写控制语句",{"2":{"1092":1}}],["程序在处理t时的性能有所提升",{"2":{"1059":1}}],["程序在棋盘游戏围棋中击败了世界冠军",{"2":{"298":1}}],["程序通过学习后",{"2":{"1059":1}}],["程序使用symbol模块替换了ndarray模块来表示f",{"2":{"821":1}}],["程序",{"2":{"282":1}}],["获取的是组件实例对象",{"2":{"1468":1}}],["获取的是dom节点",{"2":{"1468":1}}],["获取远程分支列表",{"2":{"1330":1}}],["获取长度",{"2":{"1232":1}}],["获取路由信息",{"2":{"1208":1}}],["获取大量数据和人工数据",{"0":{"1173":1},"2":{"1193":1}}],["获取资源",{"2":{"1048":1}}],["获取数据",{"2":{"1016":1}}],["获取数据集",{"0":{"872":1}}],["获取和整理数据集",{"0":{"900":1},"1":{"901":1,"902":1}}],["获取并组织数据集",{"0":{"888":1},"1":{"889":1,"890":1}}],["获取gpu列表",{"2":{"827":3}}],["获取输入序列的词元及其片段索引",{"2":{"734":1}}],["获取遮蔽语言模型任务的数据",{"2":{"722":3}}],["获取下一句子预测任务的数据",{"2":{"722":3}}],["获取一个有趣的数据集",{"2":{"454":1}}],["获取一些数据样本",{"2":{"282":1}}],["获得ureduce和z",{"2":{"1160":1}}],["获得一个n×k维度的矩阵",{"2":{"1159":1}}],["获得参数θ时",{"2":{"1143":1}}],["获得更多的训练样本",{"2":{"1129":1,"1135":1}}],["获得了一个长度为9的矢量",{"2":{"970":1}}],["获得了更多的注意力",{"2":{"388":1}}],["获得其单独的预训练glove表示",{"2":{"713":1}}],["获得的张量形状是",{"2":{"702":3}}],["获得的结果进行比较",{"2":{"216":1}}],["获得需要送入输出层的隐状态ht∈rn×2h",{"2":{"521":1}}],["获得比初始值更好的隐状态",{"2":{"336":1}}],["获得有意义的理论保证很难",{"2":{"26":1}}],["智能推荐",{"2":{"1540":1}}],["智能检索",{"2":{"1053":1}}],["智能客服",{"2":{"1053":1}}],["智能助理",{"2":{"301":1}}],["智能的",{"2":{"299":1}}],["智能体的动作会影响后续的观察",{"2":{"298":1}}],["智能体将得到奖励",{"2":{"298":1}}],["智能体可以得到奖励1",{"2":{"298":1}}],["智能体只是得到一些奖励",{"2":{"298":1}}],["智能体接收后续观察",{"2":{"298":1}}],["智能体从环境接收一些观察",{"2":{"298":1}}],["智能体",{"2":{"298":1}}],["智能代理",{"2":{"297":1}}],["智能",{"2":{"282":1}}],["任职于美国东海岸的卡耐基梅隆大学",{"2":{"1127":1}}],["任务t是什么",{"2":{"1059":1}}],["任务规划",{"2":{"1053":1}}],["任务结果",{"2":{"1052":1}}],["任务",{"2":{"658":1}}],["任务中",{"2":{"656":1}}],["任意类型",{"2":{"1404":1}}],["任意词的中心词向量和上下文词向量在数学上是等价的",{"2":{"743":1}}],["任意上下文词wo来自该上下文窗口的被认为是由下式建模概率的事件",{"2":{"708":1}}],["任意结构的",{"2":{"296":1}}],["任意长度的序列",{"2":{"289":1}}],["任一调整参数后的程序被称为模型",{"2":{"282":1}}],["任何尝试修改这个对象的操作都会被阻止",{"2":{"1515":1}}],["任何优化算法都需要一些初始的参数",{"2":{"1125":1}}],["任何一个训练实例也都是n+1维的向量",{"2":{"1080":1}}],["任何一个训练样本的输入都会和除自己以外的所有训练样本的",{"2":{"392":1}}],["任何东西的最小的大小是0",{"2":{"1000":1}}],["任何按元素二元运算的结果都将是相同形状的张量",{"2":{"994":1}}],["任何按元素的一元运算都不会改变其操作数的形状",{"2":{"994":1}}],["任何子窗口的高度和宽度都应向上取整",{"2":{"938":1}}],["任何词元x的上下文无关表示是函数f",{"2":{"731":1}}],["任何预先存在的隐状态都会被重置为默认值",{"2":{"541":1}}],["任何继承这个encoder基类的模型将完成代码实现",{"2":{"533":1}}],["任何ht→ht+1转移",{"2":{"519":1}}],["任何有关",{"2":{"290":1}}],["任何梯度的方差不受输出数量的影响",{"2":{"249":1}}],["任何特征的增大都会导致模型输出的增大",{"2":{"230":1}}],["任何点击率预测器都需要随之逐渐变化",{"2":{"193":1}}],["任何可以很好区分的样本都应该相应地显著增加或减少权重",{"2":{"191":1}}],["任何物体几乎不可能发生在同一像素上",{"2":{"145":1}}],["任何满足于将优化视为黑盒装置",{"2":{"65":1}}],["任何不起作用的约束",{"2":{"48":1}}],["旋钮的转动可以调整程序的行为",{"2":{"282":1}}],["旋转优化问题以最小化f",{"2":{"111":1}}],["旋转",{"2":{"94":1,"1173":1}}],["明确边界",{"2":{"1544":1}}],["明确地",{"2":{"282":1}}],["明确的学习率η使我们能够控制步长来解决收敛问题",{"2":{"33":1}}],["否",{"2":{"282":1}}],["否则刷新会有404错误",{"2":{"1476":1}}],["否则报错",{"2":{"1456":1}}],["否则如果",{"2":{"1223":1}}],["否则返回0",{"2":{"1090":1}}],["否则返回cpu",{"2":{"446":4}}],["否则我会考虑使用正规化方法",{"2":{"1086":1}}],["否则我们不必担心反向传播函数或参数初始化",{"2":{"423":1}}],["否则该位置为0",{"2":{"1018":1}}],["否则不建议这种方法",{"2":{"832":1}}],["否则会遇到错误",{"2":{"829":2}}],["否则用于处理的数据将会不足",{"2":{"810":1}}],["否则为异常",{"2":{"1180":1}}],["否则为1",{"2":{"776":1}}],["否则为0",{"2":{"357":1,"776":1}}],["否则h",{"2":{"743":1}}],["否则",{"2":{"709":1,"1147":1}}],["否则选择as",{"2":{"449":1}}],["否则框架将不知道在哪里存储结果",{"2":{"447":1}}],["否则应该是1",{"2":{"325":2}}],["否则将无法在语言模型中使用它们",{"2":{"316":1}}],["否则在实践中使用此运算符不是个好主意",{"2":{"791":1}}],["否则在这本书的实验中",{"2":{"256":1}}],["否则在某一层可能会切断梯度",{"2":{"242":1}}],["否则梯度的方差可能会增大",{"2":{"247":1}}],["否则整个乘积的梯度可能会消失",{"2":{"242":1}}],["否则输出为非零",{"2":{"128":1}}],["否则可能无法很好地界定f",{"2":{"41":1}}],["唤醒词问题只是冰山一角",{"2":{"288":1}}],["唤醒词",{"2":{"282":1}}],["去标记mockjs",{"2":{"1519":1}}],["去指定组件名字",{"2":{"1454":1}}],["去跟踪你知道的那些特征",{"2":{"1156":1}}],["去看看是表现差还是表现好",{"2":{"1138":1}}],["去努力接近最低点",{"2":{"1068":1}}],["去完成这个从音频中分离出音频",{"2":{"1061":1}}],["去下上万盘的棋",{"2":{"1059":1}}],["去除了与其太过相似的其他预测边界框",{"2":{"854":1}}],["去除了当年需要两个小型gpu同时运算的设计特点",{"2":{"458":1}}],["去除包含a4或猫的真实边界框的配对",{"2":{"853":1}}],["去河岸坐下来",{"2":{"754":1}}],["去银行存点钱",{"2":{"754":1}}],["去星巴克咖啡店",{"2":{"282":1}}],["去掉了最后一层的高斯激活",{"2":{"136":1}}],["阿斯顿拿起一部iphone",{"2":{"282":1}}],["医疗记录",{"2":{"1058":1}}],["医疗诊断场景下可以这样做吗",{"2":{"638":1}}],["医疗保健和基因组学等不同领域的创新",{"2":{"281":1}}],["医学信息学和其他应用领域的许多界限",{"2":{"302":1}}],["医学诊断",{"0":{"185":1}}],["识别出第一层的形状后",{"2":{"418":1}}],["识别出该图像所包含的人",{"2":{"281":1}}],["识别唤醒词",{"2":{"282":1}}],["识别唤醒词的系统",{"2":{"282":1}}],["识别",{"2":{"282":1,"518":1}}],["识别和",{"2":{"282":1}}],["识别相邻元素间相互作用的能力",{"2":{"122":1}}],["卫星图像和一些历史天气信息",{"2":{"281":1}}],["驱动正常运行的产品和系统",{"2":{"281":1}}],["编排",{"2":{"1356":1}}],["编者注",{"2":{"1061":1,"1088":1,"1148":1,"1183":1}}],["编程式导航",{"0":{"1485":1}}],["编程中的常见进阶语法与技巧",{"2":{"1237":1}}],["编程者自己并不是个下棋高手",{"2":{"1059":1}}],["编程和符号式编程的区别如下",{"2":{"817":1}}],["编程语言",{"2":{"292":2}}],["编译模型的好处之一是我们可以将模型及其参数序列化",{"2":{"821":4}}],["编译器能够根据上下文自动推断变量的类型",{"2":{"1400":1}}],["编译器就可以释放内存",{"2":{"817":1}}],["编译器可以将上述代码优化和重写为print",{"2":{"817":1}}],["编译器和解释器",{"0":{"816":1},"1":{"817":1,"818":1,"819":1,"820":1,"821":1,"822":1,"823":1}}],["编译器基本上就是自动化地执行对齐操作",{"2":{"802":1}}],["编译需要在strategy",{"2":{"509":1}}],["编译需要在",{"2":{"488":1}}],["编码",{"0":{"1197":1},"2":{"713":1,"1519":1}}],["编码器输出的上下文变量c",{"2":{"574":1}}],["编码器通过选定的函数q",{"2":{"573":1}}],["编码器将长度可变的输入序列转换成",{"2":{"573":1}}],["编码器将长度可变的序列作为输入",{"2":{"536":1}}],["编码器最终的隐状态在每一个时间步都作为解码器的输入序列的一部分",{"2":{"572":1}}],["编码器的输出用于生成编码状态",{"2":{"535":1}}],["编码器层数",{"2":{"409":1}}],["编码器自注意力权重的形状为",{"2":{"409":1}}],["编码器和解码器的特征维度都是num",{"2":{"408":1}}],["编码器",{"0":{"407":1,"532":1,"533":1,"573":1},"1":{"533":1,"534":1,"535":1,"536":1,"537":1},"2":{"408":10,"409":2,"532":2,"533":4,"534":4,"535":7,"536":1,"537":2,"550":1,"572":1,"574":1,"576":1,"578":1,"579":2}}],["编码器有效长度",{"2":{"375":1}}],["编码器在所有时间步的最终层隐状态",{"2":{"375":1}}],["编码器隐状态ht既是键",{"2":{"374":1}}],["编写news的子路由",{"2":{"1479":1}}],["编写脚本管理系统",{"2":{"1297":1}}],["编写计算代价函数",{"2":{"1126":1}}],["编写百万个不同程序",{"2":{"1058":1}}],["编写c代码进行实验",{"2":{"815":1}}],["编写c语言来测试访问对齐的内存和未对齐的内存之间的速度是否有任何差异",{"2":{"815":1}}],["编写一个应用程序",{"2":{"281":4}}],["编写出符合业务逻辑的应用程序",{"2":{"281":1}}],["编辑和删除博客文章",{"2":{"10":1,"11":1}}],["业务逻辑",{"2":{"281":1,"1490":1}}],["紧接着应用层规范化",{"2":{"404":1}}],["紧接着",{"2":{"281":1}}],["引起的代价",{"2":{"1152":1}}],["引起了一种在机器学习中的普遍共识",{"2":{"1141":1}}],["引入mitt",{"2":{"1499":1}}],["引入storetorefs",{"2":{"1492":1}}],["引入对应的usexxxxxstore\\t",{"2":{"1490":1}}],["引入definestore用于创建store",{"2":{"1490":2,"1493":1}}],["引入createpinia",{"2":{"1489":1}}],["引入已有",{"2":{"1311":1}}],["引入了先进的数值计算的概念",{"2":{"1086":1}}],["引入x0=1",{"2":{"1080":1}}],["引入的rnnmodelscratch类来训练一个长短期记忆网络",{"2":{"560":1}}],["引入这种设计是为了缓解梯度消失问题",{"2":{"555":1}}],["引入两个概念风险和经验风险",{"2":{"99":1}}],["引言",{"0":{"281":1},"1":{"282":1,"283":1,"284":1,"285":1,"286":1,"287":1,"288":1,"289":1,"290":1,"291":1,"292":1,"293":1,"294":1,"295":1,"296":1,"297":1,"298":1,"299":1,"300":1,"301":1,"302":1,"303":1,"304":1},"2":{"1057":1,"1193":1}}],["结论",{"2":{"1465":1}}],["结语",{"0":{"1305":1}}],["结束的是",{"2":{"1092":2}}],["结束",{"2":{"1092":1}}],["结合梯度下降法",{"2":{"1068":1}}],["结合",{"2":{"1053":1}}],["结合多种图像增广方法",{"0":{"881":1}}],["结合这两种方法",{"2":{"822":1}}],["结合了这两个方面的优点",{"2":{"733":1}}],["结合前向和后向递归",{"2":{"519":1}}],["结尾的方法将参数替换",{"2":{"596":1}}],["结尾",{"2":{"278":1}}],["结果与反思",{"2":{"1546":1}}],["结果也是一样的",{"2":{"1125":1}}],["结果将是数量非常惊人的特征组合",{"2":{"1097":1}}],["结果实际上是一个随机的事件",{"2":{"1025":1}}],["结果和tf",{"2":{"995":1}}],["结果和a",{"2":{"995":2}}],["结果称为矩阵的转置",{"2":{"992":1}}],["结果有什么变化",{"2":{"868":1}}],["结果如何变化",{"2":{"856":1}}],["结果的大小等于词表的大小",{"2":{"736":1}}],["结果很明显",{"2":{"615":1}}],["结果就是只能这样像小宝宝一样一点点地挪动",{"2":{"1068":1}}],["结果就是",{"2":{"575":1}}],["结果都等于零",{"2":{"575":1}}],["结果",{"2":{"513":1}}],["结果积累的误差是依照次序的ϵ2=ϵ¯+cϵ1",{"2":{"351":1}}],["结果是2",{"2":{"1092":1}}],["结果是",{"2":{"1089":1}}],["结果是局部最优点的导数将等于零",{"2":{"1068":1}}],["结果是否与预期相同",{"2":{"1024":1}}],["结果是一个包含0",{"2":{"634":1}}],["结果是产生了在计算上不可行的表达式",{"2":{"311":1}}],["结果是累加的吗",{"2":{"178":1}}],["结果会怎么样",{"2":{"253":1}}],["结果表明",{"2":{"192":1,"264":1,"266":1,"345":1}}],["结果可以看作一个只包含原始神经元子集的网络",{"2":{"171":1}}],["留下那些确实有前途的方法",{"2":{"1129":1}}],["留下权重向量每个分量的平方和",{"2":{"270":1}}],["留意在超过了某点",{"2":{"67":1}}],["仅接收",{"2":{"1469":1}}],["仅在",{"2":{"1315":2}}],["仅是个常量",{"2":{"1143":1}}],["仅适用于那些熟悉编程语言中搜索路径概念的同学",{"2":{"1092":1}}],["仅用一节",{"2":{"1002":1}}],["仅包含一个数值被称为标量",{"2":{"989":1}}],["仅使用ea",{"2":{"734":1}}],["仅涉及正例",{"2":{"708":1}}],["仅当所有词向量都等于无穷大时",{"2":{"708":1}}],["仅当查询和键相同时",{"2":{"357":1}}],["仅与训练前损失相关的参数在微调期间不会更新",{"2":{"689":1}}],["仅有一个主要问题",{"2":{"347":1}}],["仅仅学习其使用的特征",{"2":{"1187":1}}],["仅仅因为它是机器学习中的一个重要的应用",{"2":{"1187":1}}],["仅仅基于一个样本",{"2":{"1144":1}}],["仅仅基于一个异常值",{"2":{"1144":1}}],["仅仅是为了让目标函数更容易被分析",{"2":{"1145":1}}],["仅仅是从直观上给出了正则化参数c非常大的情形",{"2":{"1144":1}}],["仅仅是作简要描述",{"2":{"1143":1}}],["仅仅是因为这个假设具有很小的训练误差",{"2":{"1130":1}}],["仅仅适用于反向传播在具有隐状态的序列模型",{"2":{"313":1}}],["仅仅拥有海量的数据是不够的",{"2":{"284":1}}],["仅仅通过简单的限制特征数量",{"2":{"269":1}}],["仅保留正元素并丢弃所有负元素",{"2":{"235":1}}],["复用代码",{"2":{"1471":1}}],["复用全连接层",{"2":{"425":4}}],["复合类型",{"0":{"1405":1}}],["复合类型和高级类型",{"2":{"1403":1}}],["复合",{"2":{"1199":1}}],["复杂度更高",{"2":{"1395":1}}],["复杂度",{"2":{"1351":1}}],["复杂度由f1向f6递增",{"2":{"500":1}}],["复杂的支持结构",{"2":{"457":1}}],["复杂模型对数据造成了过拟合",{"2":{"266":1}}],["复制到cpu",{"2":{"797":3}}],["复制到x所在显存上",{"2":{"472":2}}],["复制",{"0":{"449":1}}],["复制num",{"2":{"382":4}}],["复现之前的实验",{"2":{"81":1}}],["减法",{"2":{"1218":1}}],["减",{"2":{"1070":1,"1491":1}}],["减半输出的高和宽",{"2":{"501":1}}],["减少显式类型声明的需要",{"2":{"1400":1}}],["减少了特征的数量",{"2":{"1162":1}}],["减少n维到k维",{"2":{"1159":1}}],["减少",{"2":{"968":1}}],["减少图像上的锚框数量并不困难",{"2":{"912":1}}],["减少模型对于对象出现位置的依赖",{"2":{"877":1}}],["减少batch",{"2":{"586":1}}],["减少内部协变量偏移",{"2":{"476":1}}],["减少该模型的训练损失相对困难",{"2":{"265":1}}],["减小卷积窗口",{"2":{"461":4}}],["减去1",{"2":{"320":1}}],["减轻灾难性的损害",{"2":{"179":1}}],["减轻这些限制的方法是使用足够快的cpu缓存层次结构来为处理器提供数据",{"2":{"77":1}}],["三种方式",{"0":{"1491":1}}],["三种原色",{"2":{"158":1}}],["三个平台",{"2":{"1315":1}}],["三个权重分别为",{"2":{"1102":2}}],["三个坐标分别为θ0和θ1",{"2":{"1064":1}}],["三个电子邮件",{"2":{"1058":1}}],["三",{"0":{"1048":1,"1071":1,"1222":1,"1244":1,"1298":1,"1364":1},"1":{"1072":1,"1073":1,"1074":1,"1075":1,"1076":1,"1077":1,"1223":1,"1224":1,"1225":1,"1226":1,"1227":1,"1299":1,"1300":1,"1301":1,"1365":1},"2":{"1193":1}}],["三级缓存在多个核之间共享",{"2":{"810":1}}],["三元语法等等",{"2":{"318":1}}],["三元组可用",{"2":{"300":1}}],["三阶多项式函数拟合",{"0":{"264":1}}],["损失平面上通常包含多个最小值",{"2":{"613":1}}],["损失的总和",{"2":{"263":3}}],["损失函数较平滑",{"2":{"966":1}}],["损失函数是根据锚框的类别和偏移量的预测及标注值计算得出的",{"2":{"965":1}}],["损失函数是根据模型参数定义的",{"2":{"286":1}}],["损失函数的计算与以前的训练函数略有不同",{"2":{"767":1}}],["损失函数的标量进行",{"2":{"576":2}}],["损失函数为",{"2":{"646":1}}],["损失函数和小批量随机梯度下降优化器",{"2":{"598":1}}],["损失函数",{"0":{"220":1,"575":1,"611":1,"645":1,"925":1},"1":{"646":1,"647":1,"648":1},"2":{"588":1,"611":1,"620":1}}],["损失函数通常被称为优化问题的目标函数",{"2":{"98":1}}],["查全率与查准率的关系绘制成图表",{"2":{"1140":1}}],["查全率",{"2":{"1140":1}}],["查全率=tp",{"2":{"1139":1}}],["查准率和查全率之间的权衡",{"0":{"1140":1},"2":{"1193":1}}],["查准率=tp",{"2":{"1139":1}}],["查准率",{"2":{"1139":1,"1140":1,"1176":1}}],["查阅文档",{"0":{"1005":1},"1":{"1006":1,"1007":1,"1008":1,"1009":1}}],["查阅框架的在线api文档",{"2":{"586":1}}],["查找特定函数和类的用法",{"0":{"1007":1}}],["查找模块中的所有函数和类",{"0":{"1006":1}}],["查找标签中每个像素的类索引",{"2":{"945":1}}],["查找udp和tcp",{"2":{"815":1}}],["查看日志",{"2":{"1392":1}}],["查看",{"2":{"1392":1,"1443":1}}],["查看节点",{"2":{"1392":1}}],["查看集群信息",{"2":{"1392":1}}],["查看网络",{"2":{"1345":1}}],["查看数据卷",{"2":{"1345":1}}],["查看容器日志",{"2":{"1344":1}}],["查看运行容器",{"2":{"1343":1}}],["查看本地镜像",{"2":{"1342":1}}],["查看某行历史",{"2":{"1336":1}}],["查看所有容器",{"2":{"1343":1}}],["查看所有",{"2":{"1332":1,"1392":1}}],["查看远程仓库",{"2":{"1330":1}}],["查看分支",{"2":{"1329":1}}],["查看提交日志",{"2":{"1328":1}}],["查看状态",{"2":{"1328":1}}],["查看api的用法文档",{"2":{"1008":1}}],["查看张量ones函数的用法",{"2":{"1007":1}}],["查看word2vec论文的第四节",{"2":{"788":1}}],["查看深度学习框架文档",{"2":{"597":1}}],["查看每个块的输出形状",{"2":{"495":1}}],["查看高级api中有关batchnorm的在线文档",{"2":{"477":1}}],["查看显卡信息",{"2":{"445":1}}],["查看初始化模块文档以了解不同的初始化方法",{"2":{"439":1}}],["查看参数绑定的相关内容",{"2":{"420":1}}],["查看一下前2个样本",{"2":{"262":1}}],["查询随机数生成模块中的所有属性",{"2":{"1006":1}}],["查询设备列表",{"2":{"827":1}}],["查询张量所在的设备",{"2":{"447":1}}],["查询可用gpu的数量",{"2":{"446":1}}],["查询不会对当前位置之后的",{"2":{"409":1}}],["查询和键都来自相同的输入序列",{"2":{"409":1}}],["查询来自前一个解码器层的输出",{"2":{"404":1}}],["查询个数",{"2":{"391":6}}],["查询数",{"2":{"391":2}}],["查询或者",{"2":{"382":24}}],["查询q∈rn×d",{"2":{"370":1}}],["查询的步数",{"2":{"369":1}}],["查询的个数",{"2":{"369":8,"370":8,"382":12}}],["查询的数目",{"2":{"357":1}}],["查询",{"0":{"356":1},"2":{"293":1,"385":1,"388":1,"391":1,"397":1,"401":1,"404":2,"408":1,"1208":1}}],["查询第一个参数所在的第一个设备",{"2":{"137":1}}],["存放敏感数据",{"2":{"1385":1}}],["存放配置",{"2":{"1385":1}}],["存放完整历史记录",{"2":{"1319":1}}],["存放的是训练集中的所有价格y",{"2":{"1089":1}}],["存入ind",{"2":{"1090":1}}],["存储+读取数据",{"0":{"1490":1}}],["存储集群的元数据",{"2":{"1208":1}}],["存储集合数据",{"2":{"1198":1}}],["存储层",{"2":{"1205":1}}],["存储索引数据",{"2":{"1198":1}}],["存储引擎的职责",{"2":{"1204":1}}],["存储引擎的定位与接口",{"0":{"1204":1}}],["存储引擎",{"2":{"1194":1,"1198":1,"1203":2,"1211":1}}],["存储消费者信息",{"2":{"1061":1}}],["存储信息",{"2":{"805":1}}],["存储设备也是如此",{"2":{"803":1}}],["存储器",{"0":{"803":1},"1":{"804":1,"805":1,"806":1}}],["存储器网络",{"2":{"300":1}}],["存储",{"2":{"798":1}}],["存储每个参数的梯度",{"2":{"605":1}}],["存储模型参数还有什么实际的好处",{"2":{"444":1}}],["存储一个张量列表",{"2":{"441":1}}],["存储和访问前向传播计算所需的参数",{"2":{"423":2}}],["存储在gpu上",{"0":{"448":1}}],["存储在隐状态中的序列的历史信息",{"2":{"335":1}}],["存储在poly",{"2":{"262":1}}],["存储的中间值会被重复使用",{"2":{"312":1}}],["存在一条直线把正负样本分开",{"2":{"1144":1}}],["存在一些参数集",{"2":{"500":1}}],["存在着鸿沟",{"2":{"1059":1}}],["存在着明显更先进的证明技术",{"2":{"115":1}}],["存在",{"2":{"981":1}}],["存在某个常量标量k",{"2":{"977":1}}],["存在α∈",{"2":{"46":1}}],["存在x",{"2":{"44":1}}],["互为线性函数",{"2":{"1086":1}}],["互联设备以及数字化经济带来的海量数据集",{"2":{"260":1}}],["互相关和卷积",{"0":{"130":1}}],["互相关运算",{"0":{"126":1},"2":{"126":1,"130":1}}],["过渡类名",{"2":{"1525":2}}],["过渡层",{"0":{"481":1},"2":{"481":1}}],["过滤掉高度比宽度更大的区域",{"2":{"1172":1}}],["过滤掉出现不到5次的单词",{"2":{"693":1}}],["过大",{"2":{"1115":1}}],["过于强调拟合原始数据",{"2":{"1114":1}}],["过往违约次数和其他因素相对应",{"2":{"990":1}}],["过这种方式",{"2":{"849":1}}],["过度填充任务队列可能会导致内存消耗过多",{"2":{"793":1}}],["过程是与上面类似的",{"2":{"1156":1}}],["过程代码应该看起来非常眼熟",{"2":{"635":1}}],["过程与",{"2":{"509":1}}],["过拟合的情况下",{"2":{"1134":1}}],["过拟合的问题",{"0":{"1114":1},"2":{"1193":1}}],["过拟合是指训练误差远小于验证误差",{"2":{"267":1}}],["过拟合",{"0":{"266":1},"2":{"260":1,"1132":1,"1133":1,"1134":1}}],["过拟合并不总是一件坏事",{"2":{"258":1}}],["过去用得比较多",{"2":{"1141":1}}],["过去我一直尝试用不同的编程语言来教授机器学习",{"2":{"1088":1}}],["过去式",{"2":{"751":1}}],["过去的招聘决策数据",{"2":{"284":1}}],["过去的值",{"2":{"35":1}}],["过去",{"2":{"86":1}}],["欠拟合的情况下",{"2":{"1134":1}}],["欠拟合是指模型无法继续减少训练误差",{"2":{"267":1}}],["欠拟合",{"0":{"265":1},"2":{"1114":1,"1132":1,"1133":1,"1134":1}}],["欠拟合还是过拟合",{"0":{"258":1},"1":{"259":1,"260":1}}],["欠拟合和过拟合",{"0":{"251":1},"1":{"252":1,"253":1,"254":1,"255":1,"256":1,"257":1,"258":1,"259":1,"260":1,"261":1,"262":1,"263":1,"264":1,"265":1,"266":1,"267":1,"268":1}}],["欠拟合和模型选择",{"2":{"204":1}}],["又或者你在尝试预测的事情",{"2":{"1168":1}}],["又或者在交叉验证集中",{"2":{"1143":1}}],["又或者患者住院的天数",{"2":{"639":1}}],["又向右了一点",{"2":{"1127":1}}],["又称畸变函数",{"2":{"1152":1}}],["又称标量",{"2":{"1120":1}}],["又称为正则化参数",{"2":{"1115":1}}],["又",{"2":{"1108":1}}],["又有一个数值的评估数据",{"2":{"1138":1}}],["又有哪些具体区别呢",{"2":{"1086":1}}],["又有时",{"2":{"255":1}}],["又越过一次",{"2":{"1068":1}}],["又用于预测这些锚框的类别和偏移量",{"2":{"959":1}}],["又在",{"2":{"840":1}}],["又会如何呢",{"2":{"318":1}}],["又关系到它们最初的演变方式",{"2":{"66":1}}],["坚持更切实的问题",{"2":{"254":1}}],["决策推理",{"2":{"1052":1}}],["决策树",{"2":{"299":1}}],["决策树与线性模型",{"2":{"255":1}}],["决策树与神经网络",{"2":{"254":1}}],["决定飞行员的能力",{"2":{"1156":1}}],["决定是增加更多数据",{"2":{"1138":1}}],["决定是否分配真实边界框",{"2":{"851":3}}],["决定下一步做什么",{"0":{"1129":1,"1135":1},"2":{"1193":2}}],["决定的",{"2":{"1100":1}}],["决定以何种方式调整参数需要一点微积分知识",{"2":{"987":1}}],["决定哪些行为是值得奖励的",{"2":{"298":1}}],["决定",{"2":{"282":1}}],["决定目标函数能否收敛到局部最小值",{"2":{"55":1}}],["语句的句法结构",{"2":{"1092":1}}],["语句和",{"2":{"1092":1}}],["语句也就此中止",{"2":{"1092":1}}],["语句",{"0":{"1251":1},"1":{"1252":1},"2":{"1092":5,"1227":1}}],["语句比较熟悉",{"2":{"1092":1}}],["语料库是一个比较流行的自然语言推断基准数据集",{"2":{"670":1}}],["语料库中不存在或已删除的任何词元都将映射到一个特定的未知词元",{"2":{"363":1}}],["语义分割的一个重要的数据集叫做pascal",{"2":{"950":1}}],["语义分割通过将图像划分为属于不同语义类别的区域",{"2":{"950":1}}],["语义分割数据集",{"0":{"945":1},"1":{"946":1,"947":1,"948":1,"949":1}}],["语义分割标注的像素级的边框显然更加精细",{"2":{"943":1}}],["语义分割可以识别并理解图像中每一个像素的内容",{"2":{"943":1}}],["语义分割和数据集",{"0":{"943":1},"1":{"944":1,"945":1,"946":1,"947":1,"948":1,"949":1,"950":1,"951":1}}],["语义分割",{"2":{"886":1}}],["语义分割是对图像中的每个像素分类",{"2":{"861":1}}],["语义角色标注",{"2":{"731":1}}],["语义等价",{"2":{"658":1}}],["语义文本相似度是一个流行的",{"2":{"658":1}}],["语音和强化学习领域",{"2":{"379":1,"403":1}}],["语音",{"2":{"345":1}}],["语音识别",{"2":{"302":1}}],["语音识别系统就自动触发语音转文字功能",{"2":{"282":1}}],["语音识别和语言翻译",{"2":{"253":1}}],["语言可以使用",{"2":{"1111":1}}],["语言可接受性语料库",{"2":{"657":1}}],["语言建模只揭示了序列学习能力的冰山一角",{"2":{"550":1}}],["语言模型使用左侧的上下文预测词元",{"2":{"736":1}}],["语言模型的输出将被送到一个附加的线性输出层",{"2":{"732":1}}],["语言模型增强的序列标记器",{"2":{"731":1}}],["语言模型中的",{"2":{"568":1}}],["语言模型是自然语言处理的关键",{"2":{"322":1,"564":1}}],["语言模型依然是非常有用的",{"2":{"315":1}}],["语言模型",{"2":{"315":1}}],["语言模型和数据集",{"0":{"315":1},"1":{"316":1,"317":1,"318":1,"319":1,"320":1,"321":1,"322":1,"323":1}}],["语言也是如此",{"2":{"295":1}}],["语法风格",{"2":{"1530":1}}],["语法如下",{"2":{"1459":1}}],["语法糖",{"0":{"1454":1}}],["语法贴近英语",{"2":{"1299":1}}],["语法简洁",{"2":{"1296":1}}],["语法",{"2":{"147":1,"1455":1,"1456":1}}],["抽象属性访问器",{"2":{"1416":1}}],["抽象方法",{"2":{"1416":1,"1417":1}}],["抽象类的高级用法",{"0":{"1417":1}}],["抽象类是不能被直接实例化的类",{"2":{"1415":1}}],["抽象类",{"0":{"1415":1},"1":{"1416":1,"1417":1}}],["抽象来看",{"2":{"970":1}}],["抽取图像特征",{"0":{"920":1}}],["抽取的第2个样本和第3个样本的相关性",{"2":{"253":1}}],["抽取的数据",{"2":{"191":2}}],["抽取的所有数据的总体损失的期望值",{"2":{"190":1}}],["抽样过程可能与时间有关",{"2":{"253":1}}],["格式",{"2":{"1196":1}}],["格式进行传输",{"2":{"1044":1}}],["格式转换成matplotlib格式",{"2":{"858":1}}],["格拉姆矩阵的高和宽皆为通道数c",{"2":{"923":1}}],["格拉姆矩阵中的元素容易出现较大的值",{"2":{"923":1}}],["格林先生",{"2":{"518":1}}],["格里文科和坎特利推导出了训练误差收敛到泛化误差的速率",{"2":{"253":1}}],["格什戈林的定理告诉了我们什么",{"2":{"31":1}}],["类实现多个接口",{"2":{"1422":1}}],["类实现接口",{"2":{"1422":1}}],["类接口",{"0":{"1422":1}}],["类方法",{"2":{"1254":1}}],["类方法与静态方法",{"0":{"1254":1}}],["类与对象进阶",{"0":{"1253":1},"1":{"1254":1,"1255":1}}],["类偏斜情况表现为我们的训练集中有非常多的同一种类的样本",{"2":{"1139":1}}],["类偏斜的误差度量",{"0":{"1139":1},"2":{"1193":1}}],["类型别名",{"0":{"1412":1}}],["类型总览",{"0":{"1403":1},"1":{"1404":1,"1405":1}}],["类型推断",{"0":{"1400":1},"1":{"1401":1,"1402":1},"2":{"1430":1}}],["类型断言",{"0":{"1399":1}}],["类型声明是",{"2":{"1397":1}}],["类型声明",{"0":{"1397":1},"1":{"1398":1,"1399":1}}],["类型注解",{"0":{"1259":1}}],["类型转换函数",{"2":{"1232":1}}],["类型",{"2":{"1216":1,"1304":1,"1365":1,"1384":1,"1401":3,"1402":1,"1426":1,"1433":2}}],["类型的总样本数比例的和",{"2":{"1154":1}}],["类型1设定为正类",{"2":{"1112":1}}],["类型2和类型3定为负类",{"2":{"1112":1}}],["类或语句保存在d2l包中",{"2":{"981":1}}],["类比",{"2":{"751":1,"1318":1,"1321":1,"1322":1}}],["类构造函数中的变量num",{"2":{"668":1}}],["类的学习任务",{"2":{"572":1}}],["类的成员",{"2":{"424":1}}],["类的成员变量",{"2":{"424":1}}],["类f1⊆",{"2":{"500":1}}],["类",{"2":{"500":1,"1304":1}}],["类别预测输出中的通道数分别为5×",{"2":{"956":1}}],["类别预测层使用一个保持输入高和宽的卷积层",{"2":{"954":1}}],["类别预测层",{"0":{"954":1}}],["类别对应的分量设置为1",{"2":{"640":1}}],["类别",{"2":{"639":1,"876":1,"890":1,"932":3}}],["类别感兴趣",{"2":{"639":1}}],["类别1",{"2":{"252":1}}],["类别0",{"2":{"252":1}}],["类似node的nvm",{"2":{"1291":1}}],["类似",{"2":{"1196":1,"1216":1,"1516":1}}],["类似于vue2",{"2":{"1471":1}}],["类似于召回率",{"2":{"1154":1}}],["类似于精确率",{"2":{"1154":1}}],["类似于参数较多的情况",{"2":{"1135":1}}],["类似于参数较少的情况",{"2":{"1135":1}}],["类似于向量的l2范数",{"2":{"1000":1}}],["类似于masks",{"2":{"776":1}}],["类似于语言模型",{"2":{"575":1}}],["类似于",{"2":{"572":1}}],["类似于resnet使用的4个残差块",{"2":{"482":1}}],["类似于处理器如何修改用于计算的存储器",{"2":{"300":1}}],["类似的",{"2":{"1127":1}}],["类似的应用也会出现在零售产品",{"2":{"294":1}}],["类似的推理表明",{"2":{"116":1}}],["类似地第我们选择另一个类标记为正向类",{"2":{"1112":1}}],["类似地使用",{"2":{"321":1}}],["类似地",{"2":{"252":1,"451":1,"555":1,"700":1,"727":1,"1089":2,"1144":2,"1145":2}}],["类似狭窄的峡谷",{"2":{"86":1}}],["未知",{"2":{"772":1}}],["未知词元的索引为0",{"2":{"363":2}}],["未知词元类型",{"2":{"362":1}}],["未包含在训练数据中的",{"2":{"614":1}}],["未来你也能成为网页魔法师",{"2":{"1541":1}}],["未来",{"2":{"1357":1}}],["未来我会在这个博客中陆续分享",{"2":{"1305":1}}],["未来遇到的异常可能与已掌握的异常",{"2":{"1182":1}}],["未来遇到的正向类实例可能与训练集中的非常近似",{"2":{"1182":1}}],["未来还希望探索多人协作",{"2":{"1054":1}}],["未来24小时的天气预报往往相当准确",{"2":{"351":1}}],["未来的前端",{"0":{"1540":1}}],["未来的事件不能影响过去",{"2":{"349":1}}],["未来的数据是否总是与过去相似",{"2":{"297":1}}],["未曾在训练集中出现的数据样本构成",{"2":{"252":1}}],["未丢弃",{"2":{"170":1}}],["才考虑采用主要成分分析",{"2":{"1162":1}}],["才等于0",{"2":{"1144":1}}],["才是合适的",{"2":{"1141":1}}],["才是有意义的",{"2":{"1129":1}}],["才足以真正运行起大规模的神经网络",{"2":{"1098":1}}],["才找到计算多边形面积的方法",{"2":{"980":1}}],["才将bj分配给ai",{"2":{"851":1}}],["才会有这条白色的区段出现在整条灰色区域之中",{"2":{"1127":1}}],["才会访问二级缓存中的内容",{"2":{"810":1}}],["才会作出有效的预测",{"2":{"251":1}}],["才有了批量规范化的名称",{"2":{"467":1}}],["才能被支持向量机的优化软件正确处理",{"2":{"1148":1}}],["才能决定你的方式来构建你的系统",{"2":{"1059":1}}],["才能使函数正常工作",{"2":{"835":1}}],["才能使其在学习率方面的衰减不那么激进",{"2":{"31":1}}],["才能显著优于基于凸优化的传统方法",{"2":{"456":1}}],["我都想试",{"2":{"1542":1}}],["我是",{"2":{"1542":1}}],["我是该用这个算法还是改用那个算法",{"2":{"1148":1}}],["我最近在折腾啥",{"0":{"1543":1}}],["我最常听到的答案是推荐系统",{"2":{"1187":1}}],["我最多只会花一天的时间",{"2":{"1138":1}}],["我常问他们",{"2":{"1187":1}}],["我常和工作在这儿致力于机器学习应用的人们聊天",{"2":{"1187":1}}],["我偶尔访问硅谷不同的技术公司",{"2":{"1187":1}}],["我偶尔会问你一个问题",{"2":{"1059":1}}],["我如何尝试估计我的参数",{"2":{"1185":1}}],["我衷心地希望你们能从这门课中有所收获",{"2":{"1176":1}}],["我对你们表示衷心的感谢",{"2":{"1176":1}}],["我深知要坚持学完这门课是很需要花一些时间的",{"2":{"1176":1}}],["我更希望你现在不仅仅只是认识这些工具",{"2":{"1176":1}}],["我更喜欢将分类从",{"2":{"1112":1}}],["我谈论pca作为压缩算法",{"2":{"1161":1}}],["我谈到了绘制成本函数j",{"2":{"1091":1}}],["我绘制两个在这里",{"2":{"1156":1}}],["我实际上还在研究如何利用聚类算法了解星系的形成",{"2":{"1150":1}}],["我实际上是取出了",{"2":{"1089":1}}],["我曾经列举过一些应用",{"2":{"1150":1}}],["我曾简单的介绍过非监督学习",{"2":{"1150":1}}],["我曾告诫大家不要盲目地开始",{"2":{"1141":1}}],["我正好用得最多的两个是liblinear和libsvm",{"2":{"1148":1}}],["我正在构建以下类型的",{"2":{"1054":1}}],["我真的不建议你自己写软件来求解参数θ",{"2":{"1148":1}}],["我做同样的投影",{"2":{"1145":1}}],["我做一点简化",{"2":{"1145":1}}],["我接下来忽略掉截距",{"2":{"1145":1}}],["我接下来会考虑一个特例",{"2":{"1144":1}}],["我称这条红线的长度为p",{"2":{"1145":1}}],["我称之为cost1",{"2":{"1143":1}}],["我刚刚画的这个向量的长度就知道了",{"2":{"1145":1}}],["我记得我将其设置为了100000",{"2":{"1144":1}}],["我记得他",{"2":{"251":1}}],["我觉得关键的测试",{"2":{"1141":1}}],["我么将通过确保有一个具有很多参数的学习算法来解决",{"2":{"1141":1}}],["我应该选什么词来填空",{"2":{"1141":1}}],["我应该从什么方向迈着小碎步下山",{"2":{"1067":1}}],["我认识的两位研究人员michele",{"2":{"1141":1}}],["我认为",{"2":{"1187":1}}],["我认为你会很好地建立很有技术的状态",{"2":{"1148":1}}],["我认为你们的时间",{"2":{"1061":1}}],["我认为从技术上讲",{"2":{"1111":1}}],["我认为对你来讲",{"2":{"1089":1}}],["我认为经验e",{"2":{"1059":1}}],["我提到了误差分析",{"2":{"1139":1}}],["我几乎从未见过人们这样做",{"2":{"1138":1}}],["我总是推荐你实现一个较为简单快速",{"2":{"1138":1}}],["我经常会做的是尝试手动地创建",{"2":{"1148":1}}],["我经常使用学习曲线来判断某一个学习算法是否处于偏差",{"2":{"1134":1}}],["我经常看到进行大规模的机器学习项目的人",{"2":{"1088":1}}],["我首先介绍怎样评估机器学习算法的性能",{"2":{"1129":1}}],["我很遗憾不止一次地看到很多人花了至少六个月时间来完成他们随便选择的一种方法",{"2":{"1129":1}}],["我看到好多人花费了好多时间想收集更多的训练样本",{"2":{"1129":1}}],["我必须指出这些算法实现得好或不好是有区别的",{"2":{"1111":1}}],["我必须说",{"2":{"1061":1}}],["我过去使用这些算法已经很长一段时间了",{"2":{"1111":1}}],["我通常也把同样的方法用在逻辑回归中",{"2":{"1110":1}}],["我通常使用标准方程法",{"2":{"1085":1}}],["我打算把θ看做一个向量",{"2":{"1093":1}}],["我把它们放在一起是有原因的",{"2":{"1148":1}}],["我把它写在这里",{"2":{"1110":1}}],["我把我的矩阵设置为x",{"2":{"1092":1}}],["我把你看作是机器学习研究员",{"2":{"1061":1}}],["我来给大家演示一下一个更复杂一点的函数的例子",{"2":{"1092":1}}],["我建议你用写字板或者其他可以编辑函数的文本编辑器",{"2":{"1092":1}}],["我建议在这门课中用octave来写程序",{"2":{"1088":1}}],["我只是用θ0",{"2":{"1093":1}}],["我只是想建议你",{"2":{"1092":1}}],["我只需要输入plot",{"2":{"1091":1}}],["我只需要会用help函数就可以了",{"2":{"1090":1}}],["我只需键入a×c",{"2":{"1090":1}}],["我使用的是微软的写字板程序来打开这个文件",{"2":{"1092":1}}],["我使用函数hold",{"2":{"1091":1}}],["我让",{"2":{"1092":1}}],["我先画出将要用的代价函数",{"2":{"1143":1}}],["我先告诉你如何使用",{"2":{"1092":1}}],["我先来介绍鸡尾酒宴问题",{"2":{"1061":1}}],["我发现绘制数据",{"2":{"1091":1}}],["我发现当使用像octave这样的高级语言时",{"2":{"1088":1}}],["我就可以用",{"2":{"1090":1}}],["我用",{"2":{"1143":1,"1295":1}}],["我用3种不同的符号来代表3个类别",{"2":{"1112":1}}],["我用了一个",{"2":{"1090":1}}],["我用不同的符号来表示良性和恶性肿瘤",{"2":{"1060":1}}],["我现在删掉这里的λ",{"2":{"1143":1}}],["我现在可以按如下步骤提交代码",{"2":{"1094":1}}],["我现在已经取出了向量的前五个元素",{"2":{"1092":1}}],["我现在使用第一个格子",{"2":{"1091":1}}],["我现在绘制y2",{"2":{"1091":1}}],["我现在快速地初始化一些变量",{"2":{"1090":1}}],["我现在告诉你们另一种",{"2":{"1061":1}}],["我键入",{"2":{"1092":1}}],["我键入了这个命令以后",{"2":{"1089":1}}],["我键入a",{"2":{"1089":1}}],["我又重新读取了变量",{"2":{"1089":1}}],["我也尽可能挤出时间听一些课",{"2":{"1176":1}}],["我也想告诉大家",{"2":{"1176":1}}],["我也想这个比0小很多",{"2":{"1144":1}}],["我也将这一项替换为cost0",{"2":{"1143":1}}],["我也会对监督学习算法进行简要的总结",{"2":{"1143":1}}],["我也经常感觉自己对反向传播算法的理解并不是十分深入",{"2":{"1122":1}}],["我也可以键入a",{"2":{"1089":1}}],["我也可以建立一个集合v并用命令",{"2":{"1088":1}}],["我也见过有人用",{"2":{"1088":1}}],["我可以将它们画在这个图上",{"2":{"1145":1}}],["我可以新建一个矩阵",{"2":{"1089":1}}],["我可以取",{"2":{"1089":1}}],["我可以把路径改为c",{"2":{"1089":1}}],["我可以写",{"2":{"1088":1}}],["我可以吃半头猪",{"2":{"518":1}}],["我再设一个",{"2":{"1089":1}}],["我再给你展示几个例子",{"2":{"1089":1}}],["我再进行一步梯度下降时",{"2":{"1068":1}}],["我再举另外一个监督学习的例子",{"2":{"1060":1}}],["我自然会用一个稍微跟刚才在那个品红点时比",{"2":{"1068":1}}],["我花了很长一段时间才理解这个问题",{"2":{"1068":1}}],["我还想再多说一点",{"2":{"1176":1}}],["我还可以使用函数colorbar",{"2":{"1091":1}}],["我还可以写",{"2":{"1090":1}}],["我还可以用",{"2":{"1090":1}}],["我还可以设c",{"2":{"1089":1}}],["我还是会建议你直接使用一个软件库",{"2":{"1111":1}}],["我还是把",{"2":{"1089":1}}],["我还是要告诉你们这一点一定要相信我",{"2":{"1061":1}}],["我还有一个问题",{"2":{"1068":1}}],["我得到的新的θ1",{"2":{"1068":1}}],["我的技术口味",{"0":{"1544":1}}],["我的死心塌地",{"2":{"1490":1}}],["我的样本x",{"2":{"1145":1}}],["我的第二个训练样本",{"2":{"1145":1}}],["我的意思是如果我们将向量θ写出来",{"2":{"1145":1}}],["我的意思是",{"2":{"1144":1}}],["我的意思是不管是在训练集中或是在测试集中",{"2":{"1143":1}}],["我的意思是说",{"2":{"1138":1,"1145":1}}],["我的意思是在这个等式中",{"2":{"1067":1}}],["我的桌面上就有了",{"2":{"1089":1}}],["我的桌面上有两个文件",{"2":{"1089":1}}],["我的导数项是更小的",{"2":{"1068":1}}],["我的导数越来越接近零",{"2":{"1068":1}}],["我的探索方向",{"0":{"1054":1}}],["我要稍微转换一下",{"2":{"1141":1}}],["我要定义用来拟合参数的优化目标或者叫代价函数",{"2":{"1109":1}}],["我要定义可能是最常见一种机器学习问题",{"2":{"1060":1}}],["我要给你展示假设函数的表达式",{"2":{"1107":1}}],["我要提交第一部分",{"2":{"1094":1}}],["我要在这里目录下键入submit",{"2":{"1094":1}}],["我要把θ看作一个向量",{"2":{"1093":1}}],["我要设$",{"2":{"1092":1}}],["我要将",{"2":{"1092":1}}],["我要以不同的颜色绘制余弦函数",{"2":{"1091":1}}],["我要做的就是",{"2":{"1091":1}}],["我要根据不同房屋尺寸所售出的价格",{"2":{"1063":1}}],["我在本节中没有讲解",{"2":{"1144":1}}],["我在桌面上存了一个预先定义的文件名为",{"2":{"1092":1}}],["我在更早一点的时间讲过",{"2":{"1061":1}}],["我在斯坦福大学的同事同时也是这样",{"2":{"1058":1}}],["我知道你们很多人在这门课中都非常努力",{"2":{"1176":1}}],["我知道你也许想知道求解上一页幻灯片中的优化问题为什么会产生这个结果",{"2":{"1144":1}}],["我知道我还没有解释这一点",{"2":{"1144":1}}],["我知道",{"2":{"1061":1,"1176":2}}],["我已经写了出来但没有真正定义",{"2":{"1067":1}}],["我已经见过很多人这样做了",{"2":{"1061":1}}],["我已经见到",{"2":{"1061":1}}],["我已经在无人直升机领域工作了许多年",{"2":{"1058":1}}],["我不会建议你们编写自己的代码来计算数据的平方根",{"2":{"1111":1}}],["我不打算解释为什么你需要同时更新",{"2":{"1067":1}}],["我不是说这个是简单的问题",{"2":{"1061":1}}],["我不知道谁是什么类型",{"2":{"1061":1}}],["我不知道数据里面有什么",{"2":{"1061":1}}],["我有一组样本x",{"2":{"1185":1}}],["我有一个朋友正在研究这个问题",{"2":{"1150":1}}],["我有一个正样本在这里",{"2":{"1145":1}}],["我有一个数据集",{"2":{"1092":1}}],["我有时用一个巧妙的方法来可视化矩阵",{"2":{"1091":1}}],["我有个简短的复习题给你们",{"2":{"1061":1}}],["我有些朋友在大数据中心工作",{"2":{"1061":1}}],["我有5个良性肿瘤样本",{"2":{"1060":1}}],["我没法提前知道哪些是哪些",{"2":{"1061":1}}],["我没有写下这两种和右边的三种特征",{"2":{"1060":1}}],["我甚至不知道人们有哪些不同的类型",{"2":{"1061":1}}],["我列举了总共5种不同的特征",{"2":{"1060":1}}],["我朋友研究这个问题时",{"2":{"1060":1}}],["我标出1和0表示是或者不是恶性肿瘤",{"2":{"1060":1}}],["我和一些朋友之前研究过这个",{"2":{"1060":1}}],["我将要做的是",{"2":{"1191":2}}],["我将要做的是仅仅除去1",{"2":{"1143":1}}],["我将应用高斯分布开发异常检测算法",{"2":{"1180":1}}],["我将向大家介绍异常检测",{"2":{"1178":1}}],["我将向你介绍一些实用的建议和指导",{"2":{"1129":1}}],["我将向你们介绍神经网络",{"2":{"1098":1}}],["我将不会做全部的推导",{"2":{"1145":1}}],["我将θ1​画在横轴这里",{"2":{"1145":1}}],["我将特征数n置为2",{"2":{"1145":1}}],["我将它画成粉色",{"2":{"1145":1}}],["我将它画成红色",{"2":{"1145":1}}],["我将它称为p",{"2":{"1145":1}}],["我将它写下来",{"2":{"1145":1}}],["我将它们写在这里",{"2":{"1145":1}}],["我将略述这些问题背后的数学原理",{"2":{"1144":1}}],["我将会从直观上略述为什么这个优化问题会产生大间距分类器",{"2":{"1144":1}}],["我将会从逻辑回归开始展示我们如何一点一点修改来得到本质上的支持向量机",{"2":{"1143":1}}],["我将目标函数乘上一个常量m",{"2":{"1143":1}}],["我将用z",{"2":{"1143":1}}],["我将把这些算法想象成低偏差算法",{"2":{"1141":1}}],["我将告诉你应该怎么做",{"2":{"1140":1}}],["我将告诉你怎样在octave中",{"2":{"1091":1}}],["我将谈到机器学习系统的设计",{"2":{"1137":1}}],["我将先来介绍如何评价你的学习算法",{"2":{"1129":1}}],["我将开始介绍聚类算法",{"2":{"1150":1}}],["我将开始介绍如何在",{"2":{"1089":1}}],["我将开始讨论这些方法",{"2":{"1129":1}}],["我将重点关注的问题是假如你在开发一个机器学习系统",{"2":{"1129":1}}],["我将为你解释什么是过度拟合问题",{"2":{"1114":1}}],["我将介绍高斯分布",{"2":{"1179":1}}],["我将介绍一些大间隔分类背后的数学原理",{"2":{"1145":1}}],["我将介绍一些诊断法",{"2":{"1129":1}}],["我将介绍其中的含义",{"2":{"1144":1}}],["我将介绍有关向量化的内容",{"2":{"1093":1}}],["我将介绍如何对数据进行运算",{"2":{"1090":1}}],["我将教你一种编程语言",{"2":{"1088":1}}],["我将选择最初的使用规则h代表hypothesis",{"2":{"1063":1}}],["我将在整个课程中用小写的m来表示训练样本的数目",{"2":{"1063":1}}],["我将在后面正式定义监督学习",{"2":{"1060":1}}],["我将持续记录自己在",{"2":{"1056":1}}],["我本来可以在六个月前就告诉他们",{"2":{"1059":1}}],["我想讨论推荐系统地第二个原因是",{"2":{"1187":1}}],["我想讲推荐系统有两个原因",{"2":{"1187":1}}],["我想讲一下推荐系统",{"2":{"1187":1}}],["我想讲最后一点",{"2":{"1144":1}}],["我想我的样本来自一个多元高斯分布",{"2":{"1185":1}}],["我想快速地回顾一下这门课的主要内容",{"2":{"1176":1}}],["我想快速地向你介绍一个细节的实现过程",{"2":{"1123":1}}],["我想谈一谈关于如何选择k",{"2":{"1161":1}}],["我想开始谈论第二种类型的无监督学习问题",{"2":{"1156":1}}],["我想更深入地探讨一下有关偏差和方差的问题",{"2":{"1132":1}}],["我想更加深入地讨论一下反向传播算法的这些复杂的步骤",{"2":{"1122":1}}],["我想仍然使用预测房价的学习例子",{"2":{"1129":1}}],["我想做的是确保你在设计机器学习的系统时",{"2":{"1129":1}}],["我想做的事是定义一个",{"2":{"1092":1}}],["我想向你介绍一个具有历史意义的神经网络学习的重要例子",{"2":{"1127":1}}],["我想通过一个叫做",{"2":{"1112":1}}],["我想要告诉你如何修改你已经知道的逻辑回归算法",{"2":{"1111":1}}],["我想很快地介绍一下这门课程做作业的流程",{"2":{"1094":1}}],["我想返回一个值",{"2":{"1092":1}}],["我想返回一个",{"2":{"1092":1}}],["我想告诉你们一些神经网络的背景知识",{"2":{"1098":1}}],["我想告诉你怎样为你的",{"2":{"1092":1}}],["我想告诉你一些octave的工具来绘制和可视化你的数据",{"2":{"1091":1}}],["我想算两个矩阵的乘积",{"2":{"1090":1}}],["我想在这里来讨论它",{"2":{"1086":1}}],["我想找到它的最小值",{"2":{"1068":1}}],["我想",{"2":{"1061":1}}],["我想说",{"2":{"1059":1}}],["我想吃",{"2":{"315":1}}],["我想吃奶奶",{"2":{"315":1}}],["我喜欢把这比喻成学习当木匠",{"2":{"1059":1}}],["我非常注重这部分内容",{"2":{"1059":1}}],["我会收取$20之类的",{"2":{"1168":1}}],["我会收取$50来运输你的包裹",{"2":{"1168":1}}],["我会发现",{"2":{"1145":1}}],["我会花许多时间来讲解它",{"2":{"1143":1}}],["我会探讨这一算法",{"2":{"1143":1}}],["我会在这个视频里讲到这些条件是什么",{"2":{"1141":1}}],["我会在接下来的两个视频中给出它们的定义",{"2":{"1059":1}}],["我会看一看我的交叉验证数据集",{"2":{"1138":1}}],["我会告诉你怎样用一个更加系统性的方法",{"2":{"1137":1}}],["我会告诉你可视化技术是什么",{"2":{"1127":1}}],["我会选择这些高级算法",{"2":{"1111":1}}],["我会教你们一些高级优化算法和一些高级的优化概念",{"2":{"1111":1}}],["我会教你们一点关于如何使用octave的知识",{"2":{"1061":1}}],["我会讲解一下向量化",{"2":{"1092":1}}],["我会非常迅速地告诉你",{"2":{"1090":1}}],["我会删除些",{"2":{"1086":1}}],["我会建议你这么做",{"2":{"1086":1}}],["我会讨论什么是矩阵和向量",{"2":{"1070":1}}],["我会快速地回顾你将用到的线性代数知识",{"2":{"1070":1}}],["我会对线性代数进行一个快速的复习回顾",{"2":{"1070":1}}],["我会把它看成一个实数",{"2":{"1060":1}}],["我会定义什么是监督学习",{"2":{"1059":1}}],["我会具体介绍这两种学习算法",{"2":{"1059":1}}],["我会给出这些术语的定义",{"2":{"1059":1}}],["我希望",{"2":{"1144":1}}],["我希望这几节中提到的一些技巧",{"2":{"1135":1}}],["我希望你们中的很多人都能在相应的领域",{"2":{"1176":1}}],["我希望你们从这个幻灯片中学到的主要内容是",{"2":{"1111":1}}],["我希望你都能答对",{"2":{"1094":1}}],["我希望你能更好地理解这些代价函数$",{"2":{"1066":1}}],["我希望步骤是有逻辑的",{"2":{"1093":1}}],["我希望能帮你成为最优秀的人才",{"2":{"1059":1}}],["我希望能告诉你们很多机器学习的知识",{"2":{"1058":1}}],["我希望教你有关各种不同类型的学习算法",{"2":{"1059":1}}],["我从事于机器学习",{"2":{"1058":1}}],["我感到激动的原因之一是有一天做出一个和人类一样聪明的机器",{"2":{"1058":1}}],["我去河岸边坐下",{"2":{"732":1}}],["我去银行存现金",{"2":{"732":1}}],["我累了",{"2":{"674":1}}],["我确实需要睡眠",{"2":{"674":1}}],["我",{"2":{"518":3,"674":4}}],["我们估计特征的平均值和方差并构建p",{"2":{"1181":1}}],["我们估计得到的参数与生成数据的真实参数非常接近",{"2":{"595":1}}],["我们花了大量的时间介绍了诸如线性回归",{"2":{"1176":1}}],["我们迫使算法收敛而非在最小值附近徘徊",{"2":{"1167":1}}],["我们做的是",{"2":{"1161":1}}],["我们做一个直角投影",{"2":{"1145":1}}],["我们拿到的数据就是这样的",{"2":{"1150":1}}],["我们解释了为什么支持向量机是一个大间距分类器",{"2":{"1145":1}}],["我们解释了汇聚层可以降低卷积层对目标位置的敏感性",{"2":{"879":1}}],["我们考察一个单一的训练样本",{"2":{"1145":1}}],["我们考虑的是选择参量来使训练误差最小化",{"2":{"1130":1}}],["我们考虑",{"2":{"615":1}}],["我们考虑对隐变量h1",{"2":{"519":1}}],["我们考虑以下三个在文本序列中填空的任务",{"2":{"518":1}}],["我们考虑使用",{"2":{"341":1}}],["我们考虑一个没有偏置参数的循环神经网络",{"2":{"312":1}}],["我们考虑从一组固定的特征",{"2":{"295":1}}],["我们考虑数据分布可能发生变化的各种方式",{"2":{"180":1}}],["我们考虑随机梯度下降更新",{"2":{"115":1}}],["我们画出了在不同情形下",{"2":{"1145":2}}],["我们接下来将会使用这些关于向量内积的性质试图来理解支持向量机中的目标函数",{"2":{"1145":1}}],["我们接下来将将学会",{"2":{"1117":1}}],["我们稍后会介绍支持向量机的偏差和方差",{"2":{"1144":1}}],["我们稍后将考虑不同的架构选择",{"2":{"712":1}}],["我们稍后将展示这一点",{"2":{"472":1}}],["我们观察一下",{"2":{"1144":1}}],["我们观察学习率η=0",{"2":{"57":1}}],["我们谈到查准率和召回率",{"2":{"1140":1}}],["我们谈到了协同过滤算法",{"2":{"1191":1}}],["我们谈到了怎样使用反向传播算法计算代价函数的导数",{"2":{"1123":1}}],["我们谈到了如何监控梯度下降法以确保其收敛",{"2":{"1110":1}}],["我们尝试使用不同的ε值作为阀值",{"2":{"1181":1}}],["我们尝试用一条直线来适应下面的数据",{"2":{"1134":1}}],["我们尝试预测的是结果是否属于某一个类",{"2":{"1106":1}}],["我们除了可以利用测试数据集来计算代价函数外",{"2":{"1130":1}}],["我们下一步可以做什么",{"2":{"1129":1}}],["我们下面希望探讨",{"2":{"1141":1}}],["我们下面要做的就是使用一个训练集",{"2":{"1112":1}}],["我们下面定义辅助函数apply",{"2":{"878":1}}],["我们列出的这个单子",{"2":{"1129":1}}],["我们列出了其中一些可以调整的操作",{"2":{"891":1}}],["我们非常希望在花费大量时间完成这些工作之前",{"2":{"1129":1}}],["我们单行道网络对应的自信度骤减",{"2":{"1127":1}}],["我们针对每一个",{"2":{"1124":1}}],["我们则需要对偏导数进行检验",{"2":{"1124":1}}],["我们采取一种叫做梯度的数值检验",{"2":{"1124":1}}],["我们决定要减少θ3和θ4的大小",{"2":{"1115":1}}],["我们决不能依靠测试数据进行模型选择",{"2":{"256":1}}],["我们预测评分为",{"2":{"1188":1}}],["我们预测y就是那个值",{"2":{"1112":1}}],["我们预测",{"2":{"1108":1,"1189":1}}],["我们预计共现概率的比值接近1",{"2":{"744":1}}],["我们预计其共现概率的比值接近1",{"2":{"744":1}}],["我们预计较小的共现概率比值",{"2":{"744":1}}],["我们预计会有更大的共现概率比值",{"2":{"744":1}}],["我们预计ff",{"2":{"500":1}}],["我们预计训练误差会下降",{"2":{"254":1}}],["我们预计向像素添加一些随机噪声应该是基本无影响的",{"2":{"170":1}}],["我们虽然可以使用一些二项式项来组合这些特征",{"2":{"1101":1}}],["我们被限制为使用数据中的原始特征x1",{"2":{"1101":1}}],["我们被要求对",{"2":{"181":1}}],["我们令",{"2":{"1100":2}}],["我们令查询的特征维度与键的特征维度大小相同",{"2":{"370":1}}],["我们说",{"2":{"1145":1}}],["我们说向量u等于2乘以向量v加上5乘以向量w",{"2":{"1093":1}}],["我们说过为了向量化这段代码",{"2":{"1093":1}}],["我们说标签y是",{"2":{"1025":1}}],["我们换成另一个这样对每个元素求绝对值",{"2":{"1090":1}}],["我们键入",{"2":{"1089":1}}],["我们开始学习这个算法",{"2":{"1143":1}}],["我们开始随机选择一系列的参数值",{"2":{"1081":1}}],["我们开始反向传播",{"2":{"605":1}}],["我们引入一个新的模型",{"2":{"1107":1}}],["我们引入一系列新的注释",{"2":{"1080":1}}],["我们引入了随机变量",{"2":{"1028":1}}],["我们引入了神经网络块的概念",{"2":{"422":1}}],["我们探讨了单变量",{"2":{"1080":1}}],["我们探讨了使用二维卷积神经网络处理二维图像数据的机制",{"2":{"698":1}}],["我们每一次都同时让所有的参数减去学习速率乘以代价函数的导数",{"2":{"1067":1}}],["我们每次采样的",{"2":{"330":1}}],["我们持续这么做直到找到一个局部最小值",{"2":{"1067":1}}],["我们绘制一个等高线图",{"2":{"1064":1}}],["我们绘制sigmoid函数",{"2":{"236":1}}],["我们改用糖尿病或没病",{"2":{"1061":1}}],["我们第一步就是建原型",{"2":{"1061":1}}],["我们放两个麦克风在房间中",{"2":{"1061":1}}],["我们已知的数据",{"2":{"1061":1}}],["我们已经一起学习很长一段时间了",{"2":{"1176":1}}],["我们已经讨论了svm比较抽象的层面",{"2":{"1148":1}}],["我们已经看到输入一个训练样本标签为y=1​",{"2":{"1144":1}}],["我们已经介绍了怎样评价一个学习算法",{"2":{"1135":1}}],["我们已经介绍了许多不同的学习算法",{"2":{"1129":1}}],["我们已经介绍了几种用于自然语言理解的词嵌入模型",{"2":{"730":1}}],["我们已经把要做的做完了",{"2":{"1112":1}}],["我们已经清楚地知道",{"2":{"1061":1}}],["我们已经学习了几种不同的学习算法",{"2":{"1114":1}}],["我们已经学习了按元素操作",{"2":{"997":1}}],["我们已经学习了如何用小批量随机梯度下降训练模型",{"2":{"161":1}}],["我们已经为加载图像中的狗和猫定义了真实边界框",{"2":{"853":1}}],["我们已经为snli数据集",{"2":{"685":1}}],["我们已经将所有权重放到一个3×4矩阵中",{"2":{"641":1}}],["我们已经反复提到像梯度爆炸或梯度消失",{"2":{"306":1}}],["我们已经描述了l2范数和l1范数",{"2":{"270":1}}],["我们已经在这个样本中看到p",{"2":{"1145":1}}],["我们已经在简单的线性模型背景下掌握了这些知识",{"2":{"228":1}}],["我们已经在",{"2":{"216":1,"686":1}}],["我们已经假设了一个先验",{"2":{"168":1}}],["我们已经掌握了卷积层的处理方法",{"2":{"135":1}}],["我们数据集中的每个样本都有相应的",{"2":{"1060":1}}],["我们给用户一个报价",{"2":{"1168":1}}],["我们给了代价函数一个数学上的定义",{"2":{"1065":1}}],["我们给了一系列房子的数据",{"2":{"1060":1}}],["我们给出输入一个新的",{"2":{"1112":1}}],["我们给出一个θ",{"2":{"1111":1}}],["我们给出一个多项式的例子",{"2":{"259":1}}],["我们给出了一个数学上关于梯度下降的定义",{"2":{"1068":1}}],["我们给出了",{"2":{"1063":1}}],["我们给定数据集中每个样本的正确价格",{"2":{"1060":1}}],["我们该如何表达",{"2":{"1063":1}}],["我们该如何去做",{"2":{"1059":1}}],["我们该如何处理视频片段呢",{"2":{"295":1}}],["我们打开课程网站",{"2":{"1094":1}}],["我们打算使用octave编程环境",{"2":{"1061":1}}],["我们打算让它自己进行学习",{"2":{"1059":1}}],["我们打印出小批量的bert预训练样本的形状",{"2":{"722":1}}],["我们唯一能做的就是让计算机自己学习如何驾驶直升机",{"2":{"1058":1}}],["我们创造智能的机器",{"2":{"1058":1}}],["我们创建变量x并为其分配一个初始值",{"2":{"974":1}}],["我们创建两个实例来分别读取训练和测试数据集中的所有图像文件",{"2":{"872":1}}],["我们创建了一个与另一个张量y相同的形状的z",{"2":{"1021":1}}],["我们创建了一个全为0的长度为n的向量",{"2":{"781":1}}],["我们创建了其实例mlm并对其进行了初始化",{"2":{"736":1}}],["我们创建一个新的训练集",{"2":{"1112":1}}],["我们创建一个randomfliptopbottom实例",{"2":{"879":1}}],["我们创建一个人工数据集",{"2":{"774":1}}],["我们创建一个数据样本来",{"2":{"495":1}}],["我们创建一个高度和宽度为3的二维卷积层",{"2":{"141":1}}],["我们正迎来从",{"2":{"1049":1}}],["我们正在寻找癌症肿瘤",{"2":{"1063":1}}],["我们正在寻找的是能够很好地泛化高稳定性模型的估计器",{"2":{"308":1}}],["我们正在为网络初始化参数",{"2":{"592":2}}],["我们区分了随机变量x和x可以采取的值",{"2":{"1028":1}}],["我们区分了优化问题中的解析解和数值解",{"2":{"100":1}}],["我们手动指定了它有3行和4列",{"2":{"1017":1}}],["我们导入必要的软件包",{"2":{"1026":1}}],["我们导入tensorflow",{"2":{"1017":1}}],["我们导入torch",{"2":{"1017":1}}],["我们导入pandas包并调用read",{"2":{"1011":1}}],["我们矩阵中的行可能对应于不同的房屋",{"2":{"992":1}}],["我们真正要决定的是隐藏层的层数和每个中间层的单元数",{"2":{"1126":1}}],["我们真正需要的是一种有效的算法",{"2":{"1066":1}}],["我们真正关心的是生成一个模型",{"2":{"980":1}}],["我们真正想要的是只有短范围交互的模型",{"2":{"311":1}}],["我们想预测明天北京下雨的概率",{"2":{"1025":1}}],["我们想",{"2":{"1018":1}}],["我们想在这些数据上执行数学运算",{"2":{"1018":1}}],["我们想计算z关于x的梯度",{"2":{"976":1}}],["我们想要评估一组发动机读数为正常运行情况的概率有多大",{"2":{"1025":1}}],["我们想要找到其中能拟合数据的最好模型",{"2":{"987":1}}],["我们想要计算上采样输出图像上的每个像素",{"2":{"863":1}}],["我们想要训练一个毒蘑菇检测分类器",{"2":{"291":1}}],["我们想要在患者的基因数据与痴呆状态之间寻找模式",{"2":{"251":1}}],["我们想要根据体温预测死亡率",{"2":{"230":1}}],["我们想要采用一组而不是一个隐藏表示",{"2":{"158":1}}],["我们想要使l相对于αi最大化",{"2":{"48":1}}],["我们收集的数据集",{"2":{"1156":1}}],["我们收集的香蕉检测数据集可用于演示目标检测模型",{"2":{"934":1}}],["我们收集并标记了一个小型数据集",{"2":{"930":1}}],["我们拍摄了一组香蕉的照片",{"2":{"930":1}}],["我们学到的合成图像里面有大量高频噪点",{"2":{"924":1}}],["我们学习到的卷积核权重非常接近我们之前定义的卷积核k",{"2":{"129":1}}],["我们学习了深度网络是如何实现和优化的",{"2":{"606":1}}],["我们学习了如何处理数据",{"2":{"228":1}}],["我们学习了一个分类器来区分从p",{"2":{"191":1}}],["我们学习了构建一个完整卷积神经网络的所需组件",{"2":{"135":1}}],["我们学习了",{"2":{"32":2}}],["我们输出风格迁移的模型参数",{"2":{"917":1}}],["我们初始化合成图像",{"2":{"917":1}}],["我们初始化s0=0",{"2":{"27":1}}],["我们介绍n维数组",{"2":{"1016":1}}],["我们介绍一种基于cnn的多尺度目标检测方法",{"2":{"913":1}}],["我们介绍了如何选择特征",{"2":{"1183":1}}],["我们介绍了如何拟合p",{"2":{"1180":1}}],["我们介绍了如何为广泛的自然语言处理应用",{"2":{"663":1}}],["我们介绍了一种方法",{"2":{"1167":1}}],["我们介绍了一个名为bert的预训练模型",{"2":{"656":1}}],["我们介绍了反向传播算法",{"2":{"1122":1}}],["我们介绍了无监督学习",{"2":{"1061":1}}],["我们介绍了n元语法模型",{"2":{"338":1}}],["我们介绍了softmax回归",{"2":{"228":1}}],["我们介绍了通过惩罚权重的l2范数来正则化统计模型的经典方法",{"2":{"168":1}}],["我们进一步",{"2":{"912":1}}],["我们进行经验风险最小化",{"2":{"202":1}}],["我们进行得有点快而松散",{"2":{"116":1}}],["我们基于hybridblock类构建剩余块",{"2":{"893":1}}],["我们基于用户提供的前缀",{"2":{"517":1}}],["我们提供了大量的文件",{"2":{"1094":1}}],["我们提供了两个版本的预训练的bert",{"2":{"686":1}}],["我们提供完整数据集的小规模样本",{"2":{"901":1}}],["我们提供包含前1000个训练图像和5个随机测试图像的数据集的小规模样本",{"2":{"889":1}}],["我们研究了计算机视觉中常用的各种卷积神经网络",{"2":{"886":1}}],["我们构造了一个小的基础网络",{"2":{"958":1}}],["我们构造一个将输入的高和宽放大2倍的转置卷积层",{"2":{"863":1}}],["我们构造一个步幅为32的转置卷积层",{"2":{"862":1}}],["我们构造一个",{"2":{"461":1}}],["我们构造一个具有256个隐藏单元的单隐藏层的循环神经网络层rnn",{"2":{"325":1}}],["我们构造一个高度为1",{"2":{"128":1}}],["我们构造一个6×8像素的黑白图像",{"2":{"128":1}}],["我们构造一个目标函数f",{"2":{"57":1}}],["我们构建的高和宽减半块会更改输入通道的数量",{"2":{"957":1}}],["我们构建一个新的神经网络作为目标模型",{"2":{"873":1}}],["我们平常接触到的数据集的规模通常在这两者之间",{"2":{"869":1}}],["我们标记其为背景",{"2":{"852":1}}],["我们标准化数据有两个原因",{"2":{"209":1}}],["我们丢弃矩阵第2行和第3列中的所有元素",{"2":{"851":1}}],["我们指定pretrained=true以自动下载预训练的模型参数",{"2":{"873":1}}],["我们指定输入图像",{"2":{"848":1}}],["我们指定每个权重参数应该从均值为0",{"2":{"592":1}}],["我们同样也可以训练k个支持向量机来解决多类分类问题",{"2":{"1148":1}}],["我们同样也可以利用正规方程来求解正则化线性回归模型",{"2":{"1116":1}}],["我们同样可以看到",{"2":{"1143":1}}],["我们同样把数据分为训练集",{"2":{"1133":1}}],["我们同样需要计算每一层的误差单元",{"2":{"1121":1}}],["我们同样不推荐这种方法",{"2":{"832":1}}],["我们同时也在试图将w的大小缩小到零",{"2":{"270":1}}],["我们演示了兴趣区域汇聚层的计算方法",{"2":{"938":1}}],["我们演示了在调用hybridize函数之后",{"2":{"821":1}}],["我们演示了一个具有两个输入通道的二维互相关运算的示例",{"2":{"120":1}}],["我们比较了混合编程前后执行net",{"2":{"820":1}}],["我们比较y与卷积层输出的平方误差",{"2":{"129":1}}],["我们编写与之前相同的代码",{"2":{"819":3}}],["我们编写的multiheadattention类",{"2":{"382":1}}],["我们完全可以忽略细节",{"2":{"802":1}}],["我们随机抽取了k个",{"2":{"775":1}}],["我们随机抽样一小批量非零的xij来计算梯度并更新模型参数",{"2":{"743":1}}],["我们加载wikitext",{"2":{"725":1}}],["我们加载预训练的100维glove嵌入作为初始化的词元表示",{"2":{"703":1}}],["我们讨论了核函数的概念",{"2":{"1147":1}}],["我们讨论了评价指标",{"2":{"1141":1}}],["我们讨论了模型选择问题",{"2":{"1135":1}}],["我们讨论了用梯度下降的方法最小化逻辑回归中代价函数j",{"2":{"1111":1}}],["我们讨论了情感分析问题",{"2":{"664":1}}],["我们讨论了如何在cpu和gpu上高效地训练模型",{"2":{"831":1}}],["我们讨论了如何在循环神经网络中计算梯度",{"2":{"538":1}}],["我们讨论了如何处理数据",{"2":{"440":1}}],["我们依旧可以用",{"2":{"1117":1}}],["我们依赖循环神经网络设计语言模型来生成类似中篇小说的文本",{"2":{"663":1}}],["我们依然可以用描述神经网络的方式来描述线性模型",{"2":{"617":1}}],["我们至少需要h",{"2":{"650":1}}],["我们重新定义逻辑回归的代价函数为",{"2":{"1109":1}}],["我们重新创建了net",{"2":{"592":1}}],["我们重构训练过程的实现以使其可重复使用",{"2":{"635":1}}],["我们求和会得到正确预测的数量",{"2":{"634":1}}],["我们执行以下操作",{"2":{"634":1}}],["我们执行从x到其展开式的映射",{"2":{"479":1}}],["我们回顾逻辑回归问题中我们的代价函数为",{"2":{"1120":1}}],["我们回顾一下这个表达式",{"2":{"631":1}}],["我们回顾了过去20年计算能力的快速增长",{"2":{"445":1}}],["我们认为softmax回归也是重要的基础",{"2":{"629":1}}],["我们认为需要更多训练迭代的模型比较复杂",{"2":{"254":1}}],["我们怎样获得数据",{"2":{"1173":1}}],["我们怎样才能这么做呢",{"2":{"1097":1}}],["我们怎样才能更快地找到相似的词或完成一个词的类比呢",{"2":{"753":1}}],["我们怎样才能修正它",{"2":{"59":1}}],["我们怎么能回去这个原始的二维空间呢",{"2":{"1161":1}}],["我们怎么储存数据呢",{"2":{"1089":1}}],["我们怎么解决这个问题",{"2":{"628":1}}],["我们避免计算exp⁡",{"2":{"624":1}}],["我们发现",{"2":{"622":1,"1058":1}}],["我们援引斯图尔特",{"2":{"619":1}}],["我们经常在导入它后使用短别名tf",{"2":{"1017":1}}],["我们经常从预处理原始数据开始",{"2":{"1010":1}}],["我们经常使用范数",{"2":{"1003":1}}],["我们经常试图解决优化问题",{"2":{"1001":1}}],["我们经常会遇到大量的定制的网络连接",{"2":{"842":1}}],["我们经常对当前小批量的中心词进行上下文词和噪声词的采样",{"2":{"770":1}}],["我们经常希望能够同时处理整个小批量的样本",{"2":{"615":1}}],["我们经常转换输入的维度",{"2":{"330":1}}],["我们记录下模型参数的估计值",{"2":{"613":1}}],["我们需计算在训练集n个样本上的损失均值",{"2":{"611":1}}],["我们需要另一种方法来帮助检验算法是否有效",{"2":{"1181":1}}],["我们需要另一种方法来评估我们的假设函数过拟合检验",{"2":{"1130":1}}],["我们需要据此拟合一个假设函数",{"2":{"1150":1}}],["我们需要p",{"2":{"1145":1}}],["我们需要θtx",{"2":{"1144":1}}],["我们需要的是比0值大很多",{"2":{"1144":1}}],["我们需要计算出所有特征的均值",{"2":{"1159":1}}],["我们需要计算每一层的误差单元来计算代价函数的偏导数",{"2":{"1121":1}}],["我们需要计算单词的概率",{"2":{"316":1}}],["我们需要采用一种反向传播算法",{"2":{"1121":1}}],["我们需要写出代码来计算j",{"2":{"1111":1}}],["我们需要用这个表达式来更新这些参数",{"2":{"1110":1}}],["我们需要用代码生成架构",{"2":{"442":1}}],["我们需要二次方特征",{"2":{"1108":1}}],["我们需要输出0或1",{"2":{"1107":1}}],["我们需要首先思考大脑中的神经网络是怎样的",{"2":{"1099":1}}],["我们需要进行求和运算",{"2":{"1069":1}}],["我们需要运用边际化和乘法法则来确定",{"2":{"1035":1}}],["我们需要求和法则",{"2":{"1033":1}}],["我们需要估计这些概率以及概率之间的关系",{"2":{"1029":1}}],["我们需要估计它",{"2":{"191":1}}],["我们需要检查它是否有瑕疵",{"2":{"1026":1}}],["我们需要使用交叉验证集来帮助选择模型",{"2":{"1131":1}}],["我们需要使用概率学",{"2":{"1025":1}}],["我们需要使用分类器而不是回归模型来估计p",{"2":{"347":1}}],["我们需要做两件重要的事",{"2":{"1016":1}}],["我们需要做的就是检查∇2f⪰0",{"2":{"46":1}}],["我们需要某种方法来存储和操作数据",{"2":{"1016":1}}],["我们需要借用概率语言",{"2":{"987":1}}],["我们需要清除之前的值",{"2":{"974":2}}],["我们需要在模型的前向传播过程中生成多尺度锚框",{"2":{"963":1}}],["我们需要在不同的设备之间移动数据",{"2":{"797":1}}],["我们需要整理数据集来训练和测试模型",{"2":{"890":1}}],["我们需要调整通道维的位置",{"2":{"863":1}}],["我们需要通过识别拍摄到的视频图像里的车辆",{"2":{"857":1}}],["我们需要通过添加过渡层来控制网络的维数",{"2":{"484":1}}],["我们需要给每个锚框两种类型的标签",{"2":{"855":1}}],["我们需要给共享层一个名称",{"2":{"437":3}}],["我们需要遍历剩下的三个未标记的锚框",{"2":{"853":1}}],["我们需要每个锚框的类别",{"2":{"850":1}}],["我们需要恢复它们原始的坐标值",{"2":{"848":1}}],["我们需要服务器之间相互通信",{"2":{"843":1}}],["我们需要两个基本操作",{"2":{"835":1}}],["我们需要大量的同步或屏障操作",{"2":{"832":1}}],["我们需要获得对数条件概率关于中心词向量和上下文词向量的梯度",{"2":{"784":1}}],["我们需要以理想的格式生成数据集",{"2":{"718":1}}],["我们需要能够对成对的文本序列进行推断",{"2":{"664":1}}],["我们需要能够处理这些数据的特定模型",{"2":{"305":1}}],["我们需要和输出一样多的仿射函数",{"2":{"641":1}}],["我们需要收集一个真实的数据集",{"2":{"609":1}}],["我们需要先将地址",{"2":{"802":1}}],["我们需要先有一些参数",{"2":{"601":1}}],["我们需要先卸载它",{"2":{"445":2}}],["我们需要初始化模型参数",{"2":{"592":1}}],["我们需要许多门",{"2":{"552":1}}],["我们需要评估1000010=1040序列",{"2":{"514":1}}],["我们需要设计一个更强大的架构f",{"2":{"500":1}}],["我们需要设置ph=kh−1和pw=kw−1",{"2":{"141":1}}],["我们需要走得更深",{"2":{"487":1}}],["我们需要决定在哪里执行这个操作",{"2":{"449":1}}],["我们需要确定一个拟合程度的度量",{"2":{"611":1}}],["我们需要确认安装了paddlepaddle的gpu版本",{"2":{"445":1}}],["我们需要确认是否安装了mxnet的gpu版本",{"2":{"445":1}}],["我们需要确保不创建超过gpu显存限制的数据",{"2":{"448":1}}],["我们需要确保两个张量都位于同一个设备上",{"2":{"447":1}}],["我们需要确保已安装pandas",{"2":{"208":1}}],["我们需要确保参数能够适当地收敛",{"2":{"27":1}}],["我们需要确保在获取大量动态的特征值范围时足够谨慎",{"2":{"26":1}}],["我们需要单独指定架构",{"2":{"442":1}}],["我们需要完成更多的数据操作工作",{"2":{"409":1}}],["我们需要一些测量方法",{"2":{"1036":1}}],["我们需要一些数学基础知识",{"2":{"499":1}}],["我们需要一种完全不同的方法来预处理机器翻译数据集",{"2":{"564":1}}],["我们需要一步一步地向前迈进",{"2":{"351":1}}],["我们需要一个简单的工具函数",{"2":{"836":1}}],["我们需要一个损失函数来度量预测的效果",{"2":{"645":1}}],["我们需要一个训练的目标函数",{"2":{"643":1}}],["我们需要一个有多个输出的模型",{"2":{"641":1}}],["我们需要一个计算函数",{"2":{"425":1}}],["我们需要一个更细粒度的工具来调整函数的复杂性",{"2":{"269":1}}],["我们需要一个更加可扩展的实现",{"2":{"90":1}}],["我们需要一个引理证明多维情况",{"2":{"46":1}}],["我们需要分离梯度以减少计算量",{"2":{"336":1}}],["我们需要了解神经网络训练的基础知识",{"2":{"587":1}}],["我们需要了解更多的概念和术语",{"2":{"317":1}}],["我们需要了解训练误差和泛化误差",{"2":{"252":1}}],["我们需要存储所有的计数",{"2":{"316":1}}],["我们需要想想办法来处理这一问题",{"2":{"307":1}}],["我们需要有效地利用其像素位置",{"2":{"305":1}}],["我们需要定义和初始化模型参数",{"2":{"558":1}}],["我们需要定义如何计算隐状态",{"2":{"556":1}}],["我们需要定义自己的块",{"2":{"425":1}}],["我们需要定义模型的优劣程度的度量",{"2":{"286":1}}],["我们需要定义凸集",{"2":{"39":1}}],["我们需要程序来自动调整",{"2":{"281":1}}],["我们需要比较不同的超参数设置下的同一类模型",{"2":{"255":1}}],["我们需要对整个训练集进行循环",{"2":{"1169":1}}],["我们需要对这些通道的",{"2":{"470":1}}],["我们需要对数据进行预处理",{"2":{"209":1}}],["我们需要对输入和输出的数据形状进行调整",{"2":{"122":1}}],["我们需要知道它可能适用于哪些人群",{"2":{"201":1}}],["我们需要预测明天的股票价格",{"2":{"196":1}}],["我们需要解决两个问题",{"2":{"191":1}}],["我们需要根据数据来自正确分布与来自错误分布的概率之比",{"2":{"191":1}}],["我们需要继续沿着输出层到隐藏层反向传播",{"2":{"164":1}}],["我们需要思考哪些问题",{"2":{"160":1}}],["我们需要沿输入的最后一个维度进行串联",{"2":{"148":1}}],["我们需要将一系列无标签的训练数据",{"2":{"1150":1}}],["我们需要将矩阵首先展开成为向量",{"2":{"1121":1}}],["我们需要将整个训练集都喂给我们的神经网络算法来学习模型",{"2":{"1099":1}}],["我们需要将微分的思想推广到多元函数",{"2":{"982":1}}],["我们需要将输入图像在各个通道做标准化",{"2":{"866":1}}],["我们需要将数据复制到累积结果的设备",{"2":{"835":1}}],["我们需要将真实值y的形状转换为和预测值y",{"2":{"603":1}}],["我们需要将",{"2":{"291":1}}],["我们需要将每一小批量数据移动到我们指定的设备",{"2":{"137":1}}],["我们需要将其复制到显存中",{"2":{"137":1}}],["我们需要将hessian矩阵h求逆",{"2":{"59":1}}],["我们需要",{"2":{"137":1,"835":1,"892":1,"961":1,"981":1}}],["我们需要执行",{"2":{"130":1}}],["我们需要弄清η的衰减速度",{"2":{"114":1}}],["我们需要访问两个向量中许多不相交的位置",{"2":{"77":1}}],["我们需要向每个gpu发送至少一张图像",{"2":{"77":1}}],["我们需要证明",{"2":{"45":1}}],["我们模型的表达能力将受到限制",{"2":{"610":1}}],["我们举一个实际的例子",{"2":{"609":1}}],["我们调用优化算法sgd来更新模型参数",{"2":{"605":1}}],["我们调用了深度学习库",{"2":{"421":1}}],["我们明确定义了模型参数变量",{"2":{"591":1}}],["我们直观感受一下小批量运算",{"2":{"600":1}}],["我们直观地描述了多项式的阶数和欠拟合与过拟合之间的关系",{"2":{"259":1}}],["我们直接使用编码器最后一个时间步的隐状态来初始化解码器的隐状态",{"2":{"574":1}}],["我们动手构建",{"2":{"572":1}}],["我们更提倡使用向量化的实现",{"2":{"1110":1}}],["我们更详细地描述使用注意力机制的软对齐",{"2":{"674":1}}],["我们更喜欢单词级词元化",{"2":{"566":1}}],["我们更关心相对误差y−y^y",{"2":{"210":1}}],["我们按比例放大剪裁的区域",{"2":{"1172":1}}],["我们按照标准差0",{"2":{"558":1}}],["我们按如下方式计算单隐藏层多层感知机的输出",{"2":{"232":1}}],["我们分别介绍了边界框",{"2":{"952":1}}],["我们分别标准化每个通道",{"2":{"872":1}}],["我们分别打印输出训练集的困惑度",{"2":{"546":1}}],["我们分别使用wh和wo来表示隐藏层和输出层的权重",{"2":{"307":1}}],["我们读取并调整测试图像的大小",{"2":{"964":1}}],["我们读取内容和风格图像",{"2":{"918":1}}],["我们读取一小批量训练样本",{"2":{"605":1}}],["我们读取",{"2":{"543":1}}],["我们新增一个init",{"2":{"534":1}}],["我们终究无法知道下一个词元的下文是什么",{"2":{"522":1}}],["我们获得三个参数",{"2":{"1160":1}}],["我们获得了两个文件夹hotdog",{"2":{"872":1}}],["我们获得了与",{"2":{"20":1}}],["我们获得最终候选输出序列集合",{"2":{"515":1}}],["我们逐一打印它们截取的区域",{"2":{"866":1}}],["我们逐一实现googlenet的每个模块",{"2":{"488":1}}],["我们逐个预测输出序列",{"2":{"512":1}}],["我们省略了一些为稳定训练而添加的特殊特性",{"2":{"486":1}}],["我们甚至不知道简单的神经网络",{"2":{"475":1}}],["我们甚至可以将所有元数据视为随机变量",{"2":{"1029":1}}],["我们甚至可以将置信度较低的预测边界框移除",{"2":{"854":1}}],["我们甚至可以",{"2":{"441":1}}],["我们甚至可以在较小和较大的学习率之间切换",{"2":{"114":1}}],["我们甚至可能无法提供足够的数据来构成一个合适的验证集",{"2":{"257":1}}],["我们了解一下批量规范化在实践中是如何工作的",{"2":{"467":1}}],["我们了解了如何将文本数据映射为词元",{"2":{"315":1}}],["我们无法得到一个明确定义的交叉熵值",{"2":{"624":1}}],["我们无法得知使用整个数据集来估计平均值和方差",{"2":{"467":1}}],["我们无法估计整体收敛的速度",{"2":{"60":1}}],["我们计算代价函数的偏导数后得到梯度下降的更新公式为",{"2":{"1188":1}}],["我们计算p",{"2":{"1185":1}}],["我们计算",{"2":{"1184":1}}],["我们计算的方式就是我将训练样本投影到参数向量θ",{"2":{"1145":1}}],["我们计算相对频率",{"2":{"1026":1}}],["我们计算d关于a的导数",{"2":{"979":1}}],["我们计算假设中索引为j的每个词元与前提词元的软对齐",{"2":{"674":1}}],["我们计算假设中所有词元向量的加权平均值",{"2":{"674":1}}],["我们计算了模型的输出",{"2":{"624":1}}],["我们计算小批量的平均损失关于模型参数的导数",{"2":{"613":1}}],["我们计算每个迭代周期后的损失",{"2":{"595":1}}],["我们计算所有y3∈y为",{"2":{"515":1}}],["我们计算所有y2∈y为",{"2":{"515":1}}],["我们计算出在",{"2":{"1124":1}}],["我们计算出",{"2":{"467":1}}],["我们计算正则化项相对于两个参数的梯度",{"2":{"164":1}}],["我们深度理解一下中央处理器",{"2":{"457":1}}],["我们深入探讨常见的深度学习优化算法",{"2":{"65":1}}],["我们始终可以直接设置参数",{"2":{"436":1}}],["我们访问第一个主要的块中",{"2":{"433":1}}],["我们担心速度极快的gpu可能要等到cpu运行python代码后才能运行另一个作业",{"2":{"426":4}}],["我们网络中的所有操作都对网络的激活值及网络的参数起作用",{"2":{"425":1}}],["我们把我们的训练集",{"2":{"1185":1}}],["我们把这些样本投射到图中这个一维平面",{"2":{"1161":1}}],["我们把这样从左到右的算法称为前向传播算法",{"2":{"1099":1}}],["我们把这个当作监督学习问题",{"2":{"1061":1}}],["我们把这个问题称为多项分类",{"2":{"291":1}}],["我们把从概率分布中抽取样本的过程称为抽样",{"2":{"1026":1}}],["我们把对它的讨论留在练习中",{"2":{"688":1}}],["我们把试图预测的目标",{"2":{"609":1}}],["我们把它喂给我们的学习算法",{"2":{"1063":1}}],["我们把它们设计成",{"2":{"540":1}}],["我们把它保存在",{"2":{"424":1}}],["我们把它",{"2":{"424":1}}],["我们定制的",{"2":{"423":1}}],["我们定义代价函数为一个单一训练实例的代价",{"2":{"1165":1}}],["我们定义的代价函数是所有模型误差的平方和",{"2":{"1109":1}}],["我们定义set",{"2":{"981":1}}],["我们定义训练集的迭代器",{"2":{"948":1}}],["我们定义get",{"2":{"926":1}}],["我们定义resnet",{"2":{"893":1}}],["我们定义reorg",{"2":{"890":1}}],["我们定义以下load",{"2":{"949":1}}],["我们定义以下multibox",{"2":{"854":1}}],["我们定义以下randomgenerator类",{"2":{"775":1}}],["我们定义以下get",{"2":{"757":1}}],["我们定义以下",{"2":{"722":1}}],["我们定义以下函数来使用训练好的模型net预测文本序列的情感",{"2":{"715":1}}],["我们定义attend类来计算假设",{"2":{"674":1}}],["我们定义函数read",{"2":{"667":1}}],["我们定义一个辅助函数bbox",{"2":{"858":1}}],["我们定义一个简单的多层感知机",{"2":{"819":1}}],["我们定义一个函数来训练一个迭代周期",{"2":{"635":1}}],["我们定义一个python函数来计算正态分布",{"2":{"616":1}}],["我们定义一个计时器",{"2":{"615":1}}],["我们定义load",{"2":{"569":1,"932":1}}],["我们定义了单训练样本的代价函数",{"2":{"1109":1}}],["我们定义了这样一个类别预测层",{"2":{"954":1}}],["我们定义了voc",{"2":{"945":1}}],["我们定义了",{"2":{"893":2}}],["我们定义了可以同时拆分数据和标签的split",{"2":{"836":1}}],["我们定义了可分解注意力模型来联合训练这三个步骤",{"2":{"677":1}}],["我们定义了读取ptb数据集并返回数据迭代器和词表的load",{"2":{"777":1}}],["我们定义了掩码变量masks",{"2":{"776":1}}],["我们定义了两个嵌入层",{"2":{"766":1}}],["我们定义了下面的load",{"2":{"722":1}}],["我们定义了以下tokenembedding类",{"2":{"748":1}}],["我们定义了以下",{"2":{"721":1}}],["我们定义了initializer类的子类",{"2":{"436":1}}],["我们定义了网络架构",{"2":{"417":1}}],["我们定义了一个3×3的输入x和2×2卷积核k",{"2":{"970":1}}],["我们定义了一个相同的模型",{"2":{"874":1}}],["我们定义了一个训练函数train",{"2":{"874":1}}],["我们定义了一个辅助函数",{"2":{"726":1,"882":1}}],["我们定义了一个小的bert",{"2":{"726":1}}],["我们定义了一个定制的数据集类snlibertdataset",{"2":{"687":1}}],["我们定义了一个split",{"2":{"681":1}}],["我们定义了一个名为vgg",{"2":{"507":1}}],["我们定义了一个initializer的子类",{"2":{"436":1}}],["我们定义了一个函数load",{"2":{"321":1}}],["我们定义了一个计算卷积层的函数",{"2":{"141":4}}],["我们定义矩阵x",{"2":{"340":1}}],["我们定义非线性函数σ也以按行的方式作用于其输入",{"2":{"232":1}}],["我们声明两个全连接的层",{"2":{"423":4}}],["我们上面模型中的第一个全连接的层接收一个20维的输入",{"2":{"423":1}}],["我们上面模型中的第一个全连接的层接收任意维的输入",{"2":{"423":1}}],["我们简要回顾一下sum运算符如何沿着张量中的特定维度工作",{"2":{"631":1}}],["我们简要总结一下每个块必须提供的基本功能",{"2":{"423":1}}],["我们简单更新",{"2":{"33":1}}],["我们反复调用net变量的add函数",{"2":{"422":1}}],["我们利用",{"2":{"1146":1}}],["我们利用测试集数据计算代价函数j",{"2":{"1130":1}}],["我们利用这个误差值来计算前一层的误差",{"2":{"1121":1}}],["我们利用gpu并行运算的优势",{"2":{"600":1}}],["我们利用矢量化算法来描述整层神经元",{"2":{"422":1}}],["我们利用了给定的x1",{"2":{"115":1}}],["我们关注的是具有单一输出的线性模型",{"2":{"422":1}}],["我们关心的是相对数量",{"2":{"210":1}}],["我们添加层时没有指定前一层的输出维度",{"2":{"417":1}}],["我们添加了一个状态输入states并将超参数放在字典hyperparams中",{"2":{"80":1}}],["我们忽略了建立网络时需要做的以下这些事情",{"2":{"417":1}}],["我们忽略了图像一般包含三个通道",{"2":{"158":1}}],["我们再来仔细研究一下前向传播的原理",{"2":{"1122":1}}],["我们再让每个求幂后的结果除以它们的总和",{"2":{"643":1}}],["我们再将点积除以d",{"2":{"370":1}}],["我们再进一步看看三元语法的频率是否表现出相同的行为方式",{"2":{"318":1}}],["我们积累了一些错误ϵ1=ϵ¯",{"2":{"351":1}}],["我们生成了16组锚框",{"2":{"913":1}}],["我们生成了hw组锚框",{"2":{"913":1}}],["我们生成一个包含1000个样本的数据集",{"2":{"599":1}}],["我们生成一些数据",{"2":{"350":1}}],["我们生成100个高斯随机矩阵",{"2":{"243":1}}],["我们并不知道汽车如何行驶",{"2":{"1127":1}}],["我们并不知道其中哪些特征我们要惩罚",{"2":{"1115":1}}],["我们并不担心在这里自动推断输入形状",{"2":{"472":1}}],["我们并不指望时间会停滞不前",{"2":{"347":1}}],["我们并不假设环境告诉智能体每个观测的最优动作",{"2":{"298":1}}],["我们沿列",{"2":{"340":1}}],["我们沿着依赖的方向遍历计算图并计算其路径上的所有变量",{"2":{"165":1}}],["我们刚刚使用的算法",{"2":{"1069":1}}],["我们刚刚使用矩阵乘法实现了卷积",{"2":{"970":1}}],["我们刚刚提到某个锚框",{"2":{"849":1}}],["我们刚才提到",{"2":{"340":1}}],["我们刚在",{"2":{"112":1}}],["我们拥有的隐藏层权重参数为wxh∈rd×h",{"2":{"339":1}}],["我们训练循环神经网络模型",{"2":{"335":1}}],["我们训练一个带有损失平方的线性模型",{"2":{"210":1}}],["我们知道的是θtx",{"2":{"1145":1}}],["我们知道当",{"2":{"1108":1}}],["我们知道g",{"2":{"1101":1}}],["我们知道每个结果都有真实的概率16",{"2":{"1026":1}}],["我们知道",{"2":{"957":1,"1132":1,"1152":1}}],["我们知道在第一个样本中",{"2":{"633":1}}],["我们知道梯度范数永远不会超过θ",{"2":{"334":1}}],["我们知道∥w∥2=w⊤w",{"2":{"280":1}}],["我们为每一层都增加一个偏差单位",{"2":{"1099":1}}],["我们为每个图像生成多个锚框",{"2":{"850":1}}],["我们为同一个小批量构建两个不同比例",{"2":{"956":1}}],["我们为语料库构建了一个词表",{"2":{"772":1}}],["我们为词表中的单词加载预训练的100维",{"2":{"714":1}}],["我们为自然语言处理应用设计了不同的模型",{"2":{"656":1}}],["我们为一维情况下的回归问题绘制图像",{"2":{"611":1}}],["我们为一个完整的循环神经网络模型定义了一个rnnmodel类",{"2":{"325":1}}],["我们为模型提供了一个数据集",{"2":{"289":1}}],["我们如何把所有这一切共同开发一个异常检测算法",{"2":{"1185":1}}],["我们如何能够知道哪一部分最值得我们花时间和精力去改善呢",{"2":{"1174":1}}],["我们如何判断是方差还是偏差呢",{"2":{"1132":1}}],["我们如何得到一个学习算法来进行分类呢",{"2":{"1112":1}}],["我们如何使用它们在文本序列中的距离来重新设计计算条件概率pij的方法",{"2":{"746":1}}],["我们如何更改超参数以减小词表大小",{"2":{"671":1}}],["我们如何利用bert来训练语言模型",{"2":{"662":1}}],["我们如何对一系列对话建模",{"2":{"323":1}}],["我们如何才能确定模型是真正发现了一种泛化的模式",{"2":{"251":1}}],["我们面对的问题是如何对一个文档",{"2":{"316":1}}],["我们面临着类似的问题",{"2":{"247":1}}],["我们面临着过拟合的风险",{"2":{"204":1}}],["我们离设计出这样的系统还很遥远",{"2":{"315":1}}],["我们离一个能够控制人类创造者的有知觉的人工智能系统还很远",{"2":{"301":1}}],["我们继续",{"2":{"851":1}}],["我们继续实现",{"2":{"760":1}}],["我们继续使用如",{"2":{"312":1}}],["我们继续思考多项式回归的例子",{"2":{"269":1}}],["我们看看它是如何工作的",{"2":{"433":1}}],["我们看看一些案例",{"2":{"342":1}}],["我们看看在真实数据上如果进行自然语言统计",{"2":{"318":1}}],["我们看一下",{"2":{"1145":1}}],["我们看一下读取训练数据所需的时间",{"2":{"583":1}}],["我们看一下如何将预处理后的数据加载到小批量中用于训练",{"2":{"564":1}}],["我们看一下如何使用循环神经网络来构建语言模型",{"2":{"341":1}}],["我们看一下总体策略",{"2":{"319":1}}],["我们看一下通过时间反向传播问题的细节",{"2":{"312":1}}],["我们看到黑色的决策界和训练样本之间有更大的最短距离",{"2":{"1144":1}}],["我们看到了特征缩放是如何提高梯度下降的收敛速度的",{"2":{"1110":1}}],["我们看到了如何在相同形状的两个张量上执行按元素操作",{"2":{"1019":1}}],["我们看到",{"2":{"25":1,"1061":1}}],["我们描述了循环神经网络的梯度计算方法",{"2":{"305":1}}],["我们设计出了类似于神经元的神经网络",{"2":{"1099":1}}],["我们设计了专门的卷积神经网络架构来为这类特殊的数据结构建模",{"2":{"305":1}}],["我们设v为",{"2":{"1090":1}}],["我们设变量",{"2":{"1089":1}}],["我们设为wo=",{"2":{"785":1}}],["我们设该时间步的前向和反向隐状态分别为",{"2":{"521":1}}],["我们设定pq=pk=pv=po",{"2":{"382":1}}],["我们设置了最大更新步数t=20",{"2":{"72":1}}],["我们遇到过两种类型的数据",{"2":{"305":1}}],["我们遇到过图像数据",{"2":{"134":1}}],["我们努力降低每个人了解深度学习的门槛",{"2":{"302":1}}],["我们总是知道下一个数据是什么",{"2":{"651":1}}],["我们总是希望输入与正确的标签相关联",{"2":{"298":1}}],["我们总是可以写出",{"2":{"349":1}}],["我们总是可以通过去收集更多的训练数据来缓解过拟合",{"2":{"269":1}}],["我们总是可以令η小到足以使高阶项变得不相关",{"2":{"54":1}}],["我们都掌握了可用的特征",{"2":{"1189":1}}],["我们都知道",{"2":{"1176":1}}],["我们都需要计算训练集的误差的平方和",{"2":{"1164":1}}],["我们都需要从两个分布中抽取样本",{"2":{"191":1}}],["我们都会给出k​个预测",{"2":{"1120":1}}],["我们都会预先获取大量数据",{"2":{"297":1}}],["我们都有最高的概率值",{"2":{"1112":1}}],["我们都有非零的概率",{"2":{"1028":1}}],["我们都在使用梯度下降算法",{"2":{"1085":1}}],["我们都用到了所有的训练样本",{"2":{"1069":1}}],["我们都不确定结果",{"2":{"1025":1}}],["我们都将基于贪心搜索从y中找到具有最高条件概率的词元",{"2":{"513":1}}],["我们绝不希望抛弃过去每小时有关病人病史的所有信息",{"2":{"295":1}}],["我们试着推测出离散的输出值",{"2":{"1060":1}}],["我们试着推测出一个连续值的结果",{"2":{"1060":1}}],["我们试着从",{"2":{"373":1}}],["我们试着用一台计算机和一个代码编辑器编写代码",{"2":{"282":1}}],["我们试图使用学习算法",{"2":{"1058":1}}],["我们试图找到下面的d阶多项式来估计标签y",{"2":{"259":1}}],["我们试图找到一个能够尽可能拟合训练数据的函数",{"2":{"253":1}}],["我们试图只用来自大学生的人脸数据来训练一个人脸识别系统",{"2":{"253":1}}],["我们去掉平方根",{"2":{"270":1}}],["我们这样分配数据",{"2":{"1181":1}}],["我们这样做是为了便于计算",{"2":{"270":1}}],["我们这里只需要知道l的鞍点是原始约束优化问题的最优解就足够了",{"2":{"48":1}}],["我们限制∥w∥的大小",{"2":{"270":1}}],["我们恢复一个如",{"2":{"541":1}}],["我们恢复了原来的损失函数",{"2":{"270":1}}],["我们恢复常规的梯度下降",{"2":{"88":1}}],["我们便能寻找到一个更好的解决方案",{"2":{"1157":1}}],["我们便可以用这样的方法来创造大量的数据",{"2":{"1173":1}}],["我们便可以用梯度下降算法来求得能使代价函数最小的参数了",{"2":{"1109":1}}],["我们便可以丢弃该数据",{"2":{"1168":1}}],["我们便可以将其可视化了",{"2":{"1157":1}}],["我们便可以将重点放在正则化技术上",{"2":{"269":1}}],["我们便可以计算代价函数的偏导数了",{"2":{"1121":1}}],["我们便得到",{"2":{"59":1}}],["我们实际上可以获得3个新的训练实例",{"2":{"1168":1}}],["我们实际上能得到一组庞大的训练集",{"2":{"1141":1}}],["我们实际上完全有可能成功使用这些算法",{"2":{"1111":1}}],["我们实际上是要将训练集",{"2":{"1063":1}}],["我们实际上是在使用应该被正确地称为训练数据和验证数据的数据集",{"2":{"256":1}}],["我们实战演练一下",{"2":{"1035":1}}],["我们实例化两个全为1的10000维向量",{"2":{"615":1}}],["我们实例化两个全连接层",{"2":{"423":1}}],["我们实例化",{"2":{"573":1}}],["我们实例化mylinear类并访问其模型参数",{"2":{"414":2}}],["我们实例化mydense类并访问其模型参数",{"2":{"414":1}}],["我们实现的多gpu训练的简单方法受到了巨大的python开销的影响",{"2":{"837":1}}],["我们实现的每个模型都是根据某个预先指定的分布来初始化模型的参数",{"2":{"240":1}}],["我们实现了以下knn",{"2":{"750":1}}],["我们实现了以下load",{"2":{"686":1}}],["我们实现了下面的masklm类来预测bert预训练的掩蔽语言模型任务中的掩蔽标记",{"2":{"736":1}}],["我们实现了一个my",{"2":{"436":2}}],["我们实现了一个隐藏层",{"2":{"425":1}}],["我们实现",{"2":{"172":1,"633":1}}],["我们实现一个",{"2":{"121":1}}],["我们又该怎么知道呢",{"2":{"256":1}}],["我们期望泛化误差与训练误差相近",{"2":{"254":1}}],["我们期待",{"2":{"170":1}}],["我们永远不能准确地计算出泛化误差",{"2":{"252":1}}],["我们能学习数学",{"2":{"1098":1}}],["我们能用算法来处理它们",{"2":{"1060":1}}],["我们能在机器翻译中利用bert吗",{"2":{"662":1}}],["我们能在事后修正吗",{"2":{"250":1}}],["我们能够解决它",{"2":{"1061":1}}],["我们能够同时执行16个操作",{"2":{"811":1}}],["我们能够利用过去和未来的数据来估计现在空缺的词",{"2":{"522":1}}],["我们能够计算",{"2":{"519":1}}],["我们能够在遍历b的同时",{"2":{"77":1}}],["我们能否自动地给出朋友的分组呢",{"2":{"1061":1}}],["我们能否将目标检测视为回归问题",{"2":{"942":1}}],["我们能否将具有相似行为的用户聚类呢",{"2":{"296":1}}],["我们能否简单地根据经验数据发现它们之间的关系",{"2":{"296":1}}],["我们能否描述观察到的许多数据的根本原因",{"2":{"296":1}}],["我们能否找到少量的参数来准确地捕捉数据的线性相关属性",{"2":{"296":1}}],["我们能把它们分成风景照片",{"2":{"296":1}}],["我们没有任何标签y",{"2":{"1150":1}}],["我们没有限制这些输出数字的总和为1",{"2":{"643":1}}],["我们没有将softmax概率传递到损失函数中",{"2":{"624":1}}],["我们没有编写唤醒词识别器",{"2":{"282":1}}],["我们没有机会让梯度下降优化器收敛",{"2":{"243":1}}],["我们没有好处",{"2":{"232":1}}],["我们容易受到数值下溢问题的影响",{"2":{"241":1}}],["我们现在已经知道如何进行二元分类",{"2":{"1112":1}}],["我们现在已经准备好使用fashion",{"2":{"584":1}}],["我们现在构造一个9×9",{"2":{"1090":1}}],["我们现在有了电子医疗记录",{"2":{"1058":1}}],["我们现在用一个概率向量表示",{"2":{"648":1}}],["我们现在用lambd",{"2":{"276":1}}],["我们现在忽略这些细节",{"2":{"605":1}}],["我们现在",{"2":{"528":1,"616":1}}],["我们现在了解了如何结合非线性函数来构建具有更强表达能力的多层神经网络架构",{"2":{"237":1}}],["我们现在可以分析上面定义的f函数",{"2":{"977":1}}],["我们现在可以写出通过给定的x观测到特定y的似然",{"2":{"616":1}}],["我们现在可以写出更新方程",{"2":{"33":1}}],["我们现在可以创建一个函数来可视化这些样本",{"2":{"582":1}}],["我们现在可以将存储在文件中的数据读回内存",{"2":{"441":1}}],["我们现在可以",{"2":{"261":1,"472":1}}],["我们现在可以考虑机器学习问题形式化的其他方面",{"2":{"194":1}}],["我们现在可以自由控制学习率η",{"2":{"107":1}}],["我们默认使用左侧的导数",{"2":{"235":1}}],["我们默认每次滑动一个元素",{"2":{"142":1}}],["我们鼓励好奇的读者回顾一下zeshan",{"2":{"802":1}}],["我们鼓励感兴趣的读者查看损失函数的源代码",{"2":{"220":1}}],["我们鼓励喜好研究理论的读者更深入地研究这个主题",{"2":{"169":1}}],["我们建议感兴趣的读者在读完本章后",{"2":{"426":1}}],["我们建议深入研究本模块的内容",{"2":{"248":1}}],["我们建议读者阅读",{"2":{"66":1}}],["我们建立字典data",{"2":{"206":1}}],["我们之后会讲到",{"2":{"1067":1}}],["我们之所以要求出误差的平方和",{"2":{"1064":1}}],["我们之所以列出它",{"2":{"197":1}}],["我们之前曾讲过这个优化目标函数可以被写成等于12",{"2":{"1145":1}}],["我们之前推导了两种学习算法",{"2":{"1116":1}}],["我们之前在谈线性回归时讲到的特征缩放",{"2":{"1110":1}}],["我们之前学的",{"2":{"1097":1}}],["我们之前见过的肿瘤",{"2":{"1060":1}}],["我们之前讨论的多层感知机十分适合处理表格数据",{"2":{"151":1}}],["我们之前看到问题的条件数很重要",{"2":{"66":1}}],["我们之前也遇到过",{"2":{"50":1}}],["我们才能确保提高它们的性能",{"2":{"500":1}}],["我们才观测到yi",{"2":{"196":1}}],["我们才将学习率降低",{"2":{"71":1}}],["我们部署此模型来对来自同一分布的新数据",{"2":{"195":1}}],["我们所构建的模型应该能根据该测试数据的位置告诉我们其属于一组数据的可能性",{"2":{"1178":1}}],["我们所使用的这个算法与随机梯度下降算法非常类似",{"2":{"1168":1}}],["我们所需要做的是改变k值",{"2":{"1154":1}}],["我们所做的是通过设置不同正则参数λ达到优化目的",{"2":{"1143":1}}],["我们所做的就是对每个通道执行互相关操作",{"2":{"120":1}}],["我们所能做的就是调用一些别人已经写好用来计算数字平方根的函数",{"2":{"1111":1}}],["我们所能做的是将所有模型在测试时的预测取平均数",{"2":{"192":1}}],["我们所见到的卷积神经网络层",{"2":{"967":1}}],["我们要求用户为电影打分",{"2":{"1187":1}}],["我们要针对每一个特征计算",{"2":{"1180":1}}],["我们要除去1",{"2":{"1143":1}}],["我们要替代这一条蓝色的线",{"2":{"1143":1}}],["我们要将用户按照身材聚类",{"2":{"1154":1}}],["我们要将该矩阵展开成为向量",{"2":{"1124":1}}],["我们要将梯度下降和代价函数结合",{"2":{"1069":1}}],["我们要取一个合理的",{"2":{"1115":1}}],["我们要做的是找到一个方向向量",{"2":{"1158":1}}],["我们要做的便是修改代价函数",{"2":{"1115":1}}],["我们要做的就是在我们三个分类器里面输入",{"2":{"1112":1}}],["我们要做的就是旋转360度",{"2":{"1067":1}}],["我们要拟合出一个合适的分类器",{"2":{"1112":1}}],["我们要观察逻辑回归看看发生了哪些变化",{"2":{"1110":1}}],["我们要反复更新每个参数",{"2":{"1110":1}}],["我们要试图找尽量让j",{"2":{"1110":1}}],["我们要介绍如何拟合逻辑回归模型的参数θ",{"2":{"1109":1}}],["我们要使用subplot",{"2":{"1091":1}}],["我们要使用一个数据集",{"2":{"1063":1}}],["我们要讲的问题如下",{"2":{"1086":1}}],["我们要保证这些特征都具有相近的尺度",{"2":{"1082":1}}],["我们要用代价函数j",{"2":{"1068":1}}],["我们要进入这个微分项的细节之中",{"2":{"1067":1}}],["我们要这样更新",{"2":{"1067":1}}],["我们要更新θ0和θ1",{"2":{"1067":1}}],["我们要更进一步解释代价函数j的工作原理",{"2":{"1064":1}}],["我们要花很多时间来探讨",{"2":{"1059":1}}],["我们要生成一个随机矩阵并将其相乘",{"2":{"790":1}}],["我们要选择如何表示标签",{"2":{"640":1}}],["我们要指定优化的参数",{"2":{"594":2}}],["我们要注意这样的情况",{"2":{"258":1}}],["我们要注意两种常见的情况",{"2":{"258":1}}],["我们要为损失关于这些参数的梯度分配内存",{"2":{"217":1}}],["我们要评估p",{"2":{"191":1}}],["我们要强调",{"2":{"113":1}}],["我们中的一些作者几年前和他们合作过",{"2":{"185":1}}],["我们交替使用前向传播和反向传播",{"2":{"165":1}}],["我们应用学习算法",{"2":{"1060":1}}],["我们应用比例系数和比例偏移",{"2":{"467":1}}],["我们应用链式规则得",{"2":{"312":1}}],["我们应用链式法则",{"2":{"164":1}}],["我们应该怎样应对一个有100万条记录的训练集",{"2":{"1164":1}}],["我们应该选择k",{"2":{"1153":1}}],["我们应该选择一个更能适应一般情况的模型",{"2":{"1131":1}}],["我们应该选择一个复杂度适当的模型",{"2":{"267":1}}],["我们应该如何选择呢",{"2":{"1148":1}}],["我们应该如何收集和标注数据集",{"2":{"684":1}}],["我们应该如何在gpu上读写模型参数",{"2":{"453":1}}],["我们应该将填充词元的预测排除在损失函数的计算之外",{"2":{"575":1}}],["我们应该从",{"2":{"319":1}}],["我们应该期望训练误差会更低",{"2":{"252":1}}],["我们应该定义一个调度器",{"2":{"68":1}}],["我们是否应该将discount",{"2":{"1138":1}}],["我们是否需要在每个层中进行批量规范化",{"2":{"477":1}}],["我们是否需要最小汇聚层",{"2":{"150":1}}],["我们是否可以从全连接层或卷积层中删除偏置参数",{"2":{"477":1}}],["我们是否可以将线性回归或softmax回归中的所有权重参数初始化为相同的值",{"2":{"250":1}}],["我们是否能给数据分类呢",{"2":{"296":1}}],["我们是在使用系数",{"2":{"154":1}}],["我们寻找的模式可能涉及特征之间的交互",{"2":{"151":1}}],["我们希望构建一个算法来预测他们每个人可能会给他们没看过的电影打多少分",{"2":{"1187":1}}],["我们希望构建一个模型",{"2":{"1168":1}}],["我们希望知道新的数据",{"2":{"1178":1}}],["我们希望知道这个新的飞机引擎是否有某种异常",{"2":{"1178":1}}],["我们希望判断这个引擎是否需要进一步测试",{"2":{"1178":1}}],["我们希望在平均均方误差与训练集方差的比例尽可能小的情况下选择尽可能小的k值",{"2":{"1160":1}}],["我们希望投射平均均方误差能尽可能地小",{"2":{"1158":1}}],["我们希望将这个二维的数据降至一维",{"2":{"1156":1}}],["我们希望将测量的结果作为我们机器学习的特征",{"2":{"1156":1}}],["我们希望正样本和负样本投影到θ的值大",{"2":{"1145":1}}],["我们希望找出在y=1和y=0两种情况下都使得代价函数中左边的这一项尽量为零的参数",{"2":{"1144":1}}],["我们希望假设函数的输出值将趋近于0",{"2":{"1143":1}}],["我们希望它不要有高的偏差和方差",{"2":{"1141":1}}],["我们希望它们学到两种不同的模型",{"2":{"423":1}}],["我们希望能够保证查准率和召回率的相对平衡",{"2":{"1140":1}}],["我们希望能把图像里面所有我们感兴趣的目标检测出来",{"2":{"964":1}}],["我们希望通过代价函数来观察算法预测的结果与真实情况的误差有多大",{"2":{"1120":1}}],["我们希望想出一个满足某个性质的假设函数",{"2":{"1107":1}}],["我们希望用这100个特征来构建一个非线性的多项式模型",{"2":{"1097":1}}],["我们希望衡量随机变量x与其期望值的偏置",{"2":{"1036":1}}],["我们希望从同一分布中生成多个样本",{"2":{"1026":1}}],["我们希望教给读者基础的概率知识",{"2":{"1025":1}}],["我们希望智能体",{"2":{"1025":1}}],["我们希望原地执行这些更新",{"2":{"1021":1}}],["我们希望",{"2":{"976":1,"1017":1}}],["我们希望每个gpu可以复制一半的数据",{"2":{"836":1}}],["我们希望以一种方式对训练进行拆分",{"2":{"832":1}}],["我们希望使用某个函数f来拟合该比值",{"2":{"744":1}}],["我们希望使用的优化算法",{"2":{"594":1}}],["我们希望这些样本是刚好有一半实际上属于预测的类别",{"2":{"643":1}}],["我们希望得到",{"2":{"639":1}}],["我们希望寻找一组参数",{"2":{"611":1}}],["我们希望根据房屋的面积",{"2":{"609":1}}],["我们希望有一个帮助我们选择这个阀值的方法",{"2":{"1140":1}}],["我们希望有一些机制来跳过隐状态表示中的此类词元",{"2":{"538":1}}],["我们希望有某些机制能够在一个记忆元里存储重要的早期信息",{"2":{"538":1}}],["我们希望模型的输出y^j可以视为属于类j的概率",{"2":{"643":1}}],["我们希望模型可以基于相同的注意力机制学习到不同的行为",{"2":{"380":1}}],["我们希望模型深度挖掘特征",{"2":{"168":1}}],["我们希望对一组项目进行排序",{"2":{"293":1}}],["我们希望预测",{"2":{"289":1}}],["我们希望监控训练误差和验证误差这两个数字",{"2":{"212":1}}],["我们希望逐渐降低隐藏表示的空间分辨率",{"2":{"145":1}}],["我们希望速率衰减",{"2":{"66":1}}],["我们很少能有充足的数据来对每一轮实验采用全新测试集",{"2":{"256":1}}],["我们很少使用不一致的步幅或填充",{"2":{"142":1}}],["我们很难比较本质上不同大类的模型之间",{"2":{"254":1}}],["我们很可能是在研究数学而非工程",{"2":{"235":1}}],["我们很幸运",{"2":{"189":1}}],["我们很容易检查这个函数的凸性",{"2":{"46":1}}],["我们填充宽度的两侧",{"2":{"141":1}}],["我们常常丢失边缘像素",{"2":{"141":1}}],["我们常会增加输出通道的维数",{"2":{"121":1}}],["我们组合使用卷积层",{"2":{"138":1}}],["我们必须用证据来领导我们的决策",{"2":{"1138":1}}],["我们必须保证在任何数据上的输出都是非负的且总和为1",{"2":{"643":1}}],["我们必须遍历整个数据集",{"2":{"613":1}}],["我们必须",{"2":{"602":1}}],["我们必须小心区分直觉和对我们观察到的现象的真实解释",{"2":{"475":1}}],["我们必须使用从训练集构造的词表作为测试集的词表",{"2":{"669":1}}],["我们必须使用我们自己的预测",{"2":{"351":1}}],["我们必须使用数值优化算法",{"2":{"100":1}}],["我们必须考虑到它的行为可能会影响未来的观察结果",{"2":{"297":1}}],["我们必须考虑到这种可能性",{"2":{"202":1}}],["我们必须特别警惕垃圾数据带来的后果",{"2":{"284":1}}],["我们必须精确地定义问题",{"2":{"282":1}}],["我们必须以某种方式在损失函数中添加∥w∥2",{"2":{"270":1}}],["我们必须退后一步",{"2":{"201":1}}],["我们必须在小批量中展平每个样本",{"2":{"136":1}}],["我们处理的是如",{"2":{"841":1}}],["我们处理这类结构丰富的数据的方式还不够有效",{"2":{"134":1}}],["我们处理通过训练数据的随机排列获得的批量数据",{"2":{"82":1}}],["我们称那些不可逆矩阵为奇异或退化矩阵",{"2":{"1086":1}}],["我们称a和b依赖",{"2":{"1034":1}}],["我们称这种矩阵为单位矩阵",{"2":{"1076":1}}],["我们称这个比率为条件概率",{"2":{"1031":1}}],["我们称这些变量为states",{"2":{"91":1}}],["我们称该问题为上下文赌博机",{"2":{"298":1}}],["我们称步幅为s",{"2":{"142":1}}],["我们称之为常数参数",{"2":{"425":1}}],["我们称之为回归问题",{"2":{"290":1}}],["我们称之为步幅",{"2":{"142":1}}],["我们称之为填充",{"2":{"142":1}}],["我们称其为元素",{"2":{"130":1}}],["我们先从用三角形代表的类别1开始",{"2":{"1112":1}}],["我们先从计算机的研究开始",{"2":{"800":1}}],["我们先把左半部分遮住",{"2":{"1100":1}}],["我们先来快速生成一些数据用来绘图",{"2":{"1091":1}}],["我们先来定义一下什么是一个",{"2":{"170":1}}],["我们先学习一些关于数据的实用技能",{"2":{"987":1}}],["我们先通过extract",{"2":{"923":1}}],["我们先为图像生成多个锚框",{"2":{"854":1}}],["我们先",{"2":{"828":1}}],["我们先定义它的损失函数",{"2":{"764":1}}],["我们先对所有项进行幂运算",{"2":{"644":1}}],["我们先看看如何使用单个nvidia",{"2":{"445":1}}],["我们先回顾一下多层感知机",{"2":{"422":1}}],["我们先将训练集中的所有文档合并在一起",{"2":{"363":1}}],["我们先分离梯度",{"2":{"335":1}}],["我们先读取数据集",{"2":{"329":1}}],["我们先简要回顾一下为什么上面的操作被称为卷积",{"2":{"156":1}}],["我们先构造一个卷积层",{"2":{"129":1}}],["我们先详细回顾一下这些技术",{"2":{"32":1}}],["我们不是优化这里的a+λ×b",{"2":{"1143":1}}],["我们不得不去用这一项来平衡",{"2":{"1143":1}}],["我们不对方差特征进行处理",{"2":{"1159":1}}],["我们不对",{"2":{"1115":1}}],["我们不对又称为正则化参数",{"2":{"1115":1}}],["我们不能提前预知",{"2":{"1083":1}}],["我们不能直接计算目标数据上的混淆矩阵",{"2":{"192":1}}],["我们不知道谁是在一号细分市场",{"2":{"1061":1}}],["我们不知道如何写一段程序让直升机自己飞",{"2":{"1058":1}}],["我们不知道对手的牌",{"2":{"301":1}}],["我们不想总是不必要地分配内存",{"2":{"1021":1}}],["我们不想让模型只会做这样的事情",{"2":{"251":1}}],["我们不断抽取合成图像的内容特征和风格特征",{"2":{"927":1}}],["我们不断地将隐状态传递到下一个时间步",{"2":{"333":1}}],["我们不仅知道肿瘤的尺寸",{"2":{"1060":1}}],["我们不仅想知道它们的类别",{"2":{"857":1}}],["我们不仅仅可以接收一个序列作为输入",{"2":{"305":1}}],["我们不仅仅希望输出一个类别或一个实值",{"2":{"293":1}}],["我们不妨将假设中的",{"2":{"674":1}}],["我们不妨使用所有数据对其进行训练",{"2":{"213":1}}],["我们不必传输任何信息",{"2":{"651":1}}],["我们不必单独分配参数",{"2":{"595":1}}],["我们不应该随机选择上面的某种方法来改进我们的算法",{"2":{"1129":1}}],["我们不应该想当然地认为我们能够完美地求解参数",{"2":{"605":1}}],["我们不应偏离到距",{"2":{"155":1}}],["我们不再需要样本均值中的噪声以及在微批次上估计每个小批次产生的样本方差了",{"2":{"471":1}}],["我们不再需要决定梯度何时算足够大",{"2":{"25":1}}],["我们不需要通过手动指定每个维度来改变形状",{"2":{"1017":1}}],["我们不需要编写任何特定的代码来实现并行性",{"2":{"837":1}}],["我们不需要告诉keras有多少输入进入这一层",{"2":{"591":1}}],["我们不需要告诉gluon有多少输入进入这一层",{"2":{"591":1}}],["我们不需要添加术语",{"2":{"479":1}}],["我们不需要为每个自定义层编写自定义的序列化程序",{"2":{"414":1}}],["我们不需要设计一个",{"2":{"282":1}}],["我们不会使用一个固定的数据集",{"2":{"1168":1}}],["我们不会太深究细节",{"2":{"987":1}}],["我们不会在每次对一个参数求导时都分配新的内存",{"2":{"974":1}}],["我们不会损失几天的计算结果",{"2":{"440":1}}],["我们不会深入探讨太多细节",{"2":{"350":1}}],["我们不会丢弃任何节点",{"2":{"171":1}}],["我们不希望用到测试集",{"2":{"256":1}}],["我们不可能同时满足这两个条件",{"2":{"247":1}}],["我们不可能手动设计滤波器",{"2":{"129":1}}],["我们不考虑正则化",{"2":{"190":1}}],["我们也给出了通过给出的数据集拟合参数",{"2":{"1180":1}}],["我们也给代价函数增加一个正则化的表达式",{"2":{"1117":1}}],["我们也介绍了学习算法的调试",{"2":{"1176":1}}],["我们也花时间讨论了一些特别的应用或者特别的话题",{"2":{"1176":1}}],["我们也把这个过程称为重建原始数据",{"2":{"1161":1}}],["我们也构建一个代价函数",{"2":{"1081":1}}],["我们也将知道怎样避免把过多的时间浪费在收集更多的训练数据上",{"2":{"1129":1}}],["我们也将介绍这些方法",{"2":{"1069":1}}],["我们也将带有h×w卷积核的卷积层称为h×w卷积层",{"2":{"127":1}}],["我们也需要考虑概率",{"2":{"1025":1}}],["我们也对分类问题感兴趣",{"2":{"639":1}}],["我们也希望保留传统的softmax函数",{"2":{"624":1}}],["我们也会有接近5000个组合而成的特征",{"2":{"1097":1}}],["我们也会谈到这个方法",{"2":{"1069":1}}],["我们也会加入一个噪声项来考虑观测误差带来的影响",{"2":{"610":1}}],["我们也会遇到这类问题",{"2":{"292":1}}],["我们也会看到具有非零方差的梯度",{"2":{"26":1}}],["我们也不希望编个程序把这些点画出来",{"2":{"1066":1}}],["我们也不会吃它",{"2":{"291":1}}],["我们也不能仅仅依靠训练数据来选择模型",{"2":{"256":1}}],["我们也不可能存储整个查找表",{"2":{"252":1}}],["我们也可以令学习率随着迭代次数的增加而减小",{"2":{"1167":1}}],["我们也可以同时将训练集和交叉验证集模型的代价函数误差与λ的值绘制在一张图表上",{"2":{"1133":1}}],["我们也可以考虑其他方法减小或增大正则化参数λ的值",{"2":{"1129":1}}],["我们也可以尝试增加多项式特征的方法",{"2":{"1129":1}}],["我们也可以对逻辑回归模型沿用这个定义",{"2":{"1109":1}}],["我们也可以对非极大值抑制的输出结果进行后处理",{"2":{"854":1}}],["我们也可以看到这些概率如何随着时间的推移收敛到真实概率",{"2":{"1026":1}}],["我们也可以把多个张量连结",{"2":{"1018":1}}],["我们也可以通过",{"2":{"991":1}}],["我们也可以通过将参数服务器数量增加到n来突破这一障碍",{"2":{"843":1}}],["我们也可以通过一些巧妙的预处理来解决问题",{"2":{"230":1}}],["我们也可以从另一个角度来理解glove模型",{"2":{"744":1}}],["我们也可以将标签视为一个随机变量",{"2":{"1029":1}}],["我们也可以将预先训练的词向量应用于情感分析",{"2":{"712":1}}],["我们也可以将其改为选择从均匀分布中抽取权重时的方差",{"2":{"247":1}}],["我们也可以为一维卷积指定多个输出通道",{"2":{"699":1}}],["我们也可以使用x",{"2":{"1021":1}}],["我们也可以使用矩阵",{"2":{"998":1}}],["我们也可以使用双向循环神经网络构造编码器",{"2":{"573":1}}],["我们也可以使用后向递归对同一组隐变量求和",{"2":{"519":1}}],["我们也可以在",{"2":{"501":1}}],["我们也可以直接使用深度学习框架中定义的batchnorm",{"2":{"474":1}}],["我们也可以取一个新的函数",{"2":{"286":1}}],["我们也可能会遇到概念偏移",{"2":{"183":1}}],["我们也随机初始化卷积核权重",{"2":{"127":1}}],["我们暂时忽略通道",{"2":{"126":1}}],["我们对单一的实例进行学习",{"2":{"1168":1}}],["我们对小于0和大于1的值分别取0和1",{"2":{"919":1}}],["我们对词典token",{"2":{"757":1}}],["我们对列进行求和",{"2":{"631":1}}],["我们对计算进行矢量化",{"2":{"615":1}}],["我们对第一个模块做了特别处理",{"2":{"502":1}}],["我们对每个时间步的输出层的输出进行softmax操作",{"2":{"341":1}}],["我们对模型参数采用更新步骤",{"2":{"334":1}}],["我们对编写这个程序毫无头绪",{"2":{"282":1}}],["我们对原始模型做了一点小改动",{"2":{"136":1}}],["我们对参数x",{"2":{"128":1}}],["我们对输入张量x与卷积核张量k执行互相关运算",{"2":{"121":1}}],["我们对数据样本随机均匀采样一个索引i",{"2":{"113":1}}],["我们",{"2":{"120":1,"137":1,"142":1,"146":1,"173":1,"176":1,"209":3,"271":1,"318":1,"321":1,"325":1,"331":1,"350":2,"364":1,"413":1,"442":2,"474":1,"480":1,"600":1,"625":1,"633":1,"635":2,"848":1,"858":1,"862":2,"874":1,"880":1,"882":2,"883":1,"892":1,"912":2,"932":1,"945":1,"946":1,"959":1,"964":1,"980":1,"990":1,"1020":1}}],["我们卷积核的每个输入通道将包含形状为kh×kw的张量",{"2":{"120":1}}],["我们的新模型会认为她给每部电影的评分都是该电影的平均分",{"2":{"1192":1}}],["我们的优化目标便改为同时针对x和θ进行",{"2":{"1189":1}}],["我们的字符切分部分可能已经足够好了",{"2":{"1174":1}}],["我们的流程图如下",{"2":{"1174":1}}],["我们的",{"2":{"1154":1}}],["我们的的优化目标便是找出使得代价函数最小的",{"2":{"1152":1}}],["我们的推导自始至终使用了这个简化假设",{"2":{"1145":1}}],["我们的代价函数",{"2":{"1143":1}}],["我们的书写会稍微有些不同",{"2":{"1143":1}}],["我们的网络选择出的方向是随机的",{"2":{"1127":1}}],["我们的网络可以表示为",{"2":{"241":1}}],["我们的算法可以很好的适应用户的倾向性",{"2":{"1168":1}}],["我们的算法将没有方差",{"2":{"1141":1}}],["我们的算法输出的结果在0",{"2":{"1140":1}}],["我们的算法表示为",{"2":{"1121":1}}],["我们的算法不需要额外的特征",{"2":{"252":1}}],["我们的神经网络便能够准确地模拟人类驾驶者的驾驶方向",{"2":{"1127":1}}],["我们的神经网络是一个四层的神经网络",{"2":{"1121":1}}],["我们的神经元把自己的收到的消息进行计算",{"2":{"1099":1}}],["我们的hθ",{"2":{"1120":1}}],["我们的第一个学习算法是线性回归算法",{"2":{"1063":1}}],["我们的第一步是标准化输入特征",{"2":{"467":1}}],["我们的兴趣不仅限于读取数据和写入数据",{"2":{"1018":1}}],["我们的目标和单变量线性回归问题中一样",{"2":{"1081":1}}],["我们的目标便是选择出可以使得建模误差的平方和能够最小的模型参数",{"2":{"1064":1}}],["我们的目标是预测这些分数",{"2":{"658":1}}],["我们的目标是找到能够区分正样本和负样本的决策边界",{"2":{"1150":1}}],["我们的目标是找到一个常数b",{"2":{"621":1}}],["我们的目标是找到使损失函数最小化的模型参数值",{"2":{"429":1}}],["我们的目标是寻找模型的权重w和偏置b",{"2":{"610":1}}],["我们的目标是从所有o",{"2":{"512":1}}],["我们的目标是根据过去的和当前的词元预测下一个词元",{"2":{"341":1}}],["我们的目标是生成一个模型",{"2":{"289":1}}],["我们的目标是发现某些模式",{"2":{"251":1}}],["我们的目标是发现模式",{"2":{"251":1}}],["我们的目标是学习一个模型",{"2":{"157":1}}],["我们的目的不是计算微分矩阵",{"2":{"975":1}}],["我们的重点是如何应用深度语言表征学习来解决自然语言处理问题",{"2":{"663":1}}],["我们的惊异会更大",{"2":{"651":1}}],["我们的输出函数hθ",{"2":{"1101":1}}],["我们的输出是由权重与输入特征进行矩阵",{"2":{"641":1}}],["我们的输出与类别一样多",{"2":{"630":1}}],["我们的输入和隐藏的表示都变成了三维张量",{"2":{"119":1}}],["我们的预测问题是最小化∥y−xw∥2",{"2":{"612":1}}],["我们的任务是更新这些参数",{"2":{"601":1}}],["我们的任务是使用这个有限样本的数据集来恢复这个模型的参数",{"2":{"599":1}}],["我们的合成数据集是一个矩阵x∈r1000×2",{"2":{"599":1}}],["我们的模型代价函数值为0",{"2":{"1144":1}}],["我们的模型已经准备好",{"2":{"636":1}}],["我们的模型只包含一个层",{"2":{"591":1}}],["我们的模型可能难以拟合我们的训练数据",{"2":{"155":1}}],["我们的层将保存均值和方差的移动平均值",{"2":{"472":1}}],["我们的实现只需要提供我们自己的构造函数",{"2":{"423":1}}],["我们的数据没有附带任何标签",{"2":{"1150":1}}],["我们的数据集或许看起来像这样",{"2":{"1112":1}}],["我们的数据看起来可能是像这样",{"2":{"1112":1}}],["我们的数据只包含",{"2":{"294":1}}],["我们的数据可能会有一种表示",{"2":{"230":1}}],["我们的损失由下式给出",{"2":{"270":1}}],["我们的学习算法可能会更集中于最小化权重范数∥w∥2",{"2":{"270":1}}],["我们的特征是x的幂给出的",{"2":{"259":1}}],["我们的特征现在是平移不变的",{"2":{"155":1}}],["我们的训练集可以写成只有x",{"2":{"1150":1}}],["我们的训练误差将与泛化误差相匹配",{"2":{"252":1}}],["我们的训练函数将借助adam优化器",{"2":{"210":1}}],["我们的隐藏表示h也最好采用三维张量",{"2":{"158":1}}],["我们的系统应该能够利用常识",{"2":{"152":1}}],["我们的更新使用动量v^t而不是梯度本身",{"2":{"33":1}}],["我们仅使用句号作为分隔符来拆分句子",{"2":{"718":1}}],["我们仅使用前600个",{"2":{"350":1}}],["我们仅示范使用此类内置函数的实现方式",{"2":{"528":1}}],["我们仅考虑惩罚项",{"2":{"270":1}}],["我们仅仅通过将图像数据展平成一维向量而忽略了每个图像的空间结构信息",{"2":{"134":1}}],["我们仅仅讨论了由某些允许我们在其上执行随机梯度下降的函数δxi和δyi组成的离散分布p",{"2":{"116":1}}],["我们仅展示了单个输入和单个输出通道的简化例子",{"2":{"119":1}}],["我们遍历了所有实例恰好一次",{"2":{"116":1}}],["我们显然没有这样做",{"2":{"116":1}}],["我们假使数据集是正常的",{"2":{"1178":1}}],["我们假定这些模型参数包含从源数据集中学到的知识",{"2":{"870":1}}],["我们假装有成对的",{"2":{"116":1}}],["我们假设对于我们希望推荐的东西有一些数据",{"2":{"1188":1}}],["我们假设后来有一天",{"2":{"1178":1}}],["我们假设支持向量机会选择这个决策边界",{"2":{"1145":1}}],["我们假设在我们的机器学习问题中",{"2":{"1141":1}}],["我们假设的输出",{"2":{"1110":2}}],["我们假设您的电子邮件程序会观察收到的邮件是否被你标记为垃圾邮件",{"2":{"1059":1}}],["我们假设图像中只有一个主要物体对象",{"2":{"857":1}}],["我们假设预测的偏移量都是零",{"2":{"854":1}}],["我们假设所有梯度共需160mb",{"2":{"841":1}}],["我们假设了观测中包含噪声",{"2":{"616":1}}],["我们假设任何噪声都比较正常",{"2":{"609":1}}],["我们假设它是我的第一个样本x",{"2":{"1145":1}}],["我们假设它有一个唯一的名称",{"2":{"424":1}}],["我们假设它存在于定义x的域中",{"2":{"115":1}}],["我们假设训练数据集是一个大型的文本语料库",{"2":{"316":1}}],["我们假设训练数据和测试数据都是从相同的分布中独立提取的",{"2":{"253":1}}],["我们假设1≤i≤n的xi来自某个源分布",{"2":{"191":1}}],["我们假设输入样本是",{"2":{"162":1}}],["我们假设从分布p",{"2":{"116":1}}],["我们假设随机梯度∂xf",{"2":{"115":1}}],["我们假设fi",{"2":{"113":1}}],["我们假设函数的输入是k维向量",{"2":{"102":1}}],["我们根据之前的数据预测出一个准确的输出值",{"2":{"1063":1}}],["我们根据类别和偏移量的预测和标注值计算损失函数",{"2":{"963":1}}],["我们根据标签信息y为生成的锚框标记类别",{"2":{"963":1}}],["我们根据训练集和验证集组合而成的训练模型进行训练",{"2":{"892":1}}],["我们根据估计值与观测值之间的差异来更新w",{"2":{"270":1}}],["我们根据链式法则计算目标函数关于输出层变量o的梯度",{"2":{"164":1}}],["我们根据",{"2":{"115":1}}],["我们一次给用户提供3个物流选项",{"2":{"1168":1}}],["我们一直使用方形边界框来标注和预测图像中的目标",{"2":{"943":1}}],["我们一直在使用深度学习框架的高级api直接获取张量格式的图像数据集",{"2":{"887":1}}],["我们一直在使用这个技巧",{"2":{"49":1}}],["我们一直在通过net",{"2":{"422":4}}],["我们一直在训练过程中使用随机梯度下降",{"2":{"112":1}}],["我们一开始就不会取得任何有意义的进展",{"2":{"113":1}}],["我们详细讨论了这两个目标之间的区别",{"2":{"99":1}}],["我们详述了如何执行随机梯度下降",{"2":{"84":1}}],["我们用ureduce表示",{"2":{"1159":1}}],["我们用δij",{"2":{"1121":1}}],["我们用δ来表示误差",{"2":{"1121":1}}],["我们用三角形表示",{"2":{"1112":1}}],["我们用这条规则对$",{"2":{"1093":1}}],["我们用这样的格拉姆矩阵来表达风格层输出的风格",{"2":{"923":1}}],["我们用一个聚类来运行k均值聚类方法",{"2":{"1154":1}}],["我们用一个向量化的代码实现",{"2":{"1093":1}}],["我们用一个",{"2":{"1093":1}}],["我们用一个例子介绍什么是监督学习把正式的定义放在后面介绍",{"2":{"1060":1}}],["我们用一个单独的函数定义其数学原理",{"2":{"472":1}}],["我们用python的id",{"2":{"1021":1}}],["我们用同一列的均值替换",{"2":{"1012":1}}],["我们用每个提议区域的特征来预测类别和边界框",{"2":{"937":1}}],["我们用输入图像在某个感受野区域内的信息",{"2":{"913":1}}],["我们用以下函数读取csv文件中的标签",{"2":{"890":1}}],["我们用以上adam算法来训练模型",{"2":{"34":1}}],["我们用xi表示上下文窗口中的所有上下文词的数量",{"2":{"742":1}}],["我们用",{"2":{"617":1,"864":1}}],["我们用下面的数学公式来表示这一更新过程",{"2":{"613":1}}],["我们用下面的示例代码引以为戒",{"2":{"523":1}}],["我们用与前面提到的编码器中相同的超参数来",{"2":{"574":1}}],["我们用空格代替不间断空格",{"2":{"565":1}}],["我们用它",{"2":{"376":1}}],["我们用困惑度来评价模型",{"2":{"335":1}}],["我们用数据训练",{"2":{"282":1}}],["我们用几个张量来表示我们的参数",{"2":{"217":1}}],["我们用独热编码替换它们",{"2":{"209":1}}],["我们用⊙表示",{"2":{"164":1}}],["我们用深度学习框架中内置的二维最大汇聚层",{"2":{"147":1}}],["我们用r来表示2×2管理的收敛表现",{"2":{"95":1}}],["我们首先计算所有特征的平均值",{"2":{"1184":1}}],["我们首先要随机初始化所有的聚类中心点",{"2":{"1153":1}}],["我们首先要做的决定是如何选择并表达特征向量x",{"2":{"1137":1}}],["我们首先要注意我们是否解决了正确的问题",{"2":{"201":1}}],["我们首先学习了使用梯度下降法来优化代价函数j",{"2":{"1117":1}}],["我们首先创建一个新的矩阵z",{"2":{"1021":1}}],["我们首先讨论导数的计算",{"2":{"981":1}}],["我们首先将梯度附加到想要对其计算偏导数的变量上",{"2":{"978":1}}],["我们首先将通道维移到最后一维",{"2":{"956":1}}],["我们首先将每个大小为28×28的图像展平为一个784维的固定长度的一维向量",{"2":{"135":1}}],["我们首先获取预训练模型的输出层的输入",{"2":{"905":1}}],["我们首先从图像中裁切随机大小和随机长宽比的区域",{"2":{"872":1}}],["我们首先从net访问所需的层",{"2":{"595":1}}],["我们首先为bert的两个预训练任务实现辅助函数",{"2":{"719":1}}],["我们首先求和这两组比较向量",{"2":{"676":1}}],["我们首先对每个未规范化的预测求幂",{"2":{"643":1}}],["我们首先随机抽样一个小批量b",{"2":{"613":1}}],["我们首先定义一个模型变量net",{"2":{"591":1}}],["我们首先定义一个生成块的函数",{"2":{"433":1}}],["我们首先",{"2":{"589":1,"1011":1}}],["我们首先加载时光机器数据集",{"2":{"557":1}}],["我们首先介绍重置门",{"2":{"540":1}}],["我们首先实现一下这个架构",{"2":{"480":1}}],["我们首先规范化输入",{"2":{"467":1}}],["我们首先看一下具有单隐藏层的多层感知机",{"2":{"429":1}}],["我们首先看一下前向传播函数",{"2":{"423":1}}],["我们首先使用时光机器数据集作为语料库来",{"2":{"363":1}}],["我们首先回顾",{"2":{"338":1}}],["我们首先需要对结果",{"2":{"1192":1}}],["我们首先需要检查以确定数据不在一级缓存中",{"2":{"810":1}}],["我们首先需要确定如何添加更多的层",{"2":{"526":1}}],["我们首先需要",{"2":{"332":1}}],["我们首先需要定义一个函数",{"2":{"211":1}}],["我们首先观测到xi",{"2":{"196":1}}],["我们首先采用性能相当好的现成的分类器",{"2":{"192":1}}],["我们首先构造了一个输入张量x",{"2":{"147":1}}],["我们首先用两个标量重写更新方程",{"2":{"95":1}}],["我们首先选择初始值x和常数η",{"2":{"54":1}}],["我们会做的是获取一个用户样本",{"2":{"1168":1}}],["我们会希望θtx",{"2":{"1144":1}}],["我们会从这个代价函数开始",{"2":{"1143":1}}],["我们会采用一些截词软件",{"2":{"1138":1}}],["我们会把单训练样本的代价函数的这些理念进一步发展",{"2":{"1109":1}}],["我们会令u",{"2":{"1093":1}}],["我们会使用一种叫做正则化的线性代数方法",{"2":{"1086":1}}],["我们会看到",{"2":{"1085":1}}],["我们会得出第一个机器学习算法",{"2":{"1068":1}}],["我们会得到六个候选输出序列",{"2":{"515":1}}],["我们会得到通道数为3+2×10=23的输出",{"2":{"480":1}}],["我们会得到奖励或损失",{"2":{"196":1}}],["我们会遇到更复杂",{"2":{"1066":1}}],["我们会尝试着进行定义",{"2":{"1059":1}}],["我们会考虑多个随机变量",{"2":{"1029":1}}],["我们会连续地获得不同的小批量",{"2":{"600":1}}],["我们会充分利用深度学习框架的优势",{"2":{"598":1}}],["我们会进行以下步骤",{"2":{"595":1}}],["我们会按时间顺序介绍这些模型",{"2":{"492":1}}],["我们会收集所有空间位置的值",{"2":{"470":1}}],["我们会变得兴奋并想读书",{"2":{"355":1}}],["我们会发现这些p",{"2":{"1145":1}}],["我们会发现id",{"2":{"1021":1}}],["我们会发现精度很少成为合适的衡量标准",{"2":{"201":1}}],["我们会发现关于",{"2":{"183":1}}],["我们会不断地改进我们的模型",{"2":{"196":1}}],["我们会评估我们的预测是否盈利",{"2":{"196":1}}],["我们会降低学习率",{"2":{"114":1}}],["我们会在优化上浪费太多时间",{"2":{"114":1}}],["我们会确保解不会在x2方向发散",{"2":{"87":1}}],["我们会期望在f的最小化器中只产生微小的变化",{"2":{"26":1}}],["我们陷入两难",{"2":{"87":1}}],["我们复习一下梯度下降",{"2":{"87":1}}],["我们移除了均值并将方差重新缩放到每个坐标为1",{"2":{"79":1}}],["我们来多找点数据吧",{"2":{"1129":1}}],["我们来求一个",{"2":{"1090":1}}],["我们来细化一下长短期记忆网络的数学表达",{"2":{"553":1}}],["我们来构造densenet模型",{"2":{"482":1}}],["我们来试一下这个函数",{"2":{"423":1}}],["我们来看一个例子",{"2":{"1068":1}}],["我们来看一张图片",{"2":{"619":1}}],["我们来看一下为什么支持向量机不会选择它",{"2":{"1145":1}}],["我们来看一下支持向量机会选择什么样的决策界",{"2":{"1145":1}}],["我们来看一下词量",{"2":{"722":1}}],["我们来看一下门控循环单元的数学表达",{"2":{"540":1}}],["我们来看一下完整的协变量偏移纠正算法",{"2":{"191":1}}],["我们来看看二元语法的频率是否与一元语法的频率表现出相同的行为方式",{"2":{"318":1}}],["我们来看看这些高效的代码",{"2":{"78":1}}],["我们来",{"2":{"126":1,"1007":1}}],["我们来证明一下一维情况",{"2":{"46":1}}],["我们最大化p",{"2":{"646":1}}],["我们最好可以利用在时间或空间上逐渐发生偏移的知识",{"2":{"183":1}}],["我们最好用向量化",{"2":{"77":1}}],["我们最感兴趣的是xt和x∗之间的距离如何变化的期望",{"2":{"115":1}}],["我们最终可以得到一个低误差和低方差的学习算法",{"2":{"1141":1}}],["我们最终可能会得到太多需要计算的锚框",{"2":{"911":1}}],["我们最终可能只会得到许多解的一个",{"2":{"56":1}}],["我们最终都要计算这样一个东西",{"2":{"1069":1}}],["我们最终会在优化计算时做出某些妥协",{"2":{"811":1}}],["我们最终会选择αi=0",{"2":{"48":1}}],["我们最终得到的输出远小于输入大小",{"2":{"140":1}}],["我们最终将除以hessian",{"2":{"59":1}}],["我们在vue3中使用watch的时候",{"2":{"1461":1}}],["我们在之前的视频中讨论过误差",{"2":{"1148":1}}],["我们在之前的课程已经学习过两种优化算法",{"2":{"1117":1}}],["我们在尝试最小化代价时也需要将这个惩罚纳入考虑中",{"2":{"1115":1}}],["我们在本视频中有见到了",{"2":{"1061":1}}],["我们在本节中省略了单发多框检测模型的一些实现细节",{"2":{"966":1}}],["我们在试着推测出这一系列连续值属性",{"2":{"1060":1}}],["我们在很远的距离",{"2":{"1025":1}}],["我们在这部分的目标不是教授整个科目",{"2":{"1025":1}}],["我们在这里不使用",{"2":{"962":1}}],["我们在这里将它们同语义分割简单区分一下",{"2":{"944":1}}],["我们在这里将它的输入参数变得更加通用",{"2":{"80":1}}],["我们在这里只训练20个周期",{"2":{"895":1}}],["我们在这里使用的数据集是penn",{"2":{"772":1}}],["我们在这里指定超参数",{"2":{"376":1}}],["我们在这里所做的改变是",{"2":{"364":1}}],["我们在这里忽略了标点符号和字母大写",{"2":{"361":1}}],["我们在这里保存了前一个时间步的隐藏变量ht−1",{"2":{"340":1}}],["我们在这里比较幸运",{"2":{"59":1}}],["我们在a和b上执行矩阵乘法",{"2":{"999":1}}],["我们在图片上为这些香蕉标记了边界框",{"2":{"930":1}}],["我们在一些背景图片的随机位置上放一张香蕉的图像",{"2":{"930":1}}],["我们在一个小的数据集上训练了一个word2vec模型",{"2":{"747":1}}],["我们在一个高性能的深度学习库中进行了大量的字典查找",{"2":{"426":4}}],["我们在cifar",{"2":{"883":1}}],["我们在contexts",{"2":{"776":2}}],["我们在corr2d函数中实现如上过程",{"2":{"126":1}}],["我们在示例的张量输入中添加了维度",{"2":{"854":1}}],["我们在开始时使用了更小的卷积核",{"2":{"826":1}}],["我们在词表中找到与",{"2":{"750":1}}],["我们在下面定义了高和宽减半块down",{"2":{"957":1}}],["我们在下面的类中实现textcnn模型",{"2":{"702":1}}],["我们在下面的corr1d函数中实现了一维互相关",{"2":{"699":1}}],["我们在下面讨论这两种情况",{"2":{"468":1}}],["我们在路径",{"2":{"666":1}}],["我们在训练分类器时几乎总会关注它",{"2":{"634":1}}],["我们在线性层前定义了展平层",{"2":{"623":1}}],["我们在文本数据上实现了基于循环神经网络的语言模型",{"2":{"550":1}}],["我们在观测状态和隐状态上具有以下联合概率分布",{"2":{"519":1}}],["我们在观察事实之后进行估计",{"2":{"254":1}}],["我们在fashion",{"2":{"503":1}}],["我们在每一次更新",{"2":{"1167":1}}],["我们在每一层的隐藏单元之间具有排列对称性",{"2":{"244":1}}],["我们在每个块的高度和宽度减半",{"2":{"508":1}}],["我们在每个输出通道的m⋅p⋅q个元素上同时执行每个批量规范化",{"2":{"470":1}}],["我们在方差估计值中添加一个小的常量ϵ",{"2":{"467":1}}],["我们在第一个gpu上创建张量变量x",{"2":{"448":1}}],["我们在接下来的章节中充分利用了这种多功能性",{"2":{"423":1}}],["我们在初始化参数时",{"2":{"417":1}}],["我们在引入softmax回归",{"2":{"342":1}}],["我们在更新模型参数之前裁剪梯度",{"2":{"335":1}}],["我们在此没有方差问题",{"2":{"1141":1}}],["我们在此明确一下",{"2":{"991":1}}],["我们在此计算了所有模型参数的梯度的范数",{"2":{"334":1}}],["我们在此使用内置的二维卷积层",{"2":{"129":1}}],["我们在迭代中计算这t个时间步上的梯度",{"2":{"334":1}}],["我们在序列上调用了detach函数",{"2":{"306":1}}],["我们在实例化优化器时直接通过weight",{"2":{"278":1}}],["我们在实例化trainer时直接通过wd指定weight",{"2":{"278":1}}],["我们在测试时不用暂退法",{"2":{"171":1}}],["我们在",{"2":{"156":1,"170":1,"229":1,"232":1,"306":1,"338":1,"360":1,"434":1,"572":1,"634":1,"672":1,"887":1}}],["我们在深度网络中实现rmsprop算法",{"2":{"108":1}}],["我们在时间t=0初始化v0=0",{"2":{"88":1}}],["我们在x1方向上进展很快",{"2":{"87":1}}],["我们在选择学习率需要格外谨慎",{"2":{"84":1}}],["我们在基于梯度的学习方法中遇到了两个极端情况",{"2":{"76":1}}],["我们混合网络以提高性能",{"2":{"67":1}}],["我们从其中选择一部分正常数据用于构建训练集",{"2":{"1181":1}}],["我们从带标记",{"2":{"1181":1}}],["我们从这里开始",{"2":{"1143":1}}],["我们从优化目标开始",{"2":{"1143":1}}],["我们从1行数据开始",{"2":{"1134":1}}],["我们从最后一层的误差开始计算",{"2":{"1121":1}}],["我们从第一层开始正向一层一层进行计算",{"2":{"1121":1}}],["我们从二元的分类问题开始讨论",{"2":{"1106":1}}],["我们从mxnet导入np",{"2":{"1017":1}}],["我们从mxnet导入initializer模块",{"2":{"592":1}}],["我们从动态计算梯度的树中分离目标",{"2":{"922":2}}],["我们从训练数据集中创建一个词表",{"2":{"693":1}}],["我们从读取数据集开始",{"2":{"678":1}}],["我们从情感分析应用开始",{"2":{"663":1}}],["我们从标准差为0",{"2":{"544":1}}],["我们从构造这些门控开始",{"2":{"540":1}}],["我们从它开始解读",{"2":{"538":1}}],["我们从加载数据集开始",{"2":{"528":1}}],["我们从头开始实现一个具有张量的批量规范化层",{"2":{"472":1}}],["我们从已有模型中访问参数",{"2":{"430":1}}],["我们从零开始实现长短期记忆网络",{"2":{"557":1}}],["我们从零开始实现它",{"2":{"543":1}}],["我们从零开始实现了多层感知机的每个组件",{"2":{"421":1}}],["我们从零开始编写一个块",{"2":{"423":1}}],["我们从h",{"2":{"361":1}}],["我们从一个例子开始定义推荐系统的问题",{"2":{"1187":1}}],["我们从一个简单的计算机视觉问题和一个稍稍过时的网络开始",{"2":{"832":1}}],["我们从一个简单的问题开始",{"2":{"67":1}}],["我们从一个图像分类问题开始",{"2":{"640":1}}],["我们从一个描述循环神经网络工作原理的简化模型开始",{"2":{"307":1}}],["我们从来没有想过数据最初从哪里来",{"2":{"179":1}}],["我们从均匀分布u",{"2":{"172":1}}],["我们从有关特征学习中并不常见的问题入手",{"2":{"24":1}}],["我们主要关注如何更新权重向量的优化算法",{"2":{"66":1}}],["我们以后会讲一个算法",{"2":{"1060":1}}],["我们以输入图像的每个像素为中心",{"2":{"911":1}}],["我们以图像的每个像素为中心生成不同形状的锚框",{"2":{"848":1,"855":1}}],["我们以图的方式描述了多层感知机",{"2":{"231":1}}],["我们以小批量方式加载样本",{"2":{"778":1}}],["我们以英语到法语的机器翻译为例",{"2":{"532":1}}],["我们以往假设的目标是",{"2":{"518":1}}],["我们以一些想到的方法嵌套块",{"2":{"425":1}}],["我们以",{"2":{"346":1}}],["我们以部分目标凸函数f为例",{"2":{"60":1}}],["我们以非常类似于rmsprop算法的方式重新缩放梯度以获得",{"2":{"33":1}}],["我们姑且先忽略这些考量",{"2":{"59":1}}],["我们还提到了很多关于构建机器学习系统的实用建议",{"2":{"1176":1}}],["我们还有很多更加先进的试验来实现自动驾驶技术",{"2":{"1127":1}}],["我们还会找到一种比我们目前用的更简单的写法",{"2":{"1109":1}}],["我们还会谈论其他的代价函数",{"2":{"1064":1}}],["我们还能做什么呢",{"2":{"1089":1}}],["我们还介绍了回归问题",{"2":{"1060":1}}],["我们还定义了normalize",{"2":{"947":1}}],["我们还定义了它的预测概率",{"2":{"854":1}}],["我们还从vgg中选择不同层的输出来匹配局部和全局的风格",{"2":{"920":1}}],["我们还假设源模型的输出层与源数据集的标签密切相关",{"2":{"870":1}}],["我们还描述了学术界当下使用最广泛的大规模图像数据集imagenet",{"2":{"869":1}}],["我们还构建了五个锚框",{"2":{"853":1}}],["我们还打印出了该词元的bert表示的前三个元素",{"2":{"727":1}}],["我们还使用了两个嵌入层",{"2":{"702":1}}],["我们还设计了基于循环神经网络和注意力机制的机器翻译模型",{"2":{"663":1}}],["我们还研究了自然语言推断",{"2":{"658":1}}],["我们还记录了每个文本序列的长度",{"2":{"568":1}}],["我们还指定了额外的特定词元",{"2":{"567":1}}],["我们还将讲解神经网络是怎么涉及这些问题的神经网络产生的原因是人们想尝试设计出模仿大脑的算法",{"2":{"1098":1}}],["我们还将在不同的机器学习问题中大量地使用它",{"2":{"1069":1}}],["我们还将输出序列的最大词元数指定为t",{"2":{"512":1}}],["我们还将讨论数值稳定性和参数初始化相关的问题",{"2":{"204":1}}],["我们还是有必要将其与监督学习做一下比较",{"2":{"1150":1}}],["我们还是用这个例子",{"2":{"1090":1}}],["我们还是可以轻松地将可学习的参数集成到注意力汇聚中",{"2":{"389":1}}],["我们还是应该认出它",{"2":{"152":1}}],["我们还没有讨论多层循环神经网络的意义",{"2":{"325":1}}],["我们还需实现两个实用函数",{"2":{"206":1}}],["我们还需要将其除以标准差",{"2":{"1159":1}}],["我们还需要两个东西",{"2":{"610":1}}],["我们还需要两个辅助函数",{"2":{"57":1}}],["我们还需要梯度裁剪吗",{"2":{"337":1}}],["我们还需要计算整个模型的输出层",{"2":{"327":1}}],["我们还需要创建一个单独的输出层",{"2":{"325":1}}],["我们还需要正确的数据",{"2":{"284":1}}],["我们还需要一种机制来重置单元的内容",{"2":{"552":1}}],["我们还需要一个额外的关键要素",{"2":{"232":1}}],["我们还需要一点小改动",{"2":{"137":1}}],["我们还需要注意预测系统如何导致反馈循环",{"2":{"201":1}}],["我们还需要注意过拟合",{"2":{"99":1}}],["我们还可以进行求对数运算",{"2":{"1090":1}}],["我们还可以使",{"2":{"1084":1}}],["我们还可以使用",{"2":{"1110":1}}],["我们还可以使用焦点损失",{"2":{"966":1}}],["我们还可以使用另一个工具来改善性能",{"2":{"841":1}}],["我们还可以使用从一个数据集学习的子词来切分另一个数据集的单词",{"2":{"757":1}}],["我们还可以使用替换方法normal",{"2":{"592":1}}],["我们还可以使用此函数屏蔽最后几个轴上的所有项",{"2":{"575":1}}],["我们还可以通过索引来写入variable的元素",{"2":{"1020":1}}],["我们还可以通过指定索引来将元素写入矩阵",{"2":{"1020":1}}],["我们还可以执行线性代数运算",{"2":{"1018":1}}],["我们还可以对彩色图像的三个rgb通道执行标准化",{"2":{"891":1}}],["我们还可以创建一个randomcolorjitter实例",{"2":{"880":1}}],["我们还可以调整亮度",{"2":{"877":1}}],["我们还可以将词向量应用到词类比任务中",{"2":{"751":1}}],["我们还可以将所有参数初始化为给定的常数",{"2":{"435":1}}],["我们还可以访问每个参数的梯度",{"2":{"431":1}}],["我们还可以得到一个反向的条件概率分布",{"2":{"349":1}}],["我们还可以单个",{"2":{"196":1}}],["我们还可以",{"2":{"146":1,"321":1,"414":1,"435":1,"995":1,"1017":1}}],["我们还只有一个输出通道",{"2":{"121":1}}],["我们还面临另一个问题",{"2":{"26":1}}],["我们选用逻辑回归模型或者不带核函数的支持向量机",{"2":{"1148":1}}],["我们选用目标函数f",{"2":{"54":1}}],["我们选取一部分",{"2":{"1174":1}}],["我们选取了左上角3×3的兴趣区域",{"2":{"938":1}}],["我们选取步长η1−β",{"2":{"89":1}}],["我们选择不需要任何内核参数",{"2":{"1148":1}}],["我们选择使得f1值最高的阀值",{"2":{"1140":1}}],["我们选择一个ε",{"2":{"1180":1}}],["我们选择一个预训练的卷积神经网络来抽取图像的特征",{"2":{"917":1}}],["我们选择一系列的想要测试的",{"2":{"1133":1}}],["我们选择的参数决定了我们得到的直线相对于我们的训练集的准确程度",{"2":{"1064":1}}],["我们选择的是",{"2":{"826":1}}],["我们选择第四卷积块的最后一个卷积层作为内容层",{"2":{"920":1}}],["我们选择第一个样本中第一个类的概率和第二个样本中第三个类的概率",{"2":{"633":1}}],["我们选择vgg较靠近输出的层",{"2":{"920":1}}],["我们选择预训练的resnet",{"2":{"905":1}}],["我们选择偏移我们的中心0",{"2":{"848":3}}],["我们选择注意力和多层感知机来演示如何分析文本对",{"2":{"663":1}}],["我们选择具有最高条件概率的k个词元",{"2":{"515":1}}],["我们选择",{"2":{"513":1}}],["我们选择标签是关于输入的线性函数",{"2":{"271":1}}],["我们选择哪个函数以及如何初始化参数可以决定优化算法收敛的速度有多快",{"2":{"240":1}}],["我们选择2的若干次幂作为层的宽度",{"2":{"217":1}}],["我们选择了一组未调优的超参数",{"2":{"212":1}}],["我们选择了一个稍微现代化的lenet版本",{"2":{"67":1}}],["我们选择了很小的学习率",{"2":{"80":1}}],["我们选择固定步长η",{"2":{"54":1}}],["我们选择ϵ=10−6",{"2":{"33":1}}],["我们就希望θ的范数大",{"2":{"1145":1}}],["我们就希望有对于",{"2":{"1141":1}}],["我们就开始构建支持向量机",{"2":{"1143":1}}],["我们就会得到每一个训练样本都影响这一项",{"2":{"1143":1}}],["我们就会取得进展",{"2":{"115":1}}],["我们就得到了一个能实现",{"2":{"1102":1}}],["我们就教会了阅读本书所需的",{"2":{"1002":1}}],["我们就将使用它们来检测不同尺度下各种大小的目标",{"2":{"913":1}}],["我们就有了这样一个分类问题",{"2":{"1112":1}}],["我们就有能力编译和优化多层感知机中的计算",{"2":{"819":3}}],["我们就有一个二次递减误差",{"2":{"60":1}}],["我们就需要来回传输数据以实现同步处理",{"2":{"812":1}}],["我们就需要修改循环神经网络的设计",{"2":{"520":1}}],["我们就进入了训练阶段",{"2":{"429":1}}],["我们就说序列满足马尔可夫条件",{"2":{"348":1}}],["我们就越有可能",{"2":{"260":1}}],["我们就把它作为智能猫门计算视觉系统的一部分",{"2":{"195":1}}],["我们就可以使用梯度下降",{"2":{"1111":1}}],["我们就可以使用优化算法来尝试最小化损失",{"2":{"98":1}}],["我们就可以将梯度下降算法写作如下形式",{"2":{"1110":1}}],["我们就可以更好地理解疾病",{"2":{"1058":1}}],["我们就可以按如下方式",{"2":{"959":1}}],["我们就可以向减小损失的方向更新每个参数",{"2":{"601":1}}],["我们就可以有效地学习模型",{"2":{"451":1}}],["我们就可以在任意环境和网络架构中调用该自定义层",{"2":{"415":1}}],["我们就可以在使用算法时考虑到这一点",{"2":{"200":1}}],["我们就可以用更新后的隐状态计算输出",{"2":{"325":1}}],["我们就可以收集一个包含大量音频样本的数据集",{"2":{"282":1}}],["我们就可以通过求解一个简单的线性系统来估计测试集的标签分布",{"2":{"192":1}}],["我们就可以选择学习率η=r",{"2":{"115":1}}],["我们就能知道其效果如何",{"2":{"1129":1}}],["我们就能很好的拟合了",{"2":{"1115":1}}],["我们就能够权衡对应的项",{"2":{"1143":1}}],["我们就能够使通过梯度下降",{"2":{"1111":1}}],["我们就能够有效地将所有记忆信息传递给预测部分",{"2":{"556":1}}],["我们就能得到样本有效的模型",{"2":{"155":1}}],["我们就能得到大小为128的小批量",{"2":{"77":1}}],["我们就能继续展开",{"2":{"54":1}}],["我们就不会",{"2":{"44":1}}],["我们由此得出梯度下降法和随机梯度下降法是如何相应推导出来的",{"2":{"51":1}}],["我们多次将凸性的定义应用于一次求和中的一项",{"2":{"42":1}}],["我们得到逻辑回归模型的假设",{"2":{"1107":1}}],["我们得到了支持向量机模型",{"2":{"1148":1}}],["我们得到了这里的最小化问题",{"2":{"1143":1}}],["我们得到了一个5行3列的矩阵",{"2":{"999":1}}],["我们得到了q~ij=qij",{"2":{"26":1}}],["我们得到的数据的一个之间你的原始数据",{"2":{"1161":1}}],["我们得到的代价函数将是一个非凸函数",{"2":{"1109":1}}],["我们得到的结果大约是2×160mb÷",{"2":{"842":1}}],["我们得到的步幅形状为",{"2":{"147":1}}],["我们得到以下的状态初始化",{"2":{"559":1}}],["我们得到以下定义",{"2":{"156":1}}],["我们得到与上面相同形状",{"2":{"340":1}}],["我们得到一个形状为",{"2":{"340":1}}],["我们得到长度为h的隐藏激活向量",{"2":{"162":1}}],["我们得到条件f",{"2":{"60":1}}],["我们得到",{"2":{"40":1,"60":1,"164":1,"647":2,"1032":1,"1035":1,"1143":1}}],["我们通常不使用方差项",{"2":{"1189":1}}],["我们通常不太关心恢复真正的参数",{"2":{"605":1}}],["我们通常可以通过将一些相关的特征进行组合",{"2":{"1183":1}}],["我们通常需要通过几个步骤才能进行最终的预测",{"2":{"1174":1}}],["我们通常需要多次运行k",{"2":{"1153":1}}],["我们通常初始参数为正负ε之间的随机值",{"2":{"1125":1}}],["我们通常已经在一个默认路径中",{"2":{"1089":1}}],["我们通常有更多的特征",{"2":{"1060":1}}],["我们通常有ph=pw和sh=sw",{"2":{"142":1}}],["我们通常用粗体",{"2":{"992":1}}],["我们通常选择对于模型参数可微的损失函数",{"2":{"981":1}}],["我们通常选择预测概率最高的类",{"2":{"634":1}}],["我们通常对训练样本只进行图像增广",{"2":{"882":1,"884":1}}],["我们通常对卷积层进行排列",{"2":{"138":1}}],["我们通常使用pandas软件包",{"2":{"1010":1}}],["我们通常使用边界框",{"2":{"858":1}}],["我们通常使用的是高维数据集",{"2":{"610":1}}],["我们通常从小批量的角度来考虑提高效率",{"2":{"370":1}}],["我们通常将其称为上下文",{"2":{"445":1}}],["我们通常将其称为环境",{"2":{"445":1}}],["我们通常将文本拆分为词元",{"2":{"365":1}}],["我们通常将每个词元表示为更具表现力的特征向量",{"2":{"330":1}}],["我们通常定义一个目标函数",{"2":{"286":1}}],["我们通常希望模型的参数在gpu上",{"2":{"445":3}}],["我们通常希望避免非常大的梯度值或损失值",{"2":{"262":1}}],["我们通常希望这些特征保持某种程度上的平移不变性",{"2":{"145":1}}],["我们通常更关心验证误差",{"2":{"258":1}}],["我们通常在评估几个候选模型后选择最终的模型",{"2":{"255":1}}],["我们通常会通过将训练集和交叉验证集的代价函数误差与多项式的次数绘制在同一张图表上来帮助分析",{"2":{"1132":1}}],["我们通常会随机初始化参数的值",{"2":{"1017":1}}],["我们通常会试图计算一批训练样本中每个组成部分的损失函数的导数",{"2":{"975":1}}],["我们通常会对小批量样本的数据执行矢量计算",{"2":{"644":1}}],["我们通常会在每次需要计算更新的时候随机抽取一小批样本",{"2":{"613":1}}],["我们通常会使用验证集",{"2":{"255":1}}],["我们通常会考虑到各种方式犯错的潜在成本敏感性",{"2":{"201":1}}],["我们通常会先定义损失函数",{"2":{"98":1}}],["我们通常无法获得总体数据",{"2":{"190":1}}],["我们通常计算汇聚窗口中所有元素的最大值或平均值",{"2":{"146":1}}],["我们通常情况甚至无法计算目标函数的二阶导数",{"2":{"26":1}}],["我们通过学习得到的假设可能能够非常好地适应训练集",{"2":{"1114":1}}],["我们通过学习率的调整来分离每个坐标的缩放",{"2":{"32":1}}],["我们通过符号f",{"2":{"1018":1}}],["我们通过将标量函数升级为按元素向量运算来生成向量值",{"2":{"1018":1}}],["我们通过将总和除以元素总数来计算平均值",{"2":{"995":1}}],["我们通过将重点放在sequential和block上来详细描述其优点",{"2":{"818":1}}],["我们通过调用的multibox",{"2":{"959":1}}],["我们通过自定义的vocsegdataset类来分别创建训练集和测试集的实例",{"2":{"948":1}}],["我们通过继承高级api提供的dataset类",{"2":{"947":1}}],["我们通过再缩放图像使其符合模型的输入形状",{"2":{"946":1}}],["我们通过2×2的兴趣区域汇聚层得到一个2×2的输出",{"2":{"938":1}}],["我们通过设置汇聚窗口",{"2":{"938":1}}],["我们通过前向传播",{"2":{"917":1}}],["我们通过在测量之前预热设备",{"2":{"796":1}}],["我们通过最大化似然函数",{"2":{"784":1}}],["我们通过嵌入层和批量矩阵乘法实现了跳元模型",{"2":{"761":1}}],["我们通过截断和填充将每个评论的长度设置为500",{"2":{"693":1}}],["我们通过该函数使用snli的训练集",{"2":{"688":1}}],["我们通过微调bert来重新审视这项任务",{"2":{"685":1}}],["我们通过对噪声分布的假设来解读平方损失目标函数",{"2":{"616":1}}],["我们通过对每个坐标缩放来实现高效计算的预处理器",{"2":{"32":1}}],["我们通过从均值为0",{"2":{"601":1}}],["我们通过net",{"2":{"592":2}}],["我们通过指定resize参数来测试load",{"2":{"584":1}}],["我们通过添加更多的层来解决这个问题",{"2":{"526":1}}],["我们通过实例化snlibertdataset类来",{"2":{"687":1}}],["我们通过实例化keras",{"2":{"422":1}}],["我们通过实例化nn",{"2":{"422":3}}],["我们通过尝试访问以下参数进行确认",{"2":{"418":1}}],["我们通过使用链式法可以很容易地得到梯度",{"2":{"312":1}}],["我们通过一个简单的例子来演示权重衰减",{"2":{"271":1}}],["我们通过正则化常数λ来描述这种权衡",{"2":{"270":1}}],["我们通过矩阵x∈rn×d",{"2":{"232":1}}],["我们通过这种方式获得的模型可以应用于测试集",{"2":{"213":1}}],["我们通过向x1方向伸展它来进一步扭曲这个函数",{"2":{"87":1}}],["我们通过",{"2":{"50":1}}],["我们仍然是使用滑动窗口技术来进行字符识别",{"2":{"1172":1}}],["我们仍然使用线性代数符号",{"2":{"641":1}}],["我们仍然使用软类别的模型",{"2":{"639":1}}],["我们仍然以均值0和标准差0",{"2":{"623":1}}],["我们仍然以同一函数为例",{"2":{"27":1}}],["我们仍然需要定义辅助函数",{"2":{"722":1}}],["我们仍然需要偏置项",{"2":{"610":1}}],["我们仍然需要结合更新门zt的效果",{"2":{"542":1}}],["我们仍然要限制增加函数的复杂性呢",{"2":{"505":1}}],["我们仍然可以通过调用",{"2":{"1019":1}}],["我们仍然可以通过截断",{"2":{"568":1}}],["我们仍然可以计算得到的变量的梯度",{"2":{"977":1}}],["我们仍然可以在同一个小批量的两个不同尺度上连接这两个预测输出",{"2":{"956":1}}],["我们仍然可以用下式来选择最有可能的类别",{"2":{"643":1}}],["我们仍然可以有效地训练模型",{"2":{"613":1}}],["我们仍然可以认为该模型保留了上面所说的基本架构",{"2":{"422":1}}],["我们仍然可能会看到一个非常小的非零数",{"2":{"413":1}}],["我们仍然从读取时光机器数据集开始",{"2":{"324":1}}],["我们仍然会在模型中使用它们",{"2":{"318":1}}],["我们仍然受到通过η∇fi",{"2":{"113":1}}],["我们仍然离最优解很远",{"2":{"55":1,"114":1}}],["我们仍缺乏足够的观测以确定其最佳值",{"2":{"25":1}}],["我们将所有用户的代价函数求和",{"2":{"1188":1}}],["我们将所有的分类机都运行一遍",{"2":{"1112":1}}],["我们将领略一小部分特征学习的思想",{"2":{"1187":1}}],["我们将构建特征的协方差矩阵",{"2":{"1184":1}}],["我们将构建一个高度和宽度为224的单通道数据样本",{"2":{"508":1}}],["我们将识别得出的区域进行一些扩展",{"2":{"1172":1}}],["我们将识别120类不同品种的狗",{"2":{"899":1}}],["我们将三维向量投射到一个二维的平面上",{"2":{"1156":1}}],["我们将陆续介绍其他算法",{"2":{"1150":1}}],["我们将先介绍聚类算法",{"2":{"1150":1}}],["我们将要做的事是谈论一些技术在实际使用pca很好",{"2":{"1161":1}}],["我们将要让计算机学习无标签数据",{"2":{"1150":1}}],["我们将要用来描述这个回归问题的标记如下",{"2":{"1063":1}}],["我们将向量v投影到向量u上",{"2":{"1145":1}}],["我们将向量ai和bj在",{"2":{"680":1}}],["我们将算法预测的结果分成四种情况",{"2":{"1139":1}}],["我们将会得到没有了约束",{"2":{"1145":1}}],["我们将会使用这些概念",{"2":{"1145":2}}],["我们将会很希望找到一个使第一项为0的最优解",{"2":{"1144":1}}],["我们将会讲到误差分析",{"2":{"1138":1}}],["我们将会找出一种稍微简单一点的方法来写代价函数",{"2":{"1110":1}}],["我们将数据分成训练集和测试集",{"2":{"1130":1}}],["我们将解释原因",{"2":{"1129":1}}],["我们将解析文本的常见预处理步骤",{"2":{"360":1}}],["我们将对所有的特征进行惩罚",{"2":{"1115":1}}],["我们将对其中的项加权βi",{"2":{"191":1}}],["我们将多个类中的一个类标记为正向类",{"2":{"1112":1}}],["我们将应用梯度下降法得到我们的逻辑回归算法",{"2":{"1109":1}}],["我们将它作为分类算法使用",{"2":{"1106":1}}],["我们将它们增加到224×224",{"2":{"462":1}}],["我们将因变量",{"2":{"1106":1}}],["我们将原始数据输入给它们",{"2":{"1099":1}}],["我们将开始介绍一个具体的聚类算法",{"2":{"1150":1}}],["我们将开始学习逻辑回归算法的细节",{"2":{"1106":1}}],["我们将开始深入到神经网络的技术细节",{"2":{"1098":1}}],["我们将开始给更正式的定义",{"2":{"1058":1}}],["我们将谈论一种称为正则化",{"2":{"1114":1}}],["我们将谈论如何用这些推进我们的ai",{"2":{"1058":1}}],["我们将谈到如何使用逻辑回归",{"2":{"1112":1}}],["我们将谈到octave的变量",{"2":{"1088":1}}],["我们将不得不仍然使用梯度下降法",{"2":{"1085":1}}],["我们将不得不给这个观测值指定一个非常大的梯度",{"2":{"538":1}}],["我们将用到此算法",{"2":{"1069":1}}],["我们将花费最多的精力来讨论这两种学习算法",{"2":{"1059":1}}],["我们将花大量的时间做练习",{"2":{"1058":1}}],["我们将教计算机如何去完成任务",{"2":{"1059":1}}],["我们将考虑离散空间中的概率",{"2":{"1028":1}}],["我们将考虑插值法",{"2":{"1012":1}}],["我们将集合s=",{"2":{"1027":1}}],["我们将观察到",{"2":{"1026":1}}],["我们将取消引用y指向的张量",{"2":{"1021":1}}],["我们将沿着数组中长度为1的轴进行广播",{"2":{"1019":1}}],["我们将data分成inputs和outputs",{"2":{"1012":1}}],["我们将绝对值函数和按元素求和组合起来",{"2":{"1000":1}}],["我们将上面的常规卷积2×2的输出y作为转置卷积的输入",{"2":{"970":1}}],["我们将上述步骤封装到load",{"2":{"695":1}}],["我们将上述想法总结一下",{"2":{"152":1}}],["我们将卷积核k重写为包含大量0的稀疏权重矩阵w",{"2":{"970":1}}],["我们将卷积图层的二维数组输出称为特征图",{"2":{"912":1}}],["我们将锚框类别和偏移量的损失相加",{"2":{"962":1}}],["我们将根据模型在验证集上的表现选择模型并调整超参数",{"2":{"906":1}}],["我们将根据模型在验证集上的表现来选择模型并调整超参数",{"2":{"894":1}}],["我们将根据坐标信息",{"2":{"858":1}}],["我们将10",{"2":{"890":1}}],["我们将本章和前几章的知识应用于两个流行的计算机视觉基准数据集",{"2":{"886":1}}],["我们将结合多种图像增广方法",{"2":{"881":1}}],["我们将成员变量output中参数的学习率设置为10η",{"2":{"873":1}}],["我们将图像裁剪为固定尺寸",{"2":{"946":1}}],["我们将图像的高度和宽度都缩放到256像素",{"2":{"872":1}}],["我们将图片转换为96×96分辨率",{"2":{"489":1}}],["我们将预测类别映射回它们在数据集中的标注颜色",{"2":{"866":1}}],["我们将预测结果y^",{"2":{"610":1}}],["我们将p称为预测边界框b的置信度",{"2":{"854":1}}],["我们将真实边界框b3分配给锚框a2",{"2":{"851":1}}],["我们将真实边界框bj2分配给锚框ai2",{"2":{"851":1}}],["我们将遇到更复杂的模型和更复杂的并行化方法",{"2":{"837":1}}],["我们将打印参数作为了函数调用的一部分",{"2":{"821":1}}],["我们将最大上下文窗口大小设置为5",{"2":{"774":1}}],["我们将词元映射到它们在语料库中的索引",{"2":{"773":1}}],["我们将词元序列输入注意力池化中",{"2":{"395":1}}],["我们将符号词表初始化为所有英文小写字符",{"2":{"757":1}}],["我们将说明字节对编码是如何工作的",{"2":{"757":1}}],["我们将说明针对下游应用的bert微调",{"2":{"733":1}}],["我们将获得长度为3的所有子词",{"2":{"756":1}}],["我们将找到一个词",{"2":{"751":1}}],["我们将通过符号f",{"2":{"1018":1}}],["我们将通过代码来进一步了解风格迁移的技术细节",{"2":{"917":1}}],["我们将通过一个具体的例子来说明它是如何工作的",{"2":{"913":1}}],["我们将通过模拟命令式编程来进一步了解符号式编程的概念",{"2":{"817":1}}],["我们将通过下面的词相似性和类比任务中来展示词向量的语义",{"2":{"749":1}}],["我们将通过演示来比较访问第一个全连接层的参数和访问所有层",{"2":{"432":1}}],["我们将mlm",{"2":{"736":1}}],["我们将tokens定义为长度为8的2个输入序列",{"2":{"734":1}}],["我们将始终如一地将术语",{"2":{"734":1}}],["我们将为下游自然语言处理应用微调预训练的bert模型",{"2":{"727":1}}],["我们将为训练集和测试集各生成100个样本",{"2":{"262":1}}],["我们将以此为基础来讨论如何避免过拟合和欠拟合的问题",{"2":{"1130":1}}],["我们将以",{"2":{"771":1}}],["我们将以跳元模型为例来描述这两种近似训练方法",{"2":{"707":1}}],["我们将以机器翻译为例介绍基于循环神经网络的",{"2":{"550":1}}],["我们将展示如何在官方文档中查找所需信息",{"2":{"987":1}}],["我们将展示如何微调大得多的",{"2":{"686":1}}],["我们将展示如何使用这些函数来设计bahdanau注意力",{"2":{"379":1}}],["我们将两个矩阵广播为一个更大的3×2矩阵",{"2":{"1019":1}}],["我们将两个求和结果的连结提供给函数h",{"2":{"676":1}}],["我们将两个参数传递到nn",{"2":{"591":2}}],["我们将聚合这些信息以推断逻辑关系",{"2":{"676":1}}],["我们将来自一个序列的词元的连结",{"2":{"675":1}}],["我们将注意力权重eij∈r计算为",{"2":{"674":1}}],["我们将批量大小设置为128时",{"2":{"669":1}}],["我们将批量规范化层置于全连接层中的仿射变换和激活函数之间",{"2":{"469":1}}],["我们将首先介绍目标的位置",{"2":{"857":1}}],["我们将首先研究一个流行的自然语言推断基准数据集",{"2":{"665":1}}],["我们将首先使用三阶多项式函数",{"2":{"264":1}}],["我们将针对自然语言推断对bert进行微调",{"2":{"663":1}}],["我们将探索基于循环神经网络和卷积神经网络的流行架构进行情感分析",{"2":{"663":1}}],["我们将简要介绍新的应用",{"2":{"656":1}}],["我们将自然语言处理应用的子集概括为序列级和词元级",{"2":{"656":1}}],["我们将设置一个阈值",{"2":{"643":1}}],["我们将设计能够利用这些注意力提示的模型",{"2":{"379":1}}],["我们将需要12个标量来表示权重",{"2":{"641":1}}],["我们将需要使用这些参数来做出未来的预测",{"2":{"429":1}}],["我们将比较它们的实际标签",{"2":{"636":1}}],["我们将利用animator类来可视化训练进度",{"2":{"635":1}}],["我们将这类任务称为目标检测",{"2":{"857":1}}],["我们将这种变换",{"2":{"618":1}}],["我们将这个大间距分类器中的正则化因子常数c设置的非常大",{"2":{"1144":1}}],["我们将这个大小为3的轴称为通道",{"2":{"119":1}}],["我们将这个常数c设置成一个非常大的值",{"2":{"1144":1}}],["我们将这个看到某个数值的可能性量化为密度",{"2":{"1028":1}}],["我们将这个序列转换为模型的特征",{"2":{"350":1}}],["我们将这个四维输入转换成全连接层所期望的二维输入",{"2":{"136":1}}],["我们将线性回归模型描述为一个神经网络",{"2":{"618":1}}],["我们将更深入地学习代价函数的作用",{"2":{"1066":1}}],["我们将更深入地研究初始化机制",{"2":{"417":1}}],["我们将更复杂的句子拆分技术的讨论留在本节末尾的练习中",{"2":{"718":1}}],["我们将更多的数学运算放到库中",{"2":{"615":1}}],["我们将依赖对+的调用",{"2":{"615":1}}],["我们将梯度乘以一个预先确定的正数η",{"2":{"613":1}}],["我们将梯度gt",{"2":{"88":1}}],["我们将梯度gt替换为一个小批量而不是单个观测值",{"2":{"78":1}}],["我们将偏置b合并到参数w中",{"2":{"612":1}}],["我们将执行以下循环",{"2":{"605":1}}],["我们将标准差设为0",{"2":{"599":1}}],["我们将只使用张量和自动求导",{"2":{"598":1}}],["我们将完整遍历一次数据集",{"2":{"595":1}}],["我们将features和labels作为api的参数传递",{"2":{"590":1}}],["我们将从物体检测的主要组件和技术开始",{"2":{"886":1}}],["我们将从零开始实现整个方法",{"2":{"598":1}}],["我们将从经典算法",{"2":{"587":1}}],["我们将从初始位置",{"2":{"57":1}}],["我们将高度h像素",{"2":{"585":1}}],["我们将bleu定义为",{"2":{"578":1}}],["我们将特定的",{"2":{"568":1}}],["我们将截断文本序列时",{"2":{"568":1}}],["我们将讲述更高级的替代模型",{"2":{"561":1}}],["我们将其称为输入门",{"2":{"552":1}}],["我们将其称为输出门",{"2":{"552":1}}],["我们将其从数据集中删除",{"2":{"208":1}}],["我们将引入两个广泛使用的网络",{"2":{"550":1}}],["我们将前向递归",{"2":{"519":1}}],["我们将前缀指定为time",{"2":{"333":1}}],["我们将尝试找到一个函数ff∗",{"2":{"500":1}}],["我们将尝试学习最小化",{"2":{"290":1}}],["我们将输入的高和宽从224降到96",{"2":{"488":1}}],["我们将输入x通过暂退法操作",{"2":{"172":1}}],["我们将每个锚框视为一个训练样本",{"2":{"850":1}}],["我们将每个单词视为一个词元",{"2":{"772":1}}],["我们将每个元素变成一个非负数",{"2":{"631":1}}],["我们将每个卷积块的输入和输出在通道维上连结",{"2":{"480":1}}],["我们将每次滑动元素的数量称为步幅",{"2":{"142":1}}],["我们将此功能集成到一个自定义层中",{"2":{"472":1}}],["我们将无法学到任何东西",{"2":{"467":1}}],["我们将无法获得一个好的解决方案",{"2":{"113":1}}],["我们将看到几个这样的例子",{"2":{"451":1}}],["我们将看到更多关于如何在gpu上运行模型的例子",{"2":{"451":1}}],["我们将看到如何通过在图像边界周围填充零来保证有足够的空间移动卷积核",{"2":{"126":1}}],["我们将深入研究这一算法",{"2":{"1180":1}}],["我们将深入研究一些流行的",{"2":{"134":1}}],["我们将深入探究特定的学习算法",{"2":{"1061":1}}],["我们将深入探索深度学习计算的关键组件",{"2":{"421":1}}],["我们将深入了解bert的训练前准备",{"2":{"733":1}}],["我们将基于刚刚介绍的概念描述其他模型",{"2":{"606":1}}],["我们将基于一个单向隐藏层来扩展循环神经网络架构",{"2":{"550":1}}],["我们将基于这个非参数的注意力汇聚模型来绘制预测结果",{"2":{"388":1}}],["我们将基于循环神经网络实现字符级语言模型",{"2":{"342":1}}],["我们将x更新为x−ηg",{"2":{"334":1}}],["我们将x索引为",{"2":{"158":1}}],["我们将描述如何训练用于目标检测的单发多框检测模型",{"2":{"960":1}}],["我们将描述如何实现随机采样",{"2":{"319":1}}],["我们将描述具有多个隐藏层的深层架构",{"2":{"550":1}}],["我们将描述利用sigmoid单元来控制时序信息流的架构",{"2":{"236":1}}],["我们将学习一个非常强大的非线性分类器",{"2":{"1117":1}}],["我们将学习一种叫做逻辑回归",{"2":{"1106":1}}],["我们将学习如何应用循环神经网络",{"2":{"535":1}}],["我们将学习如何改进循环神经网络模型",{"2":{"335":1}}],["我们将学习如何去设计更好的模型",{"2":{"317":1}}],["我们将学习更复杂的序列模型",{"2":{"312":1}}],["我们将学习率略微降至0",{"2":{"91":1}}],["我们将学习率提高到2",{"2":{"27":1}}],["我们将时间步t的隐状态表示为ht",{"2":{"307":1}}],["我们将时间步t存储在hyperparams字典中",{"2":{"34":1}}],["我们将阐明会发生什么以及如何在实践中解决它们",{"2":{"306":1}}],["我们将讨论如何实施类别和边界框预测",{"2":{"953":1}}],["我们将讨论如何利用这种计算性能进行研究",{"2":{"445":1}}],["我们将讨论能够利用图像空间结构的特征",{"2":{"630":1}}],["我们将讨论语言模型的基本概念",{"2":{"305":1}}],["我们将讨论因违背独立同分布假设而引起的问题",{"2":{"253":1}}],["我们将默认使用简单的启发式方法",{"2":{"278":1}}],["我们将定义一个函数来随机初始化模型参数",{"2":{"273":1}}],["我们将重点讨论如何预训练文本的这种表示",{"2":{"754":1}}],["我们将重点介绍几个倾向于影响模型泛化的因素",{"2":{"254":1}}],["我们将重点放在带权重衰减",{"2":{"161":1}}],["我们将继续使用之前定义的变量y",{"2":{"634":1}}],["我们将继续使用fashion",{"2":{"216":1}}],["我们将继续在其末尾添加特定的",{"2":{"568":1}}],["我们将继续考虑",{"2":{"550":1}}],["我们将继续从k|y|个可能的选择中",{"2":{"515":1}}],["我们将继续讨论过拟合问题和处理这些问题的方法",{"2":{"266":1}}],["我们将继续把",{"2":{"130":1}}],["我们将创建两个新的指示器特征",{"2":{"209":1}}],["我们将",{"2":{"208":1,"217":1,"218":1,"221":1,"262":1,"473":1,"599":1,"1012":1}}],["我们将希望划分训练集以创建验证集",{"2":{"208":1}}],["我们将下载不同的数据集",{"2":{"206":1}}],["我们将放在后面的章节中讨论",{"2":{"204":1}}],["我们将把这些张量转换为更一致的格式",{"2":{"956":1}}],["我们将把哲学放在一边",{"2":{"254":1}}],["我们将把所介绍的内容应用到一个真实的案例",{"2":{"204":1}}],["我们将把它与梯度下降进行比较",{"2":{"113":1}}],["我们将第一次介绍真正的深度网络",{"2":{"204":1}}],["我们将着重对实际工具的探究",{"2":{"169":1}}],["我们将j称为目标函数",{"2":{"162":1}}],["我们将一个序列中的词元与与该词元软对齐的另一个序列进行比较",{"2":{"675":1}}],["我们将一个大小为28×28的单通道",{"2":{"136":1}}],["我们将一步步研究单隐藏层神经网络的机制",{"2":{"162":1}}],["我们将参数从权重矩阵",{"2":{"153":1}}],["我们将3×3输入填充到5×5",{"2":{"141":1}}],["我们将介绍第二种主要的机器学习问题",{"2":{"1061":1}}],["我们将介绍",{"2":{"953":1}}],["我们将介绍两种可以改进模型泛化的方法",{"2":{"886":1}}],["我们将介绍用于提高计算效率的组件",{"2":{"840":1}}],["我们将介绍这两种模式及其训练方法",{"2":{"782":1}}],["我们将介绍分类问题",{"2":{"608":1}}],["我们将介绍如何使用双向循环神经网络编码文本序列",{"2":{"522":1}}],["我们将介绍一种算法",{"2":{"1066":1}}],["我们将介绍一些常用于设计深层神经网络的启发式概念",{"2":{"506":1}}],["我们将介绍一个完整的",{"2":{"134":1}}],["我们将介绍以下内容",{"2":{"429":1}}],["我们将介绍文本预处理的实用技术",{"2":{"305":1}}],["我们将介绍构成所有卷积网络主干的基本元素",{"2":{"134":1}}],["我们将按照速度o",{"2":{"115":1}}],["我们将过早停止优化",{"2":{"114":1}}],["我们将初始学习率设置为0",{"2":{"108":1}}],["我们将使用一个不同的参数替换这里使用的λ来权衡这两项",{"2":{"1143":1}}],["我们将使用梯度下降算法来求出代价函数j",{"2":{"1067":1}}],["我们将使用matplotlib",{"2":{"981":1}}],["我们将使用神经网络修改内容图像",{"2":{"916":1}}],["我们将使用训练好的自定义输出网络进行分类",{"2":{"908":1}}],["我们将使用下面这个尺寸为400×500的图像作为示例",{"2":{"878":1}}],["我们将使用微调模型来识别图像中是否包含热狗",{"2":{"871":1}}],["我们将使用二元交叉熵损失",{"2":{"765":1}}],["我们将使用这些表示来计算预训练bert的损失函数",{"2":{"735":1}}],["我们将使用预训练的glove模型来表示每个词元",{"2":{"712":1}}],["我们将使用斯坦福大学的大型电影评论数据集",{"2":{"691":1}}],["我们将使用精度",{"2":{"653":1}}],["我们将使用最大似然估计",{"2":{"645":1}}],["我们将使用正态分布初始化我们的权重w",{"2":{"630":1}}],["我们将使用python的for循环遍历向量",{"2":{"615":1}}],["我们将使用低维数据",{"2":{"599":1}}],["我们将使用gluon中的均方误差",{"2":{"593":1}}],["我们将使用类似但更复杂的fashion",{"2":{"581":1}}],["我们将使用两个循环神经网络的编码器和解码器",{"2":{"572":1}}],["我们将使用基于深度学习的模型",{"2":{"318":1}}],["我们将使用缓存的文件",{"2":{"206":1}}],["我们将使用内置的调度器",{"2":{"70":1}}],["我们将使用与之前相同的学习率来实现adagrad算法",{"2":{"27":1}}],["我们将梳理不同的调度策略对准确性的影响",{"2":{"66":1}}],["我们将h=def∇2f",{"2":{"59":1}}],["我们将权重向量投影到一个l1的球上",{"2":{"50":1}}],["我们将在随后的课程中讲误差分析",{"2":{"1137":1}}],["我们将在一个小型数据集上微调resnet模型",{"2":{"871":1}}],["我们将在实现之后",{"2":{"854":1}}],["我们将在训练代码实现中初始化网络",{"2":{"827":2}}],["我们将在训练回路中初始化网络",{"2":{"827":1}}],["我们将在训练函数里对各个小批量样本的损失求平均",{"2":{"80":1}}],["我们将在ptb数据集上使用负采样预训练word2vec",{"2":{"760":1}}],["我们将在本节中在wikitext",{"2":{"725":1}}],["我们将在本节中加载和微调经过预训练bert的小版本",{"2":{"686":1}}],["我们将在本章及后续章节中讨论如何改进这一点",{"2":{"351":1}}],["我们将在本章的其它部分讨论这些问题",{"2":{"158":1}}],["我们将在本章中其它小节使用它",{"2":{"81":1}}],["我们将在snli数据集上对定义好的可分解注意力模型进行训练和评估",{"2":{"678":1}}],["我们将在下面生成4个观测值",{"2":{"827":1}}],["我们将在下面对性能进行基准测试",{"2":{"819":4}}],["我们将在下面一步一步地对它们进行说明",{"2":{"673":1}}],["我们将在下一节介绍凸性时讨论这种情况的一些例外",{"2":{"102":1}}],["我们将在通道维度上连结张量x和x",{"2":{"148":1}}],["我们将在高度的两侧填充ph",{"2":{"141":1}}],["我们将在后续章节中使用此数据集来评估各种分类算法",{"2":{"585":1}}],["我们将在后续章节中讨论它们",{"2":{"27":1}}],["我们将在后面的章节中进行更细致的讨论",{"2":{"233":1}}],["我们将在后面章节更详细地描述它",{"2":{"210":1}}],["我们将在后面一节看到",{"2":{"61":1}}],["我们将在",{"2":{"30":1,"348":1,"538":1,"577":1,"754":1,"847":1,"1018":1}}],["我们将δx0初始化为0",{"2":{"20":1}}],["我们允许每个坐标有单独的学习率",{"2":{"27":1}}],["我们有五部电影",{"2":{"1191":1}}],["我们有关于五部电影的数据集",{"2":{"1191":1}}],["我们有10000台正常引擎的数据",{"2":{"1181":1}}],["我们有可能需要人工地创造一些数据",{"2":{"1173":1}}],["我们有400个训练实例",{"2":{"1169":1}}],["我们有一系列标签",{"2":{"1150":1}}],["我们有一个有标签的训练集",{"2":{"1150":1}}],["我们有一个参数向量我会将它也画成向量",{"2":{"1145":1}}],["我们有一个中等规模的4核心的cpu",{"2":{"810":1}}],["我们有一个宽度为11的6通道输入",{"2":{"701":1}}],["我们有一个要压缩的数据流",{"2":{"651":1}}],["我们有一个链",{"2":{"307":1}}],["我们有一个连续参数化的函数f",{"2":{"197":1}}],["我们有两项",{"2":{"1143":1}}],["我们有两种方式计算误差",{"2":{"1130":1}}],["我们有两个明显的选择",{"2":{"640":1}}],["我们有了所有的误差的表达式后",{"2":{"1121":2}}],["我们有了一个相当高效的算法",{"2":{"59":1}}],["我们有个代价函数j",{"2":{"1111":1}}],["我们有数目庞大的特征量",{"2":{"1111":1}}],["我们有这些不同的参数$",{"2":{"1110":1}}],["我们有越来越大",{"2":{"1058":1}}],["我们有史上最大的数据集比如说",{"2":{"1058":1}}],["我们有u",{"2":{"981":1}}],["我们有时需要将图像放大",{"2":{"863":1}}],["我们有以下选择",{"2":{"832":1}}],["我们有以下的循环",{"2":{"196":1}}],["我们有许多设计参数",{"2":{"812":1}}],["我们有许多有用的工具已经应用于现实",{"2":{"253":1}}],["我们有分别代表前提和假设的两个输入x",{"2":{"669":1}}],["我们有p1=4",{"2":{"578":1}}],["我们有几种方法可以访问",{"2":{"438":1}}],["我们有理由相信可以用一个更复杂的模型降低训练误差",{"2":{"258":1}}],["我们有各种各样的数据类型",{"2":{"209":1}}],["我们有该函数的一个鞍点",{"2":{"102":1}}],["我们有该函数的局部最大值",{"2":{"102":1}}],["我们有该函数的局部最小值",{"2":{"102":1}}],["我们有很多方法来计算a",{"2":{"77":1}}],["我们有∇f",{"2":{"59":1}}],["我们有",{"2":{"26":1,"742":1,"1187":1,"1188":1}}],["我们只要直接使用即可",{"2":{"1148":1}}],["我们只讨论了仅含一个变量的函数的微分",{"2":{"982":1}}],["我们只讨论了具有一个单向隐藏层的循环神经网络",{"2":{"526":1}}],["我们只着重介绍这些模型的设计思路",{"2":{"936":1}}],["我们只对图像执行标准化",{"2":{"891":1}}],["我们只对样本的",{"2":{"639":1}}],["我们只将样本数据集的批量大小设置为32",{"2":{"890":1}}],["我们只读取几张较大的测试图像",{"2":{"866":1}}],["我们只给出bilinear",{"2":{"863":1}}],["我们只关注如何识别其类别",{"2":{"857":1}}],["我们只考虑",{"2":{"848":1}}],["我们只考虑了通过前向传播",{"2":{"161":1}}],["我们只在一个gpu上计算模型的精确度",{"2":{"837":1}}],["我们只在以下几点中选择了一个合理的选择",{"2":{"744":1}}],["我们只在每个迭代周期的开始位置初始化隐状态",{"2":{"335":1}}],["我们只谈论了线性模型",{"2":{"617":1}}],["我们只运用了",{"2":{"588":1}}],["我们只保留记忆元内的所有信息",{"2":{"556":1}}],["我们只指定长度可变的序列作为编码器的输入x",{"2":{"533":1}}],["我们只有两个参数θ1",{"2":{"1145":1}}],["我们只有一个输出变量",{"2":{"1120":1}}],["我们只有过去的数据",{"2":{"522":1}}],["我们只有有限数量的手臂可以拉动",{"2":{"197":1}}],["我们只看到8个结果",{"2":{"511":1}}],["我们只想在变量存在于不同设备中时进行复制",{"2":{"449":1}}],["我们只依靠深度学习框架来完成训练的工作",{"2":{"429":1}}],["我们只展示如何将任意代码集成到神经网络计算的流程中",{"2":{"425":1}}],["我们只接触到一个简单线性函数的概念",{"2":{"278":1}}],["我们只能尝试采用和不采用截词软件这两种不同方案",{"2":{"1138":1}}],["我们只能在训练过程中通过调用extract",{"2":{"920":1}}],["我们只能在官方测试集中评估我们的模型",{"2":{"208":1}}],["我们只能把它们当作通用的",{"2":{"520":1}}],["我们只能得到3个小批量",{"2":{"320":1}}],["我们只能通过将模型应用于一个独立的测试集来估计泛化误差",{"2":{"252":1}}],["我们只能从数千或数万个数据样本中学习",{"2":{"251":1}}],["我们只能访问数据中的小部分样本",{"2":{"251":1}}],["我们只调用了深度学习框架提供的反向传播函数",{"2":{"161":1}}],["我们只使用确定性的图像预处理操作",{"2":{"903":1}}],["我们只使用过高度或宽度为1的步幅",{"2":{"142":1}}],["我们只使用前1",{"2":{"79":1}}],["我们只限于最简单的证明之一",{"2":{"115":1}}],["我们只是指在使用支持向量机时",{"2":{"1143":1}}],["我们只是讨论了y=1的情况",{"2":{"1143":1}}],["我们只是这样表示",{"2":{"1143":1}}],["我们只是说",{"2":{"1061":1}}],["我们只是将噪声添加到其他非随机梯度上",{"2":{"116":1}}],["我们只是证明了以下定理",{"2":{"94":1}}],["我们只是提供调度器作为训练算法的额外参数",{"2":{"68":1}}],["我们只介绍基础知识",{"2":{"67":1}}],["我们只需传入一个概率向量",{"2":{"1026":1}}],["我们只需重复使用此模型的输出层",{"2":{"905":1}}],["我们只需重新定义解码器即可",{"2":{"375":1}}],["我们只需重新索引下标",{"2":{"153":1}}],["我们只需在sequential中添加一个带有10个输出的全连接层",{"2":{"623":1}}],["我们只需在每个全连接层之后添加一个dropout层",{"2":{"176":1}}],["我们只需计算输入特征x和模型权重w的矩阵",{"2":{"602":1}}],["我们只需继承基础层类并实现前向传播功能",{"2":{"413":1}}],["我们只需满足",{"2":{"247":1}}],["我们只需合并隐藏层",{"2":{"232":1}}],["我们只需要从u中选取前k个向量",{"2":{"1159":1}}],["我们只需要选择不同的权重即可",{"2":{"1102":1}}],["我们只需要键入featuresx",{"2":{"1089":1}}],["我们只需要一些非常非常基础的线性代数知识",{"2":{"1070":1}}],["我们只需要索引所有元素",{"2":{"1020":1}}],["我们只需要提供张量列表",{"2":{"1018":1}}],["我们只需要将权重矩阵w的形状转置为",{"2":{"970":1}}],["我们只需要用到从输入层到最靠近输出层的内容层或风格层之间的所有层",{"2":{"920":1}}],["我们只需要遍历剩余的锚框a1",{"2":{"851":1}}],["我们只需要计算网络中的前向传播",{"2":{"811":1}}],["我们只需要评估10000×10=105个序列",{"2":{"514":1}}],["我们只需要实现",{"2":{"436":1}}],["我们只需要实例化一个sequential块并将需要的层连接在一起",{"2":{"136":1}}],["我们只需要定义两个关键函数",{"2":{"424":1}}],["我们只需要定义一个灵活的程序算法",{"2":{"282":1}}],["我们只需要考虑前向传播函数和必需的参数",{"2":{"422":1}}],["我们只需要考虑过去观察中的一个非常短的历史",{"2":{"348":1}}],["我们只需要特征x∼p",{"2":{"191":1}}],["我们只需要q的特征值和特征向量即可将问题从x整理到z",{"2":{"26":1}}],["我们只需水平和垂直翻转二维卷积核张量",{"2":{"130":1}}],["我们只需将锚框的类别标记为背景",{"2":{"852":1}}],["我们只需将一个块指定为hybridsequential",{"2":{"819":1}}],["我们只需将",{"2":{"501":1}}],["我们只需将值固定到ηt而不再增加它",{"2":{"72":1}}],["我们只需将αici",{"2":{"49":1}}],["我们只需使用高级api中的adadelta算法",{"2":{"21":1}}],["我们只会看到x¯i和f¯的最小值发声微小变化",{"2":{"26":1}}],["我们可根据情况选择用插值法和删除法",{"2":{"1014":1}}],["我们可直接使用深度学习框架中提供的rmsprop算法来训练模型",{"2":{"109":1}}],["我们可直接使用深度学习框架中提供的adagrad算法来训练模型",{"2":{"29":1}}],["我们可能能从问题中发现我们需要增加一些新的特征",{"2":{"1183":1}}],["我们可能有一个这样的样本",{"2":{"1161":1}}],["我们可能有数百兆的参数",{"2":{"1021":1}}],["我们可能有数百个参数散布在各处",{"2":{"442":1}}],["我们可能首先要初始化变量",{"2":{"1093":1}}],["我们可能需要某种算法帮助我们寻找一种结构",{"2":{"1150":1}}],["我们可能需要对疾病和症状之间的关系进行建模",{"2":{"1029":1}}],["我们可能需要使用我们的模型对逐个样本进行预测",{"2":{"471":1}}],["我们可能从一张图像中选出上千个提议区域",{"2":{"937":1}}],["我们可能不需要非常精确的计算",{"2":{"811":1}}],["我们可能不想在一开始就太大地降低学习率",{"2":{"72":1}}],["我们可能就已经开始将y的部分复制到cpu了",{"2":{"797":3}}],["我们可能想预测他们在下一年心脏病发作的概率",{"2":{"1025":1}}],["我们可能想知道动词和主语在哪里",{"2":{"295":1}}],["我们可能想让模型描绘输入图像的内容",{"2":{"292":1}}],["我们可能对后一帧中发生的事情更有把握",{"2":{"295":1}}],["我们可能永远也无法实现网络的表达能力",{"2":{"244":1}}],["我们可能面临一些问题",{"2":{"241":1}}],["我们可能根据症状来判断",{"2":{"182":1}}],["我们可能只会丢失几个像素",{"2":{"141":1}}],["我们可能希望估计某些用户购买特定图书的概率",{"2":{"1025":1}}],["我们可能希望将前提中的",{"2":{"674":1}}],["我们可能希望保持有关金融市场状况",{"2":{"526":1}}],["我们可能希望执行任意的数学运算",{"2":{"425":1}}],["我们可能希望在前向传播函数中执行python的控制流",{"2":{"425":1}}],["我们可能希望拆分这样的序列方便模型读取",{"2":{"319":1}}],["我们可能希望比较具有",{"2":{"255":1}}],["我们可能希望大幅降低图像的宽度和高度",{"2":{"140":1}}],["我们可能希望更慢地降低学习率",{"2":{"27":1}}],["我们可能会得到一条类似于这样的曲线",{"2":{"1154":1}}],["我们可能会用",{"2":{"1093":1}}],["我们可能会猜测这个模块提供了各种生成随机数的方法",{"2":{"1006":1}}],["我们可能会猜想",{"2":{"467":1}}],["我们可能会修改不同数据集上任务的图像增广操作",{"2":{"909":1}}],["我们可能会将两个数字相乘",{"2":{"809":1}}],["我们可能会发现自己面对一屏幕可怕的nan结果",{"2":{"624":1}}],["我们可能会发现验证效果不再代表真正的误差",{"2":{"212":1}}],["我们可能会遇到这样的情况",{"2":{"538":3}}],["我们可能会遇到收敛性问题",{"2":{"36":1}}],["我们可能会尝试拟合一个更复杂的模型",{"2":{"260":1}}],["我们可能会访问数十万份医疗记录",{"2":{"251":1}}],["我们可能会破坏模型",{"2":{"179":1}}],["我们可能会直觉到计算过去的平均梯度效果会很好",{"2":{"88":1}}],["我们可能无法收敛到最优解",{"2":{"84":1}}],["我们可能最终会在最小值附近弹跳",{"2":{"66":1}}],["我们可能最终会面临这样的情况",{"2":{"25":1}}],["我们可以借助vite中的插件简化",{"2":{"1454":1}}],["我们可以寻找另一部电影x",{"2":{"1189":1}}],["我们可以学习得出电影的特征",{"2":{"1189":1}}],["我们可以针对每一个用户都训练一个线性回归模型",{"2":{"1188":1}}],["我们可以针对下游应用对预训练的bert模型进行微调",{"2":{"689":1}}],["我们可以假设每部电影都有两个特征",{"2":{"1188":1}}],["我们可以假设在负梯度方向上移动的ϵ会减少f",{"2":{"54":1}}],["我们可以去参加一个学术机器学习会议",{"2":{"1187":1}}],["我们可以分析那些被算法错误预测为正常的数据",{"2":{"1183":1}}],["我们可以分成3个尺寸",{"2":{"1154":1}}],["我们可以字体网站下载各种字体",{"2":{"1173":1}}],["我们可以先令k=1",{"2":{"1160":1}}],["我们可以做很多事",{"2":{"1137":1}}],["我们可以花很多时间来考虑这一方法",{"2":{"1129":1}}],["我们可以想象",{"2":{"1122":1}}],["我们可以有很多输出变量",{"2":{"1120":1}}],["我们可以看出alice和bob似乎更倾向与爱情片",{"2":{"1187":1}}],["我们可以看出",{"2":{"1114":1}}],["我们可以看到这里有我们的训练集里房屋价格",{"2":{"1063":1}}],["我们可以看到ones函数创建一个具有指定形状的新张量",{"2":{"1007":1}}],["我们可以看到数据集的不同组件",{"2":{"945":1}}],["我们可以看到在所有这些图像中香蕉的旋转角度",{"2":{"933":1}}],["我们可以看到如果步幅为s",{"2":{"862":1}}],["我们可以看到两个物体的主要轮廓基本上在两个框内",{"2":{"858":1}}],["我们可以看到测试精度与之前的实验基本相同",{"2":{"837":1}}],["我们可以看到列表symbols现在又包含10个从其他符号迭代合并而来的符号",{"2":{"757":1}}],["我们可以看到遮蔽语言模型损失明显高于下一句预测损失",{"2":{"729":1}}],["我们可以看到输出形状是",{"2":{"332":1}}],["我们可以看到经过几次迭代后",{"2":{"59":1}}],["我们可以看到",{"2":{"49":1,"54":1,"113":1,"208":1,"247":1,"708":1,"737":1,"773":1,"854":1,"912":1,"927":1,"1018":1}}],["我们可以预测",{"2":{"1107":1}}],["我们可以预测每个输出类别的概率",{"2":{"653":1}}],["我们可以知道",{"2":{"1099":1}}],["我们可以选取图片上的两个不同位置上的两个像素",{"2":{"1097":1}}],["我们可以选择一个由100个最常出现在垃圾邮件中的词所构成的列表",{"2":{"1137":1}}],["我们可以选择一个足够小的学习率",{"2":{"73":1}}],["我们可以选择vgg网络中某些层的输出",{"2":{"920":1}}],["我们可以选择其中某些层的输出作为内容特征或风格特征",{"2":{"917":1}}],["我们可以选择增加一个列表",{"2":{"363":1}}],["我们可以应用的很好",{"2":{"1097":1}}],["我们可以应用一种称为字节对编码",{"2":{"757":1}}],["我们可以发现这个文本文档存放着我们的数据",{"2":{"1089":1}}],["我们可以发现正确的参数集",{"2":{"282":1}}],["我们可以令代价函数j为迭代次数的函数",{"2":{"1167":1}}],["我们可以令",{"2":{"1084":1}}],["我们可以绘制学习曲线来帮助判断",{"2":{"1164":1}}],["我们可以绘制直线x1+x2=3",{"2":{"1108":1}}],["我们可以绘制迭代次数和代价函数的图表来观测算法在何时趋于收敛",{"2":{"1083":1}}],["我们可以绘制出遮蔽语言模型损失和下一句预测损失",{"2":{"726":1}}],["我们可以让机器找到a与b之间的最短路径",{"2":{"1058":1}}],["我们可以让alexa打开咖啡机",{"2":{"301":1}}],["我们可以得出统计学中最有用的方程之一",{"2":{"1032":1}}],["我们可以得到θ⋅x=a",{"2":{"1099":1}}],["我们可以得到数值均匀介于0和1之间的元素",{"2":{"1088":1}}],["我们可以得到向量c=f",{"2":{"1018":1}}],["我们可以得到词表中一个单词的索引",{"2":{"748":1}}],["我们可以得到最接近输入层的模型参数的梯度",{"2":{"164":1}}],["我们可以得到输出层变量",{"2":{"162":1}}],["我们可以得到",{"2":{"41":1,"54":1}}],["我们可以避免任何关于随机性的哲学争论",{"2":{"1027":1}}],["我们可以避免上述问题",{"2":{"500":1}}],["我们可以说",{"2":{"1027":1}}],["我们可以统计1000次投掷后",{"2":{"1026":1}}],["我们可以模拟1000次投掷",{"2":{"1026":1}}],["我们可以基于任何从标量到标量的函数来创建按元素函数",{"2":{"1018":1}}],["我们可以基于当前输入xt和先前隐状态ht−1",{"2":{"338":1}}],["我们可以访问或遍历小批量的数据样本",{"2":{"992":1}}],["我们可以访问一组训练特征和标签",{"2":{"195":1}}],["我们可以连结一个多元函数对其所有变量的偏导数",{"2":{"983":1}}],["我们可以随后在y上调用反向传播",{"2":{"976":1}}],["我们可以随机水平翻转图像",{"2":{"891":1}}],["我们可以随机打乱了所有样本",{"2":{"583":1}}],["我们可以沿用准确率评价分类结果",{"2":{"962":1}}],["我们可以沿箭头的相反方向遍历计算图",{"2":{"312":1}}],["我们可以方便地",{"2":{"945":1}}],["我们可以方便地通过凸函数的下水平集",{"2":{"45":1}}],["我们可以权衡合成图像在保留内容",{"2":{"925":1}}],["我们可以决定任何图像上均匀采样的锚框的中心",{"2":{"914":1}}],["我们可以生成不同尺寸的锚框来检测不同尺寸的目标",{"2":{"914":1}}],["我们可以生成不同数量和不同大小的锚框",{"2":{"912":1}}],["我们可以确定任何图像上均匀采样锚框的中心",{"2":{"912":1}}],["我们可以利用已有的数据来预测总体中的μ和σ2的计算方法如下",{"2":{"1179":1}}],["我们可以利用神经元来组合成更为复杂的神经网络以实现更复杂的运算",{"2":{"1102":1}}],["我们可以利用深层神经网络在多个层次上对图像进行分层表示",{"2":{"913":1}}],["我们可以利用深度学习开发框架中提供的批量矩阵乘法",{"2":{"390":1}}],["我们可以利用完整imagenet数据集上的预训练模型来提取特征并仅训练小型自定义输出网络",{"2":{"909":1}}],["我们可以增加α来使得函数更加平缓",{"2":{"1167":1}}],["我们可以增加迭代轮数",{"2":{"907":1}}],["我们可以增加周期的数量",{"2":{"895":1}}],["我们可以读取整理后的含原始图像文件的数据集",{"2":{"904":1}}],["我们可以读取它们",{"2":{"897":1}}],["我们可以像",{"2":{"902":1}}],["我们可以点击",{"2":{"889":1}}],["我们可以以不同的方式裁剪图像",{"2":{"877":1}}],["我们可以参考分配到的最接近此锚框的真实边界框的位置和类别标签",{"2":{"850":1}}],["我们可以同时使用gpu和cpu",{"2":{"830":2}}],["我们可以同时处理许多不同的事情",{"2":{"789":1}}],["我们可以跳过python解释器",{"2":{"817":1}}],["我们可以依靠几行python代码实现相同的目标",{"2":{"795":1}}],["我们可以依靠在",{"2":{"316":1}}],["我们可以获得以指定像素的位置为中心的所有锚框",{"2":{"848":1}}],["我们可以获得其关于任意上下文词向量voi",{"2":{"786":1}}],["我们可以获得其相对于中心词向量vc的梯度为",{"2":{"784":1}}],["我们可以获得ϵ=−x",{"2":{"59":1}}],["我们可以定义一个简单的模型synthesizedimage",{"2":{"926":1}}],["我们可以定义一个稠密层",{"2":{"437":1}}],["我们可以定义其他变量来区分填充标记和非填充标记",{"2":{"778":1}}],["我们可以观察到以下几点",{"2":{"744":1}}],["我们可以观察到类似于蝴蝶效应的现象",{"2":{"308":1}}],["我们可以任意访问数据集中索引为idx的输入图像及其每个像素的类别索引",{"2":{"947":1}}],["我们可以任意访问从wikitext",{"2":{"723":1}}],["我们可以任意访问wikitext",{"2":{"722":1}}],["我们可以任意访问带有索引idx的前提",{"2":{"668":1}}],["我们可以实现多个输入通道的一维互相关运算",{"2":{"699":1}}],["我们可以修改本节中的哪些超参数来加速训练情感分析模型",{"2":{"697":1}}],["我们可以调用item函数或python的内置函数",{"2":{"1022":1}}],["我们可以调用函数来计算任意形状张量的平均值",{"2":{"995":1}}],["我们可以调用z",{"2":{"791":1}}],["我们可以调用read",{"2":{"669":1}}],["我们可以调用as",{"2":{"449":1}}],["我们可以考虑为下游自然语言处理应用微调bert",{"2":{"656":1}}],["我们可以考虑使用穷举搜索",{"2":{"514":1}}],["我们可以训练和验证模型了",{"2":{"895":1}}],["我们可以训练多分类的模型",{"2":{"637":1}}],["我们可以训练一个基于循环神经网络的字符级语言模型",{"2":{"336":1}}],["我们可以训练一个普通的二项分类器来区分猫和狗",{"2":{"292":1}}],["我们可以提高模型的分类精度",{"2":{"635":1}}],["我们可以提交预测到kaggle上",{"2":{"213":1}}],["我们可以评估在任意模型net的精度",{"2":{"634":1}}],["我们可以更深入地探讨指数族与softmax之间的联系",{"2":{"655":1}}],["我们可以更简洁地实现softmax回归",{"2":{"627":1}}],["我们可以更容易地逼近许多函数",{"2":{"233":1}}],["我们可以改变图像颜色的四个方面",{"2":{"880":1}}],["我们可以改变w的大小",{"2":{"49":1}}],["我们可以改为最小化负对数似然−log⁡p",{"2":{"616":1}}],["我们可以明确地写成如下形式",{"2":{"613":1}}],["我们可以开始通过代码来动手实现线性回归了",{"2":{"598":1}}],["我们可以创建一个形状为",{"2":{"1017":2}}],["我们可以创建一个环境",{"2":{"298":1}}],["我们可以创建三个相同的序列来进行",{"2":{"575":1}}],["我们可以直接实例化lstm模型",{"2":{"561":1}}],["我们可以直接调用load和save函数分别读写它们",{"2":{"441":1}}],["我们可以指定保持在原始张量的轴数",{"2":{"631":1}}],["我们可以指定用于存储和计算的设备",{"2":{"446":1,"452":1}}],["我们可以指定汇聚层的填充和步幅",{"2":{"149":1}}],["我们可以最大限度地减少在设备之间传输数据的时间",{"2":{"445":3}}],["我们可以检查第二个全连接层的参数",{"2":{"430":1}}],["我们可以子类化块以创建层",{"2":{"423":1}}],["我们可以高效地计算p",{"2":{"348":1}}],["我们可以安全地假设",{"2":{"334":1}}],["我们可以尝试使用随机梯度下降法来代替批量梯度下降法",{"2":{"1165":1}}],["我们可以尝试通过解决以下优化问题来找到它",{"2":{"500":1}}],["我们可以尝试估计",{"2":{"316":1}}],["我们可以尝试以下方法",{"2":{"77":1}}],["我们可以为不同的滤波器分配不同数量的参数",{"2":{"487":1}}],["我们可以为模型绘制一个计算图",{"2":{"312":1}}],["我们可以为每个输出通道创建一个形状为ci×kh×kw的卷积核张量",{"2":{"121":1}}],["我们可以用cpu负载与网络通信量的比例作为一个新的特征",{"2":{"1183":1}}],["我们可以用向量化的方式来循环",{"2":{"1166":1}}],["我们可以用拟合训练样本的参数$",{"2":{"1110":1}}],["我们可以用非常复杂的模型来适应非常复杂形状的判定边界",{"2":{"1108":1}}],["我们可以用线性回归的方法求出适合数据的一条直线",{"2":{"1107":1}}],["我们可以用这样的一个神经网络表示and",{"2":{"1101":1}}],["我们可以用",{"2":{"1089":1}}],["我们可以用数学语言严格地推理",{"2":{"1027":1}}],["我们可以用更大的网络处理数据",{"2":{"832":1}}],["我们可以用它来表示单个文本",{"2":{"727":1,"728":1}}],["我们可以用神经网络图",{"2":{"641":1}}],["我们可以用一个单一的激活层可以作为二元逻辑运算符",{"2":{"1102":1}}],["我们可以用一个可以训练的小型自定义输出网络替换原始输出层",{"2":{"905":1}}],["我们可以用一个标量表示每个像素值",{"2":{"640":1}}],["我们可以用一个随机变量替换∂ht",{"2":{"310":1}}],["我们可以用点积形式来简洁地表达模型",{"2":{"610":1}}],["我们可以用不同的词填空",{"2":{"518":1}}],["我们可以用创造性的方式组合不同的层",{"2":{"412":1}}],["我们可以用独立学习得到的h组不同的",{"2":{"380":1}}],["我们可以用softmax",{"2":{"339":1}}],["我们可以用深度学习框架自带算法应用adam算法",{"2":{"34":1}}],["我们可以仅仅计算",{"2":{"308":1}}],["我们可以孤立地进行模式识别",{"2":{"297":1}}],["我们可以试着用概率语言来理解模型",{"2":{"291":1}}],["我们可以忽略这种情况",{"2":{"235":1}}],["我们可以画出函数的曲线图",{"2":{"235":1}}],["我们可以很容易地设计隐藏节点来执行任意计算",{"2":{"233":1}}],["我们可以继续堆叠这样的隐藏层",{"2":{"232":1}}],["我们可以采用如下方法来近似地获得原有的特征",{"2":{"1160":1}}],["我们可以采用与之前在动量法中适用的相同推理",{"2":{"107":1}}],["我们可以采样较少的区域",{"2":{"912":1}}],["我们可以采样更多的区域",{"2":{"912":1}}],["我们可以采取的行动是有限的",{"2":{"197":1}}],["我们可以根据锚框及其预测偏移量得到预测边界框",{"2":{"964":1}}],["我们可以根据当前词元集预测的下一个词元",{"2":{"342":1}}],["我们可以根据猫和狗的大量图片训练猫检测器",{"2":{"195":1}}],["我们可以根据",{"2":{"192":1}}],["我们可以根据其特征分解q=u⊤λu重写这个问题",{"2":{"26":1}}],["我们可以使用多元高斯分布模型",{"2":{"1184":1}}],["我们可以使用多层循环神经网络",{"2":{"579":1}}],["我们可以使用这个矩阵来计算平均均方误差与训练集方差的比例",{"2":{"1160":1}}],["我们可以使用比0",{"2":{"1140":2}}],["我们可以使用联合分布",{"2":{"1037":1}}],["我们可以使用切片表示法将操作的结果分配给先前分配的数组",{"2":{"1021":1}}],["我们可以使用下标来引用向量的任一元素",{"2":{"990":1}}],["我们可以使用下面的sequence",{"2":{"575":1}}],["我们可以使用下面的公式移除",{"2":{"307":1}}],["我们可以使用以下规则来对常见函数求微分",{"2":{"981":1}}],["我们可以使用矩阵乘法来实现卷积",{"2":{"971":1}}],["我们可以使用矩阵乘法来实现转置卷积",{"2":{"970":1}}],["我们可以使用另一种类型的卷积神经网络层",{"2":{"967":1}}],["我们可以使用另一个循环神经网络作为解码器",{"2":{"574":1}}],["我们可以使用非极大值抑制",{"2":{"854":1}}],["我们可以使用tf",{"2":{"819":1}}],["我们可以使用tensorflow的高级api更简洁地实现模型",{"2":{"596":1}}],["我们可以使用嵌入层和二元交叉熵损失来训练带负采样的跳元模型",{"2":{"769":1}}],["我们可以使用训练好模型中词向量的余弦相似度来从词表中找到与输入单词语义最相似的单词",{"2":{"768":1}}],["我们可以使用训练好的模型来获得对示例句子的自然语言推断结果",{"2":{"682":1}}],["我们可以使用负采样来训练跳元模型",{"2":{"767":1}}],["我们可以使用像子词这样的符号来切分单词",{"2":{"757":1}}],["我们可以使用附加的偏置项来拟合−logα+logxi",{"2":{"744":1}}],["我们可以使用汇聚层从序列表示中提取最大值",{"2":{"700":1}}],["我们可以使用词表将imdb评论数据集加载到数据迭代器中",{"2":{"696":1}}],["我们可以使用预训练好的词向量作为下游自然语言处理任务",{"2":{"683":1}}],["我们可以使用pytorch的高级api更简洁地实现模型",{"2":{"596":1}}],["我们可以使用gluon更简洁地实现模型",{"2":{"596":1}}],["我们可以使用遮蔽来过滤不相关的计算",{"2":{"579":1}}],["我们可以使用两个循环神经网络来设计一个序列到序列学习的模型",{"2":{"579":1}}],["我们可以使用输出层和softmax操作",{"2":{"574":1}}],["我们可以使用nvidia",{"2":{"448":1}}],["我们可以使用自定义初始化方法",{"2":{"438":1}}],["我们可以使用内置函数来创建参数",{"2":{"414":1}}],["我们可以使用困惑度来评价语言模型的质量",{"2":{"343":1}}],["我们可以使用循环神经网络创建字符级语言模型",{"2":{"343":1}}],["我们可以使用平方误差作为我们的损失函数",{"2":{"259":1}}],["我们可以使用与以前相同的表示形式",{"2":{"648":1}}],["我们可以使用与37摄氏度的距离作为特征",{"2":{"230":1}}],["我们可以使用与训练网络相同的方法",{"2":{"193":1}}],["我们可以使用高级api更简洁地实现多层感知机",{"2":{"226":1}}],["我们可以使用k折交叉验证来选择模型并调整超参数",{"2":{"214":1}}],["我们可以使用上面定义的脚本下载并缓存kaggle房屋数据集",{"2":{"208":1}}],["我们可以使用我们估计的p",{"2":{"192":1}}],["我们可以使用",{"2":{"191":1,"751":1,"905":1,"1007":1,"1017":3}}],["我们可以使用q的对角线条目并相应地重新缩放它",{"2":{"26":1}}],["我们可以讨论一些协变量偏移或概念偏移可能并不明显的具体情况",{"2":{"184":1}}],["我们可以计算在bert预训练中的遮蔽语言模型任务的交叉熵损失",{"2":{"736":1}}],["我们可以计算从位置i到位置j的有效片段的分数si+ej",{"2":{"660":1}}],["我们可以计算目标函数关于输出层中参数wqh的梯度",{"2":{"312":1}}],["我们可以计算每个活性值",{"2":{"232":1}}],["我们可以计算z关于x的导数",{"2":{"164":1}}],["我们可以计算单个数据样本的损失项",{"2":{"162":1}}],["我们可以计算a",{"2":{"77":1}}],["我们可以计算aij=bi",{"2":{"77":1}}],["我们可以把一个矩阵a∈rm×n乘法看作一个从rn到rm向量的转换",{"2":{"998":1}}],["我们可以把交叉熵想象为",{"2":{"652":1}}],["我们可以把穷举搜索看作一种特殊的束搜索吗",{"2":{"517":1}}],["我们可以把前l−1层看作表示",{"2":{"231":1}}],["我们可以把隐藏表示想象为一系列具有二维张量的通道",{"2":{"158":1}}],["我们可以把卷积核看作形状为kh×kw的二维张量",{"2":{"120":1}}],["我们可以简单用p",{"2":{"1028":1}}],["我们可以简单地使用矩阵a的小写字母索引下标aij",{"2":{"992":1}}],["我们可以简单地将x1",{"2":{"982":1}}],["我们可以简单地复用之前图像分类问题里一直使用的交叉熵损失函数来计算",{"2":{"962":1}}],["我们可以简单地计算a=bc",{"2":{"77":1}}],["我们可以简化h定义为",{"2":{"154":1}}],["我们可以认为第二层中的特征是神经网络通过学习后自己得出的一系列用于预测输出变量的新特征",{"2":{"1101":1}}],["我们可以认为",{"2":{"153":1,"230":1}}],["我们可以设计基础网络",{"2":{"953":1}}],["我们可以设计三个词向量的函数来拟合这个比值",{"2":{"744":1}}],["我们可以设计一个神经网络",{"2":{"913":1}}],["我们可以设计一个包含两个主要组件的架构",{"2":{"532":1}}],["我们可以设计一个卷积核来检测图像的边缘",{"2":{"132":1}}],["我们可以设置每个稠密块使用多少个卷积层",{"2":{"482":1}}],["我们可以设置",{"2":{"155":1}}],["我们可以设定一个任意大小的矩形汇聚窗口",{"2":{"147":3}}],["我们可以",{"2":{"136":1,"141":1,"147":1,"209":1,"318":1,"363":1,"390":1,"413":1,"414":1,"425":1,"441":1,"446":1,"447":1,"575":1,"576":1,"582":1,"590":1,"591":1,"632":1,"837":1,"853":1,"854":2,"858":1,"880":1,"883":1,"968":1,"992":1,"995":1,"996":1,"1006":1}}],["我们可以在不同的环境中使用梯度下降法",{"2":{"1069":1}}],["我们可以在不影响准确性的前提下",{"2":{"824":1}}],["我们可以在同一形状的任意两个张量上调用按元素操作",{"2":{"1018":1}}],["我们可以在输入图像中均匀采样一小部分像素",{"2":{"912":1}}],["我们可以在图像分类竞赛中使用卷积神经网络和图像增广",{"2":{"897":2}}],["我们可以在图像分类竞赛中使用卷积神经网络",{"2":{"897":1}}],["我们可以在图像中截取多块高和宽为32的整数倍的矩形区域",{"2":{"866":1}}],["我们可以在图像中保留空间结构",{"2":{"135":1}}],["我们可以在两种常用的边界框表示",{"2":{"859":1}}],["我们可以在两个设备上同时进行计算和通信",{"2":{"797":1}}],["我们可以在索引1",{"2":{"775":1}}],["我们可以在卷积层之后和非线性激活函数之前应用批量规范化",{"2":{"470":1}}],["我们可以在创建张量时指定存储设备",{"2":{"448":1}}],["我们可以在向该网络发送随机数据后",{"2":{"413":1}}],["我们可以在τ步后截断",{"2":{"309":1}}],["我们可以在v中添加第四个坐标",{"2":{"158":1}}],["我们可以在顶部和底部填充相同数量的行",{"2":{"141":1}}],["我们可以在每个迭代轮数",{"2":{"68":1}}],["我们可以从之前的事例中看出",{"2":{"1115":1}}],["我们可以从这个点推测出",{"2":{"1060":1}}],["我们可以从概率分布中采样",{"2":{"1037":1}}],["我们可以从学习它的表示开始",{"2":{"754":1}}],["我们可以从两方面来考虑交叉熵分类目标",{"2":{"652":1}}],["我们可以从随机偏移量开始划分序列",{"2":{"319":1}}],["我们可以从",{"2":{"312":1,"388":1,"699":1}}],["我们可以从儿童游戏",{"2":{"152":1}}],["我们可以从数据中学习卷积核的参数",{"2":{"132":1}}],["我们可以从较小的学习率开始",{"2":{"114":1}}],["我们可以构建具有更多轴的数据结构",{"2":{"993":1}}],["我们可以构建",{"2":{"146":1}}],["我们可以构建一个更深的卷积网络",{"2":{"132":1}}],["我们可以构建一个更深的网络",{"2":{"131":1}}],["我们可以构造与",{"2":{"120":1}}],["我们可以对新求出的",{"2":{"1158":1}}],["我们可以对假设函数h",{"2":{"1130":1}}],["我们可以对标量",{"2":{"1003":1}}],["我们可以对任意张量进行的一个有用的操作是",{"2":{"995":1}}],["我们可以对任意函数建模",{"2":{"233":1}}],["我们可以对输入矩阵x和卷积核矩阵k",{"2":{"968":1}}],["我们可以对文本使用风格迁移吗",{"2":{"929":1}}],["我们可以对那些相对位置和大小应用变换",{"2":{"852":1}}],["我们可以对他们进行下采样",{"2":{"778":1}}],["我们可以对所有元素求和",{"2":{"631":1}}],["我们可以对第一层的权重w",{"2":{"244":1}}],["我们可以对每个通道输入的二维张量和卷积核的二维张量进行互相关运算",{"2":{"120":1}}],["我们可以对多变量函数使用相应的泰勒近似来思考",{"2":{"57":1}}],["我们可以跟踪时间t处的当前参数xt和风险最小化器x∗之间的距离",{"2":{"115":1}}],["我们可以近似该函数的局部最小值和全局最小值",{"2":{"101":1}}],["我们可以将批量梯度下降的求和任务分配给4台计算机进行处理",{"2":{"1169":1}}],["我们可以将不同阀值情况下",{"2":{"1140":1}}],["我们可以将其用在多类分类问题上",{"2":{"1112":1}}],["我们可以将其视为",{"2":{"646":1}}],["我们可以将其视为1×1卷积层",{"2":{"494":1}}],["我们可以将p",{"2":{"1028":1}}],["我们可以将事件",{"2":{"1028":1}}],["我们可以将概率赋值为0",{"2":{"1025":1}}],["我们可以将矩阵",{"2":{"999":1}}],["我们可以将矩阵的区块移到缓存中然后在本地将它们相乘",{"2":{"77":1}}],["我们可以将任意矩阵a∈rm×n视为一个表格",{"2":{"992":1}}],["我们可以将任何边界框的像素区域视为一组像素",{"2":{"849":1}}],["我们可以将任何监督学习问题转化为强化学习问题",{"2":{"298":1}}],["我们可以将某些数据集视为一个表",{"2":{"987":1}}],["我们可以将拟合模型的任务分解为两个关键问题",{"2":{"980":1}}],["我们可以将负锚框的高和宽减半",{"2":{"966":1}}],["我们可以将预测结果转成二维的",{"2":{"956":1}}],["我们可以将此输出转换为矩阵x",{"2":{"923":1}}],["我们可以将特征图在同一空间位置的c个单元变换为使用此空间位置生成的a个锚框类别和偏移量",{"2":{"913":1}}],["我们可以将转置卷积层初始化为双线性插值的上采样",{"2":{"867":1}}],["我们可以将统计建模人员",{"2":{"844":1}}],["我们可以将这两个输出视为两个规范化的损失",{"2":{"765":1}}],["我们可以将这两个变量都视为超参数",{"2":{"217":1}}],["我们可以将情感分析看作一项文本分类任务",{"2":{"691":1}}],["我们可以将一个文本序列中的词元与另一个文本序列中的每个词元对齐",{"2":{"673":1,"683":1}}],["我们可以将估计值与实际值进行比较",{"2":{"646":1}}],["我们可以将线性回归模型视为仅由单个人工神经元组成的神经网络",{"2":{"618":1}}],["我们可以将低频词元视为相同的未知词元",{"2":{"570":1}}],["我们可以将深度架构中的函数依赖关系形式化",{"2":{"527":1}}],["我们可以将多层循环神经网络堆叠在一起",{"2":{"526":1}}],["我们可以将后向递归",{"2":{"519":1}}],["我们可以将它们相加",{"2":{"449":1}}],["我们可以将x传输到第二个gpu并在那里执行操作",{"2":{"449":1}}],["我们可以将问题的维数增加到d=200",{"2":{"271":1}}],["我们可以将o关于任何一组参数w",{"2":{"241":1}}],["我们可以将每个图像视为具有784个输入特征",{"2":{"217":1}}],["我们可以将每个通道看作对不同特征的响应",{"2":{"121":1}}],["我们可以将暂退法应用于每个隐藏层的输出",{"2":{"174":1}}],["我们可以将",{"2":{"155":1,"981":1}}],["我们可以将全连接层形式化地表示为",{"2":{"153":1}}],["我们可以将1×1卷积层看作在每个像素位置应用的全连接层",{"2":{"122":1}}],["我们可以将动量法与随机梯度下降",{"2":{"88":1}}],["我们可以将b和c分成较小的区块矩阵",{"2":{"77":1}}],["我们可以一次计算a一行ai",{"2":{"77":1}}],["我们可以一次计算一列",{"2":{"77":1}}],["我们可以通过构造新新特征的方法来捕捉这些相关性",{"2":{"1184":1}}],["我们可以通过assign将一个操作的结果分配给一个variable",{"2":{"1021":1}}],["我们可以通过执行按元素乘法",{"2":{"997":1}}],["我们可以通过行索引",{"2":{"992":1}}],["我们可以通过预训练的卷积神经网络来抽取图像的特征",{"2":{"928":1}}],["我们可以通过深入学习",{"2":{"914":1}}],["我们可以通过对图像进行随机裁剪",{"2":{"879":1}}],["我们可以通过以下代码获取其输出层中的相应权重参数",{"2":{"876":1}}],["我们可以通过以下论证来证明这一技术的合理性",{"2":{"168":1}}],["我们可以通过转换两次来验证边界框转换函数的正确性",{"2":{"858":1}}],["我们可以通过其像素集的杰卡德系数来测量两个边界框的相似性",{"2":{"849":1}}],["我们可以通过打印参数和观察可能出现的任何错误来验证这一点",{"2":{"827":1}}],["我们可以通过向x添加所有值为1的一列来做到这一点",{"2":{"621":1}}],["我们可以通过向机器学习系统",{"2":{"282":1}}],["我们可以通过",{"2":{"596":1,"605":1,"968":1,"1017":1}}],["我们可以通过调用python的内置len",{"2":{"991":1}}],["我们可以通过调用nn",{"2":{"592":1}}],["我们可以通过调用init",{"2":{"592":1}}],["我们可以通过调整拟合多项式的阶数来限制模型的容量",{"2":{"269":1}}],["我们可以通过与真实的标签序列进行比较来评估预测序列",{"2":{"578":1}}],["我们可以通过参数字典保存和加载网络的全部参数",{"2":{"443":1}}],["我们可以通过索引来访问模型的任意层",{"2":{"430":1}}],["我们可以通过简洁的代码实现复杂的神经网络",{"2":{"422":1}}],["我们可以通过模型传递数据",{"2":{"419":1}}],["我们可以通过基本层类设计自定义层",{"2":{"415":1}}],["我们可以通过计算序列的似然概率来度量模型的质量",{"2":{"342":1}}],["我们可以通过降低η的学习率来解决这个问题",{"2":{"334":1}}],["我们可以通过最小化总损失来学习模型参数的最佳值",{"2":{"286":1}}],["我们可以通过在网络中加入一个或多个隐藏层来克服线性模型的限制",{"2":{"231":1}}],["我们可以通过在真实风险的计算中",{"2":{"191":1}}],["我们可以通过下面的网址提交预测",{"2":{"207":1}}],["我们可以通过下面几个例子来",{"2":{"172":1}}],["我们可以通过运用策略来应对这种偏移",{"2":{"189":1}}],["我们可以通过填充和步幅以获得所需的输出形状",{"2":{"147":1}}],["我们可以通过指数衰减",{"2":{"114":1}}],["我们可以通过将其应用于一个小批量观测值来提高此操作的计算效率",{"2":{"78":1}}],["我们可以通过点积进行逐元素计算",{"2":{"77":1}}],["我们可以通过使用一个compose实例来综合上面定义的不同的图像增广方法",{"2":{"881":1}}],["我们可以通过使用更大的小批量或者切换到改进的估计值st来修正它们",{"2":{"36":1}}],["我们可以通过使用∑i=0tβi=1−βt1−β来解决这个问题",{"2":{"33":1}}],["我们可以按如下方式计算向量的l2范数",{"2":{"1000":1}}],["我们可以按如下方式计算oi的平均值和方差",{"2":{"247":1}}],["我们可以按如下方式计算它",{"2":{"20":1}}],["我们可以按如下方式实现这一点",{"2":{"71":1}}],["我们可以写成f",{"2":{"52":1}}],["我们可以证明这一等价性",{"2":{"232":1}}],["我们可以证明多维情况",{"2":{"46":1}}],["我们可以证明对",{"2":{"46":1}}],["我们可以证明",{"2":{"46":1,"117":1}}],["我们可以引入凸函数",{"2":{"41":1}}],["我们可以毫不费力地进一步得到这样的结果",{"2":{"40":1}}],["我们可以放心地使用梯度的方差作为黑塞矩阵比例的廉价替代",{"2":{"26":1}}],["我们大多希望在训练的过程中降低学习率",{"2":{"25":1}}],["我们使用阀值0",{"2":{"1140":1}}],["我们使用逗号来表示一个具有5个元素的元组",{"2":{"1018":1}}],["我们使用mv函数",{"2":{"998":1}}],["我们使用平均绝对误差来评价边界框的预测结果",{"2":{"962":1}}],["我们使用格拉姆矩阵表达风格层输出的风格",{"2":{"928":1}}],["我们使用基于imagenet数据集预训练的vgg",{"2":{"920":1}}],["我们使用输入图像在某个感受野区域内的信息",{"2":{"914":1}}],["我们使用三个rgb通道的均值和标准差来对完整的imagenet数据集进行图像标准化",{"2":{"905":1}}],["我们使用所有标记的数据",{"2":{"896":1}}],["我们使用图像增广来解决过拟合的问题",{"2":{"891":1}}],["我们使用cifar",{"2":{"882":1}}],["我们使用真实边界框",{"2":{"852":1}}],["我们使用同一台机器既作为工作节点还作为服务器",{"2":{"843":1}}],["我们使用全尺寸的小批量",{"2":{"837":3}}],["我们使用全连接层实现1×1卷积",{"2":{"122":1}}],["我们使用独热向量来表示词",{"2":{"781":1}}],["我们使用负采样进行近似训练",{"2":{"775":1}}],["我们使用列表symbols中的子词",{"2":{"757":1}}],["我们使用d1来表示诊断结果",{"2":{"1035":1}}],["我们使用d2l",{"2":{"722":1}}],["我们使用data",{"2":{"605":1}}],["我们使用训练好的模型来预测两个简单句子的情感",{"2":{"704":1}}],["我们使用4个工作进程并行生成训练或测试样本",{"2":{"687":1}}],["我们使用预训练好的100维glove嵌入来表示输入词元",{"2":{"680":1}}],["我们使用argmax获得每行中最大元素的索引来获得预测类别",{"2":{"634":1}}],["我们使用reshape函数将每张原始图像展平为向量",{"2":{"632":1}}],["我们使用重载的+运算符来计算按元素的和",{"2":{"615":1}}],["我们使用重新缩放的梯度gt",{"2":{"20":1}}],["我们使用for循环",{"2":{"615":1}}],["我们使用fashion",{"2":{"489":1,"496":1}}],["我们使用n来表示数据集中的样本数",{"2":{"609":1}}],["我们使用线性模型参数w=",{"2":{"599":1}}],["我们使用内置的数据迭代器",{"2":{"583":1}}],["我们使用具有预测最高可能性的词元",{"2":{"577":4}}],["我们使用一个函数来",{"2":{"890":1}}],["我们使用一个两层门控循环单元编码器",{"2":{"573":1}}],["我们使用一个11",{"2":{"461":1}}],["我们使用了较小的语料库wikitext",{"2":{"718":1}}],["我们使用了嵌入层",{"2":{"573":1}}],["我们使用了一种在很大程度上取决于小批量中的方差的正则化",{"2":{"78":1}}],["我们使用的特征是至关重要的",{"2":{"1183":1}}],["我们使用的",{"2":{"872":1}}],["我们使用的是一个单向循环神经网络来设计编码器",{"2":{"573":1}}],["我们使用的批量大小为n",{"2":{"341":1}}],["我们使用transforms模块来创建randomflipleftright实例",{"2":{"879":1}}],["我们使用totensor实例将一批图像转换为深度学习框架所要求的格式",{"2":{"882":1}}],["我们使用tokenembedding的实例embed中预训练好的词向量来搜索相似的词",{"2":{"750":1}}],["我们使用torch",{"2":{"446":1}}],["我们使用tanh非线性激活函数来确保候选隐状态中的值保持在区间",{"2":{"541":1}}],["我们使用sigmoid函数",{"2":{"540":1}}],["我们使用来自过去和未来的观测信息来预测当前的观测",{"2":{"522":1}}],["我们使用与点积相同的matvec函数",{"2":{"998":1}}],["我们使用与点积相同的dot函数",{"2":{"998":1}}],["我们使用与",{"2":{"512":1}}],["我们使用与先前加性注意力例子中相同的键",{"2":{"370":1}}],["我们使用gpu",{"2":{"446":1}}],["我们使用以下的分布为任意权重参数w定义初始化方法",{"2":{"436":1}}],["我们使用修正线性单元作为激活函数",{"2":{"414":1}}],["我们使用字符",{"2":{"364":1}}],["我们使用xavier初始化参数",{"2":{"863":1}}],["我们使用xt−1",{"2":{"348":1}}],["我们使用x=10作为初始值",{"2":{"54":1}}],["我们使用它来替换",{"2":{"310":1}}],["我们使用不同的模型来处理",{"2":{"289":1}}],["我们使用先验和似然的乘积",{"2":{"280":1}}],["我们使用权重衰减超参数wd创建一个l2正则化器",{"2":{"278":1}}],["我们使用权重衰减来运行代码",{"2":{"277":1}}],["我们使用验证数据拟合",{"2":{"270":1}}],["我们使用正态分布来初始化权重值",{"2":{"246":1}}],["我们使用观测数据来联合学习隐藏层表示和应用于该表示的线性预测器",{"2":{"230":1}}],["我们使用paddle",{"2":{"446":1}}],["我们使用pandas分别加载包含训练数据和测试数据的两个csv文件",{"2":{"208":1}}],["我们使用prod运算符在执行必要的操作",{"2":{"164":1}}],["我们使用这些预训练的词向量来表示评论中的词元",{"2":{"714":1}}],["我们使用这些特性和标签训练f",{"2":{"195":1}}],["我们使用这样一个事实",{"2":{"46":1}}],["我们使用新数据更新现有的网络权重",{"2":{"193":1}}],["我们使用适当的对应项",{"2":{"164":1}}],["我们使用高度为5",{"2":{"141":1}}],["我们使用交叉熵损失函数和小批量随机梯度下降",{"2":{"137":1}}],["我们使用在imagenet数据集上预训练的resnet",{"2":{"873":1}}],["我们使用在",{"2":{"137":1}}],["我们使用二次函数f",{"2":{"108":1}}],["我们使用1+γ+γ2+",{"2":{"107":1}}],["我们使用小批量随机梯度下降进行优化",{"2":{"80":1}}],["我们使用∇f",{"2":{"62":1}}],["我们使用",{"2":{"46":1,"173":1,"326":1,"601":1,"635":1,"648":1,"679":1,"834":1,"893":1}}],["我们使用有界长度的变量",{"2":{"40":1}}],["我们使用变量st来累加过去的梯度方差",{"2":{"27":1}}],["我们使用作者的原始符号和命名",{"2":{"20":1}}],["健康",{"2":{"251":1}}],["痴呆",{"2":{"251":1}}],["共轭梯度法",{"2":{"1111":1}}],["共轭梯度",{"2":{"1109":1}}],["共产生nhnw个中间结果",{"2":{"968":1}}],["共有120个输出类别",{"2":{"905":3}}],["共有18层",{"2":{"502":1}}],["共现概率的比值能够直观地表达词与词之间的关系",{"2":{"744":1}}],["共现",{"2":{"741":1}}],["共指消解",{"2":{"731":1}}],["共享网络和存储",{"2":{"1380":1}}],["共享宿主机内核",{"2":{"1346":1}}],["共享链路",{"2":{"812":1}}],["共享",{"2":{"248":1,"414":1}}],["共适应性",{"2":{"170":1}}],["默认插槽",{"0":{"1506":1},"2":{"1506":1}}],["默认是被卸载掉的",{"2":{"1475":1}}],["默认修饰符",{"2":{"1425":1}}],["默认远程",{"2":{"1324":1}}],["默认分支是",{"2":{"1322":1}}],["默认",{"2":{"1315":1}}],["默认为并行执行",{"2":{"1310":1}}],["默认参数",{"2":{"1230":1}}],["默认占系统内存的",{"2":{"1201":1}}],["默认大小",{"2":{"1198":1}}],["默认使用",{"2":{"1198":1}}],["默认地将主要成分分析作为学习过程中的一部分",{"2":{"1162":1}}],["默认值是none",{"2":{"974":2}}],["默认值",{"2":{"796":2,"1484":1}}],["默认初始化",{"0":{"246":1}}],["默认情况下max",{"2":{"1090":1}}],["默认情况下为",{"2":{"206":1}}],["默认情况下",{"2":{"136":1,"142":1,"147":1,"278":2,"434":4,"445":3,"446":1,"447":1,"452":1,"592":2,"593":3,"631":1,"790":2,"818":1,"995":1}}],["乘积",{"2":{"1090":1}}],["乘以向量",{"2":{"1145":1}}],["乘以后面的微分项",{"2":{"1110":1}}],["乘以某个别的向量δ",{"2":{"1093":1}}],["乘以a",{"2":{"1090":1}}],["乘以",{"2":{"1090":1,"1093":1}}],["乘以100个矩阵后",{"2":{"243":4}}],["乘",{"2":{"1088":1}}],["乘矩阵和向量",{"2":{"1070":1}}],["乘法法则",{"2":{"981":1}}],["乘法和加法",{"2":{"124":1}}],["乘法和加法作为单独的操作",{"2":{"77":4}}],["乘法",{"2":{"78":1,"989":1,"1218":1}}],["神经核",{"2":{"1099":1}}],["神经系统科学家做了下面这个有趣的实验",{"2":{"1098":1}}],["神经元利用微弱的电流进行沟通",{"2":{"1099":1}}],["神经元和大脑",{"0":{"1098":1},"2":{"1193":1}}],["神经元要么完全激活要么完全不激活",{"2":{"242":1}}],["神经生物学家沃伦",{"2":{"619":1}}],["神经机器翻译",{"2":{"564":1}}],["神经网络还不流行",{"2":{"1148":1}}],["神经网络训练起来可能会特别慢",{"2":{"1148":1}}],["神经网络使用于什么时候呢",{"2":{"1148":1}}],["神经网络在以上三种情况下都可能会有较好的表现",{"2":{"1148":1}}],["神经网络算法的输出结果为四种可能情形之一",{"2":{"1103":1}}],["神经网络中",{"2":{"1101":1}}],["神经网络能够通过学习得出其自身的一系列特征",{"2":{"1101":1}}],["神经网络类似",{"2":{"1100":1}}],["神经网络模型是许多逻辑单元按照不同层级组织起来的网络",{"2":{"1099":1}}],["神经网络模型建立在很多神经元之上",{"2":{"1099":1}}],["神经网络模型可以指定设备",{"2":{"451":1}}],["神经网络是大量神经元相互链接并通过电脉冲来交流的一个网络",{"2":{"1099":1}}],["神经网络是计算量有些偏大的算法",{"2":{"1098":1}}],["神经网络是一种很古老的算法",{"2":{"1098":1}}],["神经网络又东山再起了",{"2":{"1098":1}}],["神经网络逐渐兴起于二十世纪八九十年代",{"2":{"1098":1}}],["神经网络可能会比svm慢",{"2":{"1148":1}}],["神经网络可能为我们打开一扇进入遥远的人工智能梦的窗户",{"2":{"1098":1}}],["神经网络可能推断",{"2":{"169":1}}],["神经网络可以在",{"2":{"829":2}}],["神经网络图",{"0":{"618":1}}],["神经网络架构的设计也逐渐变得更加抽象",{"2":{"506":1}}],["神经网络往往被其他机器学习方法超越",{"2":{"454":1}}],["神经网络与gpu",{"0":{"451":1}}],["神经网络将这个固定层的输出通过一个全连接层",{"2":{"425":1}}],["神经网络研究人员已经从考虑单个人工神经元的行为转变为从层的角度构思网络",{"2":{"421":1}}],["神经网络的方差和偏差",{"2":{"1135":1}}],["神经网络的学习",{"0":{"1119":1},"1":{"1120":1,"1121":1,"1122":1,"1123":1,"1124":1,"1125":1,"1126":1,"1127":1},"2":{"1193":1}}],["神经网络的研究从1995年左右开始停滞不前",{"2":{"299":1}}],["神经网络的前面几层应该只探索输入图像中的局部区域",{"2":{"152":1}}],["神经网络的前面几层应该对相同的图像区域具有相似的反应",{"2":{"152":1}}],["神经网络",{"0":{"1096":1},"1":{"1097":1,"1098":1,"1099":1,"1100":1,"1101":1,"1102":1,"1103":1},"2":{"299":1,"1148":1,"1176":1,"1193":1}}],["神经网络设计中的另一个问题是其参数化所固有的对称性",{"2":{"244":1}}],["神经网络有点像c语言",{"2":{"233":1}}],["神经网络过拟合与每一层都依赖于前一层激活值相关",{"2":{"170":1}}],["神经网络并不局限于单独查看每个特征",{"2":{"169":1}}],["破坏了模型的稳定收敛",{"2":{"241":1}}],["⏟ρt−2",{"2":{"519":1}}],["⏟ρt−1",{"2":{"519":1}}],["⏟π3",{"2":{"519":1}}],["⏟π2",{"2":{"519":1}}],["⏟v",{"2":{"241":1}}],["⏟m",{"2":{"241":2}}],["∘f1",{"2":{"241":1}}],["糟糕的预测性能甚至会加倍放大事态的严重性",{"2":{"284":1}}],["糟糕选择可能会导致我们在训练时遇到梯度爆炸或梯度消失",{"2":{"240":1}}],["糟糕程度",{"2":{"190":1}}],["数值介于0和1之间",{"2":{"1088":1}}],["数值结果接近2",{"2":{"981":1}}],["数值稳定性和模型初始化",{"0":{"240":1},"1":{"241":1,"242":1,"243":1,"244":1,"245":1,"246":1,"247":1,"248":1,"249":1,"250":1}}],["数组方法中的类型推断",{"2":{"1402":1}}],["数组类型",{"2":{"1405":1}}],["数组类型推断",{"2":{"1401":1}}],["数组类型声明",{"2":{"1398":1}}],["数组的其余四个元素是边界框左上角和右下角的",{"2":{"932":1}}],["数组中的第一个元素是边界框中对象的类别",{"2":{"932":1}}],["数学背后的大边界分类",{"2":{"1193":1}}],["数学上不管你是否包含",{"2":{"1145":1}}],["数学上来讲",{"2":{"1144":1}}],["数学并不能解决你关心的实际的问题",{"2":{"1058":1}}],["数学表示法使用∑符号表示求和",{"2":{"995":1}}],["数学表示法使用a∈rm×n",{"2":{"992":1}}],["数学符号⊙",{"2":{"994":1}}],["数学原理和实践者的智慧",{"2":{"980":1}}],["数学和算法与",{"2":{"825":1}}],["数学家对估计",{"2":{"299":1}}],["数字字面量类型",{"2":{"1414":1}}],["数字枚举",{"2":{"1413":1}}],["数字分别是20",{"2":{"812":1}}],["数字助理的一个关键要素是准确识别语音的能力",{"2":{"301":1}}],["数据和实验说话",{"2":{"1544":1}}],["数据仪表盘",{"2":{"1529":1}}],["数据在组件的自身",{"2":{"1508":1}}],["数据在主内存中创建",{"2":{"452":1}}],["数据中的某个属性",{"2":{"1465":2}}],["数据卷与网络",{"0":{"1345":1}}],["数据科学",{"2":{"1294":1}}],["数据科学在道德上存疑的使用",{"2":{"299":1}}],["数据存储抽象",{"2":{"1386":1}}],["数据存储与读取",{"2":{"1204":1}}],["数据存在一个自然的方向",{"2":{"349":1}}],["数据先进入内存缓存",{"2":{"1198":1}}],["数据页",{"2":{"1198":1}}],["数据页结构与",{"0":{"1198":1}}],["数据不总是可以直接获得的",{"2":{"1173":1}}],["数据可视化",{"0":{"1157":1},"2":{"1193":1}}],["数据可能与不同层的堆叠有关",{"2":{"526":1}}],["数据压缩不仅允许我们压缩数据",{"2":{"1156":1}}],["数据压缩",{"0":{"1156":1},"2":{"1193":1}}],["数据点为",{"2":{"1092":1}}],["数据还是有些少",{"2":{"1086":1}}],["数据分析与可视化",{"2":{"1303":1}}],["数据分析",{"2":{"1051":1,"1053":1,"1297":1}}],["数据分发",{"0":{"836":1},"2":{"836":1}}],["数据库",{"2":{"1347":1}}],["数据库数据",{"2":{"1297":1}}],["数据库之一",{"2":{"1194":1}}],["数据库挖掘",{"2":{"1058":1}}],["数据库等",{"2":{"1052":1}}],["数据库等外部工具",{"2":{"1050":1}}],["数据库和服务",{"2":{"1042":1}}],["数据操作",{"0":{"1016":1},"1":{"1017":1,"1018":1,"1019":1,"1020":1,"1021":1,"1022":1,"1023":1,"1024":1}}],["数据样本",{"2":{"992":1}}],["数据增广",{"2":{"872":1}}],["数据需要跨多个gpu拆分",{"2":{"838":1}}],["数据同步",{"0":{"835":1}}],["数据并行训练",{"0":{"841":1}}],["数据并行训练本身是不复杂的",{"2":{"838":1}}],["数据并行性",{"0":{"833":1}}],["数据并行是最方便的",{"2":{"832":1}}],["数据量可能会超出gpu总线的带宽",{"2":{"832":1}}],["数据混叠现象会导致严重的性能退化",{"2":{"814":1}}],["数据传输要争取量大次少而不是量少次多",{"2":{"814":1}}],["数据的原始格式将被转换为可以在训练期间迭代的小批量",{"2":{"771":1}}],["数据之前",{"2":{"611":1}}],["数据处理",{"2":{"587":1}}],["数据迭代器的性能非常重要",{"2":{"586":1}}],["数据迭代器是获得更高性能的关键组件",{"2":{"585":1}}],["数据加载器每次都会",{"2":{"583":1}}],["数据数据集",{"2":{"566":1}}],["数据挖掘和优化的思想",{"2":{"303":1}}],["数据规模",{"2":{"300":1}}],["数据",{"0":{"284":1,"456":1},"2":{"297":1,"901":1,"1448":1,"1451":2,"1454":1,"1456":1,"1457":1,"1459":1,"1462":4,"1463":4,"1464":4,"1465":1,"1466":1,"1467":1,"1468":1,"1470":1,"1497":1,"1503":1}}],["数据上好得多",{"2":{"258":1}}],["数据预处理的方式通常会对最终结果产生巨大影响",{"2":{"467":1}}],["数据预处理",{"0":{"209":1,"1010":1},"1":{"1011":1,"1012":1,"1013":1,"1014":1,"1015":1}}],["数据集s共有n个元素",{"2":{"1154":1}}],["数据集包含俄勒冈州波特兰市的住房价格",{"2":{"1063":1}}],["数据集的tar文件大约为2gb",{"2":{"945":1}}],["数据集的由小变大为现代深度学习的成功奠定基础",{"2":{"284":1}}],["数据集和模型通常都很大",{"2":{"824":1}}],["数据集上预训练bert",{"2":{"726":1}}],["数据集由灰度图像组成",{"2":{"582":1}}],["数据集来训练这个机器翻译模型",{"2":{"572":1}}],["数据集中有47行",{"2":{"1089":1}}],["数据集中可能存在标签噪声",{"2":{"646":1}}],["数据集中所有样本的损失均值",{"2":{"613":1}}],["数据集中的每个词wi将有概率地被丢弃",{"2":{"773":1}}],["数据集中的每个词现在被子词",{"2":{"757":1}}],["数据集中的每一行都是制表符分隔的文本序列对",{"2":{"565":1}}],["数据集中的第一个小批量数据",{"2":{"569":1}}],["数据集中",{"2":{"566":1}}],["数据集中是拥有标注的照片",{"2":{"151":1}}],["数据集",{"0":{"666":1},"1":{"667":1,"668":1,"669":1},"2":{"386":1,"565":3,"774":1}}],["数据集vs计算机内存和计算能力",{"2":{"300":1}}],["数据集相对较小",{"2":{"299":1}}],["数据集可能由动物图像组成",{"2":{"291":1}}],["数据集大小",{"0":{"260":1}}],["数据集要大得多",{"2":{"205":1}}],["数据集增加到原始大小的两倍",{"2":{"83":1}}],["数据已作预处理",{"2":{"79":1}}],["数据高效",{"2":{"76":1}}],["阈值单元在其输入低于某个阈值时取值0",{"2":{"236":1}}],["被子组件自己",{"2":{"1501":1}}],["被监视的数据",{"2":{"1463":1}}],["被访问的磁盘数量",{"2":{"1178":1}}],["被称作",{"2":{"1141":1}}],["被称为神经重接实验",{"2":{"1098":1}}],["被称为停用词",{"2":{"318":1}}],["被称为",{"2":{"299":1,"1297":1,"1302":1}}],["被称为离线学习",{"2":{"297":1}}],["被称为活性值",{"2":{"232":1}}],["被发明出来",{"2":{"980":1}}],["被新计算的梯度覆盖",{"2":{"974":2}}],["被移除的一些框实际上是有用的",{"2":{"856":1}}],["被混合执行时就不再使用python解释器",{"2":{"821":1}}],["被丢弃的概率就越大",{"2":{"773":1}}],["被设置为4",{"2":{"762":1}}],["被附加到每个词的尾部",{"2":{"757":1}}],["被连结起来作为文本序列的表示",{"2":{"713":1}}],["被抵消了",{"2":{"624":1}}],["被送入解码器",{"2":{"576":1}}],["被定义为",{"2":{"156":1}}],["⋅x",{"2":{"1069":2,"1145":1}}],["⋅σ",{"2":{"709":2}}],["⋅un",{"2":{"709":1}}],["⋅p",{"2":{"519":1,"783":3}}],["⋅m",{"2":{"241":1}}],["⋅∂h",{"2":{"241":1}}],["⋅",{"2":{"232":1,"241":1,"519":2,"624":1,"675":2,"1145":6,"1154":2}}],["⋅0",{"2":{"46":1}}],["σ−1",{"2":{"1184":1}}],["σ=1m∑i=1m",{"2":{"1184":1,"1185":1}}],["σ=2nin+nout",{"2":{"247":1}}],["σj2",{"2":{"1180":1,"1184":1}}],["σj2=1m∑i=1m",{"2":{"1180":1}}],["σxσy=∑i=1n",{"2":{"1154":1}}],["σxσy=e",{"2":{"1154":1}}],["σx",{"2":{"966":1}}],["σx=σy=0",{"2":{"852":1}}],["σw=σh=0",{"2":{"852":1}}],["σ12σ",{"2":{"597":1}}],["σ^b2=1|b|∑x∈b",{"2":{"467":1}}],["σ^b是小批量b的样本标准差",{"2":{"467":1}}],["σ",{"2":{"232":2,"708":1,"1146":1,"1147":3,"1159":1,"1180":1,"1185":9}}],["σ2|x|−0",{"2":{"966":1}}],["σ2=2nin+nout",{"2":{"247":1}}],["σ2=1m∑i=1m",{"2":{"1179":1}}],["σ2=1",{"2":{"247":1}}],["σ2+μ2",{"2":{"209":1}}],["σ2",{"2":{"170":1,"616":1,"966":1,"1146":1,"1159":1,"1179":2,"1180":1}}],["温度越高风险就越低",{"2":{"230":1}}],["温度越高风险越大",{"2":{"230":1}}],["接收props",{"2":{"1500":2}}],["接收参数",{"2":{"1481":1,"1482":1}}],["接收+限制类型+指定默认值+限制必要性",{"2":{"1469":1}}],["接收+限制类型",{"2":{"1469":1}}],["接收数据的组件中",{"2":{"1499":1}}],["接收数据",{"2":{"1047":1}}],["接近3百万个",{"2":{"1097":1}}],["接近均匀概率分布1",{"2":{"316":1}}],["接口继承",{"0":{"1423":1}}],["接口定义了对象的结构",{"2":{"1418":1}}],["接口",{"0":{"1418":1},"1":{"1419":1,"1420":1,"1421":1,"1422":1,"1423":1},"2":{"1040":1,"1042":1}}],["接步幅为2的3×3的最大汇聚层",{"2":{"502":1}}],["接",{"2":{"448":1}}],["接着我要写一个",{"2":{"1092":1}}],["接着我们手动选择数据",{"2":{"1174":1}}],["接着我们以宽高比作为过滤条件",{"2":{"1172":1}}],["接着我们",{"2":{"423":1}}],["接着在resnet加入所有残差块",{"2":{"502":1}}],["接着",{"2":{"282":1,"1112":1}}],["接着使用高级api实现了算法",{"2":{"228":1}}],["接受时间考验奖",{"2":{"475":1}}],["接受一组输入",{"2":{"422":1}}],["接受一些输入",{"2":{"422":1}}],["接受一张图像",{"2":{"281":1}}],["接受自然文本表示的问题",{"2":{"281":1}}],["接受地理信息",{"2":{"281":1}}],["接下来应该怎么办",{"2":{"1129":1}}],["接下来我度量这条红线的长度",{"2":{"1145":1}}],["接下来我将演示的这段视频是我从",{"2":{"1127":1}}],["接下来我们再来讲讲操作数据的方法",{"2":{"1089":1}}],["接下来我们会引入一些术语我们现在要做的便是为我们的模型选择合适的参数",{"2":{"1064":1}}],["接下来我们实现一个",{"2":{"635":1}}],["接下来我们",{"2":{"332":1,"626":1,"828":1}}],["接下来学习了更高级的优化算法",{"2":{"1117":1}}],["接下来再介绍一个or函数",{"2":{"1101":1}}],["接下来这个神经元接收这条消息",{"2":{"1099":1}}],["接下来是向量化的代码实现",{"2":{"1093":1}}],["接下来就是弄清楚如何最大限度地最小化代价函数j",{"2":{"1110":1}}],["接下来就是y1是被平方后的结果",{"2":{"1092":1}}],["接下来就需要一种算法",{"2":{"287":1}}],["接下来一个操作",{"2":{"1089":1}}],["接下来对j",{"2":{"1086":1}}],["接下来部分将使用交并比来衡量锚框和真实边界框之间",{"2":{"849":1}}],["接下来的课程中",{"2":{"1117":1}}],["接下来的每个多尺度特征块将上一层提供的特征图的高和宽缩小",{"2":{"953":1}}],["接下来的几节将介绍几种用于目标检测的深度学习方法",{"2":{"857":1}}],["接下来的两个语句f",{"2":{"816":1}}],["接下来的内容",{"0":{"1070":1},"2":{"1193":1}}],["接下来的内容中将重点关注适合深度学习的互连方式",{"2":{"812":1}}],["接下来的内容将简要描述强化学习问题",{"2":{"297":1}}],["接下来将简要地回顾一下部分基本线性代数内容",{"2":{"988":1}}],["接下来将详细地介绍各个组件",{"2":{"801":1}}],["接下来将实现transformer模型的剩余部分",{"2":{"404":1}}],["接下来看看这在实践中是如何运作的",{"2":{"791":1,"828":1}}],["接下来看看另一个简单例子",{"2":{"790":1}}],["接下来让我们将数据通过网络",{"2":{"418":1}}],["接下来描述的是基于正弦函数和余弦函数的固定位置编码",{"2":{"398":1}}],["接下来比较下面几个架构",{"2":{"397":1}}],["接下来会经常引用前面提到的概念",{"2":{"288":1}}],["接下来",{"2":{"54":1,"57":1,"70":1,"108":1,"115":1,"126":1,"128":1,"129":1,"142":1,"164":2,"176":1,"209":1,"213":1,"312":1,"316":1,"326":1,"331":1,"339":1,"340":1,"341":1,"350":1,"375":2,"388":1,"392":1,"409":1,"414":3,"417":1,"422":1,"442":1,"445":2,"467":1,"482":1,"508":1,"521":1,"541":1,"558":1,"602":1,"604":1,"616":1,"633":1,"640":1,"645":1,"676":1,"692":1,"735":1,"774":1,"811":1,"827":1,"851":1,"853":1,"862":2,"879":2,"882":2,"883":1,"890":1,"892":1,"893":1,"913":1,"917":1,"937":1,"945":1,"970":1,"974":1,"1088":1}}],["接下来来看一下交集",{"2":{"40":1}}],["哪里怪",{"2":{"1490":1}}],["哪里可能出错",{"2":{"621":1}}],["哪部分管道的接下去做",{"0":{"1174":1}}],["哪怕是周围词语中的一个词",{"2":{"1141":1}}],["哪个和方差有关",{"2":{"1132":1}}],["哪个和偏差有关",{"2":{"1132":1}}],["哪个效果最好",{"2":{"227":1}}],["哪种布局会输",{"2":{"1059":1}}],["哪种类型的神经网络架构更适合处理一词多义",{"2":{"525":1}}],["哪一个",{"2":{"291":1,"639":1}}],["哪些方法可能有助于改进学习算法的效果",{"2":{"1135":1}}],["哪些行为是需要惩罚的",{"2":{"298":1}}],["哪些没有起作用",{"2":{"207":1}}],["哪些人群可能无效",{"2":{"201":1}}],["确实在学校里接受这样的培训",{"2":{"1098":1}}],["确实是可以计算出正确的代价函数的",{"2":{"1092":1}}],["确实有用",{"2":{"442":1}}],["确认模型参数存储在同一个gpu上",{"2":{"451":1}}],["确保某个",{"2":{"1382":1}}],["确保",{"2":{"1315":1,"1443":1}}],["确保环境干净可控",{"2":{"1312":1}}],["确保每个隐藏层的单元个数相同",{"2":{"1126":1}}],["确保你明白了定义中的每一步",{"2":{"1092":1}}],["确保你对内容有所理解",{"2":{"1059":1}}],["确保多台机器只在没有不合理延迟的情况下工作是相当困难的",{"2":{"843":1}}],["确保充分了解加速器的特定功能",{"2":{"814":1}}],["确保结果的和为1",{"2":{"631":1}}],["确保至少安装了一个nvidia",{"2":{"445":1}}],["确保它们实际上是同一个对象",{"2":{"437":2}}],["确保预测仅依赖于已生成的输出词元",{"2":{"404":1}}],["确保梯度的长度以θ为界限",{"2":{"50":1}}],["确定新样本是否是异常",{"2":{"1180":1}}],["确定每一个字符是什么",{"2":{"1171":1}}],["确定参数beta和gamma",{"2":{"477":1}}],["确定下一轮对话",{"2":{"295":1}}],["确定",{"2":{"295":1,"341":1}}],["确定图中的蘑菇不是死帽蕈",{"2":{"291":1}}],["确定图像描绘的是一只猫",{"2":{"291":1}}],["确定输入",{"2":{"282":1}}],["确定此超参数的最佳值",{"2":{"223":1}}],["手艺活",{"2":{"1539":1}}],["手",{"2":{"1154":1}}],["手写识别",{"2":{"1058":1}}],["手写数字可能有10类",{"2":{"291":1}}],["手动",{"2":{"1309":1}}],["手动收集",{"2":{"1173":1}}],["手动调度由此产生的并行程序将是相当痛苦的",{"2":{"797":1}}],["手动实现一个简单的多层感知机是很容易的",{"2":{"222":1}}],["手工提供100",{"2":{"1174":1}}],["手工进行更新是一件很痛苦的事情",{"2":{"973":1}}],["手工对特征数据集进行预处理",{"2":{"454":1}}],["手工设计一些卷积核",{"2":{"133":1}}],["手机的语音识别系统就被唤醒了",{"2":{"282":1}}],["忽略正则化直接训练",{"0":{"276":1}}],["忽略了如何做出这些选择的细节",{"2":{"240":1}}],["忽略像素之间的空间结构",{"2":{"217":1}}],["忽视对一个亚群体的幸福的可预见风险可能会导致我们执行劣质的护理水平",{"2":{"201":1}}],["权重矩阵的形状是",{"2":{"970":1}}],["权重矩阵whq∈r2h×q",{"2":{"521":1}}],["权重",{"2":{"835":1}}],["权重为w∈rd×q",{"2":{"644":1}}],["权重将构成一个784×10的矩阵",{"2":{"630":1}}],["权重决定了每个特征对我们预测值的影响",{"2":{"610":1}}],["权重whq∈rh×q和偏置bq∈r1×q都是输出层的模型参数",{"2":{"527":1}}],["权重wxh",{"2":{"521":1,"527":1}}],["权重wij都是从同一分布中独立抽取的",{"2":{"247":1}}],["权重参数和偏置参数分别为w和b",{"2":{"469":1}}],["权重衰减功能在深度学习框架的优化器中提供",{"2":{"279":1}}],["权重衰减为我们提供了一种连续的机制来调整函数的复杂度",{"2":{"270":1}}],["权重衰减是最广泛使用的正则化的技术之一",{"2":{"270":1}}],["权重衰减",{"0":{"269":1},"1":{"270":1,"271":1,"272":1,"273":1,"274":1,"275":1,"276":1,"277":1,"278":1,"279":1,"280":1},"2":{"270":1}}],["权重衰减和dropout",{"2":{"215":1}}],["权重总和标准化为1且观测值的半衰期为γ−1",{"2":{"107":1}}],["把对的事情做出来",{"2":{"1549":1}}],["把对象中的每一组key",{"2":{"1483":1}}],["把事情做对",{"2":{"1549":1}}],["把抽象落地",{"2":{"1549":1}}],["把想法写出来",{"2":{"1545":1}}],["把踩过的坑",{"2":{"1545":1}}],["把大模型塞进真实场景",{"2":{"1543":1}}],["把点子变成可用产品",{"2":{"1542":1}}],["把$listeners所有的东西",{"2":{"1496":1}}],["把请求回来的字符串",{"2":{"1495":1}}],["把返回的对象中每一组key",{"2":{"1483":1}}],["把收到了每一组params参数",{"2":{"1483":1}}],["把setup函数中使用的composition",{"2":{"1471":1}}],["把sin和cos写成微分方程",{"2":{"353":1}}],["把多台",{"2":{"1348":1}}],["把暂存区内容存进本地仓库",{"2":{"1319":1}}],["把watch",{"2":{"1137":1}}],["把x",{"2":{"1099":1}}],["把耳朵到听觉皮层的神经切断",{"2":{"1098":1}}],["把",{"2":{"1093":1,"1496":1,"1544":1,"1547":1}}],["把他们用100覆盖掉",{"2":{"1092":1}}],["把个体聚类到不同的类或不同类型的组",{"2":{"1061":1}}],["把所有计算记录在磁带上",{"2":{"974":1}}],["把代码放到autograd",{"2":{"974":1}}],["把两个最好的结合起来",{"0":{"733":1}}],["把它们定为0",{"2":{"1060":1}}],["把它们端对端地叠起来形成一个更大的张量",{"2":{"1018":1}}],["把它们加在一起",{"2":{"699":1}}],["把它们看作长度为784的向量",{"2":{"630":1}}],["把一只狮子狗误认为雪纳瑞可能不会太糟糕",{"2":{"291":1}}],["把最后一层看作线性预测器",{"2":{"231":1}}],["把预测提交给kaggle",{"2":{"215":1}}],["把剩下的丢弃",{"2":{"172":1}}],["访问修饰符",{"0":{"1425":1}}],["访问",{"2":{"1384":1}}],["访问过的页面",{"2":{"1178":1}}],["访问数据的程序",{"2":{"1042":1}}],["访问第1行和第2行",{"2":{"1020":1}}],["访问张量的长度",{"2":{"991":1}}],["访问以",{"2":{"848":1}}],["访问稀疏数据和处理中断这两个目标是一个积极研究的领域",{"2":{"811":1}}],["访问各个层的参数",{"2":{"439":1}}],["访问参数",{"2":{"429":1}}],["访问房价预测竞赛页面",{"2":{"213":1}}],["访问和读取数据集",{"0":{"208":1}}],["步长和填充",{"2":{"826":4}}],["步数或词元序列长度",{"2":{"369":1}}],["步的预测",{"2":{"351":3}}],["步骤",{"0":{"870":1,"1311":1}}],["步骤确定前提中的",{"2":{"675":1}}],["步骤2的输入被扰动了ϵ1",{"2":{"351":1}}],["步骤非常简单",{"2":{"213":1}}],["步行到市中心的时间",{"2":{"295":1}}],["步行距离",{"2":{"290":1}}],["步",{"2":{"282":1}}],["步和第",{"2":{"282":1}}],["步幅被指定为中间结果",{"2":{"969":1}}],["步幅和多通道",{"0":{"969":1}}],["步幅大于1的计算优势是什么",{"2":{"144":1}}],["步幅可以减小输出的高和宽",{"2":{"143":1}}],["步幅",{"0":{"142":1}}],["步幅则可以在这类情况下提供帮助",{"2":{"140":1}}],["步幅2说明什么",{"2":{"144":1}}],["步幅2",{"2":{"136":1}}],["步幅为2的7×7卷积层后",{"2":{"502":1}}],["步幅为2的最大汇聚层",{"2":{"459":1}}],["步幅为2",{"2":{"495":1,"507":1}}],["步幅为4",{"2":{"461":4}}],["步幅为1",{"2":{"142":1}}],["步幅为",{"2":{"124":1,"150":1}}],["既读取又修改",{"2":{"1460":1}}],["既允许用户使用纯命令式编程进行开发和调试",{"2":{"818":1}}],["既然每张特征图上都有hw个不同的空间位置",{"2":{"913":1}}],["既然我们把肿瘤的尺寸看做区分恶性或良性的特征",{"2":{"1060":1}}],["既然我们已经生成了多尺度的锚框",{"2":{"913":1}}],["既然我们知道应该选择什么样的超参数",{"2":{"213":1}}],["既然候选记忆元通过使用tanh函数来确保值范围在",{"2":{"563":1}}],["既相对易于计算又高效",{"2":{"26":1}}],["折验证",{"2":{"212":1}}],["折",{"2":{"211":1}}],["返回值",{"2":{"1455":1,"1456":1}}],["返回值等指定类型",{"2":{"1397":1}}],["返回一个对象",{"2":{"1451":1}}],["返回一个可迭代对象",{"2":{"1246":1}}],["返回一个由词元列表组成的列表",{"2":{"362":1}}],["返回对象的数据类型",{"2":{"1232":1}}],["返回布尔值",{"0":{"1219":1}}],["返回1和0表示真与假",{"2":{"1090":1}}],["返回5",{"2":{"1089":1}}],["返回4",{"2":{"1089":1}}],["返回结果的形状是",{"2":{"854":1}}],["返回的对象不再是响应式的",{"2":{"1518":1}}],["返回的对象赋给net变量",{"2":{"422":1}}],["返回的是每一列的最大值",{"2":{"1090":1}}],["返回的是1",{"2":{"1089":1}}],["返回的第一个元素包含了为每个锚框标记的四个偏移值",{"2":{"853":1}}],["返回的第二个元素是掩码",{"2":{"853":1}}],["返回的结果中有三个元素",{"2":{"853":1}}],["返回的锚框变量y的形状",{"2":{"848":1}}],["返回带有负采样的跳元模型的小批量样本",{"2":{"776":1}}],["返回负采样中的噪声词",{"2":{"775":1}}],["返回跳元模型中的中心词和上下文词",{"2":{"774":1}}],["返回形状为",{"2":{"763":1}}],["返回上一个隐藏层在不同时间步的隐状态",{"2":{"713":3}}],["返回数据迭代器和imdb评论数据集的词表",{"2":{"695":3}}],["返回概率最大的分类标签总是最优解吗",{"2":{"638":1}}],["返回训练损失和训练精度",{"2":{"635":3}}],["返回训练和验证误差的平均值",{"2":{"211":1}}],["返回累计时间",{"2":{"615":1}}],["返回时间总和",{"2":{"615":1}}],["返回时光机器数据集的词元索引列表和词表",{"2":{"364":1}}],["返回时光机器数据集的迭代器和词表",{"2":{"321":1}}],["返回平均时间",{"2":{"615":1}}],["返回fashion",{"2":{"582":1}}],["返回翻译数据集的迭代器和词表",{"2":{"569":1}}],["返回该单词在此上下文中的向量表示",{"2":{"525":1}}],["返回所有可用的gpu",{"2":{"446":4}}],["返回从pos位置开始的长度为num",{"2":{"320":1}}],["返回",{"2":{"293":1,"1090":1}}],["返回本地文件名",{"2":{"206":1}}],["开启replace模式",{"2":{"1484":1}}],["开启",{"2":{"1371":1}}],["开箱即用",{"2":{"1348":1}}],["开销大",{"2":{"1346":1}}],["开销小",{"2":{"1346":1}}],["开头的行都被视为注释",{"2":{"1314":1}}],["开头的句子的概率",{"2":{"316":1}}],["开空调",{"2":{"1299":1}}],["开始标而不是0",{"2":{"1112":1}}],["开始介绍分类问题",{"2":{"1106":1}}],["开始介绍这些算法是如何工作的",{"2":{"1061":1}}],["开始",{"2":{"1092":1}}],["开始时我们随机选择一个参数的组合",{"2":{"1067":1}}],["开始使用octave",{"2":{"1061":1}}],["开始的函数",{"2":{"1006":1}}],["开始和结束的函数",{"2":{"1006":1}}],["开始之前",{"2":{"208":1}}],["开创性的著作",{"2":{"299":1}}],["开发体验",{"2":{"1530":1}}],["开发体验优异",{"2":{"1527":1}}],["开发和评价一个异常检测系统",{"0":{"1181":1},"2":{"1193":1}}],["开发出无与伦比的产品和应用",{"2":{"1176":1}}],["开发复杂的算法",{"2":{"1137":1}}],["开发项目的时间是很宝贵的",{"2":{"1088":1}}],["开发",{"2":{"1054":1,"1297":1,"1325":1,"1374":1}}],["开发人员思考能否将这两种编程模型的优点结合起来",{"2":{"818":2}}],["开发人员在设计gluon时思考了这个问题",{"2":{"818":1}}],["开发人员可以从上述的业务逻辑出发",{"2":{"281":1}}],["开发人员可能提出如下一个解决方案",{"2":{"281":1}}],["开发人员必须细致地考虑应用程序所有可能遇到的边界情况",{"2":{"281":1}}],["开发人员会拥有一些数据且急于开发模型",{"2":{"179":1}}],["开发模式",{"0":{"15":1}}],["建议写成函数",{"2":{"1465":1}}],["建议写法与风格规范",{"0":{"1264":1}}],["建议用help命令",{"2":{"1088":1}}],["建议用户在延迟太高时",{"2":{"806":1}}],["建议先在纸上勾勒出新算法的性能",{"2":{"814":1}}],["建议使用nccl来实现gpu之间的高速数据传输",{"2":{"812":1}}],["建议以向前的方向遍历内存",{"2":{"810":1}}],["建议读者参考",{"2":{"800":1}}],["建议对每个小批量进行同步",{"2":{"793":1}}],["建议注意隐式的阻塞器",{"2":{"791":1}}],["建议的选择是",{"2":{"743":1}}],["建模时采用线性代数表示法会比较方便",{"2":{"610":1}}],["建立向量v并赋值1",{"2":{"1088":1}}],["建立",{"2":{"1048":1}}],["建立模型",{"2":{"473":1}}],["建立一个矩阵a",{"2":{"1088":1}}],["建立一个词表",{"2":{"360":1}}],["建立一个人脸检测器",{"2":{"188":1}}],["建立一个产品推荐系统",{"2":{"187":1}}],["建立一个垃圾邮件过滤器",{"2":{"187":1}}],["建筑年份由整数表示",{"2":{"208":1}}],["地址值",{"2":{"1463":1}}],["地标",{"2":{"1146":1}}],["地标的作用",{"2":{"1146":1}}],["地进行梯度聚合",{"2":{"841":1}}],["地震是时空相关的",{"2":{"345":1}}],["地震具有很强的相关性",{"2":{"345":1}}],["地理位置",{"2":{"296":1,"1199":1}}],["地去学习了",{"2":{"296":1}}],["地图应用程序在启动后筛选了若干条路线",{"2":{"282":1}}],["地下室状况等",{"2":{"208":1}}],["地学习",{"2":{"196":1}}],["屋顶类型由离散类别表示",{"2":{"208":1}}],["屋顶类型",{"2":{"208":1}}],["施工年份",{"2":{"208":1}}],["竞赛数据分为训练集和测试集",{"2":{"208":1}}],["选项应始终被声明为一个函数",{"2":{"1441":1}}],["选项卡",{"2":{"889":1,"901":1}}],["选项卡有下载数据的链接",{"2":{"208":1}}],["选项卡下可以找到数据集",{"2":{"207":1}}],["选出",{"2":{"1181":1}}],["选修",{"0":{"1145":1,"1184":1},"2":{"1193":4}}],["选取合适的那一个",{"2":{"1137":1}}],["选取代价函数值最小的模型",{"2":{"1131":1}}],["选择在哪个",{"2":{"1376":1}}],["选择一个感兴趣的方向做深入",{"2":{"1304":1}}],["选择一个预训练的卷积神经网络",{"2":{"937":1}}],["选择特征",{"0":{"1183":1},"2":{"1193":1}}],["选择主成分的数量",{"0":{"1160":1},"2":{"1193":1}}],["选择的时候思考我们运用k",{"2":{"1154":1}}],["选择的力量也就更强大",{"2":{"355":1}}],["选择聚类数目的方法时",{"2":{"1154":1}}],["选择聚类数",{"0":{"1154":1},"2":{"1193":1}}],["选择代价函数最小的结果",{"2":{"1153":1}}],["选择支持向量机的原因主要在于它的代价函数是凸函数",{"2":{"1148":1}}],["选择参数",{"2":{"1144":1}}],["选择得出交叉验证误差最小的模型",{"2":{"1133":1}}],["选择λ的方法为",{"2":{"1133":1}}],["选择出哪一个分类器是可信度最高效果最好的",{"2":{"1112":1}}],["选择这四个单选按钮中的一个",{"2":{"1059":1}}],["选择第二个和第三个元素",{"2":{"1020":1}}],["选择最后一个元素",{"2":{"1020":1}}],["选择每个卷积块的第一个卷积层作为风格层",{"2":{"920":1}}],["选择gpu",{"2":{"841":1}}],["选择15",{"2":{"721":1}}],["选择网络中的第一个图层",{"2":{"592":2}}],["选择缩放点积注意力作为每一个注意力头",{"2":{"382":1}}],["选择不同的初始参数组合",{"2":{"1067":1}}],["选择不同的内容和风格层",{"2":{"929":1}}],["选择不同的注意力评分函数会带来不同的注意力汇聚操作",{"2":{"371":1}}],["选择不同的注意力评分函数a会导致不同的注意力汇聚操作",{"2":{"367":1}}],["选择不同的优化算法和学习率调度",{"2":{"74":1}}],["选择有监督的学习算法",{"2":{"289":1}}],["选择要上传的预测文件",{"2":{"213":1}}],["选择奇数的好处是",{"2":{"141":1}}],["选择",{"2":{"58":1}}],["选择合适的学习率η",{"2":{"57":1}}],["选择它们的大小足以确保所有i的ci",{"2":{"48":1}}],["选择ρ=0",{"2":{"21":1}}],["促进协作和竞争",{"2":{"207":1}}],["你写几行代码",{"2":{"1535":1}}],["你今天有点怪",{"2":{"1490":1}}],["你好啊",{"2":{"1452":1}}],["你好",{"2":{"1233":1}}],["你是否能找到一部不同的电影",{"2":{"1191":1}}],["你所选择的特征",{"2":{"1187":1}}],["你所认为正确的选项",{"2":{"1059":1}}],["你最想改进的机器学习应用有哪些",{"2":{"1187":1}}],["你最终会得到类似粉线这样的决策界",{"2":{"1144":1}}],["你最终使用的代码表达方式可能会有些许不同",{"2":{"1093":1}}],["你测量了飞机引擎的一些特征变量",{"2":{"1178":1}}],["你们中好多人",{"2":{"1176":1}}],["你们的开发时间是最有价值的资源",{"2":{"1061":1}}],["你依然花了好多时间来做这些复习题",{"2":{"1176":1}}],["你依然挤出时间来观看这些课程视频",{"2":{"1176":1}}],["你既可以保证随机梯度下降法正在正常运转和收敛",{"2":{"1167":1}}],["你真正关心的可能是这条红线的方向",{"2":{"1156":1}}],["你从那些工程队得到的",{"2":{"1156":1}}],["你经常跟哪些人联系",{"2":{"1150":1}}],["你实际上所需要的一些东西",{"2":{"1148":1}}],["你实际并不需要编写代码来计算代价函数j",{"2":{"1111":1}}],["你事实上可以得到同样的结果",{"2":{"1145":1}}],["你完全可以跳过它",{"2":{"1145":1}}],["你完成了支持向量机中的部分内容",{"2":{"1143":1}}],["你完成家庭作业的时候",{"2":{"1094":1}}],["你知道的",{"2":{"1148":1,"1185":1}}],["你知道在这个最小化问题中",{"2":{"1143":1}}],["你知道",{"2":{"1143":2,"1156":1}}],["你知道什么是正态分布的随机变量",{"2":{"1088":1}}],["你知道什么是高斯随机变量",{"2":{"1088":1}}],["你不难发现此时逻辑回归的输出将趋近于1",{"2":{"1143":1}}],["你不需要自己来做",{"2":{"1111":1}}],["你不需要记住所有这些命令",{"2":{"1091":1}}],["你为学习算法所设计的特征量的选择",{"2":{"1143":1}}],["你都要手动地检测这些例子",{"2":{"1138":1}}],["你总是会去尝试很多新的想法",{"2":{"1138":1}}],["你很难知道你应该把时间花在什么地方来提高算法的表现",{"2":{"1138":1}}],["你并不能提前知道你是否需要复杂的特征变量",{"2":{"1138":1}}],["你更有可能选择一个真正的好方法",{"2":{"1137":1}}],["你该如何判断一个假设函数是过拟合的呢",{"2":{"1130":1}}],["你通过执行这种测试",{"2":{"1129":1}}],["你通常不需要手动选择学习率",{"2":{"1111":1}}],["你希望用它发现社交网络中关系密切的朋友",{"2":{"1150":1}}],["你希望从获取更多特征的角度来收集更多的数据",{"2":{"1129":1}}],["你希望不只用3种或5种特征",{"2":{"1060":1}}],["你应如何决定接下来应该选择哪条道路",{"2":{"1129":1}}],["你应该已经感觉到自己已经成为机器学习方面的专家了吧",{"2":{"1176":1}}],["你应该已经掌握了批量梯度算法",{"2":{"1069":1}}],["你应该是能够得到一个高效得多的线性回归算法",{"2":{"1093":1}}],["你应该知道有一种计算代价函数j最小值的数值解法",{"2":{"1069":1}}],["你应该计算公式右边的部分",{"2":{"1067":1}}],["你已经完全具备了应用这些机器学习工具来创造伟大成就的能力",{"2":{"1176":1}}],["你已经见过一系列不同的学习算法",{"2":{"1143":1}}],["你已经有了丰富的机器学习知识",{"2":{"1117":1}}],["你已经学会了在octave中如何加载或存储数据",{"2":{"1090":1}}],["你对机器学习的理解可能已经比许多工程师深入了",{"2":{"1117":1}}],["你现在也可以将逻辑回归分类器用在多类分类的问题上",{"2":{"1112":1}}],["你现在知道了基本的挑选分类器的方法",{"2":{"1112":1}}],["你现在正在理解我的话",{"2":{"1098":1}}],["你连一根线到舌头上安装的电极阵列上",{"2":{"1098":1}}],["你在前额上带一个灰度摄像头",{"2":{"1098":1}}],["你得写很多不同的软件来模拟所有这些五花八门的奇妙的事情",{"2":{"1098":1}}],["你需要进行qa",{"2":{"1178":1}}],["你需要做的是找出电影",{"2":{"1191":1}}],["你需要做的是找到一个θ​",{"2":{"1144":1}}],["你需要做的就是输入合适的代码来计算这里的这些东西",{"2":{"1111":1}}],["你需要做的就是提交一个5×5的矩阵",{"2":{"1094":1}}],["你需要同时更新θ0和θ1",{"2":{"1067":1}}],["你仍然能实现线性回归算法",{"2":{"1093":1}}],["你仍然可以通过后端观察异步吗",{"2":{"794":1}}],["你把x和θ看做向量",{"2":{"1093":1}}],["你把这些数据画出来",{"2":{"1060":1}}],["你看到和编辑的代码文件所在目录",{"2":{"1319":1}}],["你看到我所做的是使用逗号连接函数调用",{"2":{"1091":1}}],["你看一下周围",{"2":{"1067":1}}],["你键入figure",{"2":{"1091":1}}],["你输入print",{"2":{"1091":1}}],["你怎样把数据加载到",{"2":{"1089":1}}],["你同样可以用向量",{"2":{"1088":1}}],["你只需要编写代码来计算导数项",{"2":{"1111":1}}],["你只需要在c++",{"2":{"1093":1}}],["你只需要一行代码",{"2":{"1093":1}}],["你只需要进行大规模的资源配置",{"2":{"1088":1}}],["你只用再花时间用c++或java这些语言把算法重新实现就行了",{"2":{"1088":1}}],["你的带高维特征x和映射到这的低维表示z",{"2":{"1161":1}}],["你的特征变量的数量这是相当大的",{"2":{"1148":1}}],["你的学习算法会受异常点",{"2":{"1144":1}}],["你的想法是提高了算法表现",{"2":{"1138":1}}],["你的密码是否会显示出来取决于你使用的操作系统",{"2":{"1094":1}}],["你的这两个特征值将始终满足约束",{"2":{"1086":1}}],["你的代码是否包含启发式设计选择",{"2":{"304":1}}],["你也需要选择内核参数或你想要使用的相似函数",{"2":{"1148":1}}],["你也会同样地计算出内积",{"2":{"1145":1}}],["你也能像硅谷的大部分机器学习从业者一样",{"2":{"1135":1}}],["你也许能想到",{"2":{"1143":1}}],["你也许能想到的是尝试选用更少的特征集",{"2":{"1129":1}}],["你也许需要一些不同的文件夹",{"2":{"1112":1}}],["你也不可能记得住",{"2":{"1089":1}}],["你也知道1米等于3",{"2":{"1086":1}}],["你也可以把这些优化算法用于线性回归",{"2":{"1111":1}}],["你也可以写",{"2":{"1092":1}}],["你也可以求另一条对角线的和也是是369",{"2":{"1090":1}}],["你也可以输入1",{"2":{"1090":1}}],["你也可以对每一个元素",{"2":{"1090":1}}],["你也可以为它赋值",{"2":{"1089":1}}],["你也可以在",{"2":{"1092":1}}],["你也可以在运算中使用这些较为复杂的索引",{"2":{"1089":1}}],["你也可以在这门课里面使用",{"2":{"1088":1}}],["你也可以键入length",{"2":{"1089":1}}],["你也可以键入",{"2":{"1089":1}}],["你也可以做逻辑运算",{"2":{"1088":1}}],["你也可以用matlab",{"2":{"1061":1}}],["你也可能希望避免为不是模型参数的张量过度分配内存",{"2":{"1021":1}}],["你或许会知道",{"2":{"1086":1}}],["你或许每天都在不知不觉中使用了机器学习的算法每次",{"2":{"1058":1}}],["你移动的幅度会自动变得越来越小",{"2":{"1068":1}}],["你认为下一步梯度下降法会怎样工作",{"2":{"1068":1}}],["你环顾四周",{"2":{"1067":1}}],["你再看看周围",{"2":{"1067":1}}],["你才能明白我的话",{"2":{"1098":1}}],["你才能自动并更有效地销售或不同的细分市场一起进行销售",{"2":{"1061":1}}],["你才移植它到c++或java或别的语言",{"2":{"1061":1}}],["你几乎听不到你面前那人的声音",{"2":{"1061":1}}],["你参加过鸡尾酒宴吧",{"2":{"1061":1}}],["你就有了一个数据集",{"2":{"1178":1}}],["你就应该能将逻辑回归和线性回归应用于更大的问题中",{"2":{"1111":1}}],["你就应该知道如何实现一个完整的逻辑回归算法",{"2":{"1110":1}}],["你就能得到不错的结果",{"2":{"1111":1}}],["你就能让你的数据中心工作得更高效",{"2":{"1061":1}}],["你就直接实现这个算法",{"2":{"1093":1}}],["你就会明白可视化技术到底是什么",{"2":{"1127":1}}],["你就会得到这些不同的式子",{"2":{"1093":1}}],["你就会有一个简单得多",{"2":{"1093":1}}],["你就可以使用一个复杂的优化库",{"2":{"1111":1}}],["你就可以调用高级的优化函数",{"2":{"1111":1}}],["你就可以这样计算",{"2":{"1093":1}}],["你就可以快速地可视化你的数据",{"2":{"1090":1}}],["你就可以用octave来实现一些算法了",{"2":{"1061":1}}],["你就把它看成是矩阵",{"2":{"1090":1}}],["你就已经理解并应用了线性回归算法",{"2":{"290":1}}],["你就已经可以确定承包商的定价结构",{"2":{"290":1}}],["你要设置几个options",{"2":{"1111":1}}],["你要预测的变量",{"2":{"1106":1}}],["你要知道",{"2":{"1090":1}}],["你要做的就是运行一个像这样的octave",{"2":{"1111":1}}],["你要做的就是",{"2":{"1089":1}}],["你要告诉他们这房子能卖多少钱",{"2":{"1063":1}}],["你要学会使用这个原型工具",{"2":{"1061":1}}],["你要学会如何恰当地使用这些工具",{"2":{"1059":1}}],["你要分析多少特定基因已经表达",{"2":{"1061":1}}],["你要分析出它们是否有一个特定的基因",{"2":{"1061":1}}],["你要判断它们是否曾经被盗过",{"2":{"1060":1}}],["你有多熟练是否擅长做误差分析和排除学习算法",{"2":{"1148":1}}],["你有多少数据",{"2":{"1148":1}}],["你有一个新的飞机引擎从生产线上流出",{"2":{"1178":1}}],["你有一个含两个参数的问题",{"2":{"1111":1}}],["你有一大批同样的货物",{"2":{"1060":1}}],["你有两种方法可以实现",{"2":{"1098":1}}],["你有许多客户",{"2":{"1060":1}}],["你有上千件一模一样的货物等待出售",{"2":{"1060":1}}],["你想我了没",{"2":{"1490":1}}],["你想令第一项为0",{"2":{"1144":1}}],["你想开发学习算法来处理这两个问题",{"2":{"1060":1}}],["你想用无限多种特征",{"2":{"1060":1}}],["你电脑的内存肯定不够用",{"2":{"1060":1}}],["你能否找到与之相关的其它产品",{"2":{"1191":1}}],["你能否估算出肿瘤是恶性的或是良性的概率",{"2":{"1060":1}}],["你能做的是使用一个在线学习机制",{"2":{"1168":1}}],["你能做的就是运行一个聚类算法",{"2":{"1061":1}}],["你能够明白怎样选择一条最合适",{"2":{"1129":1}}],["你能够用它来非常迅速地实现这门课中我们已经学过的",{"2":{"1088":1}}],["你能理解",{"2":{"1122":1}}],["你能检索这些顾客数据集",{"2":{"1061":1}}],["你能从数据中找到某种结构吗",{"2":{"1061":1}}],["你能想到深度学习优化还涉及哪些其他挑战",{"2":{"105":1}}],["你拥有这些工具",{"2":{"1059":1}}],["你点击",{"2":{"1059":1}}],["你还是觉得反向传播依然很复杂",{"2":{"1122":1}}],["你还可以使用第三方库",{"2":{"1235":1}}],["你还可以通过设置你的",{"2":{"1092":1}}],["你还可以在哪里应用端到端的训练方法",{"2":{"304":1}}],["你还讲学习到关于机器学习的前沿状况",{"2":{"1058":1}}],["你用facebook或苹果的图片分类程序他能认出你朋友的照片",{"2":{"1058":1}}],["你打开谷歌",{"2":{"1058":1}}],["你将能够编写更加健壮和可维护的代码",{"2":{"1436":1}}],["你将能够了解到这方面的一个例子",{"2":{"1187":1}}],["你将这些数据绘制成图表",{"2":{"1178":1}}],["你将遇到的主要问题",{"2":{"1137":1}}],["你将逐渐发现还有更强大的非线性分类器",{"2":{"1117":1}}],["你将会得到一个正常的解",{"2":{"1086":1}}],["你将学习到这门技术的前沿",{"2":{"1058":1}}],["你将获得一手经验",{"2":{"205":1}}],["你会在这里看到",{"0":{"1546":1}}],["你会在3的时候达到一个肘点",{"2":{"1154":1}}],["你会注意到现在p",{"2":{"1145":1}}],["你会看到大公司会获取如此多的数据",{"2":{"1168":1}}],["你会看到左下角的这条曲线",{"2":{"1143":1}}],["你会看到网络的输出是一条灰色的区段",{"2":{"1127":1}}],["你会看到这个算法的概况",{"2":{"1063":1}}],["你会惊讶地发现",{"2":{"1110":1}}],["你会得到一个非常有趣的决策边界",{"2":{"1144":1}}],["你会得到一个性能很好的学习算法",{"2":{"1141":1}}],["你会得到一切你需要知道",{"2":{"1067":1}}],["你会得到这个等式",{"2":{"1110":1}}],["你会发现这种模式",{"2":{"1154":1}}],["你会发现每个样本",{"2":{"1143":1}}],["你会发现自己已经不知不觉地成为一个了解许多先进机器学习技术的专家了",{"2":{"1129":1}}],["你会发现",{"2":{"1068":1,"1089":1}}],["你会发现我的导数",{"2":{"1068":1}}],["你会发现最佳的下山方向",{"2":{"1067":1}}],["你会需要很多很多行的代码",{"2":{"1061":1}}],["你会更倾向于学习更多数学",{"2":{"1002":1}}],["你会希望清楚地区分技术和直觉",{"2":{"475":1}}],["你可能有一个特征",{"2":{"1156":1}}],["你可能注意到括号里面的这一项是向量θ的范数",{"2":{"1145":1}}],["你可能已经超越了很多人了",{"2":{"1137":1}}],["你可能回想起你之前在这里学到过",{"2":{"1089":1}}],["你可能会想尝试一些不同的库",{"2":{"1111":1}}],["你可能会开始担心操作效率的问题",{"2":{"426":1}}],["你可能会好奇为什么每个layer都有一个",{"2":{"424":1}}],["你可以仅用它构建简单的页面交互",{"2":{"1526":1}}],["你可以推荐给他",{"2":{"1191":1}}],["你可以有一个算法",{"2":{"1187":1}}],["你可以运行一个你自己的网站",{"2":{"1168":1}}],["你可以重新分配资源",{"2":{"1150":1}}],["你可以做比这困难得多需要逻辑回归的事情",{"2":{"1148":1}}],["你可以做的一件事就是构建一个模型",{"2":{"1063":1}}],["你可以连接许多你可能会用来编写学习算法的主要编程语言",{"2":{"1148":1}}],["你可以亲自实现这些想法",{"2":{"1147":1}}],["你可以看看这个数字",{"2":{"1138":1}}],["你可以看到一条水平的菜单栏显示的是驾驶操作人选择的方向",{"2":{"1127":1}}],["你可以看到在不同的方格",{"2":{"1091":1}}],["你可以发现某些系统性的规律",{"2":{"1138":1}}],["你可以通过它更快地实践你的新想法",{"2":{"1138":1}}],["你可以通过画出学习曲线来做出进一步的选择",{"2":{"1138":1}}],["你可以通过conda",{"2":{"445":1}}],["你可以画出学习曲线",{"2":{"1138":1}}],["你可以充分运用以上这些内容来判断哪些途径可能是有帮助的",{"2":{"1135":1}}],["你可以得到一个范围的不同分布一样",{"2":{"1185":1}}],["你可以得到一段更简单",{"2":{"1093":1}}],["你可以得到θ1和",{"2":{"1111":1}}],["你可以认为算法有一个智能的内部循环",{"2":{"1111":1}}],["你可以认为我们的假设就是估计",{"2":{"1110":1}}],["你可以专门学一门课来提高数值计算能力",{"2":{"1111":1}}],["你可以弹响指",{"2":{"1098":1}}],["你可以想象实现这三个方程的方式之一",{"2":{"1093":1}}],["你可以想像下",{"2":{"1061":1}}],["你可以把它应用到很多地方",{"2":{"1148":1}}],["你可以把这个问题扩展为一个很大的项目",{"2":{"1129":1}}],["你可以把这个方法当成一个生成矩阵的快速方法",{"2":{"1088":1}}],["你可以把下面这部分作为一个进阶知识",{"2":{"1092":1}}],["你可以键入exit命令然后回车就会退出",{"2":{"1092":1}}],["你可以键入help",{"2":{"1091":1}}],["你可以写出像右边这样的代码",{"2":{"1093":1}}],["你可以写",{"2":{"1092":1}}],["你可以改变轴的刻度",{"2":{"1091":1}}],["你可以输入max",{"2":{"1090":1}}],["你可以使用addpath",{"2":{"1092":1}}],["你可以使用",{"2":{"1089":1}}],["你可以使用这种基本的语法来将结果打印到屏幕",{"2":{"1088":1}}],["你可以设置集合w",{"2":{"1088":1}}],["你可以像下面这么做",{"2":{"1088":1}}],["你可以在命令后加一个分号",{"2":{"1088":1}}],["你可以用这种方式来避免一种电脑编程里的过早优化问题",{"2":{"1138":1}}],["你可以用这样的一个线性方程",{"2":{"1086":1}}],["你可以用octave中用help命令了解细节",{"2":{"1091":1}}],["你可以用它来最小化任何代价函数j",{"2":{"1068":1}}],["你可以很快地学会所有你需要了解的线性代数知识",{"2":{"1070":1}}],["你可以实现和使用更强大的线性回归模型",{"2":{"1070":1}}],["你可以实现这些算法",{"2":{"1061":1}}],["你可以当作无监督学习问题",{"2":{"1061":1}}],["你可以到这个url网址news",{"2":{"1061":1}}],["你可以将",{"2":{"1040":1,"1042":1}}],["你可以获得高于0",{"2":{"690":1}}],["你可以假设承包商收取一些基本费用",{"2":{"290":1}}],["你遇到的哪些问题有许多解决它们的样本",{"2":{"304":1}}],["你当前正在编写的代码的哪些部分可以",{"2":{"304":1}}],["你让人修理了排水管",{"2":{"290":1}}],["你比在20世纪90年代工作的任何人都有优势",{"2":{"237":1}}],["涵盖了2006",{"2":{"205":1}}],["影响也非常小",{"2":{"1143":1}}],["影响当前层的神经元",{"2":{"204":1}}],["影响摄像头的图像质量",{"2":{"193":1}}],["广泛应用于从个人项目到企业级应用的开发中",{"2":{"1526":1}}],["广泛用于生产环境",{"2":{"1355":1}}],["广播",{"2":{"968":1,"1023":1}}],["广播机制",{"0":{"1019":1},"2":{"1019":1}}],["广播机制在",{"2":{"610":1}}],["广播机制使l2",{"2":{"275":4}}],["广播context",{"2":{"574":4}}],["广义上说",{"2":{"790":3}}],["广义上adadelta被称为没有学习率",{"2":{"19":1}}],["广义的",{"2":{"300":1}}],["广告",{"2":{"300":1}}],["广告商呢",{"2":{"203":1}}],["失控反馈循环",{"2":{"201":1}}],["举例子",{"2":{"1191":1}}],["举例说明",{"2":{"699":1,"742":1,"1101":1}}],["举例说明什么时候可能需要隐变量自回归模型来捕捉数据的动力学模型",{"2":{"353":1}}],["举个具体的例子",{"2":{"1093":1}}],["举个例子",{"2":{"201":1,"291":1,"292":1,"660":1,"1060":1,"1296":1}}],["举一个例子",{"2":{"1011":1}}],["举一个极端的例子",{"2":{"651":1}}],["举一个具体的例子",{"2":{"289":1}}],["举一个有点荒谬却可能真实存在的例子",{"2":{"179":1}}],["举一个简单的例子",{"2":{"59":1,"77":1}}],["责任和透明度",{"0":{"201":1}}],["西洋双陆棋或星际争霸都是强化学习的应用实例",{"2":{"199":1}}],["西联汇款",{"2":{"169":1}}],["围棋由于其巨大的状态空间",{"2":{"301":1}}],["围棋",{"2":{"199":1}}],["强大的调试工具",{"2":{"1527":1}}],["强大的扩展性",{"2":{"1359":1}}],["强",{"2":{"1205":1}}],["强迫使得所有的数据都在同一个平面上",{"2":{"1156":1}}],["强制飞桨在返回之前完成所有计算",{"2":{"790":1}}],["强制pytorch在返回之前完成所有计算",{"2":{"790":1}}],["强制mxnet在返回之前完成所有后端计算",{"2":{"790":1}}],["强制教学方法将原始输出序列",{"2":{"579":1}}],["强制教学",{"2":{"576":4}}],["强调的是端到端的学习",{"2":{"564":1}}],["强调如何基于环境而行动",{"2":{"199":1}}],["强化期望行为和减少不良行为",{"2":{"299":1}}],["强化学习和推荐系统等各种术语",{"2":{"1059":1}}],["强化学习就会发挥最好的作用",{"2":{"300":1}}],["强化学习问题被称为马尔可夫决策过程",{"2":{"298":1}}],["强化学习智能体必须不断地做出选择",{"2":{"298":1}}],["强化学习智能体可能知道一个好的策略",{"2":{"298":1}}],["强化学习智能体选择的",{"2":{"298":1}}],["强化学习可能还必须处理部分可观测性问题",{"2":{"298":1}}],["强化学习者必须处理学分分配",{"2":{"298":1}}],["强化学习还可以解决许多监督学习无法解决的问题",{"2":{"298":1}}],["强化学习框架的通用性十分强大",{"2":{"298":1}}],["强化学习的目标是产生一个好的策略",{"2":{"298":1}}],["强化学习的过程在",{"2":{"298":1}}],["强化学习",{"0":{"199":1,"298":1},"2":{"199":1}}],["控制路由跳转时操作浏览器历史记录的模式",{"2":{"1484":1}}],["控制平面",{"0":{"1376":1},"2":{"1381":1}}],["控制失败策略",{"2":{"1313":1}}],["控制程序的执行流程",{"2":{"1222":1}}],["控制变化速率",{"2":{"1146":1}}],["控制语句",{"0":{"1092":1},"2":{"1193":1}}],["控制我们观测到的xt",{"2":{"519":1}}],["控制全连接层的模型复杂度",{"2":{"461":1}}],["控制流",{"2":{"425":4}}],["控制理论",{"2":{"198":1}}],["控制器算法是一个流行的选择",{"2":{"198":1}}],["控制",{"0":{"198":1}}],["⟶model",{"2":{"196":1}}],["⟶observation",{"2":{"196":1}}],["新建文件",{"2":{"1499":1}}],["新用户",{"2":{"1431":1}}],["新语法切换",{"2":{"1329":1}}],["新版本提交后替换旧版本",{"2":{"1200":1}}],["新产生的特征的意义就必须由我们自己去发现了",{"2":{"1157":1}}],["新产品推出后",{"2":{"193":1}}],["新房屋价格",{"2":{"614":1}}],["新模型和原模型将同样有效",{"2":{"500":1}}],["新添加的层如何提升神经网络的性能",{"2":{"499":1}}],["新的生命周期钩子",{"2":{"1441":1}}],["新的内置组件",{"2":{"1441":1}}],["新的特性",{"0":{"1441":1}}],["新的代价函数将会水平的从这里到右边",{"2":{"1143":1}}],["新的",{"2":{"1112":1}}],["新的导数会变小一点点",{"2":{"1068":1}}],["新的张量将存储在内存中",{"2":{"1017":3}}],["新的挑战出现在多台机器上进行分布式训练",{"2":{"843":1}}],["新的隐状态ht就会接近候选隐状态h~t",{"2":{"542":1}}],["新的候选状态h~t",{"2":{"542":1}}],["新的容量控制方法",{"2":{"300":1}}],["新的梯度替换不再指向特定实例下降最陡的方向",{"2":{"86":1}}],["新数据集",{"2":{"286":2}}],["新闻数据在news组件中",{"2":{"1508":1}}],["新闻001",{"2":{"1482":1}}],["新闻事件分类的例子",{"2":{"1061":1}}],["新闻文章",{"2":{"754":1}}],["新闻周期会使得正在讨论的话题产生时间依赖性",{"2":{"253":1}}],["新闻内容逐渐变化",{"2":{"193":1}}],["偏好类型安全",{"2":{"1544":1}}],["偏差和方差的问题",{"2":{"1135":1}}],["偏差",{"2":{"1132":1,"1135":1}}],["偏导",{"2":{"1086":1}}],["偏导数",{"0":{"982":1},"2":{"164":1}}],["偏移量转换",{"2":{"852":3}}],["偏移量",{"2":{"610":1}}],["偏移为",{"2":{"193":1}}],["偏置为b∈r1×q",{"2":{"644":1}}],["偏置初始化为0",{"2":{"630":1}}],["偏置将构成一个1×10的行向量",{"2":{"630":1}}],["偏置是指当所有特征都取值为0时",{"2":{"610":1}}],["偏置是w0给出的",{"2":{"259":1}}],["偏置bh",{"2":{"527":1}}],["偏置参数初始化为零",{"2":{"592":2}}],["偏置参数将初始化为零",{"2":{"592":1}}],["偏置参数设置为0",{"2":{"434":2}}],["偏置参数为bh∈r1×h",{"2":{"339":1}}],["偏置参数没有衰减",{"2":{"278":3}}],["偏置名称通常以",{"2":{"278":1}}],["进程级隔离",{"2":{"1346":1}}],["进阶操作",{"0":{"1331":1},"1":{"1332":1,"1333":1,"1334":1,"1335":1}}],["进阶学习",{"2":{"1304":1}}],["进入容器",{"2":{"1344":1,"1392":1}}],["进入项目虚拟环境",{"2":{"1293":1}}],["进入虚拟环境",{"2":{"1281":1,"1285":1}}],["进入上下文",{"2":{"1252":1}}],["进入你的网站",{"2":{"1168":1}}],["进入我的",{"2":{"1089":1}}],["进入路径",{"2":{"945":1}}],["进化的关键阶段",{"2":{"1049":1}}],["进一步假设目标类别的数量为10",{"2":{"956":1}}],["进一步假设从内存中获取用于avx2操作的指令至少需要一个寄存器",{"2":{"810":1}}],["进而触发update",{"2":{"1500":1}}],["进而学习得到一个假设h",{"2":{"1063":1}}],["进而更频繁地被推荐",{"2":{"294":1}}],["进而我们可以得到一个解p",{"2":{"192":1}}],["进行分组并存到一个矩阵中",{"2":{"1191":1}}],["进行分类的问题",{"2":{"252":1}}],["进行的误差分析方法",{"2":{"1183":1}}],["进行参数估计",{"2":{"1180":1}}],["进行误差分析",{"2":{"1138":1}}],["进行画图",{"2":{"1130":1}}],["进行惩罚",{"2":{"1115":1}}],["进行逻辑回归的速度大大提高",{"2":{"1111":1}}],["进行特征缩放依旧是非常必要的",{"2":{"1109":1}}],["进行赋值",{"2":{"1088":1}}],["进行如下变换",{"2":{"1086":1}}],["进行实时搜索与回答",{"2":{"1053":1}}],["进行",{"2":{"1047":1}}],["进行m=500组实验",{"2":{"1038":1}}],["进行预热",{"2":{"828":1}}],["进行处理",{"2":{"821":1}}],["进行情感分析",{"2":{"691":1}}],["进行比较",{"2":{"675":1,"1083":1,"1124":1}}],["进行一些非线性处理",{"2":{"619":1}}],["进行模型正则化",{"2":{"491":1}}],["进行注意力计算",{"2":{"408":1}}],["进行匹配",{"2":{"356":1}}],["进行多步预测",{"2":{"351":1}}],["进行重排列",{"2":{"244":1}}],["进行联合优化",{"2":{"223":1}}],["进行自动化决策的工具",{"2":{"201":1}}],["进行评分",{"2":{"195":1}}],["进行加权得到",{"2":{"154":1}}],["混淆",{"2":{"999":1}}],["混淆矩阵c是一个k×k矩阵",{"2":{"192":1}}],["混合式可能会影响模型的灵活性",{"2":{"821":1}}],["混合式",{"2":{"820":1}}],["混合式编程",{"0":{"818":1}}],["混合搭配各种组合块的方法",{"2":{"425":1}}],["混合数据集中的概率由下式给出",{"2":{"191":1}}],["≠p",{"2":{"192":1}}],["≠0没有消失",{"2":{"54":1}}],["见过",{"2":{"284":1}}],["见",{"2":{"191":1,"207":1,"280":1,"339":1,"662":1,"959":1}}],["∫∫l",{"2":{"191":1,"192":1}}],["依旧可以使用",{"2":{"1394":1}}],["依然感到有点神奇",{"2":{"1122":1}}],["依然像一个黑箱",{"2":{"1122":1}}],["依然是",{"2":{"1089":1}}],["依据两部电影的特征向量之间的距离",{"2":{"1189":1}}],["依据概率原理",{"2":{"631":1}}],["依据链式法则",{"2":{"312":1}}],["依靠实现良好的数据迭代器",{"2":{"585":1}}],["依照transformer架构来实例化编码器",{"2":{"409":1}}],["依赖中间件扩展",{"2":{"1205":1}}],["依赖ht时",{"2":{"312":1}}],["依赖于隐藏层中的模型参数whx和whh",{"2":{"312":1}}],["依赖于隐状态ht",{"2":{"312":1}}],["依赖于wqh",{"2":{"312":1}}],["依赖性假设意味着条件分布保持不变",{"2":{"191":1}}],["依次计算和存储梯度",{"2":{"312":1}}],["依次计算每个中间变量和参数的梯度",{"2":{"164":1}}],["依此类推",{"2":{"298":1,"418":1,"842":1,"1088":1,"1092":1,"1112":1}}],["制造出新的信息",{"2":{"187":1}}],["拍摄了另一组照片",{"2":{"186":1}}],["聪明",{"2":{"186":1}}],["饮酒以及其他许多与疾病无关的因素上存在差异",{"2":{"185":1}}],["饮食",{"2":{"185":1}}],["激活环境",{"2":{"1277":1}}],["激活虚拟环境",{"2":{"1273":1}}],["激活单元和输出分别表达为",{"2":{"1099":1}}],["激活值和梯度",{"2":{"832":1}}],["激活层和卷积层",{"2":{"505":1}}],["激活和卷积",{"2":{"480":1}}],["激活函数为ϕ",{"2":{"469":1}}],["激活函数是分段线性的",{"2":{"235":1}}],["激活函数的输出",{"2":{"232":1}}],["激活函数",{"0":{"218":1,"234":1,"460":1},"1":{"235":1,"236":1,"237":1},"2":{"234":1}}],["激活函数使用relu而不是sigmoid",{"2":{"67":1}}],["激励和反馈循环的许多问题",{"2":{"294":1}}],["激发",{"2":{"236":1}}],["激素水平",{"2":{"185":1}}],["假想你是一个飞机引擎制造商",{"2":{"1178":1}}],["假使",{"2":{"1140":1}}],["假使我们是一个电影供应商",{"2":{"1187":1}}],["假使我们有两个相关的特征",{"2":{"1184":1}}],["假使我们有有关于许多不同国家的数据",{"2":{"1157":1}}],["假使我们的例子中总体效果为72",{"2":{"1174":1}}],["假使我们的数据呈现这样的分布情况",{"2":{"1108":1}}],["假使我们需要在一张图片中识别行人",{"2":{"1172":1}}],["假使我们正在经营一家物流公司",{"2":{"1168":1}}],["假使我们正在针对一张",{"2":{"1162":1}}],["假使我们要采用两种不同的仪器来测量一些东西的尺寸",{"2":{"1156":1}}],["假使我们又观测到一个非常大尺寸的恶性肿瘤",{"2":{"1107":1}}],["假使我们采用的都是50x50像素的小图片",{"2":{"1097":1}}],["假使我们回归问题的训练集",{"2":{"1063":1}}],["假说表示",{"0":{"1107":1},"2":{"1193":1}}],["假",{"2":{"737":1,"1088":1}}],["假定你有一个提供运输服务的公司",{"2":{"1168":1}}],["假定有一最小化问题",{"2":{"1143":1}}],["假定控制附加噪声ϵ的噪声模型是指数分布",{"2":{"621":1}}],["假定两个张量的形状分别是",{"2":{"390":1}}],["假定在向量形式的x中",{"2":{"334":1}}],["假若我们对图像中的像素位置进行重排",{"2":{"305":1}}],["假如说它能够描述x",{"2":{"1141":1}}],["假如说你发现在预测房价时产生了巨大的误差",{"2":{"1129":1}}],["假如说你现在需要一个学习算法能自动地将邮件归类到不同的文件夹里",{"2":{"1112":1}}],["假如说你想预测房价",{"2":{"1060":1}}],["假如有这样一些假设",{"2":{"1141":1}}],["假如有人检测出乳腺肿瘤",{"2":{"1060":1}}],["假如你已经完成了正则化线性回归",{"2":{"1129":1}}],["假如你有一个朋友",{"2":{"1060":1}}],["假如某个特征",{"2":{"1110":1}}],["假如我输入max",{"2":{"1090":1}}],["假如我们有非常多的特征",{"2":{"1115":1}}],["假如我们只选用灰度图片",{"2":{"1097":1}}],["假如我们想把它存入硬盘",{"2":{"1089":1}}],["假如我们想识别图片中不同类型的椅子",{"2":{"869":1}}],["假如我们面前有五个物品",{"2":{"355":1}}],["假如我们环游美国",{"2":{"183":1}}],["假如",{"2":{"1089":2,"1129":1}}],["假如数据流中的每个数据完全相同",{"2":{"651":1}}],["假如需要我们编写程序来响应一个",{"2":{"282":1}}],["假如开发人员要试图解决以下问题之一",{"2":{"281":1}}],["假设我有两个向量",{"2":{"1145":1}}],["假设我们采用线性回归模型",{"2":{"1188":1}}],["假设我们未知两个的特征",{"2":{"1156":1}}],["假设我们利用之前介绍的一对多方法来解决一个多类分类问题",{"2":{"1148":1}}],["假设我们编写一个非学习而来的算法",{"2":{"1139":1}}],["假设我们要在10个不同次数的二项式模型之间进行选择",{"2":{"1131":1}}],["假设我们要随机初始一个尺寸为10×11的参数矩阵",{"2":{"1125":1}}],["假设我们已经完成了可以实现这两件事的代码",{"2":{"1111":1}}],["假设我们已经拥有尽可能多的高质量数据",{"2":{"269":1}}],["假设我们希望训练一个模型来识别视觉对象",{"2":{"1097":1}}],["假设我们掷骰子",{"2":{"1026":1}}],["假设我们为一家大型在线书店工作",{"2":{"1025":1}}],["假设我们指定随机裁剪的输出图像的形状为320×480",{"2":{"948":1}}],["假设我们在输出中有q个类别",{"2":{"644":1}}],["假设我们在时间步3选择词元",{"2":{"513":1}}],["假设我们在时间步t有小批量输入xt∈rn×d",{"2":{"340":1}}],["假设我们读取了一个批量的样本x",{"2":{"644":1}}],["假设我们使用一种需要大量参数的学习算法",{"2":{"1141":1}}],["假设我们使用一个非常高次的多项式模型",{"2":{"1134":1}}],["假设我们使用两个特征",{"2":{"1082":1}}],["假设我们使用softmax回归来预测下一个单词",{"2":{"638":1}}],["假设我们使用神经网络来实现",{"2":{"537":1}}],["假设我们观测到所有的xi",{"2":{"519":1}}],["假设我们的训练集只有一个样本",{"2":{"1121":1}}],["假设我们的训练集特征矩阵为",{"2":{"1085":1}}],["假设我们的原始输入为x",{"2":{"501":1}}],["假设我们的小批量包含m个样本",{"2":{"470":1}}],["假设我们的预测偏差了10万美元",{"2":{"210":1}}],["假设我们至少有两个gpu",{"2":{"448":1}}],["假设我们只想使用时间步t",{"2":{"549":1}}],["假设我们只想复用网络的一部分",{"2":{"444":1}}],["假设我们只有有限的训练数据",{"2":{"99":1}}],["假设我们将使用神经网络来训练语言模型",{"2":{"319":1}}],["假设我们拥有一个对称矩阵m∈rn×n",{"2":{"314":1}}],["假设我们需要预测患者的心脏病是否会发作",{"2":{"289":1}}],["假设我们处理的是k个类别的分类任务",{"2":{"192":1}}],["假设我们分别从p",{"2":{"191":1}}],["假设我们训练了一个贷款申请人违约风险模型",{"2":{"179":1}}],["假设我们有非常多的特征",{"2":{"1097":1}}],["假设我们有两个特征量",{"2":{"1093":1}}],["假设我们有两个卷积核",{"2":{"124":1}}],["假设我们有c张形状为h×w的特征图",{"2":{"913":1}}],["假设我们有多个gpu",{"2":{"832":1}}],["假设我们有三个权重矩阵",{"2":{"1121":1}}],["假设我们有三个类发生的概率相等",{"2":{"655":1}}],["假设我们有三个序列",{"2":{"307":1}}],["假设我们有一系列随机变量",{"2":{"1038":1}}],["假设我们有一些数据x1",{"2":{"621":1}}],["假设我们有一个函数f",{"2":{"981":1}}],["假设我们有一个nh×nw的输入张量和一个kh×kw的卷积核",{"2":{"968":1}}],["假设我们有一个巨大的新闻文章池和大量的查询",{"2":{"662":1}}],["假设我们有一个分类问题",{"2":{"298":1}}],["假设我们有一个简单的多层感知机",{"2":{"244":1}}],["假设我们有一个非线性单元",{"2":{"239":1}}],["假设我们有一个训练集",{"2":{"191":1}}],["假设我们有一个足够充分的照片数据集",{"2":{"151":1}}],["假设我们有一个对称随机矩阵m",{"2":{"105":1}}],["假设我们有函数y=f",{"2":{"164":1}}],["假设我们想对函数y=2x⊤x关于列向量x求导",{"2":{"974":1}}],["假设我们想要将数据聚类成n个组",{"2":{"1151":1}}],["假设我们想要将数据增强",{"2":{"935":1}}],["假设我们想要获得任何一对句子的语义相似级别",{"2":{"684":1}}],["假设我们想要连接同一网络的多个实例",{"2":{"428":1}}],["假设我们想要训练一个皮肤癌识别模型",{"2":{"284":1}}],["假设我们想要通过绘制集合内点之间的所有直线并检查这些直线是否包含来验证集合的凸性",{"2":{"52":1}}],["假设我们想设计一个检测癌症的算法",{"2":{"185":1}}],["假设我们想从一张图片中找到某个物体",{"2":{"152":1}}],["假设我们想最小化函数f",{"2":{"103":1}}],["假设我们正在训练一个语言模型",{"2":{"25":1}}],["假设特征值有足够的信息来预测y值",{"2":{"1141":1}}],["假设特征值的序列顺序为|λi|≥|λi+1|",{"2":{"314":1}}],["假设λ=0",{"2":{"1121":1}}],["假设因为第一层是输入变量",{"2":{"1121":1}}],["假设神经网络的训练样本有m个",{"2":{"1120":1}}],["假设的定义发生了变化",{"2":{"1110":1}}],["假设的否定可以从前提中推断出来",{"2":{"665":1}}],["假设现在是在个有些小的鸡尾酒宴中",{"2":{"1061":1}}],["假设现在有一个向量分布在多个gpu上",{"2":{"835":1}}],["假设说她的肿瘤大概这么大",{"2":{"1060":1}}],["假设说你想通过查看病历来推测乳腺癌良性与否",{"2":{"1060":1}}],["假设人口总体是相当健康的",{"2":{"1035":1}}],["假设p",{"2":{"1032":1}}],["假设pij",{"2":{"105":1}}],["假设事件a1为整个样本空间",{"2":{"1027":1}}],["假设n维向量x中的元素是x1",{"2":{"1000":1}}],["假设可微分函数y有变量u1",{"2":{"984":1}}],["假设可以从前提中推断出来",{"2":{"665":1}}],["假设函数y=f",{"2":{"984":1}}],["假设函数f和g都是可微的",{"2":{"981":1}}],["假设y是作为x的函数计算的",{"2":{"976":1}}],["假设y1和y2的每个单元分别生成了5个和3个锚框",{"2":{"956":1}}],["假设卷积神经网络抽取的特征x的高度和宽度都是4",{"2":{"938":1}}],["假设卷积层",{"2":{"160":1}}],["假设卷积层执行互相关运算并学习",{"2":{"130":1}}],["假设选择性搜索生成了n个提议区域",{"2":{"938":1}}],["假设该输出的样本数为1",{"2":{"923":1}}],["假设此处的c张特征图是cnn基于输入图像的正向传播算法获得的中间输出",{"2":{"913":1}}],["假设列表s的长度为1",{"2":{"912":1}}],["假设trainer实例中的学习率为η",{"2":{"873":1}}],["假设给定输入图像",{"2":{"863":1}}],["假设s",{"2":{"862":1}}],["假设最大的预测概率为p",{"2":{"854":1}}],["假设矩阵x中的最大值为x23",{"2":{"851":1}}],["假设锚框是a1",{"2":{"851":1}}],["假设能够将梯度分为4个部分",{"2":{"841":1}}],["假设hdd制造商将存储密度从每平方英寸1",{"2":{"815":1}}],["假设磁头几乎是瞬间移动的",{"2":{"815":1}}],["假设向量处理单元启用了256位带宽的avx2",{"2":{"810":1}}],["假设10000t2",{"2":{"792":1}}],["假设上下文词是在给定任何中心词的情况下独立生成的",{"2":{"783":1}}],["假设上下文词是在给定中心词的情况下独立生成的",{"2":{"783":1}}],["假设中心词选择",{"2":{"783":1}}],["假设zg是词典中的子词g的向量",{"2":{"756":1}}],["假设词典中不同词的数量",{"2":{"781":1}}],["假设词wi在语料库中出现两次",{"2":{"742":1}}],["假设词表大小为10000",{"2":{"734":1}}],["假设词表中不同词元的数目为n",{"2":{"330":1}}],["假设batch",{"2":{"736":3}}],["假设正例和负例s",{"2":{"708":1}}],["假设是",{"2":{"674":1}}],["假设是存在漏洞的",{"2":{"253":1}}],["假设前提是",{"2":{"674":1}}],["假设和标签",{"2":{"667":1,"668":1}}],["假设及其标签的列表",{"2":{"667":1}}],["假设",{"2":{"665":4,"667":1,"670":1,"1063":1,"1143":1}}],["假设为每个查询标记了最相关的文章",{"2":{"662":1}}],["假设整个数据集",{"2":{"646":1}}],["假设每个图像属于类别",{"2":{"640":1}}],["假设每次输入是一个2×2的灰度图像",{"2":{"640":1}}],["假设每步中的值减半",{"2":{"71":1}}],["假设自变量x和因变量y之间的关系是线性的",{"2":{"609":1}}],["假设试图为电压和电流的关系建立一个模型",{"2":{"607":1}}],["假设样本数能够被批量大小整除",{"2":{"605":1}}],["假设同一个小批量中的每个序列都应该具有相同的长度num",{"2":{"568":1}}],["假设有两个矩阵a∈rn×k和b∈rk×m",{"2":{"999":1}}],["假设有h个隐藏单元",{"2":{"553":1}}],["假设有一类特定的神经网络架构f",{"2":{"500":1}}],["假设有一个完成训练的基于多头注意力的模型",{"2":{"384":1}}],["假设有一个查询",{"2":{"367":1}}],["假设有一组房屋销售数据表格",{"2":{"290":1}}],["假设存在某个隐变量ht",{"2":{"519":1}}],["假设具有最高条件概率",{"2":{"515":1}}],["假设它的运行速度比gpu快4倍",{"2":{"457":1}}],["假设变量z已经存在于第二个gpu上",{"2":{"449":3}}],["假设你有了一个快速而不完美的算法实现",{"2":{"1138":1}}],["假设你将θ1初始化在局部最低点",{"2":{"1068":1}}],["假设你经营着一家公司",{"2":{"1060":1}}],["假设你安装了cuda10",{"2":{"445":1}}],["假设你想在",{"2":{"105":1}}],["假设已经安装了cuda10",{"2":{"445":1}}],["假设设计一个深度架构",{"2":{"402":1}}],["假设第一个小批量数据包含n个矩阵x1",{"2":{"390":1}}],["假设查询和键的所有元素都是独立的随机变量",{"2":{"370":1}}],["假设训练数据集中有100",{"2":{"323":1}}],["假设训练数据是从某个分布ps",{"2":{"180":1}}],["假设批量大小为2",{"2":{"320":1}}],["假设网络一次只处理具有n个时间步的子序列",{"2":{"319":1}}],["假设在时间步t有一个小批量的输入数据",{"2":{"527":1}}],["假设在步骤1之后",{"2":{"351":1}}],["假设在现实情况下相当长的序列",{"2":{"347":1}}],["假设在单词级别对文本数据进行词元化",{"2":{"316":1}}],["假设在一个与测试集的特征有着本质不同的数据集上进行训练",{"2":{"181":1}}],["假设长度为t的文本序列中的词元依次为x1",{"2":{"315":1}}],["假设这三个阶段的持续时间分别为t1",{"2":{"792":1}}],["假设这个分类器输出",{"2":{"291":1}}],["假设这两种自然尺度都以米为单位",{"2":{"61":1}}],["假设后院有一个如",{"2":{"291":1}}],["假设本书的作者们一起驱车去咖啡店",{"2":{"282":1}}],["假设硬币是公平的",{"2":{"252":1}}],["假设标签的分布随时间变化",{"2":{"192":1}}],["假设标签是随机均匀分配的",{"2":{"169":1}}],["假设对于带标签的数据",{"2":{"191":1}}],["假设计算图对当前拥有的gpu来说太大了",{"2":{"167":1}}],["假设想计算二阶导数",{"2":{"167":1}}],["假设一台机器有k个gpu",{"2":{"833":1}}],["假设一个医生对患者进行艾滋病病毒",{"2":{"1035":1}}],["假设一个锚框a被分配了一个真实边界框b",{"2":{"852":1}}],["假设一个交易员想在t日的股市中表现良好",{"2":{"346":1}}],["假设一个模型被用来监控重症监护病人",{"2":{"295":1}}],["假设一个大学生正在努力准备期末考试",{"2":{"252":1}}],["假设一个变量以毫米表示高度",{"2":{"61":1}}],["假设一些标量函数x的输入x是n×m矩阵",{"2":{"167":1}}],["假设损失函数为l",{"2":{"162":1}}],["假设输出的词表只包含五个元素",{"2":{"515":1}}],["假设输出中有四个词元",{"2":{"513":1}}],["假设输出层将上述两个隐藏单元的多层感知机转换为仅一个输出单元",{"2":{"244":1}}],["假设输出层的参数只有权重w",{"2":{"162":1}}],["假设输入有ci个通道",{"2":{"969":1}}],["假设输入图像的高度为h",{"2":{"848":1}}],["假设输入序列是x1",{"2":{"573":1}}],["假设输入序列中有t个词元",{"2":{"374":1}}],["假设输入是一个小批量",{"2":{"540":1}}],["假设输入表示x∈rn×d",{"2":{"398":1}}],["假设输入形状为nh×nw",{"2":{"140":1}}],["假设输入为ci×h×w",{"2":{"124":1}}],["假设输入的通道数为ci",{"2":{"120":1}}],["假设u包含偏置参数",{"2":{"153":1}}],["假设汇聚层的输入大小为c×h×w",{"2":{"150":1}}],["假设kh是奇数",{"2":{"141":1}}],["假设以下情景",{"2":{"140":1}}],["假设之前输出为y",{"2":{"131":1}}],["假设其他条件不变",{"2":{"130":1}}],["假设f",{"2":{"118":1}}],["假设所有ξ的目标函数f",{"2":{"115":1}}],["假设a",{"2":{"46":1}}],["假设x为n维向量",{"2":{"983":1}}],["假设xi",{"2":{"924":1}}],["假设x∗∈x是一个局部最小值",{"2":{"44":1}}],["假设x和y是凸集",{"2":{"40":1}}],["概述",{"0":{"1040":1,"1451":1},"1":{"1041":1,"1042":1},"2":{"1497":1,"1498":1,"1499":1,"1500":1,"1501":1,"1502":1,"1503":1}}],["概述了机器学习中令人不安的趋势",{"2":{"475":1}}],["概括地说",{"2":{"802":1}}],["概括一下",{"2":{"605":1}}],["概率可能是违反直觉的",{"2":{"1035":1}}],["概率论公理",{"0":{"1027":1}}],["概率的估计值",{"2":{"1026":1}}],["概率是一种灵活的语言",{"2":{"1025":1}}],["概率给了我们一种正式的途径来说明我们的确定性水平",{"2":{"1025":1}}],["概率",{"0":{"1025":1},"1":{"1026":1,"1027":1,"1028":1,"1029":1,"1030":1,"1031":1,"1032":1,"1033":1,"1034":1,"1035":1,"1036":1,"1037":1,"1038":1},"2":{"1027":1}}],["概率p",{"2":{"651":1}}],["概率为",{"2":{"170":1}}],["概率为其他情况h",{"2":{"170":1}}],["概念",{"2":{"1470":1,"1493":1}}],["概念不涉及维度",{"2":{"1000":1}}],["概念上简单但经验上强大的自然语言深度表示预训练已经彻底改变了各种自然语言处理任务的解决方案",{"2":{"733":1}}],["概念的变化总是缓慢的",{"2":{"193":1}}],["概念偏移很难用原则性的方式解决",{"2":{"193":1}}],["概念偏移纠正",{"0":{"193":1}}],["概念偏移",{"0":{"183":1}}],["描述",{"2":{"1068":1,"1216":1}}],["描述了elmo",{"2":{"733":1}}],["描述了门控循环单元中的重置门和更新门的输入",{"2":{"540":1}}],["描述了底层图像特征",{"2":{"455":1}}],["描述了与协变量偏移相反的问题",{"2":{"182":1}}],["描述为什么涉及多个超参数更具挑战性",{"2":{"223":1}}],["描述一个类似的音频卷积层的架构",{"2":{"160":1}}],["提升代码复用率与可维护性",{"2":{"1527":1}}],["提升程序可读性与复用性",{"2":{"1228":1}}],["提交后忘记添加文件",{"2":{"1337":1}}],["提交到本地仓库",{"2":{"1328":1}}],["提交历史像火车轨道",{"2":{"1321":1}}],["提交说明",{"2":{"1321":1,"1328":1}}],["提交时间",{"2":{"1321":1}}],["提交人",{"2":{"1321":1}}],["提交",{"0":{"1321":1}}],["提交修改",{"2":{"1318":1}}],["提交kaggle预测",{"0":{"213":1}}],["提前知道你应该做什么",{"2":{"1138":1}}],["提醒一件事",{"2":{"1092":1}}],["提议区域",{"2":{"937":1}}],["提出了一个特别优化的问题",{"2":{"1148":1}}],["提出一种随机梯度下降算法来解决这个问题",{"2":{"621":1}}],["提出的bleu",{"2":{"578":1}}],["提取出的数据集位于",{"2":{"945":1}}],["提取后返回的是一个参数类实例",{"2":{"431":1}}],["提取偏置",{"2":{"431":1}}],["提供数据",{"2":{"1503":1}}],["提供数据的组件",{"2":{"1499":1}}],["提供",{"2":{"1209":1}}],["提供特定能力",{"2":{"1042":1}}],["提供商和厂商",{"2":{"1041":1}}],["提供了多种属性修饰符来控制类成员的访问性和行为",{"2":{"1424":1}}],["提供了丰富的类型系统",{"2":{"1403":1}}],["提供了",{"2":{"1041":1,"1374":1}}],["提供了一个非常简单的解决方案",{"2":{"493":1}}],["提供了一些后端实现",{"2":{"422":1}}],["提供上下文的方式进行了标准化",{"2":{"1040":1}}],["提供的虚拟机",{"2":{"1312":1}}],["提供的有用信息很少",{"2":{"773":1}}],["提供的若干个公开数据集",{"2":{"456":1}}],["提供三个门和一个额外的记忆元",{"2":{"559":1}}],["提供许多猫和狗的图片来设计一个",{"2":{"282":1}}],["提高到了89",{"2":{"1174":1}}],["提高性能的关键是维护操作的",{"2":{"805":1}}],["提高python速度的最好方法是完全避免使用python",{"2":{"426":1}}],["提高生成文本的多样性和生成图像的重建质量",{"2":{"198":1}}],["提高原始分类器的精度",{"2":{"180":1}}],["提示必须先初始化网络",{"2":{"418":1}}],["提示",{"2":{"64":1,"150":1,"203":1,"215":1,"268":1,"353":1,"411":2,"420":1,"453":1,"621":1,"638":2,"655":1,"746":1,"759":1,"788":1,"794":1,"815":2,"846":1,"876":1,"929":1,"935":1,"1038":2}}],["狗的品种识别",{"0":{"899":1},"1":{"900":1,"901":1,"902":1,"903":1,"904":1,"905":1,"906":1,"907":1,"908":1,"909":1,"910":1}}],["狗的预测概率",{"2":{"854":2}}],["狗和猫其中的每个类",{"2":{"854":1}}],["狗和猫的类索引分别为0",{"2":{"853":1}}],["狗或飞盘",{"2":{"455":1}}],["狗咬人",{"2":{"315":1,"345":1}}],["狗",{"2":{"180":1,"291":1,"296":1,"639":1,"640":3,"888":1,"1025":2}}],["猫和背景的标签",{"2":{"943":1}}],["猫和山峰的照片吗",{"2":{"296":1}}],["猫位于图像的中间",{"2":{"879":1}}],["猫的预测概率",{"2":{"854":2}}],["猫科动物",{"2":{"316":1}}],["猫图检测器",{"2":{"282":1}}],["猫",{"2":{"180":1,"291":1,"316":1,"639":1,"640":3,"888":1,"1025":5}}],["区别",{"2":{"1458":1}}],["区别一个肿瘤是恶性的还是良性的",{"2":{"1106":1}}],["区别只在于的取值不同",{"2":{"1101":1}}],["区别好是垃圾还是非垃圾邮件",{"2":{"1061":1}}],["区域提议网络能够学习到如何生成高质量的提议区域",{"2":{"939":1}}],["区域提议网络作为faster",{"2":{"939":1}}],["区域提议网络的计算步骤如下",{"2":{"939":1}}],["区域目标类别",{"2":{"938":1}}],["区域卷积神经网络",{"0":{"936":1},"1":{"937":1,"938":1,"939":1,"940":1,"941":1,"942":1},"2":{"936":1}}],["区域的宽度和高度都被缩放到200像素",{"2":{"879":1}}],["区间中的向量",{"2":{"540":1}}],["区间上都是最小值",{"2":{"44":1}}],["区分开来",{"2":{"734":1}}],["区分白色和黑色动物",{"2":{"193":1}}],["区分猫和狗的能力可能会变为猜测",{"2":{"1025":1}}],["区分猫和狗",{"2":{"193":1}}],["区分狗和猫",{"2":{"180":1}}],["机器运行算法让我们更好地了解人类基因组",{"2":{"1058":1}}],["机器人也常通过该任务来检测感兴趣的目标",{"2":{"857":1}}],["机器人学",{"2":{"301":1}}],["机器能思考吗",{"2":{"299":1}}],["机器翻译长期以来一直是基于翻译输出和翻译真实值之间的表面n元语法匹配来进行评估的",{"2":{"671":1}}],["机器翻译中的输入序列和输出序列都是长度可变的",{"2":{"572":1}}],["机器翻译指的是将文本序列从一种语言自动翻译成另一种语言",{"2":{"570":1}}],["机器翻译的数据集是由源语言和目标语言的文本序列对组成的",{"2":{"564":1}}],["机器翻译的输入和输出都为文字序列",{"2":{"295":1}}],["机器翻译与数据集",{"0":{"564":1},"1":{"565":1,"566":1,"567":1,"568":1,"569":1,"570":1,"571":1}}],["机器翻译是序列转换模型的一个核心问题",{"2":{"532":1}}],["机器翻译数据集上训练transformer模型",{"2":{"409":1}}],["机器翻译",{"2":{"295":1,"564":1}}],["机器学习教程中文笔记目录",{"0":{"1193":1}}],["机器学习中对于方差我们通常只除以m而非统计学中的",{"2":{"1179":1}}],["机器学习中的大思想也是这样",{"2":{"1187":1}}],["机器学习中的关键组件",{"0":{"283":1},"1":{"284":1,"285":1,"286":1,"287":1}}],["机器学习中的公平",{"0":{"201":1}}],["机器学习系统对于一个宽泛的应用领域来说",{"2":{"1148":1}}],["机器学习系统的设计",{"0":{"1136":1},"1":{"1137":1,"1138":1,"1139":1,"1140":1,"1141":1},"2":{"1193":1}}],["机器学习系统会变得有知觉",{"2":{"301":1}}],["机器学习诊断法",{"2":{"1129":1}}],["机器学习被用于数据挖掘的原因之一是网络和自动化技术的增长",{"2":{"1058":1}}],["机器学习已经成为计算机的一个能力",{"2":{"1058":1}}],["机器学习不只是用于人工智能领域",{"2":{"1058":1}}],["机器学习能做些什么事情",{"2":{"1058":1}}],["机器学习就是做出预测",{"2":{"1025":1}}],["机器学习还涉及如何做出预测",{"2":{"987":1}}],["机器学习通常需要处理大型数据集",{"2":{"987":1}}],["机器学习实践者用分类这个词来描述两个有微妙差别的问题",{"2":{"639":1}}],["机器学习是一门对科技",{"2":{"1176":1}}],["机器学习是一个正在蓬勃发展",{"2":{"454":1}}],["机器学习是什么",{"0":{"1059":1},"2":{"1059":1,"1193":1}}],["机器学习是目前信息技术中最激动人心的方向之一",{"2":{"1058":1}}],["机器学习是无处不在的",{"2":{"301":1}}],["机器学习研究计算机系统如何利用经验",{"2":{"303":1}}],["机器学习可以使用数据来学习输入和输出之间的转换",{"2":{"302":1}}],["机器学习正在成为工程师和科学家必备的工具",{"2":{"301":1}}],["机器学习在互联网上提供搜索",{"2":{"301":1}}],["机器学习和统计的关注点从",{"2":{"300":1}}],["机器学习的数据",{"0":{"1141":1},"2":{"1193":1}}],["机器学习的时间也是很宝贵的",{"2":{"1088":1}}],["机器学习的整个子领域都侧重于使用矩阵分解及其向高阶张量的泛化",{"2":{"1002":1}}],["机器学习的第二个影响来自克劳德",{"2":{"299":1}}],["机器学习的输出又将去往何方",{"2":{"297":1}}],["机器学习的输入",{"2":{"297":1}}],["机器学习的许多应用中都存在类似的问题",{"2":{"179":1}}],["机器学习算法将会怎么帮助你呢",{"2":{"1060":1}}],["机器学习算法可以提供临时标签",{"2":{"292":1}}],["机器学习算法会积累更多的经验",{"2":{"281":1}}],["机器学习模型中的关键要素是训练数据",{"2":{"620":1}}],["机器学习模型会根据这些属性进行预测",{"2":{"284":1}}],["机器学习模型需要注意防止过拟合",{"2":{"267":1}}],["机器学习渗透在生活中的方方面面",{"2":{"282":1}}],["机器学习应用在日常生活中的方方面面",{"2":{"282":1}}],["机器学习",{"2":{"281":1,"292":2,"1058":1,"1176":1,"1297":1}}],["机中",{"2":{"135":1}}],["穿运动鞋申请人会违约",{"2":{"179":1}}],["穿牛津鞋申请人会偿还",{"2":{"179":1}}],["收集更多的数据",{"2":{"1137":1}}],["收集非常多",{"2":{"1061":1}}],["收集和标记数据可能需要大量的时间和金钱",{"2":{"869":1}}],["收集这些数据集需要昂贵的传感器",{"2":{"454":1}}],["收集训练数据的分布和在实际中遇到的数据分布可能有很大的不同",{"2":{"185":1}}],["收入从0增加到5万",{"2":{"230":1}}],["收入较高的申请人比收入较低的申请人更有可能偿还贷款",{"2":{"230":1}}],["收益是否减少",{"2":{"178":1}}],["收敛到最优解",{"2":{"115":1}}],["收敛就会更好",{"2":{"114":1}}],["收敛就会停滞",{"2":{"84":1}}],["收敛会发生什么",{"2":{"111":1}}],["收敛率最初是如何提高的",{"2":{"95":1}}],["收敛风险较小",{"2":{"82":1}}],["收敛性会如何改变",{"2":{"75":1}}],["收敛性分析",{"0":{"60":1}}],["收敛将变得非常快",{"2":{"60":1}}],["收敛速度取决于随机梯度标准的限制方式",{"2":{"115":1}}],["收敛速度是由r的特征值决定的",{"2":{"95":1}}],["收敛速度",{"2":{"60":1}}],["收敛",{"2":{"60":1}}],["收敛时为什么需要降低学习率η",{"2":{"37":1}}],["定位",{"2":{"1546":1}}],["定时触发",{"2":{"1309":1}}],["定向梯度直方图",{"2":{"455":1}}],["定量描述该结果",{"2":{"178":1}}],["定义并暴露一个store",{"2":{"1490":2,"1493":1}}],["定义响应式变量",{"2":{"1455":1}}],["定义工作进程数量",{"2":{"1365":1}}],["定义本",{"2":{"1315":1}}],["定义方式",{"2":{"1309":1}}],["定义函数",{"0":{"1229":1}}],["定义函数def",{"2":{"717":1}}],["定义几个函数",{"2":{"981":1}}],["定义u=f",{"2":{"981":1}}],["定义好模型后",{"2":{"961":1}}],["定义完整的模型",{"2":{"959":1}}],["定义图像的预处理函数和后处理函数",{"2":{"919":1}}],["定义图像中狗和猫的边界框",{"2":{"858":1}}],["定义train",{"2":{"883":1}}],["定义tensorflow训练策略",{"2":{"332":1}}],["定义和初始化模型",{"0":{"873":1}}],["定义在这两种表示法之间进行转换的函数",{"2":{"858":1}}],["定义下面的show",{"2":{"848":1}}],["定义计算流程",{"2":{"817":1}}],["定义前向传播",{"0":{"763":1}}],["定义两个宽度为2和4的一维卷积核",{"2":{"701":1}}],["定义多个一维卷积核",{"2":{"701":1}}],["定义空词表以加载预定义词表",{"2":{"686":3}}],["定义预测函数",{"2":{"682":1}}],["定义用于加载数据集的类",{"0":{"668":1}}],["定义见第3章",{"2":{"635":5,"636":1}}],["定义见第8章",{"2":{"335":8}}],["定义softmax操作后",{"2":{"632":1}}],["定义softmax操作",{"0":{"631":1}}],["定义的",{"2":{"1462":2,"1463":2,"1464":2,"1465":1}}],["定义的训练函数来训练模型",{"2":{"626":1}}],["定义的超参数调用train",{"2":{"326":1}}],["定义优化算法",{"0":{"594":1,"604":1}}],["定义损失函数和评价函数",{"0":{"962":1}}],["定义损失函数",{"0":{"593":1,"603":1,"633":1,"921":1},"1":{"922":1,"923":1,"924":1,"925":1}}],["定义简单的神经网络架构",{"2":{"587":1}}],["定义load",{"2":{"584":1}}],["定义l2范数惩罚",{"0":{"274":1}}],["定义门控循环单元模型",{"2":{"545":1}}],["定义隐状态的初始化函数",{"2":{"545":1}}],["定义一个自定义类型persons",{"2":{"1469":1}}],["定义一个接口",{"2":{"1469":1}}],["定义一个响应式对象",{"2":{"1456":1}}],["定义一个虚拟主机",{"2":{"1365":1}}],["定义一个plot函数来简洁地绘制多条曲线",{"2":{"981":1}}],["定义一个新的输出网络",{"2":{"905":3}}],["定义一个函数叫",{"2":{"1092":1}}],["定义一个函数",{"2":{"883":1}}],["定义一个函数在一个迭代周期内训练模型",{"2":{"335":1}}],["定义一个辅助函数",{"2":{"882":1}}],["定义一个在动画中绘制数据的实用程序类",{"2":{"635":1}}],["定义一个data",{"2":{"600":1}}],["定义一个",{"2":{"480":1}}],["定义nadaraya",{"2":{"391":1}}],["定义注意力解码器",{"0":{"375":1}}],["定义了所有需要的函数之后",{"2":{"332":1}}],["定义训练阶段代码",{"0":{"767":1}}],["定义训练策略",{"2":{"546":1}}],["定义训练代码实现",{"0":{"275":1}}],["定义训练函数",{"2":{"263":1,"837":1}}],["定义模型的正向传播",{"2":{"423":1}}],["定义模型的前向传播",{"2":{"423":3}}],["定义模型",{"0":{"174":1,"325":1,"391":1,"545":1,"559":1,"591":1,"602":1,"632":1,"702":1},"2":{"602":1,"834":3}}],["定义模型参数",{"0":{"173":1}}],["定义具有两个隐藏层的多层感知机",{"2":{"173":1}}],["定义为f的hessian",{"2":{"59":1}}],["定义凸集",{"2":{"45":1}}],["定义",{"0":{"39":1,"521":1,"893":1,"894":1,"906":1},"1":{"40":1,"41":1,"42":1},"2":{"1077":1,"1339":1,"1347":1,"1348":1,"1381":1}}],["替换掉了",{"2":{"1525":1}}],["替换广播机制中按元素操作的两个张量",{"2":{"1024":1}}],["替换实验中的内容图像和风格图像",{"2":{"929":1}}],["替换每个损失项的权重",{"2":{"743":1}}],["替换输入序列中的词元",{"2":{"736":1}}],["替换",{"2":{"170":1,"374":1}}],["替换为",{"2":{"690":1}}],["替换为四阶权重张量w",{"2":{"153":1}}],["替换为先前观察所得梯度的平方之和来解决这个问题",{"2":{"25":1}}],["他希望使用聚类算法来更好的组织计算机集群",{"2":{"1150":1}}],["他是我的同事",{"2":{"1127":1}}],["他是论文",{"2":{"455":1}}],["他可能并没有生病",{"2":{"1112":1}}],["他可以将篮球投入篮框中",{"2":{"1098":1}}],["他可以四处走动而不撞到任何东西",{"2":{"1098":1}}],["他能滑滑板",{"2":{"1098":1}}],["他能以大约220000",{"2":{"1063":1}}],["他因为癌症眼球惨遭移除",{"2":{"1098":1}}],["他就等于1的平方",{"2":{"1092":1}}],["他俩同时都在说话",{"2":{"1061":1}}],["他想知道这房子能卖多少钱",{"2":{"1060":1}}],["他有一套750平方英尺房子",{"2":{"1060":1}}],["他有痴呆症",{"2":{"251":1}}],["他说",{"2":{"1059":1}}],["他编写了一个西洋棋程序",{"2":{"1059":1}}],["他定义机器学习为",{"2":{"1059":1}}],["他对该示例进行了详细回顾",{"2":{"475":1}}],["他对动物进行了层次分类",{"2":{"291":1}}],["他被认为是",{"2":{"355":1}}],["他查看过去的回报",{"2":{"353":1}}],["他提出神经元通过积极强化学习",{"2":{"299":1}}],["他也是优生学的倡导者",{"2":{"299":1}}],["他的许多算法",{"2":{"299":1}}],["他发明了最小均方算法",{"2":{"299":1}}],["他收到了250美元的账单",{"2":{"290":1}}],["他甚至可以完全记住过去考试的答案",{"2":{"252":1}}],["他们似乎在很多企业中占据很高的优先级",{"2":{"1187":1}}],["他们关注一群人",{"2":{"1150":1}}],["他们所做的就是改变了训练数据集的大小",{"2":{"1141":1}}],["他们也采取了一些过去常用",{"2":{"1141":1}}],["他们用了几种不同的学习算法",{"2":{"1141":1}}],["他们尝试了许多种不同的算法",{"2":{"1141":1}}],["他们尝试通过机器学习算法来区分常见的易混淆的单词",{"2":{"1141":1}}],["他们做的只是某天早上醒来",{"2":{"1137":1}}],["他们每天的工作就是使用这些学习算法来解决众多实际问题",{"2":{"1135":1}}],["他们很遗憾地发现自己选择的是一条不归路",{"2":{"1129":1}}],["他们总认为",{"2":{"1129":1}}],["他们提供了一些比这个方法更加稳定的驾驶控制技术",{"2":{"1127":1}}],["他们确实有一个智能的内部循环",{"2":{"1111":1}}],["他们通常写得很好",{"2":{"1093":1}}],["他们想从哪里寄出包裹",{"2":{"1168":1}}],["他们想解决什么样的机器易于协同地工作",{"2":{"1061":1}}],["他们想出了一个",{"2":{"186":1}}],["他们可能没有完全理解怎样运用这些算法",{"2":{"1129":1}}],["他们可能已经有了大体的框架",{"2":{"1059":1}}],["他们可能很小",{"2":{"241":1}}],["他们应该采取一种学习算法",{"2":{"1059":1}}],["他们有百万的用户",{"2":{"1058":1}}],["他们较大的值由0",{"2":{"959":1}}],["他们需要处理分布式同步中固有的复杂性",{"2":{"844":1}}],["他们希望能够用简单的术语表达优化",{"2":{"844":1}}],["他们将数字的更新版本保存到github",{"2":{"813":1}}],["他们为什么将线性模型作为一个起点呢",{"2":{"619":1}}],["他们为获胜的解决方案提供奖金",{"2":{"207":1}}],["他们使用两个显存为3gb的nvidia",{"2":{"457":1}}],["他们意识到卷积神经网络中的计算瓶颈",{"2":{"457":1}}],["他们还认为",{"2":{"455":1}}],["他们认为特征本身应该被学习",{"2":{"455":1}}],["他们都一样的好",{"2":{"319":1}}],["他们跨越学术界和企业界共享工具",{"2":{"302":1}}],["他们依靠一个简单的相关性过滤来识别一组相关条目",{"2":{"293":1}}],["他们的区别甚小",{"2":{"1179":1}}],["他们的意思就是同步更新",{"2":{"1067":1}}],["他们的数值也相同吗",{"2":{"972":1}}],["他们的主要区别是什么",{"2":{"942":1}}],["他们的杰卡德系数是他们交集的大小除以他们并集的大小",{"2":{"849":1}}],["他们的批量规范化实现略有不同",{"2":{"468":1}}],["他们的创新cuda",{"2":{"457":1}}],["他们的乘积可能非常大",{"2":{"241":1}}],["他们的行为使得他们的决策看起来不那么随机",{"2":{"198":1}}],["他们专注于阈值单元",{"2":{"236":1}}],["他们在没有坦克的情况下拍摄了森林的航拍照片",{"2":{"186":1}}],["他们浪费了一大笔钱",{"2":{"185":1}}],["他们正在研究一种血液检测方法",{"2":{"185":1}}],["他们建议在计算后续层之前向网络的每一层注入噪声",{"2":{"170":1}}],["他将",{"2":{"475":1}}],["他将从均值为零的分布ϵ∼n",{"2":{"170":1}}],["他将高斯噪声添加到线性模型的输入中",{"2":{"170":1}}],["称为降维",{"2":{"1156":1}}],["称为聚类中心",{"2":{"1151":1}}],["称为簇",{"2":{"1150":1}}],["称为线性搜索",{"2":{"1111":1}}],["称为魔方阵或幻方",{"2":{"1090":1}}],["称为主对角线",{"2":{"1076":1}}],["称为全连接层",{"2":{"618":1}}],["称为权重",{"2":{"610":1}}],["称为特征",{"2":{"609":1}}],["称为标签",{"2":{"609":1}}],["称为样本空间",{"2":{"1027":1}}],["称为样本",{"2":{"609":1}}],["称为编码器",{"2":{"404":1}}],["称为k步预测",{"2":{"351":1}}],["称为内插法",{"2":{"345":1}}],["称为外推法",{"2":{"345":1}}],["称为循环层",{"2":{"340":1}}],["称为训练数据集",{"2":{"286":1}}],["称为隐藏表示",{"2":{"232":1}}],["称为卷积运算",{"2":{"130":1}}],["称这种情况为",{"2":{"170":1}}],["注入数据",{"2":{"1503":1}}],["注入噪声只会在输入",{"2":{"170":1}}],["注",{"2":{"1084":1,"1085":1,"1109":1,"1115":2,"1117":1,"1159":1,"1162":1,"1179":1,"1184":1,"1189":1}}],["注释机制",{"0":{"1314":1}}],["注释",{"2":{"981":1,"1314":1}}],["注释器通常在归档和标记之间有一年的延迟",{"2":{"292":1}}],["注意这个重要的内置关系",{"2":{"1499":1}}],["注意这是一个没有眼球的孩子",{"2":{"1098":1}}],["注意区分原生事件与自定义事件中的$event",{"2":{"1498":1}}],["注意区分好",{"2":{"1498":1}}],["注意点如下",{"2":{"1465":1}}],["注意点",{"2":{"1455":1,"1456":1,"1465":1}}],["注意到右边是求和",{"2":{"1093":1}}],["注意到有一种常见的误解认为环同步与其他同步算法在本质上是不同的",{"2":{"842":1}}],["注意到当列表中的其余部分还在计算时",{"2":{"797":3}}],["注意我们实现层的基础设计模式",{"2":{"472":1}}],["注意gpu的卡号是从0开始的",{"2":{"446":1}}],["注意一些关键细节",{"2":{"423":1}}],["注意两个全连接层都是model类的实例",{"2":{"422":1}}],["注意力和多层感知机",{"2":{"656":1}}],["注意力和基于位置的前馈网络",{"2":{"408":1}}],["注意力头数",{"2":{"409":1}}],["注意力中进行缩放点积计算和残差连接中进行加法计算",{"2":{"408":1}}],["注意力保留了自回归",{"2":{"404":1}}],["注意力输出和输入嵌入都连结为循环神经网络解码器的输入",{"2":{"375":1}}],["注意力",{"0":{"373":1},"1":{"374":1,"375":1,"376":1,"377":1,"378":1},"2":{"397":1,"408":1}}],["注意力权重α是使用",{"2":{"374":1}}],["注意力权重",{"2":{"369":1,"388":2}}],["注意力权重为1",{"2":{"357":1}}],["注意力汇聚可以分为非参数型和带参数型",{"2":{"393":1}}],["注意力汇聚的",{"2":{"388":1}}],["注意力汇聚的输出就是基于这些注意力权重的值的加权和",{"2":{"367":1}}],["注意力汇聚是yi的加权平均",{"2":{"388":1}}],["注意力汇聚有选择地聚合了值",{"2":{"385":1}}],["注意力汇聚",{"0":{"385":1},"1":{"386":1,"387":1,"388":1,"389":1,"390":1,"391":1,"392":1,"393":1,"394":1}}],["注意力汇聚输出的形状为",{"2":{"369":1}}],["注意力汇聚函数f就被表示成值的加权和",{"2":{"367":1}}],["注意力汇聚得到的是加权平均的总和值",{"2":{"357":1}}],["注意力评分函数的计算效率更高",{"2":{"371":1}}],["注意力评分函数",{"0":{"367":1},"1":{"368":1,"369":1,"370":1,"371":1,"372":1}}],["注意力的可视化",{"0":{"357":1}}],["注意力机制",{"0":{"379":1},"2":{"379":1}}],["注意力机制与全连接的层或汇聚层不同",{"2":{"358":1}}],["注意力机制与全连接层或者汇聚层的区别源于增加的自主提示",{"2":{"358":1}}],["注意力机制的设计有许多替代方案",{"2":{"356":1}}],["注意力机制通过注意力汇聚使选择偏向于值",{"2":{"358":1}}],["注意力机制通过注意力汇聚",{"2":{"356":1}}],["注意力机制解决了困扰统计学一个多世纪的问题",{"2":{"300":1}}],["注意力是否仍然产生相同的结果",{"2":{"372":1}}],["注意力是如何应用于视觉世界中的呢",{"2":{"355":1}}],["注意力是稀缺的",{"2":{"354":1}}],["注意力不是免费的",{"2":{"354":1}}],["注意力经济",{"2":{"354":1}}],["注意力提示",{"0":{"354":1},"1":{"355":1,"356":1,"357":1,"358":1,"359":1}}],["注意均匀分布u",{"2":{"247":1}}],["注意在添加隐藏层之后",{"2":{"232":1}}],["注意显示数据流的箭头方向主要是向右和向上的",{"2":{"163":1}}],["注意",{"0":{"674":1},"2":{"33":1,"73":1,"126":1,"154":1,"165":1,"208":1,"211":1,"217":2,"231":1,"235":2,"236":2,"237":1,"258":1,"269":1,"276":1,"277":1,"278":1,"325":1,"347":1,"350":3,"418":2,"422":5,"423":4,"425":2,"430":1,"431":1,"436":1,"445":1,"458":1,"502":1,"534":1,"573":1,"599":1,"602":1,"605":1,"631":1,"632":1,"646":1,"683":1,"699":1,"722":1,"725":1,"727":1,"743":1,"757":1,"784":1,"807":1,"821":1,"974":1,"981":2,"984":1,"990":1,"997":1,"998":3,"1012":1,"1017":1,"1027":1,"1117":1,"1451":3,"1454":3,"1455":1,"1463":1,"1492":1,"1501":1,"1503":1}}],["毕晓普证明了",{"2":{"170":1}}],["毕竟数学应该是逻辑自洽的",{"2":{"841":1}}],["毕竟没有线缆",{"2":{"812":1}}],["毕竟一部好电影需要更多的支持和认可",{"2":{"345":1}}],["毕竟ht是可以仅仅存储到目前为止观察到的所有数据",{"2":{"338":1}}],["毕竟我们使用的仍然是链式法则来计算梯度",{"2":{"306":1}}],["毕竟这是一场比赛",{"2":{"208":1}}],["毕竟",{"2":{"59":1,"88":1,"122":1,"253":1,"301":1,"308":1,"342":1,"345":1,"349":1,"417":1,"426":4,"442":1,"486":1,"804":1,"812":1,"832":1,"843":2}}],["毕竟rd中任意两点之间的线存在rd",{"2":{"40":1}}],["毕竟在这种情况下",{"2":{"26":1}}],["毕竟对大多数非凸问题来说",{"2":{"26":1}}],["克隆远程仓库",{"2":{"1327":1}}],["克隆仓库到本地",{"2":{"13":1}}],["克劳德",{"2":{"651":1}}],["克莱德定律",{"2":{"300":1}}],["克贝尔",{"2":{"299":1}}],["克里斯托弗",{"2":{"170":1}}],["好玩",{"2":{"1533":1}}],["好看",{"2":{"1533":1}}],["好像人的手臂",{"2":{"1154":1}}],["好吧",{"2":{"1129":1}}],["好比上图表示的有3个类别",{"2":{"1112":1}}],["好了它返回了我们用刚才写的代码创建的一个5x5的单位矩阵",{"2":{"1094":1}}],["好了",{"2":{"1061":1}}],["好让你的算法可以利用大量的特征",{"2":{"1060":1}}],["好的svm优化软件包总是会找到全局最小值",{"2":{"1148":1}}],["好的",{"2":{"1061":1,"1135":1,"1143":1,"1150":1}}],["好的方面",{"2":{"334":1}}],["好的一面是",{"2":{"297":1}}],["好极了",{"2":{"284":1}}],["好",{"2":{"170":2,"849":1}}],["扰动的稳健性",{"0":{"170":1}}],["扰动的程度不会改变",{"2":{"31":1}}],["尼日利亚",{"2":{"169":1}}],["带说明",{"2":{"1335":1}}],["带注释的完整",{"0":{"1315":1}}],["带来计算上的优势",{"2":{"1143":1}}],["带来的影响之一是我们需要保留中间值",{"2":{"165":1}}],["带入代价函数得到",{"2":{"1109":1}}],["带宽的大幅增加迫使计算机设计者将固态驱动器与pcie总线相连接",{"2":{"805":1}}],["带宽",{"2":{"803":1,"804":1,"812":1}}],["带掩码的二元交叉熵损失",{"2":{"765":2}}],["带全局语料统计的跳元模型",{"0":{"742":1}}],["带下标的b",{"2":{"641":1}}],["带下标的w",{"2":{"641":1}}],["带遮蔽的softmax交叉熵损失函数",{"2":{"575":4}}],["带填充以保持分辨率的卷积层",{"2":{"507":1}}],["带参数的层",{"0":{"414":1}}],["带参数的模型加入可学习的参数后",{"2":{"392":1}}],["带参数的注意力汇聚",{"2":{"391":1}}],["带参数注意力汇聚",{"0":{"389":1},"1":{"390":1,"391":1,"392":1}}],["带有注意力机制解码器的基本接口",{"2":{"375":2}}],["带有阶数d的项数迅速增加",{"2":{"269":1}}],["带有和带有不凸二次函数动量的梯度下降",{"2":{"94":1}}],["后台管理系统",{"2":{"1529":1}}],["后期项目上线",{"2":{"1476":1}}],["后来捐赠给",{"2":{"1374":1}}],["后来逐渐演进到支持",{"2":{"1350":1}}],["后两部则是动作片",{"2":{"1187":1}}],["后两个网络架构是如何显著减少模型参数大小的",{"2":{"491":1}}],["后续章节将讲到",{"2":{"998":1}}],["后续的讨论主要集中在经典的循环神经网络模型上",{"2":{"527":1}}],["后处理函数postprocess则将输出图像中的像素值还原回标准化之前的值",{"2":{"919":1}}],["后端能搭",{"2":{"1542":1}}],["后端",{"2":{"1347":1}}],["后端开发",{"2":{"1303":1}}],["后端可以通过自动化地并行计算和通信来提高性能",{"2":{"798":1}}],["后端必须能够跟踪计算图中各个步骤之间的依赖关系",{"2":{"790":3}}],["后端管理自己的线程",{"2":{"790":3}}],["后",{"2":{"727":1,"848":1,"1181":1}}],["后向",{"2":{"524":1}}],["后向递归也可以写为ρt−1=g",{"2":{"519":1}}],["后三个块各包含两个卷积层",{"2":{"508":1}}],["后面就讲",{"2":{"1478":1}}],["后面我们会看了一些视频后",{"2":{"1156":1}}],["后面我还讲介绍如何使用高级api并行训练网络",{"2":{"831":1}}],["后面",{"2":{"1061":1}}],["后面再加上用于空间下采样的最大汇聚层",{"2":{"507":1}}],["后面是两个1×1的卷积层",{"2":{"494":1}}],["后面的章节将通过一些实际的例子来回顾这些内容",{"2":{"1017":1}}],["后面的章节将介绍更多的数据预处理技术",{"2":{"1010":1}}],["后面的章节将讲到这点",{"2":{"992":1}}],["后面的章节内容将经常调用show",{"2":{"357":1}}],["后面的预测误差依此类推",{"2":{"351":1}}],["后者是模型的输出层",{"2":{"873":1}}],["后者是真实边界框相对于锚框的偏移量",{"2":{"850":1}}],["后者已经获得了命令式编程的扩展",{"2":{"817":1}}],["后者称为突发读取",{"2":{"802":1}}],["后者的速度要快得多",{"2":{"790":2}}],["后者有3",{"2":{"726":1}}],["后者则依赖于意识",{"2":{"358":1}}],["后者则关注在给定有限数据量的情况下寻找合适的模型",{"2":{"99":1}}],["后者可以保证来自两个相邻的小批量中的子序列在原始序列上也是相邻的",{"2":{"322":1}}],["后者会考得更好",{"2":{"252":1}}],["后将其参数相乘",{"2":{"164":1}}],["右边则是主要成分分析的误差",{"2":{"1158":1}}],["右边函数我称它为cost0",{"2":{"1143":1}}],["右边上部分是sigmod函数",{"2":{"1101":1}}],["右边是一只猫",{"2":{"857":1}}],["右半部分其实就是以",{"2":{"1100":1}}],["右图为0索引向量",{"2":{"1072":1}}],["右下角y",{"2":{"932":3}}],["右下角x",{"2":{"932":3}}],["右下y",{"2":{"858":1}}],["右下x",{"2":{"858":1}}],["右下",{"2":{"858":2,"859":1}}],["右",{"2":{"851":1}}],["右上角表示输出",{"2":{"163":1}}],["右侧一半",{"2":{"141":1}}],["左边的是线性回归的误差",{"2":{"1158":1}}],["左边的函数",{"2":{"1143":1}}],["左图为1索引向量",{"2":{"1072":1}}],["左右的价格卖掉这个房子",{"2":{"1063":1}}],["左右翻转图像",{"2":{"879":1}}],["左上角和右下角的",{"2":{"938":1}}],["左上角y",{"2":{"932":3}}],["左上角x",{"2":{"932":3}}],["左上y",{"2":{"858":2}}],["左上x",{"2":{"858":2}}],["左上",{"2":{"858":2,"859":1}}],["左",{"2":{"851":1}}],["左下角表示输入",{"2":{"163":1}}],["左侧大约一半",{"2":{"141":1}}],["样本和直观理解",{"2":{"1193":2}}],["样本和直观理解ii",{"0":{"1102":1}}],["样本i的轮廓系数",{"2":{"1154":1}}],["样本少的情况",{"2":{"1147":1}}],["样本",{"2":{"722":1,"723":1}}],["样本个数n",{"2":{"540":1}}],["样本由圆圈表示",{"2":{"386":1}}],["样本也可以指代输入特征",{"2":{"289":1}}],["样本有时也叫做数据点",{"2":{"284":1}}],["样本标签为y",{"2":{"162":1}}],["样本数n",{"2":{"521":1}}],["样本数量",{"2":{"263":3}}],["样本数与这层神经网络的维度一致",{"2":{"172":1}}],["样本数",{"2":{"137":3,"527":1,"635":4}}],["深层次",{"2":{"1456":1}}],["深层流水线和其他使cpu能够运行各种程序的功能",{"2":{"457":1}}],["深入",{"0":{"1307":1},"1":{"1308":1,"1309":1,"1310":1,"1311":1,"1312":1,"1313":1,"1314":1,"1315":1}}],["深入探讨反向传播的细节",{"2":{"161":1}}],["深刻理解",{"2":{"499":1}}],["深蓝公司利用大规模并行性",{"2":{"301":1}}],["深度循环神经网络需要大量的调参",{"2":{"530":1}}],["深度循环神经网络",{"0":{"526":1},"1":{"527":1,"528":1,"529":1,"530":1,"531":1}}],["深度卷积神经网络的突破出现在2012年",{"2":{"455":1}}],["深度卷积神经网络",{"0":{"454":1},"1":{"455":1,"456":1,"457":1,"458":1,"459":1,"460":1,"461":1,"462":1,"463":1,"464":1,"465":1}}],["深度",{"2":{"302":1}}],["深度强化学习",{"2":{"298":1}}],["深度网络的泛化性质令人费解",{"2":{"169":1}}],["深度神经网络学习图像特征级别抽象层次",{"2":{"915":1}}],["深度神经网络也有可能过拟合",{"2":{"169":1}}],["深度神经网络位于偏差",{"2":{"169":1}}],["深度学习存储和操作数据的主要接口是张量",{"2":{"1023":1}}],["深度学习一直是提高计算机视觉系统性能的变革力量",{"2":{"886":1}}],["深度学习都是更可取的统计建模范式",{"2":{"811":1}}],["深度学习就不会成功",{"2":{"811":1}}],["深度学习从业者喜欢绘制图表来可视化模型中正在发生的事情",{"2":{"618":1}}],["深度学习实践者很少会去花费大力气寻找这样一组参数",{"2":{"613":1}}],["深度学习对计算资源要求很高",{"2":{"457":1}}],["深度学习库已经演变成提供越来越粗糙的抽象",{"2":{"421":1}}],["深度学习计算",{"0":{"421":1}}],["深度学习成功背后的一个因素是神经网络的灵活性",{"2":{"412":1}}],["深度学习不仅取代了传统机器学习的浅层模型",{"2":{"303":1}}],["深度学习社区引以为豪的是",{"2":{"302":1}}],["深度学习消除了以前分隔计算机视觉",{"2":{"302":1}}],["深度学习方法中最显著的共同点是使用端到端训练",{"2":{"302":1}}],["深度学习是关于优化的学习",{"2":{"987":1}}],["深度学习是通过学习多层次的转换来进行的多层次的表示学习",{"2":{"303":1}}],["深度学习是",{"2":{"302":1}}],["深度学习是一套强大的技术",{"2":{"281":1}}],["深度学习主要应用于这些问题的计算机视觉方面",{"2":{"301":1}}],["深度学习提供了强大的工具",{"2":{"299":1}}],["深度学习与经典方法的区别主要在于",{"2":{"285":1}}],["深度学习目前的生机要归功于",{"2":{"260":1}}],["深度学习只有在有数千个训练样本时才优于线性模型",{"2":{"260":1}}],["深度学习框架可以自动计算导数",{"2":{"978":1}}],["深度学习框架可以将python前端的控制与后端的执行解耦",{"2":{"793":1}}],["深度学习框架通过自动计算导数",{"2":{"973":1}}],["深度学习框架通常有预定义的方法来初始化参数",{"2":{"592":1}}],["深度学习框架通常实现十几种不同的启发式方法",{"2":{"248":1}}],["深度学习框架的高级api提供了在imagenet数据集上预训练的各种模型",{"2":{"905":1}}],["深度学习框架的高级api提供了循环神经网络层的实现",{"2":{"327":1}}],["深度学习框架",{"2":{"795":1}}],["深度学习框架在这些著名的技巧之外采取了额外的预防措施",{"2":{"627":1}}],["深度学习框架在传播思想方面发挥了至关重要的作用",{"2":{"300":1}}],["深度学习框架中的批量规范化api将为我们解决上述问题",{"2":{"472":1}}],["深度学习框架中的步幅与汇聚窗口的大小相同",{"2":{"147":1}}],["深度学习框架要求计算的所有输入数据都在同一设备上",{"2":{"452":1}}],["深度学习框架提供了许多不同的图像增广方法",{"2":{"884":1}}],["深度学习框架提供了内置函数来保存和加载整个网络",{"2":{"442":1}}],["深度学习框架提供默认随机初始化",{"2":{"434":1}}],["深度学习框架没有提供我们需要的初始化方法",{"2":{"436":1}}],["深度学习框架无法判断网络的输入维度是什么",{"2":{"417":1}}],["深度学习框架为了便于我们使用权重衰减",{"2":{"278":1}}],["深度学习的计算量非常大",{"2":{"809":1}}],["深度学习的一个关键优势是它不仅取代了传统学习管道末端的浅层模型",{"2":{"302":1}}],["深度学习的一个主要优势是可以处理不同长度的数据",{"2":{"284":1}}],["深度学习的成功案例",{"0":{"301":1}}],["深度学习的发展",{"0":{"300":1}}],["深度学习的优化充满挑战",{"2":{"103":1}}],["深度学习的动量一直被认为是有益的",{"2":{"86":1}}],["深度学习模型的目标函数通常有许多局部最优解",{"2":{"101":1}}],["深度学习优化存在许多挑战",{"2":{"100":1}}],["深度学习",{"2":{"99":1,"1297":1}}],["深度学习中更经常地使用l2范数的平方",{"2":{"1000":1}}],["深度学习中",{"2":{"287":1,"975":1}}],["深度学习中有许多启发式的技术旨在防止过拟合",{"2":{"253":1}}],["深度学习中的许多操作需要相对较高的内存带宽",{"2":{"457":1}}],["深度学习中的优化挑战",{"0":{"100":1},"1":{"101":1,"102":1,"103":1}}],["深度学习中的问题是在凸集上定义的",{"2":{"40":1}}],["深度学习中出现的几乎所有优化问题都是非凸的",{"2":{"65":1}}],["学一些新的东西",{"2":{"1176":1}}],["学术等领域建立许多高性能的机器学习系统",{"2":{"1148":1}}],["学术论文也不得不分配大量页面来推导更新规则",{"2":{"161":1}}],["学着做微积分",{"2":{"1098":1}}],["学会处理我们的触觉",{"2":{"1098":1}}],["学生能够更快更好地学习并掌握这些算法",{"2":{"1088":1}}],["学生可能试图通过死记硬背考题的答案来做准备",{"2":{"252":1}}],["学者和业余爱好者开发了各种成熟的开源框架",{"2":{"588":1}}],["学者们研究了一些特殊情况下的强化学习问题",{"2":{"298":1}}],["学习成本较高",{"2":{"1530":1}}],["学习成本低",{"2":{"1351":1}}],["学习建议",{"0":{"1436":1}}],["学习笔记",{"0":{"1316":1,"1338":1,"1373":1,"1396":1},"1":{"1317":1,"1318":1,"1319":1,"1320":1,"1321":1,"1322":1,"1323":1,"1324":1,"1325":1,"1326":1,"1327":1,"1328":1,"1329":1,"1330":1,"1331":1,"1332":1,"1333":1,"1334":1,"1335":1,"1336":1,"1337":1,"1339":1,"1340":1,"1341":1,"1342":1,"1343":1,"1344":1,"1345":1,"1346":1,"1347":1,"1348":1,"1349":1,"1350":1,"1351":1,"1374":1,"1375":1,"1376":1,"1377":1,"1378":1,"1379":1,"1380":1,"1381":1,"1382":1,"1383":1,"1384":1,"1385":1,"1386":1,"1387":1,"1388":1,"1389":1,"1390":1,"1391":1,"1392":1,"1393":1,"1394":1,"1395":1,"1397":1,"1398":1,"1399":1,"1400":1,"1401":1,"1402":1,"1403":1,"1404":1,"1405":1,"1406":1,"1407":1,"1408":1,"1409":1,"1410":1,"1411":1,"1412":1,"1413":1,"1414":1,"1415":1,"1416":1,"1417":1,"1418":1,"1419":1,"1420":1,"1421":1,"1422":1,"1423":1,"1424":1,"1425":1,"1426":1,"1427":1,"1428":1,"1429":1,"1430":1,"1431":1,"1432":1,"1433":1,"1434":1,"1435":1,"1436":1}}],["学习更加复杂",{"2":{"1143":1}}],["学习曲线陡峭",{"2":{"1351":1}}],["学习曲线是将训练集误差和交叉验证集误差作为训练集样本数量",{"2":{"1134":1}}],["学习曲线是学习算法的一个很好的合理检验",{"2":{"1134":1}}],["学习曲线就是一种很好的工具",{"2":{"1134":1}}],["学习曲线",{"0":{"1134":1},"2":{"1193":1}}],["学习可以更加高速",{"2":{"1061":1}}],["学习算法的工作了",{"2":{"1063":1}}],["学习算法还广泛用于自定制程序",{"2":{"1058":1}}],["学习算法需要输出有序的元素子集",{"2":{"293":1}}],["学习速率和批量大小作为输入",{"2":{"604":1}}],["学习另一层作为恒等映射",{"2":{"504":1}}],["学习嵌套函数",{"2":{"504":1}}],["学习表征",{"0":{"455":1},"1":{"456":1,"457":1}}],["学习语言模型",{"0":{"316":1}}],["学习预测不相互排斥的类别的问题称为多标签分类",{"2":{"292":1}}],["学习到的参数c",{"2":{"1143":1}}],["学习到的模型参数也接近真实值w=",{"2":{"264":1}}],["学习到一个分类器是不可能的",{"2":{"180":1}}],["学习数据",{"2":{"196":1}}],["学习问题的分类法",{"0":{"194":1},"1":{"195":1,"196":1,"197":1,"198":1,"199":1,"200":1}}],["学习的卷积核k",{"2":{"130":1}}],["学习由x生成y的卷积核",{"2":{"129":1}}],["学习卷积核时",{"2":{"132":1}}],["学习卷积核",{"0":{"129":1}}],["学习率也需要稍微提高一些",{"2":{"838":1}}],["学习率是0",{"2":{"837":1}}],["学习率有多高",{"2":{"477":1}}],["学习率等",{"2":{"337":1}}],["学习率设置为多少会带来最好的结果",{"2":{"223":1}}],["学习率调度的任何功能都处于休眠状态",{"2":{"113":1}}],["学习率调度器",{"0":{"66":1,"68":1},"1":{"67":1,"68":1,"69":1,"70":1,"71":1,"72":1,"73":1,"74":1,"75":1}}],["学习率需要由实验者调度",{"2":{"110":1}}],["学习率需要更慢地降低",{"2":{"30":1}}],["学习率太小会没有进展",{"2":{"63":1}}],["学习率太大会使模型发散",{"2":{"63":1}}],["学习率的值在t∈",{"2":{"72":1}}],["学习率的大小很重要",{"2":{"63":1,"66":1}}],["学习率的降低可能相当剧烈",{"2":{"27":1}}],["学习率η可由算法设计者设置",{"2":{"55":1}}],["学习率",{"0":{"55":1,"1083":1},"2":{"55":1,"129":4,"223":1,"1193":1}}],["学习率要么对于常见特征而言降低太慢",{"2":{"25":1}}],["学习",{"2":{"25":1,"282":3,"286":1,"304":1}}],["绿线的预测显然并不理想",{"2":{"351":1}}],["绿",{"2":{"284":1,"1061":1}}],["绿色和蓝色",{"2":{"158":1,"993":1}}],["绿和蓝",{"2":{"119":1,"872":1}}],["测量两个人是否具有完全相同的身高没有太大意义",{"2":{"1028":1}}],["测量通过以太网发送消息时的数据包开销",{"2":{"815":1}}],["测量waitall和wait",{"2":{"794":1}}],["测量同时在两个gpu上执行两个矩阵乘法与在一个gpu上按顺序执行两个矩阵乘法所需的时间",{"2":{"453":1}}],["测量计算1000个100×100矩阵的矩阵乘法所需的时间",{"2":{"453":1}}],["测量f和g之间的重叠",{"2":{"156":1}}],["测试环境",{"2":{"1349":1}}],["测试环境还是云端",{"2":{"1339":1}}],["测试时",{"2":{"903":1}}],["测试集评估在通过训练集让我们的模型学习得出其参数后",{"2":{"1130":1}}],["测试集包含300000张图像",{"2":{"888":1}}],["测试集约有10000对",{"2":{"667":1}}],["测试精度",{"2":{"828":3,"837":3}}],["测试按顺序访问或按给定步幅访问内存时的速度差异",{"2":{"815":1}}],["测试fasttext结果",{"2":{"753":1}}],["测试样本数",{"2":{"386":4}}],["测试样本的真实输出",{"2":{"386":4}}],["测试样本",{"2":{"386":4}}],["测试",{"2":{"382":1,"1035":1}}],["测试bahdanau注意力解码器",{"2":{"375":1}}],["测试性能可能会显著偏离训练性能",{"2":{"286":1}}],["测试分布",{"2":{"191":1}}],["测试数据集中的图像大小和形状各异",{"2":{"866":1}}],["测试数据集不会用于训练",{"2":{"582":1}}],["测试数据集用于评估拟合的模型",{"2":{"286":1}}],["测试数据",{"2":{"186":1}}],["测试dropout",{"2":{"172":1}}],["测试准确度方面的进展停滞时",{"2":{"67":1}}],["亦或简单地称之为该卷积层的权重",{"2":{"155":1}}],["应尽可能大",{"2":{"1154":1}}],["应尽可能小",{"2":{"1154":1}}],["应当远大于0",{"2":{"1143":1}}],["应用配置",{"2":{"1392":1}}],["应用与依赖打包在镜像中",{"2":{"1354":1}}],["应用方向",{"2":{"1297":1}}],["应用所学的机器学习工具",{"2":{"1176":1}}],["应用实例",{"0":{"1170":1},"1":{"1171":1,"1172":1,"1173":1,"1174":1},"2":{"1193":1}}],["应用这种方法",{"2":{"1167":1}}],["应用这些算法时",{"2":{"1143":1}}],["应用它们建立一个复杂的非线性分类器",{"2":{"1145":1}}],["应用机器学习的建议",{"2":{"1128":1,"1193":1}}],["应用得非常广泛",{"2":{"1098":1}}],["应用刚刚学到的算法",{"2":{"1069":1}}],["应用场景",{"0":{"1053":1},"2":{"1515":1}}],["应用示例",{"0":{"1048":1}}],["应用图像增广的原因是",{"2":{"877":1}}],["应用逆偏移变换来返回预测的边界框坐标",{"2":{"854":1}}],["应用的末端有wifi",{"2":{"812":1}}],["应用词嵌入",{"0":{"768":1}}],["应用预训练词向量",{"0":{"749":1},"1":{"750":1,"751":1}}],["应用",{"0":{"663":1,"1035":1},"2":{"1529":1,"1543":1,"1548":1}}],["应用于个人知识管理",{"2":{"1054":1}}],["应用于目标检测",{"2":{"935":1}}],["应用于不同自然语言处理任务",{"2":{"754":1}}],["应用于天文学研究",{"2":{"616":1}}],["应用于fashion",{"2":{"135":1}}],["应用relu非线性函数之前",{"2":{"501":1}}],["应用一个全连接层",{"2":{"494":1}}],["应用densenet的思想设计一个基于多层感知机的模型",{"2":{"485":1}}],["应用batchnorm",{"2":{"473":1}}],["应用标准化后",{"2":{"467":1}}],["应用反向传播来计算和存储梯度",{"2":{"306":1}}],["应用和算法方面的进展就像寒武纪大爆发",{"2":{"300":1}}],["应用程序的",{"2":{"1040":1,"1042":1}}],["应用程序会向购物车数据库表中添加一个条目",{"2":{"281":1}}],["应用程序与数据库引擎进行交互",{"2":{"281":1}}],["应该能回到这个压缩表示",{"2":{"1161":1}}],["应该如何处理",{"2":{"1114":1}}],["应该很简单",{"2":{"999":1}}],["应该对此很熟悉",{"2":{"992":1}}],["应该使用kaggle竞赛的完整数据集",{"2":{"890":1}}],["应该使用transformer的编码器还是解码器",{"2":{"411":1}}],["应该强调的是",{"2":{"743":1}}],["应该被标记为",{"2":{"659":1}}],["应该知道实现softmax回归的细节",{"2":{"629":1}}],["应该是最大化",{"2":{"513":1}}],["应该看到近乎线性的缩放",{"2":{"453":1}}],["应该注意的是",{"2":{"446":2}}],["应该比解释p",{"2":{"349":1}}],["应该以简单的模型为目标",{"2":{"170":1}}],["应该仅导致隐藏表示h中的平移",{"2":{"154":1}}],["处的代价值",{"2":{"1124":1}}],["处的像素值",{"2":{"153":1,"924":1}}],["处的像素",{"2":{"153":1}}],["处和",{"2":{"1124":1}}],["处像素的强度是否总是增加",{"2":{"230":1}}],["处理错误",{"2":{"1471":1}}],["处理连接的相关配置",{"2":{"1365":1}}],["处理",{"2":{"1297":1}}],["处理音频的库",{"2":{"1061":1}}],["处理多个随机变量",{"0":{"1029":1},"1":{"1030":1,"1031":1,"1032":1,"1033":1,"1034":1,"1035":1}}],["处理缺失值",{"0":{"1012":1}}],["处理矩形输入",{"2":{"848":3}}],["处理器拥有的数量",{"2":{"812":1}}],["处理器0需要停止它正在做的事情",{"2":{"810":1}}],["处理器还可以在分支指令中同时执行多条代码路径",{"2":{"808":1}}],["处理器核心中添加向量处理单元可以显著提高吞吐量",{"2":{"811":1}}],["处理器核心",{"2":{"807":1}}],["处理器能够执行的操作远比主内存接口所能提供的多得多",{"2":{"77":1}}],["处理合理大小的",{"2":{"600":1}}],["处理序列数据需要统计工具和新的深度神经网络架构",{"2":{"346":1}}],["处理非凸非线性优化问题",{"2":{"302":1}}],["处理这一问题的一种方法是对我们的数据进行预处理",{"2":{"230":1}}],["处理离散值",{"2":{"209":1}}],["处理单个观测值需要我们执行许多单一矩阵",{"2":{"78":1}}],["原理如下",{"2":{"1502":1}}],["原生事件",{"2":{"1498":2}}],["原生支持分布式",{"2":{"1205":1}}],["原神",{"2":{"1456":1,"1457":1}}],["原来写在methods中",{"2":{"1451":1}}],["原来写在data中",{"2":{"1451":1}}],["原高斯分布模型被广泛使用着",{"2":{"1184":1}}],["原高斯分布模型",{"2":{"1184":1}}],["原高斯分布模型和多元高斯分布模型的比较",{"2":{"1184":1}}],["原本的高斯分布模型是多元高斯分布模型的一个子集",{"2":{"1184":1}}],["原版的alexnet采用了双数据流设计",{"2":{"459":1}}],["原料",{"2":{"295":1}}],["原因在于主要成分分析只是近似地丢弃掉一些特征",{"2":{"1162":1}}],["原因是各个特征之间通常情况存在某种相关性",{"2":{"1160":1}}],["原因是",{"2":{"1058":1,"1148":1}}],["原因有两个",{"2":{"1021":1}}],["原因有很多",{"2":{"318":1}}],["原因其实很简单",{"2":{"457":1}}],["原因如下",{"2":{"316":1}}],["原因可能各不相同",{"2":{"281":1}}],["原因很简单",{"2":{"232":1,"251":1}}],["原始对象",{"2":{"1518":1}}],["原始类型",{"2":{"1404":1}}],["原始模型和多元高斯分布比较如图",{"2":{"1185":1}}],["原始模型与多元高斯模型的关系如图",{"2":{"1185":1}}],["原始特征只是输入层",{"2":{"1101":1}}],["原始数据集还包含表示稀有",{"2":{"772":1}}],["原始数据集中的每个样本都是28×28的图像",{"2":{"630":1}}],["原始bert",{"2":{"726":1}}],["原始bert模型的两个版本分别带有1",{"2":{"656":1}}],["原始的数字是取自于杰夫迪恩的stanford讲座",{"2":{"800":1}}],["原始的bert已经在图书语料库",{"2":{"737":1}}],["原始的bert有两个版本",{"2":{"728":1}}],["原始的bert模型有数以亿计的参数",{"2":{"686":1}}],["原始的bert模型是在更大的语料库上预训练的",{"2":{"686":1}}],["原始的snli数据集包含的信息比我们在实验中真正需要的信息丰富得多",{"2":{"667":1}}],["原始的输出序列",{"2":{"576":1}}],["原始论文使用pn1",{"2":{"578":1}}],["原始文本数据需要经过",{"2":{"565":1}}],["原始vgg网络有5个卷积块",{"2":{"508":1}}],["原始训练数据被分成k个不重叠的子集",{"2":{"257":1}}],["原始图像的边界丢失了许多有用信息",{"2":{"140":1}}],["原则上说",{"2":{"578":1}}],["原则上",{"2":{"256":1,"349":1}}],["原则",{"2":{"152":1}}],["平方误差代价函数",{"2":{"1069":1}}],["平方误差函数的两个输入均为extract",{"2":{"922":1}}],["平方误差可以定义为以下公式",{"2":{"611":1}}],["平方英尺",{"2":{"609":1}}],["平方损失",{"2":{"350":3}}],["平方可和的",{"2":{"156":1}}],["平移不变性",{"0":{"154":1},"2":{"152":2,"154":1}}],["平均寿命等",{"2":{"1157":1}}],["平均汇聚忽略了输入xi",{"2":{"388":1}}],["平均汇聚",{"0":{"387":1}}],["平均汇聚层可以被视为输入的加权平均值",{"2":{"357":1}}],["平均汇聚层会输出该窗口内的平均值",{"2":{"149":1}}],["平均验证log",{"2":{"212":1}}],["平均训练log",{"2":{"212":1}}],["平均而言",{"2":{"113":1}}],["扫描图像",{"2":{"152":1}}],["沃尔多",{"2":{"157":1}}],["沃尔多检测器",{"2":{"152":1}}],["沃尔多在哪里",{"0":{"157":1},"1":{"158":1},"2":{"152":1,"157":1}}],["读读开源项目的实现",{"2":{"1549":1}}],["读操作",{"2":{"1209":1}}],["读",{"2":{"1200":1}}],["读出",{"2":{"569":1}}],["读写文件",{"0":{"440":1},"1":{"441":1,"442":1,"443":1,"444":1}}],["读者可能已经注意到mxnet张量看起来与numpy的ndarray几乎相同",{"2":{"445":1}}],["读者可能会开始担心操作效率的问题",{"2":{"426":3}}],["读者可能会好奇为什么每个module都有一个",{"2":{"424":1}}],["读者可能会好奇为什么每个gluon中的block都有一个",{"2":{"424":1}}],["读者的目标就是找出他",{"2":{"152":1}}],["读取",{"2":{"961":1,"1460":1}}],["读取所有voc图像并标注",{"2":{"945":3}}],["读取一个小批量",{"2":{"932":1}}],["读取一小批量数据",{"2":{"583":1}}],["读取香蕉检测数据集中的图像和标签",{"2":{"932":3}}],["读取香蕉检测数据集",{"2":{"932":1}}],["读取由原始图像组成的数据集",{"2":{"892":1}}],["读取fname来给标签字典返回一个文件名",{"2":{"890":1}}],["读取并将它们转换为张量格式",{"2":{"887":1}}],["读取图像x",{"2":{"863":1}}],["读取imdb评论数据集文本序列和标签",{"2":{"692":1}}],["读取训练和测试数据集",{"2":{"692":1}}],["读取第一个小批量数据样本并打印",{"2":{"600":1}}],["读取小批量",{"0":{"583":1}}],["读取长序列的主要方式是随机采样和顺序分区",{"2":{"322":1}}],["读取长序列数据",{"0":{"319":1},"1":{"320":1,"321":1}}],["读取每个小批量的子序列的特征x和标签y",{"2":{"321":1}}],["读取数据集和初始化",{"0":{"961":1}}],["读取数据集",{"0":{"79":1,"361":1,"462":1,"582":1,"590":1,"600":1,"667":1,"679":1,"692":1,"772":1,"864":1,"892":1,"904":1,"932":1,"948":1,"1011":1}}],["读音上听起来非常相似",{"2":{"315":1}}],["猪通常不在天上飞",{"2":{"152":1}}],["理解如下",{"2":{"1122":1}}],["理解这些步骤究竟是在做什么",{"2":{"1122":1}}],["理解这段代码至关重要",{"2":{"605":1}}],["理解",{"2":{"315":1,"1508":1}}],["理解泛化性也是一个困难的问题",{"2":{"253":1}}],["理想情况下",{"2":{"152":1,"282":1,"1110":1}}],["理论上也可以在逻辑回归中使用核函数",{"2":{"1147":1}}],["理论上来说",{"2":{"1109":1}}],["理论上这很容易",{"2":{"26":1}}],["理论分析",{"0":{"93":1},"1":{"94":1,"95":1}}],["想出一堆方法来试试",{"2":{"1137":1}}],["想出一个符合规范的程序才是最困难的部分",{"2":{"233":1}}],["想更加高产的话",{"2":{"1061":1}}],["想知道前端开发有多酷吗",{"2":{"1532":1}}],["想知道看到1的几率有多大",{"2":{"1026":1}}],["想知道如何操作可参考horovod",{"2":{"841":1}}],["想要通过画出假设函数来进行观察",{"2":{"1130":1}}],["想要通过矩阵相乘来实现它",{"2":{"970":1}}],["想要深入学习数学内容",{"2":{"1017":1}}],["想要训练这个模型将不可实现",{"2":{"151":1}}],["想了解详细信息可以参见",{"2":{"841":1}}],["想象成",{"2":{"1040":1,"1042":1}}],["想象为",{"2":{"652":1}}],["想象一个561×728的输入图像",{"2":{"911":1}}],["想象一个球在一个盒子里",{"2":{"48":1}}],["想象一下你正站立在山的这一点上",{"2":{"1067":1}}],["想象一下有人正在看网飞",{"2":{"345":1}}],["想象一下",{"2":{"152":1,"244":1,"281":1,"284":1,"355":1,"395":1,"651":1,"937":1,"976":1,"1059":1,"1060":2}}],["想法则与众不同",{"2":{"455":1}}],["想一想读取长序列数据的其他方法",{"2":{"323":1}}],["想一想这意味着什么",{"2":{"169":1}}],["层级不深",{"2":{"1458":1}}],["层关系",{"0":{"1203":1}}],["层时的权重的矩阵",{"2":{"1099":1}}],["层映射到第$",{"2":{"1099":1}}],["层的激活单元数决定",{"2":{"1120":1}}],["层的激活单元数加一为列数的矩阵",{"2":{"1099":1}}],["层的第",{"2":{"1099":1,"1121":1,"1122":1}}],["层的执行顺序是作为参数传递的",{"2":{"422":3}}],["层序softmax",{"0":{"709":1},"2":{"709":1}}],["层组成的小多层感知机中",{"2":{"657":1}}],["层组以各种重复模式排列的类似架构现在也是普遍存在",{"2":{"422":1}}],["层和块的顺序连接由sequential块处理",{"2":{"427":1}}],["层和块",{"0":{"422":1},"1":{"423":1,"424":1,"425":1,"426":1,"427":1,"428":1}}],["层可以有局部参数",{"2":{"415":1}}],["层规范化",{"2":{"406":1}}],["层规范化和批量规范化的目标相同",{"2":{"406":1}}],["层次结构相关性可能取决于模型的使用者计划如何使用模型",{"2":{"291":1}}],["层次结构假定在许多类之间存在某种关系",{"2":{"291":1}}],["层数和训练迭代周期",{"2":{"251":1}}],["层",{"2":{"145":1,"215":1,"302":1,"404":1,"422":1,"617":1,"1203":1,"1205":3}}],["聚簇中正确分类的样本数占该聚簇总样本数的比例和",{"2":{"1154":1}}],["聚合的nvlink带宽明显高于pcie带宽",{"2":{"842":1}}],["聚合梯度所花费的时间不会增加",{"2":{"842":1}}],["聚合梯度的时间随节点数线性增长",{"2":{"842":1}}],["聚合梯度被重新分发到每个gpu中",{"2":{"833":1}}],["聚合梯度",{"2":{"828":1}}],["聚合梯度将减小步长大小",{"2":{"88":1}}],["聚合步骤在以下aggregate类中定义",{"2":{"676":1}}],["聚合",{"0":{"676":1},"2":{"1203":1}}],["聚类的衡量指标",{"2":{"1154":1}}],["聚类参考资料",{"2":{"1154":1}}],["聚类后我们制造的t",{"2":{"1154":1}}],["聚类只是无监督学习中的一种",{"2":{"1061":1}}],["聚类算法和无监督学习算法同样还用在很多其它的问题上",{"2":{"1061":1}}],["聚类应用的一个例子就是在谷歌新闻中",{"2":{"1061":1}}],["聚类",{"2":{"296":1,"1149":1,"1193":1}}],["聚集信息",{"2":{"145":1}}],["着色部分是输出元素以及用于输出计算的输入和内核张量元素",{"2":{"142":1}}],["行存储",{"2":{"1205":1}}],["行的第",{"2":{"1080":1}}],["行第",{"2":{"1077":2}}],["行列数相等的可以加",{"2":{"1073":1}}],["行动和反馈能力的智能系统",{"2":{"1050":1}}],["行人",{"2":{"857":1}}],["行为会如何改变",{"2":{"477":1}}],["行为的组织",{"2":{"299":1}}],["行代表词元在序列中的位置",{"2":{"398":1}}],["行",{"2":{"141":2,"1077":1,"1088":2}}],["非线性的函数",{"2":{"1143":1}}],["非线性假设",{"0":{"1097":1},"2":{"1193":1}}],["非线性激活函数",{"2":{"507":1}}],["非线性激活函数和汇聚层",{"2":{"138":1}}],["非正式地说",{"2":{"1000":1}}],["非降维求和",{"0":{"996":1}}],["非标量变量的反向传播",{"0":{"975":1}}],["非最大限度的抑制可以被学习吗",{"2":{"856":1}}],["非极大值抑制是一种贪心算法",{"2":{"856":1}}],["非易失性内存增强",{"2":{"805":1}}],["非本句",{"2":{"512":1}}],["非模型参数的变量初始化为0和1",{"2":{"472":3}}],["非挤压激活函数和有效的正则化技术",{"2":{"454":1}}],["非参数的nadaraya",{"2":{"389":1}}],["非参数的注意力汇聚",{"2":{"388":1}}],["非参数注意力汇聚",{"0":{"388":1}}],["非自主提示",{"2":{"385":1}}],["非自主性提示和感官输入又是什么",{"2":{"359":1}}],["非自主性提示",{"2":{"356":1,"358":1}}],["非自主性提示是基于环境中物体的突出性和易见性",{"2":{"355":1}}],["非常的不同",{"2":{"1182":1}}],["非常难",{"2":{"1182":1}}],["非常难决定应该在哪一项上花费时间和精力",{"2":{"1137":1}}],["非常少量的正向类",{"2":{"1182":1}}],["非常小的情形",{"2":{"1144":1}}],["非常多的网络的新闻内容",{"2":{"1061":1}}],["非常好",{"2":{"1058":1}}],["非常适合构建可扩展",{"2":{"1047":1}}],["非常简单",{"2":{"1021":1}}],["非常容易使用",{"2":{"812":1}}],["非常",{"2":{"518":1}}],["非常不同",{"2":{"475":1}}],["非常强大",{"2":{"299":1}}],["非常昂贵",{"2":{"299":1}}],["非常有效",{"2":{"186":1}}],["非平稳分布",{"0":{"187":1},"2":{"187":1}}],["非凸函数",{"2":{"41":2}}],["检出仓库代码",{"2":{"1315":1}}],["检验时",{"2":{"1124":1}}],["检查",{"2":{"1544":1}}],["检查镜像",{"2":{"1340":1}}],["检查类型",{"2":{"1259":1}}],["检查骰子的唯一方法是多次投掷并记录结果",{"2":{"1026":1}}],["检查参数是否不同",{"2":{"437":1}}],["检查参数是否相同",{"2":{"437":3}}],["检查均值是否为0",{"2":{"413":1}}],["检查输出是否具有正确的形状",{"2":{"332":1}}],["检查模型",{"2":{"136":1}}],["检测数据中心的计算机运行状况",{"2":{"1182":1}}],["检测器最终可以学会",{"2":{"282":1}}],["检测图像中不同颜色的边缘",{"2":{"128":1}}],["黑线看起来是更稳健的决策界",{"2":{"1144":1}}],["黑白",{"2":{"136":1}}],["黑色皮肤的人群",{"2":{"284":1}}],["黑色",{"2":{"50":2}}],["总是可以",{"2":{"1137":1}}],["总是预测类1的模型将产生13的误差",{"2":{"252":1}}],["总结一份",{"2":{"1547":1}}],["总结一下这段视频",{"2":{"1091":1}}],["总结一下",{"2":{"237":1,"613":1,"1085":1,"1138":1,"1191":1}}],["总结和致谢",{"0":{"1176":1},"2":{"1193":1}}],["总结",{"0":{"1175":1,"1211":1,"1294":1,"1513":1,"1531":1},"1":{"1176":1},"2":{"1193":1,"1444":1}}],["总结下",{"2":{"1167":1}}],["总结下本视频内容",{"2":{"1061":1}}],["总共需要80毫秒",{"2":{"841":1}}],["总共产生1000个点",{"2":{"350":2}}],["总线依赖着这个内置关系",{"2":{"1499":1}}],["总线会因为处理器型号",{"2":{"807":1}}],["总线",{"2":{"807":1}}],["总带宽高达100gb",{"2":{"801":1}}],["总执行时间小于两个部分执行时间的总和",{"2":{"796":1}}],["总体而言",{"2":{"530":1,"832":1}}],["总体来看",{"2":{"136":1}}],["总之这个图示有助于你理解支持向量机模型的做法",{"2":{"1144":1}}],["总之是",{"2":{"1143":1}}],["总之当你发现的矩阵x",{"2":{"1086":1}}],["总之",{"2":{"354":1,"451":1,"542":1,"573":1,"574":1,"734":1,"789":1,"802":1,"1086":1,"1112":1,"1145":1}}],["总的来说",{"2":{"294":1,"802":1}}],["总预测的数量",{"2":{"137":3}}],["总而言之",{"2":{"77":1,"179":1,"282":1,"290":1,"397":1,"535":1}}],["成员",{"2":{"1425":1}}],["成员运算符",{"0":{"1221":1}}],["成员等",{"2":{"1217":1}}],["成员变量output的参数是随机初始化的",{"2":{"873":1}}],["成功预测有恶性肿瘤的病人的百分比",{"2":{"1139":1,"1140":1}}],["成功地捕捉了作者的喜好",{"2":{"294":1}}],["成本",{"2":{"812":1}}],["成长和社交",{"2":{"354":1}}],["成为一个更加通用的注意力汇聚",{"2":{"388":1}}],["成为一个长度为`batch",{"2":{"275":1}}],["成为一个长度为batch",{"2":{"275":3}}],["成为监督学习的主流方法",{"2":{"135":1}}],["成立",{"2":{"60":1,"655":1}}],["性能与体验",{"2":{"1543":1}}],["性能飞升",{"2":{"1540":1}}],["性能的提升",{"0":{"1438":1}}],["性能优化实践",{"0":{"1371":1}}],["性能远超",{"2":{"1363":1}}],["性能度量值p呢",{"2":{"1059":1}}],["性能相媲美的成果",{"2":{"135":1}}],["性别或年龄偏见",{"2":{"301":1}}],["性质",{"0":{"43":1},"1":{"44":1,"45":1,"46":1}}],["目录结构",{"2":{"1320":1}}],["目录中",{"2":{"1094":1}}],["目测比那些硅谷工程师还厉害",{"2":{"1117":1}}],["目的是",{"2":{"1500":1}}],["目的是寻找表示本身",{"2":{"302":1}}],["目的是识别图像",{"2":{"135":1}}],["目前是4版本",{"2":{"1474":1}}],["目前vue",{"2":{"1443":1}}],["目前事实上的容器编排标准",{"2":{"1355":1}}],["目前大家对机器学习算法可能还只是略懂",{"2":{"1117":1}}],["目前存在几种不同类型的学习算法",{"2":{"1059":1}}],["目前还不清楚研究是否能在特定问题上实现良好的线性缩放",{"2":{"832":1}}],["目前还不存在能够自我改进",{"2":{"301":1}}],["目前为止",{"2":{"816":1,"1080":1,"1148":1}}],["目前resnet架构仍然是许多视觉任务的首选架构",{"2":{"422":1}}],["目前只需要知道的是",{"2":{"397":1}}],["目前",{"2":{"253":1,"254":1,"301":1,"802":1,"1143":1}}],["目标地点以及特定的用户数据",{"2":{"1168":1}}],["目标规划",{"2":{"1052":1}}],["目标导向性",{"2":{"1050":1}}],["目标的类别数为1",{"2":{"961":1}}],["目标模型的输出层需要从头开始训练",{"2":{"875":1}}],["目标模型从源模型中复制所有模型设计及其参数",{"2":{"875":1}}],["目标模型finetune",{"2":{"873":1}}],["目标检测有两种类型的损失",{"2":{"962":1}}],["目标检测领域没有像mnist和fashion",{"2":{"930":1}}],["目标检测数据集",{"0":{"930":1},"1":{"931":1,"932":1,"933":1,"934":1,"935":1}}],["目标检测模型需要预测输入图像上hw组锚框类别和偏移量",{"2":{"913":1}}],["目标检测模型会计算每个类别的预测概率",{"2":{"854":1}}],["目标检测不仅可以识别图像中所有感兴趣的物体",{"2":{"859":1}}],["目标检测在多个领域中被广泛使用",{"2":{"857":1}}],["目标检测和边界框",{"0":{"857":1},"1":{"858":1,"859":1,"860":1}}],["目标检测训练集带有真实边界框的位置及其包围物体类别的标签",{"2":{"850":1}}],["目标检测算法通常会在输入图像中采样大量的区域",{"2":{"847":1}}],["目标检测或语义分割相关的学术竞赛和商业应用都以这种方法为基础",{"2":{"134":1}}],["目标是找到向量u",{"2":{"1158":1}}],["目标是迅速地展示",{"2":{"1088":1}}],["目标是在序列的末尾辨别校验和是否正确",{"2":{"538":1}}],["目标是基于到目前为止我们看到的词元来预测下一个词元",{"2":{"320":1}}],["目标是基于结构和语法假设对文本进行分解和注释",{"2":{"295":1}}],["目标参数",{"0":{"431":1}}],["目标都是将由n个词元组成的序列映射到另一个长度相等的序列",{"2":{"397":1}}],["目标",{"2":{"296":1,"373":1,"1001":1}}],["目标不是简单的",{"2":{"293":1}}],["目标函数l通过隐状态h1",{"2":{"312":1}}],["目标函数l通过o1",{"2":{"312":1}}],["目标函数l仅通过ot",{"2":{"312":1}}],["目标函数关于模型输出的微分计算是相当简单的",{"2":{"312":1}}],["目标函数通常是训练数据集中每个样本的损失函数的平均值",{"2":{"113":1}}],["目标函数值的下降在1个迭代轮数后就变得较为平缓",{"2":{"80":1}}],["目标函数的hessian",{"2":{"59":2}}],["目标函数的梯度",{"2":{"54":1,"56":1,"57":1,"59":2,"113":1}}],["目标函数",{"0":{"286":1},"2":{"48":1,"54":1,"56":1,"57":1,"59":1,"113":1}}],["填充关于每个参数的偏导数",{"2":{"973":1}}],["填充被应用于的输出",{"2":{"969":1}}],["填充输入",{"2":{"722":3}}],["填充缺失的单词",{"2":{"522":1}}],["填充词元的预测将通过乘以0权重在损失中过滤掉",{"2":{"722":3}}],["填充词元",{"2":{"363":1}}],["填充可以增加输出的高度和宽度",{"2":{"143":1}}],["填充是p",{"2":{"142":1}}],["填充不同的高度和宽度",{"2":{"141":1}}],["填充和步幅的大小来间接控制输出形状",{"2":{"938":1}}],["填充和步幅可以手动设定",{"2":{"147":1}}],["填充和步幅可用于有效地调整数据的维度",{"2":{"143":1}}],["填充和步幅",{"0":{"140":1,"147":1},"1":{"141":1,"142":1,"143":1,"144":1}}],["填充",{"0":{"141":1,"969":1},"2":{"134":1,"568":2}}],["填充为s",{"2":{"862":1}}],["填充为1的3×3卷积层不改变特征图的形状",{"2":{"957":1}}],["填充为16",{"2":{"862":1}}],["填充为1",{"2":{"507":1}}],["填充为0",{"2":{"142":1}}],["填充为",{"2":{"124":1,"150":1}}],["久而久之",{"2":{"134":1,"1059":1}}],["群论和一系列的补充实验",{"2":{"134":1}}],["现实生活中",{"2":{"1028":1}}],["现实中",{"2":{"513":1}}],["现有的监督模型是专门为给定的任务定制的",{"2":{"731":1}}],["现有的计算机几乎不可能计算它",{"2":{"514":1}}],["现成的预训练bert模型可能不适合医学等特定领域的应用",{"2":{"718":1}}],["现代python项目依赖管理和打包工具",{"2":{"1283":1}}],["现代的固态驱动器的iops可以达到10万到50万",{"2":{"805":1}}],["现代系统还拥有各种通信资源",{"2":{"798":1}}],["现代系统拥有多种设备",{"2":{"798":1}}],["现代深度学习库也为我们实现了这些组件",{"2":{"588":1}}],["现代循环网络经常采用这种扩展",{"2":{"550":1}}],["现代循环神经网络",{"0":{"550":1}}],["现代卷积神经网络",{"0":{"492":1}}],["现代卷积神经网络的设计得益于生物学",{"2":{"134":1}}],["现代笔记本电脑最多有4核",{"2":{"457":1}}],["现在既然你已经对特征参数向量进行了学习",{"2":{"1191":1}}],["现在如果你考察你的数据在横轴x上的投影",{"2":{"1145":1}}],["现在状况会有很大不同",{"2":{"1145":1}}],["现在开始建立支持向量机",{"2":{"1143":1}}],["现在开发人员要编写一个程序来管理网上商城",{"2":{"281":1}}],["现在也用得比较少了",{"2":{"1141":1}}],["现在也常用resnet替代",{"2":{"953":1}}],["现在这个系统的短处",{"2":{"1138":1}}],["现在这个图显示在第一个格子",{"2":{"1091":1}}],["现在要做的就是训练这个逻辑回归分类器",{"2":{"1112":1}}],["现在你已经掌握了很多机器学习的工具",{"2":{"1176":1}}],["现在你已经知道如何使用这些高级的优化算法",{"2":{"1111":1}}],["现在你知道了这个的长度是多少了",{"2":{"1145":1}}],["现在你知道如何实施应用pca",{"2":{"1161":1}}],["现在你知道如何实现逻辑回归",{"2":{"1110":1}}],["现在你知道如何在",{"2":{"1092":1}}],["现在你知道如何绘制octave中不同的图像",{"2":{"1091":1}}],["现在你的问题是要想改进这个算法",{"2":{"1129":1}}],["现在讲下决策边界",{"2":{"1108":1}}],["现在回到我的",{"2":{"1094":1}}],["现在warmupexercise",{"2":{"1094":1}}],["现在当我在",{"2":{"1092":1}}],["现在y2显示在右边",{"2":{"1091":1}}],["现在文件名被存在一个字符串中",{"2":{"1089":1}}],["现在便有了一个3",{"2":{"1088":1}}],["现在c变量的值是真",{"2":{"1088":1}}],["现在举一个字符串的例子",{"2":{"1088":1}}],["现在写一个变量",{"2":{"1088":1}}],["现在命令提示已经变得简化了",{"2":{"1088":1}}],["现在让我给这两个方程命名",{"2":{"1143":1}}],["现在让我告诉你使用",{"2":{"1092":1}}],["现在让我示范最基本的octave代码",{"2":{"1088":1}}],["现在让我们看一下这对于优化目标函数意味着什么",{"2":{"1145":1}}],["现在让我们看看当我们试图通过initialize函数初始化参数时会发生什么",{"2":{"418":1}}],["现在让我们看看是否可以通过仅查看",{"2":{"129":1}}],["现在让我们来看看如何计算u和v之间的内积",{"2":{"1145":1}}],["现在让我们来看看这对在fashion",{"2":{"68":1}}],["现在让我们回头来看向量v",{"2":{"1145":1}}],["现在让我们更认真地考虑第一个例子",{"2":{"1025":1}}],["现在让我们选择exp⁡",{"2":{"744":1}}],["现在让我们",{"2":{"667":1,"854":1}}],["现在让我们考虑下面这里的训练样本",{"2":{"1145":1}}],["现在让我们考虑一下",{"2":{"1144":1}}],["现在让我们考虑一个非凸函数",{"2":{"59":1}}],["现在让我们考虑词元级任务",{"2":{"659":1}}],["现在让我们考虑整个结果分布的情况",{"2":{"648":1}}],["现在让我们关注",{"2":{"406":1}}],["现在让我们尝试自己实现一个多层感知机",{"2":{"216":1}}],["现在打开octave",{"2":{"1088":1}}],["现在主要是用python",{"2":{"1088":1}}],["现在python变主流了",{"2":{"1061":1}}],["现在来到我的目录c",{"2":{"1094":1}}],["现在来看一下结果",{"2":{"1092":1}}],["现在来个小测验",{"2":{"1060":1}}],["现在来回顾一下",{"2":{"1060":1}}],["现在来观察注意力的权重",{"2":{"388":1}}],["现在他希望把房子卖掉",{"2":{"1060":1}}],["现在我将要看看这些项",{"2":{"1145":1}}],["现在我将告诉你一些人们尝试定义的示例",{"2":{"1059":1}}],["现在我的桌面上就出现了一个新文件",{"2":{"1089":1}}],["现在我用不同的符号来表示这些数据",{"2":{"1060":1}}],["现在我们介绍随机梯度下降算法的调试",{"2":{"1167":1}}],["现在我们希望hθ",{"2":{"1143":1}}],["现在我们换个角度来看什么是梯度下降",{"2":{"1111":1}}],["现在我们来看一下目标函数",{"2":{"1145":1}}],["现在我们来看看我们",{"2":{"129":1}}],["现在我们来说如何在",{"2":{"1092":1}}],["现在我们来分析另外一个例子",{"2":{"1092":1}}],["现在我们来算$a",{"2":{"1090":1}}],["现在我们来求每一行的和",{"2":{"1090":1}}],["现在我们加上索引值",{"2":{"1089":1}}],["现在我们清除所有变量",{"2":{"1089":1}}],["现在我们对房价模型增加更多的特征",{"2":{"1080":1}}],["现在我们对单变量的情况有了更好的理解",{"2":{"57":1}}],["现在我们能够非常便宜地把信寄到这个美国甚至全世界的原因之一就是当你写一个像这样的信封",{"2":{"1058":1}}],["现在我们能直接访问参数以设定它们的初始值",{"2":{"592":2}}],["现在我们知道如何对骰子进行采样",{"2":{"1026":1}}],["现在我们知道如何计算点积",{"2":{"998":1}}],["现在我们使用函数来数据",{"2":{"796":1}}],["现在我们几乎准备好为bert预训练定制一个dataset类",{"2":{"722":1}}],["现在我们有一个训练集",{"2":{"1112":1}}],["现在我们有一个朋友很不幸检查出乳腺肿瘤",{"2":{"1060":1}}],["现在我们有两组比较向量va",{"2":{"676":1}}],["现在我们有了凸集",{"2":{"41":1}}],["现在我们打印第一个小批量的形状",{"2":{"669":1}}],["现在我们只需一行代码就可以",{"2":{"633":1}}],["现在我们只需要假设σ是某个固定常数就可以忽略第一项",{"2":{"616":1}}],["现在我们已经掌握了梯度下降",{"2":{"1069":1}}],["现在我们已经准备好使用这样的背景知识来设计一个目标检测模型",{"2":{"952":1}}],["现在我们已经准备好了模型训练所有需要的要素",{"2":{"605":1}}],["现在我们已经了解了word2vec模型的技术细节和大致的训练方法",{"2":{"771":1}}],["现在我们已经实现了lenet",{"2":{"137":1}}],["现在我们",{"2":{"584":1,"927":1,"959":1}}],["现在我们定义一个函数",{"2":{"568":1}}],["现在我们定义了两个方便的函数",{"2":{"446":1}}],["现在我们准备",{"2":{"545":1}}],["现在我们看看如何正确地初始化参数",{"2":{"434":1}}],["现在我们看看它的实际应用",{"2":{"125":1}}],["现在我们在编写代码时无须知道维度是什么就可以设置参数",{"2":{"417":1}}],["现在我们在其后附加一个卷积层",{"2":{"131":1}}],["现在我们构建了由num",{"2":{"408":1}}],["现在我们可以应用边际化和乘法规则",{"2":{"1035":1}}],["现在我们可以应用上述几个法则来计算u",{"2":{"981":1}}],["现在我们可以调用multibox",{"2":{"854":1}}],["现在我们可以调用网络三次",{"2":{"820":1}}],["现在我们可以调用网络两次",{"2":{"820":3}}],["现在我们可以为每个锚框标记类别和偏移量了",{"2":{"852":1}}],["现在我们可以",{"2":{"837":1,"981":1}}],["现在我们可以通过实例化三个类bertencoder",{"2":{"738":1}}],["现在我们可以通过房屋面积x1和房龄x2来估计一个",{"2":{"614":1}}],["现在我们可以训练和验证模型了",{"2":{"907":1}}],["现在我们可以训练全卷积网络了",{"2":{"865":1}}],["现在我们可以训练双向循环神经网络进行情感分析",{"2":{"715":1}}],["现在我们可以训练textcnn模型进行情感分析",{"2":{"704":1}}],["现在我们可以创建数据迭代器了",{"2":{"694":1}}],["现在我们可以在snli数据集上训练和评估模型",{"2":{"681":1}}],["现在我们可以对工作负载进行基准测试",{"2":{"615":1}}],["现在我们可以更仔细地看看sequential类是如何工作的",{"2":{"424":1}}],["现在我们可以测试predict",{"2":{"333":1}}],["现在我们可以开始对深度神经网络的探索",{"2":{"228":1}}],["现在我们可以计算最接近输出层的模型参数的梯度",{"2":{"164":1}}],["现在我们可以比较前四个实验的时间与损失",{"2":{"80":1}}],["现在我们将b与它的转置进行比较",{"2":{"992":1}}],["现在我们将优化参数以最大化观测数据的概率",{"2":{"643":1}}],["现在我们将",{"2":{"545":1}}],["现在我们将使用卷积层的输出作为2×2最大汇聚的输入",{"2":{"146":1}}],["现在我们将输入的二维图像转置",{"2":{"128":1}}],["现在它涉及到各个行业和基础科学中",{"2":{"1058":1}}],["现在inputs和outputs中的所有条目都是数值类型",{"2":{"1013":1}}],["现在先将高阶张量暂放一边",{"2":{"993":1}}],["现在在代码中访问",{"2":{"992":1}}],["现在计算x的另一个函数",{"2":{"974":1}}],["现在计算y",{"2":{"974":1}}],["现在看看调用hybridize函数会发生什么",{"2":{"821":1}}],["现在使用函数来处理数据",{"2":{"796":2}}],["现在式",{"2":{"751":1}}],["现在每个训练步的梯度计算成本与词表大小无关",{"2":{"708":1}}],["现在训练已经完成",{"2":{"636":1}}],["现在第二项除了常数1σ2外",{"2":{"616":1}}],["现在又转向块",{"2":{"506":1}}],["现在假设我们使用了非常非常大的训练集",{"2":{"1141":1}}],["现在假设我们有一个模型",{"2":{"1108":1}}],["现在假设f∗是我们真正想要找到的函数",{"2":{"500":1}}],["现在假设局部极小值x∗不是f的全局极小值",{"2":{"44":1}}],["现在有了更好的训练方法",{"2":{"486":1}}],["现在alexnet可以开始被训练了",{"2":{"463":1}}],["现在gpu显存相对充裕",{"2":{"459":1}}],["现在数据在同一个gpu上",{"2":{"449":1}}],["现在是时候学习如何加载和存储权重向量和整个模型了",{"2":{"440":1}}],["现在是猫",{"2":{"180":1}}],["现在可以访问",{"2":{"1433":1}}],["现在可以绘制出图像中所有以",{"2":{"848":1}}],["现在可以在不同的gpu上同时聚合每个部分",{"2":{"841":1}}],["现在可以使用我们的mysequential类重新实现多层感知机",{"2":{"424":1}}],["现在可以先",{"2":{"407":1}}],["现在可以",{"2":{"406":1}}],["现在希望修剪最不重要的注意力头以提高预测速度",{"2":{"384":1}}],["现在仅需要将多层理解为一层循环神经网络的输出被用作下一层循环神经网络的输入就足够了",{"2":{"325":1}}],["现在的问题的是",{"2":{"1156":1}}],["现在的问题是如何",{"2":{"319":1}}],["现在的输出包含3个通道",{"2":{"121":1}}],["现在人们可以借助于相关偏微分方程的数值模拟",{"2":{"302":1}}],["现在模型每次听到",{"2":{"282":1}}],["现在考虑我们的优化问题",{"2":{"1144":1}}],["现在考虑下我们想要逻辑回归做什么",{"2":{"1143":1}}],["现在考虑第二个例子",{"2":{"1025":1}}],["现在考虑一个更一般的场景",{"2":{"984":1}}],["现在考虑一个句子",{"2":{"727":1}}],["现在考虑反向传播过程",{"2":{"247":1}}],["现在考虑任意a",{"2":{"40":1}}],["现在用z标签表示",{"2":{"191":1}}],["现在都是狗",{"2":{"180":1}}],["现在引用上述的第二个原则",{"2":{"155":1}}],["现在引用上述的第一个原则",{"2":{"154":1}}],["现在简要解释一下原因",{"2":{"78":1}}],["现在更新的规模不再取决于偏差的量",{"2":{"35":1}}],["现在",{"2":{"34":1,"113":1,"114":1,"128":1,"137":1,"152":1,"191":1,"192":1,"209":1,"247":1,"263":1,"266":1,"270":1,"282":2,"291":1,"312":1,"321":1,"335":1,"340":1,"350":1,"363":2,"413":1,"414":1,"467":1,"488":1,"519":1,"557":1,"573":1,"575":1,"576":1,"616":1,"635":1,"669":1,"674":1,"678":1,"685":1,"742":1,"757":1,"767":1,"837":1,"883":1,"895":1,"959":1,"960":1,"1068":3,"1090":2,"1093":1,"1110":1,"1117":1,"1121":1,"1143":7,"1145":3,"1168":1,"1187":1}}],["现在讨论关于稀疏特征",{"2":{"25":1}}],["无限创意空间",{"0":{"1536":1}}],["无限维向量集合中抽取的向量",{"2":{"156":1}}],["无服务器",{"2":{"1357":1}}],["无需编译",{"2":{"1302":1}}],["无需额外安装",{"2":{"1268":1}}],["无需固定表结构",{"2":{"1195":1}}],["无重复元素的无序集合",{"2":{"1216":1}}],["无中间层",{"2":{"1101":1}}],["无状态的会话管理机制",{"2":{"1047":1}}],["无须两个特征同时保留",{"2":{"1086":1}}],["无须按随机顺序读取它",{"2":{"932":1}}],["无须多言",{"2":{"339":1}}],["无热狗",{"2":{"872":1}}],["无torchscript",{"2":{"820":1}}],["无混合式",{"2":{"820":1}}],["无关的单词wk",{"2":{"744":2}}],["无语义重叠",{"2":{"658":1}}],["无穷大",{"2":{"624":1}}],["无隐状态的神经网络",{"0":{"339":1}}],["无监督学习也可用于天文数据分析",{"2":{"1061":1}}],["无监督学习或聚集有着大量的应用",{"2":{"1061":1}}],["无监督学习算法可能会把这些数据分成两个不同的簇",{"2":{"1061":1}}],["无监督学习就能判断出数据有两个不同的聚集簇",{"2":{"1061":1}}],["无监督学习",{"0":{"296":1,"1061":1,"1150":1},"2":{"1059":1,"1193":2}}],["无法捕获试图学习的模式",{"2":{"258":1}}],["无法检测水平边缘",{"2":{"128":1}}],["无论你是喜欢设计美学",{"2":{"1541":1}}],["无论你是前端新手",{"2":{"1531":1}}],["无论你是做科研",{"2":{"1305":1}}],["无论你是初学者",{"2":{"1295":1}}],["无论你是用octave",{"2":{"1093":1}}],["无论前面是否有1",{"2":{"1143":1}}],["无论训练集有多么大误差都不会有太大改观",{"2":{"1134":1}}],["无论i值是多少",{"2":{"1112":1}}],["无论使用哪个深度学习框架",{"2":{"1016":1}}],["无论好坏",{"2":{"811":1}}],["无论上下文是什么",{"2":{"754":1}}],["无论我们使用什么手段来观察特征x和标签y",{"2":{"610":1}}],["无论我们想出什么算法",{"2":{"252":1}}],["无论这个样本是一个句子的一部分还是跨越了多个句子的一个片断",{"2":{"568":1}}],["无论是炫酷动画",{"2":{"1536":1}}],["无论是本地",{"2":{"1339":1}}],["无论是否异常",{"2":{"1236":1}}],["无论是线性回归问题",{"2":{"1117":1}}],["无论是线性回归还是逻辑回归都有这样一个缺点",{"2":{"1097":1}}],["无论是对于octave",{"2":{"1093":1}}],["无论是医疗诊断",{"2":{"886":1}}],["无论是cpu还是gpu",{"2":{"452":1}}],["无论是输入还是隐藏表示都拥有空间结构",{"2":{"153":1}}],["无论何时我们要对多个项进行操作",{"2":{"447":1}}],["无论模型有多精确",{"2":{"292":1}}],["无论什么类型的机器学习问题",{"2":{"283":1}}],["无论积累多少经验",{"2":{"281":1}}],["无论哪种方法找到这个物体",{"2":{"152":1}}],["无论x",{"2":{"146":1}}],["无论用严格卷积运算或互相关运算",{"2":{"132":1}}],["阴影区域",{"2":{"851":3}}],["阴影部分是第一个输出元素以及用于输出计算的输入和核张量元素",{"2":{"141":1}}],["阴影部分是第一个输出元素以及用于计算这个输出的输入和核张量元素",{"2":{"120":1}}],["阴影输出元素值19的感受野是输入阴影部分的四个元素",{"2":{"131":1}}],["特性",{"2":{"1530":1}}],["特殊类型",{"2":{"1404":1}}],["特殊符号",{"2":{"757":1}}],["特殊的词尾符号",{"2":{"757":1}}],["特殊词元",{"2":{"737":1}}],["特殊词元在遮蔽语言模型任务中不被预测",{"2":{"721":1}}],["特殊分类标记",{"2":{"657":1}}],["特定的序列开始词元",{"2":{"576":1}}],["特定的填充词元被添加到序列的末尾",{"2":{"575":1}}],["特定的",{"2":{"572":2}}],["特点如下",{"2":{"1451":1}}],["特点包括",{"2":{"1195":1}}],["特点数",{"2":{"883":3}}],["特点",{"0":{"302":1},"2":{"1199":1,"1339":1,"1347":1,"1348":1,"1461":1,"1511":1,"1512":1,"1515":1,"1516":1}}],["特斯拉",{"2":{"301":1}}],["特征是很重要的",{"2":{"1187":1}}],["特征可能包含",{"2":{"1178":1}}],["特征值有足够的信息量",{"2":{"1141":1}}],["特征值x包含了足够的信息",{"2":{"1141":1}}],["特征和直观理解1",{"0":{"1101":1}}],["特征和多项式回归",{"0":{"1084":1},"2":{"1193":1}}],["特征缩放非常有必要",{"2":{"1084":1}}],["特征缩放",{"0":{"1082":1},"2":{"1193":1}}],["特征矩阵x的维度是",{"2":{"1080":1}}],["特征矩阵和标签向量作为输入",{"2":{"600":1}}],["特征的回归模型",{"2":{"1080":1}}],["特征图的形状或以同一单元为中心的锚框的数量可能会有所不同",{"2":{"956":1}}],["特征图的高度和宽度设置为4",{"2":{"912":1}}],["特征图在相同空间位置的c个单元在输入图像上的感受野相同",{"2":{"913":1}}],["特征应该由多个共同学习的神经网络层组成",{"2":{"455":1}}],["特征大小",{"2":{"369":1}}],["特征",{"2":{"181":1,"186":1,"289":1,"320":1,"339":1,"350":1,"422":1,"1097":1}}],["特征映射和感受野",{"0":{"131":1}}],["特别要提及的是",{"2":{"1168":1}}],["特别注意一下",{"2":{"1090":1}}],["特别注意对于所有i",{"2":{"26":1}}],["特别地",{"2":{"142":1}}],["特别是你最好不要使用",{"2":{"1111":1}}],["特别是当我们处理巨大的训练集时",{"2":{"1070":1}}],["特别是当我们计算目标函数l关于参数wh的梯度时",{"2":{"307":1}}],["特别是回归问题",{"2":{"1064":1}}],["特别是层之间计算的工作负载不能正确匹配的时候",{"2":{"832":1}}],["特别是他们发现深层且窄的卷积",{"2":{"510":1}}],["特别是关于",{"2":{"475":1}}],["特别是在多个服务器之间分发参数时",{"2":{"844":1}}],["特别是在控制流方面",{"2":{"821":1}}],["特别是在gpu环境中",{"2":{"819":1}}],["特别是在第二次世界大战中使用计算机破解语言编码",{"2":{"564":1}}],["特别是在较短的时间内使他们收敛更加棘手",{"2":{"466":1}}],["特别是在深度学习领域",{"2":{"258":1}}],["特别是对于之前从未接触过它的人",{"2":{"1070":1}}],["特别是对于qlc",{"2":{"805":1}}],["特别是对于大型语料库",{"2":{"745":1}}],["特别是对于一些不常见的单词组合",{"2":{"316":1}}],["特别是对于频繁出现的单词",{"2":{"316":1}}],["特别是gpu的普及",{"2":{"300":1}}],["特别是小批量随机梯度下降结合起来",{"2":{"88":1}}],["特别是因为最初的参数集是随机的",{"2":{"66":1}}],["特别是",{"2":{"26":1,"114":1,"116":1,"118":1,"348":1,"526":1,"811":1,"843":1,"1161":1}}],["呢",{"2":{"129":1,"1089":1,"1093":1}}],["高并发处理能力",{"2":{"1359":1}}],["高效并发与持久化",{"2":{"1211":1}}],["高可用",{"2":{"1209":1,"1210":1}}],["高可用性",{"2":{"1195":1}}],["高可用的网络服务",{"2":{"1047":1}}],["高扩展性",{"2":{"1195":1}}],["高偏差",{"2":{"1144":1,"1147":2}}],["高偏差和高方差的问题基本上来说是欠拟合和过拟合的问题",{"2":{"1132":1}}],["高方差",{"2":{"1144":1,"1147":2}}],["高×宽×通道数",{"2":{"956":1}}],["高宽比在3",{"2":{"903":3}}],["高和宽",{"2":{"967":1}}],["高和宽减半块会扩大每个单元在其输出特征图中的感受野",{"2":{"957":1}}],["高和宽减半块",{"0":{"957":1}}],["高和宽分别为h和w",{"2":{"923":1}}],["高和宽都可以被32整除",{"2":{"864":1}}],["高和宽均减半",{"2":{"481":1}}],["高",{"2":{"858":1}}],["高端设备",{"2":{"812":1}}],["高端磁盘在9个盘片上可容纳高达16tb的容量",{"2":{"804":1}}],["高速扩展总线由直接连接到cpu的多个通道组成",{"2":{"801":1}}],["高速扩展总线",{"2":{"801":1}}],["高速互连等等",{"2":{"457":1}}],["高频词在训练中可能不是那么有用",{"2":{"778":1}}],["高频词",{"2":{"773":1}}],["高频",{"2":{"773":2}}],["高级通用编程语言",{"2":{"1296":1}}],["高级优化算法和正则化技术",{"2":{"1117":1}}],["高级优化",{"0":{"1111":1},"2":{"1193":1}}],["高级用户请注意",{"2":{"436":1}}],["高级用户",{"2":{"421":1}}],["高级api的优势将大大增加",{"2":{"595":1}}],["高级api的循环神经网络层返回一个输出和一个更新后的隐状态",{"2":{"327":1}}],["高级api封装了前文介绍的所有配置细节",{"2":{"561":1}}],["高级api包含了前文介绍的所有配置细节",{"2":{"547":1}}],["高级api提供了循环神经网络的实现",{"2":{"325":1}}],["高斯分布样例",{"2":{"1179":1}}],["高斯分布",{"0":{"1179":1},"2":{"1193":1}}],["高斯核指数部分可以视为注意力评分函数",{"2":{"367":1}}],["高斯",{"2":{"299":1}}],["高维的数据",{"2":{"278":1}}],["高维线性回归",{"0":{"271":1}}],["高阶多项式函数拟合",{"0":{"266":1}}],["高阶多项式函数相对于低阶多项式的训练误差应该始终更低",{"2":{"259":1}}],["高阶多项式函数比低阶多项式函数复杂得多",{"2":{"259":1}}],["高阶多项式的参数较多",{"2":{"259":1}}],["高度是某个u2作为u的第二个分量",{"2":{"1145":1}}],["高度恰好为1",{"2":{"1028":1}}],["高度会被自动计算得出",{"2":{"1017":1}}],["高度分别为ha和hb",{"2":{"852":1}}],["高度和通道数分别为n",{"2":{"701":1}}],["高度和宽度方面具有不同的大小",{"2":{"956":1}}],["高度和宽度均为32像素并有三个颜色通道",{"2":{"888":1}}],["高度和宽度",{"2":{"494":1,"915":1}}],["高度和宽度都为224的",{"2":{"461":1}}],["高度和宽度两边的填充分别为2和1",{"2":{"141":1}}],["高度和宽度分别为h和w的卷积核可以被称为h×w卷积或h×w卷积核",{"2":{"127":1}}],["高度",{"2":{"129":4,"136":3,"858":2,"859":1,"882":1,"932":1,"956":1,"1017":1}}],["高学习率如何导致较差的局部最小值",{"2":{"56":1}}],["基本切换效果",{"0":{"1474":1}}],["基本类型数据",{"2":{"1458":1}}],["基本类型",{"2":{"1457":1,"1462":3}}],["基本类型不要用它",{"2":{"1456":1}}],["基本类型的响应式数据",{"0":{"1455":1}}],["基本类型别名",{"2":{"1412":1}}],["基本泛型函数",{"0":{"1430":1}}],["基本接口",{"0":{"1419":1}}],["基本抽象类",{"0":{"1416":1}}],["基本联合类型",{"2":{"1407":1}}],["基本语法",{"0":{"1398":1}}],["基本上我们可以利用循环",{"2":{"1120":1}}],["基本上用三行代码或者一个for",{"2":{"1093":1}}],["基本上可以说取这个红点的切线",{"2":{"1068":1}}],["基本的容器编排",{"2":{"1351":1}}],["基本的想法实现以后",{"2":{"1088":1}}],["基本的卷积块被称为inception块",{"2":{"487":1}}],["基本思想是输入一组不同个体",{"2":{"1061":1}}],["基本概率论",{"0":{"1026":1},"1":{"1027":1,"1028":1}}],["基本操作",{"0":{"968":1,"1088":1,"1328":1},"2":{"1193":1}}],["基本网络块用于从输入图像中抽取特征",{"2":{"958":1}}],["基本网络块",{"0":{"958":1}}],["基本网络用于从输入图像中提取特征",{"2":{"953":1}}],["基本而言",{"2":{"911":1}}],["基本模型",{"2":{"726":1}}],["基本形式",{"2":{"659":1}}],["基本再也不会更新",{"2":{"195":1}}],["基于客户端",{"2":{"1362":1}}],["基于镜像创建并运行容器",{"2":{"1340":1}}],["基于内容的推荐系统",{"0":{"1188":1},"2":{"1193":1}}],["基于邮件的正文信息开发一系列复杂的特征",{"2":{"1137":1}}],["基于邮件的路由信息开发一系列复杂的特征",{"2":{"1137":1}}],["基于被标记为垃圾的邮件",{"2":{"1059":1}}],["基于图结构",{"2":{"1052":1}}],["基于基础网络块和各个多尺度特征块",{"2":{"965":1}}],["基于y",{"2":{"959":1}}],["基于该特征图生成的锚框数量较多",{"2":{"953":1}}],["基于每个gpu上的批量数据分别计算预测和梯度",{"2":{"843":1}}],["基于带宽的成本和复杂性",{"2":{"832":1}}],["基于同样的原因",{"2":{"811":1}}],["基于gpu的并行计算",{"0":{"796":1}}],["基于word2vec中的跳元模型",{"2":{"758":1}}],["基于多层感知机",{"2":{"663":1}}],["基于我们在",{"2":{"531":1}}],["基于这些推导出的结果",{"2":{"1109":1}}],["基于这六个序列",{"2":{"515":1}}],["基于这种设计",{"2":{"381":1}}],["基于上一时间步的k个候选输出序列",{"2":{"515":1}}],["基于上面定义的corr2d函数",{"2":{"127":1}}],["基于位置的前馈网络对序列中的所有位置的表示进行变换时使用的是同一个多层感知机",{"2":{"405":1}}],["基于位置的前馈网络",{"0":{"405":1},"2":{"405":4}}],["基于平均汇聚来计算所有训练样本输出值的平均值",{"2":{"387":1}}],["基于适当的张量操作",{"2":{"383":1}}],["基于k=1",{"2":{"351":1}}],["基于嵌入维度τ",{"2":{"350":1}}],["基于过去事件得到的分布不会改变",{"2":{"349":1}}],["基于条件概率公式",{"2":{"349":1}}],["基于其他人的意见做出评价",{"2":{"345":1}}],["基于循环神经网络的字符级语言模型",{"0":{"341":1}}],["基于一个具有随机权重的模型进行预测",{"2":{"326":1}}],["基于相同的设置",{"2":{"321":1}}],["基于",{"0":{"1443":1,"1444":1},"2":{"312":1,"391":1,"1528":2}}],["基于下列公式替换at",{"2":{"307":1}}],["基于链式法则",{"2":{"306":1}}],["基于rkhs的算法往往难以应用到大型",{"2":{"278":1}}],["基于卷积神经网络架构的模型在计算机视觉领域中已经占主导地位",{"2":{"134":1}}],["基础类型分类",{"0":{"1404":1}}],["基础语法",{"2":{"1304":1}}],["基础概念",{"0":{"1195":1,"1317":1},"1":{"1318":1,"1319":1,"1320":1,"1321":1,"1322":1,"1323":1,"1324":1,"1325":1}}],["基础用户",{"2":{"421":1}}],["基础",{"0":{"85":1},"1":{"86":1,"87":1,"88":1,"89":1}}],["验证上述实现输出",{"2":{"968":1}}],["验证上述二维互相关运算的输出",{"2":{"126":1}}],["验证它是否能按预期工作",{"2":{"413":1}}],["验证",{"2":{"258":1,"711":1}}],["验证集中每个类别的样本数",{"2":{"890":1}}],["验证集将为每个类别拆分出max",{"2":{"890":1}}],["验证集和测试集",{"2":{"772":1}}],["验证集可以用于模型选择",{"2":{"267":1}}],["验证集",{"0":{"256":1}}],["验证log",{"2":{"211":1}}],["验证平均汇聚层",{"2":{"146":1}}],["验证二维最大汇聚层的输出",{"2":{"146":1}}],["验证互相关运算的输出",{"2":{"120":1}}],["×log",{"2":{"1109":1,"1110":2}}],["×2矩阵",{"2":{"1090":1}}],["×1",{"2":{"1088":1}}],["×c",{"2":{"1076":1}}],["×4=5444个锚框",{"2":{"959":1}}],["×",{"2":{"126":1,"140":1,"141":1,"142":3,"938":1,"968":1,"1090":1}}],["包装成一个对象",{"2":{"1495":1}}],["包结构与",{"0":{"1258":1}}],["包",{"2":{"582":1}}],["包含所有被ref属性标识的dom元素或组件实例",{"2":{"1502":1}}],["包含所有父组件传入的标签属性",{"2":{"1501":1}}],["包含所有图像和csv标签文件的香蕉检测数据集可以直接从互联网下载",{"2":{"931":1}}],["包含一系列",{"2":{"1310":1}}],["包含一个序列中n个词元的d维嵌入表示",{"2":{"398":1}}],["包含了什么时候一个有效的方法去学习复杂的非线性函数",{"2":{"1148":1}}],["包含了",{"2":{"1085":1}}],["包含了四个单词的一个文本序列的概率是",{"2":{"316":1}}],["包含它们只是为了防止手动标记测试集并提交标记结果",{"2":{"888":1}}],["包含s1或r1的",{"2":{"848":1}}],["包含许多特征的深度模型需要大量的有标签数据",{"2":{"456":1}}],["包含着直到当前时间步第i个块解码的输出表示",{"2":{"408":4}}],["包含死帽蕈的概率是0",{"2":{"291":1}}],["包含层层数据转换",{"2":{"285":1}}],["包含256个隐藏单元",{"2":{"225":1}}],["包含值",{"2":{"209":1,"431":1}}],["包含在该窗口中的部分张量与卷积核张量进行按元素相乘",{"2":{"126":1}}],["包括基础类型",{"2":{"1403":1}}],["包括基本数学运算",{"2":{"1023":1}}],["包括常见事件",{"2":{"1309":1}}],["包括算术",{"2":{"1217":1}}],["包括监督学习算法和无监督学习算法等等",{"2":{"1176":1}}],["包括并行系统和映射化简方法",{"2":{"1176":1}}],["包括考虑截词的处理",{"2":{"1137":1}}],["包括线性回归和逻辑回归",{"2":{"1114":1}}],["包括包括",{"2":{"1110":1}}],["包括c++",{"2":{"1088":1}}],["包括向量点积和矩阵乘法",{"2":{"1018":1}}],["包括像求幂这样的一元运算符",{"2":{"1018":1}}],["包括从均匀分布",{"2":{"1006":1}}],["包括存储",{"2":{"987":1}}],["包括验证集",{"2":{"896":1,"908":1}}],["包括shape",{"2":{"820":1}}],["包括theano和tensorflow",{"2":{"817":1}}],["包括在cpu或其他gpu上的操作",{"2":{"789":1}}],["包括两端",{"2":{"709":1}}],["包括数据流水线",{"2":{"598":1}}],["包括",{"2":{"587":1,"975":1,"1365":1}}],["包括隐状态所在的时间步",{"2":{"573":2}}],["包括yann",{"2":{"455":1}}],["包括启发式参数初始化",{"2":{"454":1}}],["包括参数初始化和反向传播",{"2":{"427":1}}],["包括参数化relu",{"2":{"235":1}}],["包括轮数",{"2":{"223":1}}],["包括过拟合",{"2":{"204":1}}],["包括一些花哨的算子理论方法",{"2":{"191":1}}],["包括凸函数和非凸函数",{"2":{"41":1}}],["输出内容到控制台",{"2":{"1232":1}}],["输出一段模糊的浅灰色区域",{"2":{"1127":1}}],["输出一对前提和假设之间的逻辑关系",{"2":{"682":1}}],["输出变量",{"2":{"1063":1}}],["输出可能不止两个值",{"2":{"1060":1}}],["输出可以被认为是一个矩阵",{"2":{"730":1}}],["输出true",{"2":{"981":1}}],["输出像素所处的通道维可以保有输入像素在同一位置上的分类结果",{"2":{"967":1}}],["输出特征图上",{"2":{"954":1}}],["输出特征形状为单个标量",{"2":{"591":2}}],["输出和输入在特征图宽和高上的空间坐标一一对应",{"2":{"954":1}}],["输出连结后的各个提议区域抽取的特征",{"2":{"938":1}}],["输出有什么变化",{"2":{"929":1}}],["输出图像在坐标",{"2":{"863":1}}],["输出由非极大值抑制保存的最终预测边界框",{"2":{"854":1}}],["输出由下式给出",{"2":{"247":1}}],["输出列表l中的所有预测边界框",{"2":{"854":1}}],["输出中两个轴的坐标各分别除以了图像的宽度和高度",{"2":{"848":1}}],["输出中的每个元素是中心词向量和上下文或噪声词向量的点积",{"2":{"763":1}}],["输出中的每个元素都是从输入图像中同一位置的元素的线性组合",{"2":{"122":1}}],["输出操作",{"2":{"804":1}}],["输出词表大小",{"2":{"748":1}}],["输出维度f由mlp的num",{"2":{"674":1}}],["输出端子",{"2":{"619":1}}],["输出线",{"2":{"619":1}}],["输出门参数",{"2":{"558":4}}],["输出门是ot∈rn×h",{"2":{"553":1}}],["输出数",{"2":{"527":1}}],["输出通道数量与alexnet中的相同",{"2":{"495":1}}],["输出通道的数量进一步增加",{"2":{"461":4}}],["输出通道的数目远大于lenet",{"2":{"461":4}}],["输出执行批量规范化",{"2":{"470":1}}],["输出序列的生成就完成了",{"2":{"577":4}}],["输出序列的最大长度为3",{"2":{"515":1}}],["输出序列的查询不会与输入序列中填充位置的词元进行注意力计算",{"2":{"409":1}}],["输出序列的所有词元都在同一时间处理",{"2":{"408":4}}],["输出序列是通过词元一个接着一个解码的",{"2":{"408":4}}],["输出序列是说话人所说内容的文本记录",{"2":{"295":1}}],["输出与输入的张量形状相同",{"2":{"396":1}}],["输出与输入具有相同高度和宽度",{"2":{"141":1}}],["输出x的形状",{"2":{"382":8}}],["输出x的形状为",{"2":{"375":4}}],["输出层4个神经元分别用来表示4类",{"2":{"1103":1}}],["输出层中的模型参数将使用十倍的学习率",{"2":{"874":2}}],["输出层中的学习率比其他层的学习率大十倍",{"2":{"873":1}}],["输出层将从头开始进行训练",{"2":{"870":1}}],["输出层除外",{"2":{"870":1}}],["输出层变量设为ot∈rn×q",{"2":{"527":1}}],["输出层计算得到的输出为",{"2":{"521":1}}],["输出层",{"2":{"423":3}}],["输出层的计算仅基于第l个隐藏层最终的隐状态",{"2":{"527":1}}],["输出层的计算不能过度依赖于h1",{"2":{"171":1}}],["输出层的输出类似于多层感知机中的计算",{"2":{"340":1}}],["输出层由下式给出",{"2":{"339":1}}],["输出层参数",{"2":{"331":4,"544":4,"558":4}}],["输出ot∈rq的方式为",{"2":{"312":1}}],["输出表示为ot",{"2":{"307":1}}],["输出比输入长得多",{"2":{"295":1}}],["输出是另一个相同长度的向量",{"2":{"1026":1}}],["输出是这些位置的预测结果",{"2":{"736":1}}],["输出是音频文件",{"2":{"295":1}}],["输出是否保留更多内容或减少更多噪点",{"2":{"929":1}}],["输出是否",{"2":{"282":1}}],["输出则为固定数量",{"2":{"295":1}}],["输出的形状是什么",{"2":{"915":1}}],["输出的形状可能与输入的形状不同",{"2":{"423":2}}],["输出的类别预测与输入图像在像素级别上具有一一对应关系",{"2":{"861":1}}],["输出的预测值由输入特征通过线性模型的仿射变换决定",{"2":{"610":1}}],["输出的结果告诉我们一些重要的事情",{"2":{"430":1}}],["输出的queries",{"2":{"382":4}}],["输出的也是垃圾",{"2":{"284":1}}],["输出的方差不受输入数量的影响",{"2":{"249":1}}],["输出映射",{"2":{"282":1}}],["输出映射上增强平滑性",{"2":{"170":1}}],["输出为输入中每个区域的最大值或平均值",{"2":{"146":1}}],["输出形状为",{"2":{"142":1,"713":3}}],["输出y",{"2":{"141":1}}],["输出y中的1代表从白色到黑色的边缘",{"2":{"128":1}}],["输出单个元素z",{"2":{"131":1}}],["输出",{"2":{"129":1,"325":1,"386":1,"404":1,"573":4,"574":4,"836":1,"969":1,"1235":1,"1239":1,"1296":1}}],["输出大小等于输入大小nh×nw减去卷积核大小kh×kw",{"2":{"126":1}}],["输出大小略小于输入大小",{"2":{"126":1}}],["输出张量的四个元素由二维互相关运算得到",{"2":{"126":1}}],["输入到一个算法中",{"2":{"1150":1}}],["输入向量x有三个维度",{"2":{"1103":1}}],["输入用户名密码",{"2":{"1094":1}}],["输入imagesc",{"2":{"1091":1}}],["输入ylabel",{"2":{"1091":1}}],["输入命令",{"2":{"1088":1,"1091":1}}],["输入3",{"2":{"1088":1}}],["输入5",{"2":{"1088":1}}],["输入变量",{"2":{"1063":2}}],["输入轴1的维数在输出形状中消失",{"2":{"995":1}}],["输入元素",{"2":{"968":1}}],["输入元素的常规卷积",{"2":{"968":1}}],["输入图像会被随机裁剪为固定尺寸而不是缩放",{"2":{"950":1}}],["输入图像将总共有whnm个锚框",{"2":{"848":1}}],["输入参数boxes可以是长度为4的张量",{"2":{"858":1}}],["输入表示",{"0":{"734":1}}],["输入表示为xt",{"2":{"307":1}}],["输入paragraphs",{"2":{"722":3}}],["输入会被转置",{"2":{"713":3}}],["输入张量中的每个元素都要乘以卷积核",{"2":{"968":1}}],["输入张量的宽度",{"2":{"701":1}}],["输入张量和核张量通过",{"2":{"126":1}}],["输入文本的每个词元的bert表示被送到相同的额外全连接层中",{"2":{"659":1}}],["输入终端",{"2":{"619":1}}],["输入值都是已经给定的",{"2":{"618":1}}],["输入解码器",{"2":{"579":1}}],["输入为x1",{"2":{"618":1}}],["输入为xt∈rn×d",{"2":{"553":1}}],["输入为固定尺寸的图像",{"2":{"295":1}}],["输入数量",{"2":{"644":1}}],["输入数为d",{"2":{"553":1}}],["输入数据的数量这个数字将会随着我们遇到的数据量的增加而增加",{"2":{"347":1}}],["输入数据的数量",{"2":{"347":1}}],["输入门参数",{"2":{"558":4}}],["输入门it控制采用多少来自c~t的新数据",{"2":{"555":1}}],["输入门是it∈rn×h",{"2":{"553":1}}],["输入门",{"0":{"553":1},"2":{"562":1}}],["输入个数d",{"2":{"540":1}}],["输入通道的数量in",{"2":{"507":1}}],["输入通常是变长序列",{"2":{"406":1}}],["输入可以由特殊的",{"2":{"721":1}}],["输入可以通过层间的残余连接更快地向前传播",{"2":{"504":1}}],["输入可通过跨层数据线路更快地向前传播",{"2":{"501":1}}],["输入可用于未来迭代的训练数据",{"2":{"201":1}}],["输入序列的信息被编码到循环神经网络编码器的隐状态中",{"2":{"572":1}}],["输入序列的有效长度",{"2":{"534":1}}],["输入序列的不同部分被选择性地聚集在注意力池中",{"2":{"376":1}}],["输入序列对应的每个位置",{"2":{"404":1}}],["输入序列中与当前预测相关的部分",{"2":{"373":1}}],["输入序列是说话人的录音",{"2":{"295":1}}],["输入x的形状",{"2":{"382":4,"405":1}}],["输入x的形状为",{"2":{"375":1}}],["输入xt−1",{"2":{"347":1}}],["输入x和输出o的深层网络",{"2":{"241":1}}],["输入维度为d",{"2":{"339":1}}],["输入和隐状态可以拼接后与隐藏层中的一个权重变量相乘",{"2":{"307":1}}],["输入和输出都是任意长度的序列",{"2":{"550":1}}],["输入和输出都是可变长度的序列",{"2":{"295":1}}],["输入和输出形状一致",{"2":{"501":1}}],["输入和输出来自相同的词表",{"2":{"331":1}}],["输入和输出的通道数量都是d",{"2":{"397":1}}],["输入和输出的出现顺序基本相同",{"2":{"295":1}}],["输入和输出的数量基本上是相同的",{"2":{"295":1}}],["输入是房屋尺寸大小",{"2":{"1063":1}}],["输入是具有11个词元的句子",{"2":{"701":1}}],["输入是由当前时间步的输入和前一时间步的隐状态给出",{"2":{"540":1}}],["输入是文本",{"2":{"295":1}}],["输入是高度为3",{"2":{"126":1}}],["输入特征可能是生命体征",{"2":{"289":1}}],["输入的两个值必须一样",{"2":{"1102":1}}],["输入的具体内容",{"2":{"295":1}}],["输入的是垃圾",{"2":{"284":1}}],["输入的高度和宽度都为3",{"2":{"140":1}}],["输入在任一方向上越远离0点",{"2":{"237":1}}],["输入层不涉及任何计算",{"2":{"231":1}}],["输入往往是高维对象",{"2":{"192":1}}],["输入",{"2":{"128":1,"129":1,"145":1,"282":1,"386":1,"404":1,"573":1,"836":1,"1089":1,"1091":2}}],["图上的数据看起来可以分成两个分开的点集",{"2":{"1150":1}}],["图上画的这些点没有标签信息",{"2":{"1150":1}}],["图外",{"2":{"1143":1}}],["图中水平坐标",{"2":{"1146":1}}],["图中的矩阵尺寸为",{"2":{"1116":1}}],["图中有一只猫",{"2":{"292":1}}],["图中有两个凸集",{"2":{"50":1}}],["图形化日志",{"2":{"1328":1}}],["图形模式将会被启用",{"2":{"819":1}}],["图形处理器",{"2":{"457":1}}],["图片",{"2":{"1363":1,"1533":1}}],["图片文字识别",{"0":{"1170":1},"1":{"1171":1,"1172":1,"1173":1,"1174":1},"2":{"1193":1}}],["图片源自科林",{"2":{"800":1}}],["图片张量",{"2":{"582":2}}],["图",{"2":{"404":1,"841":1}}],["图灵在他著名的论文",{"2":{"299":1}}],["图灵",{"2":{"299":1}}],["图像文字识别应用所作的事是",{"2":{"1171":1}}],["图像会附带一个标签",{"2":{"1029":1}}],["图像包含数百万像素",{"2":{"1029":1}}],["图像实际上是狗或猫二选一",{"2":{"1025":1}}],["图像以n维数组形式出现",{"2":{"993":1}}],["图像可能拥有不同数量个边界框",{"2":{"932":1}}],["图像上4行和4列的锚框的中心是均匀分布的",{"2":{"912":1}}],["图像数据集通常以图像文件的形式出现",{"2":{"887":1}}],["图像增广和混合编程",{"2":{"897":1}}],["图像增广基于现有的训练数据生成随机图像",{"2":{"884":1}}],["图像增广技术对于alexnet的成功是必不可少的",{"2":{"877":1}}],["图像增广在对训练图像进行一系列的随机变化之后",{"2":{"877":1}}],["图像增广",{"0":{"877":1,"891":1,"903":1},"1":{"878":1,"879":1,"880":1,"881":1,"882":1,"883":1,"884":1,"885":1}}],["图像",{"2":{"872":2}}],["图像宽度",{"2":{"848":1}}],["图像高度",{"2":{"848":1}}],["图像分割可能会将狗分为两个区域",{"2":{"944":1}}],["图像分割将图像划分为若干组成区域",{"2":{"944":1}}],["图像分割和实例分割",{"0":{"944":1}}],["图像分辨率更高",{"2":{"463":1}}],["图像分类中使用的哪种图像增强方法是难以用于语义分割的",{"2":{"951":1}}],["图像分类数据集",{"0":{"581":1},"1":{"582":1,"583":1,"584":1,"585":1,"586":1}}],["图像分类问题中",{"2":{"295":1}}],["图像分类",{"0":{"887":1},"1":{"888":1,"889":1,"890":1,"891":1,"892":1,"893":1,"894":1,"895":1,"896":1,"897":1,"898":1},"2":{"289":1,"1543":1}}],["图像特征都是机械地计算出来的",{"2":{"455":1}}],["图像的小批量的形状为",{"2":{"932":1}}],["图像的大小和纵横比各有不同",{"2":{"872":1}}],["图像的原始像素值",{"2":{"302":1}}],["图像的平移不变性使我们以相同的方式处理局部图像",{"2":{"159":1}}],["图像描绘狗的似然",{"2":{"230":1}}],["图像中坐标的原点是图像的左上角",{"2":{"858":1}}],["图像中是否到处都有存在沃尔多的可能",{"2":{"158":1}}],["图像中目标的边缘检测",{"0":{"128":1}}],["图像不是二维张量",{"2":{"158":1}}],["图像是否包含一只猫呢",{"2":{"145":1}}],["图像通过lenet",{"2":{"136":1}}],["图像卷积",{"0":{"125":1},"1":{"126":1,"127":1,"128":1,"129":1,"130":1,"131":1,"132":1,"133":1}}],["反向代理缓存",{"2":{"1371":1}}],["反向代理配置",{"2":{"1364":1}}],["反向代理",{"0":{"1368":1},"2":{"1361":1}}],["反向代理服务器",{"2":{"1359":1}}],["反向函数就是np",{"2":{"1183":1}}],["反向传播算法做的是",{"2":{"1122":1}}],["反向传播算法似乎并不简洁",{"2":{"1122":1}}],["反向传播算法的直观理解",{"0":{"1122":1},"2":{"1193":1}}],["反向传播算法",{"0":{"1121":1},"2":{"1193":1}}],["反向传播在每个gpu上分别执行",{"2":{"837":3}}],["反向传播几步后",{"2":{"624":1}}],["反向传播按相反的顺序",{"2":{"166":1}}],["反向传播重复利用前向传播中存储的中间值",{"2":{"165":1}}],["反向传播期间参数",{"2":{"165":1}}],["反向传播",{"0":{"164":1},"2":{"164":1,"576":2,"973":1}}],["反向传播和计算图",{"0":{"161":1},"1":{"162":1,"163":1,"164":1,"165":1,"166":1,"167":1}}],["反向传播的目的是计算梯度∂j",{"2":{"164":1}}],["反向传播的计算成本是多少",{"2":{"124":1}}],["反向传播的内存占用是多少",{"2":{"124":1}}],["反垃圾邮件",{"2":{"1058":1}}],["反传",{"2":{"797":2}}],["反之也同样容易",{"2":{"1022":2}}],["反之亦然",{"2":{"683":1,"748":1,"1030":1}}],["反之亦然吗",{"2":{"124":1}}],["反之",{"2":{"568":1,"920":1,"1144":1}}],["反而只会使本小节中的符号变得混乱",{"2":{"307":1}}],["反应了德国人喜欢把动词放在句尾的特殊倾向",{"2":{"295":1}}],["反面",{"2":{"252":1}}],["看这条绿线",{"2":{"1145":1}}],["看作更高级的特征",{"2":{"1100":1}}],["看作x0",{"2":{"1093":1}}],["看作θtx",{"2":{"1093":1}}],["看作对事件的概率分配",{"2":{"1026":1}}],["看特征值里是否有一些多余的特征",{"2":{"1086":1}}],["看出图像会显得很扁",{"2":{"1082":1}}],["看上去有些模糊",{"2":{"1148":1}}],["看上去有点不一样",{"2":{"1061":1}}],["看上去同线性回归一样",{"2":{"1117":1}}],["看上去绝对是个复杂的程序",{"2":{"1061":1}}],["看成是标量",{"2":{"1060":1}}],["看到的一些建立的各种分布模型",{"2":{"1185":1}}],["看到了逻辑回归",{"2":{"1148":1}}],["看到一个5",{"2":{"1028":1}}],["看到奇数",{"2":{"1027":2}}],["看到5",{"2":{"1027":1}}],["看到",{"2":{"316":1}}],["看起来就是这个样子",{"2":{"1178":1}}],["看起来就像使用3个聚类来进行聚类是正确的",{"2":{"1154":1}}],["看起来就好像有一个很清楚的肘在那儿",{"2":{"1154":1}}],["看起来是这个样子",{"2":{"1060":1}}],["看起来很眼熟",{"2":{"932":1}}],["看起来很无聊",{"2":{"318":1}}],["看起来非常类似于lenet",{"2":{"832":1}}],["看起来仍然不错",{"2":{"351":1}}],["看起来不像我们以前见过的任何垃圾邮件",{"2":{"187":1}}],["看起来似乎没有多大意义",{"2":{"122":1}}],["看",{"2":{"142":1,"1098":5,"1138":1}}],["看看这些样本是否有某种系统化的趋势",{"2":{"1138":1}}],["看看这个无监督学习算法",{"2":{"1061":1}}],["看看我们是否能够有一个更简单的方法",{"2":{"1093":1}}],["看看我们的周围",{"2":{"1067":1}}],["看看",{"2":{"1089":1}}],["看看代价函数到底是在干什么",{"2":{"1065":1}}],["看看会发生什么",{"2":{"979":1,"1004":1}}],["看看会得到什么算法",{"2":{"59":1}}],["看看在这场比赛中能达到什么准确度和排名",{"2":{"898":1}}],["看看turing",{"2":{"815":1}}],["看看深度学习框架是否会自动地并行地执行它们",{"2":{"799":1}}],["看看有什么不同",{"2":{"790":1}}],["看看它们的区别",{"2":{"790":2}}],["看看它如何影响数据加载速度",{"2":{"779":1}}],["看看它是否随着时间的推移而改善",{"2":{"115":1}}],["看看cpu和gpu之间的速度差异",{"2":{"453":1}}],["看看如果仅对该参数进行少量变动",{"2":{"287":1}}],["看看如何处理二维图像数据和隐藏表示",{"2":{"126":1}}],["看看关于按层自适应速率缩放的论文",{"2":{"250":1}}],["卷积输入x和转置的卷积输出z具有相同的形状",{"2":{"972":1}}],["卷积块的通道数控制了输出通道数相对于输入通道数的增长",{"2":{"480":1}}],["卷积块编码得到的表征在输出之前需由一个或多个全连接层进行处理",{"2":{"138":1}}],["卷积和矩阵乘法",{"2":{"457":1}}],["卷积是当把一个函数",{"2":{"156":1}}],["卷积",{"0":{"156":1},"2":{"156":1}}],["卷积窗口中某个位置包含的输入子张量",{"2":{"699":1}}],["卷积窗口在输入张量上从左向右滑动",{"2":{"699":1}}],["卷积窗口的形状是11×11",{"2":{"459":1}}],["卷积窗口分别向下滑动三行和向右滑动两列",{"2":{"142":1}}],["卷积窗口可以跳过中间位置",{"2":{"142":1}}],["卷积窗口从输入张量的左上角开始",{"2":{"126":1,"142":1}}],["卷积的反向传播函数可以通过将其输入与转置的权重矩阵w⊤相乘来实现",{"2":{"970":1}}],["卷积的前向传播函数可以通过将其输入与权重矩阵相乘并输出向量y=wx来实现",{"2":{"970":1}}],["卷积的输出具有高度p和宽度q",{"2":{"470":1}}],["卷积的输出形状取决于输入形状和卷积核的形状",{"2":{"140":1}}],["卷积的输出形状由批量大小",{"2":{"136":1}}],["卷积的本质是有效提取相邻像素间的相关特征",{"2":{"122":1}}],["卷积编码器",{"2":{"136":1}}],["卷积编码器和全连接层密集块",{"2":{"136":1}}],["卷积神经网络为图像抽取的特征图中的每个单元均得到一个长度为c的新特征",{"2":{"939":1}}],["卷积神经网络的前向传播是独立的",{"2":{"938":1}}],["卷积神经网络的输入是由原始像素值或是经过简单预处理",{"2":{"454":1}}],["卷积神经网络在计算机视觉和机器学习领域中很有名气",{"2":{"454":1}}],["卷积神经网络和自注意力都拥有并行计算的优势",{"2":{"397":1,"401":1}}],["卷积神经网络是分层的",{"2":{"397":1}}],["卷积神经网络与多层感知机的训练差异可能是巨大的",{"2":{"155":1}}],["卷积神经网络正是将空间不变性",{"2":{"152":1}}],["卷积神经网络中卷积核的高度和宽度通常为奇数",{"2":{"141":1}}],["卷积神经网络也越来越受欢迎",{"2":{"134":1}}],["卷积神经网络需要的参数少于全连接架构的网络",{"2":{"134":1}}],["卷积神经网络",{"0":{"134":1,"135":1},"1":{"136":1,"137":1,"138":1,"139":1},"2":{"138":1,"151":1,"159":1,"300":1,"656":1,"663":2}}],["卷积核宽度分别为3",{"2":{"702":1}}],["卷积核需要具有相同数量的输入通道",{"2":{"699":1}}],["卷积核的大小是奇数",{"2":{"141":1}}],["卷积核的高度和宽度都为2",{"2":{"140":1}}],["卷积核的高度和宽度都是2",{"2":{"126":1}}],["卷积核形状为kh×kw",{"2":{"140":1}}],["卷积核k只可以检测垂直边缘",{"2":{"128":1}}],["卷积核",{"2":{"126":1,"128":1}}],["卷积核大小为co×ci×kh×kw",{"2":{"124":1}}],["卷积核和输出看作二维张量",{"2":{"119":1}}],["卷积层部分",{"2":{"508":4}}],["卷积层也适合于文本数据吗",{"2":{"160":1}}],["卷积层通常比全连接层需要更少的参数",{"2":{"159":1}}],["卷积层根据滤波器v选取给定大小的窗口",{"2":{"157":1}}],["卷积层仍然可以识别到模式",{"2":{"146":1}}],["卷积层的输入和输出由四维张量组成",{"2":{"494":1}}],["卷积层的输出不会受太大影响",{"2":{"132":1}}],["卷积层的输出都不会受到影响",{"2":{"130":1}}],["卷积层的一个简单应用",{"2":{"128":1}}],["卷积层中的两个被训练的参数是卷积核权重和标量偏置",{"2":{"127":1}}],["卷积层对输入和卷积核权重进行互相关运算",{"2":{"127":1}}],["卷积层是个错误的叫法",{"2":{"126":1}}],["卷积层",{"0":{"122":1,"127":1,"470":1},"2":{"490":1,"505":1}}],["构成一个含有多个变量的模型",{"2":{"1080":1}}],["构造函数体可以为空",{"2":{"1428":1}}],["构造函数中",{"2":{"127":1}}],["构造他们以为的简单的方法",{"2":{"1138":1}}],["构造模型",{"0":{"862":1}}],["构造一个paddle数据迭代器",{"2":{"590":1}}],["构造一个pytorch数据迭代器",{"2":{"590":1}}],["构造一个tensorflow数据迭代器",{"2":{"590":1}}],["构造一个gluon数据迭代器",{"2":{"590":1}}],["构造一个没有任何参数的自定义层",{"2":{"413":1}}],["构造一个二维卷积层",{"2":{"129":4}}],["构造了一个具有3个输出通道的卷积核",{"2":{"121":1}}],["构建复杂的现代单页应用",{"2":{"1526":1}}],["构建生产包",{"2":{"1315":1}}],["构建生产版本",{"2":{"16":1}}],["构建出完美的机器学习系统",{"2":{"1176":1}}],["构建出具有出色性能的系统",{"2":{"800":1}}],["构建项目",{"2":{"1053":1}}],["构建状态驱动的智能体系统",{"2":{"1052":1}}],["构建命令行工具",{"2":{"1047":1}}],["构建从rgb到voc类别索引的映射",{"2":{"945":3}}],["构建并可视化两个iou为0",{"2":{"856":1}}],["构建并行和分布式训练算法的能力有了显著提高",{"2":{"300":1}}],["构建包含共享参数层的多层感知机并对其进行训练",{"2":{"439":1}}],["构建词表将词元字符串映射为数字索引",{"2":{"365":1}}],["构建词表",{"2":{"363":1}}],["构建一个学习算法的推荐方法为",{"2":{"1138":1}}],["构建一个字典",{"2":{"363":1}}],["构建一个分类器",{"2":{"203":1}}],["构建一个具有对角线边缘的图像x",{"2":{"133":1}}],["构建",{"0":{"16":1}}],["执行创建命令",{"2":{"1443":1}}],["执行测试脚本",{"2":{"1315":1}}],["执行所在环境",{"2":{"1312":1}}],["执行中",{"2":{"1252":1}}],["执行逻辑",{"2":{"1052":1}}],["执行轨迹",{"2":{"1052":1}}],["执行体",{"2":{"1050":1}}],["执行原地操作",{"2":{"1021":1}}],["执行它的反向传播函数",{"2":{"978":1}}],["执行前向传播",{"2":{"959":1}}],["执行代码并观察遇到的错误",{"2":{"823":1}}],["执行计算",{"2":{"801":1}}],["执行多条指令并同步以获得中间结果",{"2":{"794":1}}],["执行10000次计算所花费的总时间可以减少到t1+10000t2+t3",{"2":{"792":1}}],["执行10000次计算所需的总时间约为10000",{"2":{"792":1}}],["执行",{"2":{"644":1}}],["执行的",{"2":{"592":2}}],["执行严格卷积运算时",{"2":{"130":1}}],["执行互相关运算",{"2":{"121":1,"128":1}}],["执行更新",{"2":{"20":1}}],["迭代的过程一定会是每一次迭代都在减小代价函数",{"2":{"1152":1}}],["迭代模型参数",{"2":{"917":1}}],["迭代轮数",{"2":{"910":1}}],["迭代周期",{"2":{"635":1}}],["迭代周期数和学习率",{"2":{"628":1}}],["迭代期间来自两个相邻的小批量中的子序列在原始序列中确实是相邻的",{"2":{"321":1}}],["迭代卷积核",{"2":{"129":4}}],["迭代",{"2":{"121":1,"1151":3}}],["维护数据",{"2":{"1471":1}}],["维护网络规则",{"2":{"1377":1}}],["维护与服务器一对一连接的协议客户端",{"2":{"1042":1}}],["维向量",{"2":{"1093":1}}],["维向量的集合是凸集",{"2":{"40":1}}],["维参数矢量θ",{"2":{"1086":1}}],["维数",{"2":{"991":1}}],["维基百科的所有条目",{"2":{"316":1}}],["维度和形状",{"0":{"991":1}}],["维度和存储可以自动推断",{"2":{"596":2}}],["维度",{"2":{"119":1,"991":1}}],["比调用循环快",{"2":{"1169":1}}],["比随着感觉走要更好",{"2":{"1137":1}}],["比现在解决问题的方法强大n倍的学习算法",{"2":{"1117":1}}],["比现代深度学习兴起时间还要早",{"2":{"134":1}}],["比起较大的目标",{"2":{"912":1}}],["比赛网址是https",{"2":{"899":1}}],["比赛数据集分为训练集和测试集",{"2":{"888":1,"900":1}}],["比赛的网址是https",{"2":{"887":1}}],["比赛",{"0":{"887":1},"1":{"888":1,"889":1,"890":1,"891":1,"892":1,"893":1,"894":1,"895":1,"896":1,"897":1,"898":1}}],["比硬盘驱动器快一个数量级",{"2":{"805":1}}],["比硬盘驱动器快3个数量级",{"2":{"805":1}}],["比任何学习算法带来的进步要大得多",{"2":{"454":1}}],["比整个模型小",{"2":{"422":1}}],["比单个层大",{"2":{"422":1}}],["比",{"2":{"315":1,"741":1}}],["比方说100",{"2":{"1111":1}}],["比方说",{"2":{"298":1,"1063":1,"1080":1,"1088":1,"1092":2,"1111":1}}],["比例",{"2":{"198":1}}],["比率来计算权重βi",{"2":{"192":1}}],["比较麻烦",{"2":{"1454":1}}],["比较运算符",{"0":{"1219":1}}],["比较标注边界框和标注类别哪个需要更长的时间",{"2":{"860":1}}],["比较不同学习率时模型的精确度",{"2":{"839":1}}],["比较和聚合",{"2":{"683":1}}],["比较和汇总",{"2":{"673":1}}],["比较步骤和聚合步骤组合在一起",{"2":{"677":1}}],["比较真实参数和通过训练学到的参数来评估训练的成功程度",{"2":{"605":1}}],["比较生成数据集的真实参数和通过有限数据训练获得的模型参数",{"2":{"595":1}}],["比较门控循环单元",{"2":{"563":1}}],["比较rnn",{"2":{"549":1}}],["比较使用和不使用图像增广的训练结果和测试精度",{"2":{"885":1}}],["比较使用门控循环单元替换长短期记忆网络后模型的精确度和训练速度",{"2":{"531":1}}],["比较使用暂退法和权重衰减的效果",{"2":{"178":1}}],["比较浅层且宽的卷积更有效",{"2":{"510":1}}],["比较lenet在使用和不使用批量规范化情况下的学习率",{"2":{"477":1}}],["比较卷积神经网络",{"0":{"397":1}}],["比较",{"0":{"675":1},"2":{"388":1,"1217":1}}],["比较策略",{"0":{"311":1}}],["比较随机梯度下降的收敛性",{"2":{"118":1}}],["比如同时在多个操作系统和",{"2":{"1313":1}}],["比如为亚马逊和像网飞这样的公司",{"2":{"1187":1}}],["比如引擎运转时产生的热量",{"2":{"1178":1}}],["比如学习曲线",{"2":{"1176":1}}],["比如x",{"2":{"1176":1}}],["比如x1的平方",{"2":{"1129":1}}],["比如z",{"2":{"1161":1}}],["比如市场分割",{"2":{"1150":1}}],["比如这个我之前提到的样本",{"2":{"1145":1}}],["比如这个样本",{"2":{"1145":1}}],["比如这里",{"2":{"1127":1}}],["比如我希望它小于等于",{"2":{"1144":1}}],["比如我们加入一个额外的正样本",{"2":{"1144":1}}],["比如我们可以把c设置成了非常大的常数",{"2":{"1144":1}}],["比如我们假设c的值为100000或者其它非常大的数",{"2":{"1144":1}}],["比如我们不用直线拟合这些数据",{"2":{"1060":1}}],["比如我们经常使用的",{"2":{"781":1}}],["比如大于等于1",{"2":{"1144":1}}],["比如大矩阵的乘法",{"2":{"453":1}}],["比如有很多特征的逻辑回归或线性回归",{"2":{"1141":1}}],["比如他们会说",{"2":{"1129":1}}],["比如使用电话调查来得到更多的房屋案例",{"2":{"1129":1}}],["比如1",{"2":{"1112":1}}],["比如1000个类别",{"2":{"188":1}}],["比如如果你正在使用c",{"2":{"1111":1}}],["比如以下这种情况",{"2":{"1103":1}}],["比如逻辑与",{"2":{"1101":1}}],["比如matlab或者你正在用python",{"2":{"1093":1}}],["比如if",{"2":{"1091":1}}],["比如改成",{"2":{"1091":1}}],["比如设置a为一个3×2的矩阵",{"2":{"1090":1}}],["比如键入",{"2":{"1089":1}}],["比如你们可能熟悉的c或c++",{"2":{"1092":1}}],["比如你经常发email的",{"2":{"1061":1}}],["比如你朋友那个新房子的价格",{"2":{"1060":1}}],["比如肿块密度",{"2":{"1060":1}}],["比如是否在1",{"2":{"1028":1}}],["比如圆",{"2":{"980":1}}],["比如指定高度h2和宽度w2",{"2":{"938":1}}],["比如axis=0",{"2":{"996":1}}],["比如aws",{"2":{"819":1}}],["比如a=bc",{"2":{"77":1}}],["比如sentences",{"2":{"724":1}}],["比如spacy和nltk",{"2":{"724":1}}],["比如文本标注",{"2":{"659":1}}],["比如某些样本可能被误标",{"2":{"646":1}}],["比如说推荐系统",{"2":{"1176":1}}],["比如说眼睛想要给大脑传递一个消息",{"2":{"1099":1}}],["比如说我们想对v中的每个元素都加1",{"2":{"1090":1}}],["比如说我们试图预测婴儿儿童青少年青年人中年人老年人",{"2":{"640":1}}],["比如说现在有两个矩阵a和b",{"2":{"1075":1}}],["比如说可能有三种乳腺癌",{"2":{"1060":1}}],["比如说",{"2":{"1058":1,"1090":1,"1093":1,"1111":1,"1145":1,"1150":1}}],["比如说batch",{"2":{"472":1}}],["比如预测房屋被售出价格",{"2":{"639":1}}],["比如预测房屋价格",{"2":{"609":1}}],["比如一次房屋交易相对应的数据",{"2":{"609":1}}],["比如一个二次方模型",{"2":{"1084":1}}],["比如一个",{"2":{"285":1}}],["比如p",{"2":{"515":1}}],["比如gpu",{"2":{"446":1}}],["比如想在一个新的网络中使用之前网络的前两层",{"2":{"444":1}}],["比如初始化为1",{"2":{"435":1}}],["比如管理访问",{"2":{"414":1}}],["比如人类的视觉神经系统大约每秒收到108位的信息",{"2":{"354":1}}],["比如二元语法",{"2":{"318":1}}],["比如打开电灯开关",{"2":{"301":1}}],["比如下面这个例子",{"2":{"295":1}}],["比如下面是一些例子",{"2":{"193":1}}],["比如像素和抽象类别之间的关系",{"2":{"281":1}}],["比如从2到3",{"2":{"269":1}}],["比如当我们对微博的主题进行分类时",{"2":{"253":1}}],["比如当图像不满足平移不变时",{"2":{"155":1}}],["比如在数字间相加或相乘",{"2":{"989":1}}],["比如在cpu和gpu之间",{"2":{"797":1}}],["比如在部署中进行预测",{"2":{"440":1}}],["比如在处理卷积神经网络时",{"2":{"423":1}}],["比如在一个有关医疗的训练数据集中",{"2":{"284":1}}],["比如在",{"2":{"171":1}}],["比如包含1024×1024×3个像素",{"2":{"158":1}}],["比如u",{"2":{"154":1}}],["比如",{"2":{"105":1,"140":1,"141":1,"201":1,"253":2,"255":1,"281":1,"282":4,"284":3,"289":1,"290":2,"291":1,"292":2,"294":1,"295":1,"296":3,"304":1,"316":1,"342":1,"345":1,"573":1,"754":1,"881":1,"912":1,"1029":2,"1034":1,"1058":1,"1061":1,"1064":1,"1089":1,"1090":1,"1092":1,"1111":1,"1127":1,"1141":2,"1143":1,"1144":1,"1168":1,"1176":2}}],["比如η=0",{"2":{"59":1}}],["比如f",{"2":{"59":1,"156":1}}],["比如权重衰减",{"2":{"49":1}}],["比如λ=1−p|x∗−x",{"2":{"44":1}}],["向当前组件的子组件通信",{"2":{"1501":1}}],["向外部暴露数据",{"2":{"1471":2}}],["向上移动",{"2":{"1413":1}}],["向",{"2":{"1049":1}}],["向kaggle提交结果的方法与",{"2":{"896":1}}],["向目标模型添加输出层",{"2":{"870":1}}],["向多个设备分发参数",{"2":{"835":1}}],["向内存发送地址并设置传输大约需要100ns",{"2":{"802":1}}],["向右的方向为x轴的正方向",{"2":{"858":1}}],["向右和向左遍历",{"2":{"709":1}}],["向右滑动",{"2":{"142":1}}],["向图表中添加多个数据点",{"2":{"635":1}}],["向量v可以画在这里",{"2":{"1145":1}}],["向量v",{"2":{"1092":1}}],["向量vi和ui分别表示词wi作为中心词和上下文词",{"2":{"742":1}}],["向量是一种特殊的矩阵",{"2":{"1072":1}}],["向量是一阶张量",{"2":{"993":1}}],["向量泛化自标量",{"2":{"1003":1}}],["向量范数要满足一些属性",{"2":{"1000":1}}],["向量范数是将向量映射到标量的函数f",{"2":{"1000":1}}],["向量的重要性进行排序",{"2":{"1158":1}}],["向量的范数是表示一个向量有多大",{"2":{"1000":1}}],["向量的长度通常称为向量的维度",{"2":{"991":1}}],["向量积的知识后",{"2":{"999":1}}],["向量积来描述在给定前一层的值时",{"2":{"998":1}}],["向量积",{"0":{"998":1},"2":{"998":7,"999":1}}],["向量或轴的维度被用来表示向量或轴的长度",{"2":{"991":1}}],["向量只是一个数字数组",{"2":{"991":1}}],["向量x可以写为",{"2":{"990":1}}],["向量x对应于单个数据样本的特征",{"2":{"610":1}}],["向量通常记为粗体",{"2":{"990":1}}],["向量可以被视为标量值组成的列表",{"2":{"990":1}}],["向量",{"0":{"990":1},"1":{"991":1},"2":{"983":1,"994":1,"1003":3}}],["向量y关于向量x的导数的最自然解释是一个矩阵",{"2":{"975":1}}],["向量乘法",{"2":{"644":1}}],["向量乘法再加上偏置b得到的",{"2":{"641":1}}],["向量乘法表示为",{"2":{"610":1}}],["向量乘法后加上偏置b",{"2":{"602":1}}],["向量乘法得到它的每个输出",{"2":{"591":1}}],["向量和标量的乘法",{"2":{"312":1}}],["向量和矩阵",{"2":{"307":1}}],["向量化",{"0":{"1093":1,"1191":1},"2":{"1193":2}}],["向量化使代码更加高效",{"2":{"82":1}}],["向量化和缓存",{"0":{"77":1}}],["向用户推荐他们可能喜欢",{"2":{"281":1}}],["向本节中描述的模型的隐藏层添加偏置项",{"2":{"167":1}}],["向下移动",{"2":{"1413":1}}],["向下翻转",{"2":{"1090":1}}],["向下的方向为y轴的正方向",{"2":{"858":1}}],["向下",{"2":{"142":1}}],["向梯度添加正态噪声等同于最小化损失函数f",{"2":{"118":1}}],["首都",{"2":{"751":1}}],["首选随机梯度下降",{"2":{"117":1}}],["首先训练模型能够区分字符与非字符",{"2":{"1172":1}}],["首先要做的是用许多固定尺寸的图片来训练一个能够准确识别行人的模型",{"2":{"1172":1}}],["首先要做什么",{"0":{"1137":1},"2":{"1193":1}}],["首先对训练集随机",{"2":{"1165":1}}],["首先应该做的事是去检查一个这么大规模的训练集是否真的必要",{"2":{"1164":1}}],["首先应该通过观察所有特征检查是否有多余的特征",{"2":{"1086":1}}],["首先选择k个随机的点",{"2":{"1151":1}}],["首先大部分算法",{"2":{"1141":1}}],["首先引入一些便于稍后讨论的新标记方法",{"2":{"1120":1}}],["首先构造一个能表达",{"2":{"1102":1}}],["首先构造一个3行1列的1向量",{"2":{"1090":1}}],["首先初始化我的梯度下降算法",{"2":{"1068":1}}],["首先需要先掌握一些基本技能",{"2":{"987":1}}],["首先需要注册一个kaggle账户",{"2":{"887":1}}],["首先需要注册一个账户",{"2":{"207":1}}],["首先将内容图像和风格图像的高和宽分别调整为300和450像素",{"2":{"927":1}}],["首先使用的批量大小是256",{"2":{"837":1}}],["首先使用经典统计模型的函数依赖类型",{"2":{"520":1}}],["首先导入spacy",{"2":{"717":1}}],["首先我们考虑一下滤波器",{"2":{"487":1}}],["首先我们需要访问底层的数值",{"2":{"431":1}}],["首先我们反思一下在模型训练期间到底发生了什么",{"2":{"190":1}}],["首先回顾一个经典注意力框架",{"2":{"379":1}}],["首先是使内存总线变得更宽",{"2":{"802":1}}],["首先是含3×3卷积层的第二条路径输出最多通道",{"2":{"488":1}}],["首先是如何使用单个gpu",{"2":{"445":1}}],["首先是检查",{"2":{"351":1}}],["首先是由",{"2":{"300":1}}],["首先定义预测函数来生成prefix之后的新字符",{"2":{"333":1}}],["首先为集合中的每个元素分配相应的相关性分数",{"2":{"293":1}}],["首先介绍一些核心组件",{"2":{"283":1}}],["首先让我们把数据放到",{"2":{"1092":1}}],["首先让我们",{"2":{"263":1}}],["首先凸函数的局部极小值也是全局极小值",{"2":{"44":1}}],["首先",{"2":{"25":1,"33":2,"46":1,"66":1,"75":1,"77":1,"126":1,"128":1,"153":1,"161":1,"179":1,"180":1,"206":1,"209":2,"210":1,"217":1,"229":1,"258":1,"271":1,"273":1,"281":1,"294":1,"299":1,"301":1,"311":1,"312":1,"316":1,"319":1,"340":1,"350":1,"356":1,"361":1,"375":1,"413":1,"418":1,"423":1,"430":1,"445":1,"457":2,"467":1,"471":1,"500":1,"513":1,"532":1,"543":1,"565":1,"572":1,"609":1,"612":1,"615":1,"617":1,"634":1,"635":1,"692":1,"699":1,"725":1,"733":1,"756":1,"757":1,"760":1,"761":1,"811":1,"817":1,"819":1,"835":1,"847":1,"853":1,"874":1,"887":1,"890":1,"912":1,"917":1,"918":1,"930":1,"953":1,"961":1,"974":1,"1016":2,"1017":6,"1021":1,"1025":1,"1026":1,"1086":1,"1092":1,"1093":1,"1141":1,"1143":1,"1145":1,"1185":1}}],["恰好一次的概率是",{"2":{"116":1}}],["恰到好处",{"2":{"58":1}}],["δj",{"2":{"1122":4}}],["δ是一个向量",{"2":{"1093":1}}],["δ在这里是一个向量",{"2":{"1093":1}}],["δ",{"2":{"1093":2,"1121":2}}],["δωj",{"2":{"400":8}}],["δ的范围之外",{"2":{"155":1}}],["δ或|b|",{"2":{"155":1}}],["δyi",{"2":{"116":1}}],["δxt=ρδxt−1+",{"2":{"20":1}}],["δxt用于存储模型本身中参数变化二阶导数的泄露平均值",{"2":{"20":1}}],["令特征2拥有较大的偏差",{"2":{"1184":1}}],["令特征1拥有较小的偏差",{"2":{"1184":1}}],["令其实现的唯一的办法就是这两个数较大",{"2":{"1145":1}}],["令其输入麦克风采集到的原始音频片段",{"2":{"282":1}}],["令θ0=0",{"2":{"1145":1}}],["令∂j",{"2":{"1086":1}}],["令x=1",{"2":{"981":1}}],["令n等于样本最少的类别中的图像数量",{"2":{"890":1}}],["令ωj=1",{"2":{"400":1}}],["令",{"2":{"115":1,"241":1}}],["令e",{"2":{"60":1}}],["所做的",{"2":{"1154":1}}],["所做的而向量化的方法",{"2":{"1093":1}}],["所创建的大量数据在应用这些算法时",{"2":{"1143":1}}],["所谓的异常检测问题就是",{"2":{"1178":1}}],["所谓的瞬时变化率是基于x中的变化h",{"2":{"981":1}}],["所谓的时髦",{"2":{"183":1}}],["所得图像为原始面积的0",{"2":{"903":3}}],["所需的时间",{"2":{"820":1}}],["所需的参数更少",{"2":{"135":1}}],["所花费的时间不比处理一个样本时多太多",{"2":{"600":1}}],["所定义的加性注意力打分函数计算的",{"2":{"374":1}}],["所述的prod运算符",{"2":{"312":1}}],["所示的蘑菇",{"2":{"291":1}}],["所示",{"2":{"183":1,"207":1,"289":1,"295":1,"532":1,"851":3}}],["所涉及的计算",{"2":{"161":1}}],["所有钩子执行的",{"2":{"1451":1}}],["所有属性都是可选的",{"2":{"1410":1}}],["所有属性都是只读的",{"2":{"1410":1}}],["所有操作通过它的",{"2":{"1376":1}}],["所有写操作先写日志",{"2":{"1202":1}}],["所有样本的s",{"2":{"1154":1}}],["所有机器学习方法都涉及从数据中提取信息",{"2":{"987":1}}],["所有中间结果相加以获得最终结果",{"2":{"968":1}}],["所有模型参数初始化为随机值",{"2":{"874":1}}],["所有预测的非背景边界框都按置信度降序排序",{"2":{"854":1}}],["所有预测词元的掩码都设置为1",{"2":{"575":1}}],["所有gpu上的参数更新完成",{"2":{"843":1}}],["所有gpu尽管有不同的观测结果",{"2":{"832":1}}],["所有这些工具都能有效地指引你决定接下来应该怎样做",{"2":{"1176":1}}],["所有这些语言都具有各种线性代数库",{"2":{"1093":1}}],["所有这些都是联合发生的随机变量",{"2":{"1029":1}}],["所有这些都需要更快",{"2":{"811":1}}],["所有这些参数都来自",{"2":{"340":1}}],["所有提取的子词都必须是指定的长度",{"2":{"757":1}}],["所有以wi为中心词的上下文词形成一个词索引的多重集ci",{"2":{"742":1}}],["所有前提中的词元与假设中词元i软对齐",{"2":{"675":1}}],["所有假设中的词元与前提中词元i软对齐",{"2":{"675":1}}],["所有其他情况",{"2":{"665":1}}],["所有格结尾",{"2":{"659":1}}],["所有输入x1",{"2":{"641":1}}],["所有输入都得到值0",{"2":{"270":1}}],["所有可能的组合进行求和",{"2":{"519":1}}],["所有可能的子序列的覆盖范围将是有限的",{"2":{"319":1}}],["所有变量和相关的计算都分配给cpu",{"2":{"445":3}}],["所有组成层的参数集合",{"2":{"422":1}}],["所有纸制品都是黑白印刷的",{"2":{"355":1}}],["所有需要存储的都是指向翻译过程的中间状态的指针",{"2":{"300":1}}],["所有图像共分为10个类别",{"2":{"217":1}}],["所有均值消失",{"2":{"209":1}}],["所有类似的数据集都托管在地址为data",{"2":{"206":1}}],["所有的数据都会分到一个聚类里",{"2":{"1154":1}}],["所有的",{"2":{"1115":1}}],["所有的cpu将梯度发送到中央参数服务器中",{"2":{"843":1}}],["所有的例子都与监督学习有关",{"2":{"296":1}}],["所有的路沿都被渲染成了相同的纹理",{"2":{"186":1}}],["所有的申请者都会穿牛津鞋",{"2":{"179":1}}],["所有元素都被保留",{"2":{"172":4}}],["所有元素都被丢弃",{"2":{"172":4}}],["所有边的填充行数和列数相同",{"2":{"141":1}}],["所有x和y都满足f",{"2":{"115":1}}],["所学的卷积核的权重张量",{"2":{"129":1}}],["所以如下代码并不会引起页面的更新",{"2":{"1455":1}}],["所以如果我们能让这些高次项的系数接近于0的话",{"2":{"1115":1}}],["所以如果神经元想要传递一个消息",{"2":{"1099":1}}],["所以如果你想要修改",{"2":{"1092":1}}],["所以如果键入",{"2":{"1089":1}}],["所以如果a太小的话",{"2":{"1068":1}}],["所以学习参数θ就是支持向量机假设函数的形式",{"2":{"1143":1}}],["所以上述表达式只留下了第二项",{"2":{"1143":1}}],["所以上面输出的估计值看起来不错",{"2":{"1026":1}}],["所以更准确的说",{"2":{"1122":1}}],["所以与线性回归不同",{"2":{"1117":1}}],["所以梯度下降算法将分两种情形",{"2":{"1116":1}}],["所以梯度下降将自动采取较小的幅度",{"2":{"1068":1}}],["所以对于正则化",{"2":{"1115":1}}],["所以对于这些算法的一种思路是",{"2":{"1111":1}}],["所以对这段可选材料大家放轻松吧",{"2":{"1086":1}}],["所以逻辑函数的梯度下降",{"2":{"1110":1}}],["所以实际上是不一样的",{"2":{"1109":1}}],["所以实际上没有必要再另外减小a",{"2":{"1068":1}}],["所以即使你没有完全理解为何是等价的",{"2":{"1093":1}}],["所以即使是在最佳值中",{"2":{"26":1}}],["所以θ就是θ",{"2":{"1093":1}}],["所以n等于2",{"2":{"1093":1}}],["所以说如果你需要定义一个函数并且返回多个值",{"2":{"1092":1}}],["所以最后的结果是取出向量",{"2":{"1092":1}}],["所以第一列的最大值就是8",{"2":{"1090":1}}],["所以0",{"2":{"1090":1}}],["所以元素小于3的返回1",{"2":{"1090":1}}],["所以现在",{"2":{"1089":1}}],["所以现在工作空间中啥都没了",{"2":{"1089":1}}],["所以现在很少需要跨gpu分解模型",{"2":{"459":1}}],["所以有",{"2":{"1086":1}}],["所以有必要定义一个函数",{"2":{"600":1}}],["所以当我有一个很大的机器学习问题时",{"2":{"1111":1}}],["所以当我们接近局部最低时",{"2":{"1068":1}}],["所以当所有这些位置的输入相同时",{"2":{"405":1}}],["所以随着梯度下降法的运行",{"2":{"1068":1}}],["所以你只需插入上述两个公式",{"2":{"1185":1}}],["所以你把这个偏导数项∂∂θjj",{"2":{"1110":1}}],["所以你可以用这个方法来求得每一行或每一列的最值",{"2":{"1090":1}}],["所以你将更新j",{"2":{"1067":1}}],["所以你希望预测离散输出0",{"2":{"1060":1}}],["所以不能确定我们得到的局部最小值是否便是全局最小值",{"2":{"1067":1}}],["所以不需要调用初始化函数",{"2":{"147":1}}],["所以是无监督学习",{"2":{"1061":1}}],["所以已知你朋友的信息",{"2":{"1061":1}}],["所以显示到一起",{"2":{"1061":1}}],["所以谷歌新闻做的就是搜索非常多的新闻事件",{"2":{"1061":1}}],["所以叫做聚类算法",{"2":{"1061":1}}],["所以人们显然会很在意这个问题",{"2":{"1060":1}}],["所以又把它看成一个连续的数值",{"2":{"1060":1}}],["所以房价实际上是一系列离散的值",{"2":{"1060":1}}],["所以我还是推荐你在交叉验证向量上来做误差分析",{"2":{"1138":1}}],["所以我强烈推荐在交叉验证集上来实施误差分析",{"2":{"1138":1}}],["所以我强烈建议不要用numpy或者r来完整这门课的作业",{"2":{"1088":1}}],["所以我写了这个关于theta的",{"2":{"1111":1}}],["所以我选择输入",{"2":{"1094":1}}],["所以我已经完成了作业的第一部分",{"2":{"1094":1}}],["所以我有θ0",{"2":{"1093":1}}],["所以我希望你们可以理解这个逻辑",{"2":{"1092":1}}],["所以我在这里输入带引号的r绘制余弦函数",{"2":{"1091":1}}],["所以我可以键入featuresx",{"2":{"1089":1}}],["所以我把它归为分类问题",{"2":{"1060":1}}],["所以我会花很多时间来教你这些机器学习",{"2":{"1059":1}}],["所以我认为需求远远没有被满足现在学习",{"2":{"1058":1}}],["所以我们谈到了偏差和方差的问题",{"2":{"1176":1}}],["所以我们要做的就是在一定程度上减小这些参数$",{"2":{"1115":1}}],["所以我们要求f是标量函数",{"2":{"744":1}}],["所以我们想要尽量减小这一项",{"2":{"1110":1}}],["所以我们在接下来的要研究的算法就叫做逻辑回归算法",{"2":{"1106":1}}],["所以我们在引用它时不会加粗",{"2":{"990":1}}],["所以我们的",{"2":{"1101":1}}],["所以我们刚才用",{"2":{"1089":1}}],["所以我们把这个当作监督学习",{"2":{"1061":1}}],["所以我们已知数据集",{"2":{"1061":1}}],["所以我们根据账号是否被盗过",{"2":{"1060":1}}],["所以我们只需要花几个美分把这封信寄到数千英里外",{"2":{"1058":1}}],["所以我们只需要一个字典raw",{"2":{"757":1}}],["所以我们知道真正的参数是什么",{"2":{"605":1}}],["所以我们用批量大小",{"2":{"604":1}}],["所以我们应该先定义损失函数",{"2":{"603":1}}],["所以我们将该数字设置为1",{"2":{"591":2}}],["所以我们可以在训练开始之前就提取出内容特征和风格特征",{"2":{"920":1}}],["所以我们可以直接实例化门控循环单元模型",{"2":{"547":1}}],["所以我们可以通过一个序列中所有的n个词元的交叉熵损失的平均值来衡量",{"2":{"342":1}}],["所以我们不能访问或操作它们",{"2":{"592":2}}],["所以我们不能盲目地将这一语言模型应用于任何预测任务",{"2":{"523":1}}],["所以我们不想让惩罚分配给一个特征的系数比分配给其他任何特征的系数更大",{"2":{"209":1}}],["所以我们需要将x移到那里",{"2":{"449":1}}],["所以我们也可以像通过嵌套列表索引一样访问它们",{"2":{"433":1}}],["所以我们会把视力最敏锐的地方放到咖啡上",{"2":{"355":1}}],["所以我们有",{"2":{"1101":1}}],["所以我们有相当大的自由度",{"2":{"319":1}}],["所以我们有隐藏层权重w",{"2":{"232":1}}],["所以我们通过d2l",{"2":{"275":1}}],["所以我们使用reshape将每个二维图像转换为一个长度为num",{"2":{"219":1}}],["所以我们最后一层的神经元应该对整个输入的全局敏感",{"2":{"145":1}}],["所以很自然地",{"2":{"1025":1}}],["所以很容易估计分布q",{"2":{"192":1}}],["所以它们往往最终比梯度下降收敛得快多了",{"2":{"1111":1}}],["所以它们的对数永远不会大于0",{"2":{"646":1}}],["所以它的shape与它的size相同",{"2":{"1017":1}}],["所以难以应用上述任何规则来微分这些函数",{"2":{"984":1}}],["所以传递一个1的梯度是合适的",{"2":{"975":1}}],["所以传输需要2",{"2":{"841":1}}],["所以下载可能需要一段时间",{"2":{"945":1}}],["所以需要在损失计算中指定通道维",{"2":{"865":1}}],["所以类别被标记为猫",{"2":{"853":1}}],["所以生成含所有锚框中心的网格",{"2":{"848":3}}],["所以总时间现在是",{"2":{"842":1}}],["所以稍微修改了一下",{"2":{"826":1}}],["所以几乎所有的现代cpu都包含向量处理单元",{"2":{"807":1}}],["所以独热向量不能编码词之间的相似性",{"2":{"781":1}}],["所以一种可能性是f",{"2":{"744":1}}],["所以平方损失项是",{"2":{"743":1}}],["所以除了一个项以外的所有项j都消失了",{"2":{"646":1}}],["所以softmax回归的输出层也是全连接层",{"2":{"641":1}}],["所以网络只在这两个gpu上初始化",{"2":{"827":1}}],["所以网络输出维度为10",{"2":{"630":1}}],["所以网络不可能知道输入层权重的维数",{"2":{"418":1}}],["所以通常我们在计算层数时不考虑输入层",{"2":{"618":1}}],["所以经验误差只是关于模型参数的函数",{"2":{"611":1}}],["所以没有人会手动计算梯度",{"2":{"601":1}}],["所以bleu为更长的n元语法的精确度分配更大的权重",{"2":{"578":1}}],["所以先介绍候选记忆元",{"2":{"554":1}}],["所以输出中的每个单元在输入上都有一个6×6的感受野",{"2":{"957":1}}],["所以输出层的10维对应于最后输出结果的数量",{"2":{"136":1}}],["所以输入和输出都选择相同数量",{"2":{"528":1}}],["所以无法直接与所有的gpu相连接",{"2":{"841":1}}],["所以无法利用这一点的序列模型将在相关任务上表现不佳",{"2":{"518":1}}],["所以无须减小高和宽",{"2":{"502":1}}],["所以每个稠密块将增加128个通道",{"2":{"482":1}}],["所以这是你在使用svm的时候不需要太去担心的一个问题",{"2":{"1148":1}}],["所以这推广到新的训练集上是不适用的",{"2":{"1130":1}}],["所以这样一来",{"2":{"1090":1}}],["所以这就是无监督学习",{"2":{"1061":1}}],["所以这些颜色",{"2":{"1061":1}}],["所以这些函数有时被称为损失函数",{"2":{"286":1}}],["所以这种优化是可以实现的",{"2":{"817":1}}],["所以这个减法运算是一个向量减法",{"2":{"1093":1}}],["所以这个颜色条显示不同深浅的颜色所对应的值",{"2":{"1091":1}}],["所以这个图标上面有",{"2":{"1089":1}}],["所以这个就是无监督学习",{"2":{"1061":1}}],["所以这个词汇集合的基数|y|就是词表的大小",{"2":{"512":1}}],["所以这个名字用词不当",{"2":{"475":1}}],["所以只能根据每个小批次的平均值和方差不断训练模型",{"2":{"467":1}}],["所以用类别数为10",{"2":{"461":4}}],["所以模型本身难以序列化",{"2":{"442":1}}],["所以模型需要更多的迭代周期来更好地收敛",{"2":{"335":1}}],["所以参数的梯度处于初始状态",{"2":{"431":1}}],["所以在大多数实现线性回归中",{"2":{"1086":1}}],["所以在4×5矩阵上使用它进行尝试",{"2":{"836":1}}],["所以在每个词",{"2":{"757":1}}],["所以在获得词元表示之前",{"2":{"713":3}}],["所以在这里",{"2":{"591":2}}],["所以在这个任务中是有可能记住整个数据集的",{"2":{"251":1}}],["所以在最后一个时间步的多层隐状态的形状是",{"2":{"573":1}}],["所以在很长的序列中计算会非常慢",{"2":{"397":1,"401":1}}],["所以卷积层的计算复杂度为o",{"2":{"397":1}}],["所以将线性回归描述为神经网络似乎不合适",{"2":{"619":1}}],["所以将不会得到很好的精度",{"2":{"522":1}}],["所以将所有文本行展平到一个列表中",{"2":{"364":1}}],["所以将适当地加大权重",{"2":{"310":1}}],["所以转过头",{"2":{"355":1}}],["所以估计这类单词正确的概率要困难得多",{"2":{"316":1}}],["所以训练循环神经网络交替使用前向传播和通过时间反向传播",{"2":{"312":1}}],["所以偏置参数b不会衰减",{"2":{"278":1}}],["所以跨像素的权重是一致的",{"2":{"122":1}}],["所以遵循",{"2":{"46":1}}],["所以",{"2":{"42":1,"45":1,"46":1,"126":1,"127":1,"158":1,"183":1,"369":1,"467":1,"578":1,"615":1,"651":1,"1058":2,"1059":1,"1061":8,"1068":3,"1069":2,"1085":1,"1088":3,"1089":4,"1090":2,"1092":2,"1093":1,"1098":1,"1109":1,"1110":2,"1111":3,"1156":1,"1161":4,"1168":1,"1176":4,"1185":1}}],["所以连接a和b的线段包含在x和y中",{"2":{"40":1}}],["所以该集合是非凸的",{"2":{"40":1}}],["很小",{"2":{"1145":1,"1191":1}}],["很有可能",{"2":{"1141":1}}],["很类似于回归问题",{"2":{"1141":1}}],["很重要的一点是训练集和测试集均要含有各种类型的数据",{"2":{"1130":1}}],["很显然在局部最低时导数等于零",{"2":{"1068":1}}],["很显然",{"2":{"800":1}}],["很好地理解算法和模型才可以捕获统计方面的问题",{"2":{"800":1}}],["很高兴",{"2":{"518":1}}],["很可能",{"2":{"475":1,"1035":1}}],["很可能会有几次小余震",{"2":{"345":1}}],["很少出现的词元通常被移除",{"2":{"363":1}}],["很少直接用于深度学习",{"2":{"53":1}}],["很多人都为这门课贡献了自己的很多精力",{"2":{"1176":1}}],["很多人都在这门课上花了很多时间",{"2":{"1176":1}}],["很多视频的时间都长达数小时",{"2":{"1176":1}}],["很多高级的线性代数函数库已经能够利用多核cpu的多个核心来并行地处理矩阵运算",{"2":{"1169":1}}],["很多很多年前",{"2":{"1141":1}}],["很多计算机系统程序员交流",{"2":{"1058":1}}],["很多时候我都看到人们试图将机器学习算法应用于某些问题",{"2":{"1059":1}}],["很多时候",{"2":{"1029":1}}],["很多时候图像里有多个我们感兴趣的目标",{"2":{"857":1}}],["很多n元组很少出现",{"2":{"318":1}}],["很多学术会议也致力于这一主题",{"2":{"293":1}}],["很明显绿色的x所代表的数据点很可能是异常值",{"2":{"1184":1}}],["很明显",{"2":{"300":1,"326":1,"349":1,"518":1}}],["很容易计算的一个量就是向量u的范数",{"2":{"1145":1}}],["很容易",{"2":{"1022":2}}],["很容易导致模型参数过多",{"2":{"954":1}}],["很容易被优化",{"2":{"286":1}}],["很容易看出一种令人担忧的模式是如何出现的",{"2":{"201":1}}],["很大时",{"2":{"254":1}}],["很流行",{"2":{"242":1}}],["很远的地方",{"2":{"155":1}}],["很难获得有意义的收敛保证",{"2":{"114":1}}],["再回放",{"2":{"1202":1}}],["再写入数据文件",{"2":{"1202":1}}],["再通过",{"2":{"1198":1}}],["再一个例子是检测一个数据中心",{"2":{"1178":1}}],["再以新的尺寸对图片进行剪裁",{"2":{"1172":1}}],["再以对应该输出通道的卷积核计算出结果",{"2":{"121":1}}],["再求和",{"2":{"1169":1}}],["再来决定用更多的数据训练",{"2":{"1138":1}}],["再来几个例子",{"2":{"1089":1}}],["再加上正则化参数",{"2":{"1143":1}}],["再加上命令xlabel",{"2":{"1091":1}}],["再加上30毫秒将权重向量传输回来",{"2":{"841":1}}],["再用c++或者java去改写",{"2":{"1088":1}}],["再给所有的参数一个新的值",{"2":{"1081":1}}],["再小一点的一步",{"2":{"1068":1}}],["再让",{"2":{"1092":1}}],["再让算法去自动地发现细分市场",{"2":{"1061":1}}],["再让它降低",{"2":{"114":1}}],["再根据这些样本作出预测",{"2":{"1060":1}}],["再见",{"2":{"1059":1}}],["再如",{"2":{"1058":1}}],["再举一个更复杂的例子",{"2":{"1029":1}}],["再打印预测结果",{"2":{"866":1}}],["再为这些锚框一一预测类别和偏移量",{"2":{"854":1}}],["再使用0",{"2":{"1107":1}}],["再使用paddle",{"2":{"819":1}}],["再使用tf",{"2":{"819":1}}],["再使用torch",{"2":{"819":1}}],["再调用hybridize",{"2":{"819":1}}],["再自动编译成计算图",{"2":{"818":1}}],["再查看数据中心或云中的多台计算机的连接方式",{"2":{"800":1}}],["再与词元i的比较",{"2":{"675":2}}],["再与后续输出的词元共同组成序列",{"2":{"409":1}}],["再定义模型和损失函数",{"2":{"637":1}}],["再次检出代码",{"2":{"1315":1}}],["再次感谢你们选修这门课程",{"2":{"1176":1}}],["再次的函数调用产生了令人惊讶的结果",{"2":{"821":1}}],["再次使用numpy进行可视化",{"2":{"616":2}}],["再次减少特征的数量",{"2":{"479":1}}],["再接上一个输出个数为标签类别数的全连接层",{"2":{"488":1}}],["再结合在",{"2":{"466":1}}],["再试试预处理会怎么样",{"2":{"465":1}}],["再试一个计算量很小的任务呢",{"2":{"453":1}}],["再分别输入到编码器和解码器中",{"2":{"404":1}}],["再经过softmax运算得到的",{"2":{"367":1}}],["再将其它类都标记为负向类",{"2":{"1112":1}}],["再将这两个拼接的矩阵相乘",{"2":{"340":1}}],["再将数据送入一个全连接的多层感知机中",{"2":{"134":1}}],["再生核希尔伯特空间",{"2":{"278":1}}],["再比如通过摄取到的一组传感器读数预测读数的正常与异常程度",{"2":{"285":1}}],["再比如",{"2":{"199":1,"284":2,"290":1,"295":2,"296":1,"1058":2}}],["再到第二个卷积层之后的16个",{"2":{"136":1}}],["再进行如上的互相关运算",{"2":{"128":1}}],["再额外加上一个偏置",{"2":{"122":1}}],["再把它们加在一起",{"2":{"120":2}}],["再对通道求和",{"2":{"120":1}}],["再忽略不重要的高阶项",{"2":{"59":1}}],["参阅深度学习框架的在线文档",{"2":{"885":1}}],["参考之前pinia部分的讲解",{"2":{"1504":1}}],["参考文档",{"2":{"1106":1,"1178":1}}],["参考视频",{"2":{"1058":1,"1059":1,"1060":1,"1061":1,"1063":1,"1064":1,"1065":1,"1066":1,"1067":1,"1068":1,"1069":1,"1070":1,"1072":1,"1073":1,"1074":1,"1075":1,"1076":1,"1077":1,"1080":1,"1081":1,"1082":1,"1083":1,"1084":1,"1085":1,"1086":1,"1088":1,"1089":1,"1090":1,"1091":1,"1092":1,"1093":1,"1094":1,"1097":1,"1098":1,"1099":1,"1100":1,"1101":1,"1102":1,"1103":1,"1107":1,"1108":1,"1109":1,"1110":1,"1111":1,"1112":1,"1114":1,"1115":1,"1116":1,"1117":1,"1120":1,"1121":1,"1122":1,"1123":1,"1124":1,"1125":1,"1126":1,"1127":1,"1129":1,"1130":1,"1131":1,"1132":1,"1133":1,"1134":1,"1135":1,"1137":1,"1138":1,"1139":1,"1140":1,"1141":1,"1143":1,"1144":1,"1145":1,"1146":1,"1147":1,"1148":1,"1150":1,"1151":1,"1152":1,"1153":1,"1154":1,"1156":1,"1157":1,"1158":1,"1159":1,"1160":1,"1161":1,"1162":1,"1164":1,"1165":1,"1166":1,"1167":1,"1168":1,"1169":1,"1171":1,"1172":1,"1173":1,"1174":1,"1176":1,"1179":1,"1180":1,"1181":1,"1182":1,"1183":1,"1184":1,"1185":1,"1187":1,"1188":1,"1189":1,"1190":1,"1191":1,"1192":1}}],["参考resnet论文",{"2":{"505":1}}],["参考特征分解的在线附录",{"2":{"102":1}}],["参与求梯度和迭代的拉伸和偏移参数",{"2":{"472":4}}],["参见glove论文",{"2":{"746":1}}],["参见本书附录中关于数学分布的一节",{"2":{"647":1}}],["参见",{"2":{"221":1,"480":1,"718":1,"726":1}}],["参数属性",{"0":{"1428":1}}],["参数类型",{"0":{"1230":1}}],["参数向量$",{"2":{"1110":1}}],["参数又可被成为权重",{"2":{"1099":1}}],["参数服务器的核心思想首先是由",{"2":{"840":1}}],["参数服务器",{"0":{"840":1},"1":{"841":1,"842":1,"843":1,"844":1,"845":1,"846":1}}],["参数开销为o",{"2":{"642":1}}],["参数w和b的最优值是使整个数据集的似然最大的值",{"2":{"616":1}}],["参数指定的",{"2":{"568":1}}],["参数绑定",{"0":{"437":1}}],["参数命名约定是如何工作的",{"2":{"433":1}}],["参数是复合的对象",{"2":{"431":1}}],["参数名称允许唯一标识每个参数",{"2":{"430":1}}],["参数访问",{"0":{"430":1},"1":{"431":1,"432":1,"433":1}}],["参数访问与初始化",{"2":{"421":1}}],["参数管理",{"0":{"429":1},"1":{"430":1,"431":1,"432":1,"433":1,"434":1,"435":1,"436":1,"437":1,"438":1,"439":1}}],["参数",{"2":{"422":1,"470":1}}],["参数num",{"2":{"320":1}}],["参数batch",{"2":{"320":1}}],["参数可以被看作旋钮",{"2":{"282":1}}],["参数采用的值",{"2":{"254":1}}],["参数有更大取值范围的模型可能更为复杂",{"2":{"254":1}}],["参数初始化一直是深度学习基础研究的热点领域",{"2":{"248":1}}],["参数初始化",{"0":{"245":1,"434":1},"1":{"246":1,"247":1,"248":1,"435":1,"436":1},"2":{"429":1}}],["参数更新过小",{"2":{"241":1}}],["参数更新过大",{"2":{"241":1}}],["参数的随机初始化",{"2":{"1126":1}}],["参数的数量是多少",{"2":{"498":1}}],["参数的范数也代表了一种有用的简单性度量",{"2":{"170":1}}],["参数的方差大大减少",{"2":{"114":1}}],["参数大幅减少的代价是",{"2":{"155":1}}],["场景中常作为",{"2":{"1372":1}}],["场景中",{"2":{"114":1}}],["分享一些能复用的做法和决策思路",{"2":{"1545":1}}],["分钟级",{"2":{"1346":1}}],["分发和运行应用",{"2":{"1339":1}}],["分支管理",{"0":{"1329":1}}],["分支开发",{"2":{"1325":1}}],["分支是指向",{"2":{"1322":1}}],["分支",{"0":{"1322":1}}],["分支打开",{"2":{"1315":1}}],["分支时触发",{"2":{"1315":1}}],["分片",{"2":{"1210":1}}],["分片信息",{"2":{"1208":1}}],["分片逻辑",{"0":{"1207":1}}],["分片集群",{"0":{"1206":1},"1":{"1207":1},"2":{"1211":1}}],["分片路由",{"2":{"1203":1}}],["分号的意思就是换到下一行",{"2":{"1089":1}}],["分离计算",{"0":{"976":1}}],["分层同步策略可以工作的很好",{"2":{"845":1}}],["分层softmax使用二叉树中从根节点到叶节点的路径构造损失函数",{"2":{"710":1}}],["分层softmax将",{"2":{"709":1}}],["分的速度旋转",{"2":{"815":1}}],["分为训练集",{"2":{"772":1}}],["分割",{"2":{"757":1}}],["分解技巧会带来比二次复杂度更理想的线性复杂度",{"2":{"683":1}}],["分母或规范化常数",{"2":{"631":1}}],["分辨率降低",{"2":{"502":1}}],["分配一个列向量",{"2":{"1088":1}}],["分配将被复用",{"2":{"1021":1}}],["分配的真实边界框的张量",{"2":{"851":3}}],["分配和初始化任何必需的变量",{"2":{"472":1}}],["分配给每个值的注意力权重取决于将值所对应的键和查询作为输入的函数",{"2":{"393":1}}],["分配大量的空间",{"2":{"262":1}}],["分析出现这种情况的原因",{"2":{"511":1}}],["分析了alexnet的计算性能",{"2":{"465":1}}],["分析",{"2":{"311":1}}],["分析它们的牛顿法收敛速度",{"2":{"60":1}}],["分数",{"2":{"294":1}}],["分类指的是",{"2":{"1060":1}}],["分类精度即正确预测数量与总预测数量之比",{"2":{"634":1}}],["分类精度",{"0":{"634":1}}],["分类可能变得比二项分类",{"2":{"291":1}}],["分类问题中也存在这样的问题",{"2":{"1114":1}}],["分类问题",{"0":{"640":1,"1106":1},"2":{"1193":1}}],["分类问题的例子有",{"2":{"1106":1}}],["分类问题的目标是预测数据属于一组类别中的哪一个",{"2":{"608":1}}],["分类问题的常见损失函数被称为交叉熵",{"2":{"291":1}}],["分类问题希望模型能够预测样本属于哪个类别",{"2":{"291":1}}],["分类器80",{"2":{"291":1}}],["分类器90",{"2":{"291":1}}],["分类器可能会输出图像是猫的概率为0",{"2":{"291":1}}],["分类器仅仅学会了如何区分有阴影的树和没有阴影的树",{"2":{"186":1}}],["分类是训练一个分类器来输出预测的类别",{"2":{"291":1}}],["分类",{"0":{"291":1},"2":{"293":1}}],["分布有两个参数",{"2":{"1185":1}}],["分布告诉我们x获得某一值的概率",{"2":{"1028":1}}],["分布式集群的演进",{"0":{"1355":1}}],["分布式集群",{"2":{"1352":1}}],["分布式版本控制系统",{"2":{"1318":1}}],["分布式系统",{"2":{"1211":1}}],["分布式",{"0":{"1210":1}}],["分布式架构",{"2":{"1194":1,"1211":1}}],["分布式并行训练算法也需要变得更加复杂",{"2":{"840":1}}],["分布式优化训练的经验和超乎常人的耐心",{"2":{"151":1}}],["分布偏移纠正",{"0":{"189":1},"1":{"190":1,"191":1,"192":1,"193":1}}],["分布偏移示例",{"0":{"184":1},"1":{"185":1,"186":1,"187":1,"188":1}}],["分布偏移的类型",{"0":{"180":1},"1":{"181":1,"182":1,"183":1}}],["分布的变化而产生的",{"2":{"181":1}}],["分别设置为0和1",{"2":{"1012":1}}],["分别设为3和0",{"2":{"605":1}}],["分别预测该锚框的二元类别",{"2":{"939":1}}],["分别计算内容损失",{"2":{"925":1}}],["分别包含训练和测试狗图像",{"2":{"901":1}}],["分别包含rgb",{"2":{"900":1}}],["分别包含7个和3个单词的两个句子",{"2":{"774":1}}],["分别被分割为",{"2":{"757":1}}],["分别用y=1",{"2":{"1112":1}}],["分别用矩阵表示",{"2":{"1099":1}}],["分别用vi∈rd和ui∈rd表示用作上下文词和中心词的两个向量",{"2":{"785":1}}],["分别用vi∈rd和ui∈rd表示其用作中心词和上下文词时的两个向量",{"2":{"783":1}}],["分别用it和hk表示词w",{"2":{"708":1}}],["分别用于存储正确预测的数量和预测的总数量",{"2":{"634":1}}],["分别具有4个和5个输出通道",{"2":{"701":1}}],["分别对应于",{"2":{"667":1}}],["分别对应于卷积层的数量num",{"2":{"507":2}}],["分别解读基于循环神经网络和卷积神经网络的模型设计",{"2":{"663":1}}],["分别为push和replace",{"2":{"1484":1}}],["分别为t",{"2":{"582":1}}],["分别为1和2",{"2":{"575":1}}],["分别为self",{"2":{"423":1}}],["分别初始化成1和0",{"2":{"472":4}}],["分别有4096个输出",{"2":{"459":1}}],["分别有120",{"2":{"136":1}}],["分别是",{"2":{"1470":1}}],["分别是该层的权重和偏置",{"2":{"430":1}}],["分别是单个单词和连续单词对的出现次数",{"2":{"316":1}}],["分别表示输入数和输出数",{"2":{"414":1}}],["分别可视化这个实验中的多个头的注意力权重",{"2":{"384":1}}],["分别将x乘以w",{"2":{"340":1}}],["分别使用替换方法以及不替换方法进行采样时",{"2":{"118":1}}],["分段常数指数衰减多项式衰减η",{"2":{"114":1}}],["动画",{"2":{"1533":1}}],["动",{"2":{"1533":1}}],["动手练习",{"2":{"1304":1}}],["动机二",{"0":{"1157":1},"2":{"1193":1}}],["动机一",{"0":{"1156":1},"2":{"1193":1}}],["动起来",{"2":{"1051":1}}],["动词",{"2":{"659":1}}],["动态变化的问题",{"2":{"1384":1}}],["动态类型",{"2":{"1296":1}}],["动态调整行为路径",{"2":{"1052":1}}],["动态执行智能体",{"2":{"1049":1}}],["动态规划",{"2":{"519":1}}],["动态学习率",{"0":{"114":1}}],["动作",{"0":{"1311":1},"2":{"298":2,"300":1,"1490":2,"1493":1}}],["动量v",{"2":{"96":1}}],["动量方法需要维护一组辅助变量",{"2":{"91":1}}],["动量是由",{"2":{"86":1}}],["动量是深度学习及其后优化中一个深入研究的主题",{"2":{"86":1}}],["动量法的实现非常简单",{"2":{"96":1}}],["动量法可以防止在随机梯度下降的优化过程停滞的问题",{"2":{"96":1}}],["动量法都是可取的",{"2":{"96":1}}],["动量法用过去梯度的平均值来替换梯度",{"2":{"96":1}}],["动量法还是q",{"2":{"94":1}}],["动量法仍然很好地收敛了",{"2":{"88":1}}],["动量法",{"0":{"84":1,"88":1},"1":{"85":1,"86":1,"87":1,"88":1,"89":1,"90":1,"91":1,"92":1,"93":1,"94":1,"95":1,"96":1,"97":1},"2":{"88":1}}],["动量和规模在状态变量中清晰可见",{"2":{"33":1}}],["改变m和n",{"2":{"1038":1}}],["改变颜色",{"0":{"880":1}}],["改变均值会产生沿x轴的偏移",{"2":{"616":1}}],["改变为",{"2":{"513":1}}],["改变张量的最里层维度的尺寸",{"2":{"405":1}}],["改变神经网络架构并评估其性能",{"2":{"353":1}}],["改变学习速率会如何影响结果",{"2":{"223":1}}],["改变学习率η",{"2":{"113":1}}],["改进计算",{"0":{"792":1}}],["改进结果",{"2":{"455":1}}],["改进本节实验中的模型",{"2":{"353":1}}],["改进",{"2":{"72":1}}],["模糊的直觉",{"2":{"1545":1}}],["模糊处理",{"2":{"1173":1}}],["模板化",{"2":{"1544":1}}],["模板",{"2":{"1530":1}}],["模板中可以直接使用",{"2":{"1451":1}}],["模板方法模式",{"2":{"1417":1}}],["模式",{"2":{"1047":1}}],["模块与包管理",{"0":{"1256":1},"1":{"1257":1,"1258":1}}],["模块与导入",{"0":{"1234":1},"1":{"1235":1}}],["模块是",{"2":{"1234":1}}],["模块化构建思维链",{"2":{"1052":1}}],["模块",{"0":{"1262":1},"2":{"1017":1,"1052":1,"1304":1}}],["模块和npx",{"2":{"1017":1}}],["模型选型",{"2":{"1546":1}}],["模型选择的方法为",{"2":{"1131":1}}],["模型选择和交叉验证集",{"0":{"1131":1},"2":{"1193":1}}],["模型选择",{"0":{"212":1,"251":1,"255":1},"1":{"252":1,"253":1,"254":1,"255":1,"256":2,"257":2,"258":1,"259":1,"260":1,"261":1,"262":1,"263":1,"264":1,"265":1,"266":1,"267":1,"268":1}}],["模型p",{"2":{"1178":1}}],["模型拟合程度低",{"2":{"1132":1}}],["模型拟合程度更低",{"2":{"1132":1}}],["模型所预测的值与训练集中实际值之间的差距",{"2":{"1064":1}}],["模型表示2",{"0":{"1100":1}}],["模型表示1",{"0":{"1099":1}}],["模型表示",{"0":{"1063":1},"2":{"1193":3}}],["模型表现得非常出色",{"2":{"179":1}}],["模型调用",{"2":{"1050":1}}],["模型连接各种数据源和工具提供了标准化的接口",{"2":{"1040":1,"1042":1}}],["模型与外部世界连接",{"2":{"1040":1}}],["模型上下文协议",{"2":{"1040":1}}],["模型只能将模型与我们实际能看到的数据相拟合",{"2":{"980":1}}],["模型只会将输入作为生成输出的",{"2":{"295":1}}],["模型有多糟糕",{"2":{"980":1}}],["模型基于每个像素的预测类别是否正确来计算准确率",{"2":{"865":1}}],["模型输出与输入图像的高和宽相同",{"2":{"862":1}}],["模型实在太小了",{"2":{"837":1}}],["模型能够获得优异的计算性能和可移植性",{"2":{"821":1}}],["模型被分解成两个文件",{"2":{"821":1}}],["模型性能时将非常有用",{"2":{"820":1}}],["模型来提高性能",{"2":{"789":1}}],["模型类似于跳元模型",{"2":{"785":1}}],["模型可以将输入图像调大",{"2":{"966":1}}],["模型可以通过有监督地从海量文本数据中学习",{"2":{"754":1}}],["模型可能是",{"2":{"1146":1}}],["模型可能就需要拥有",{"2":{"295":1}}],["模型可能更容易过拟合",{"2":{"254":1}}],["模型为上下文的敏感表示设计了通用的任务无关模型",{"2":{"732":1}}],["模型为每个可能的类分配一个概率",{"2":{"291":1}}],["模型预测和评估",{"0":{"653":1}}],["模型预测下一个时间步",{"2":{"351":1}}],["模型中的特征为",{"2":{"1080":1}}],["模型中的各层如",{"2":{"574":1}}],["模型中的网络一次处理具有预定义长度",{"2":{"319":1}}],["模型就会停止预测",{"2":{"572":1}}],["模型就倾向只保留旧状态",{"2":{"542":1}}],["模型就很有可能有偏见",{"2":{"284":1}}],["模型还将学会在需要的时候重置隐状态",{"2":{"539":1}}],["模型也可以学会跳过不相关的临时观测",{"2":{"539":1}}],["模型也可以成功地评估风险",{"2":{"251":1}}],["模型设计",{"0":{"459":1}}],["模型设计和超参数选择",{"2":{"205":1}}],["模型学习到了一些类似于传统滤波器的特征抽取器",{"2":{"455":1}}],["模型学习了许多",{"2":{"302":1}}],["模型将预测",{"2":{"1108":1}}],["模型将学会在第一次观测之后不更新隐状态",{"2":{"539":1}}],["模型将在同一gpu上计算结果",{"2":{"451":1}}],["模型将仅对齐",{"2":{"373":1}}],["模型返回了x中所有项的和",{"2":{"425":1}}],["模型做了一些不寻常的事情",{"2":{"425":1}}],["模型总是预测标签词元的概率为0",{"2":{"342":1}}],["模型总是完美地估计标签词元的概率为1",{"2":{"342":1}}],["模型化",{"2":{"338":1}}],["模型通过预热期进行自我更新",{"2":{"336":1}}],["模型是从零开始实现的模型或由高级api构建的模型",{"2":{"334":1}}],["模型需要的正是截断的通过时间反向传播方法所具备的轻度正则化效果",{"2":{"311":1}}],["模型需要判断从未见过的患者",{"2":{"251":1}}],["模型像一个打工仔",{"2":{"296":1}}],["模型和优化算法",{"2":{"288":1}}],["模型对于",{"2":{"282":1}}],["模型接收一段音频作为输入",{"2":{"282":1}}],["模型族的另一个模型只在听到",{"2":{"282":1}}],["模型族",{"2":{"282":1}}],["模型函数的选择范围较广",{"2":{"259":1}}],["模型的输出是",{"2":{"1168":1}}],["模型的其余部分保持不变",{"2":{"939":1}}],["模型的前向传播只需返回模型参数即可",{"2":{"926":1}}],["模型的准确性如何变化",{"2":{"876":2}}],["模型的编译也是值得的",{"2":{"821":1}}],["模型的计算结果保持不变",{"2":{"819":1}}],["模型的计算代价及其应用",{"0":{"522":1}}],["模型的架构与基本的循环神经网络单元是相同的",{"2":{"545":1}}],["模型的初始化也需要谨慎",{"2":{"530":1}}],["模型的困惑度为1",{"2":{"342":1}}],["模型的权重是wi给出的",{"2":{"259":1}}],["模型的预测与训练数据耦合的各种机制都没有得到解释",{"2":{"201":1}}],["模型往往更容易过拟合",{"2":{"254":1}}],["模型复杂性和数据集大小之间通常存在关系",{"2":{"260":1}}],["模型复杂性由什么构成是一个复杂的问题",{"2":{"254":1}}],["模型复杂性",{"0":{"254":1,"259":1}}],["模型仍将继续运行得非常好",{"2":{"253":1}}],["模型误差的期望",{"2":{"252":1}}],["模型应用在同样从原始样本的分布中抽取的无限多数据样本时",{"2":{"252":1}}],["模型最终可以在训练集上达到完美的精度",{"2":{"251":1}}],["模型现在需要跟踪和更新额外的参数",{"2":{"232":1}}],["模型",{"0":{"219":1,"225":1,"285":1,"374":1,"381":1,"404":1,"673":1,"785":1,"893":1,"953":1},"1":{"674":1,"675":1,"676":1,"677":1,"786":1,"954":1,"955":1,"956":1,"957":1,"958":1,"959":1},"2":{"210":1,"282":1,"317":1,"388":1,"576":1,"578":1,"598":1,"980":1}}],["模型都能正常工作",{"2":{"189":1}}],["模型在所有键值对注意力权重都是一个有效的概率分布",{"2":{"388":1}}],["模型在训练数据集上计算得到的误差",{"2":{"252":1}}],["模型在部署中会出现灾难性的失败",{"2":{"179":1}}],["模型在给定数据样本上的正则化损失为",{"2":{"162":1}}],["模型训练完后",{"2":{"1172":1}}],["模型训练函数train只迭代小型自定义输出网络的参数",{"2":{"906":1}}],["模型训练后",{"2":{"376":1}}],["模型训练",{"0":{"137":1},"2":{"509":1}}],["模型更简洁",{"2":{"135":1}}],["模型参数也更多",{"2":{"756":1}}],["模型参数的随着训练更新变幻莫测",{"2":{"467":1}}],["模型参数是wxh和whh的拼接",{"2":{"340":1}}],["模型参数",{"2":{"282":1}}],["模型参数都会更新",{"2":{"80":1}}],["模型参数每个迭代轮数只迭代一次",{"2":{"80":1}}],["模拟有噪声的梯度",{"2":{"113":2}}],["降至二维的特征向量",{"2":{"1156":1}}],["降至常数o",{"2":{"113":1}}],["降维的算法只负责减少维数",{"2":{"1157":1}}],["降维可以帮助我们",{"2":{"1157":1}}],["降维",{"0":{"995":1,"1155":1},"1":{"996":1,"1156":1,"1157":1,"1158":1,"1159":1,"1160":1,"1161":1,"1162":1},"2":{"1193":1}}],["降低开发心智负担",{"2":{"1527":1}}],["降低全变分损失",{"2":{"924":1}}],["降低其峰值",{"2":{"616":1}}],["降低卷积层对位置的敏感性",{"2":{"145":1}}],["降低学习率进一步解决了任何非平滑优化问题的困难",{"2":{"91":1}}],["降低ηt+1←ηt⋅α",{"2":{"71":1}}],["加",{"2":{"1491":1}}],["加深理解",{"2":{"1436":1}}],["加快范围查询",{"2":{"1199":1}}],["加等操作",{"2":{"1088":1}}],["加法",{"2":{"1218":1}}],["加法和标量乘法",{"0":{"1073":1},"2":{"1193":1}}],["加法法则",{"2":{"981":1}}],["加法操作后输出张量的形状相同",{"2":{"406":1}}],["加入残差连接",{"2":{"491":1}}],["加入窗口形状为3×3",{"2":{"459":1}}],["加载index",{"2":{"1444":1}}],["加载",{"2":{"1202":1}}],["加载香蕉检测数据集",{"2":{"932":3}}],["加载voc语义分割数据集",{"2":{"864":1,"949":3}}],["加载wikitext",{"2":{"722":3,"725":1}}],["加载spacy英语软件包",{"2":{"717":1}}],["加载预训练的词向量",{"0":{"714":1}}],["加载预训练的bert",{"0":{"686":1}}],["加载预训练词向量",{"0":{"703":1,"748":1}}],["加载预训练bert参数",{"2":{"686":3}}],["加载预先训练好的bert参数",{"2":{"686":1}}],["加载数据集",{"0":{"568":1}}],["加载数据",{"2":{"523":3}}],["加载和保存模型参数",{"0":{"442":1}}],["加载和保存张量",{"0":{"441":1}}],["加载序列数据的迭代器",{"2":{"321":1}}],["加上正则化项",{"2":{"1188":1}}],["加上3的平方",{"2":{"1092":1}}],["加上2的平方",{"2":{"1092":1}}],["加上第一个7×7卷积层和最后一个全连接层",{"2":{"502":1}}],["加上一个包含序列结束词元",{"2":{"376":3}}],["加上人才的迅速涌入",{"2":{"302":1}}],["加性注意力和缩放点积注意力",{"2":{"381":1}}],["加性注意力",{"0":{"369":1},"2":{"369":4}}],["加权经验风险最小化",{"2":{"191":1}}],["加权使用的权重为",{"2":{"153":1}}],["加权项γ设置为0",{"2":{"108":1}}],["加速卡是为训练还是推断而优化的",{"2":{"811":1}}],["加速鲁棒特征",{"2":{"454":1}}],["加速度这方面也是动量如此起效的关键原因之一",{"2":{"86":1}}],["加速",{"2":{"86":2}}],["几秒钟后",{"2":{"1059":1}}],["几个月前",{"2":{"1058":1}}],["几个样本的图像及其相应的标签",{"2":{"582":1}}],["几个预处理步骤",{"2":{"565":1}}],["几十年来",{"2":{"564":1}}],["几何学",{"2":{"454":1}}],["几乎可以忽略不计",{"2":{"1179":1}}],["几乎总是会调用set",{"2":{"1017":1}}],["几乎所有现实的应用都至少涉及到一些违背独立同分布假设的情况",{"2":{"253":1}}],["几乎上是在算法收敛时呈线性递增",{"2":{"106":1}}],["几天甚至数周",{"2":{"65":1}}],["球",{"2":{"105":1}}],["球会滚到最低的地方",{"2":{"48":1}}],["鞍上平衡一个",{"2":{"105":1}}],["鞍点是梯度消失的另一个原因",{"2":{"102":1}}],["鞍点",{"0":{"102":1},"2":{"102":1}}],["鞍点和梯度消失",{"2":{"100":1}}],["关闭所有服务",{"2":{"1347":1}}],["关键字约束泛型",{"2":{"1433":1}}],["关键字",{"2":{"1399":1}}],["关键字参数",{"2":{"1230":1}}],["关键在于求出代价函数的导数",{"2":{"1069":1}}],["关注新版本的特性更新",{"2":{"1436":1}}],["关注社交网络",{"2":{"1150":1}}],["关注的原因是数量级及以上的差异",{"2":{"814":1}}],["关系图",{"2":{"1319":1}}],["关系",{"2":{"665":1,"1350":1}}],["关联的特征值λ满足p",{"2":{"105":1}}],["关于多元高斯分布",{"2":{"1185":1}}],["关于方差",{"2":{"1135":1}}],["关于人体回声定位或者说人体声纳",{"2":{"1098":1}}],["关于人工智能的非技术性文章中",{"2":{"301":1}}],["关于线性代数的更多信息",{"0":{"1002":1}}],["关于x的函数",{"2":{"975":1}}],["关于模型参数的导数",{"2":{"613":1}}],["关于模型计算性能",{"2":{"204":1}}],["关于各种架构的详细讨论请参阅",{"2":{"521":1}}],["关于序列到序列模型",{"2":{"408":1}}],["关于如何更有效地使用双向循环神经网络的讨论",{"2":{"523":1}}],["关于如何处理审查",{"2":{"294":1}}],["关于如何设置学习率",{"2":{"114":1}}],["关于",{"2":{"292":1,"1154":1}}],["关于隐藏层输出的梯度∂j",{"2":{"164":1}}],["关于实例",{"2":{"78":1}}],["关于为什么在理论上某些策略会导致较轻的过拟合",{"2":{"68":1}}],["关于对角线预处理矩阵diag−12",{"2":{"31":1}}],["个人博客或后台项目",{"2":{"1531":1}}],["个人博客",{"2":{"1529":1}}],["个人项目",{"2":{"1325":1}}],["个人看到的新闻应该由他们喜欢的facebook页面决定吗",{"2":{"201":1}}],["个用户",{"2":{"1187":1}}],["个地标",{"2":{"1147":1}}],["个样本",{"2":{"1147":1}}],["个鸡蛋",{"2":{"1141":1}}],["个激活单元受到第",{"2":{"1121":1}}],["个激活单元",{"2":{"1099":1}}],["个特征",{"2":{"1080":2,"1110":1,"1162":1}}],["个训练实例的第",{"2":{"1080":1}}],["个训练实例",{"2":{"1080":1}}],["个观察实例",{"2":{"1063":1}}],["个元素进行加和",{"2":{"1093":1}}],["个元素",{"2":{"1017":3}}],["个高和宽",{"2":{"848":3}}],["个锚框",{"2":{"848":4}}],["个参数影响而导致的误差",{"2":{"1121":1}}],["个参数",{"2":{"843":1}}],["个位置",{"2":{"722":1}}],["个词元",{"2":{"568":1}}],["个",{"2":{"512":1}}],["个顺序操作可以并行计算",{"2":{"397":1}}],["个顺序操作无法并行化",{"2":{"397":1}}],["个顺序操作",{"2":{"397":1}}],["个性化和排名",{"2":{"301":1}}],["个性化",{"2":{"294":1}}],["个等效方案",{"2":{"105":1}}],["个条目的存储代价会很高",{"2":{"59":1}}],["重庆",{"2":{"1518":1,"1519":1}}],["重定向",{"0":{"1486":1}}],["重点关注",{"2":{"1452":1}}],["重建的压缩表示",{"0":{"1161":1},"2":{"1193":1}}],["重合时",{"2":{"1146":1}}],["重塑它之后",{"2":{"970":1}}],["重置门打开时",{"2":{"548":1}}],["重置门参数",{"2":{"544":4}}],["重置门",{"2":{"544":1}}],["重置门有助于捕获序列中的短期依赖关系",{"2":{"542":1,"548":1}}],["重置门rt∈rn×h和",{"2":{"540":1}}],["重置门允许我们控制",{"2":{"540":1}}],["重置门和更新门的最佳值是什么",{"2":{"549":1}}],["重置门和更新门",{"0":{"540":1}}],["重写虚拟dom的实现和tree",{"2":{"1439":1}}],["重写为",{"2":{"708":1}}],["重写",{"2":{"388":1}}],["重复劳动",{"2":{"1544":1}}],["重复步骤2",{"2":{"1151":1}}],["重复上面的步骤",{"2":{"1067":1}}],["重复上述过程",{"2":{"854":1}}],["重复了",{"2":{"848":3}}],["重复的前向传播将导致相同的输出",{"2":{"821":1}}],["重复以下训练",{"2":{"605":1}}],["重复层的模式",{"2":{"506":1}}],["重复第",{"2":{"282":1}}],["重复采用训练数据集的时候",{"2":{"116":1}}],["重新定向到已有路由",{"2":{"1486":1}}],["重新计算该类的质心",{"2":{"1151":1}}],["重新布局网络",{"2":{"1150":1}}],["重新好好看看这些副本",{"2":{"1089":1}}],["重新设为",{"2":{"1089":1}}],["重新设计一个求控制流梯度的例子",{"2":{"979":1}}],["重新排列张量",{"2":{"702":3}}],["重新审视交叉熵",{"0":{"652":1}}],["重新审视softmax的实现",{"0":{"624":1}}],["重新审视过拟合",{"0":{"169":1}}],["重新运行实验并在计算损失时不使用遮蔽",{"2":{"580":1}}],["重新聚焦眼睛",{"2":{"355":1}}],["重新发现",{"2":{"300":1}}],["重新考虑如何评估我们的技术",{"2":{"201":1}}],["重要的不是你该选择使用学习算法a还是学习算法b",{"2":{"1143":1}}],["重要的是清楚地知道上面式子中上下标的含义",{"2":{"1121":1}}],["重要的是将这些指导性直觉与既定的科学事实区分开来",{"2":{"475":1}}],["重要的是要确保小心使用这些算法",{"2":{"301":1}}],["重要的是",{"2":{"201":1,"974":1}}],["重要性权重将对应于标签似然比率",{"2":{"192":1}}],["重参数化通常会有所帮助",{"2":{"104":1}}],["重力将与盒子两侧对球施加的力平衡",{"2":{"48":1}}],["85",{"2":{"1401":1}}],["8307",{"2":{"1035":1}}],["832",{"2":{"488":4}}],["81米之间更有意义",{"2":{"1028":1}}],["888",{"2":{"1464":1}}],["88",{"2":{"853":2,"854":2,"959":2}}],["8gb",{"2":{"813":1}}],["8mb范围内",{"2":{"810":1}}],["86的测试精度吗",{"2":{"690":1}}],["8和0",{"2":{"643":1}}],["8+ϵ",{"2":{"386":1}}],["8082",{"2":{"1369":1}}],["8081",{"2":{"1369":1}}],["8080",{"2":{"300":1,"1369":1}}],["80343185",{"2":{"1121":1}}],["80米的概率为0",{"2":{"1028":1}}],["800",{"2":{"834":3}}],["80",{"2":{"565":1,"721":1,"736":1,"813":2,"1364":1,"1367":1,"1369":1,"1389":1,"1390":1,"1391":2,"1464":1}}],["80486",{"2":{"300":1}}],["80186",{"2":{"300":1}}],["8×1=0",{"2":{"291":1}}],["8×0=∞",{"2":{"291":1}}],["8",{"0":{"1070":1,"1097":1,"1098":1,"1099":1,"1100":1,"1101":1,"1102":1,"1103":1,"1127":1,"1185":1,"1325":1,"1350":1,"1387":1,"1395":1,"1424":1,"1460":1,"1480":1,"1495":1,"1504":1,"1521":1,"1522":1,"1523":1,"1524":1,"1525":1},"1":{"1425":1,"1426":1,"1427":1,"1428":1,"1481":1,"1482":1,"1522":1,"1523":1,"1524":1,"1525":1},"2":{"101":2,"107":1,"120":2,"126":1,"128":2,"129":4,"141":8,"146":2,"172":4,"235":8,"242":7,"291":1,"305":1,"386":4,"399":1,"405":4,"407":7,"408":3,"413":5,"414":6,"429":5,"433":4,"437":11,"480":8,"488":1,"565":1,"692":1,"699":1,"721":1,"726":3,"734":3,"736":3,"744":1,"842":2,"853":2,"854":3,"872":3,"882":6,"912":2,"927":3,"938":1,"956":5,"970":2,"1018":5,"1061":2,"1063":1,"1064":1,"1070":1,"1080":1,"1084":1,"1097":1,"1098":2,"1099":1,"1100":1,"1101":1,"1102":1,"1103":1,"1106":1,"1123":1,"1127":1,"1130":1,"1132":1,"1153":1,"1154":1,"1178":1,"1182":1,"1185":1,"1187":1,"1191":1,"1193":10,"1239":1}}],["84和10个输出",{"2":{"136":1}}],["84",{"2":{"67":6,"136":6,"473":9,"474":8}}],["πx",{"2":{"101":1}}],["πt+1",{"2":{"519":1}}],["πt",{"2":{"72":1,"519":1}}],["值为对象",{"2":{"1502":2}}],["值为零",{"2":{"852":3}}],["值是一个函数",{"2":{"1451":1}}],["值却仍然在正常范围内",{"2":{"1184":1}}],["值越接近1表示样本i聚类越合理",{"2":{"1154":1}}],["值下",{"2":{"1146":1}}],["值设为一个10行1列的零向量",{"2":{"1092":1}}],["值域在0～1之间",{"2":{"932":1}}],["值存储的push与pull操作描述如下",{"2":{"844":1}}],["值存储之间存在相似性并非巧合",{"2":{"844":1}}],["值存储",{"2":{"844":1}}],["值n=3时",{"2":{"756":1}}],["值对应房子的价格",{"2":{"1063":1}}],["值对并生成一个注意力输出",{"2":{"395":1}}],["值对计算注意力",{"2":{"370":1}}],["值v∈rdv",{"2":{"381":1}}],["值v∈rm×v的缩放点积注意力是",{"2":{"370":1}}],["值和有效长度",{"2":{"370":1}}],["值的输出序列",{"2":{"513":1}}],["值的长度为v",{"2":{"370":1}}],["值的维度",{"2":{"369":5,"370":4}}],["值得期待",{"0":{"1540":1}}],["值得关注",{"0":{"1051":1}}],["值得一提的是",{"2":{"340":1,"939":1,"1148":1}}],["值得注意的是参数θ0​的更新规则与其他情况不同",{"2":{"1117":1}}],["值得注意的是",{"2":{"130":1,"338":1,"382":1,"388":1,"403":1,"409":1,"591":4,"669":1,"674":1,"726":1,"737":1,"811":1}}],["值",{"2":{"101":1,"367":1,"369":12,"370":8,"382":24,"391":9,"392":1,"409":2,"854":1,"1063":1,"1112":1,"1133":1,"1140":1,"1160":1,"1180":1,"1183":1}}],["值小于在x附近任意其他点的f",{"2":{"101":1}}],["没有",{"2":{"1426":1,"1433":1}}],["没有为任何电影评分",{"2":{"1192":1}}],["没有所谓最好的选择聚类数的方法",{"2":{"1154":1}}],["没有内核参数的理念",{"2":{"1148":1}}],["没有必要把这些命令都记住",{"2":{"1089":1}}],["没有必要找到最优解",{"2":{"103":1}}],["没有人有这耐心去下这么多盘棋",{"2":{"1059":1}}],["没有一对边界框过于相似",{"2":{"854":1}}],["没有一个正确的答案",{"2":{"270":1}}],["没有特定的顺序",{"2":{"600":2}}],["没有任何卷积层或循环神经网络层",{"2":{"403":1}}],["没有标签的情况下",{"2":{"296":1}}],["没有足够的数据用于学到高阶系数应该具有接近于零的值",{"2":{"266":1}}],["没有改变",{"2":{"181":1}}],["没有输出",{"2":{"142":1}}],["没有约束力",{"2":{"106":1}}],["没有解析解",{"2":{"100":1}}],["没有其它真正理由让大家使用不同的希腊变量来表示在动量法",{"2":{"20":1}}],[">关闭弹窗",{"2":{"1522":1}}],[">关于",{"2":{"1474":1}}],[">更多",{"2":{"1507":1}}],[">汽车价格+1",{"2":{"1503":1}}],[">资产+1",{"2":{"1503":1}}],[">玩具给父亲",{"2":{"1497":1}}],[">news",{"2":{"1484":1}}],[">xxxx",{"2":{"1479":2}}],[">跳转",{"2":{"1478":2}}],[">home",{"2":{"1477":1}}],[">主页",{"2":{"1477":1}}],[">新闻",{"2":{"1474":1}}],[">首页",{"2":{"1474":1}}],[">再来一只狗",{"2":{"1471":1}}],[">加载中",{"2":{"1471":1}}],[">vue路由测试",{"2":{"1474":1}}],[">vue",{"2":{"1468":1}}],[">前端",{"2":{"1468":1}}],[">尚硅谷",{"2":{"1468":1}}],[">水位+10",{"2":{"1467":1}}],[">水温+1",{"2":{"1467":1}}],[">水温",{"2":{"1467":1}}],[">点我更新a",{"2":{"1501":1}}],[">点我",{"2":{"1471":1,"1503":1}}],[">点我+1",{"2":{"1471":1}}],[">点我打印内容",{"2":{"1468":1}}],[">点我sum+1",{"2":{"1462":1,"1470":1}}],[">点我查看联系方式",{"2":{"1445":1,"1451":1,"1454":1,"1455":1}}],[">全名改为",{"2":{"1460":1}}],[">测试",{"2":{"1456":1,"1457":1,"1468":1,"1498":1}}],[">修改整个车",{"2":{"1465":1,"1466":1}}],[">修改整个人",{"2":{"1463":1,"1464":1}}],[">修改第二台车",{"2":{"1465":1,"1466":1}}],[">修改第一台车",{"2":{"1465":1,"1466":1}}],[">修改第一游戏",{"2":{"1456":1,"1457":1}}],[">修改obj",{"2":{"1464":1}}],[">修改性别",{"2":{"1459":1}}],[">修改年龄",{"2":{"1459":1,"1463":1,"1464":1,"1465":1,"1466":1}}],[">修改汽车价格",{"2":{"1456":1,"1457":1}}],[">修改名字",{"2":{"1445":1,"1451":1,"1454":1,"1455":1,"1459":1,"1463":1,"1464":1,"1465":1,"1466":1}}],[">年龄+1",{"2":{"1445":1,"1451":1,"1454":1,"1455":1}}],[">=",{"2":{"436":4,"446":4,"718":1,"721":1,"851":6,"852":6,"947":6,"1223":2,"1462":1,"1467":4}}],[">03b",{"2":{"399":1}}],[">",{"2":{"99":2,"172":3,"211":1,"334":3,"364":1,"424":1,"425":4,"565":1,"566":1,"568":1,"578":1,"634":4,"635":2,"687":6,"720":1,"748":1,"848":1,"854":3,"894":1,"906":1,"977":4,"1198":2,"1246":1,"1259":1,"1269":1,"1277":1,"1299":1,"1420":1,"1434":2,"1435":2,"1443":1,"1444":2,"1445":2,"1451":2,"1454":4,"1455":2,"1456":3,"1457":3,"1459":2,"1460":4,"1462":2,"1463":2,"1464":2,"1465":2,"1466":2,"1467":2,"1468":8,"1469":7,"1470":3,"1471":4,"1474":6,"1477":2,"1478":2,"1479":6,"1481":4,"1482":4,"1490":3,"1491":1,"1492":2,"1497":5,"1498":3,"1500":21,"1501":8,"1503":5,"1506":4,"1507":5,"1508":9,"1522":2,"1523":2}}],["下次要提交的改动",{"2":{"1319":1}}],["下的",{"2":{"1309":1}}],["下划线风格",{"2":{"1215":1}}],["下半部分是真值表",{"2":{"1101":1}}],["下课后复习一下我键入的这些代码好好地看一看",{"2":{"1089":1}}],["下图所示的数据集包含身高和体重两项特征构成的",{"2":{"1151":1}}],["下图是一个由两个特征的训练集",{"2":{"1180":1}}],["下图是一个回归问题的例子",{"2":{"1114":1}}],["下图是一个以逻辑回归模型作为自身学习模型的神经元示例",{"2":{"1099":1}}],["下图的神经元",{"2":{"1102":3}}],["下图中是两个相关特征",{"2":{"1184":1}}],["下图中绿色的区域是经过这些步骤后被认为是文字的区域",{"2":{"1172":1}}],["下图中左半部分是神经网络的设计与output层表达式",{"2":{"1101":1}}],["下图中蓝线所指",{"2":{"1064":1}}],["下图为一个3层的神经网络",{"2":{"1099":1}}],["下图说明",{"2":{"99":1}}],["下雨的概率是0",{"2":{"1025":1}}],["下雨了",{"2":{"342":1}}],["下",{"2":{"915":1}}],["下采样通过删除高频词来显著缩短句子",{"2":{"773":1}}],["下采样高频词",{"2":{"773":1}}],["下采样",{"0":{"773":1}}],["下数据的负对数似然",{"2":{"621":1}}],["下文将介绍一个算法",{"2":{"850":1}}],["下文",{"2":{"518":1}}],["下来",{"2":{"448":1}}],["下一步是训练一个模型来完成将文字分割成一个个字符的任务",{"2":{"1172":1}}],["下一步是继续计算第二层的误差",{"2":{"1121":1}}],["下一步是初始化模型参数",{"2":{"544":1}}],["下一次迭代又移动了一大步",{"2":{"1068":1}}],["下一次迭代中",{"2":{"201":1}}],["下一句预测",{"0":{"737":1},"2":{"737":1}}],["下一句预测任务损失的和",{"2":{"726":3}}],["下一个视频中",{"2":{"1067":1}}],["下一个数据是xx",{"2":{"651":1}}],["下一个词元的实际选择数的调和平均数",{"2":{"342":1}}],["下一章将详细讨论由这些层组成的网络",{"2":{"618":1}}],["下载miniconda并安装",{"2":{"1276":1}}],["下载数据集",{"0":{"889":1,"901":1,"931":1}}],["下载数据集后",{"2":{"565":1}}],["下载ptb数据集",{"2":{"777":3}}],["下载并提取路径",{"2":{"692":1}}],["下载并解压zip",{"2":{"206":1}}],["下载完snli数据集后",{"2":{"687":1}}],["下载snli数据集并返回数据迭代器和词表",{"2":{"669":3,"679":1}}],["下载fashion",{"2":{"584":4}}],["下载一个由tatoeba项目的双语句子对",{"2":{"565":1}}],["下载一个data",{"2":{"206":1}}],["下载和预处理数据集",{"0":{"565":1}}],["下载和缓存数据集",{"0":{"206":1}}],["下载nvidia驱动和cuda",{"2":{"445":1}}],["下载data",{"2":{"206":1}}],["下载",{"2":{"206":1}}],["下面这行的写法是",{"2":{"1495":1}}],["下面引入一些标记",{"2":{"1187":1}}],["下面引入一些标记法来帮助描述模型",{"2":{"1099":1}}],["下面谈谈如何选择特征",{"2":{"1183":1}}],["下面给出主成分分析问题的描述",{"2":{"1158":1}}],["下面给出了源模型的成员变量fc",{"2":{"873":2}}],["下面给出了更多的场景",{"2":{"345":1}}],["下面介绍怎样做",{"2":{"1153":1}}],["下面再举几个例子",{"2":{"1098":1}}],["下面再举另一个例子",{"2":{"1098":1}}],["下面将核函数应用到支持向量机",{"2":{"1147":1}}],["下面将介绍如何进行一对多的分类工作",{"2":{"1112":1}}],["下面将read",{"2":{"945":1}}],["下面将列出一些常见的机器学习问题和应用",{"2":{"288":1}}],["下面定义了训练循环",{"2":{"927":1}}],["下面定义的gram函数将格拉姆矩阵除以了矩阵中元素的个数",{"2":{"923":1}}],["下面定义两个函数",{"2":{"920":1}}],["下面构建一个新的网络net",{"2":{"920":1}}],["下面加载本节将使用的示例图像",{"2":{"857":1}}],["下面用一个具体的例子来说明上述算法",{"2":{"851":1}}],["下面用深度学习框架自带算法实现一个通用的训练函数",{"2":{"81":1}}],["下面提取数据集中的所有中心词及其上下文词",{"2":{"774":1}}],["下面显示了前8个正类样本图片和最后8张负类样本图片",{"2":{"872":1}}],["下面显示了如何使用二元交叉熵损失中的sigmoid激活函数",{"2":{"765":1}}],["下面显示了训练集和测试集中的三个",{"2":{"667":1}}],["下面计算给定变量的二进制交叉熵损失",{"2":{"765":1}}],["下面完成一个",{"2":{"751":1}}],["下面输出与",{"2":{"750":1}}],["下面导出在时间步t处的方程",{"2":{"554":1}}],["下面演示各个模块输出的形状变化",{"2":{"488":1}}],["下面在实践中试一试它的运作方式",{"2":{"827":1}}],["下面在",{"2":{"409":1}}],["下面实现的",{"2":{"407":1}}],["下面实现一个通用的训练函数",{"2":{"80":1}}],["下面看一下输出结果的绘制图",{"2":{"392":1}}],["下面看看如何定义bahdanau注意力",{"2":{"375":1}}],["下面考虑一个高斯核",{"2":{"388":1}}],["下面通过一个具体的例子来说明锚框标签",{"2":{"853":1}}],["下面通过",{"2":{"376":1}}],["下面描述的bahdanau注意力模型",{"2":{"374":1}}],["下面来",{"2":{"1007":1}}],["下面来实现加性注意力",{"2":{"369":1}}],["下面来看看如何通过这两种注意力提示",{"2":{"356":1}}],["下面使用键和值相同的小例子来",{"2":{"382":1}}],["下面使用一个简单的例子进行演示",{"2":{"357":1}}],["下面使用这个训练函数",{"2":{"81":1}}],["下面列举了帮助研究人员在过去十年中取得巨大进步的想法",{"2":{"300":1}}],["下面是",{"2":{"1109":1}}],["下面是该神经网络的可能结构示例",{"2":{"1103":1}}],["下面是一些普遍使用的准则",{"2":{"1148":1}}],["下面是一些更为有用的符号",{"2":{"1088":1}}],["下面是一组神经元的示意图",{"2":{"1099":1}}],["下面是一个聚类示例",{"2":{"1151":1}}],["下面是一个只针对θ1进行检验的示例",{"2":{"1124":1}}],["下面是一个例子",{"2":{"1097":1}}],["下面是一个",{"2":{"665":1}}],["下面是一个非常简单的示例",{"2":{"295":1}}],["下面是与",{"2":{"137":1}}],["下面的写法是setup语法糖",{"2":{"1454":1}}],["下面的对比有助于选择采用监督学习还是异常检测",{"2":{"1182":1}}],["下面的三维图表表示的是密度估计函数",{"2":{"1180":1}}],["下面的三个思维实验将有助于更好地说明这种情况",{"2":{"252":1}}],["下面的课程的的数学性可能不是那么强",{"2":{"1137":1}}],["下面的方法也可能有效",{"2":{"1129":1}}],["下面的公式推导过程见",{"2":{"1121":1}}],["下面的set",{"2":{"981":1}}],["下面的segment",{"2":{"757":1}}],["下面的一些法则方便使用",{"2":{"981":1}}],["下面的一个文本对将被贴上",{"2":{"665":1}}],["下面的反向传播函数计算z=u",{"2":{"976":1}}],["下面的示例可以解释这一点",{"2":{"969":1}}],["下面的",{"2":{"835":1}}],["下面的讨论是非常笼统和粗略的",{"2":{"800":1}}],["下面的讨论解释了这些数字的一些基本原理",{"2":{"800":1}}],["下面的reorg",{"2":{"890":1,"902":1}}],["下面的run函数将执行10次矩阵",{"2":{"796":1}}],["下面的rnn函数定义了如何在一个时间步内计算隐状态和输出",{"2":{"332":1}}],["下面的nextsentencepred类使用单隐藏层的多层感知机来预测第二个句子是否是bert输入序列中第一个句子的下一个句子",{"2":{"737":1}}],["下面的bertencoder类类似于",{"2":{"734":1}}],["下面的get",{"2":{"734":1,"774":1}}],["下面的compare个类定义了比较步骤",{"2":{"675":1}}],["下面的centeredlayer类要从其输入中减去均值",{"2":{"413":1}}],["下面的train",{"2":{"726":1}}],["下面的truncate",{"2":{"568":1}}],["下面的tokenize",{"2":{"566":1}}],["下面的tokenize函数将文本行列表",{"2":{"362":1}}],["下面的实验将说明这一点",{"2":{"522":1}}],["下面的内容将深入研究alexnet的细节",{"2":{"458":1}}],["下面的mysequential类提供了与默认sequential类相同的功能",{"2":{"424":1}}],["下面的mlp类继承了表示块的类",{"2":{"423":1}}],["下面的masked",{"2":{"368":1}}],["下面的encoderblock类包含两个子层",{"2":{"407":1}}],["下面的缩放点积注意力的实现使用了暂退法进行模型正则化",{"2":{"370":1}}],["下面的函数返回tokens",{"2":{"727":1}}],["下面的函数通过调用",{"2":{"720":1}}],["下面的函数实现小批量随机梯度下降更新",{"2":{"604":1}}],["下面的函数将绘制所有的训练样本",{"2":{"386":1}}],["下面的函数",{"2":{"361":1}}],["下面的代码可以实现这样的转换",{"2":{"1121":1}}],["下面的代码片段绘制了下采样前后每句话的词元数量的直方图",{"2":{"773":1}}],["下面的代码片段是基于多头注意力对一个张量完成自注意力的计算",{"2":{"396":1}}],["下面的代码定义了输入如何通过网络映射到输出",{"2":{"632":1}}],["下面的代码生成合成数据集",{"2":{"599":1}}],["下面的代码生成一个网络",{"2":{"422":1}}],["下面的代码实现了vgg",{"2":{"508":1}}],["下面的代码从第二个全连接层",{"2":{"431":1}}],["下面的代码每次可以从数据中随机生成一个小批量",{"2":{"320":1}}],["下面的代码将实例化两个标量",{"2":{"989":1}}],["下面的代码将",{"2":{"879":1}}],["下面的代码将模型参数放在gpu上",{"2":{"451":1}}],["下面的代码将模型拟合训练数据集",{"2":{"275":1}}],["下面的代码将在",{"2":{"448":1}}],["下面的代码将所有权重参数初始化为标准差为0",{"2":{"435":1}}],["下面的代码将生成一个名为submission",{"2":{"213":1}}],["下面的download函数用来下载数据集",{"2":{"206":1}}],["下面的模型将第一个和第二个隐藏层的暂退概率分别设置为0",{"2":{"174":1}}],["下面的例子分别演示了当我们沿行",{"2":{"1018":1}}],["下面的例子显示",{"2":{"405":1}}],["下面的例子展示了如何使用这种方法产生更好的解决方案",{"2":{"71":1}}],["下面的例子说明了即使学习率从0",{"2":{"87":1}}],["下面的例子说明了",{"2":{"56":1}}],["下面",{"2":{"78":1,"121":1,"122":2,"136":1,"142":1,"147":1,"148":1,"231":1,"234":1,"236":1,"277":1,"317":1,"319":1,"432":1,"433":1,"472":1,"474":1,"564":1,"572":1,"573":1,"574":1,"584":1,"616":1,"633":1,"656":1,"663":1,"674":1,"704":1,"714":1,"782":1,"817":1,"818":1,"840":1,"862":1,"891":1,"913":1,"919":1,"926":1,"938":1,"1088":1}}],["下面我们要基于这些特征来构建一个推荐系统算法",{"2":{"1188":1}}],["下面我们可以查看训练集和测试集所保留的样本个数",{"2":{"948":1}}],["下面我们深入了解一下这个数据集",{"2":{"945":1}}],["下面我们创建数据加载器实例的方式与",{"2":{"904":1}}],["下面我们看一下如何在相对较大的图像上使用图像增广",{"2":{"903":1}}],["下面我们了解一下全卷积网络模型最基本的设计",{"2":{"862":1}}],["下面我们了解一下adam算法",{"2":{"32":1}}],["下面我们实现了offset",{"2":{"854":1}}],["下面我们为锚框和真实边界框样本添加一个维度",{"2":{"853":1}}],["下面我们为每个输入计算三个未规范化的预测",{"2":{"641":1}}],["下面我们加载50维glove嵌入",{"2":{"748":1}}],["下面我们简单思考一下这种梯度异常在实践中的意义",{"2":{"538":1}}],["下面我们使用xavier初始化方法初始化第一个神经网络层",{"2":{"435":1}}],["下面我们使用nasa开发的测试机翼的数据集不同飞行器产生的噪声来比较这些优化算法",{"2":{"79":1}}],["下面我们继续定义具有参数的层",{"2":{"414":1}}],["下面我们指定了超参数来",{"2":{"407":1}}],["下面我们",{"2":{"320":1,"569":1,"595":1,"945":1}}],["下面我们将数据集按行写入csv文件中",{"2":{"1011":1}}],["下面我们将使用一个简单网络来演示多gpu训练",{"2":{"833":1}}],["下面我们将重点讨论数据并行性",{"2":{"832":1}}],["下面我们将展示如何使用深度学习框架的高级api来实现这一点",{"2":{"825":1}}],["下面我们将展示如何计算目标函数相对于所有分解模型参数的梯度",{"2":{"312":1}}],["下面我们将详细讨论各类门控",{"2":{"539":1}}],["下面我们将其应用",{"2":{"473":1}}],["下面我们将从头开始实现权重衰减",{"2":{"272":1}}],["下面我们将看到",{"2":{"93":1}}],["下面我们绘制tanh函数",{"2":{"237":1}}],["下面我们绘制relu函数的导数",{"2":{"235":1}}],["下面我们定义了模型训练函数train",{"2":{"894":1}}],["下面我们定义了两个函数",{"2":{"99":1}}],["下面我们定义一个函数来裁剪模型的梯度",{"2":{"334":1}}],["下面我们定义一些函数",{"2":{"41":1}}],["下面我们来看看协方差矩阵是如何影响模型的",{"2":{"1184":1}}],["下面我们来看一下凸函数一些有趣的性质",{"2":{"43":1}}],["下面我们来训练一个标准的逻辑回归分类器",{"2":{"1112":1}}],["下面我们来描述风格迁移的损失函数",{"2":{"921":1}}],["下面我们来定义一个用于加载snli数据集的类",{"2":{"668":1}}],["下面我们来实现这个模块",{"2":{"502":1}}],["下面我们来查看",{"2":{"501":1}}],["下面我们来展示如何实现梯度下降",{"2":{"54":1}}],["下面我们用反证法给出证明",{"2":{"44":1}}],["经历了",{"2":{"1437":1}}],["经典统计学习技术中的线性回归和softmax回归可以视为线性神经网络",{"2":{"587":1}}],["经典卷积神经网络的基本组成部分是下面的这个序列",{"2":{"507":1}}],["经典机器学习的流水线看起来更像下面这样",{"2":{"454":1}}],["经典泛化理论认为",{"2":{"170":1}}],["经常被销毁和重新创建",{"2":{"1380":1}}],["经常地这样做之后",{"2":{"1138":1}}],["经常需要与数据和工具集成",{"2":{"1041":1}}],["经常使用卷积神经网络",{"2":{"395":1}}],["经常提到人工智能奇点的问题",{"2":{"301":1}}],["经常包含在复杂深层网络的设计中",{"2":{"122":1}}],["经验风险是训练数据的平均损失",{"2":{"202":1}}],["经验风险是训练数据集的平均损失",{"2":{"99":1}}],["经验风险最小化即在",{"2":{"190":1}}],["经验风险",{"2":{"190":1}}],["经验风险与实际风险",{"0":{"190":1}}],["经过正则化处理的模型与原模型的可能对比如下图所示",{"2":{"1115":1}}],["经过p评判",{"2":{"1059":1}}],["经过预训练后",{"2":{"754":1}}],["经过预处理后",{"2":{"696":1}}],["经过大量研究试错后的结晶",{"2":{"492":1}}],["经过训练后",{"2":{"429":1}}],["经过变换后",{"2":{"382":4}}],["经过掩蔽softmax操作",{"2":{"368":1}}],["经过几个预测步骤之后",{"2":{"351":1}}],["经过最初的快速发展",{"2":{"299":1}}],["经过一番训练",{"2":{"282":1}}],["经过一段时间后",{"2":{"78":1}}],["经过思考",{"2":{"281":1}}],["经过10层5×5的卷积后",{"2":{"140":1}}],["经过额外的步骤",{"2":{"113":1}}],["经过20步之后",{"2":{"57":1}}],["按产出自然生长",{"2":{"1548":1}}],["按主题归档",{"2":{"1548":1}}],["按需发布",{"2":{"1544":1}}],["按需引入",{"2":{"1527":1}}],["按需调度资源",{"2":{"1355":1}}],["按这种方法我们可以逐渐构造出越来越复杂的函数",{"2":{"1102":1}}],["按下回车键",{"2":{"1094":1}}],["按梯度下降最快方向进行",{"2":{"1068":1}}],["按行计算",{"2":{"996":1}}],["按元素",{"2":{"1018":1}}],["按元素运算将二元运算符应用于两个数组中的每对位置对应的元素",{"2":{"1018":1}}],["按元素相乘",{"2":{"699":1}}],["按元素乘积",{"2":{"541":1}}],["按元素分配只需遍历分别为b和c的所有行和列",{"2":{"77":1}}],["按词元生成输出",{"2":{"373":1}}],["按出现频率排序",{"2":{"363":1}}],["按照字段范围切分",{"2":{"1207":1}}],["按照距离k个中心点的距离",{"2":{"1151":1}}],["按照支持向量机的惯例",{"2":{"1143":1}}],["按照",{"2":{"1100":1}}],["按照这样的方法对向量v操作",{"2":{"1088":1}}],["按照惯例",{"2":{"819":1,"1143":1}}],["按照想要执行的顺序添加层",{"2":{"422":1}}],["按照链式法则",{"2":{"307":1}}],["按照传统惯例",{"2":{"98":1}}],["按钮下载数据集",{"2":{"889":1,"901":1}}],["按钮",{"2":{"213":3,"1059":1,"1533":1}}],["按相反的顺序从输出层到输入层遍历网络",{"2":{"164":1}}],["按顺序",{"2":{"162":1}}],["按凸性我们有",{"2":{"115":1}}],["推动持续集成与持续部署",{"2":{"1354":1}}],["推动领域进步的是数据特征",{"2":{"454":1}}],["推送冲突",{"2":{"1337":1}}],["推送标签",{"2":{"1335":1}}],["推送到远程",{"2":{"1330":1}}],["推行工作上的细节",{"0":{"1192":1},"2":{"1193":1}}],["推出评分",{"2":{"1191":1}}],["推理链路",{"2":{"1546":1}}],["推理",{"2":{"1050":2}}],["推理和将规则纳入系统的能力",{"2":{"301":1}}],["推断为",{"2":{"1401":2}}],["推断出来",{"2":{"670":1}}],["推断更多地表示基于数据集估计参数",{"2":{"614":1}}],["推断机器人的精确位置",{"2":{"298":1}}],["推荐从学习html",{"2":{"1541":1}}],["推荐阅读",{"2":{"1531":1}}],["推荐阅读与工具资源",{"0":{"1055":1}}],["推荐使用reactive",{"2":{"1458":1}}],["推荐使用虚拟环境",{"2":{"1264":1}}],["推荐资源",{"0":{"1306":1}}],["推荐的入门路径如下",{"2":{"1304":1}}],["推荐在大型项目中规范代码",{"2":{"1259":1}}],["推荐",{"0":{"1444":1},"2":{"294":1,"301":1}}],["推荐系统就是类型设置的一个例子",{"2":{"1187":1}}],["推荐系统问题实际上受到很少的关注",{"2":{"1187":1}}],["推荐系统是个有趣的问题",{"2":{"1187":1}}],["推荐系统首先会优先推送一个购买量较大",{"2":{"294":1}}],["推荐系统有可能形成反馈循环",{"2":{"294":1}}],["推荐系统算法经过调整",{"2":{"294":1}}],["推荐系统都可以检索得分最高的对象集",{"2":{"294":1}}],["推荐系统会为",{"2":{"294":1}}],["推荐系统",{"0":{"294":1,"1186":1},"1":{"1187":1,"1188":1,"1189":1,"1190":1,"1191":1,"1192":1},"2":{"1193":1}}],["推导过程",{"2":{"1109":1}}],["推导出使用平方误差的线性回归优化问题的解析解",{"2":{"621":1}}],["推导正向和反向传播方程",{"2":{"167":1}}],["推导h",{"2":{"97":1}}],["推回",{"2":{"48":1}}],["变基",{"0":{"1334":1}}],["变种",{"0":{"1199":1}}],["变大了",{"2":{"1145":1}}],["变尺度法",{"2":{"1111":1}}],["变小而变大",{"2":{"1109":1}}],["变成了中间层的向量",{"2":{"1100":1}}],["变成m×o矩阵",{"2":{"1075":1}}],["变成可落地的智能系统",{"2":{"1051":1}}],["变化率",{"2":{"981":1}}],["变化也快得多",{"2":{"87":1}}],["变得更好意味着最小化一个损失函数",{"2":{"980":1}}],["变得至关重要",{"2":{"499":1}}],["变为必填",{"2":{"1435":1}}],["变为可选",{"2":{"1435":1}}],["变为",{"2":{"421":1,"736":3}}],["变为r",{"2":{"95":1}}],["变量类型声明",{"2":{"1398":1}}],["变量的定义与命名",{"0":{"1214":1},"1":{"1215":1}}],["变量与数据类型",{"0":{"1213":1},"1":{"1214":1,"1215":1,"1216":1}}],["变量作为一个数据结构可以存储你想要的options",{"2":{"1111":1}}],["变量prediction",{"2":{"1093":1}}],["变量b等于",{"2":{"1088":1}}],["变量boxes中x轴和y轴的坐标值已分别除以图像的宽度和高度",{"2":{"848":1}}],["变量",{"2":{"424":1,"853":1,"1304":1}}],["变量中",{"2":{"325":1}}],["变量在算法的后期阶段移动非常缓慢",{"2":{"108":1}}],["设a",{"2":{"1090":1}}],["设矩阵a=xtx",{"2":{"1085":1}}],["设",{"2":{"1077":1,"1090":1}}],["设函数f",{"2":{"983":1}}],["设y=f",{"2":{"982":1}}],["设步幅为1且没有填充",{"2":{"968":1}}],["设真实类别j的预测概率是pj",{"2":{"966":1}}],["设特征图的高和宽分别为h和w",{"2":{"954":1}}],["设目标类别的数量为q",{"2":{"954":1}}],["设批量大小为64",{"2":{"948":1}}],["设输入为一张图像",{"2":{"938":1}}],["设定μ和描述的一样σ",{"2":{"1185":1}}],["设定为非常小的值",{"2":{"1143":1}}],["设定某个实数来评估你的学习算法",{"2":{"1139":1}}],["设定全局变量",{"2":{"837":1}}],["设定一个任意大小的矩形汇聚窗口",{"2":{"147":1}}],["设备",{"2":{"836":1}}],["设备有运行开销",{"2":{"814":1}}],["设pij=defp",{"2":{"744":1}}],["设pij为用于生成上下文词wj的条件概率xij",{"2":{"742":1}}],["设n",{"2":{"709":1}}],["设为32",{"2":{"482":1}}],["设全连接层的输入为x",{"2":{"469":1}}],["设小批量大小为1",{"2":{"341":1}}],["设隐藏层的激活函数为ϕ",{"2":{"339":1}}],["设单个样本的输入及其对应的标签分别为",{"2":{"312":1}}],["设计等方向的实践与探索",{"2":{"1056":1}}],["设计说明请参考",{"2":{"843":1}}],["设计这种设备的原因之一是可以根据需要独立地添加或删除模块",{"2":{"811":1}}],["设计并实验具有更加复杂的数据依赖关系的计算任务",{"2":{"799":1}}],["设计自然语言处理模型",{"2":{"663":1}}],["设计自定义层和块",{"2":{"421":1}}],["设计了一个通用的",{"2":{"572":1}}],["设计了网络后",{"2":{"433":1}}],["设计一套新的特征函数",{"2":{"455":1}}],["设计一个高效的同步协议是非常重要的",{"2":{"842":1}}],["设计一个实验来验证这一点",{"2":{"799":1}}],["设计一个实验来回答这些问题",{"2":{"178":1}}],["设计一个实验",{"2":{"799":2}}],["设计一个具有多个隐藏层的双向循环神经网络",{"2":{"525":1}}],["设计一个更好的模型",{"2":{"465":1}}],["设计一个返回输入数据的傅立叶系数前半部分的层",{"2":{"416":1}}],["设计一个接受输入并计算张量降维的层",{"2":{"416":1}}],["设计一个定义在r2上的目标函数",{"2":{"64":1}}],["设计可伸缩算法的关键挑战之一是深度学习优化的主力",{"2":{"300":1}}],["设想一下",{"2":{"295":1}}],["设置的小一点",{"2":{"1144":1}}],["设置的非常大",{"2":{"1144":1}}],["设置一点惩罚",{"2":{"1115":1}}],["设置三角形的值为1",{"2":{"1112":1}}],["设置θ0",{"2":{"1092":1}}],["设置c为2",{"2":{"1090":1}}],["设置b为一个3",{"2":{"1090":1}}],["设置",{"2":{"1089":1,"1315":1}}],["设置a等于圆周率π",{"2":{"1088":1}}],["设置matplotlib的轴",{"2":{"981":1}}],["设置matplotlib的图表大小",{"2":{"981":1}}],["设置persistent=true来运行t",{"2":{"976":1}}],["设置demo为false",{"2":{"889":1}}],["设置non",{"2":{"797":1}}],["设置为其在字典中的相对频率",{"2":{"775":1}}],["设置为评估模式",{"2":{"137":2}}],["设置最大上下文窗口大小为2",{"2":{"774":1}}],["设置学习率为0",{"2":{"635":1}}],["设置超参数很棘手",{"2":{"605":1}}],["设置ht",{"2":{"527":1}}],["设置束宽为2",{"2":{"515":1}}],["设置transpose",{"2":{"370":3}}],["设置卷积层输入为x",{"2":{"146":1}}],["设置匹配参数会产生非常类似的轨迹",{"2":{"92":1}}],["∑j",{"2":{"1189":1}}],["∑j=1nθj2=θtθ⇒θtmθ其中",{"2":{"1147":1}}],["∑j=1nexp⁡",{"2":{"388":1,"389":1}}],["∑j=1nk",{"2":{"388":1}}],["∑j=1mexp⁡",{"2":{"367":1}}],["∑j=1kcijp",{"2":{"192":1}}],["∑=1m∑i=1n",{"2":{"1159":1}}],["∑icbi2",{"2":{"1154":3}}],["∑icai2",{"2":{"1154":3}}],["∑i=1n",{"2":{"1154":1}}],["∑i=1n|xi−yi|p",{"2":{"1154":1}}],["∑i=1n|xi|p",{"2":{"1000":1}}],["∑i=1m∑k=1kyk",{"2":{"1120":1}}],["∑i=1m",{"2":{"1115":2}}],["∑i=1dwi=1",{"2":{"997":1}}],["∑i",{"2":{"924":1,"1188":1,"1189":1}}],["∑i∈vexp⁡",{"2":{"785":1,"786":1}}],["∑i∈vexp",{"2":{"783":1,"784":2,"785":1}}],["∑i∈v∑j∈vh",{"2":{"743":1}}],["∑iαixi",{"2":{"42":1}}],["∑iαif",{"2":{"42":1}}],["∑w∈vp",{"2":{"709":1}}],["∑k∈vexp",{"2":{"742":1}}],["∑k=1mexp⁡",{"2":{"674":1}}],["∑k=1nexp⁡",{"2":{"674":1}}],["∑k=1qexp⁡",{"2":{"647":2}}],["∑kexp⁡",{"2":{"624":6,"631":1,"643":1}}],["∑ht−1p",{"2":{"519":1}}],["∑htp",{"2":{"519":1}}],["∑h2π2",{"2":{"519":1}}],["∑h1p",{"2":{"519":1}}],["∑t=1tηte",{"2":{"115":1}}],["∑t=1tηt=e",{"2":{"115":1}}],["∑t=1tηtr",{"2":{"115":1}}],["∑t=1tηt",{"2":{"115":3}}],["∑τ=0∞βτ=11−β",{"2":{"89":1}}],["该线性回归模型的代价为预测误差的平方和",{"2":{"1188":1}}],["该分布在中央最多",{"2":{"1185":1}}],["该用户可能选择接受",{"2":{"1168":1}}],["该怎么办",{"2":{"1103":1}}],["该怎么做呢",{"2":{"1110":1}}],["该怎么做",{"2":{"444":1}}],["该视频将暂停",{"2":{"1059":1}}],["该参数指定微分函数关于self的梯度",{"2":{"975":1}}],["该网络串联3个高和宽减半块",{"2":{"958":1}}],["该块应用了在",{"2":{"957":1}}],["该块可以在卷积神经网络中使用",{"2":{"497":1}}],["该图在运行前经过编译和优化",{"2":{"1021":1}}],["该图层使用填充为1的3×3的卷积层",{"2":{"954":1}}],["该图只显示连接模式",{"2":{"618":1}}],["该窗口将被划分为h2×w2子窗口网格",{"2":{"938":1}}],["该窗口根据其步幅大小在输入的所有区域上滑动",{"2":{"146":1}}],["该合成图像是风格迁移过程中唯一需要更新的变量",{"2":{"917":1}}],["该字典将文件名中不带扩展名的部分映射到其标签",{"2":{"890":1}}],["该区域的宽高比从0",{"2":{"879":1}}],["该通道的每个值减去该通道的平均值",{"2":{"872":1}}],["该位置通常由矩形边界框表示",{"2":{"859":1}}],["该如何如何量化呢",{"2":{"849":1}}],["该如何修改训练",{"2":{"830":1}}],["该链路最多只能以16gb",{"2":{"842":1}}],["该连接方式下的任何一对设备都可以同时执行",{"2":{"812":1}}],["该语料库取自",{"2":{"772":1}}],["该层的权重是一个矩阵",{"2":{"762":1}}],["该层需要输入参数",{"2":{"414":1}}],["该层需要两个参数",{"2":{"414":1}}],["该索引允许同一元素的多个实例",{"2":{"742":1}}],["该文本序列表示将被转换为情感分析输出",{"2":{"712":1}}],["该路径依次向左",{"2":{"709":1}}],["该向量最终被转换为用于二元情感预测的2维输出向量",{"2":{"701":1}}],["该词元同时编码前提和假设的信息",{"2":{"688":1}}],["该多层感知机由两个全连接层组成",{"2":{"688":1}}],["该假设与前提中索引i的词元进行软对齐",{"2":{"674":1}}],["该男子正在睡觉",{"2":{"665":1}}],["该事件的信息量也就更大",{"2":{"651":1}}],["该数字在不同的计算机和cpu供应商之间是否有所不同",{"2":{"815":1}}],["该数值被称为分布p的熵",{"2":{"650":1}}],["该数据集有四行三列",{"2":{"1011":1}}],["该数据集包括一个的csv文件",{"2":{"932":1}}],["该数据集包含1400张热狗的",{"2":{"872":1}}],["该数据集称为训练数据集",{"2":{"609":1}}],["该数据集由一些为训练而收集的样本组成",{"2":{"286":1}}],["该训练函数将会运行多个迭代周期",{"2":{"635":1}}],["该行的最大元素为0",{"2":{"634":2}}],["该名称来自统计物理学中一个模拟粒子群分布的方程",{"2":{"631":1}}],["该信息通过突触权重wi来加权",{"2":{"619":1}}],["该信息作为输入传递到下一个双向层",{"2":{"521":1}}],["该预测过程如",{"2":{"577":1}}],["该代码与之前在",{"2":{"528":1}}],["该代码看起来几乎与我们上面的代码相同",{"2":{"474":1}}],["该策略已用于",{"2":{"513":1}}],["该汇聚层通道数量为所需的输出数量",{"2":{"497":1}}],["该模块将输入特征图的高度和宽度减半",{"2":{"957":1}}],["该模块同nin一样使用全局平均汇聚层",{"2":{"488":1}}],["该模型的输出变量范围始终在0和1之间",{"2":{"1107":1}}],["该模型的预测是词表的所有可用词元上的均匀分布",{"2":{"342":1}}],["该模型简单",{"2":{"952":1}}],["该模型已在imagenet数据集上进行了预训练",{"2":{"871":1}}],["该模型使用了更小的卷积核",{"2":{"826":3}}],["该模型glove被称为全局向量",{"2":{"743":1}}],["该模型与原始的bert基础模型一样大",{"2":{"690":1}}],["该模型可以对广泛的自然语言处理任务进行最少的架构更改",{"2":{"656":1}}],["该模型可以使用强化学习方法",{"2":{"356":1}}],["该模型预测未来词元的能力却可能存在严重缺陷",{"2":{"523":1}}],["该模型预测这些社区还会有更多的犯罪",{"2":{"201":1}}],["该模型在较短的时间内达到了较低的困惑度",{"2":{"326":1}}],["该模型能有效降低训练损失和测试损失",{"2":{"264":1}}],["该模型通过单个仿射变换将我们的输入直接映射到输出",{"2":{"229":1}}],["该序列的自注意力输出为一个长度相同的序列",{"2":{"396":1}}],["该架构中使用了多头注意力",{"2":{"379":1}}],["该架构如",{"2":{"136":1}}],["该随机变量在预期中是正确的",{"2":{"310":1}}],["该环境给予智能体的奖励",{"2":{"298":1}}],["该标记指示哪些单词引用命名实体",{"2":{"295":1}}],["该问题的一种可能的解决方案",{"2":{"293":1}}],["该方法将执行得很好",{"2":{"252":1}}],["该方法根据微积分中的链式规则",{"2":{"164":1}}],["该测试集由随机选取的",{"2":{"252":1}}],["该激活被送到输出单元",{"2":{"244":1}}],["该梯度是l−l个矩阵",{"2":{"241":1}}],["该变量与y具有相同的值",{"2":{"976":1}}],["该变量指定了每个vgg块里卷积层个数和输出通道数",{"2":{"508":1}}],["该变换的参数为权重w",{"2":{"241":1}}],["该变体为relu添加了一个线性项",{"2":{"235":1}}],["该按钮位于右侧",{"2":{"213":1}}],["该平台促进了竞争方法之间的直接定量比较",{"2":{"207":1}}],["该平台帮助用户通过论坛和共享代码进行互动",{"2":{"207":1}}],["该技术不同于标准的暂退法技术",{"2":{"178":1}}],["该算法包含以下步骤",{"2":{"851":1}}],["该算法存储了计算某些参数梯度时所需的任何中间变量",{"2":{"164":1}}],["该算法根本无法收敛",{"2":{"114":1}}],["该检测器将图像分割成多个区域",{"2":{"152":1}}],["该卷积层以y为输入",{"2":{"131":1}}],["该卷积核在这里由矩阵k表示",{"2":{"130":1}}],["该函数的图像为",{"2":{"1107":1}}],["该函数创建了合成图像的模型实例",{"2":{"926":1}}],["该函数获取所有的gpu",{"2":{"883":1}}],["该函数使用微调",{"2":{"874":1}}],["该函数将锚框和偏移量预测作为输入",{"2":{"854":1}}],["该函数在",{"2":{"760":1}}],["该函数在x1的方向上非常平坦",{"2":{"87":1}}],["该函数计算遮蔽语言模型和下一句子预测任务的损失",{"2":{"726":1}}],["该函数接收批量大小",{"2":{"600":1}}],["该函数接受模型参数集合",{"2":{"604":1}}],["该函数接受张量参数",{"2":{"436":1}}],["该函数接受输入张量x和卷积核张量k",{"2":{"126":1}}],["该函数能打乱数据集中的样本并以小批量方式获取数据",{"2":{"600":1}}],["该函数有三个参数",{"2":{"507":1}}],["该函数有两个参数",{"2":{"507":1}}],["该函数返回可能替换后的输入词元",{"2":{"721":1}}],["该函数返回给定形状和数据类型的所需张量",{"2":{"436":1}}],["该函数返回corpus",{"2":{"364":1}}],["该函数生成同一个块的多个实例",{"2":{"428":1}}],["该函数以dropout的概率丢弃张量输入x中的元素",{"2":{"172":1}}],["该项目使用mit许可证",{"2":{"18":1}}],["观测结果足以捕获实际的依赖关系",{"2":{"311":1}}],["观看深入分析和互动动画",{"2":{"86":1}}],["观察能否找出一些问题",{"2":{"1183":1}}],["观察效果",{"2":{"1147":1}}],["观察和分析实验结果",{"2":{"1038":1}}],["观察和分析不同的实验结果",{"2":{"97":1}}],["观察损失函数值下降的快慢",{"2":{"607":1}}],["观察每个层输出的形状",{"2":{"508":1}}],["观察一下resnet中不同模块的输入形状是如何变化的",{"2":{"502":1}}],["观察图像特征的提取方法",{"2":{"455":1}}],["观察模型各层的参数和梯度",{"2":{"439":1}}],["观察到的价格xt",{"2":{"346":1}}],["观察到了什么",{"2":{"268":1,"280":1}}],["观察上面的优化轨迹",{"2":{"88":1}}],["观察前5个迭代轮数的性能",{"2":{"73":1}}],["观察并分析实验结果",{"2":{"37":1}}],["文字侦测",{"2":{"1171":1}}],["文件定义多个服务",{"2":{"1347":1}}],["文件快照",{"2":{"1320":1}}],["文件内容",{"2":{"1320":1}}],["文件操作等",{"2":{"1304":1}}],["文件与路径管理",{"2":{"1263":1}}],["文件读写的标准方式",{"0":{"1252":1}}],["文件中支持标准",{"2":{"1314":1}}],["文件中",{"2":{"1089":1}}],["文件",{"0":{"1198":1},"2":{"686":1,"1011":1,"1089":2,"1198":1,"1302":1,"1309":1,"1388":1}}],["文件和一个预训练参数的",{"2":{"686":1}}],["文本数据通常有",{"2":{"773":1}}],["文本数据更不符合",{"2":{"284":1}}],["文本文件的每一行表示由空格分隔的一句话",{"2":{"772":1}}],["文本序列的标记",{"2":{"734":1}}],["文本标记",{"2":{"661":1,"733":1}}],["文本标注和问答",{"2":{"663":1}}],["文本标注",{"0":{"659":1}}],["文本片段",{"2":{"660":1}}],["文本对分类",{"2":{"733":1}}],["文本对分类或回归",{"0":{"658":1},"2":{"661":1}}],["文本对或其中的任何词元",{"2":{"727":1,"728":1}}],["文本对回归",{"2":{"658":1}}],["文本输出的第二行",{"2":{"636":1}}],["文本输出的第一行",{"2":{"636":1}}],["文本是序列数据的一种最常见的形式之一",{"2":{"365":1}}],["文本是最常见例子之一",{"2":{"360":1}}],["文本词表",{"2":{"363":1}}],["文本总行数",{"2":{"361":1}}],["文本预处理",{"0":{"360":1},"1":{"361":1,"362":1,"363":1,"364":1,"365":1,"366":1}}],["文本和视频都是连续的",{"2":{"345":1}}],["文本和时间序列分析",{"2":{"134":1}}],["文本",{"2":{"315":1,"363":1,"412":1,"1404":1}}],["文本到语音转换和机器翻译",{"2":{"550":1}}],["文本到语音",{"2":{"295":1}}],["文章尽量带可复制的代码片段",{"2":{"1548":1}}],["文章中所有词元的分数还通过softmax转换成概率分布",{"2":{"660":1}}],["文章中的单词是按顺序写的",{"2":{"305":1}}],["文章",{"2":{"86":1}}],["文档模型",{"2":{"1211":1}}],["文档存储",{"2":{"1205":1}}],["文档存取",{"2":{"1204":1}}],["文档的多字段查询",{"2":{"1199":1}}],["文档的逻辑容器",{"2":{"1196":1}}],["文档",{"0":{"1196":1},"2":{"1196":1,"1300":1}}],["文档数据库的智能问答",{"2":{"1054":1}}],["文档解析",{"2":{"1053":1}}],["文档工具",{"2":{"12":1}}],["文档生成",{"2":{"11":1}}],["诚然",{"2":{"86":1}}],["上线注意点",{"2":{"1546":1}}],["上头的开发者",{"2":{"1542":1}}],["上手难度",{"2":{"1530":1}}],["上手容易",{"0":{"1299":1}}],["上海",{"2":{"1518":1,"1519":1}}],["上运行",{"2":{"1376":1}}],["上游仓库",{"2":{"1324":1}}],["上传的文件路径",{"2":{"1315":1}}],["上执行构建与发布",{"2":{"1315":1}}],["上执行这些命令",{"2":{"816":1}}],["上限分析等等内容",{"2":{"1176":1}}],["上限分析中",{"2":{"1174":1}}],["上限分析",{"0":{"1174":1},"2":{"1193":1}}],["上式中的u是一个具有与数据之间最小投射误差的方向向量构成的矩阵",{"2":{"1159":1}}],["上求和",{"2":{"1110":1}}],["上标",{"2":{"1085":1}}],["上标t代表矩阵转置",{"2":{"1085":1}}],["上图是5个不同的模型",{"2":{"1184":1}}],["上图所示的神经网络中θ",{"2":{"1099":1}}],["上图的",{"2":{"1080":1}}],["上图中的",{"2":{"1122":1}}],["上图中",{"2":{"1060":1,"1158":1,"1178":1}}],["上个视频里的",{"2":{"1061":1}}],["上个视频中",{"2":{"1061":1}}],["上生成锚框",{"2":{"912":1}}],["上下翻转不会妨碍识别",{"2":{"879":1}}],["上下翻转图像",{"2":{"879":1}}],["上下文类型推断",{"0":{"1402":1}}],["上下文管理器",{"0":{"1251":1},"1":{"1252":1}}],["上下文记忆",{"2":{"1050":1,"1052":1}}],["上下文窗口中间i",{"2":{"774":1}}],["上下文窗口内的词共现可以携带丰富的语义信息",{"2":{"741":1}}],["上下文词对",{"2":{"774":1}}],["上下文词",{"2":{"774":1}}],["上下文词可以是词表v中的任意项",{"2":{"707":1}}],["上下文向量",{"2":{"731":1}}],["上下文敏感",{"2":{"731":1}}],["上下文无关表示具有明显的局限性",{"2":{"731":1}}],["上下文变量在所有的时间步与解码器的输入进行拼接",{"2":{"574":1}}],["上下文变量仅仅是输入序列在最后时间步的隐状态ht",{"2":{"573":1}}],["上训练目标模型",{"2":{"870":1}}],["上预训练神经网络模型",{"2":{"870":1}}],["上完成",{"2":{"841":1}}],["上设置模型",{"2":{"828":1}}],["上评估得到的",{"2":{"613":1}}],["上节介绍了框架下的注意力机制的主要成分",{"2":{"385":1}}],["上节我们解析了卷积层的原理",{"2":{"125":1}}],["上一个时间步的隐状态是",{"2":{"540":1}}],["上一个稠密块的输出通道数",{"2":{"482":4}}],["上一章我们介绍了卷积神经网络的基本原理",{"2":{"492":1}}],["上一时间步的编码器全层隐状态",{"2":{"375":1}}],["上一节中我们讨论了小批量随机梯度下降作为加速计算的手段",{"2":{"86":1}}],["上面代码的本质如下",{"2":{"1500":1}}],["上面进行的讨论中只是将特征矩阵中的一行",{"2":{"1099":1}}],["上面方法可能很难找到梯度",{"2":{"984":1}}],["上面提到使用异步计算可以将执行10000次计算所需的总时间减少到t1+10000t2+t3",{"2":{"794":1}}],["上面式子的解并不依赖于σ",{"2":{"616":1}}],["上面实现的迭代对教学来说很好",{"2":{"600":1}}],["上面所说的这些概念都没有得到充分的解释",{"2":{"306":1}}],["上面的代价函数只是针对一个用户的",{"2":{"1188":1}}],["上面的代码将生成一个submission",{"2":{"908":1}}],["上面的代码将生成一个",{"2":{"896":1}}],["上面的代码片段在",{"2":{"790":1}}],["上面的代码可能看起来很简单",{"2":{"592":2}}],["上面的很多方法都可以扩展开来扩展成一个六个月或更长时间的项目",{"2":{"1129":1}}],["上面的回归问题中如果我们的模型是",{"2":{"1115":1}}],["上面的例子里第一个",{"2":{"1092":1}}],["上面的xw是一个向量",{"2":{"602":1}}],["上面的multiheadattention类将使用下面定义的两个转置函数",{"2":{"382":1}}],["上面的公式是",{"2":{"316":1}}],["上面的列表仅仅触及了机器学习对实际应用的影响之处的皮毛",{"2":{"301":1}}],["上面的推理仅仅触及了现代参数初始化方法的皮毛",{"2":{"248":1}}],["上面的问题更为严重",{"2":{"241":1}}],["上面的隐藏单元由输入的仿射函数给出",{"2":{"232":1}}],["上面的输出乍一看似乎有所不同",{"2":{"148":1}}],["上有同样的性能",{"2":{"286":1}}],["上进行验证",{"2":{"257":1}}],["上的仓库",{"2":{"1319":1}}],["上的元素均为1以外全都为0",{"2":{"1076":1}}],["上的所有单位",{"2":{"912":1}}],["上的像素依据输入图像上这4个像素及其与",{"2":{"863":1}}],["上的非叶节点向量之间的点积",{"2":{"709":1}}],["上的自然语言推断任务设计了一个基于注意力的结构",{"2":{"685":1}}],["上的电影",{"2":{"345":1}}],["上的输出",{"2":{"236":1}}],["上的对应加和",{"2":{"156":1}}],["上性能优于暂退法的方法",{"2":{"178":1}}],["上",{"0":{"896":1},"2":{"137":1,"237":1,"449":1,"663":1,"801":1,"863":1,"982":1}}],["上述代码",{"2":{"1454":1}}],["上述代码实现了一个具有4个隐藏单元和2个输出的简单网络",{"2":{"821":1}}],["上述是个有点不正式的定义",{"2":{"1059":1}}],["上述结构与",{"2":{"901":1}}],["上述结果显然令人瞠目结舌",{"2":{"523":1}}],["上述结果对于循环神经网络中的梯度意味着什么",{"2":{"314":1}}],["上述生成锚框的方法在下面的multibox",{"2":{"848":1}}],["上述条件概率可以重写为",{"2":{"783":1}}],["上述思想在下面的batchify函数中实现",{"2":{"776":1}}],["上述两个预训练任务中的所有标签都可以从预训练语料库中获得",{"2":{"737":1}}],["上述循环神经网络",{"2":{"574":1}}],["上述编码器的实现",{"2":{"573":1}}],["上述的注意",{"2":{"675":1}}],["上述的计算结果只是候选隐状态",{"2":{"542":1}}],["上述的位置编码还允许模型学习得到输入序列中相对位置信息",{"2":{"400":1}}],["上述算法可以用来实现",{"2":{"367":1}}],["上述算法依赖于一个重要的假设",{"2":{"191":1}}],["上述问题的一种方法是进行参数初始化",{"2":{"245":1}}],["上述不同情况之间的一个关键区别是",{"2":{"200":1}}],["上述函数相当于先前实现的互相关函数corr2d",{"2":{"122":1}}],["上述推理构成了",{"2":{"86":1}}],["上述推理可以通过以下鞍点优化问题来表示",{"2":{"48":1}}],["泄漏平均值",{"0":{"86":1}}],["大众",{"2":{"1465":1,"1466":1}}],["大帅老猿",{"2":{"1449":1}}],["大团队",{"2":{"1325":1}}],["大公司如",{"2":{"1303":1}}],["大型数据集的学习",{"0":{"1164":1},"2":{"1193":1}}],["大型语料库中的词",{"2":{"744":1}}],["大规模生产环境",{"2":{"1351":1}}],["大规模机器学习",{"2":{"1163":1,"1193":1}}],["大规模数据集变得触手可及",{"2":{"300":1}}],["大",{"2":{"1147":1,"1530":1}}],["大数",{"2":{"1146":1}}],["大数f≈e−",{"2":{"1146":1}}],["大数定律",{"2":{"1026":1}}],["大边界分类背后的数学",{"0":{"1145":1}}],["大边界的直观理解",{"0":{"1144":1},"2":{"1193":1}}],["大间距分类器的描述",{"2":{"1144":1}}],["大家经常干的事情是",{"2":{"1138":1}}],["大家都知道这对人类意味着什么",{"2":{"1058":1}}],["大写字母来表示",{"2":{"992":1}}],["大写字母转换为小写字母",{"2":{"718":1}}],["大大减少训练时间",{"2":{"824":1}}],["大大简化了深度学习算法的实现",{"2":{"161":1}}],["大量的负向类",{"2":{"1182":1}}],["大量的数据是有帮助的情况",{"2":{"1141":1}}],["大量的硅谷公司正在收集web上的单击数据",{"2":{"1058":1}}],["大量文献认为列向量是向量的默认方向",{"2":{"990":1}}],["大量",{"2":{"773":1}}],["大量评论的数据被记录下来",{"2":{"691":1}}],["大模型有3",{"2":{"728":1}}],["大模型",{"2":{"726":1}}],["大了一倍以上",{"2":{"718":1}}],["大到11×11的卷积核",{"2":{"486":1}}],["大部分人并不尝试着列出可能的方法",{"2":{"1137":1}}],["大部分的自然语言处理和大部分的计算机视觉",{"2":{"1058":1}}],["大部分的进展都来自于对特征有了更聪明的想法",{"2":{"454":1}}],["大部分深度学习框架都在命令式编程与符号式编程之间进行选择",{"2":{"818":1}}],["大部分研究只基于小的公开数据集",{"2":{"456":1}}],["大部分机器学习的成功应用都使用了监督学习",{"2":{"289":1}}],["大于",{"2":{"1092":1}}],["大于1的特征值将会发散",{"2":{"312":1}}],["大于或等于",{"2":{"51":1}}],["大都是由廉价传感器和互联网规模应用所产生的大量数据",{"2":{"303":1}}],["大约经过两分钟的训练后",{"2":{"1127":1}}],["大约是0",{"2":{"1026":1}}],["大约为100",{"2":{"804":1}}],["大约2010年开始",{"2":{"300":1}}],["大约一半在顶部",{"2":{"141":1}}],["大多流行的优化算法通常基于一种基本方法",{"2":{"287":1}}],["大多时候",{"2":{"284":1}}],["大多数人的选择方法是随便从这些方法中选择一种",{"2":{"1129":1}}],["大多数人用来选择这些方法的标准是凭感觉的",{"2":{"1129":1}}],["大多数图像增广方法都具有一定的随机性",{"2":{"878":1}}],["大多数深度学习研究者和实践者都可以使用一台具有相当数量的内存",{"2":{"801":1}}],["大多数深度学习问题并不属于这一类",{"2":{"102":1}}],["大多数常见的深度学习模型都有类似的训练过程",{"2":{"637":1}}],["大多数文本序列的词元数量少于20个",{"2":{"566":1}}],["大多数的数据并非如此",{"2":{"305":1}}],["大多数机器学习会涉及到数据的转换",{"2":{"285":1}}],["大多数激活函数都是非线性的",{"2":{"234":1}}],["大多数新闻她只阅读一次",{"2":{"198":1}}],["大多数目标函数都很复杂",{"2":{"100":1}}],["大多数优化算法都关注的是最小化",{"2":{"98":1}}],["大脑的学习算法就能找出学习数据的方法",{"2":{"1098":1}}],["大脑的这一部分这一小片红色区域是你的听觉皮层",{"2":{"1098":1}}],["大脑就会学会处理它",{"2":{"1098":1}}],["大脑处理的方法",{"2":{"1098":1}}],["大脑可以学会去以看而不是听的方式处理图像",{"2":{"1098":1}}],["大脑自己也能够识别它",{"2":{"282":1}}],["大脑仍然能够自己执行认知功能",{"2":{"282":1}}],["大小和位置都有所不同",{"2":{"933":1}}],["大小和数量",{"2":{"289":1}}],["大小写和数字",{"2":{"723":1}}],["大小为batch",{"2":{"583":1}}],["大小为100的小批量在运行时间上甚至优于梯度下降",{"2":{"80":1}}],["大小为10的小批量比随机梯度下降更有效",{"2":{"80":1}}],["大小分别为k1和k2",{"2":{"124":1}}],["显式指定类型",{"2":{"1430":1}}],["显然越高次数的多项式模型越能够适应我们的训练数据集",{"2":{"1131":1}}],["显然从中得到了一些启示",{"2":{"495":1}}],["显然我们可以找到xt+1=f",{"2":{"349":1}}],["显然",{"2":{"308":1,"315":1,"347":1,"388":1,"811":1,"837":1,"1035":1}}],["显然线性模型很难让我们在竞赛中获胜",{"2":{"210":1}}],["显存",{"2":{"165":1}}],["显示出一个具体的行驶方向这就表示神经网络算法",{"2":{"1127":1}}],["显示出神经网络已经随机初始化了",{"2":{"1127":1}}],["显示变量a等于3",{"2":{"1088":1}}],["显示所有边界框",{"2":{"848":1}}],["显示以图像中以某个像素为中心的所有锚框",{"2":{"848":1}}],["显示矩阵热图",{"2":{"357":1}}],["显示不同输入",{"2":{"139":1}}],["显示优化过程中2d变量的轨迹",{"2":{"57":3}}],["显著降低",{"2":{"106":1}}],["显而易见",{"2":{"78":1,"316":1}}],["矢量化是性能的关键",{"2":{"814":1}}],["矢量化",{"0":{"809":1}}],["矢量化使数学表达上更简洁",{"2":{"620":1}}],["矢量化代码通常会带来数量级的加速",{"2":{"615":1}}],["矢量化加速",{"0":{"615":1}}],["矢量求和作为评分函数是否比",{"2":{"372":1}}],["矢量",{"2":{"78":2}}],["矢量x的坐标",{"2":{"61":1}}],["逐步掌握复杂的泛型和高级类型",{"2":{"1436":1}}],["逐行连结输入x",{"2":{"970":1}}],["逐个访问它们可能会很麻烦",{"2":{"432":1}}],["逐渐学习更多行的数据",{"2":{"1134":1}}],["逐渐地",{"2":{"301":1}}],["逐渐降低其表示的空间分辨率",{"2":{"138":1}}],["逐列计算a=bc",{"2":{"77":3}}],["逐元素计算a=bc",{"2":{"77":4}}],["每节车厢是",{"2":{"1321":1}}],["每计算常数b次训练实例",{"2":{"1166":1}}],["每组抽取n=10个样本",{"2":{"1038":1}}],["每组抽取10个样本",{"2":{"1026":1}}],["每组包含3个中心相同的锚框",{"2":{"913":1}}],["每天",{"2":{"1315":1}}],["每天运动时间等",{"2":{"990":1}}],["每天都有大量的书面文本产生",{"2":{"754":1}}],["每列的加和都是1",{"2":{"1035":1}}],["每列nh次",{"2":{"968":1}}],["每列对应一个相关的属性",{"2":{"290":1}}],["每台机器的梯度被发送到其本地cpu中",{"2":{"843":1}}],["每台设备上的网络需要先初始化",{"2":{"829":2}}],["每分钟转数",{"2":{"804":1}}],["每秒钟alvinn生成12次数字化图片",{"2":{"1127":1}}],["每秒输入",{"2":{"804":1}}],["每秒最多可以执行一千万次随机读取",{"2":{"802":1}}],["每秒浮点运算",{"2":{"300":1}}],["每行表示一个数据样本",{"2":{"1011":1}}],["每行nw次",{"2":{"968":1}}],["每行代表一个段落",{"2":{"718":1}}],["每行总和为1",{"2":{"631":1}}],["每行数据",{"2":{"609":1}}],["每行对应于模型的预测类别",{"2":{"192":1}}],["每",{"2":{"604":1}}],["每层的参数都在其属性中",{"2":{"430":1}}],["每层的隐藏单元数",{"2":{"223":1}}],["每层都是dense类的一个实例",{"2":{"422":1}}],["每两个数字和每四个数字上的比特值",{"2":{"399":1}}],["每一次梯度下降迭代",{"2":{"1164":1}}],["每一次都重新进行随机初始化",{"2":{"1153":1}}],["每一个特征向量都有50个特征",{"2":{"1157":1}}],["每一个网络都生成一个行驶方向",{"2":{"1127":1}}],["每一个a都是由上一层所有的x和每一个x所对应的决定的",{"2":{"1099":1}}],["每一个神经元又是一个个学习模型",{"2":{"1099":1}}],["每一个神经元都可以被认为是一个处理单元",{"2":{"1099":1}}],["每一个对角线三个数字加起来都是等于同一个数",{"2":{"1090":1}}],["每一个注意力汇聚都被称作一个头",{"2":{"380":1}}],["每一列",{"2":{"1090":1}}],["每一列是一种特征",{"2":{"610":1}}],["每一项任务可以由一个单独的小队来负责解决",{"2":{"1171":1}}],["每一项",{"2":{"989":1}}],["每一行",{"2":{"1090":1}}],["每一行包含着相同的训练输入",{"2":{"392":4}}],["每一行都包含着相同的训练输出",{"2":{"392":4}}],["每一行都包含着相同的训练输入",{"2":{"392":4}}],["每一行都包含着相同的测试输入",{"2":{"388":4}}],["每一行都包含着要在给定的每个查询的值",{"2":{"388":4}}],["每一行的属性构成了一个房子样本的特征向量",{"2":{"290":1}}],["每一张单独的照片即为一个样本",{"2":{"284":1}}],["每一层的θ",{"2":{"1120":1}}],["每一层的输出变量都是下一层的输入变量",{"2":{"1099":1}}],["每一层的隐状态将存储在",{"2":{"325":1}}],["每一层的期望值等于没有噪音时的值",{"2":{"170":1}}],["每一层提供一个层次的表示",{"2":{"302":1}}],["每一层l由变换fl定义",{"2":{"241":1}}],["每一层都输出到上面的层",{"2":{"231":1}}],["每一层与它的上一层相连",{"2":{"204":1}}],["每一层只包含局部的信息",{"2":{"155":1}}],["每一层特征的高度和宽度都减小了",{"2":{"136":1}}],["每一层有多个输出通道是至关重要的",{"2":{"121":1}}],["每条实线对应于骰子的6个值中的一个",{"2":{"1026":1}}],["每条路线都显示了预计的通行时间",{"2":{"282":1}}],["每条记录都包括房屋的属性值和属性",{"2":{"208":1}}],["每套房子的价格只出现在训练集中",{"2":{"208":1}}],["每场比赛都以至少一个数据集为中心",{"2":{"207":1}}],["每张照片具有百万级像素",{"2":{"151":1}}],["每个组件都可以读取",{"2":{"1490":1}}],["每个阶段都有两个钩子",{"2":{"1470":1}}],["每个节点的代理",{"2":{"1377":1}}],["每个容器只关注一个服务",{"2":{"1354":1}}],["每个容器只包含应用及其依赖",{"2":{"1353":1}}],["每个开发者的本地仓库都有完整历史",{"2":{"1318":1}}],["每个集合和索引都有单独的文件",{"2":{"1198":1}}],["每个叉",{"2":{"1178":1}}],["每个聚簇中正确分类的样本数占该",{"2":{"1154":1}}],["每个类输出的加和",{"2":{"1120":1}}],["每个类别对应一个输出",{"2":{"641":1}}],["每个类别由训练数据集",{"2":{"582":1}}],["每个类别由1000个图像表示",{"2":{"188":1}}],["每个包含一组输入x和一组输出信号y",{"2":{"1120":1}}],["每个像素则只有一个值",{"2":{"1097":1}}],["每个像素可能是一个或者多个数值",{"2":{"134":1}}],["每个元素都要乘",{"2":{"1073":1}}],["每个元素的形状",{"2":{"574":1}}],["每个向量也是如此",{"2":{"991":1}}],["每个图像总共生成",{"2":{"959":1}}],["每个图像对应四个特征x1",{"2":{"640":1}}],["每个块生成的特征图既用于生成锚框",{"2":{"959":1}}],["每个块后的分辨率减半",{"2":{"507":1}}],["每个高和宽减半块由两个填充为1的3×3的卷积层",{"2":{"957":1}}],["每个兴趣区域被划分为子窗口网格",{"2":{"938":1}}],["每个区域由5个元素表示",{"2":{"938":1}}],["每个提议区域都将被标注类别和真实边界框",{"2":{"937":1}}],["每个边界框的标签将被长度为5的数组表示",{"2":{"932":1}}],["每个锚框都根据真实值边界框来标记了类和偏移量",{"2":{"913":1}}],["每个中间张量被替换部分的位置与输入张量中元素的位置相对应",{"2":{"968":1}}],["每个中间结果都是一个",{"2":{"968":1}}],["每个中间活性值h以暂退概率p由随机变量h",{"2":{"170":1}}],["每个中心点都将有",{"2":{"848":3}}],["每个服务器只需要存储o",{"2":{"843":1}}],["每个服务器的带宽是有限的",{"2":{"843":1}}],["每个nvlink连接都能够以300gbit",{"2":{"842":1}}],["每个nin块后有一个最大汇聚层",{"2":{"495":1}}],["每个部分为40mb",{"2":{"841":1}}],["每个小批量都是使用train",{"2":{"837":1}}],["每个小批量包含一组特征和标签",{"2":{"600":1}}],["每个gpu还具有6个nvlink连接",{"2":{"842":1}}],["每个gpu通过pcie链路连接到主机cpu",{"2":{"842":1}}],["每个gpu使用这个小批量随机梯度",{"2":{"833":1}}],["每个gpu根据分配给它的小批量子集",{"2":{"833":1}}],["每个gpu生成16个通道的数据",{"2":{"832":1}}],["每个gpu占用的显存",{"2":{"832":1}}],["每个gpu将流入特定层的数据作为输入",{"2":{"832":1}}],["每个gpu有多个处理单元",{"2":{"789":1}}],["每个新模型的并行计算都从零开始实现是无趣的",{"2":{"825":1}}],["每个流式多处理器都由这样的四个块组成",{"2":{"811":1}}],["每个核心都能够在任何时候处理这样的操作",{"2":{"809":1}}],["每个处理器核心都由一组相当复杂的组件组成",{"2":{"808":1}}],["每个磁头读取一个磁道的比特",{"2":{"804":1}}],["每个存储体大部分时候都可以独立地读取内存",{"2":{"802":1}}],["每个后续传输只需要0",{"2":{"802":1}}],["每个后续模块将输出通道数量翻倍",{"2":{"508":1}}],["每个设备通常有多个gpu",{"2":{"789":1}}],["每个词都有两个d维向量表示",{"2":{"783":1}}],["每个词都被表示为一个长度为n的向量",{"2":{"781":1}}],["每个词对应一个从0到n−1的不同整数",{"2":{"781":1}}],["每个词元的表示可以是一个向量",{"2":{"754":1}}],["每个词元的条件概率也不同于",{"2":{"513":1}}],["每个词元都通过自注意力直接连接到任何其他词元",{"2":{"397":1}}],["每个词元都由一个d维向量表示",{"2":{"341":1}}],["每个词元都表示为一个数字索引",{"2":{"330":1}}],["每个句子至少需要有2个词",{"2":{"774":1}}],["每个一维卷积层在最大时间汇聚层合并后",{"2":{"702":3}}],["每个嵌入层的输出形状都是",{"2":{"702":3}}],["每个通道都能够双向传输16gbit",{"2":{"801":1}}],["每个通道都有自己的拉伸",{"2":{"470":1}}],["每个通道的输出是该通道的最大值",{"2":{"700":1}}],["每个批量的特征维度显示批量大小和输入特征数",{"2":{"600":1}}],["每个解码器当前时间步的输入都将来自于前一时间步的预测词元",{"2":{"577":1}}],["每个文本序列将具有相同的长度",{"2":{"568":1}}],["每个文本序列可以是一个句子",{"2":{"565":1}}],["每个文本序列又被拆分成一个词元列表",{"2":{"362":1}}],["每个隐状态都连续地传递到当前层的下一个时间步和下一层的当前时间步",{"2":{"526":1}}],["每个隐藏单元将为0",{"2":{"467":1}}],["每个隐藏层中激活值的方差是多少",{"2":{"178":1}}],["每个隐藏层包含256个单元",{"2":{"173":1}}],["每个示例中的输入数d",{"2":{"521":1}}],["每个短语的",{"2":{"518":1}}],["每个时间步的隐状态由当前时间步的前后数据同时决定",{"2":{"524":1}}],["每个时间步的隐状态和输出可以写为",{"2":{"307":1}}],["每个时间步下的四个数字分别表示在该时间步",{"2":{"513":1}}],["每个模块都有一条64位宽的总线",{"2":{"802":1}}],["每个模块提供20",{"2":{"802":1}}],["每个模块有4个卷积层",{"2":{"502":1}}],["每个模块使用若干个同样输出通道数的残差块",{"2":{"502":1}}],["每个附加层都应该更容易地包含原始函数作为其元素之一",{"2":{"500":1}}],["每个张量都有一个设备",{"2":{"445":1}}],["每个参数都表示为参数类的一个实例",{"2":{"431":1}}],["每个添加的块都按照它们被添加的顺序执行",{"2":{"424":1}}],["每个单位",{"2":{"912":1}}],["每个单独的层接收输入",{"2":{"422":1}}],["每个单元格的值cij是验证集中",{"2":{"192":1}}],["每个层都有可学习的参数",{"2":{"455":1}}],["每个层都有两个子层",{"2":{"404":1}}],["每个层对象都存在",{"2":{"418":1}}],["每个层的输入维度为",{"2":{"418":1}}],["每个注意力头都根据查询",{"2":{"409":1}}],["每个注意力头hi",{"2":{"381":1}}],["每个子层都采用了残差连接",{"2":{"404":1}}],["每个数组都有一个设备",{"2":{"445":1}}],["每个数组都有一个环境",{"2":{"445":1}}],["每个数字被投中了多少次",{"2":{"1026":1}}],["每个数字",{"2":{"399":1}}],["每个数据集由一个个样本",{"2":{"284":1}}],["每个查询都会关注所有的键",{"2":{"395":1}}],["每个查询都会在键值对上分配不同的权重",{"2":{"376":1}}],["每个头都可能会关注输入的不同部分",{"2":{"381":1}}],["每个值都与一个键",{"2":{"356":1}}],["每个分类对应一个",{"2":{"298":1}}],["每个视频片段可能由不同数量的帧组成",{"2":{"295":1}}],["每个",{"2":{"289":1,"470":1,"1154":1,"1310":1}}],["每个样本都包括一张图片和一个标签",{"2":{"892":1}}],["每个样本都可以并行地进行模型计算",{"2":{"600":1}}],["每个样本都是一个评论及其标签",{"2":{"692":1}}],["每个样本都是由源和目标组成的文本序列对",{"2":{"568":1}}],["每个样本都是在原始的长序列上任意捕获的子序列",{"2":{"320":1}}],["每个样本都是声波振幅的测量值",{"2":{"282":1}}],["每个样本包含从标准正态分布中采样的2个特征",{"2":{"599":1}}],["每个样本包含特征和相应标签值",{"2":{"296":1}}],["每个样本中的输入数",{"2":{"527":1}}],["每个样本80个特征",{"2":{"208":1}}],["每个样本80个特征和1个标签",{"2":{"208":1}}],["每个输出通道将有一个ci×kh×kw的卷积核",{"2":{"969":1}}],["每个输出通道先获取所有输入通道",{"2":{"121":1}}],["每个输出对应于它自己的仿射函数",{"2":{"641":1}}],["每个输入都与每个输出",{"2":{"618":1}}],["每个输入都会影响隐藏层中的每个神经元",{"2":{"231":1}}],["每个输入图像的高度和宽度均为28像素",{"2":{"582":1}}],["每个神经元对其敏感的感受野",{"2":{"145":1}}],["每个全连接层减少维数",{"2":{"136":1}}],["每个汇聚层的高度和宽度都减半",{"2":{"136":1}}],["每个2×2池操作",{"2":{"136":1}}],["每个卷积层后接一个批量规范化层和relu激活函数",{"2":{"501":1}}],["每个卷积层使用5×5卷积核和一个sigmoid激活函数",{"2":{"136":1}}],["每个卷积块使用相同数量的输出通道",{"2":{"480":1}}],["每个卷积块中的基本单元是一个卷积层",{"2":{"136":1}}],["每个rgb输入图像具有3×h×w的形状",{"2":{"119":1}}],["每个迭代轮数的时间都会增加",{"2":{"80":1}}],["每个迭代轮数所需的时间比随机梯度下降和批量梯度下降所需的时间短",{"2":{"80":1}}],["每次提交都是",{"2":{"1320":1}}],["每次",{"2":{"1312":1,"1321":1}}],["每次交互事件并不只产生一个数据集",{"2":{"1168":1}}],["每次就通过自身加上$",{"2":{"1093":1}}],["每次你去亚马逊或netflix或itunes",{"2":{"1058":1}}],["每次您阅读您的电子邮件垃圾邮件筛选器",{"2":{"1058":1}}],["每次都在原有算法更新规则的基础上令$",{"2":{"1116":1}}],["每次都分配新的内存可能很快就会将内存耗尽",{"2":{"974":1}}],["每次都对输入",{"2":{"121":1}}],["每次传输需要10毫秒=160mb",{"2":{"841":1}}],["每次执行一位的加法",{"2":{"615":1}}],["每次更新都需要计算损失函数关于模型参数的梯度",{"2":{"601":1}}],["每次抽取一小批量样本",{"2":{"600":1}}],["每次迭代可能不会减小代价函数",{"2":{"1083":1}}],["每次迭代都需要通过代价高昂的许多线性代数层传递数据",{"2":{"457":1}}],["每次迭代的计算代价从梯度下降的o",{"2":{"113":1}}],["每次迭代的梯度下降计算代价将较高",{"2":{"113":1}}],["每次在k−1个子集上进行训练",{"2":{"257":1}}],["每次滑动多个元素",{"2":{"142":1}}],["每次我们执行代码时",{"2":{"77":1}}],["每次我们计算一个元素aij时",{"2":{"77":1}}],["每|1−ηλ|",{"2":{"95":1}}],["每当一个用户询问从地点a至地点b的快递费用时",{"2":{"1168":1}}],["每当一个样本被处理",{"2":{"80":1}}],["每当我研究机器学习的问题时",{"2":{"1138":1}}],["每当我在使用这个函数",{"2":{"1090":1}}],["每当我们执行w←w−ηtgt时",{"2":{"78":1}}],["每当我们处于有界区域|f",{"2":{"60":1}}],["每当单个设备不足以进行优化时",{"2":{"812":1}}],["每当python前端线程执行前三条语句中的一条语句时",{"2":{"790":1}}],["每当更新门zt接近1时",{"2":{"542":1}}],["每当重置门rt中的项接近1时",{"2":{"541":1}}],["每当ξt=0时",{"2":{"310":1}}],["每当优化进度停顿时",{"2":{"114":1}}],["每当数据非常相似时",{"2":{"76":1}}],["每当进展趋于稳定时就降低学习率",{"2":{"74":1}}],["每当t∈s时",{"2":{"71":1}}],["每当gt2具有值很大的变量或更新很稀疏时",{"2":{"35":1}}],["每当特征值λi很大时",{"2":{"26":1}}],["矩阵策略",{"0":{"1313":1}}],["矩阵来训练算法",{"2":{"1192":1}}],["矩阵展开为向量",{"2":{"1124":1}}],["矩阵转成一个向量",{"2":{"1090":1}}],["矩阵转置的基本性质",{"2":{"1077":1}}],["矩阵也可以这样操作",{"2":{"1090":1}}],["矩阵b",{"2":{"1089":1}}],["矩阵b将复制行",{"2":{"1019":1}}],["矩阵再在右边附上一个新添加的列矩阵",{"2":{"1089":1}}],["矩阵第一个索引值为1或3的元素",{"2":{"1089":1}}],["矩阵第二列的所有元素",{"2":{"1089":1}}],["矩阵第i行",{"2":{"398":1}}],["矩阵x",{"2":{"1086":1}}],["矩阵x中两行和两列中的元素已被丢弃",{"2":{"851":1}}],["矩阵向量乘法",{"0":{"1074":1},"2":{"1193":1}}],["矩阵向量积ax是一个长度为m的列向量",{"2":{"998":1}}],["矩阵项",{"2":{"1072":1}}],["矩阵元素",{"2":{"1072":1}}],["矩阵泛化自向量",{"2":{"1003":1}}],["矩阵和向量的乘法如图",{"2":{"1074":1}}],["矩阵和向量",{"0":{"1072":1},"2":{"1193":1}}],["矩阵和张量执行各种操作",{"2":{"1003":1}}],["矩阵和张量分别具有零",{"2":{"1003":1}}],["矩阵和张量是线性代数中的基本数学对象",{"2":{"1003":1}}],["矩阵和任意数量轴的张量",{"2":{"994":1}}],["矩阵可以分解为因子",{"2":{"1002":1}}],["矩阵a=",{"2":{"1090":1}}],["矩阵a将复制列",{"2":{"1019":1}}],["矩阵a中元素的和可以记为∑i=1m∑j=1naij",{"2":{"995":1}}],["矩阵a",{"2":{"994":1,"1089":1,"1090":1}}],["矩阵是二阶张量",{"2":{"993":1}}],["矩阵是向量的推广一样",{"2":{"993":1}}],["矩阵是有用的数据结构",{"2":{"992":1}}],["矩阵的和",{"2":{"1120":1}}],["矩阵的第一列还是",{"2":{"1089":1}}],["矩阵的第二列",{"2":{"1089":1}}],["矩阵的第二列的所有元素",{"2":{"1089":1}}],["矩阵的",{"2":{"1089":1}}],["矩阵的列数",{"2":{"1089":1}}],["矩阵的行数",{"2":{"1089":1}}],["矩阵的逆",{"2":{"1077":1}}],["矩阵的乘法满足结合律",{"2":{"1076":1}}],["矩阵的乘法不满足交换律",{"2":{"1076":1}}],["矩阵的乘法",{"2":{"1073":1}}],["矩阵的加法",{"2":{"1073":1}}],["矩阵的维数即行数×列数",{"2":{"1072":1}}],["矩阵的转置",{"2":{"992":1,"1077":1}}],["矩阵的高次幂可能导致神经网络特征值的发散或消失",{"2":{"313":1}}],["矩阵将向量从一阶推广到二阶",{"2":{"992":1}}],["矩阵中的非常大或非常小的元素可能造成数值上溢或下溢",{"2":{"631":1}}],["矩阵乘以",{"2":{"1090":1}}],["矩阵乘积发生爆炸",{"2":{"243":1}}],["矩阵乘法的性质",{"0":{"1076":1},"2":{"1076":1,"1193":1}}],["矩阵乘法可以简单地称为矩阵乘法",{"2":{"999":1}}],["矩阵乘法ab看作简单地执行m次矩阵",{"2":{"999":1}}],["矩阵乘法时需要使用的数据分配到两个变量",{"2":{"796":1}}],["矩阵乘法",{"0":{"999":1,"1075":1},"2":{"77":1,"78":1,"164":1,"999":1,"1075":1,"1193":1}}],["矩阵o和正特征值的对角矩阵λ",{"2":{"94":1}}],["矩阵",{"0":{"992":1,"998":1,"999":1,"1315":1},"2":{"77":1,"241":1,"992":1,"999":1,"1000":1,"1077":1,"1089":2,"1090":1}}],["矩阵m的特征值λi在至少一个j的选项中满足|λi−mjj|≤∑k≠j|mjk|的要求",{"2":{"31":1}}],["具名插槽",{"0":{"1507":1}}],["具备短期和长期的",{"2":{"1050":1}}],["具有两个轴以上的张量没有特殊的数学名称",{"2":{"1017":1}}],["具有两个轴的张量对应数学上的矩阵",{"2":{"1017":1}}],["具有一个轴的张量对应数学上的向量",{"2":{"1017":1}}],["具有一组相关",{"2":{"422":1}}],["具有符号中可能最长子字的词元段",{"2":{"757":1}}],["具有最大值的",{"2":{"757":1}}],["具有不同宽度的卷积核可以捕获不同数目的相邻词元之间的局部特征",{"2":{"701":1}}],["具有n个样本",{"2":{"646":1}}],["具有较大的负值",{"2":{"624":1}}],["具有分支预测器",{"2":{"457":1}}],["具有多个gpu",{"2":{"445":1}}],["具有更多参数的模型可能被认为更复杂",{"2":{"254":1}}],["具有全连接层的多层感知机的参数开销可能会高得令人望而却步",{"2":{"231":1}}],["具有输入噪声的训练等价于tikhonov正则化",{"2":{"170":1}}],["具有16个内核和avx",{"2":{"77":1}}],["具体使用",{"2":{"1503":1}}],["具体说明",{"2":{"1501":1}}],["具体数据",{"2":{"1498":1}}],["具体编码",{"2":{"1486":1,"1490":2,"1503":1,"1508":1,"1518":1}}],["具体配置",{"2":{"1444":1}}],["具体操作如下",{"2":{"1444":1}}],["具体方法",{"2":{"1416":1}}],["具体方法是在所有计数中添加一个小常量",{"2":{"316":1}}],["具体的请求匹配规则",{"2":{"1365":1}}],["具体的评价方法如下",{"2":{"1181":1}}],["具体的技术细节对于理解深度学习模型并不重要",{"2":{"519":1}}],["具体来讲",{"2":{"1129":2}}],["具体来说",{"2":{"45":1,"57":1,"80":1,"295":1,"307":1,"335":1,"373":1,"379":1,"382":1,"385":1,"395":1,"397":1,"404":1,"550":1,"578":1,"642":1,"663":1,"731":1,"751":1,"854":1,"937":1,"939":1,"940":1,"946":1,"954":1,"1026":1,"1070":1,"1109":1,"1112":1}}],["具体计算方法是ci←f",{"2":{"1018":1}}],["具体取决于它们的数值精度",{"2":{"811":1}}],["具体取决于用户的预算和电源负载的大小",{"2":{"801":1}}],["具体而言",{"2":{"312":1,"708":1,"872":1,"983":1,"994":1,"1091":1,"1144":2,"1169":1}}],["具体地说",{"2":{"42":1,"71":1,"178":1,"211":1,"291":1,"340":1,"522":1,"578":1,"771":1,"773":1,"785":1,"1085":1,"1086":1}}],["随网络深度的增加而升级",{"2":{"915":1}}],["随后解构",{"2":{"1492":1}}],["随后选择3",{"2":{"1443":1}}],["随后所有的梯度被聚合为一",{"2":{"838":1}}],["随后",{"2":{"639":1}}],["随后的卷积窗口形状固定为1×1",{"2":{"494":1}}],["随后是",{"2":{"300":1}}],["随之而来的是批量规范化带来的噪声注入的好处",{"2":{"78":1}}],["随着训练数据集的增大",{"2":{"1141":1}}],["随着训练数据量的增加",{"2":{"260":1}}],["随着我接近最低点",{"2":{"1068":1}}],["随着我们不断地靠近全局最小值",{"2":{"1167":1}}],["随着我们要讲的学习算法越来越复杂",{"2":{"1085":1}}],["随着我们设计越来越深的网络",{"2":{"499":1}}],["随着我们对预测时间k值的增加",{"2":{"352":1}}],["随着自动化的出现",{"2":{"1058":1}}],["随着",{"2":{"1051":1,"1132":1,"1133":1,"1357":1}}],["随着大语言模型",{"2":{"1049":1}}],["随着投掷次数的增加",{"2":{"1026":1}}],["随着gpu数量的增加学习率应该如何扩展",{"2":{"839":1}}],["随着tensorflow2",{"2":{"819":1}}],["随着在线社交媒体和评论平台的快速发展",{"2":{"691":1}}],["随着批量规范化的普及",{"2":{"475":1}}],["随着互联网的公司的出现",{"2":{"300":1}}],["随着时间的推移",{"2":{"299":1,"345":1,"421":1}}],["随着数据的收集和可获得性",{"2":{"299":1}}],["随着阶数d的增长",{"2":{"269":1}}],["随着拍摄角度的移动",{"2":{"145":1}}],["随着层叠的上升",{"2":{"136":1}}],["随着神经网络层数的加深",{"2":{"121":1}}],["随着优化的进展",{"2":{"111":1}}],["随着目标函数解的梯度接近或变为零",{"2":{"101":1}}],["随着后者增加",{"2":{"78":1}}],["随着缓存的大小的增加",{"2":{"77":1}}],["随机数生成",{"2":{"1263":1}}],["随机选择k个训练实例",{"2":{"1153":1}}],["随机选择一个元素i的概率是1",{"2":{"116":1}}],["随机变量函数的方差衡量的是",{"2":{"1036":1}}],["随机变量几乎可以是任何数量",{"2":{"1028":1}}],["随机变量",{"0":{"1028":1},"2":{"1028":2}}],["随机更改亮度",{"2":{"903":3}}],["随机更改图像的色调",{"2":{"880":1}}],["随机更改图像的亮度",{"2":{"880":2}}],["随机值为原始图像的50",{"2":{"880":1}}],["随机裁剪特征和标签图像",{"2":{"946":3}}],["随机裁剪图像",{"2":{"903":3}}],["随机裁剪出一个高度和宽度均为40像素的正方形图像",{"2":{"891":3}}],["随机裁剪",{"2":{"879":1}}],["随机改变训练样本可以减少模型对某些属性的依赖",{"2":{"877":1}}],["随机访问存储的一些关键特性是",{"2":{"803":1}}],["随机访问存储",{"2":{"801":1}}],["随机",{"2":{"784":2}}],["随机生成一个10×10矩阵并使用softmax运算来确保每行都是有效的概率分布",{"2":{"359":1}}],["随机生成一个小批量数据的特征和标签以供读取",{"2":{"319":1}}],["随机范围包括num",{"2":{"320":1}}],["随机的",{"2":{"320":2}}],["随机采样和顺序分区",{"2":{"335":1}}],["随机采样",{"0":{"320":1}}],["随机截断",{"0":{"310":1}}],["随机存取存储器没有跟上数据增长的步伐",{"2":{"300":1}}],["随机存取存储器",{"2":{"299":1}}],["随机初始化",{"0":{"1125":1,"1153":1},"2":{"1193":2}}],["随机初始化是保证在进行优化前打破对称性的关键",{"2":{"249":1}}],["随机初始化会产生巨大的发散",{"2":{"73":1}}],["随机梯度和有限样本",{"0":{"116":1}}],["随机梯度是对梯度的良好估计",{"2":{"113":1}}],["随机梯度∇fi",{"2":{"113":1}}],["随机梯度更新",{"0":{"113":1}}],["随机梯度下降收敛",{"0":{"1167":1},"2":{"1193":1}}],["随机梯度下降算法便已经走出了很远",{"2":{"1165":1}}],["随机梯度下降算法在每一次计算之后便更新参数",{"2":{"1165":1}}],["随机梯度下降算法为",{"2":{"1165":1}}],["随机梯度下降法",{"0":{"1165":1},"2":{"1193":1}}],["随机梯度下降通常也能找到非常好的解",{"2":{"605":1}}],["随机梯度下降将收敛到最优解",{"2":{"117":1}}],["随机梯度下降中变量的轨迹比我们在",{"2":{"113":1}}],["随机梯度下降",{"0":{"112":1,"613":1},"1":{"113":1,"114":1,"115":1,"116":1,"117":1,"118":1},"2":{"83":1,"113":1,"300":1}}],["随机梯度下降的变体",{"2":{"454":1}}],["随机梯度下降的最优性保证在非凸情况下一般不可用",{"2":{"117":1}}],["随机梯度下降的",{"2":{"82":1}}],["随机梯度下降的收敛速度快于梯度下降",{"2":{"80":1}}],["随机梯度下降并不特别",{"2":{"76":1}}],["随机梯度下降在解决优化问题时比梯度下降更有效",{"2":{"32":1}}],["事务与一致性",{"2":{"1204":1}}],["事务支持",{"2":{"1204":1}}],["事件名是任意名称",{"2":{"1498":1}}],["事件名是特定的",{"2":{"1498":1}}],["事件对象$event",{"2":{"1498":2}}],["事件触发时运行",{"2":{"1315":1}}],["事件a的概率",{"2":{"1027":1}}],["事件",{"2":{"1027":2}}],["事情就更加复杂了",{"2":{"802":1}}],["事情会变得更加棘手",{"2":{"445":3}}],["事情会更微妙一些",{"2":{"77":1}}],["事情并不那么简单",{"2":{"345":1}}],["事实是由于错误的累积",{"2":{"351":1}}],["事实证明",{"2":{"103":1,"116":1,"183":1,"302":1,"422":1,"467":1,"1061":3}}],["事实上有许多研究人员正在研究这样一些内容",{"2":{"1150":1}}],["事实上是一个负值",{"2":{"1145":1}}],["事实上这就等于向量θ的长度",{"2":{"1145":1}}],["事实上只要优化算法支持",{"2":{"841":1}}],["事实上我们可以把它写成",{"2":{"59":1}}],["事实上",{"2":{"49":1,"65":1,"101":1,"114":1,"115":1,"210":1,"233":1,"242":1,"259":1,"270":2,"291":1,"292":1,"299":2,"300":1,"319":1,"325":1,"342":1,"345":2,"349":1,"454":1,"455":2,"500":1,"519":1,"520":1,"521":1,"526":1,"550":1,"564":1,"605":1,"613":1,"639":1,"730":1,"797":1,"827":1,"849":1,"876":1,"905":1,"957":1,"980":1,"1000":1,"1058":1,"1060":1,"1061":3,"1070":2,"1088":1,"1089":1,"1111":1,"1141":1,"1143":2,"1144":2}}],["二类分类",{"2":{"1120":1}}],["二类分类和多类分类",{"2":{"1120":1}}],["二者不同",{"2":{"1061":1}}],["二者各有利弊",{"2":{"76":1}}],["二",{"0":{"1043":1,"1062":1,"1217":1,"1241":1,"1297":1,"1315":1,"1360":1},"1":{"1044":1,"1045":1,"1046":1,"1047":1,"1063":1,"1064":1,"1065":1,"1066":1,"1067":1,"1068":1,"1069":1,"1070":1,"1218":1,"1219":1,"1220":1,"1221":1,"1242":1,"1243":1,"1361":1,"1362":1,"1363":1},"2":{"1193":1}}],["二和任意数量的轴",{"2":{"1003":1}}],["二级缓存比一级缓存大",{"2":{"810":1}}],["二级缓存是下一站",{"2":{"810":1}}],["二元分类问题",{"2":{"1112":1}}],["二元逻辑运算符",{"2":{"1102":1}}],["二元交叉熵损失",{"0":{"765":1}}],["二元语法和三元语法的齐普夫定律的指数是不一样的",{"2":{"323":1}}],["二元语法和三元语法",{"2":{"318":1}}],["二元语法",{"2":{"317":1}}],["二次复杂度",{"2":{"674":1}}],["二次凸函数",{"0":{"94":1}}],["二进制表示",{"2":{"399":1}}],["二维卷积层的核心计算是二维互相关运算",{"2":{"132":1}}],["二阶导数的核的形式是什么",{"2":{"133":1}}],["二阶导数矩阵",{"2":{"51":1}}],["二阶导数可能也需要o",{"2":{"26":1}}],["小目标与进行中",{"0":{"1547":1}}],["小猪佩奇",{"2":{"1469":1}}],["小规模集群",{"2":{"1351":1}}],["小团队",{"2":{"1325":1}}],["小游戏",{"2":{"1301":1}}],["小脚本项目",{"2":{"1294":1}}],["小",{"2":{"1145":1,"1147":1,"1530":1}}],["小写的符号",{"2":{"990":1}}],["小心缓存影响",{"2":{"815":1}}],["小王子",{"2":{"342":1}}],["小于1的特征值将会消失",{"2":{"312":1}}],["小工具",{"2":{"292":1}}],["小爱同学",{"2":{"282":1}}],["小批量梯度下降算法是介于批量梯度下降算法和随机梯度下降算法之间的算法",{"2":{"1166":1}}],["小批量梯度下降",{"0":{"1166":1},"2":{"1193":1}}],["小批量计算虽然高效",{"2":{"932":1}}],["小批量包含的数据量就越大",{"2":{"832":1}}],["小批量加载训练实例",{"0":{"776":1}}],["小批量数目",{"2":{"694":3}}],["小批量数据量更大时",{"2":{"838":1}}],["小批量数据的时间步数",{"2":{"337":1}}],["小批量数据形状是二维张量",{"2":{"330":1}}],["小批量的未规范化预测o和输出概率y^",{"2":{"644":1}}],["小批量样本的矢量化加快了和x和w的矩阵",{"2":{"644":1}}],["小批量样本的矢量化",{"0":{"644":1}}],["小批量中每个样本是一行",{"2":{"631":1}}],["小批量中的子序列不一定在原始序列上相邻",{"2":{"320":2}}],["小批量限制了gpu的效率",{"2":{"300":1}}],["小批量上计算的",{"2":{"469":1}}],["小批量上梯度的自然变化能够将参数从局部极小值中跳出",{"2":{"101":1}}],["小批量上的计算基本上与完整矩阵一样有效",{"2":{"78":1}}],["小批量",{"0":{"78":1},"2":{"78":1,"600":1}}],["小批量随机梯度下降来优化模型的损失函数",{"2":{"635":1}}],["小批量随机梯度下降只需要设置lr值",{"2":{"594":1}}],["小批量随机梯度下降只需要设置learning",{"2":{"594":3}}],["小批量随机梯度下降算法是一种优化神经网络的标准工具",{"2":{"594":4}}],["小批量随机梯度下降可以通过以下方式计算",{"2":{"86":1}}],["小批量随机梯度下降和梯度下降的表现将如何变化",{"2":{"83":1}}],["小批量随机梯度下降比随机梯度下降和梯度下降的速度快",{"2":{"82":1}}],["小批量随机梯度下降提供了两全其美的答案",{"2":{"82":1}}],["小批量随机梯度下降能够平衡收敛速度和计算效率",{"2":{"80":1}}],["小批量随机梯度下降",{"0":{"76":1},"1":{"77":1,"78":1,"79":1,"80":1,"81":1,"82":1,"83":1},"2":{"244":1,"604":4}}],["小结一下使用神经网络时的步骤",{"2":{"1126":1}}],["小结",{"0":{"22":1,"30":1,"36":1,"51":1,"63":1,"74":1,"82":1,"96":1,"104":1,"110":1,"117":1,"123":1,"132":1,"138":1,"143":1,"149":1,"159":1,"166":1,"177":1,"202":1,"214":1,"222":1,"226":1,"238":1,"249":1,"267":1,"279":1,"303":1,"313":1,"322":1,"327":1,"336":1,"343":1,"352":1,"358":1,"365":1,"371":1,"377":1,"383":1,"393":1,"401":1,"410":1,"415":1,"419":1,"427":1,"438":1,"443":1,"452":1,"464":1,"476":1,"484":1,"490":1,"497":1,"504":1,"510":1,"516":1,"524":1,"530":1,"536":1,"548":1,"562":1,"570":1,"579":1,"585":1,"596":1,"606":1,"620":1,"627":1,"637":1,"654":1,"661":1,"670":1,"683":1,"689":1,"696":1,"705":1,"710":1,"716":1,"723":1,"728":1,"739":1,"745":1,"752":1,"758":1,"769":1,"778":1,"787":1,"793":1,"798":1,"814":1,"822":1,"829":1,"838":1,"845":1,"855":1,"859":1,"867":1,"875":1,"884":1,"897":1,"909":1,"914":1,"928":1,"934":1,"941":1,"950":1,"965":1,"971":1,"978":1,"985":1,"1003":1,"1008":1,"1014":1,"1023":1,"1037":1,"1541":1}}],["试着计算第二层的值",{"2":{"1100":1}}],["试着实现这个想法",{"2":{"868":1}}],["试着通过调整超参数来改善翻译效果",{"2":{"580":1}}],["试着增加迭代轮数",{"2":{"465":1}}],["试着重写动量和二次矩更新",{"2":{"37":1}}],["试图将θtx设置得非常大",{"2":{"1143":1}}],["试图学习视觉数据的逐级表征",{"2":{"455":1}}],["试图造成事故",{"2":{"199":1}}],["试图避开某物体",{"2":{"199":1}}],["试图直接使用最小范数或最大熵原理重新校准期望算子",{"2":{"191":1}}],["试一试其他填充和步幅组合",{"2":{"144":1}}],["试试使用完整kaggle比赛数据集",{"2":{"910":1}}],["试试在真正的机器学习问题上应用rmsprop算法会发生什么",{"2":{"111":1}}],["试试梯度下降和动量法来解决一个二次问题",{"2":{"97":1}}],["试验不同的取值来调整学习率",{"2":{"111":1}}],["试验参数如何",{"2":{"97":1}}],["试验给定固定学习率的优化行为",{"2":{"75":1}}],["较大",{"2":{"1147":2}}],["较大时",{"2":{"1144":1}}],["较大的过拟合可能意味着我们可以通过正则化技术来获益",{"2":{"212":1}}],["较大的β相当于长期平均值",{"2":{"86":1}}],["较小",{"2":{"1144":1,"1147":2}}],["较小时",{"2":{"1132":2,"1133":1,"1144":1}}],["较小的目标在图像上出现的可能性更多样",{"2":{"912":1}}],["较小的λ值对应较少约束的w",{"2":{"270":1}}],["较小的步长将导致参数更接近零",{"2":{"68":1}}],["较好地",{"2":{"849":1}}],["较容易",{"2":{"504":1}}],["较复杂的函数类并不总是向",{"2":{"500":1}}],["较短的序列比较长的序列更有可能出现",{"2":{"342":1}}],["较少的过拟合可能表明现有数据可以支撑一个更强大的模型",{"2":{"212":1}}],["较高比特位的交替频率低于较低比特位",{"2":{"399":1}}],["较高维度的鞍点甚至更加隐蔽",{"2":{"102":1}}],["较高的学习率最初就会导致发散",{"2":{"73":1}}],["函数中用到哪些属性",{"2":{"1467":1}}],["函数中实现",{"2":{"852":1}}],["函数创建一个应用实例",{"2":{"1444":1}}],["函数接口",{"0":{"1420":1}}],["函数接受一个device参数",{"2":{"796":2}}],["函数返回一个值",{"2":{"1461":1}}],["函数返回值类型推断",{"2":{"1401":1}}],["函数返回的第二个值是梯度值",{"2":{"1111":1}}],["函数表达式类型声明",{"2":{"1398":1}}],["函数参数和返回值类型声明",{"2":{"1398":1}}],["函数参数",{"2":{"1397":1}}],["函数执行结束",{"2":{"1244":1}}],["函数开始执行",{"2":{"1244":1}}],["函数式编程技巧",{"0":{"1238":1},"1":{"1239":1,"1240":1}}],["函数可以将重复使用的代码封装成一个单元",{"2":{"1228":1}}],["函数可以展现数学上的过程",{"2":{"1086":1}}],["函数定义与使用",{"0":{"1228":1},"1":{"1229":1,"1230":1}}],["函数cost0",{"2":{"1144":1}}],["函数后",{"2":{"1111":1}}],["函数会真的返回2个值",{"2":{"1092":1}}],["函数能让你看到当前工作空间中的所有变量",{"2":{"1089":1}}],["函数值偏离该函数的期望的程度",{"2":{"1036":1}}],["函数演示了这一点",{"2":{"1021":1}}],["函数来求解代价函数最小化的参数",{"2":{"1117":1}}],["函数来计算代价函数",{"2":{"1092":1}}],["函数来",{"2":{"991":1}}],["函数通常依赖于许多变量",{"2":{"982":1}}],["函数通过super",{"2":{"423":1}}],["函数y=2x⊤x关于x的梯度应为4x",{"2":{"974":1}}],["函数依赖关系",{"0":{"527":1}}],["函数类型别名",{"2":{"1412":1}}],["函数类型",{"2":{"1405":1}}],["函数类",{"0":{"500":1}}],["函数将返回一个矩阵",{"2":{"1090":1}}],["函数将返回一个列表",{"2":{"325":1}}],["函数将会等待一个cuda设备上的所有流中的所有核心的计算完成",{"2":{"796":2}}],["函数将每个模块逐个添加到有序字典",{"2":{"424":2}}],["函数也非常简单",{"2":{"422":1}}],["函数也能将其输入压缩转换到区间",{"2":{"237":1}}],["函数非常简单",{"2":{"422":1}}],["函数实现的一个python技巧",{"2":{"422":2}}],["函数分析和巴拿赫空间理论的研究",{"2":{"270":1}}],["函数阶数等于数据样本数量的多项式函数可以完美拟合训练集",{"2":{"259":1}}],["函数的时候",{"2":{"1160":1}}],["函数的值为0",{"2":{"1144":1}}],["函数的值范围为",{"2":{"554":1}}],["函数的指针",{"2":{"1111":1}}],["函数的代码示例",{"2":{"1109":1}}],["函数的特点是",{"2":{"1109":1}}],["函数的形状类似于sigmoid函数",{"2":{"237":1}}],["函数的解可能是局部最小值",{"2":{"102":1}}],["函数",{"2":{"172":1,"235":1,"423":2,"436":1,"722":1,"750":1,"947":1,"1052":1,"1061":1,"1090":1,"1101":1,"1111":2,"1181":1,"1183":1,"1232":1,"1304":1}}],["函数形式如下所示",{"2":{"72":1}}],["函数f∗靠拢",{"2":{"500":1}}],["函数f=0",{"2":{"270":1}}],["函数f",{"2":{"41":1,"44":2,"46":1,"54":1,"983":1,"986":1}}],["让世界看到你的创意和实力",{"2":{"1541":1}}],["让网页动起来",{"2":{"1539":1}}],["让网站不仅能用",{"2":{"1533":1}}],["让它们动起来",{"2":{"1533":1}}],["让它们高效地工作",{"2":{"1135":1}}],["让应用有更好的用户体验",{"2":{"1523":1}}],["让路由组件更方便的收到参数",{"2":{"1483":1}}],["让setup中的逻辑更清楚易懂",{"2":{"1471":1}}],["让相关功能的代码更加有序的组织在一起",{"2":{"1449":1}}],["让数据更像正态分布",{"2":{"1183":1}}],["让你轻松打造强大功能",{"2":{"1538":1}}],["让你把宝贵的时间用在刀刃上",{"2":{"1176":1}}],["让你知道octave能用来做什么",{"2":{"1088":1}}],["让字符分类输出的结果100",{"2":{"1174":1}}],["让字符切分输出的结果100",{"2":{"1174":1}}],["让模型判断是否为行人",{"2":{"1172":1}}],["让每一台计算机处理数据集的一个子集",{"2":{"1169":1}}],["让用户们可多次登陆",{"2":{"1168":1}}],["让",{"2":{"1092":3,"1207":1}}],["让西洋棋程序自己跟自己下了上万盘棋",{"2":{"1059":1}}],["让我举一个例子吧",{"2":{"1178":1}}],["让我来给大家复习一下关于向量内积的知识",{"2":{"1145":1}}],["让我取这里的z=1",{"2":{"1143":1}}],["让我告诉你它在",{"2":{"1111":1}}],["让我解释一下是怎么回事",{"2":{"1093":1}}],["让我用一个更复杂的命令",{"2":{"1091":1}}],["让我进一步阐述这个过程",{"2":{"1067":1}}],["让我知道这四个",{"2":{"1059":1}}],["让我推荐机器学习学生毕业的人远远多于机器学习的毕业生",{"2":{"1058":1}}],["让我们开始讨论推荐系统问题形式化",{"2":{"1187":1}}],["让我们谈谈参数拟合或参数估计问题",{"2":{"1185":1}}],["让我们谈论降维是什么",{"2":{"1156":1}}],["让我们假定我们想要一个学习算法来帮助我们",{"2":{"1168":1}}],["让我们假设层xj的输入也具有零均值和方差γ2",{"2":{"247":1}}],["让我们假设该分布具有零均值和方差σ2",{"2":{"247":1}}],["让我们看一下示意图",{"2":{"1145":1}}],["让我们看看逻辑运算",{"2":{"1088":1}}],["让我们看看fashion",{"2":{"837":1}}],["让我们看看模型描述中的前几行",{"2":{"821":1}}],["让我们看看paddle",{"2":{"821":1}}],["让我们看看save的实际功能",{"2":{"821":1}}],["让我们看看export的实际功能",{"2":{"821":1}}],["让我们看看如何通过将sequential替换为hybridsequential来解决代码中这个瓶颈",{"2":{"819":1}}],["让我们看看按顺序",{"2":{"792":1}}],["让我们看看一个简单的策略",{"2":{"513":1}}],["让我们看看效果如何",{"2":{"351":1}}],["让我们看看某些没有非线性的全连接层输出",{"2":{"247":1}}],["让我们看看这条红色直线的斜率",{"2":{"1068":1}}],["让我们看看这在实践中是如何运作的",{"2":{"552":1}}],["让我们看看这在实践中意味着什么",{"2":{"351":1}}],["让我们看看这样一个网络的细节",{"2":{"521":1}}],["让我们看看这些原则是如何转化为数学表示的",{"2":{"152":1}}],["让我们看看这对gt的统计属性有什么影响",{"2":{"78":1}}],["让我们看看",{"2":{"137":1,"208":1,"433":1,"837":1}}],["让我们看看指数衰减在实践中是什么样子",{"2":{"114":1}}],["让我们看看当我们最小化函数f",{"2":{"95":1}}],["让我们看看当降低动量参数时会发生什么",{"2":{"88":1}}],["让我们看看它到底是什么样子",{"2":{"157":1}}],["让我们看看它在实验中是如何运作的",{"2":{"91":1}}],["让我们看看它们各自的操作速度是多少",{"2":{"77":1}}],["让我们看看在这个新函数上执行梯度下降时会发生什么",{"2":{"87":1}}],["让我们看看在学习率稍小的情况下它是如何生效的",{"2":{"59":1}}],["让我们看看实践中会发生什么",{"2":{"59":1}}],["让我们看看其他问题",{"2":{"59":1}}],["让我们尝试在代价项的第一项为0的情形下理解该优化问题",{"2":{"1144":1}}],["让我们尝试使用一个阶数过高的多项式来训练模型",{"2":{"266":1}}],["让我们一起讨论一下这个问题",{"2":{"1141":1}}],["让我们有更多的垃圾邮件和非垃圾邮件的样本",{"2":{"1137":1}}],["让我们再回去从直观的角度看看优化目标",{"2":{"1143":1}}],["让我们再次回到最开始的例子",{"2":{"1135":1}}],["让我们再看看线性函数拟合",{"2":{"265":1}}],["让我们打开这个文件",{"2":{"1092":1}}],["让我们打印数据迭代器的第一个小批量",{"2":{"777":1}}],["让我们打印出0",{"2":{"399":1}}],["让我们设置a等于一个5×5的magic方阵",{"2":{"1091":1}}],["让我们设置y2",{"2":{"1091":1}}],["让我们设置许多缩放比",{"2":{"848":1}}],["让我们把这些概念应用到到线性回归和逻辑回归中去",{"2":{"1115":1}}],["让我们把",{"2":{"1089":1,"1090":1}}],["让我们回车",{"2":{"1089":1}}],["让我们回顾一下在分布式架构中数据并行的训练方法",{"2":{"841":1}}],["让我们回顾一下嵌入层是如何工作的",{"2":{"761":1}}],["让我们回顾一下",{"2":{"270":1}}],["让我们进行500组实验",{"2":{"1026":1}}],["让我们进一步假设输入图像的高度和宽度都是40像素",{"2":{"938":1}}],["让我们熟悉一下导数的几个等价符号",{"2":{"981":1}}],["让我们做一个实验",{"2":{"981":1}}],["让我们暂时忽略通道",{"2":{"968":1}}],["让我们展示10幅带有真实边界框的图像",{"2":{"933":1}}],["让我们考虑",{"2":{"912":1}}],["让我们考虑一下x=",{"2":{"57":1}}],["让我们以这种方法而只需将其插入到异常检测算法",{"2":{"1185":1}}],["让我们以valid",{"2":{"890":1}}],["让我们以跳元模型为例来思考word2vec设计",{"2":{"788":1}}],["让我们根据图像中的锚框和真实边界框的位置来分析下面返回的类别标签",{"2":{"853":1}}],["让我们定义一个矩阵x∈rna×nb",{"2":{"851":1}}],["让我们定义一个简单的方法",{"2":{"68":1}}],["让我们修改输出精度",{"2":{"847":1}}],["让我们为一些样例输入打印此skip",{"2":{"763":1}}],["让我们为新闻文章设计一个搜索引擎算法",{"2":{"662":1}}],["让我们通过一些例子来获取一些直观的感受",{"2":{"1065":1}}],["让我们通过一个例子来开始",{"2":{"1063":1}}],["让我们通过假设条件独立性来计算出应用bayes定理的必要概率",{"2":{"1035":1}}],["让我们通过具体案例演示微调",{"2":{"871":1}}],["让我们通过在gpu上计算",{"2":{"797":1}}],["让我们通过调用d2l",{"2":{"760":1}}],["让我们通过实例化",{"2":{"560":1}}],["让我们使用基于随机左右翻转的图像增广来",{"2":{"883":1}}],["让我们使用图像增广来训练模型",{"2":{"882":1}}],["让我们使用",{"2":{"827":1}}],["让我们使用一个比",{"2":{"826":1}}],["让我们使用一个小批量的两个样本来测试此函数",{"2":{"776":1}}],["让我们使用加载的词向量来验证",{"2":{"751":1}}],["让我们使用训练好的模型对两个简单的句子进行情感预测",{"2":{"715":1}}],["让我们将矩阵a用它的行向量表示",{"2":{"998":1}}],["让我们将预训练词向量应用到词的相似性和类比任务中",{"2":{"747":1}}],["让我们将多重集ci中的元素j的重数表示为xij",{"2":{"742":1}}],["让我们将重置门rt",{"2":{"541":1}}],["让我们首先看看如何使用矩阵乘法来实现卷积",{"2":{"970":1}}],["让我们首先回顾",{"2":{"741":1}}],["让我们首先调用内置的初始化器",{"2":{"435":1}}],["让我们创建一个实例并初始化它的参数",{"2":{"734":1}}],["让我们创建一个textcnn实例",{"2":{"702":1}}],["让我们构造一个具有两个隐藏层的双向循环神经网络来表示单个文本以进行情感分析",{"2":{"713":1}}],["让我们计算如果测试出来呈阳性",{"2":{"1035":1}}],["让我们计算梯度",{"2":{"977":1}}],["让我们计算",{"2":{"709":1}}],["让我们绘制评论词元长度的直方图",{"2":{"693":1}}],["让我们绘制一些函数并检查哪些函数满足要求",{"2":{"41":1}}],["让我们读取并打印第一个小批量样本",{"2":{"590":1}}],["让我们聚焦于神经网络局部",{"2":{"501":1}}],["让我们先考虑单变量函数",{"2":{"984":1}}],["让我们先读取一张图像",{"2":{"912":1}}],["让我们先定义一个度量时间的类",{"2":{"820":1}}],["让我们先来说明这个性质",{"2":{"730":1}}],["让我们先看看一维卷积是如何工作的",{"2":{"699":1}}],["让我们先迂回到概率图模型",{"2":{"518":1}}],["让我们先从数学上了解一下",{"2":{"478":1}}],["让我们先在下面的positionalencoding类中实现它",{"2":{"398":1}}],["让我们来试试用honey",{"2":{"1137":1}}],["让我们来从这些房子的数据中多找点特征吧",{"2":{"1129":1}}],["让我们来说说函数",{"2":{"1092":1}}],["让我们来说明如何以单词",{"2":{"756":1}}],["让我们来谈谈更多的操作",{"2":{"1090":1}}],["让我们来回顾一下训练神经网络时出现的一些实际挑战",{"2":{"467":1}}],["让我们来验证一下",{"2":{"442":1}}],["让我们来看下面的用户评分数据",{"2":{"1192":1}}],["让我们来看这样一个图",{"2":{"1154":1}}],["让我们来看一看我们在什么情况下应该怎样选择",{"2":{"1135":1}}],["让我们来看一看只有单隐藏层的多层感知机",{"2":{"339":1}}],["让我们来看一个更为复杂的例子",{"2":{"1093":1}}],["让我们来看一个c++",{"2":{"1093":1}}],["让我们来看一些例子",{"2":{"1093":1}}],["让我们来看一组数据",{"2":{"1060":1}}],["让我们来看看怎样能用这三步",{"2":{"1093":1}}],["让我们来看看向量和矩阵",{"2":{"1088":1}}],["让我们来看看saved",{"2":{"821":1}}],["让我们来看看它们的实现",{"2":{"771":1}}],["让我们来看看从第一个批量规范化层中学到的",{"2":{"473":1}}],["让我们来看看动量法在实验中是如何运作的",{"2":{"90":1}}],["让我们来看看批量梯度下降的优化是如何进行的",{"2":{"80":1}}],["让我们来看看如果a太小或a太大会出现什么情况",{"2":{"1068":1}}],["让我们来看看如果使用默认设置",{"2":{"67":1}}],["让我们来看看如何从数据中有效地生成小批量",{"2":{"79":1}}],["让我们来看看这些操作在实践中的效率如何",{"2":{"77":1}}],["让我们来看看f¯",{"2":{"26":1}}],["让我们来看看最小化f",{"2":{"26":1}}],["让我们实例化一个多层感知机",{"2":{"418":1}}],["让我们实现自定义版本的全连接层",{"2":{"414":1}}],["让我们向该层提供一些数据",{"2":{"413":1}}],["让我们在numpy和飞桨张量中都这样做",{"2":{"790":1}}],["让我们在numpy和pytorch张量中都这样做",{"2":{"790":1}}],["让我们在numpy和mxnet",{"2":{"790":1}}],["让我们在接下来的seq2seqattentiondecoder类中",{"2":{"375":1}}],["让我们在实践中尝试一下",{"2":{"350":1}}],["让我们在一系列值上绘制它的行为",{"2":{"68":1}}],["让我们讨论如何度量语言模型的质量",{"2":{"342":1}}],["让我们检查一下使用随机抽样方法的结果",{"2":{"335":1}}],["让我们",{"2":{"326":1,"332":1,"333":1,"335":1,"351":1,"363":1,"409":1,"451":1,"502":1,"566":1,"573":1,"932":1,"961":1}}],["让我们从最大化文本序列中所有这些事件的联合概率开始训练词嵌入",{"2":{"708":1}}],["让我们从熟悉的多层感知机开始尝试一下",{"2":{"442":1}}],["让我们从基本概率规则开始",{"2":{"316":1}}],["让我们从简单的一维梯度下降开始",{"2":{"53":1}}],["让我们仔细看看sigmoid函数为什么会导致梯度消失",{"2":{"242":1}}],["让我们直观地知道最好的模型有超出简单的模型多少",{"2":{"210":1}}],["让我们用这些想法",{"2":{"1185":1}}],["让我们用代码试一试",{"2":{"1026":1}}],["让我们用数学语言将这个模型形式化地描述出来",{"2":{"381":1}}],["让我们用",{"2":{"131":1,"863":1}}],["让我们用一些样本数据来验证这一点",{"2":{"122":1}}],["让我们详细地解读一下它的实际作用",{"2":{"122":1}}],["让我们详细写出这些方程式",{"2":{"107":1}}],["让我们专注于可以进行全面理论分析的学习率计划",{"2":{"114":1}}],["让我们图像化各种数值的γ在过去40个时间步长的权重",{"2":{"107":1}}],["让我们快速验证这个梯度是否计算正确",{"2":{"974":1}}],["让我们快速看一下算法在实验中的表现如何",{"2":{"88":1}}],["让我们快速证明一下",{"2":{"45":1}}],["让我们递归地将vt扩展到",{"2":{"86":1}}],["让我们接着上面正式开始讨论",{"2":{"27":1}}],["让他们做出合适的设计决策",{"2":{"800":1}}],["让完全自主如此具有挑战性的是",{"2":{"301":1}}],["让优化持续进行",{"2":{"71":1}}],["78",{"2":{"1401":1}}],["784",{"2":{"173":2,"176":2,"217":4,"225":2,"623":2,"630":4}}],["7=0",{"2":{"1107":1}}],["79米和1",{"2":{"1028":1}}],["79",{"2":{"959":1}}],["71",{"2":{"959":1}}],["71和0",{"2":{"959":1}}],["713",{"2":{"876":2}}],["7z后",{"2":{"889":1}}],["7z和test",{"2":{"889":1}}],["70",{"2":{"813":1}}],["700px",{"2":{"295":1}}],["768",{"2":{"734":4}}],["768个隐藏单元",{"2":{"726":1}}],["76e5be1548fd8222e5074cf0faae75edff8cf93f",{"2":{"79":4}}],["7b3820b35da691042e5d34c0971ac3edbd80d3f4",{"2":{"686":1}}],["75且宽高比为1的蓝色锚框很好地围绕着图像中的狗",{"2":{"848":1}}],["75",{"2":{"515":1,"565":1,"743":1,"775":2,"813":2,"848":6,"1223":1}}],["7×7卷积层",{"2":{"488":1}}],["7的",{"2":{"399":1}}],["777",{"2":{"1499":1}}],["77",{"2":{"101":2}}],["7",{"0":{"1069":1,"1086":1,"1094":1,"1103":1,"1112":1,"1114":1,"1115":1,"1116":1,"1117":1,"1126":1,"1135":1,"1162":1,"1184":1,"1290":1,"1324":1,"1349":1,"1386":1,"1394":1,"1418":1,"1459":1,"1479":1,"1494":1,"1503":1,"1509":1,"1510":1,"1514":1,"1517":1,"1520":1},"1":{"1291":1,"1292":1,"1293":1,"1419":1,"1420":1,"1421":1,"1422":1,"1423":1,"1510":1,"1511":2,"1512":2,"1513":2,"1514":1,"1515":2,"1516":2,"1517":1,"1518":2,"1519":2,"1520":1},"2":{"70":1,"107":1,"120":2,"126":1,"129":4,"146":3,"375":4,"409":4,"488":1,"508":4,"573":4,"616":4,"635":2,"648":1,"699":2,"736":3,"774":2,"834":3,"842":2,"854":3,"927":3,"1058":1,"1059":1,"1061":2,"1069":1,"1073":1,"1086":1,"1094":1,"1101":1,"1103":1,"1107":2,"1112":1,"1114":1,"1115":1,"1116":1,"1117":1,"1120":1,"1125":1,"1126":1,"1127":1,"1135":2,"1140":1,"1152":1,"1162":1,"1171":1,"1184":1,"1193":13,"1218":1}}],["单机容器运行",{"2":{"1394":1}}],["单机容器很好",{"2":{"1355":1}}],["单机多容器编排",{"2":{"1355":1}}],["单机环境下的多容器编排",{"2":{"1349":1}}],["单机",{"0":{"1205":1},"2":{"1205":1,"1210":1}}],["单键",{"2":{"1199":1}}],["单元中得到的激活项的",{"2":{"1122":1}}],["单元的值为0",{"2":{"559":1}}],["单层神经元",{"2":{"1101":1}}],["单位矩阵",{"2":{"1076":1}}],["单位是千美元",{"2":{"1060":1}}],["单位是平方英尺",{"2":{"1060":1}}],["单变量线性回归",{"0":{"1062":1},"1":{"1063":1,"1064":1,"1065":1,"1066":1,"1067":1,"1068":1,"1069":1,"1070":1},"2":{"1193":1}}],["单下划线",{"2":{"1006":1}}],["单发多框检测生成不同数量和不同大小的锚框",{"2":{"965":1}}],["单发多框检测生成不同大小的锚框",{"2":{"953":1}}],["单发多框检测是一种多尺度目标检测模型",{"2":{"965":1}}],["单发多框检测使用多尺度特征图来生成锚框并预测其类别和偏移量",{"2":{"956":1}}],["单发多框检测采用同样的方法来降低模型复杂度",{"2":{"954":1}}],["单发多框检测论文中选用了在分类层之前截断的vgg",{"2":{"953":1}}],["单发多框检测",{"0":{"952":1},"1":{"953":1,"954":1,"955":1,"956":1,"957":1,"958":1,"959":1,"960":1,"961":1,"962":1,"963":1,"964":1,"965":1,"966":1},"2":{"952":1}}],["单gpu上进行自动评估",{"2":{"829":2}}],["单一文本分类",{"2":{"733":1}}],["单数或质量",{"2":{"659":1}}],["单文本分类和文本对分类",{"2":{"663":1}}],["单文本分类将单个文本序列作为输入",{"2":{"657":1}}],["单文本分类",{"0":{"657":1}}],["单1x1卷积层",{"2":{"487":4}}],["单通道数据",{"2":{"461":1}}],["单独保存每个向量则会变得很麻烦",{"2":{"442":1}}],["单个神经网络",{"2":{"422":1}}],["单个gpu不足以处理可用于训练的大量数据",{"2":{"300":1}}],["单步预测效果不错",{"2":{"351":1}}],["单词的训练速度很慢",{"2":{"773":1}}],["单词的",{"2":{"772":1}}],["单词级词元化仍然是个好主意吗",{"2":{"571":1}}],["单词序列似乎也遵循齐普夫定律",{"2":{"318":1}}],["单词",{"2":{"318":1,"757":1}}],["单项式的阶数是幂的和",{"2":{"269":1}}],["单因子调度器",{"0":{"70":1}}],["单单一步就足以完美地收敛",{"2":{"59":1}}],["余弦相似度",{"2":{"781":1,"1154":1}}],["余弦调度器在某些计算机视觉问题中很受欢迎",{"2":{"74":1}}],["余弦调度器是",{"2":{"72":1}}],["余弦调度器",{"0":{"72":1}}],["余弦学习率调度在实践中的一些问题上运行效果很好",{"2":{"69":1}}],["余弦函数为非凸的",{"2":{"41":1}}],["策略",{"0":{"69":1},"1":{"70":1,"71":1,"72":1,"73":1},"2":{"319":1,"512":1,"1201":1}}],["之所以有如此大的差距",{"2":{"457":1}}],["之类的特征",{"2":{"209":1}}],["之后我们介绍了分类问题",{"2":{"1060":1}}],["之后将严格定义空间",{"2":{"989":1}}],["之后将介绍",{"2":{"137":1,"325":2}}],["之后用于创建锚框的四角坐标",{"2":{"848":3}}],["之后聚合结果向所有的gpu广播",{"2":{"838":1}}],["之后=",{"2":{"773":1}}],["之后的部分",{"2":{"512":1}}],["之后的每个模块在第一个残差块里将上一个模块的通道数翻倍",{"2":{"502":1}}],["之后是含5×5卷积层的第三条路径和含3×3最大汇聚层的第四条路径",{"2":{"488":1}}],["之后为常量",{"2":{"425":1}}],["之后输出的n×n矩阵乘以n×d矩阵",{"2":{"397":1}}],["之后",{"2":{"244":1,"619":1,"816":1,"851":1,"873":1,"959":1,"1121":1}}],["之后向下调整学习率",{"2":{"68":1}}],["之前提到",{"2":{"1169":1}}],["之前都计算一次代价",{"2":{"1167":1}}],["之前视频中说过",{"2":{"1145":1}}],["之前几节中",{"2":{"887":1}}],["之前几节我们学习了一些训练深度网络的基本工具和网络正则化的技术",{"2":{"205":1}}],["之前=",{"2":{"773":1}}],["之前",{"2":{"626":1,"821":1,"905":1}}],["之前在线性模型中",{"2":{"526":1}}],["之前首次介绍神经网络时",{"2":{"422":1}}],["之前的输出子序列y1",{"2":{"512":1}}],["之前的介绍中",{"2":{"429":1}}],["之前的单词",{"2":{"338":1}}],["之前的猫狗分类例子中",{"2":{"291":1}}],["之前我们构建的异常检测系统也使用了带标记的数据",{"2":{"1182":1}}],["之前我们在计算神经网络预测结果的时候我们采用了一种正向传播方法",{"2":{"1121":1}}],["之前我们也谈到了肿瘤分类问题的例子",{"2":{"1106":1}}],["之前我们已经看到过",{"2":{"1097":1}}],["之前我们已经介绍了一些基本的机器学习概念",{"2":{"421":1}}],["之前我们只添加了1个全连接层",{"2":{"225":1}}],["之前我们将softmax回归模型",{"2":{"135":1}}],["之前我们会理所当然地读取数据的小批量",{"2":{"78":1}}],["之前检测到的垂直边缘消失了",{"2":{"128":1}}],["之间相互通信",{"2":{"1500":1}}],["之间存在微妙的区别",{"2":{"1028":1}}],["之间存在权衡",{"2":{"82":1}}],["之间较大的差异将导致更大的损失",{"2":{"611":1}}],["之间呢",{"2":{"563":1}}],["之间进行按元素的凸组合就可以实现这个目标",{"2":{"542":1}}],["之间传输数据比计算慢得多",{"2":{"450":1}}],["之间分配的注意力权重",{"2":{"388":4}}],["之间的一个分数",{"2":{"1183":1}}],["之间的内积",{"2":{"1145":1}}],["之间的误差",{"2":{"1121":1}}],["之间的通信提供基础",{"2":{"1043":1}}],["之间的关系如下图所示",{"2":{"1109":1}}],["之间的关系相同",{"2":{"755":2}}],["之间的关系与",{"2":{"755":2}}],["之间的差异",{"2":{"647":1,"800":1}}],["之间的交互形成了注意力汇聚",{"2":{"385":1}}],["之间的分工大大简化了工作",{"2":{"300":1}}],["之间的联系",{"2":{"170":1}}],["之间的",{"2":{"156":1}}],["之间",{"2":{"72":1,"563":1,"880":1,"1086":1,"1106":1,"1140":1,"1148":1,"1166":1}}],["之外的点投影到集合中接近原始点",{"2":{"50":1}}],["甚至网页上的字体颜色和布局",{"2":{"1533":1}}],["甚至有时候是0",{"2":{"1182":1}}],["甚至有人可能会觉得",{"2":{"240":1}}],["甚至当你的数据不是线性可分的时候",{"2":{"1144":1}}],["甚至会比",{"2":{"1141":1}}],["甚至发散",{"2":{"1068":1}}],["甚至怎么存储这些特征都存在问题",{"2":{"1060":1}}],["甚至院系",{"2":{"1025":1}}],["甚至print",{"2":{"817":1}}],["甚至pcie通道也可以是可交换的",{"2":{"812":1}}],["甚至多个gpu",{"2":{"816":1}}],["甚至把它们作为通用gpu",{"2":{"457":1}}],["甚至不知道在哪里执行计算",{"2":{"447":1}}],["甚至没有足够的信息来确定模型应该包含多少参数",{"2":{"417":1}}],["甚至是打字速度等",{"2":{"1178":1}}],["甚至是更多",{"2":{"1141":1}}],["甚至是几个月去进行深入的研究",{"2":{"1137":1}}],["甚至是一串字符序列",{"2":{"360":1}}],["甚至是一个词元序列进行建模",{"2":{"316":1}}],["甚至是非参数化的最大汇聚层或平均汇聚层",{"2":{"356":1}}],["甚至预约理发师和提供电话支持对话",{"2":{"301":1}}],["甚至",{"2":{"299":1,"301":1}}],["甚至开发视频游戏的人工智能",{"2":{"298":1}}],["甚至像图像和音频这样复杂的非结构化数据",{"2":{"296":1}}],["甚至包含了一些社会偏见时",{"2":{"284":1}}],["甚至可能世界上使用最广泛的一种分类算法",{"2":{"1110":1}}],["甚至可能无法收敛",{"2":{"1068":1}}],["甚至可能发散",{"2":{"58":1}}],["甚至可以动态调整",{"2":{"180":1}}],["甚至超过小批量上的梯度平均值",{"2":{"86":1}}],["甚至矢量",{"2":{"78":1}}],["甚至在每个小批量",{"2":{"68":1}}],["慢慢开始学会使用这些命令",{"2":{"1089":1}}],["慢",{"2":{"66":1}}],["衰减速率同样很重要",{"2":{"66":1}}],["直升机飞行员",{"2":{"1156":1}}],["直方图交集核函数",{"2":{"1148":1}}],["直至遍历完整个数据集",{"2":{"600":1}}],["直接修改",{"2":{"1491":1}}],["直接通过名字跳转",{"2":{"1478":1}}],["直接写数据名",{"2":{"1463":1}}],["直接写数据名即可",{"2":{"1462":1}}],["直接使用即可",{"2":{"1455":1}}],["直接使用传入的移动平均所得的均值和方差",{"2":{"472":3}}],["直接",{"2":{"1323":1}}],["直接运行",{"2":{"1302":1}}],["直接赋值即可创建变量",{"2":{"1214":1}}],["直接键入clear",{"2":{"1089":1}}],["直接打一撇",{"2":{"1077":1}}],["直接内存访问允许cpu以外的设备直接向内存写入",{"2":{"815":1}}],["直接与专用硅片上的gpu连接",{"2":{"802":1}}],["直接将神经网络与其他机器学习方法进行比较也许不公平",{"2":{"454":1}}],["直接读取文件中存储的参数",{"2":{"442":1}}],["直径和质量来描述",{"2":{"296":1}}],["直观地对比三种模型中的词元频率",{"2":{"318":1}}],["直观地说",{"2":{"66":1,"121":1,"209":1,"467":2,"475":1,"773":1,"849":1,"912":1}}],["直观上可以想象在靠近输入的底层",{"2":{"158":1}}],["直观来说",{"2":{"78":1}}],["直到找到可以使得比例小于1",{"2":{"1160":1}}],["直到倒数第二层",{"2":{"1121":1}}],["直到n+1",{"2":{"1093":1}}],["直到i",{"2":{"1092":1}}],["直到数值2",{"2":{"1088":1}}],["直到增加到2",{"2":{"1088":1}}],["直到他们不再是多余的为止",{"2":{"1086":1}}],["直到最后一层的hθ",{"2":{"1121":1}}],["直到最终移动幅度非常小",{"2":{"1068":1}}],["直到最近",{"2":{"301":1}}],["直到你发现实际上离最低点越来越远",{"2":{"1068":1}}],["直到你接近局部最低点的位置",{"2":{"1067":1}}],["直到l中的所有预测边界框都曾被用作基准",{"2":{"854":1}}],["直到丢弃掉矩阵x中nb列中的所有元素",{"2":{"851":1}}],["直到fancy",{"2":{"816":1}}],["直到计算出变量z为止",{"2":{"791":1}}],["直到连结长度达到maxini+mi",{"2":{"776":1}}],["直到满足max",{"2":{"687":1}}],["直到它们的长度变为num",{"2":{"668":1}}],["直到它满足条件为止",{"2":{"425":1}}],["直到完成",{"2":{"605":1}}],["直到这些参数足够拟合我们的数据",{"2":{"601":1}}],["直到其长度达到num",{"2":{"568":1}}],["直到预测序列中出现特定的序列结束词元",{"2":{"512":1}}],["直到该数字达到512",{"2":{"508":1}}],["直到全局平均汇聚层聚集所有特征",{"2":{"502":1}}],["直到所有形状都已知为止",{"2":{"418":1}}],["直到人们忘记了这部电影曾经获得的奖项",{"2":{"345":1}}],["直到2005年才稍有起色",{"2":{"299":1}}],["直到模型学会从情况到行动的映射",{"2":{"296":1}}],["直到模型在任务中的表现令人满意",{"2":{"282":1}}],["直到每一篇文章都有严格的人工审核",{"2":{"292":1}}],["直到生成最后的输出",{"2":{"231":1}}],["直到反向传播完成",{"2":{"165":1}}],["直到权重向量的分布达到一个驻点",{"2":{"71":1}}],["直到停止条件达成",{"2":{"54":1}}],["训练的模型将能够非常完美地适应较少的训练数据",{"2":{"1134":1}}],["训练的计算成本取决于词表大小的对数",{"2":{"710":1}}],["训练的计算量与每一步的噪声词数成线性关系",{"2":{"710":1}}],["训练出如此强大的自动驾驶汽车",{"2":{"1127":1}}],["训练精确度的和中的示例数",{"2":{"963":3}}],["训练精确度的和",{"2":{"963":3}}],["训练线性回归模型来预测真实边界框",{"2":{"937":1}}],["训练线性回归模型曾经是一个不容易的作业问题",{"2":{"300":1}}],["训练多个支持向量机对目标分类",{"2":{"937":1}}],["训练多层感知机模型时",{"2":{"255":1}}],["训练代码与前几章的实现非常相似",{"2":{"828":1}}],["训练硬件和推断硬件在性能和价格方面有不同的优点",{"2":{"814":1}}],["训练时间为3个月",{"2":{"800":1}}],["训练时间为1周",{"2":{"800":1}}],["训练连续词袋模型与训练跳元模型几乎是一样的",{"2":{"786":1}}],["训练glove是为了尽量降低以下损失函数",{"2":{"743":1}}],["训练bert可能需要很长时间",{"2":{"726":1}}],["训练softmax回归循环模型与训练线性回归模型非常相似",{"2":{"637":1}}],["训练函数需要分配gpu并将所有模型参数复制到所有设备",{"2":{"837":1}}],["训练函数",{"0":{"894":1,"906":1},"2":{"635":1}}],["训练函数train",{"2":{"137":1}}],["训练中",{"2":{"579":1}}],["训练序列到序列模型",{"2":{"576":4}}],["训练长短期记忆网络",{"2":{"561":1}}],["训练期间需要多少显存",{"2":{"498":1}}],["训练nin与训练alexnet",{"2":{"496":1}}],["训练模式还与预测模式的bn处理不同",{"2":{"472":1}}],["训练模式下用当前的均值和方差做标准化",{"2":{"472":1}}],["训练模式下",{"2":{"472":2}}],["训练模式",{"2":{"467":1}}],["训练模型的准确性可能无法满足实际要求",{"2":{"869":1}}],["训练模型10个迭代周期",{"2":{"635":1}}],["训练模型时要对数据集进行遍历",{"2":{"600":1}}],["训练模型一个迭代周期",{"2":{"335":2,"635":4}}],["训练模型",{"0":{"483":1,"489":1,"496":1,"503":1,"509":1,"569":1,"927":1,"960":1,"963":1},"1":{"961":1,"962":1,"963":1},"2":{"80":4,"335":4,"350":1,"523":3,"635":1,"883":1,"927":1}}],["训练深层网络",{"0":{"467":1}}],["训练深层神经网络是十分困难的",{"2":{"466":1}}],["训练深度网络的常见策略之一是保持学习率为一组分段的常量",{"2":{"71":1}}],["训练卷积神经网络就更昂贵",{"2":{"463":1}}],["训练alexnet",{"0":{"463":1}}],["训练imagenet模型",{"2":{"462":1}}],["训练可能需要数百个迭代轮数",{"2":{"457":1}}],["训练阶段代码实现定义如下",{"2":{"767":1}}],["训练阶段",{"2":{"408":4}}],["训练这个新模型并可视化其注意力权重",{"2":{"394":1}}],["训练完带参数的注意力汇聚模型后可以发现",{"2":{"392":1}}],["训练带参数的注意力汇聚模型",{"2":{"392":1}}],["训练样本",{"2":{"890":1,"1069":1,"1146":1}}],["训练样本的输出",{"2":{"386":4}}],["训练样本的数量",{"2":{"254":1}}],["训练样本数",{"2":{"386":3}}],["训练结束后",{"2":{"376":1,"409":1,"546":1}}],["训练要比没有注意力机制的",{"2":{"376":1}}],["训练与预测",{"0":{"326":1}}],["训练该模型需要对这些参数进行梯度计算",{"2":{"312":1}}],["训练网络一个迭代周期",{"2":{"335":2}}],["训练网络",{"2":{"299":1}}],["训练损失总和",{"2":{"576":3,"635":4}}],["训练损失求和",{"2":{"576":1}}],["训练损失仍然很高",{"2":{"265":1}}],["训练损失之和",{"2":{"137":3,"335":4}}],["训练误差就会很低了",{"2":{"1141":1}}],["训练误差和验证误差都很严重",{"2":{"258":1}}],["训练误差和泛化误差",{"0":{"252":1},"1":{"253":1,"254":1}}],["训练误差和泛化误差通常不同",{"2":{"99":1}}],["训练误差",{"2":{"252":1}}],["训练过程代码与我们从零开始实现时所做的非常相似",{"2":{"595":1}}],["训练过程通常包含如下步骤",{"2":{"282":1}}],["训练过程",{"2":{"225":1,"605":1}}],["训练log",{"2":{"211":1,"213":1}}],["训练",{"0":{"210":1,"221":1,"335":1,"350":1,"376":1,"392":1,"409":1,"529":1,"546":1,"560":1,"576":1,"595":1,"605":1,"626":1,"635":1,"764":1,"784":1,"786":1,"828":1,"837":1,"865":1},"1":{"765":1,"766":1,"767":1},"2":{"688":1,"980":2}}],["训练集较小时也同样适用",{"2":{"1184":1}}],["训练集的方差为",{"2":{"1160":1}}],["训练集误差不断增加",{"2":{"1133":1}}],["训练集误差较小",{"2":{"1133":1}}],["训练集误差和交叉验证集误差近似时",{"2":{"1132":1}}],["训练集",{"2":{"1112":1}}],["训练集对应的正确答案",{"2":{"1061":1}}],["训练集数目",{"2":{"692":1}}],["训练集约有550000对",{"2":{"667":1}}],["训练集和测试集分别包含60000和10000张图像",{"2":{"582":1}}],["训练集和测试集并不来自同一个分布",{"2":{"202":1}}],["训练集损失会朝哪个方向移动",{"2":{"287":1}}],["训练集q",{"2":{"191":1}}],["训练集中没有这样的数据",{"2":{"188":1}}],["训练集由真实照片组成",{"2":{"181":1}}],["训练一个计算广告模型",{"2":{"187":1}}],["训练数据集中样本最少的类别中的样本数",{"2":{"890":1}}],["训练数据集中词的概率可以根据给定词的相对词频来计算",{"2":{"316":1}}],["训练数据集中的样本越少",{"2":{"260":1}}],["训练数据集用于拟合模型参数",{"2":{"286":1}}],["训练数据集包括1460个样本",{"2":{"208":1}}],["训练数据集的最低经验风险可能与最低风险",{"2":{"99":1}}],["训练数据",{"2":{"190":1}}],["训练数据包括",{"2":{"181":1}}],["训练和验证模型",{"0":{"895":1,"907":1}}],["训练和评估模型",{"0":{"678":1,"681":1,"704":1,"715":1},"1":{"679":1,"680":1,"681":1,"682":1}}],["训练和评估lenet",{"2":{"137":1}}],["训练和预测的工作方式与",{"2":{"546":1}}],["训练和预测",{"2":{"335":4}}],["训练和部署的",{"2":{"301":1}}],["训练和测试深度学习模型",{"2":{"440":1}}],["训练和测试数据集大小",{"2":{"262":1}}],["训练和测试",{"0":{"175":1}}],["训练比预测需要更多的内存",{"2":{"166":1}}],["训练神经网络的一些关键技巧仍然缺失",{"2":{"454":1}}],["训练神经网络",{"0":{"165":1},"2":{"1126":1}}],["训练准确度",{"2":{"883":3}}],["训练准确度总和",{"2":{"635":4}}],["训练准确度将如何继续提高",{"2":{"67":1}}],["训练准确率之和",{"2":{"137":3}}],["训练就会需要过长时间",{"2":{"66":1}}],["训练复杂的深度学习模型可能需要数小时",{"2":{"65":1}}],["正则表达式处理",{"2":{"1263":1}}],["正则化项可调整为",{"2":{"1147":1}}],["正则化项为",{"2":{"162":1}}],["正则化和偏差",{"0":{"1133":1},"2":{"1193":1}}],["正则化的那一项只是排除了每一层θ0后",{"2":{"1120":1}}],["正则化的逻辑回归模型",{"0":{"1117":1},"2":{"1193":1}}],["正则化线性回归的梯度下降算法的变化在于",{"2":{"1116":1}}],["正则化线性回归的代价函数为",{"2":{"1116":1}}],["正则化线性回归",{"0":{"1116":1},"2":{"1193":1}}],["正则化",{"0":{"1113":1},"1":{"1114":1,"1115":1,"1116":1,"1117":1},"2":{"1114":1,"1193":1}}],["正则化是处理过拟合的常用方法",{"2":{"279":1}}],["正样本的数量很少",{"2":{"1182":1}}],["正因如此",{"2":{"1098":1,"1176":1}}],["正因为这样",{"2":{"1088":1}}],["正规方程及不可逆性",{"0":{"1086":1},"2":{"1193":1}}],["正规方程的python实现",{"2":{"1085":1}}],["正规方程方法是不能用的",{"2":{"1085":1}}],["正规方程方法是更好的解决方案",{"2":{"1085":1}}],["正规方程写作",{"2":{"1085":1}}],["正规方程是通过求解下面的方程来找出使得代价函数最小的参数的",{"2":{"1085":1}}],["正规方程",{"0":{"1085":1},"2":{"1085":1,"1193":1}}],["正逐步从",{"2":{"1051":1}}],["正类",{"2":{"872":1}}],["正在逐步取代传统的虚拟机和单体架构",{"2":{"1352":1}}],["正在逐步重塑我们与机器的交互方式",{"2":{"1056":1}}],["正在尝试将",{"2":{"1054":1}}],["正在推动",{"2":{"1051":1}}],["正在为我们表演",{"2":{"665":1}}],["正在从",{"2":{"206":1}}],["正态分布",{"2":{"616":1,"1006":1,"1017":1}}],["正态分布和线性回归之间的关系很密切",{"2":{"616":1}}],["正态分布与平方损失",{"0":{"616":1}}],["正向代理",{"2":{"1361":1}}],["正向代理与反向代理",{"0":{"1361":1}}],["正向传播",{"2":{"429":1}}],["正向估计通常比反向估计更容易",{"2":{"352":1}}],["正是那些高次项导致了过拟合的产生",{"2":{"1115":1}}],["正是由于这个原因和其他一些我们后面会讨论到的技术因素",{"2":{"1098":1}}],["正是由于这个基于批量统计的标准化",{"2":{"467":1}}],["正是因为这一点",{"2":{"1088":1}}],["正是因为这些矩阵和向量提供了一种有效的方式来组织大量的数据",{"2":{"1070":1}}],["正是因为他们有良好的学习算法",{"2":{"1058":1}}],["正是在这一背景下应运而生",{"2":{"1049":1}}],["正是基于这种设计将输入序列的编码信息送入到解码器中来生成输出序列的",{"2":{"572":1}}],["正是具有",{"2":{"379":1}}],["正是本着这种精神",{"2":{"302":1}}],["正是出于这个原因",{"2":{"65":1}}],["正式称为类",{"2":{"291":1}}],["正常",{"0":{"264":1}}],["正面比例明显偏离12的可能性将会降低",{"2":{"252":1}}],["正面",{"2":{"252":1}}],["正确否定",{"2":{"1139":1}}],["正确肯定",{"2":{"1139":1}}],["正确答案",{"2":{"1060":2}}],["正确的输出结果",{"2":{"1174":1}}],["正确的答案",{"2":{"1063":1}}],["正确的",{"2":{"1048":1}}],["正确的驾驶需要感知",{"2":{"301":1}}],["正确预测数",{"2":{"634":3}}],["正确预测的数量",{"2":{"137":3,"827":1}}],["正确地标记文献很重要",{"2":{"292":1}}],["正确",{"2":{"179":1,"1122":1,"1165":1,"1174":3}}],["正如向量将标量从零阶推广到一阶",{"2":{"992":1}}],["正如从上面代码中所看到的",{"2":{"848":1}}],["正如从代码中所看到的",{"2":{"407":1,"508":1}}],["正如从图中所看到",{"2":{"235":1}}],["正如所看到的",{"2":{"399":1,"872":1}}],["正如所见到的",{"2":{"404":1}}],["正如所见",{"2":{"88":1}}],["正如上述代码",{"2":{"631":1}}],["正如上文提到的",{"2":{"574":1}}],["正如上面提到的",{"2":{"368":1}}],["正如上图所示",{"2":{"367":1}}],["正如上图",{"2":{"242":1}}],["正如刚才所说",{"2":{"312":1}}],["正如",{"2":{"231":1,"920":1,"973":1}}],["正如事实证明的那样",{"2":{"186":1}}],["正如预期的那样",{"2":{"114":1,"773":1}}],["正如我们之前开发的学习算法",{"2":{"1143":1}}],["正如我们之后将看到的",{"2":{"983":1}}],["正如我们将在后续章节中看到的",{"2":{"642":1}}],["正如我们前面提到的",{"2":{"471":1}}],["正如我们所看到你只有10个样本",{"2":{"1086":1}}],["正如我们所看到的",{"2":{"113":1,"318":1,"956":1,"1035":1,"1156":1}}],["正如我们所看到的那样",{"2":{"103":2}}],["正如我们所提到的",{"2":{"956":1}}],["正如我们所料",{"2":{"351":1,"693":1}}],["正如我们所讨论的",{"2":{"189":1}}],["正如我们向他们解释的那样",{"2":{"185":1}}],["正如我们在构造nn",{"2":{"592":2}}],["正如我们在",{"2":{"58":1,"121":1,"140":1,"170":1,"312":1,"532":1,"572":1,"604":1,"663":1,"742":1}}],["正如人们所期望的",{"2":{"86":1}}],["正如在从零开始实现中一样",{"2":{"595":1}}],["正如在本节前面所述",{"2":{"408":1}}],["正如在本节开头所述",{"2":{"406":1}}],["正如在",{"2":{"26":1,"397":1,"656":1,"685":1,"686":1,"980":1}}],["咒语",{"2":{"65":1}}],["都能提供优秀的开发体验和工程能力",{"2":{"1531":1}}],["都能监听响应式数据的变化",{"2":{"1467":1}}],["都能一致运行",{"2":{"1339":1}}],["都能成为你可靠的工具",{"2":{"1305":1}}],["都能用",{"2":{"1302":1}}],["都能帮你轻松搞定",{"2":{"1301":1}}],["都能够相当准确地回答口头问题",{"2":{"301":1}}],["都保留下来了",{"2":{"1160":1}}],["都具有相似的性能",{"2":{"1141":1}}],["都已经被公认是比较领先的",{"2":{"1141":1}}],["都计算一个近似的梯度值",{"2":{"1124":1}}],["都选择最高可能性的输出变量",{"2":{"1112":1}}],["都等于",{"2":{"1106":1}}],["都为369",{"2":{"1090":1}}],["都在广泛使用",{"2":{"1303":1}}],["都在聊天",{"2":{"1061":1}}],["都在致力于回答这个问题",{"2":{"270":1}}],["都应用了机器学习",{"2":{"1058":1}}],["都应该和物体的位置无关",{"2":{"152":1}}],["都致力于概率学的工作",{"2":{"1025":1}}],["都与numpy的ndarray类似",{"2":{"1016":1}}],["都与假设中的",{"2":{"675":1}}],["都有相同的可能发生",{"2":{"1026":1}}],["都有bij=aji",{"2":{"992":1}}],["都有∇x∥x∥f2=2x",{"2":{"983":1}}],["都有∇xx⊤ax=",{"2":{"983":1}}],["都有∇xx⊤a=a",{"2":{"983":1}}],["都有∇xax=a⊤",{"2":{"983":1}}],["都用于训练模型和对测试集进行分类",{"2":{"908":1}}],["都围绕着同一目标",{"2":{"854":1}}],["都不重要",{"2":{"1112":1}}],["都不相关的单词wk",{"2":{"744":1}}],["都不会自动提高",{"2":{"281":1}}],["都使用4头注意力",{"2":{"409":1}}],["都要求满足sublayer",{"2":{"404":1}}],["都会执行",{"2":{"1236":1}}],["都会为总代价函数",{"2":{"1143":1}}],["都会趋近于0",{"2":{"1115":1}}],["都会趋近于",{"2":{"1115":1}}],["都会在一定程度上减小",{"2":{"1115":1}}],["都会被忽略",{"2":{"821":1}}],["都会被ct",{"2":{"374":1}}],["都会返回一小批量样本",{"2":{"694":1}}],["都会遇到这些组件",{"2":{"283":1}}],["都依赖于同一迭代周期中前面所有的小批量数据",{"2":{"335":1}}],["都将作为自然语言",{"2":{"315":1}}],["都将无法对球施加任何力",{"2":{"48":1}}],["都是新值",{"2":{"1463":1}}],["都是一种你几乎绕不开的语言",{"2":{"1295":1}}],["都是一个合理的选择",{"2":{"1064":1}}],["都是你的无标签数据",{"2":{"1178":1}}],["都是掷出骰子的有效事件",{"2":{"1027":1}}],["都是标量值",{"2":{"989":1}}],["都是张量格式",{"2":{"853":1}}],["都是形状为n×q的矩阵",{"2":{"644":1}}],["都是可微的",{"2":{"984":1}}],["都是可调节的超参数",{"2":{"635":1}}],["都是可以在硬件上并行化的操作",{"2":{"457":1}}],["都是第l个隐藏层的模型参数",{"2":{"527":1}}],["都是由一些状态转移概率p",{"2":{"519":1}}],["都是深度学习优于传统机器学习方法的问题",{"2":{"302":1}}],["都是重要的开放性研究问题",{"2":{"294":1}}],["都是概念偏移的日常映射",{"2":{"183":1}}],["都被随机设置",{"2":{"282":1}}],["都可能会出现少量的观测误差",{"2":{"610":1}}],["都可能会知道存在着一系列此类",{"2":{"65":1}}],["都可以用来计算θ和x",{"2":{"1145":1}}],["都可以构造多项式来解决",{"2":{"1117":1}}],["都可以被升级为按元素运算",{"2":{"1018":1}}],["都可以线性投影到",{"2":{"400":1}}],["都可以追究到这种方式",{"2":{"179":1}}],["都需要将一行和一列向量复制到cpu中",{"2":{"77":1}}],["本站怎么逛",{"0":{"1548":1}}],["本质是一个函数",{"2":{"1471":1}}],["本质上",{"2":{"913":1}}],["本质上是输出决定的",{"2":{"290":1}}],["本地单机集群",{"2":{"1393":1}}],["本地存储等",{"2":{"1386":1}}],["本地开发",{"2":{"1349":1}}],["本地",{"2":{"1340":1}}],["本地仓库的副本",{"2":{"1324":1}}],["本地仓库",{"2":{"1319":2}}],["本地只有工作拷贝",{"2":{"1318":1}}],["本地数据源",{"2":{"1042":1}}],["本周以一个垃圾邮件分类器算法为例进行讨论",{"2":{"1137":1}}],["本视频将快速地介绍一系列的命令",{"2":{"1088":1}}],["本讲义都用",{"2":{"1076":1}}],["本课中",{"2":{"1059":2}}],["本小节中的",{"2":{"993":1,"994":1}}],["本例只想求偏导数的和",{"2":{"975":1}}],["本次视频我们更深入研究一下",{"2":{"1068":1}}],["本次视频中",{"2":{"1061":1}}],["本次比赛的数据集是imagenet数据集的子集",{"2":{"905":1}}],["本次",{"2":{"899":1}}],["本文汇总了",{"2":{"1237":1}}],["本文将从",{"2":{"1194":1}}],["本文选择了一个多层门控循环单元来实现编码器",{"2":{"573":1}}],["本文的一个观点是",{"2":{"486":1}}],["本书中所说的张量均指的是张量类的实例",{"2":{"1016":1}}],["本书中我们用到一种名为梯度下降",{"2":{"613":1}}],["本书不可能介绍每一个tensorflow函数和类",{"2":{"1005":1}}],["本书不可能介绍每一个pytorch函数和类",{"2":{"1005":1}}],["本书不可能介绍每一个mxnet函数和类",{"2":{"1005":1}}],["本书用r表示所有",{"2":{"989":1}}],["本书采用了数学表示法",{"2":{"989":1}}],["本书对读者数学基础无过分要求",{"2":{"987":1}}],["本书主要关注的是命令式编程",{"2":{"816":1}}],["本书并不打算全面涵盖所有此类应用",{"2":{"663":1}}],["本书附录中关于信息论的一节",{"2":{"648":1}}],["本书将在后面介绍更多数学知识",{"2":{"1002":1}}],["本书将尝试坚持使用预测这个词",{"2":{"614":1}}],["本书将高度h像素",{"2":{"582":1}}],["本书将带读者开启机器学习之旅",{"2":{"281":1}}],["本书旨在传达实践者用来发展深层神经网络的直觉",{"2":{"475":1}}],["本书的实现接受",{"2":{"635":1}}],["本书的关注点是神经网络机器翻译方法",{"2":{"564":1}}],["本书的alexnet模型在这方面与原始论文稍有不同",{"2":{"459":1}}],["本书的其他章节大都不需要多个gpu",{"2":{"445":1}}],["本书在这里提供的是一个稍微精简版本的alexnet",{"2":{"458":1}}],["本书在讨论模型选择的部分",{"2":{"211":1}}],["本书免费分发和使用",{"2":{"302":1}}],["本书后面的章节将讨论无监督学习技术",{"2":{"296":1}}],["本书后面章节将讨论其他运用不确定性概念的算法",{"2":{"291":1}}],["本书",{"2":{"291":1}}],["本书大部分章节将关注平方误差损失函数的最小化",{"2":{"290":1}}],["本书也将提及一些传统方法",{"2":{"285":1}}],["本书已经使用了许多优化算法来训练深度学习模型",{"2":{"65":1}}],["本节视频中我将会讲到有关该算法的向量化实现",{"2":{"1191":1}}],["本节为选修部分",{"2":{"1145":1}}],["本节为了给出一些直观的印象",{"2":{"254":1}}],["本节课中我们略去了一步",{"2":{"1144":1}}],["本节最后我把推导过程写下",{"2":{"1086":1}}],["本节最后一个示例中的变量y1和y2是否完全相同",{"2":{"124":1}}],["本节提供了一些查tensorflow",{"2":{"1005":1}}],["本节提供了一些查看pytorch",{"2":{"1005":1}}],["本节提供了一些查看mxnet",{"2":{"1005":1}}],["本节提供了一个非常简短的入门教程",{"2":{"980":1}}],["本节后面的内容将正式介绍长度",{"2":{"997":1}}],["本节使用resnet",{"2":{"830":2}}],["本节不能替代硬件和系统设计的相关课程",{"2":{"800":1}}],["本节给出了一个简单的两层多层感知机在cpu和两个gpu上训练时的计算图及其依赖关系的例子",{"2":{"797":1}}],["本节代码中的哪些其他超参数可能会影响数据加载速度",{"2":{"779":1}}],["本节从用于预训练词嵌入模型的数据集开始",{"2":{"771":1}}],["本节直接实现了基于数学定义softmax运算的softmax函数",{"2":{"638":1}}],["本节如在",{"2":{"622":1}}],["本节稍后将详细介绍这种工作机制",{"2":{"591":2}}],["本节稍后的内容将对其进行更详细的解析",{"2":{"282":1}}],["本节里我们将输入高和宽从224降到96来简化计算",{"2":{"483":1}}],["本节的目标是帮助读者了解并运行一些在阅读本书的过程中会用到的基本数值计算工具",{"2":{"1017":1}}],["本节的代码至少需要两个gpu来运行",{"2":{"825":1}}],["本节的内容可以作为理解某些算法为什么比其他算法更高效以及如何实现良好吞吐量的起点",{"2":{"800":1}}],["本节的余下部分将通过训练这个模型",{"2":{"389":1}}],["本节的其余部分将着重于应对这种偏移的技术细节",{"2":{"189":1}}],["本节中定义了形状",{"2":{"1004":1}}],["本节中的实验至少需要两个gpu来运行",{"2":{"795":1}}],["本节中的函数cross",{"2":{"638":1}}],["本节中代码的运行时间会发生什么变化",{"2":{"779":1}}],["本节中",{"2":{"360":1}}],["本节到目前为止讨论的问题",{"2":{"302":1}}],["本节已经广泛地讨论了机器学习",{"2":{"302":1}}],["本节",{"2":{"169":1,"429":1,"445":1,"572":1,"630":1}}],["本节我们将简要介绍使用pandas预处理原始数据",{"2":{"1010":1}}],["本节我们将在kaggle上实战狗品种识别问题",{"2":{"899":1}}],["本节我们将通过介绍信息论基础来理解交叉熵损失",{"2":{"648":1}}],["本节我们将通过kaggle比赛",{"2":{"205":1}}],["本节我们将使用刚刚在",{"2":{"629":1}}],["本节我们将介绍一些正则化模型的技术",{"2":{"269":1}}],["本节我们将介绍填充",{"2":{"140":1}}],["本节我们将详细介绍数据预处理",{"2":{"205":1}}],["本节我们将以图像为例",{"2":{"125":1}}],["本节继续更详细地说明随机梯度下降",{"2":{"112":1}}],["本节将探讨语义分割",{"2":{"943":1}}],["本节将探讨更有效的优化算法",{"2":{"85":1}}],["本节将运用我们在前几节中学到的知识来参加cifar",{"2":{"887":1}}],["本节将从原始图像文件开始",{"2":{"887":1}}],["本节将讨论这项广泛应用于计算机视觉的技术",{"2":{"877":1}}],["本节将讨论优化与深度学习之间的关系以及在深度学习中使用优化的挑战",{"2":{"98":1}}],["本节将详细介绍如何从零开始并行地训练网络",{"2":{"831":1}}],["本节将使用textcnn模型来演示如何设计一个表示单个文本",{"2":{"698":1}}],["本节将使用自注意力进行序列编码",{"2":{"395":1}}],["本节将下载一个预训练好的小版本的bert",{"2":{"685":1}}],["本节将描述并实现这种基于注意力的自然语言推断方法",{"2":{"672":1}}],["本节将首先介绍贪心搜索",{"2":{"512":1}}],["本节将展示如何构建自定义层",{"2":{"412":1}}],["本节将展示如何使用深度学习框架的高级api提供的函数更有效地实现相同的语言模型",{"2":{"324":1}}],["本节将根据",{"2":{"329":1}}],["本节将回顾序列模型梯度的计算方式",{"2":{"306":1}}],["本节将更深入地探讨序列模型反向传播的细节",{"2":{"306":1}}],["本节将更深入地研究具有多输入和多输出通道的卷积核",{"2":{"119":1}}],["本节将更详细地探讨这些主题",{"2":{"240":1}}],["本节将通过一些基本的数学和计算图",{"2":{"161":1}}],["本节将介绍线性代数中的基本数学对象",{"2":{"988":1}}],["本节将介绍r",{"2":{"936":1}}],["本节将介绍迁移学习中的常见技巧",{"2":{"870":1}}],["本节将介绍两种近似训练方法",{"2":{"707":1}}],["本节将介绍两个流行的评分函数",{"2":{"367":1}}],["本节将介绍如何使用卷积神经网络",{"2":{"916":1}}],["本节将介绍如何",{"2":{"588":1}}],["本节将介绍机器翻译问题及其后文需要使用的数据集",{"2":{"564":1}}],["本节将介绍一个稍微简化的googlenet版本",{"2":{"486":1}}],["本节将介绍批量规范化",{"2":{"466":1}}],["本节将介绍注意力汇聚的更多细节",{"2":{"385":1}}],["本节将介绍",{"2":{"224":1,"967":1}}],["本节将介绍汇聚",{"2":{"145":1}}],["本节将介绍lenet",{"2":{"135":1}}],["本章会快速介绍一些基本且常用的数学知识",{"2":{"987":1}}],["本章也将介绍它",{"2":{"987":1}}],["本章的后续章节将更详细地介绍如何使用全卷积网络预测图像中像素级的语义",{"2":{"940":1}}],["本章的很多章节将涉及到一些研究",{"2":{"379":1}}],["本章开头",{"2":{"886":1}}],["本章我们将看到",{"2":{"754":1}}],["本章我们将介绍神经网络的整个训练过程",{"2":{"587":1}}],["本章我们已经学习了许多有效优化的技术",{"2":{"32":1}}],["本章介绍的批量规范化",{"2":{"492":1}}],["本章介绍的神经网络是将人类直觉和相关数学见解结合后",{"2":{"492":1}}],["本章介绍的卷积神经网络",{"2":{"134":1}}],["本章后面的大部分内容将围绕着如何有效估计",{"2":{"347":1}}],["本章将简要介绍这些知识",{"2":{"987":1}}],["本章将重点介绍计算机视觉领域",{"2":{"886":1}}],["本章将重点描述然后使用不同类型的深度学习架构",{"2":{"663":1}}],["本章将集中讨论影响计算性能的主要因素",{"2":{"824":1}}],["本章将探讨两种流行且具有代表性的下游自然语言处理任务",{"2":{"663":1}}],["本章将介绍现代的卷积神经网络架构",{"2":{"492":1}}],["本章将介绍权重衰减和暂退法等正则化技术",{"2":{"204":1}}],["本章将从基本的概念介绍开始讲起",{"2":{"204":1}}],["本章将关注优化算法在最小化目标函数方面的性能",{"2":{"100":1}}],["本章中的优化算法都属于此类别",{"2":{"100":1}}],["本章包括了凸优化的入门",{"2":{"65":1}}],["速度会慢得惊人",{"2":{"1026":1}}],["速度的优势可以从很小的百分比到两倍以上",{"2":{"821":1}}],["速度从1gb",{"2":{"801":1}}],["速度就会快得多",{"2":{"63":1}}],["速度通常为o",{"2":{"25":1}}],["给好奇心留出口",{"2":{"1545":1}}],["给路上的同伴",{"2":{"1545":1}}],["给路由规则命名",{"2":{"1478":1}}],["给未来的自己",{"2":{"1545":1}}],["给积木穿衣服",{"2":{"1533":1}}],["给input元素绑定原生input事件",{"2":{"1500":1}}],["给子组件绑定自定义事件",{"2":{"1498":1}}],["给电影",{"2":{"1189":1}}],["给电影i的评分",{"2":{"1187":1}}],["给我们的学习算法",{"2":{"1063":1}}],["给你讲授学习算法就好像给你一套工具",{"2":{"1059":1}}],["给予计算机学习能力的领域",{"2":{"1059":1}}],["给类别损失和偏移损失设置不同比重的超参数",{"2":{"966":1}}],["给每个像素",{"2":{"866":1}}],["给出计算导数项和代价函数的方法",{"2":{"1111":1}}],["给出v中每个元素的相反数",{"2":{"1090":1}}],["给出一些天气监测数据",{"2":{"1025":1}}],["给出一个英语句子",{"2":{"289":1}}],["给出两个矩阵a和b",{"2":{"1004":1}}],["给出前三个词a",{"2":{"751":1}}],["给出的分布方差",{"2":{"655":1}}],["给出的方向",{"2":{"62":1}}],["给出任何样本特征",{"2":{"653":1}}],["给出更多的数据",{"2":{"260":1}}],["给出",{"2":{"94":1,"519":1}}],["给定新的一个训练实例",{"2":{"1180":1}}],["给定新的观测结果",{"2":{"196":1}}],["给定数据集",{"2":{"1178":1}}],["给定未标记的数据集",{"2":{"1161":1}}],["给定参数向量$",{"2":{"1145":1}}],["给定另一个随机变量c时",{"2":{"1034":1}}],["给定同一形状的任意两个向量u和v和二元运算符f",{"2":{"1018":1}}],["给定任意值a和b",{"2":{"1030":1}}],["给定任意方阵a",{"2":{"1004":1}}],["给定任意向量x",{"2":{"1000":1}}],["给定任何锚框ai",{"2":{"851":1}}],["给定任何查询",{"2":{"356":1}}],["给定两个概率为p",{"2":{"1038":1}}],["给定两个向量x",{"2":{"997":1}}],["给定两个锚框或边界框的列表",{"2":{"849":1}}],["给定具有相同形状的任意两个张量",{"2":{"994":1}}],["给定观察到的信息",{"2":{"987":1}}],["给定y=f",{"2":{"981":1}}],["给定超参数γ",{"2":{"966":1}}],["给定超参数λ",{"2":{"162":1}}],["给定形状为1×c×h×w的特征图变量",{"2":{"915":1}}],["给定10个",{"2":{"913":1}}],["给定特征图的宽度和高度fmap",{"2":{"912":1}}],["给定特征估计目标的过程通常称为预测",{"2":{"614":1}}],["给定高度为320和宽度为480的输入",{"2":{"862":1}}],["给定高度和宽度为8的输入",{"2":{"141":1}}],["给定框a和b",{"2":{"852":1}}],["给定图像",{"2":{"851":1}}],["给定集合a和b",{"2":{"849":1}}],["给定由n个计算节点",{"2":{"842":1}}],["给定由单个特征x和对应实数标签y组成的训练数据",{"2":{"259":1}}],["给定的z",{"2":{"1161":1}}],["给定的随机的小批量样本都将被分成k个部分",{"2":{"833":1}}],["给定的成对的",{"2":{"386":1}}],["给定需要训练的模型",{"2":{"833":1}}],["给定上下文词wo1",{"2":{"785":1}}],["给定中心词",{"2":{"783":1}}],["给定中心词wc",{"2":{"783":1}}],["给定中心词wc的上下文窗口",{"2":{"708":1}}],["给定中心词wi",{"2":{"742":1}}],["给定wi作为语料库中的中心词",{"2":{"744":1}}],["给定训练样本",{"2":{"726":1}}],["给定训练数据特征x和对应的已知标签y",{"2":{"610":1}}],["给定长度为t的文本序列",{"2":{"708":1,"783":1,"785":1}}],["给定输入向量x和权重矩阵w",{"2":{"970":1}}],["给定输入图像的形状为256×256",{"2":{"958":1}}],["给定输入x",{"2":{"920":1}}],["给定输入",{"2":{"817":1}}],["给定输入张量x和核张量k",{"2":{"699":1}}],["给定输入特征",{"2":{"289":1}}],["给定预测概率分布y",{"2":{"634":1}}],["给定",{"2":{"614":1,"1147":1}}],["给定标签序列a",{"2":{"578":2}}],["给定标签yi",{"2":{"190":1}}],["给定查询q∈rdq",{"2":{"381":1}}],["给定查询q∈rq和",{"2":{"369":1}}],["给定用户和物品",{"2":{"294":1}}],["给定k个变量",{"2":{"269":1}}],["给定x",{"2":{"262":1,"1190":1}}],["给定元素x",{"2":{"235":1}}],["给定足够的神经元和正确的权重",{"2":{"233":1}}],["给定2×2卷积核",{"2":{"131":1}}],["给定n个样本的训练数据集",{"2":{"113":1}}],["给定函数",{"2":{"101":1}}],["给定一系列图像",{"2":{"636":1}}],["给定一小批量的输入序列x",{"2":{"573":1}}],["给定一组由向量x∈rd表示的值",{"2":{"997":1}}],["给定一组用户的网页浏览记录",{"2":{"296":1}}],["给定一组照片",{"2":{"296":1}}],["给定一组标准的特征",{"2":{"284":1}}],["给定一组降低学习率的时间点",{"2":{"71":1}}],["给定一个点z",{"2":{"1161":1}}],["给定一个训练样本",{"2":{"1146":1}}],["给定一个训练好的模型和一个新的样本",{"2":{"171":1}}],["给定一个样本给定一个样本x",{"2":{"1145":1}}],["给定一个样本特征",{"2":{"291":1}}],["给定一个疾病和一个症状",{"2":{"1029":1}}],["给定一个矩阵x",{"2":{"631":1}}],["给定一个数据集",{"2":{"610":1}}],["给定一个英文的输入序列",{"2":{"532":1}}],["给定一个小批量的输入数据",{"2":{"521":1}}],["给定一个小批量样本x∈rn×d",{"2":{"339":1}}],["给定一个具有x特性和y标签的数据集",{"2":{"500":1}}],["给定一个由词元组成的输入序列x1",{"2":{"396":1}}],["给定一个定义在凸集x上的凸函数f",{"2":{"45":1}}],["给定一个凸双曲余弦函数c",{"2":{"59":1}}],["给定一个凸函数f",{"2":{"42":1}}],["给定一个凸集x和两个向量x和y证明了投影不会增加距离",{"2":{"52":1}}],["给定一个凸集x",{"2":{"41":1}}],["给定凸集xi",{"2":{"40":1}}],["幸运的是现在我们有octave",{"2":{"1111":1}}],["幸运的是",{"2":{"61":1,"103":1,"130":1,"180":1,"191":1,"193":1,"208":1,"221":1,"281":1,"301":1,"354":1,"457":1,"459":1,"519":1,"520":1,"605":1,"616":1,"640":1,"642":1,"709":1,"797":1,"811":1,"984":1,"987":1,"1017":1,"1021":1,"1091":1,"1129":1}}],["项目中",{"2":{"1444":1}}],["项目实战",{"2":{"1304":1}}],["项将等于0",{"2":{"1143":1}}],["项代表缺失值",{"2":{"1012":1}}],["项",{"2":{"61":1,"1012":1}}],["超参数",{"2":{"959":1}}],["超参数通常是我们根据训练迭代结果来调整的",{"2":{"613":1}}],["超参数num",{"2":{"544":1,"558":1}}],["超参数wd将乘以wd",{"2":{"278":1}}],["超出有效长度的值都被掩蔽为0",{"2":{"368":1}}],["超出了本节的范围",{"2":{"26":1}}],["超分辨率",{"2":{"248":1}}],["超过该数值之后",{"2":{"95":1}}],["超常",{"2":{"60":1}}],["另外特征冗余也会导致协方差矩阵不可逆",{"2":{"1184":1}}],["另外的簇中",{"2":{"1154":1}}],["另外一种情况是当y=0时",{"2":{"1143":1}}],["另外一个门用来决定何时将数据读入单元",{"2":{"552":1}}],["另外顺便说一下",{"2":{"1089":1}}],["另外请注意",{"2":{"821":1}}],["另外每小时100美元",{"2":{"290":1}}],["另外",{"2":{"60":1,"95":1,"300":1,"363":1,"422":2,"446":3,"461":4,"467":1,"494":1,"502":1,"527":1,"573":1,"578":1,"615":1,"751":1,"879":1,"907":1,"1058":1,"1061":1,"1084":1,"1089":2,"1090":1,"1092":2,"1098":1,"1109":1,"1110":2,"1182":1}}],["另一件事是",{"2":{"1138":1}}],["另一张是风格图像",{"2":{"916":1}}],["另一组研究人员",{"2":{"455":1}}],["另一种方法是",{"2":{"1173":1}}],["另一种方法是按动量法中的方式使用泄漏平均值",{"2":{"106":1}}],["另一种是",{"2":{"1143":1}}],["另一种是当use",{"2":{"501":1}}],["另一种考虑这个问题的角度是为了有一个高性能的学习算法",{"2":{"1141":1}}],["另一种考虑梯度下降的思路是",{"2":{"1111":1}}],["另一种更简单的方法是直接用",{"2":{"1090":1}}],["另一种增广方法是改变颜色",{"2":{"880":1}}],["另一种解决方案是应用迁移学习",{"2":{"869":1}}],["另一种常用的边界框表示方法是边界框中心的",{"2":{"858":1}}],["另一种预测这个领域发展的方法",{"2":{"455":1}}],["另一类与搜索和排名相关的问题是推荐系统",{"2":{"294":1}}],["另一名学生可能会通过试图理解给出某些答案的原因来做准备",{"2":{"252":1}}],["另一个常见的错误是",{"2":{"1162":1}}],["另一个仪器测量的结果是厘米",{"2":{"1156":1}}],["另一个样本",{"2":{"1145":1}}],["另一个计算公式是",{"2":{"1145":1}}],["另一个方法",{"2":{"1129":1}}],["另一个方法是用零填充序列",{"2":{"350":1}}],["另一个被称为逆",{"2":{"1086":1}}],["另一个年代近一点的定义",{"2":{"1059":1}}],["另一个有用属性是依赖",{"2":{"1034":1}}],["另一个最基本的操作之一是点积",{"2":{"997":1}}],["另一个覆盖以黄色为主的其余部分身体",{"2":{"944":1}}],["另一个是inv",{"2":{"1086":1}}],["另一个是锚框真实相对于边界框的偏移量",{"2":{"855":1}}],["另一个是固定权重",{"2":{"702":1}}],["另一个是将本书中使用的所有数据集从data",{"2":{"206":1}}],["另一个严重问题是",{"2":{"522":1}}],["另一个参数也会改变",{"2":{"437":2}}],["另一个用于表示偏置项",{"2":{"414":1}}],["另一个用于动量v",{"2":{"95":1}}],["另一个问题来自这样一个事实",{"2":{"305":1}}],["另一个关键的发展是生成对抗网络",{"2":{"300":1}}],["另一个影响可以在神经科学和心理学中找到",{"2":{"299":1}}],["另一个例子",{"2":{"296":1}}],["另一个重要因素是数据集的大小",{"2":{"260":1}}],["另一个同样重要的方面是初始化",{"2":{"66":1}}],["另一个变量以公里表示高度的情况",{"2":{"61":1}}],["另一个策略是重新引入学习率",{"2":{"59":1}}],["另一方面是期望开发者既能完成统计学习建模还精通系统和网络也是不切实际的",{"2":{"840":1}}],["另一方面",{"2":{"60":1,"65":1,"73":1,"78":1,"113":1,"114":1,"165":1,"191":1,"210":1,"258":1,"460":1,"476":1,"643":1,"656":1,"718":1,"731":1,"742":1,"802":1,"819":1,"852":1,"1028":1}}],["恒定",{"2":{"60":1}}],["取舍理由",{"2":{"1546":1}}],["取消监视",{"2":{"1467":1}}],["取消暂存",{"2":{"1333":1}}],["取余",{"2":{"1218":1}}],["取得成功的人不是拥有最好算法的人",{"2":{"1141":1}}],["取得最小值的参数$",{"2":{"1110":1}}],["取值离散的情况",{"2":{"1106":1}}],["取值为某个u1",{"2":{"1145":1}}],["取值为",{"2":{"1106":1}}],["取值",{"2":{"1093":1}}],["取值从",{"2":{"1092":1}}],["取值范围为0～1",{"2":{"882":1}}],["取值r1",{"2":{"848":1}}],["取值s1",{"2":{"848":1}}],["取两边的对数得到uj⊤vi≈logα+logxij−logxi",{"2":{"744":1}}],["取两边的绝对值",{"2":{"60":1}}],["取悦这位老板很容易",{"2":{"296":1}}],["取而代之的是你可以使用一个在线学习算法来连续的学习",{"2":{"1168":1}}],["取而代之",{"2":{"292":1}}],["取决于机器的内存限制",{"2":{"990":1}}],["取决于模型参数whx和whh",{"2":{"312":1}}],["取决于我们最终想用模型做什么",{"2":{"292":1}}],["取决于运气",{"2":{"252":1}}],["取决于由前向传播给出的隐藏变量h的当前值",{"2":{"165":1}}],["取决于是黑白还是彩色图像",{"2":{"134":1}}],["取代",{"2":{"983":1}}],["取代η增加了控制优化算法收敛的复杂性",{"2":{"114":1}}],["取代梯度计算",{"2":{"86":1}}],["取最小值",{"2":{"62":1}}],["取a∈x和b∈y",{"2":{"40":1}}],["代号",{"2":{"1437":1}}],["代理服务器端",{"2":{"1361":1}}],["代理客户端访问外部资源",{"2":{"1361":1}}],["代价函数修改为",{"2":{"1147":1}}],["代价函数cost1",{"2":{"1144":1}}],["代价函数cost0",{"2":{"1143":1}}],["代价函数中",{"2":{"1143":1}}],["代价函数可能几乎为0",{"2":{"1114":1}}],["代价函数j",{"2":{"1109":1,"1111":1}}],["代价函数的直观理解",{"2":{"1193":2}}],["代价函数的直观理解ii",{"0":{"1066":1}}],["代价函数的直观理解i",{"0":{"1065":1}}],["代价函数的参数表示也会稍微有些不同",{"2":{"1143":1}}],["代价函数的值",{"2":{"1131":2}}],["代价函数的样子",{"2":{"1066":1}}],["代价函数也被称作平方误差函数",{"2":{"1064":1}}],["代价函数",{"0":{"1064":1,"1109":1,"1115":1,"1120":1},"2":{"1188":1,"1193":4}}],["代表技术",{"2":{"1353":1}}],["代表电影的动作程度",{"2":{"1188":1}}],["代表电影的数量",{"2":{"1187":1}}],["代表用户",{"2":{"1187":1}}],["代表用户的数量",{"2":{"1187":1}}],["代表与x",{"2":{"1152":1}}],["代表下一层中误差单元的下标",{"2":{"1121":1}}],["代表目前计算层中的激活单元的下标",{"2":{"1121":1}}],["代表目前所计算的是第几层",{"2":{"1121":1}}],["代表目标变量",{"2":{"1063":1}}],["代表逻辑函数",{"2":{"1107":1}}],["代表从第一层映射到第二层的权重的矩阵",{"2":{"1099":1}}],["代表从第",{"2":{"1099":1}}],["代表了我们所知道的每层含义",{"2":{"1098":1}}],["代表这是一个47×2的矩阵",{"2":{"1089":1}}],["代表矩阵的逆",{"2":{"1085":1}}],["代表矩阵乘法",{"2":{"219":2}}],["代表第j",{"2":{"1099":1}}],["代表第",{"2":{"1080":1}}],["代表第i",{"2":{"1063":1}}],["代表单位矩阵",{"2":{"1076":1}}],["代表hypothesis",{"2":{"1063":1}}],["代表学习算法的解决方案或函数也称为假设",{"2":{"1063":1}}],["代表训练集中的实例",{"2":{"1063":1}}],["代表训练集中实例的数量",{"2":{"1063":1}}],["代表特征向量",{"2":{"1107":1}}],["代表特征矩阵中第",{"2":{"1080":1}}],["代表特征的数量",{"2":{"1080":1}}],["代表特征",{"2":{"1063":1}}],["代表良性",{"2":{"1060":1}}],["代表沿轴1",{"2":{"1020":1}}],["代表是哪个设备需要同步",{"2":{"796":2}}],["代码性能与调试",{"0":{"1260":1},"1":{"1261":1,"1262":1}}],["代码风格与高级用法",{"2":{"1237":1}}],["代码出现问题的有可能性也就越小",{"2":{"1093":1}}],["代码",{"2":{"1081":1,"1436":1}}],["代码示例",{"2":{"1081":1}}],["代码如下",{"2":{"1017":2,"1125":1,"1452":1,"1454":1}}],["代码的主要区别在于在调用网络之前拆分了一个小批量",{"2":{"827":1}}],["代码健全性检查",{"2":{"575":1}}],["代码执行和许多其他的python代码",{"2":{"426":4}}],["代码几乎与d2l",{"2":{"67":4}}],["代码实现",{"0":{"21":1}}],["代入这个更新方程",{"2":{"60":1}}],["回退到指定",{"2":{"1333":1}}],["回退与撤销",{"0":{"1333":1}}],["回车",{"2":{"1089":1}}],["回忆",{"2":{"954":1}}],["回忆一下在",{"2":{"413":1}}],["回归一词指的是",{"2":{"1063":1}}],["回归这个词的意思是",{"2":{"1060":1}}],["回归可以用于预测多少的问题",{"2":{"639":1}}],["回归变得更加容易",{"2":{"622":1}}],["回归问题中最常用的损失函数是平方误差函数",{"2":{"611":1}}],["回归经常用来表示输入和输出之间的关系",{"2":{"608":1}}],["回归是训练一个回归函数来输出一个数值",{"2":{"291":1}}],["回归",{"0":{"290":1},"2":{"290":1,"608":1,"1106":1}}],["回到我们的文字识别应用中",{"2":{"1174":1}}],["回到你原有的高维数据的一种近似",{"2":{"1161":1}}],["回到它的本质",{"2":{"1068":1}}],["回到2012年的重大突破",{"2":{"457":1}}],["回到上面的",{"2":{"157":1}}],["回到本节开头提到的对象边缘检测示例",{"2":{"146":1}}],["回想当时的数据集",{"2":{"1061":1}}],["回想",{"2":{"687":1}}],["回想之前我们定义一个函数",{"2":{"502":1}}],["回想之前的方程x",{"2":{"60":1}}],["回想在",{"2":{"108":1}}],["回想我们在",{"2":{"87":1}}],["回想一下在",{"2":{"953":1}}],["回想一下词在word2vec中是如何表示的",{"2":{"756":1}}],["回想一下任意函数的泰勒展开式",{"2":{"479":1}}],["回想一下sequential的设计是为了把其他模块串起来",{"2":{"424":1}}],["回想一下softmax",{"2":{"150":1}}],["回想一下如",{"2":{"229":1,"811":1}}],["回想一下我们应用多层感知机来预测房价的例子",{"2":{"467":1}}],["回想一下我们之前在",{"2":{"220":1}}],["回想一下我们在",{"2":{"103":1,"130":1,"307":1,"317":1,"707":1,"765":1}}],["回想一下vt=∑τ=0t−1βτgt−τ",{"2":{"89":1}}],["回想一下",{"2":{"77":1,"135":1,"164":1,"171":1,"217":1,"269":1,"270":1,"330":1,"338":1,"341":1,"348":1,"414":1,"468":1,"469":1,"473":2,"475":1,"494":1,"509":1,"568":1,"575":1,"600":1,"602":2,"624":1,"630":1,"631":1,"688":1,"727":1,"731":1,"736":1,"862":1,"883":1,"903":1,"905":1,"912":1,"951":1,"959":2}}],["回顾高斯分布的基本知识",{"2":{"1179":1}}],["回顾刚才给出的",{"2":{"1152":1}}],["回顾我们之前讨论过使用高阶多项式模型来解决无法用直线分隔的分类问题",{"2":{"1146":1}}],["回顾在一开始提到的乳腺癌分类问题",{"2":{"1107":1}}],["回顾分别在",{"2":{"998":1}}],["回顾来看",{"2":{"841":1}}],["回顾前几章中感兴趣的模型",{"2":{"823":2}}],["回顾一下代价函数",{"2":{"1115":1}}],["回顾一下",{"2":{"583":1,"595":1,"633":1,"1068":1}}],["回顾一些函数f",{"2":{"59":1}}],["回顾训练误差和泛化误差之间的关系",{"2":{"280":1}}],["回顾",{"0":{"157":1},"1":{"158":1},"2":{"591":1,"1135":1,"1144":1}}],["回顾adam算法",{"2":{"33":1}}],["ξt=πt−1",{"2":{"310":1}}],["ξt=0",{"2":{"310":1}}],["ξt从第t步的某个分布中提取",{"2":{"115":1}}],["ξt",{"2":{"115":13,"310":1}}],["ξ",{"2":{"60":4,"115":2}}],["泰勒展开式是确切的",{"2":{"59":1}}],["遵循编码器",{"2":{"572":1}}],["遵循",{"2":{"59":1,"1264":1}}],["牛顿法在凸问题中一旦开始正常工作",{"2":{"63":1}}],["牛顿法",{"0":{"59":1}}],["会失去响应式",{"2":{"1458":1}}],["会修改历史",{"2":{"1334":1}}],["会自动创建并初始化这些属性",{"2":{"1428":1}}],["会自动创建虚拟环境",{"2":{"1285":1}}],["会自动拉起新的",{"2":{"1382":1}}],["会自动将形状为",{"2":{"136":1}}],["会考虑到结果变量",{"2":{"1162":1}}],["会非常耗时",{"2":{"1147":1}}],["会被证明同样成立",{"2":{"1145":1}}],["会是一个非常小的数",{"2":{"1145":1}}],["会是一个凸函数",{"2":{"1109":1}}],["会得到这样的一个投影",{"2":{"1145":1}}],["会得到更好的结果吗",{"2":{"910":1}}],["会远小于0",{"2":{"1143":1}}],["会遇到过拟合",{"2":{"1114":1}}],["会给你两种不同的实现方式",{"2":{"1093":1}}],["会讲到的一些其他的算法",{"2":{"1085":1}}],["会产生更新",{"2":{"1067":1}}],["会产生一个单元素张量",{"2":{"1018":1}}],["会用与不会用的人之间",{"2":{"1059":1}}],["会赢",{"2":{"1059":1}}],["会执行矩阵",{"2":{"998":3}}],["会很有用",{"2":{"996":1}}],["会在这两个矩阵上执行元素加法",{"2":{"994":1}}],["会在后端自动构建计算图",{"2":{"795":1}}],["会将对应的函数",{"2":{"981":1}}],["会怎样",{"2":{"830":1}}],["会怎么布置",{"2":{"815":1}}],["会怎么样",{"2":{"58":1,"842":1}}],["会随着n的增长而增加",{"2":{"578":1}}],["会启发人们使用具有状态的神经网络来实现该架构",{"2":{"535":1}}],["会存在哪些问题",{"2":{"498":1}}],["会听到一个完全不同的故事",{"2":{"454":1}}],["会出现什么样的问题",{"2":{"428":1}}],["会改变成基于位置的前馈网络的输出尺寸",{"2":{"405":1}}],["会造成误差的快速累积和预测质量的极速下降",{"2":{"352":1}}],["会有若干个变量是我们感兴趣的",{"2":{"1029":1}}],["会有什么好处",{"2":{"811":1}}],["会有什么问题呢",{"2":{"788":1}}],["会有许多五星级和一星级评分",{"2":{"294":1}}],["会有其他解决办法",{"2":{"211":1}}],["会发现机器学习研究人员相信机器学习既重要又美丽",{"2":{"454":1}}],["会发现",{"2":{"376":1}}],["会发现之前找到的明显关系并不成立",{"2":{"251":1}}],["会发生什么事情",{"2":{"268":1}}],["会发生什么情况",{"2":{"133":1,"178":3,"1018":1}}],["会发生什么",{"2":{"23":1,"139":1,"178":1,"215":2,"244":1,"337":1,"420":1,"449":2,"607":1,"823":1,"830":2,"979":1}}],["会以不同的随机顺序遍历它",{"2":{"116":1}}],["会看出什么",{"2":{"83":1}}],["自由扩展",{"2":{"1527":1}}],["自带的编排工具",{"2":{"1395":1}}],["自带的",{"2":{"1348":1}}],["自带电池的语言",{"2":{"1302":1}}],["自己动手编写一个app组件",{"2":{"1444":1}}],["自己计算导数同样对于逻辑回归",{"2":{"1117":1}}],["自己练习一些矩阵",{"2":{"1088":1}}],["自驱型智能体",{"2":{"1052":1}}],["自监督的word2vec",{"0":{"782":1}}],["自监督学习",{"2":{"754":1}}],["自然地",{"2":{"923":1}}],["自然会想简化这个过程",{"2":{"591":1}}],["自然语言风格更友好",{"2":{"1299":1}}],["自然语言是用来表达人脑思维的复杂系统",{"2":{"780":1}}],["自然语言推断是一个序列级别的文本对分类问题",{"2":{"685":1}}],["自然语言推断的可分解注意模型的主要缺点是什么",{"2":{"684":1}}],["自然语言推断研究",{"2":{"670":1}}],["自然语言推断一直是理解自然语言的中心话题",{"2":{"665":1}}],["自然语言推断也被称为识别文本蕴涵任务",{"2":{"665":1}}],["自然语言推断决定了一对文本序列之间的逻辑关系",{"2":{"665":1}}],["自然语言推断",{"0":{"665":1,"672":1,"685":1},"1":{"673":1,"674":1,"675":1,"676":1,"677":1,"678":1,"679":1,"680":1,"681":1,"682":1,"683":1,"684":1,"686":1,"687":1,"688":1,"689":1,"690":1},"2":{"665":1,"731":1}}],["自然语言推断与数据集",{"0":{"664":1},"1":{"665":1,"666":1,"667":1,"668":1,"669":1,"670":1,"671":1}}],["自然语言推断和语义文本相似性",{"2":{"661":1}}],["自然语言统计",{"0":{"318":1}}],["自然语言处理是指研究使用自然语言的计算机和人类之间的交互",{"2":{"754":1}}],["自然语言处理的科学家更喜欢使用一个叫做困惑度",{"2":{"342":1}}],["自然语言处理",{"0":{"663":1,"754":1},"2":{"281":1,"302":1}}],["自2000年以来",{"2":{"445":1}}],["自2017年横空出世",{"2":{"379":1}}],["自定义事件常用于",{"2":{"1498":1}}],["自定义事件",{"0":{"1498":1},"2":{"1498":2}}],["自定义hook的优势",{"2":{"1471":1}}],["自定义hook",{"0":{"1471":1}}],["自定义映射类型",{"2":{"1435":1}}],["自定义类型",{"0":{"1411":1},"1":{"1412":1,"1413":1,"1414":1}}],["自定义模块与导入",{"0":{"1257":1}}],["自定义异常类",{"0":{"1249":1}}],["自定义了一个语义分割数据集类vocsegdataset",{"2":{"947":1}}],["自定义语义分割数据集类",{"0":{"947":1}}],["自定义初始化",{"0":{"436":1}}],["自定义块",{"0":{"423":1}}],["自定义层或自定义损失函数",{"2":{"598":1}}],["自定义层",{"0":{"412":1},"1":{"413":1,"414":1,"415":1,"416":1}}],["自注意力权重",{"2":{"408":3}}],["自注意力同时具有并行计算和最短的最大路径长度这两个优势",{"2":{"403":1}}],["自注意力具有o",{"2":{"397":1}}],["自注意力",{"0":{"396":1},"2":{"395":1,"408":4}}],["自注意力和位置编码",{"0":{"395":1},"1":{"396":1,"397":1,"398":1,"399":1,"400":1,"401":1,"402":1}}],["自主驾驶",{"0":{"1127":1}}],["自主提示",{"2":{"385":1}}],["自主性提示",{"2":{"356":1,"358":1}}],["自主性提示被称为查询",{"2":{"356":1}}],["自主性的与非自主性的注意力提示解释了人类的注意力的方式",{"2":{"356":1}}],["自19世纪以来",{"2":{"379":1}}],["自经济学研究稀缺资源分配以来",{"2":{"354":1}}],["自回归模型",{"0":{"347":1}}],["自我推理",{"2":{"301":1}}],["自发",{"2":{"296":1}}],["自动追踪依赖并在状态变更时高效更新视图",{"2":{"1527":1}}],["自动推断返回类型为",{"2":{"1401":1}}],["自动推断为",{"2":{"1401":3,"1402":2}}],["自动类型推断",{"0":{"1401":1}}],["自动伸缩",{"2":{"1351":1,"1395":1}}],["自动生成的",{"2":{"1315":1}}],["自动生成",{"2":{"1315":1}}],["自动触发一次",{"2":{"1315":1}}],["自动写",{"2":{"1297":1}}],["自动办公",{"2":{"1297":1}}],["自动化",{"2":{"1543":1}}],["自动化测试与运维",{"2":{"1303":1}}],["自动化运维",{"2":{"1297":1}}],["自动化写作与代码助手中",{"2":{"1054":1}}],["自动安装指定python版本",{"2":{"1293":1}}],["自动管理虚拟环境与依赖",{"2":{"1279":1}}],["自动选举新的",{"2":{"1209":1}}],["自动捕捉特征之间的相关性",{"2":{"1184":1}}],["自动调用",{"2":{"1052":1}}],["自动启动",{"2":{"1048":1}}],["自动将一个图像中的风格应用在另一图像之上",{"2":{"916":1}}],["自动驾驶",{"2":{"886":1,"1193":1}}],["自动驾驶汽车",{"0":{"186":1}}],["自动地发现市场分类",{"2":{"1061":1}}],["自动地把它们聚类到一起",{"2":{"1061":1}}],["自动地",{"2":{"837":1}}],["自动并行和多gpu计算",{"2":{"824":1}}],["自动并行",{"0":{"795":1},"1":{"796":1,"797":1,"798":1,"799":1}}],["自动语音识别",{"2":{"295":1}}],["自动微分使系统能够随后反向传播梯度",{"2":{"973":1}}],["自动微分可以用来学习模型的参数吗",{"2":{"607":1}}],["自动微分",{"0":{"973":1},"1":{"974":1,"975":1,"976":1,"977":1,"978":1,"979":1},"2":{"161":1}}],["自适应方法",{"0":{"58":1},"1":{"59":1,"60":1,"61":1,"62":1}}],["自变量max",{"2":{"720":1}}],["自变量在迭代后期的移动幅度较小",{"2":{"27":1}}],["自变量的迭代轨迹较平滑",{"2":{"27":1}}],["标识图像中的对象",{"2":{"1029":1}}],["标注这些锚框的分类和偏移量",{"2":{"853":1}}],["标志ignore",{"2":{"688":1}}],["标记一个对象",{"2":{"1519":1}}],["标记数据",{"2":{"1173":1}}],["标记其为背景",{"2":{"852":2}}],["标记锚框的类别和偏移量",{"2":{"852":1}}],["标记类别和偏移量",{"0":{"852":1}}],["标记的索引",{"2":{"738":3}}],["标记单个文本的结束或分隔成对文本",{"2":{"657":1}}],["标记为",{"2":{"295":1,"386":2,"737":1}}],["标记",{"2":{"295":1}}],["标记和解析",{"2":{"295":1}}],["标记问题",{"0":{"292":1}}],["标签不是目的",{"2":{"1543":1}}],["标签为y=0​",{"2":{"1144":1}}],["标签中颜色相同的像素属于同一个语义类别",{"2":{"945":1}}],["标签还包含真实边界框的信息",{"2":{"934":1}}],["标签的",{"0":{"1468":1}}],["标签的小批量的形状为",{"2":{"932":1}}],["标签的数量相同",{"2":{"691":1}}],["标签y将是一个三维向量",{"2":{"640":1}}],["标签类别数是10",{"2":{"495":4}}],["标签可能是猫狗",{"2":{"291":1}}],["标签被设置为数字0～9",{"2":{"291":1}}],["标签同时被均值为0",{"2":{"271":1}}],["标签",{"0":{"1335":1},"2":{"213":1,"289":1,"320":1,"339":1,"350":2,"635":2,"653":1,"667":2,"692":1,"850":1}}],["标签或概念如何发生偏移",{"2":{"189":1}}],["标签偏移的一个好处是",{"2":{"192":1}}],["标签偏移纠正",{"0":{"192":1}}],["标签偏移和协变量偏移假设可以同时成立",{"2":{"182":1}}],["标签偏移在这里是恰当的假设",{"2":{"182":1}}],["标签偏移是一个合理的假设",{"2":{"182":1}}],["标签偏移",{"0":{"182":1},"2":{"182":1}}],["标量由只有一个元素的张量表示",{"2":{"989":1}}],["标量会被加到向量的每个分量上",{"2":{"602":1}}],["标量或者矢量",{"2":{"382":4}}],["标量",{"0":{"989":1},"2":{"367":1,"994":1,"1003":2}}],["标量函数",{"0":{"95":1}}],["标量作为输出",{"2":{"57":1}}],["标准方程法是一个比梯度下降法更快的替代算法",{"2":{"1085":1}}],["标准方程是一个很好的计算参数$",{"2":{"1085":1}}],["标准输入输出",{"2":{"1047":1}}],["标准化项目管理",{"2":{"1294":1}}],["标准化图像的每个通道",{"2":{"891":3,"903":3}}],["标准化状态变量由下式获得",{"2":{"33":1}}],["标准的流水线",{"2":{"591":1}}],["标准差为1的标准高斯分布",{"2":{"1017":1}}],["标准差为0",{"2":{"271":1,"592":1,"601":1}}],["标准差σ",{"2":{"616":1}}],["标准差的额外减少是微乎其微的",{"2":{"78":1}}],["标准暂退法包括在计算下一层之前将当前层中的一些节点置零",{"2":{"170":1}}],["⊤=a",{"2":{"1004":1}}],["⊤vi",{"2":{"744":1}}],["⊤vc",{"2":{"709":4}}],["⊤f",{"2":{"674":1}}],["⊤∂j∂o",{"2":{"164":1}}],["⊤q",{"2":{"94":1}}],["⊤给出",{"2":{"57":1}}],["⊤作为输入",{"2":{"57":1}}],["⊤",{"2":{"57":1,"599":1,"609":1,"983":2,"1004":1}}],["⊤的情况",{"2":{"57":1}}],["⊤h",{"2":{"46":1}}],["导航区",{"2":{"1474":1}}],["导出环境配置",{"2":{"1277":1}}],["导出当前环境依赖到requirements",{"2":{"1269":1}}],["导入模块的方式",{"0":{"1235":1}}],["导入竞赛所需的包和模块",{"2":{"887":1}}],["导致模型变成",{"2":{"1115":1}}],["导致模型无法学习",{"2":{"241":1}}],["导致计算量也会很大",{"2":{"824":1}}],["导致固态驱动器在按位随机写入时性能非常差",{"2":{"805":1}}],["导致错过截止期",{"2":{"800":1}}],["导致它无法广泛应用在深度学习里",{"2":{"612":1}}],["导致了实用算法的快速进步",{"2":{"302":1}}],["导致几乎不可行",{"2":{"26":1}}],["导数值会自动变得越来越小",{"2":{"1068":1}}],["导数可以被解释为函数相对于其变量的瞬时变化率",{"2":{"985":1}}],["导数u",{"2":{"981":1}}],["导数和微分",{"0":{"981":1}}],["导数是我们softmax模型分配的概率与实际发生的情况",{"2":{"647":1}}],["导数的和等于和的导数",{"2":{"270":1}}],["导数越接近0",{"2":{"236":1,"237":1}}],["导数",{"2":{"54":1}}],["能跑的",{"2":{"1548":1}}],["能跑的代码",{"2":{"1545":1}}],["能自动就不手动",{"2":{"1544":1}}],["能解决问题才是",{"2":{"1543":1}}],["能量化就不拍脑袋",{"2":{"1543":1}}],["能落地",{"2":{"1542":1}}],["能实现极速的服务启动",{"2":{"1444":1}}],["能力",{"2":{"1374":1}}],["能直接处理",{"2":{"1363":1}}],["能支撑从",{"2":{"1210":1}}],["能适应大规模的特征",{"2":{"1184":1}}],["能很有信心的预测出y值吗",{"2":{"1141":1}}],["能让我动手的",{"2":{"1542":1}}],["能让我好奇",{"2":{"1542":1}}],["能让你把这个问题当做是一个异常检测",{"2":{"1182":1}}],["能让你花上几天几周",{"2":{"1137":1}}],["能让计算机处理无限多个特征",{"2":{"1060":1}}],["能更详细地进行查看",{"2":{"1089":1}}],["能显示出",{"2":{"1089":1}}],["能执行规划",{"2":{"1050":1}}],["能简化联合概率p",{"2":{"1038":1}}],["能在海量数据下实现",{"2":{"1207":1}}],["能在一个环境中智能地行动",{"2":{"1025":1}}],["能在测试集上获得更高的准确度吗",{"2":{"684":1}}],["能创作出更有趣的合成图像吗",{"2":{"929":1}}],["能取得什么结果",{"2":{"910":1}}],["能取得最小值",{"2":{"54":1}}],["能获得怎样的准确度",{"2":{"898":1}}],["能进一步改善结果吗",{"2":{"910":1}}],["能进一步改进吗",{"2":{"898":1}}],["能进一步提升模型的精度吗",{"2":{"868":1}}],["能提高它们的计算性能吗",{"2":{"823":1}}],["能通过改进损失函数来改进单发多框检测吗",{"2":{"966":1}}],["能通过重新实现它们来提高它们的计算性能吗",{"2":{"823":1}}],["能通过直接最小化价格的对数来改进模型吗",{"2":{"215":1}}],["能基于普朗克定律使用光谱能量密度来确定物体的温度吗",{"2":{"607":1}}],["能否从以下几个方面进一步改进模型",{"2":{"966":1}}],["能否得到更好的非参数的nadaraya",{"2":{"394":1}}],["能否为具有不同矢量长度的查询和键设计新的评分函数",{"2":{"372":1}}],["能使模型正常工作吗",{"2":{"328":1}}],["能使循环神经网络模型过拟合吗",{"2":{"328":1}}],["能设法估计么",{"2":{"323":1}}],["能找到类似的矩阵方程吗",{"2":{"280":1}}],["能找到adadelta无法解决的优化问题吗",{"2":{"23":1}}],["能用其他方法解决这个问题吗",{"2":{"268":1}}],["能够轻松支撑数十万并发连接",{"2":{"1359":1}}],["能够轻松解释任意事实的模型是复杂的",{"2":{"254":1}}],["能够了解如何选择好的特征变量",{"2":{"1183":1}}],["能够支持平行处理",{"2":{"1166":1}}],["能够判断一个算法是偏差还是方差有问题",{"2":{"1132":1}}],["能够深入了解某种算法到底是否有用",{"2":{"1129":1}}],["能够比仅仅使用原始输入",{"2":{"1100":1}}],["能够帮助我们建立更好的分类模型",{"2":{"1097":1}}],["能够自动地找出能使代价函数j最小化的参数θ0和θ1的值",{"2":{"1066":1}}],["能够自动地找出这些使代价函数j取最小值的参数θ0和θ1来",{"2":{"1066":1}}],["能够指导我们生成出有效性超出用于训练的数据集本身的模型",{"2":{"980":1}}],["能够量化目标的实际值与预测值之间的差距",{"2":{"611":1}}],["能够通过专用机制决定什么时候记忆或忽略隐状态中的输入",{"2":{"552":1}}],["能够将困惑度降到多低",{"2":{"531":1}}],["能够将任何输入特征映射到标签",{"2":{"289":1}}],["能够在试图解决一般任务的同时",{"2":{"301":1}}],["能够花费更多时间来优化这些参数",{"2":{"300":1}}],["能够拟合更复杂的模型可能是有益的",{"2":{"260":1}}],["能够解释深层神经网络泛化性能的理论基础",{"2":{"253":1}}],["能够表达任何可计算的程序",{"2":{"233":1}}],["能构造一个不随机丢失值的情况吗",{"2":{"215":1}}],["能利用这种效应来优化算法吗",{"2":{"105":1}}],["来绕开深度响应",{"2":{"1513":1}}],["来说",{"2":{"1455":1}}],["来捕捉各种异常的可能",{"2":{"1183":1}}],["来算出整个样本集的代价函数",{"2":{"1167":1}}],["来求解",{"2":{"1159":1}}],["来存储与第i个实例数据最近的聚类中心的索引",{"2":{"1151":1}}],["来存放",{"2":{"1089":1}}],["来替换模型中的每一项",{"2":{"1146":1}}],["来替换我们现在用的方法",{"2":{"1110":1}}],["来提供一个高性能的学习算法",{"2":{"1141":1}}],["来提高模型的泛化能力",{"2":{"884":1}}],["来提高特定任务的性能",{"2":{"303":1}}],["来提高分数",{"2":{"215":1}}],["来帮助你决定下一步的做法",{"2":{"1138":1}}],["来找到相关电影和产品的方法",{"2":{"1191":1}}],["来找到帮助文档",{"2":{"1090":1}}],["来找出你的算法是否有高偏差和高方差的问题",{"2":{"1138":1}}],["来试图很快的把结果搞出来",{"2":{"1138":1}}],["来获得一些新的更好的特征",{"2":{"1183":1}}],["来获得我们的特征向量",{"2":{"1137":1}}],["来获得输入序列中每个词元的特征向量",{"2":{"573":1}}],["来代表",{"2":{"1112":2}}],["来代替",{"2":{"527":1}}],["来区分开来自工作的邮件",{"2":{"1112":1}}],["来监测梯度下降",{"2":{"1110":1}}],["来同时更新所有$",{"2":{"1110":1}}],["来输出对假设的预测",{"2":{"1110":2}}],["来输出图像的内容特征",{"2":{"920":1}}],["来拟合出逻辑回归的参数",{"2":{"1110":1}}],["来作为特征",{"2":{"1097":1}}],["来让你的代码运行得更高效",{"2":{"1093":1}}],["来做到这一点",{"2":{"1092":1}}],["来标记垂直轴的值",{"2":{"1091":1}}],["来标记x轴即水平轴",{"2":{"1091":1}}],["来标注每张图片的相关类别",{"2":{"456":1}}],["来返回第二行的所有元素",{"2":{"1089":1}}],["来显示",{"2":{"1089":1}}],["来解释这个优化问题是如何得到一个大间距分类器的",{"2":{"1144":1}}],["来解释它",{"2":{"741":1}}],["来解决多类别分类问题",{"2":{"1112":1}}],["来解决当m比n小的时候的问题",{"2":{"1086":1}}],["来展示那两个相关联的特征值",{"2":{"1086":1}}],["来预测用户接受报价使用我们的物流服务的可能性",{"2":{"1168":1}}],["来预测真和假",{"2":{"1140":1}}],["来预测肿瘤的恶性与否",{"2":{"1060":1}}],["来预测输入图像上与该区域位置相近的锚框类别和偏移量",{"2":{"913":1,"914":1}}],["来为你定制服务",{"2":{"1058":1}}],["来为所需张量中的每个元素赋予确定值",{"2":{"1017":1}}],["来理解这些数据",{"2":{"1058":1}}],["来执行按元素操作",{"2":{"1019":1}}],["来初始化矩阵",{"2":{"1017":1}}],["来取代x",{"2":{"1017":1}}],["来确认这一解释",{"2":{"1007":1}}],["来确保缓存的作用不影响最终的结果",{"2":{"796":3}}],["来确保数值的稳定性",{"2":{"627":1}}],["来确保合适的收敛",{"2":{"530":1}}],["来发现数据集中的结构并解决预测问题",{"2":{"1002":1}}],["来引用",{"2":{"992":1}}],["来访问矩阵中的标量元素aij",{"2":{"992":1}}],["来跟踪计算是哪些数据通过哪些操作组合起来产生输出",{"2":{"973":1}}],["来加快求导",{"2":{"973":1}}],["来加载香蕉检测数据集",{"2":{"932":1}}],["来识别并理解图像中像素级别的内容",{"2":{"950":1}}],["来保留特征图上的空间信息",{"2":{"940":1}}],["来描述对象的空间位置",{"2":{"858":1}}],["来描述如何在当前时间步中使用前一个时间步的隐藏变量",{"2":{"340":1}}],["来移除类似的预测边界框",{"2":{"855":1}}],["来移动预测的位置",{"2":{"572":1}}],["来聚合值",{"2":{"844":1}}],["来更新θ",{"2":{"1093":1}}],["来更新θj",{"2":{"1093":1}}],["来更新它所维护的完整的模型参数集",{"2":{"833":1}}],["来更积极地减低它",{"2":{"114":1}}],["来学习模型参数",{"2":{"784":1}}],["来评估模型的性能",{"2":{"653":1}}],["来量化这种惊异程度",{"2":{"651":1}}],["来激励模型精准地估计概率",{"2":{"643":1}}],["来调整网络输入的形状",{"2":{"623":1}}],["来看一个不同的决策边界",{"2":{"1145":1}}],["来看下面的例子",{"2":{"611":1}}],["来看看他犯了什么错",{"2":{"1138":1}}],["来看看实际的显存消耗",{"2":{"485":1}}],["来看看下面的例子",{"2":{"296":1}}],["来估算房屋价格",{"2":{"609":1}}],["来规范化步长",{"2":{"604":1}}],["来重新训练模型并对测试集进行分类",{"2":{"896":1}}],["来重新衡量每个数据样本的权重",{"2":{"191":1}}],["来重写参数值",{"2":{"592":1}}],["来指定初始化权重的方法",{"2":{"592":2}}],["来管理",{"2":{"552":1}}],["来设计基于",{"2":{"535":1}}],["来定义双向lstm模型",{"2":{"523":3}}],["来利用各种计算资源",{"2":{"502":1}}],["来构建深层网络",{"2":{"492":1}}],["来观察每一层输出的形状",{"2":{"461":1}}],["来销售",{"2":{"457":1}}],["来表示聚类中心",{"2":{"1151":1}}],["来表示这个误差矩阵",{"2":{"1121":1}}],["来表示",{"2":{"1093":1}}],["来表示账户未被盗",{"2":{"1060":1}}],["来表示一元标量运算符",{"2":{"1018":1}}],["来表示矩阵a",{"2":{"992":1}}],["来表示另一个数据集的tokens",{"2":{"757":1}}],["来表示第i块gpu",{"2":{"446":1}}],["来表示n个样本的小批量",{"2":{"232":1}}],["来了解编译",{"2":{"426":1}}],["来注入绝对的或相对的位置信息",{"2":{"398":1,"401":1}}],["来注释一个句子",{"2":{"295":1}}],["来变换查询",{"2":{"380":1}}],["来支付的",{"2":{"354":1}}],["来计算在时间步t",{"2":{"574":1}}],["来计算输出类别的概率分布",{"2":{"339":1}}],["来计算时间步t处的任何时间的隐状态",{"2":{"338":1}}],["来改善困惑度",{"2":{"337":1}}],["来将这些单词组合指定为非零计数",{"2":{"316":1}}],["来传递",{"2":{"315":1}}],["来自家人的邮件或者是有关兴趣爱好的邮件",{"2":{"1112":1}}],["来自朋友的邮件",{"2":{"1112":1}}],["来自于一个",{"2":{"1089":1}}],["来自三个值",{"2":{"1088":1}}],["来自卡内基梅隆大学",{"2":{"1059":1}}],["来自一台机器上的所有的本地gpu的梯度聚合在一个gpu上",{"2":{"843":1}}],["来自大型语料库的大量罕见事件往往被交叉熵损失建模",{"2":{"742":1}}],["来自bertencoder的正向推断encoded",{"2":{"736":1}}],["来自语言模型的嵌入",{"2":{"731":1}}],["来自语义文本相似性基准数据集的样本包括",{"2":{"658":1}}],["来自transformers的双向编码器表示",{"0":{"730":1},"1":{"731":1,"732":1,"733":1,"734":1,"735":1,"736":1,"737":1,"738":1,"739":1,"740":1},"2":{"733":1}}],["来自多个源的加权输入以加权和y=∑ixiwi+b的形式汇聚在细胞核中",{"2":{"619":1}}],["来自训练数据集的输出序列y1",{"2":{"574":1}}],["来自xt的信息基本上被忽略",{"2":{"542":1}}],["来自两个相邻的",{"2":{"320":2}}],["来自nec实验室和伊利诺伊大学香槟分校的研究人员获得了28",{"2":{"301":1}}],["来自哪里",{"2":{"297":1}}],["来自所有先前层",{"2":{"131":1}}],["来训练一个筛选简历的模型",{"2":{"284":1}}],["来训练模型",{"2":{"191":1}}],["来控制只允许猫进入",{"2":{"195":1}}],["来演示汇聚层中填充和步幅的使用",{"2":{"147":1}}],["来补偿5×5卷积核导致的特征减少",{"2":{"136":1}}],["来",{"2":{"128":1,"351":1,"852":1,"932":1}}],["来实现addnorm类",{"2":{"406":1}}],["来实现的",{"2":{"300":1}}],["来实现",{"2":{"80":1,"1086":1}}],["来有效管理",{"2":{"66":1}}],["来迭代x",{"2":{"54":1}}],["来得到一个简化得多的问题",{"2":{"26":1}}],["⪅f",{"2":{"54":1}}],["η表示学习率",{"2":{"613":1}}],["ηλ",{"2":{"95":2}}],["η",{"2":{"95":2}}],["ηt2∥∂xf",{"2":{"115":1}}],["ηt是当t时的目标学习率",{"2":{"72":1}}],["ηt=ηt+η0−ηt2",{"2":{"72":1}}],["ηt⋅α",{"2":{"70":1}}],["ηmin",{"2":{"70":1}}],["η2f",{"2":{"54":1,"55":1}}],["η是学习率",{"2":{"27":1}}],["将接收的value值赋给input元素的value属性",{"2":{"1500":1}}],["将外部请求转发到内部服务器",{"2":{"1361":1}}],["将请求分发到对应",{"2":{"1208":1}}],["将对你学习算法的性能有很大的影响",{"2":{"1187":1}}],["将对这些企业的有实质性和直接的影响",{"2":{"1187":1}}],["将新剪裁的切片按比例缩小至模型所采纳的尺寸",{"2":{"1172":1}}],["将新剪裁的切片也交给模型进行判断",{"2":{"1172":1}}],["将图片上的文字与其他环境对象分离开来",{"2":{"1171":1}}],["将图像增广应用于训练集",{"2":{"883":1}}],["将图像裁剪成标准尺寸是一种方法",{"2":{"284":1}}],["将图像错误地分到某一类别可能被视为种族歧视",{"2":{"201":1}}],["将后面的维数省去",{"2":{"1158":1}}],["将后面这个式子",{"2":{"1110":1}}],["将开始讨论如何利用支持向量机的原理",{"2":{"1145":1}}],["将θ2​",{"2":{"1145":1}}],["将u投影到v上",{"2":{"1145":1}}],["将负号移到了表达式的里面",{"2":{"1143":1}}],["将神经网络的分类定义为两种情况",{"2":{"1120":1}}],["将神经网络堆叠在一起",{"2":{"492":1}}],["将构建的",{"2":{"1109":1}}],["将该组所关联的中心点移动到平均值的位置",{"2":{"1151":1}}],["将该目录添加到octave的搜索路径",{"2":{"1092":1}}],["将该用户id与商品id关联起来",{"2":{"281":1}}],["将多条命令例如imagesc",{"2":{"1091":1}}],["将多输入",{"2":{"681":1}}],["将显示第一张图",{"2":{"1091":2}}],["将显示实现该函数的python代码",{"2":{"1007":1}}],["将返回2",{"2":{"1089":1}}],["将返回3",{"2":{"1089":1}}],["将返回两个句子字符串的列表",{"2":{"724":1}}],["将向量表达形式转为矩阵表达形式",{"2":{"1086":1}}],["将解决不可逆性的问题",{"2":{"1086":1}}],["将结果存储为32位浮点数以进行除法",{"2":{"1026":1}}],["将概率分配给一些离散选择的分布称为多项分布",{"2":{"1026":1}}],["将本节中的条件语句x",{"2":{"1024":1}}],["将大小为1的张量转换为python标量",{"2":{"1022":1}}],["将深度学习框架定义的张量",{"2":{"1022":2}}],["将深度学习应用于强化学习的问题",{"2":{"298":1}}],["将计算封装在tensorflow图中",{"2":{"1021":1}}],["将预处理后的数据集转换为张量格式",{"2":{"1015":1}}],["将预测为1的区域和预测为",{"2":{"1108":1}}],["将预测偏移量用到的l1范数损失替换为平滑l1范数损失",{"2":{"966":1}}],["将预测类别与真实y元素进行比较",{"2":{"634":1}}],["将预测保存在csv文件中可以简化将结果上传到kaggle的过程",{"2":{"213":1}}],["将张量乘以或加上一个标量不会改变张量的形状",{"2":{"994":1}}],["将两个向量规范化得到单位长度后",{"2":{"997":1}}],["将两个相同形状的矩阵相加",{"2":{"994":1}}],["将两个求和结果的连结送到多层感知机中",{"2":{"676":3}}],["将某些计算移动到记录的计算图之外",{"2":{"976":1}}],["将通过对y中的元素求和来创建",{"2":{"975":1}}],["将通道维度视为不同特征",{"2":{"494":1}}],["将能够通过",{"2":{"974":1}}],["将步幅从1更改为2会增加中间张量的高和权重",{"2":{"969":1}}],["将voc标签中的rgb值映射到它们的类别索引",{"2":{"945":3}}],["将单发多框检测与本节介绍的方法进行比较",{"2":{"942":1}}],["将单词映射到实向量的技术称为词嵌入",{"2":{"780":1}}],["将全连接层的输出分别转换为形状为n×q",{"2":{"938":1}}],["将卷积神经网络的输出和提议区域作为输入",{"2":{"938":1}}],["将卷积神经网络的输出的形状记为1×c×h1×w1",{"2":{"938":1}}],["将会是非常小的数",{"2":{"1145":1}}],["将会是什么呢",{"2":{"1145":1}}],["将会等于p",{"2":{"1145":1}}],["将会由这一项表示",{"2":{"1143":1}}],["将会涉及更多复杂的命令",{"2":{"1088":1}}],["将会生成大小为s",{"2":{"912":1}}],["将会在反向传播过程中产生长度为o",{"2":{"334":1}}],["将超参数设为batch",{"2":{"898":1}}],["将包含原始图像文件的数据集组织为所需格式后",{"2":{"897":1}}],["将文字分割成一个个单一的字符",{"2":{"1171":1}}],["将文件复制到目标目录",{"2":{"890":1}}],["将文本转换为预训练数据集",{"0":{"722":1}}],["将文本转换为数字索引序列",{"2":{"360":1}}],["将文本字符与更长的笔迹对齐",{"2":{"373":1}}],["将文本词元为单词和更改vocab实例的min",{"2":{"366":1}}],["将文本词元化为字符而不是单词",{"2":{"341":1}}],["将文本行拆分为单词或字符词元",{"2":{"362":1}}],["将文本作为字符串加载到内存中",{"2":{"360":1}}],["将验证集从原始的训练集中拆分出来",{"2":{"890":2}}],["将从源数据集学到的知识迁移到目标数据集",{"2":{"869":1}}],["将特定的路径",{"2":{"1486":1}}],["将特定的梯度值从工作节点发送到公共存储",{"2":{"844":1}}],["将特征图的高度和宽度减小一半",{"2":{"912":2}}],["将特征图的高度和宽度增加32倍",{"2":{"862":1}}],["将边界框",{"2":{"858":1}}],["将边界框在图中画出",{"2":{"858":1}}],["将非极大值抑制应用于预测边界框",{"2":{"854":1}}],["将类标签和分配的边界框坐标初始化为零",{"2":{"852":3}}],["将类别特征转化为指标特征",{"2":{"214":1}}],["将最接近的真实边界框分配给锚框",{"2":{"851":3}}],["将真实边界框分配给锚框",{"0":{"851":1}}],["将锚框变量y的形状更改为",{"2":{"848":1}}],["将共生成wh",{"2":{"848":1}}],["将x和y拆分到多个设备上",{"2":{"836":3}}],["将x变形为",{"2":{"375":3}}],["将一个响应式对象中的每一个属性",{"2":{"1459":1}}],["将一个小批量数据均匀地分布在多个gpu上",{"2":{"836":1}}],["将一些英语句子翻译成法语",{"2":{"409":1}}],["将k个gpu中的局部梯度聚合",{"2":{"833":1}}],["将k设置为其他值",{"2":{"779":1}}],["将问题分散到4个gpu",{"2":{"832":1}}],["将问题和段落分别作为第一个和第二个文本序列",{"2":{"660":1}}],["将流程编译成可执行的程序",{"2":{"817":1}}],["将命中参数装入缓存后",{"2":{"814":1}}],["将算法与硬件相匹配",{"2":{"814":1}}],["将12个流式多处理器分组为图形处理集群",{"2":{"811":1}}],["将信息写回主内存",{"2":{"810":1}}],["将内存访问模式保持在本地也是提高性能的一个好方法",{"2":{"810":1}}],["将cpu与大多数组件",{"2":{"801":1}}],["将ci的结果相加",{"2":{"120":1}}],["将mxnet管理的内存转换到python将迫使后端等待特定变量就绪",{"2":{"793":1}}],["将moving",{"2":{"472":2}}],["将来也是不太可能改变的",{"2":{"789":1}}],["将来自上一个时间步的预测得到的词元作为解码器的当前输入",{"2":{"576":1}}],["将噪声词w的采样概率p",{"2":{"775":1}}],["将随机选择15",{"2":{"736":1}}],["将随时间被保存并传递到当前时间步",{"2":{"555":1}}],["将bert输入序列的最大长度设置为512",{"2":{"729":1}}],["将bert输入序列的最大长度设置为64",{"2":{"722":1}}],["将bidirectional设置为true以获取双向循环神经网络",{"2":{"713":2}}],["将批量大小从b更改为k⋅b",{"2":{"839":1}}],["将批量大小设置为512",{"2":{"722":1}}],["将批量大小减少到10",{"2":{"80":1}}],["将用于生成两个预训练任务的训练样本的辅助函数和用于填充输入的辅助函数放在一起",{"2":{"722":1}}],["将用于初始化下一个小批量数据第一个样本的隐状态",{"2":{"335":1}}],["将词映射到实向量的技术称为词嵌入",{"2":{"787":1}}],["将词表中的所有单词分别作为中心词和上下文词使用",{"2":{"766":1}}],["将词替换为",{"2":{"721":1}}],["将词元列表展平成一个列表",{"2":{"363":1}}],["将此单一文本表示转换为输出类别",{"2":{"713":1}}],["将此对截断方法与snlibertdataset类中使用的方法进行比较",{"2":{"690":1}}],["将此应用于上述问题",{"2":{"64":1}}],["将num",{"2":{"690":1}}],["将与另一个序列中的词元进行比较",{"2":{"675":1}}],["将假设中的",{"2":{"674":1}}],["将序列长度设置为50",{"2":{"669":1}}],["将序列从一种语言自动翻译成另一种语言",{"2":{"564":1}}],["将被选择来控制行驶方向",{"2":{"1127":1}}],["将被弃用",{"2":{"1047":1}}],["将被附加到较短的序列后",{"2":{"668":1}}],["将被一个两层的感知机转换成形状为",{"2":{"405":1}}],["将snli数据集解析为前提",{"2":{"667":1}}],["将direction设置为",{"2":{"713":1}}],["将d个输入转换为q个输出的成本可以减少到o",{"2":{"642":1}}],["将dropout和relu应用于lenet",{"2":{"465":1}}],["将展平每个图像",{"2":{"630":1}}],["将有接近零的值",{"2":{"624":1}}],["将有k个特征值",{"2":{"102":1}}],["将损失关于w的导数设为0",{"2":{"612":1}}],["将明显大于使用字符级词元化时的词表大小",{"2":{"570":1}}],["将机器翻译的文本序列转换成小批量",{"2":{"568":1}}],["将机器学习应用于这些问题的关键部分是提出人工设计的特征工程方法",{"2":{"302":1}}],["将lth隐藏层",{"2":{"527":1}}],["将前提中的",{"2":{"674":1}}],["将前向隐状态h→t",{"2":{"521":1}}],["将前几个单词作为例外消除后",{"2":{"318":1}}],["将得出",{"2":{"519":1,"1090":1}}],["将得到与键对应的值的概率分布",{"2":{"367":1}}],["将得到与互相关运算",{"2":{"130":1}}],["将得到初始化值域",{"2":{"247":1}}],["将在学习经验e后得到提高",{"2":{"1059":1}}],["将在以下路径中找到整个数据集",{"2":{"901":1}}],["将在",{"2":{"513":1,"913":1}}],["将在实际输出中丢弃",{"2":{"512":1}}],["将它保存一下",{"2":{"1094":1}}],["将它们转换成小批量的样本",{"2":{"776":1}}],["将它们替换为全局平均汇聚层",{"2":{"497":1}}],["将它一次应用于一个小批量的数据",{"2":{"239":1}}],["将四维的输出转成二维的输出",{"2":{"495":4}}],["将现代深度学习的实践比作炼金术",{"2":{"475":1}}],["将训练好的模型用于预测时",{"2":{"471":1}}],["将训练数据集变换为键和值",{"2":{"392":1}}],["将提取的特征送入最喜欢的分类器中",{"2":{"454":1}}],["将触发全局解释器锁",{"2":{"452":1}}],["将触发运行时错误",{"2":{"418":1}}],["将输出层finetune",{"2":{"876":1}}],["将输出图像的坐标",{"2":{"863":1}}],["将输出向量除以2",{"2":{"425":1}}],["将输入值转换到区间",{"2":{"540":1}}],["将输入添加到输出",{"2":{"501":1}}],["将输入直接加在最后的relu激活函数前",{"2":{"501":1}}],["将输入数据作为其前向传播函数的参数",{"2":{"423":2}}],["将抛出一个错误",{"2":{"418":1}}],["将影响每个后续层的维数",{"2":{"417":1}}],["将层作为组件合并到更复杂的模型中",{"2":{"413":1}}],["将逐行呈现两层多头注意力的权重",{"2":{"409":1}}],["将比较的是卷积神经网络",{"2":{"397":1}}],["将高斯核代入",{"2":{"388":1}}],["将高度和宽度的步幅设置为2",{"2":{"142":1}}],["将查询x和键xi之间的关系建模为",{"2":{"388":1}}],["将查询和键连结起来后输入到一个多层感知机",{"2":{"369":1}}],["将第一项",{"2":{"382":4}}],["将几个英语句子翻译成法语",{"2":{"376":1,"578":1}}],["将作为初始化解码器的隐状态",{"2":{"375":1}}],["将作为注意力的键和值",{"2":{"375":1}}],["将遵循",{"2":{"374":1}}],["将注意力汇聚的输出计算可以作为值的加权平均",{"2":{"371":1}}],["将注意力机制与全连接层或汇聚层区别开来",{"2":{"356":1}}],["将每一个用户对某一部电影的评分减去所有用户对该电影评分的平均值",{"2":{"1192":1}}],["将每一行除以其规范化常数",{"2":{"631":1}}],["将每一条文本行转换成一个数字索引列表",{"2":{"363":1}}],["将每个数据样本作为矩阵中的行向量更为常见",{"2":{"992":1}}],["将每个提议区域的特征连同其标注的边界框作为一个样本",{"2":{"937":1}}],["将每个提议区域的特征连同其标注的类别作为一个样本",{"2":{"937":1}}],["将每个提议区域变形为网络需要的输入尺寸",{"2":{"937":1}}],["将每个gpu的所有梯度相加",{"2":{"837":3}}],["将每个单词作为一个词元",{"2":{"693":1}}],["将每个通道的高和宽变成1",{"2":{"488":1}}],["将每个块的输出作为下一个块的输入",{"2":{"422":3}}],["将每个block的输出作为输入传递给下一层",{"2":{"422":1}}],["将每个索引映射为相互不同的单位向量",{"2":{"330":1}}],["将时间机器数据集加载到文本行的列表中",{"2":{"361":1}}],["将拆分的词元映射到数字索引",{"2":{"360":1}}],["将字符串拆分为词元",{"2":{"360":1}}],["将选择引导至感官输入",{"2":{"356":1}}],["将ptb数据集加载到文本行的列表中",{"2":{"772":1}}],["将p",{"2":{"349":1,"1180":1}}],["将h乘以w",{"2":{"340":1}}],["将参与计算下一时间步t+1的隐状态ht+1",{"2":{"340":1}}],["将拼接的结果送入带有激活函数ϕ的全连接层",{"2":{"340":1}}],["将隐藏变量h用作输出层的输入",{"2":{"339":1}}],["将导致隐状态初始化的差异",{"2":{"335":1}}],["将导致x的更新非常缓慢",{"2":{"55":1}}],["将上采样的结果记作y",{"2":{"863":1}}],["将上面的两个采样函数包装到一个类中",{"2":{"321":1}}],["将上述算法应用到一个带有四个锚框的具体示例中",{"2":{"854":1}}],["将上述算法应用于多个目标函数",{"2":{"64":1}}],["将上述展开除以f",{"2":{"60":1}}],["将以梯度爆炸或梯度消失的形式表现",{"2":{"313":1}}],["将数据与视图绑定",{"2":{"1527":1}}],["将数据从三维降至二维",{"2":{"1156":1}}],["将数据从二维降至一维",{"2":{"1156":1}}],["将数据读入计算机后对其进行处理",{"2":{"1016":1}}],["将数据传递到模型之前",{"2":{"632":1}}],["将数据集读取到由多条文本行组成的列表中",{"2":{"361":1}}],["将数据集缓存在本地目录",{"2":{"206":1}}],["将数据映射为数据对yt=xt",{"2":{"350":1}}],["将数据转换为某种适合于浅层模型的形式",{"2":{"302":1}}],["将resnet",{"2":{"300":1}}],["将观察大小提高到64000个",{"2":{"300":1}}],["将拥有最短和最长脚的两个人送走",{"2":{"299":1}}],["将打开一整套新的建模问题",{"2":{"297":1}}],["将详细阐述",{"2":{"291":1}}],["将之前没有见过的样本特征放到这个",{"2":{"289":1}}],["将是样本的标签",{"2":{"289":1}}],["将权重衰减集成到优化算法中",{"2":{"278":1}}],["将权重βi代入到每个数据样本",{"2":{"191":1}}],["将原来的训练目标最小化训练标签上的预测损失",{"2":{"270":1}}],["将这个模型记作",{"2":{"1112":1}}],["将这个图例放在右上方",{"2":{"1091":1}}],["将这多条命令写在同一行中",{"2":{"1091":1}}],["将这h个注意力汇聚的输出拼接在一起",{"2":{"380":1}}],["将这些用户的电影评分",{"2":{"1191":1}}],["将这些值存储于一个近似梯度矩阵中",{"2":{"1124":1}}],["将这些复杂的步骤梳理了一遍",{"2":{"1122":1}}],["将这些操作在octave中熟练运用",{"2":{"1088":1}}],["将这些展开式结合到多层感知机中",{"2":{"479":1}}],["将这些索引直接输入神经网络可能会使学习变得困难",{"2":{"330":1}}],["将这些张量ci连结在一起可以得到形状为ci×kh×kw的卷积核",{"2":{"120":1}}],["将这一理论扩展到更一般种类的函数",{"2":{"253":1}}],["将倾向于总是预测多数类",{"2":{"252":1}}],["将模型参数分配给用于计算的cpu或gpu",{"2":{"905":2}}],["将模型参数复制到num",{"2":{"837":3}}],["将模型设置为训练模式",{"2":{"635":2}}],["将模型设置为评估模式",{"2":{"634":2}}],["将模型的输入和参数同模型的输出关联起来",{"2":{"602":1}}],["将模型的参数存储在一个叫做",{"2":{"442":1}}],["将模型保存下来",{"2":{"429":1}}],["将模型读写到磁盘",{"2":{"421":1}}],["将模型在训练数据上拟合的比在潜在分布中更接近的现象称为过拟合",{"2":{"251":1}}],["将模型拟合各种数据集",{"2":{"179":1}}],["将a的一个副本分配给b",{"2":{"994":3}}],["将alexnet",{"2":{"491":1}}],["将alexnet直接应用于fashion",{"2":{"462":1}}],["将a23代入到σ2的条件中",{"2":{"247":1}}],["将adadelta的收敛行为与adagrad和rmsprop进行比较",{"2":{"23":1}}],["将迭代周期数设置为10",{"2":{"221":1}}],["将实值数据重新缩放为零均值和单位方法",{"2":{"214":1}}],["将网络应用于测试集",{"2":{"213":1}}],["将小于1的值设置为1",{"2":{"210":4}}],["将小批量随机梯度下降与实际从训练集中取样替换的变体进行比较",{"2":{"83":1}}],["将",{"2":{"209":1,"647":1,"690":1,"1077":1}}],["将所有输入的图像和标签读入内存",{"2":{"945":1}}],["将所有梯度发送到服务器所需的时间是o",{"2":{"843":1}}],["将所有通道上的结果相加以产生一维输出张量",{"2":{"699":1}}],["将所有目标值视为单个向量",{"2":{"621":1}}],["将所有数据视为单个矩阵",{"2":{"621":1}}],["将所有数字除以255",{"2":{"584":1}}],["将所有特征放到向量x∈rd中",{"2":{"610":1}}],["将所有词元的损失乘以掩码",{"2":{"575":1}}],["将所有时间步的隐状态转换为上下文变量",{"2":{"573":1}}],["将所有功能打包到load",{"2":{"364":1}}],["将所有缺失的值替换为相应特征的平均值",{"2":{"209":1}}],["将所学知识付诸实践",{"2":{"205":1}}],["将游戏渲染引擎中的合成数据用作额外的训练数据",{"2":{"186":1}}],["将暂退概率作为唯一的参数传递给它的构造函数",{"2":{"176":1}}],["将剩余部分除以1",{"2":{"172":1}}],["将中间变量z∈rh通过激活函数ϕ后",{"2":{"162":1}}],["将减少到200×200像素",{"2":{"140":1}}],["将平均汇聚层替换为最大汇聚层",{"2":{"139":1}}],["将互相关运算表示为矩阵乘法",{"2":{"133":1}}],["将weight和bias声明为两个模型参数",{"2":{"127":1}}],["将如何更改随机梯度下降求解器",{"2":{"118":1}}],["将不等式",{"2":{"115":1}}],["将其调节更新到最新的用户行为",{"2":{"1168":1}}],["将其用于减少过拟合",{"2":{"1162":1}}],["将其与距离最近的中心点关联起来",{"2":{"1151":1}}],["将其与y​中的实际数据进行比较",{"2":{"1120":1}}],["将其写入我们的优化目标",{"2":{"1145":1}}],["将其分成3个二元分类问题",{"2":{"1112":1}}],["将其作为实例加入到我们的训练集中来",{"2":{"1107":1}}],["将其重新接到一个动物的大脑上",{"2":{"1098":1}}],["将其重新格式化以导出到kaggle",{"2":{"213":1}}],["将其中3个gpu的梯度发送到第4个gpu上需要30毫秒",{"2":{"841":1}}],["将其扩展到两个以上的数字",{"2":{"655":1}}],["将其转换为固定形状的隐状态",{"2":{"572":1}}],["将其应用于",{"2":{"485":1}}],["将其传输回环境",{"2":{"298":1}}],["将其视为二项分类问题可能没有多大意义",{"2":{"292":1}}],["将其代入不等式",{"2":{"115":1}}],["将其代入泰勒展开式我们可以得到",{"2":{"54":1}}],["将其设置为0",{"2":{"91":1}}],["将其减半至β=0",{"2":{"88":1}}],["将列向量c",{"2":{"77":1}}],["将余弦调度器应用于大型计算机视觉问题",{"2":{"75":1}}],["将学习率设置为η=η0",{"2":{"68":1}}],["得到countstore",{"2":{"1492":1}}],["得到参数",{"2":{"1180":1}}],["得到更好的决策界",{"2":{"1144":1}}],["得到svm",{"2":{"1143":1}}],["得到大量的数据并在某种类型的学习算法中进行训练",{"2":{"1141":1}}],["得到代价函数",{"2":{"1117":1}}],["得到正弦函数",{"2":{"1091":1}}],["得到a中每一个元素的倒数",{"2":{"1090":1}}],["得到每一个元素的倒数",{"2":{"1090":1}}],["得到每个样本的规范化常数",{"2":{"631":1}}],["得到这样一个3×2矩阵",{"2":{"1090":1}}],["得到我们之前构建的矩阵",{"2":{"1089":1}}],["得到我们想要的任意形状的独立样本数组",{"2":{"1026":1}}],["得到相应答案",{"2":{"1088":1}}],["得到y=x",{"2":{"976":1}}],["得到vi",{"2":{"784":1}}],["得到了我们赋值给y的标量输出",{"2":{"974":1}}],["得到了",{"2":{"744":1}}],["得到了x=0处的全局最小值",{"2":{"59":1}}],["得到解析解",{"2":{"612":1}}],["得到在时间步t的候选隐状态",{"2":{"541":1}}],["得到一个",{"2":{"348":1}}],["得到一个梯度",{"2":{"244":1}}],["得到现在等于1英尺的估计值",{"2":{"299":1}}],["得到后验",{"2":{"280":1}}],["得到平均模型输出μ",{"2":{"192":1}}],["得到d次导数的最小核的大小是多少",{"2":{"133":1}}],["得到的训练集图片被压缩为30x32像素",{"2":{"1127":1}}],["得到的结果就是这些非负的元素",{"2":{"1090":1}}],["得到的结果是总共需要60毫秒",{"2":{"841":1}}],["得到的是m×1的向量",{"2":{"1074":1}}],["得到的统计结果称之为语料",{"2":{"363":1}}],["得到的张量再求和得到一个单一的标量值",{"2":{"126":1}}],["得到的解就会振荡",{"2":{"58":1}}],["得到二维张量",{"2":{"120":1}}],["得到",{"2":{"60":1,"115":1,"312":1}}],["得出梯度下降算法为",{"2":{"1117":1}}],["得出的结果是",{"2":{"1089":1}}],["得出",{"2":{"54":1,"57":1,"555":1}}],["得多",{"2":{"26":1}}],["利用类型检查和自动补全",{"2":{"1436":1}}],["利用已有的数据",{"2":{"1173":1}}],["利用神经网络",{"2":{"1172":1}}],["利用k",{"2":{"1151":1}}],["利用数值检验方法检验这些偏导数",{"2":{"1126":1}}],["利用反向传播方法计算所有偏导数",{"2":{"1126":1}}],["利用反向传播给出的梯度来更新模型参数",{"2":{"165":1}}],["利用正向传播方法计算所有的hθ",{"2":{"1126":1}}],["利用训练集的结果与神经网络预测的结果求出最后一层的误差",{"2":{"1121":1}}],["利用训练好的循环神经网络",{"2":{"578":1}}],["利用这些方法",{"2":{"1111":1}}],["利用这一事实",{"2":{"348":1}}],["利用向量化的方法会使得计算更为简便",{"2":{"1100":1}}],["利用计算图",{"2":{"795":1}}],["利用来自大型语料库的现有文本序列",{"2":{"754":1}}],["利用当时不同任务的不同最佳模型",{"2":{"731":1}}],["利用",{"2":{"725":1,"1146":1,"1313":1}}],["利用预定义的bert输入序列的最大长度",{"2":{"687":1}}],["利用softmax的定义",{"2":{"647":1}}],["利用test",{"2":{"635":1}}],["利用高性能计算来避免减慢训练过程",{"2":{"585":1}}],["利用残差块",{"2":{"504":1}}],["利用谷歌图像搜索",{"2":{"456":1}}],["利用机器学习算法",{"2":{"282":1}}],["利用链式法则",{"2":{"164":1}}],["利用泰勒展开",{"2":{"54":1}}],["利用上面的引理和一维情况的结果",{"2":{"46":1}}],["考虑成1",{"2":{"1143":1}}],["考虑输出和输入同一空间坐标",{"2":{"954":1}}],["考虑下面的思维试验",{"2":{"842":1}}],["考虑下面这段简单的命令式程序",{"2":{"816":1}}],["考虑下面这个回归问题",{"2":{"386":1}}],["考虑另一种选择符号式编程",{"2":{"817":1}}],["考虑最坏的情况",{"2":{"810":1}}],["考虑最大化联合概率",{"2":{"708":1}}],["考虑以下情况",{"2":{"810":1}}],["考虑上下文窗口中的词",{"2":{"773":1}}],["考虑词wi可能在语料库中出现多次",{"2":{"742":1}}],["考虑1个",{"2":{"720":1}}],["考虑相对于任何未规范化的预测oj的导数",{"2":{"647":1}}],["考虑对数的定义域",{"2":{"638":1}}],["考虑对掷硬币的结果",{"2":{"252":1}}],["考虑由一个序列组成的样本",{"2":{"573":1}}],["考虑由两个2×4矩阵表示的样本",{"2":{"368":1}}],["考虑",{"2":{"297":1,"397":1,"727":1,"1109":1}}],["考虑高维输入可能发生的情况",{"2":{"269":1}}],["考虑多项式的模型选择",{"2":{"268":1}}],["考虑数据集",{"2":{"252":1}}],["考虑28×28的灰度图像",{"2":{"252":1}}],["考虑预测性警务系统",{"2":{"201":1}}],["考虑到这是一个三行两列的矩阵",{"2":{"1088":1}}],["考虑到自然语言中丰富的多义现象和复杂的语义",{"2":{"731":1}}],["考虑到数据和计算的稀缺性",{"2":{"299":1}}],["考虑到环境",{"0":{"200":1}}],["考虑到h可能非常大",{"2":{"59":1}}],["考虑一段话",{"2":{"660":1}}],["考虑一下由不同的语言模型给出的对",{"2":{"342":1}}],["考虑一下我们用于读取长序列的随机偏移量",{"2":{"323":1}}],["考虑一下区分猫和狗的问题",{"2":{"181":1}}],["考虑一个随机变量x",{"2":{"1028":1}}],["考虑一个具有形状",{"2":{"1004":1}}],["考虑一个具有l层",{"2":{"241":1}}],["考虑一个如",{"2":{"841":1}}],["考虑一个极端情况",{"2":{"538":1}}],["考虑一个卷积核大小为k的卷积层",{"2":{"397":1}}],["考虑一个相对简单的状况",{"2":{"356":1}}],["考虑一个简单问题",{"2":{"790":3}}],["考虑一个简单地使用查表法来回答问题的模型",{"2":{"252":1}}],["考虑一个简单的mlp",{"2":{"105":1}}],["考虑一个二元分类问题",{"2":{"180":1}}],["考虑一类连续可微实值函数f",{"2":{"54":1}}],["考虑这个函数f",{"2":{"102":2}}],["考虑这个函数",{"2":{"94":1}}],["考虑函数f",{"2":{"56":1}}],["考虑同一优化问题中η=0",{"2":{"55":1}}],["考虑两个不相交的集合x∩y=∅",{"2":{"40":1}}],["还会在控制台中发出警告",{"2":{"1515":1}}],["还需要编写一个不写setup的script标签",{"2":{"1454":1}}],["还需要更深入的知识",{"2":{"65":1}}],["还支持",{"2":{"1394":1}}],["还愿意花时间来研究那些编程练习",{"2":{"1176":1}}],["还要",{"2":{"1533":1}}],["还要让更多的人生活得更加美好",{"2":{"1176":1}}],["还要保证数据的特性损失最小",{"2":{"1158":1}}],["还要区分不同的目标实例",{"2":{"944":1}}],["还列出了变量的维度",{"2":{"1089":1}}],["还知道对应患者的年龄",{"2":{"1060":1}}],["还通过额外的全卷积网络预测目标的像素级位置",{"2":{"940":1}}],["还包括区域提议网络中锚框的二元类别和边界框预测",{"2":{"939":1}}],["还想得到它们在图像中的具体位置",{"2":{"857":1}}],["还请注意",{"2":{"833":1}}],["还在",{"2":{"831":1}}],["还在小批量的随机梯度上使用ewma",{"2":{"36":1}}],["还解释了其原理",{"2":{"475":1}}],["还可以键入",{"2":{"1089":1}}],["还可以设置地更复杂",{"2":{"1088":1}}],["还可以一个gpu对一个gi",{"2":{"841":1}}],["还可以并行地",{"2":{"798":1}}],["还可以计算两个二元分类的交叉熵损失",{"2":{"737":1}}],["还可以在测试数据上的评估来判断过拟合",{"2":{"256":1}}],["还可能发生什么其它的情况呢",{"2":{"518":1}}],["还可能是一个单词",{"2":{"364":1}}],["还适用于其他n元语法",{"2":{"322":1}}],["还增加一个验证数据集",{"2":{"256":1}}],["还能想到其他领域的应用吗",{"2":{"951":1}}],["还能想出其他什么方法来处理过拟合",{"2":{"280":1}}],["还能识别它们的位置",{"2":{"859":1}}],["还能同时受益于简单且可重复的设计选择",{"2":{"832":1}}],["还能够将大多数程序转换为符号式程序",{"2":{"818":1}}],["还能够执行给定的程序",{"2":{"801":1}}],["还能够高效地计算",{"2":{"134":1}}],["还能设计出其他神经网络可能会表现出对称性且需要被打破的情况吗",{"2":{"250":1}}],["还有成千上万的开源组件和插件",{"2":{"1538":1}}],["还有很多其它的",{"2":{"1187":1}}],["还有很多的方式来生成矩阵",{"2":{"1088":1}}],["还有评价学习算法比较实用的训练集",{"2":{"1176":1}}],["还有更好的方法构造",{"2":{"1146":1}}],["还有更多的选择",{"2":{"114":1}}],["还有像有很多特征变量的问题",{"2":{"1130":1}}],["还有定义的函数体",{"2":{"1092":1}}],["还有几个命令",{"2":{"1091":1}}],["还有自然数e的幂次运算",{"2":{"1090":1}}],["还有异或运算",{"2":{"1088":1}}],["还有另一种最常见的监督学习方式",{"2":{"1063":1}}],["还有市场分割",{"2":{"1061":1}}],["还有第三类",{"2":{"1061":1}}],["还有层之间的接口需要大量的数据传输的时候",{"2":{"832":1}}],["还有",{"2":{"811":1,"1090":2}}],["还有模型本身",{"2":{"620":1}}],["还有哪些其他数据集可用",{"2":{"586":1}}],["还有其他一些特别的应用",{"2":{"1176":1}}],["还有其他一些算法",{"2":{"1111":1}}],["还有其他的代价函数也能很好地发挥作用",{"2":{"1064":1}}],["还有其他方法来应对循环神经网络中的梯度爆炸吗",{"2":{"314":1}}],["还有其它可以适用于",{"2":{"537":1}}],["还有个明显的问题是词频衰减的速度相当地快",{"2":{"318":1}}],["还有一种基于内存的学习算法",{"2":{"1141":1}}],["还有一种更高级的功能",{"2":{"1092":1}}],["还有一些更好的方式来选择k",{"2":{"1160":1}}],["还有一些常被用来令代价函数最小的算法",{"2":{"1109":1}}],["还有一些离奇的例子",{"2":{"1098":1}}],["还有一些有用的函数",{"2":{"1090":1}}],["还有一些其他的特征",{"2":{"1060":1}}],["还有一些解决方案要求我们完全跳出统计预测",{"2":{"179":1}}],["还有一个更加强大的算法广泛的应用于工业界和学术界",{"2":{"1143":1}}],["还有一个更微妙的问题",{"2":{"1067":1}}],["还有一个技巧",{"2":{"1090":1}}],["还有一个小技巧",{"2":{"1089":1}}],["还有一个关键问题",{"2":{"804":1}}],["还有一个由系统用来执行计算的后端",{"2":{"790":3}}],["还有一个问题",{"2":{"660":1}}],["还有一头驴",{"2":{"292":1}}],["还有什么会影响经验风险接近真实风险的程度",{"2":{"203":1}}],["还有什么因素会影响输出的大小呢",{"2":{"140":1}}],["还有许多优化变体可以执行周期性学习率调整",{"2":{"66":1}}],["还是喜欢解决技术难题",{"2":{"1541":1}}],["还是简洁设计",{"2":{"1536":1}}],["还是追求极致开发效率的资深开发者",{"2":{"1531":1}}],["还是开发应用",{"2":{"1305":1}}],["还是自动生成",{"2":{"1301":1}}],["还是想进入数据科学",{"2":{"1295":1}}],["还是可行的",{"2":{"1153":1}}],["还是等于0",{"2":{"1143":1}}],["还是更关心第二项的优化",{"2":{"1143":1}}],["还是更麻烦一点",{"2":{"1088":1}}],["还是保证正则参数足够小",{"2":{"1143":1}}],["还是有一些人会在测试集上来做误差分析",{"2":{"1138":1}}],["还是让它变得更坏",{"2":{"1138":1}}],["还是其他选择",{"2":{"1138":1}}],["还是别的什么",{"2":{"1138":1}}],["还是别的语言",{"2":{"1093":1}}],["还是逻辑回归问题",{"2":{"1117":1}}],["还是应用到那些你可能会感兴趣的问题中",{"2":{"1098":1}}],["还是那个矩阵",{"2":{"1089":1}}],["还是回归问题",{"2":{"1060":1}}],["还是因为自动化技术",{"2":{"1058":1}}],["还是智能滤波器",{"2":{"886":1}}],["还是鸡",{"2":{"639":1}}],["还是绿色",{"2":{"518":1}}],["还是探索新的策略空间",{"2":{"298":1}}],["还是随着时间的推移会发生变化",{"2":{"297":1}}],["还是",{"2":{"64":1,"1060":1,"1112":1}}],["还考虑它的曲率的二阶方法可以帮我们解决这个问题",{"2":{"58":1}}],["还被沿用到更高级的算法中",{"2":{"53":1}}],["只将对象的顶层属性设置为只读",{"2":{"1516":1}}],["只会使对象的最顶层属性变成响应式的",{"2":{"1512":1}}],["只会确定分配给每个类别的概率",{"2":{"643":1}}],["只跟踪引用值的变化",{"2":{"1511":1}}],["只读取",{"2":{"1460":1}}],["只读属性不能被修改",{"2":{"1426":1}}],["只读属性",{"2":{"1419":1}}],["只能在类内部访问",{"2":{"1425":1}}],["只能传入指定的值",{"2":{"1407":1}}],["只能获得最后一层的输出",{"2":{"920":1}}],["只提供单机容器运行的问题",{"2":{"1374":1}}],["只在有必要的时候",{"2":{"1162":1}}],["只适用于线性模型",{"2":{"1085":1}}],["只接收一个输入",{"2":{"1018":1}}],["只对整个图像做卷积神经网络的前向传播",{"2":{"941":1}}],["只训练小型自定义输出网络",{"2":{"906":3}}],["只使用最简单的随机左右翻转",{"2":{"882":1}}],["只使用矩阵乘法",{"2":{"372":1}}],["只保留置信度更高的结果作为最终输出",{"2":{"854":1}}],["只遍历剩下的na−nb个锚框",{"2":{"851":1}}],["只用于评估模型性能",{"2":{"582":1}}],["只取其前num",{"2":{"568":1}}],["只代表一个卡和相应的显存",{"2":{"446":1}}],["只关注一小部分信息的能力对进化更加有意义",{"2":{"379":1}}],["只不过它能自动选择学习速率α",{"2":{"1111":1}}],["只不过写得小一点而已",{"2":{"1093":1}}],["只不过现在是上下排列",{"2":{"1089":1}}],["只不过是把文件名写成了一个字符串的形式",{"2":{"1089":1}}],["只不过",{"2":{"374":1}}],["只转换最后一个轴",{"2":{"369":1}}],["只是形式类似",{"2":{"1146":1}}],["只是把u和v的位置交换一下",{"2":{"1145":1}}],["只是这里是由两条线段组成",{"2":{"1143":1}}],["只是将输入向量",{"2":{"1100":1}}],["只是替换了好",{"2":{"1061":1}}],["只是没法正确的工作于是这就浪费了六个月的时间",{"2":{"1059":1}}],["只是最终层中的输出数量被设置为目标数据集中的类数",{"2":{"873":1}}],["只是不同设备之间的特性差异可能更大",{"2":{"803":1}}],["只是不像我们在循环神经网络中看到的那样前向运算",{"2":{"519":1}}],["只是gpu的速度更快",{"2":{"802":1}}],["只是为了解释深度学习架构",{"2":{"663":1}}],["只是其额外的全连接层中的参数与用于预测开始位置的参数无关",{"2":{"660":1}}],["只是权重更新公式更为复杂",{"2":{"545":1}}],["只是在具体数值上有所不同",{"2":{"488":1}}],["只是位置编码通过使用三角函数",{"2":{"399":1}}],["只是机器学习可以解决的众多问题中的一个",{"2":{"288":1}}],["只是翻转一下符号",{"2":{"286":1}}],["只是均值和方差需要存在",{"2":{"247":1}}],["只是隐藏单元的仿射函数",{"2":{"232":1}}],["只是多层感知机的实现里增加了带有激活函数的隐藏层",{"2":{"226":1}}],["只需取消对以下行的注释来安装pandas",{"2":{"1011":1}}],["只需要一个单一的学习算法就可以了",{"2":{"1098":1}}],["只需要一些基本的微积分",{"2":{"973":1}}],["只需要一次抽取一个词元xt∼p",{"2":{"315":1}}],["只需要增加一个",{"2":{"520":1}}],["只需要调用成员函数begin",{"2":{"325":1}}],["只需要基于前面的对话片断中的文本",{"2":{"315":1}}],["只需将求和终止为∂ht−τ",{"2":{"309":1}}],["只需将l2的平方惩罚添加到原始目标函数中",{"2":{"272":1}}],["只需尽快识别出模式并模仿他们的行为即可",{"2":{"296":1}}],["只需几行代码就可以快速构建模型",{"2":{"237":1}}],["只需几行代码就可以",{"2":{"219":1}}],["只需在目标函数中加上一个惩罚就可以了",{"2":{"51":1}}],["只要你有一个还算大的训练集",{"2":{"1179":1}}],["只要你使用",{"2":{"1129":1}}],["只要我们认为实际数据有可能和经过这样处理后的数据类似",{"2":{"1173":1}}],["只要确保在执行函数之前",{"2":{"1092":1}}],["只要特征变量数量小于一万",{"2":{"1085":1}}],["只要特征变量的数目并不大",{"2":{"1085":1}}],["只要可以正确理解深度学习所需的数学知识即可",{"2":{"987":1}}],["只要可以随机选择",{"2":{"339":1}}],["只要gpu的显存足够大",{"2":{"832":1}}],["只要这些语言能够被python或者mxnet支持",{"2":{"821":1}}],["只要这种是近似精确的",{"2":{"348":1}}],["只要某个变量不再需要",{"2":{"817":1}}],["只要有可用的资源gpu上就可以同时执行多个程序",{"2":{"811":1}}],["只要将任何文本序列想象成一维图像即可",{"2":{"698":1}}],["只要输出门接近1",{"2":{"556":1}}],["只要交互类型建模具有足够的灵活性",{"2":{"526":1}}],["只要所有的数据和参数都在同一个设备上",{"2":{"451":1}}],["只要知道r",{"2":{"115":1}}],["只要当前损失和最优损失之间的差异超过ηtl2",{"2":{"115":1}}],["只有对角线上有值",{"2":{"1160":1}}],["只有0",{"2":{"1139":1}}],["只有很少或没有其他类的样本",{"2":{"1139":1}}],["只有数据并行这种并行训练策略值得推荐",{"2":{"841":1}}],["只有额外的多层感知机",{"2":{"688":1}}],["只有隐状态会传递到输出层",{"2":{"562":1}}],["只有隐状态才会传递到输出层",{"2":{"559":1}}],["只有使用足够大的小批量",{"2":{"467":1}}],["只有第一层需要延迟初始化",{"2":{"418":1}}],["只有生成的词元才能用于解码器的自注意力计算中",{"2":{"408":1}}],["只有30000多个单词",{"2":{"361":1}}],["只有前n",{"2":{"350":1}}],["只有一个数测量这个长度",{"2":{"1156":1}}],["只有一个轴的张量",{"2":{"991":1}}],["只有一个轴",{"2":{"991":1}}],["只有一个链路",{"2":{"812":1}}],["只有一个重置门或一个更新门会怎样",{"2":{"549":1}}],["只有一个与",{"2":{"318":1}}],["只有一组最初未知回报的可用动作时",{"2":{"298":1}}],["只有一定程度的噪声可能会使参数跳出局部最小值",{"2":{"101":1}}],["只有当",{"2":{"1146":1}}],["只有当此iou大于预定义的阈值时",{"2":{"851":1}}],["只有当相对比率f",{"2":{"773":1}}],["只有当较复杂的函数类包含较小的函数类时",{"2":{"500":1}}],["只有当模型真正发现了一种泛化模式时",{"2":{"251":1}}],["只有当我们做到这一点后",{"2":{"196":1}}],["只有zip",{"2":{"206":1}}],["只有在学习算法运行了足够长的时间之后",{"2":{"1127":1}}],["只有在你已经让它工作后",{"2":{"1061":1}}],["只有在必要时才会将逗号插入到单独的索引中",{"2":{"992":1}}],["只有在我们第一次尝试通过网络传递数据时才会进行真正的初始化",{"2":{"592":2}}],["只有在训练模型时才使用dropout",{"2":{"174":4}}],["只有在这些不常见的特征出现时",{"2":{"25":1}}],["并配置好default",{"2":{"1523":1}}],["并因其",{"2":{"1359":1}}],["并运行在指定",{"2":{"1310":1}}],["并和大家分享",{"2":{"1187":1}}],["并令",{"2":{"1147":1}}],["并介绍实际应用",{"2":{"1147":1}}],["并发",{"2":{"1203":1}}],["并发控制",{"0":{"1200":1},"2":{"1204":1}}],["并发现数据量非常大时",{"2":{"1141":1}}],["并发起imagenet挑战赛",{"2":{"456":1}}],["并衡量它的表现",{"2":{"1139":1}}],["并着手优化",{"2":{"1138":1}}],["并没有一个很直观的理解",{"2":{"1122":1}}],["并没有真正的测试数据集",{"2":{"256":1}}],["并最终导致选择较小一些的θ3和θ4",{"2":{"1115":1}}],["并自动选择一个好的学习速率",{"2":{"1111":1}}],["并自动地把顾客划分到不同的细分市场中",{"2":{"1061":1}}],["并引起你的肌肉收缩",{"2":{"1099":1}}],["并引入了一个新的权重参数whh∈rh×h",{"2":{"340":1}}],["并向其他神经元传递消息",{"2":{"1099":1}}],["并处理这些数据",{"2":{"1098":1}}],["并学会解读从环境反弹回来的声波模式",{"2":{"1098":1}}],["并学习如何更简洁地实现其他模型",{"2":{"606":1}}],["并把声音信号传递给你的听觉皮层",{"2":{"1098":1}}],["并把它们的面积相加",{"2":{"980":1}}],["并联合调用它们",{"2":{"1093":1}}],["并回车",{"2":{"1091":1}}],["并按下回车键",{"2":{"1088":1}}],["并按照提示设置适当的路径",{"2":{"445":1}}],["并更新θ1",{"2":{"1067":1}}],["并更好地捕获序列中的长距离依赖关系",{"2":{"555":1}}],["并更好地捕获时间步距离很长的序列的依赖关系",{"2":{"542":1}}],["并依此类推",{"2":{"1067":1}}],["并决定从什么方向将会最快下山",{"2":{"1067":1}}],["并问自己要在某个方向上",{"2":{"1067":1}}],["并尝试将这些学习算法用于不同大小的训练数据集中",{"2":{"1141":1}}],["并尝试将其分类",{"2":{"1141":1}}],["并尝试更直观地解释它在计算什么",{"2":{"1064":1}}],["并尝试使用机器学习算法来分析数据",{"2":{"1058":1}}],["并想要确定肿瘤是良性的还是恶性的",{"2":{"1063":1}}],["并链接复杂的c++或java库",{"2":{"1061":1}}],["并开始了解不同的算法",{"2":{"1058":1}}],["并开始撰写自己的研究论文时",{"2":{"475":1}}],["并可以自己实现学习机器学习的算法",{"2":{"1058":1}}],["并可以应用于任何情况",{"2":{"832":1}}],["并给出相似的结果",{"2":{"1148":1}}],["并给出骰子在每组实验后出现值的估计概率",{"2":{"1026":1}}],["并给出沿哪个轴连结",{"2":{"1018":1}}],["并复用先前分配的且不再需要的值",{"2":{"1021":1}}],["并产生一个输出",{"2":{"1018":1}}],["并采用基于cpu的计算",{"2":{"1017":3}}],["并存储在csv",{"2":{"1011":1}}],["并存储从零开始实现的循环神经网络模型的参数",{"2":{"332":1}}],["并让算法为我们从数据中找出某种结构",{"2":{"1061":1}}],["并让列向量bj∈rk作为矩阵b的第j列",{"2":{"999":1}}],["并让kh和kw为卷积核的高度和宽度",{"2":{"121":1}}],["并执行一些熟悉的算术运算",{"2":{"989":1}}],["并执行大量的随机内存访问",{"2":{"600":1}}],["并用hist命令绘制直方图",{"2":{"1088":1}}],["并用p",{"2":{"1031":1}}],["并用数学符号和相应的代码实现来表示它们",{"2":{"988":1}}],["并用它们来生成序列",{"2":{"550":1}}],["并访问得到的梯度",{"2":{"978":1}}],["并创造一个与f有相同的超参数",{"2":{"971":1}}],["并创建一个与f具有相同的超参数",{"2":{"969":1}}],["并预测数据是否异常",{"2":{"1181":1}}],["并预测其类别",{"2":{"963":1}}],["并预测明天的天气",{"2":{"281":1}}],["并逐步将通道数翻倍",{"2":{"958":1}}],["并具有不同的形状和大小",{"2":{"937":1}}],["并标注它们的类别和边界框",{"2":{"937":1}}],["并生成了1000张不同角度和大小的香蕉图像",{"2":{"930":1}}],["并同时迁移了风格图像的色彩",{"2":{"927":1}}],["并同时计算softmax及其对数",{"2":{"624":1}}],["并保证目标检测的精度",{"2":{"939":1}}],["并保留内容层和风格层的输出",{"2":{"920":1}}],["并保持批量大小为256",{"2":{"622":1}}],["并探讨最近在学术界和行业中具有影响力的方法和应用",{"2":{"886":1}}],["并探讨其存在的问题",{"2":{"512":1}}],["并设置σ",{"2":{"1185":1}}],["并设置如何同时",{"2":{"880":1}}],["并设置数据迭代器的批量大小为256",{"2":{"629":1}}],["并根据图像做出适当的决定",{"2":{"1098":1}}],["并根据目标数据集对这些参数进行微调",{"2":{"875":1}}],["并根据不同的数据对它们进行训练",{"2":{"423":1}}],["并转成卷积神经网络所需要的四维输入格式",{"2":{"866":1}}],["并丢弃矩阵中i2th行和j2th列中的所有元素",{"2":{"851":1}}],["并调整区域边界从而更准确地预测目标的真实边界框",{"2":{"847":1}}],["并调用load",{"2":{"669":1}}],["并基于两个环直接同步数据",{"2":{"842":1}}],["并基于这个前缀生成10个后续字符",{"2":{"333":1}}],["并附加梯度",{"2":{"835":1}}],["并均匀地分配到gpu上",{"2":{"833":1}}],["并相应地更新参数",{"2":{"828":1}}],["并拥有相对成熟的python软件生态",{"2":{"822":1}}],["并行地计算精确度和发布网络的最终性能",{"2":{"828":1}}],["并行运行",{"2":{"827":1}}],["并行化也会有所帮助",{"2":{"799":1}}],["并行化对单设备计算机来说并不是很有用",{"2":{"795":1}}],["并行计算与通信",{"0":{"797":1}}],["并行计算的能力也对强化学习的进步做出了相当关键的贡献",{"2":{"300":1}}],["并行执行",{"2":{"793":1,"837":1}}],["并填充零",{"2":{"776":1}}],["并取两者的对数",{"2":{"743":1}}],["并取决于数据集",{"2":{"286":1}}],["并从图像的左上角开始截取形状为320×480的区域用于预测",{"2":{"866":1}}],["并从节点i开始同步块i",{"2":{"842":1}}],["并从中生成预训练样本",{"2":{"722":1}}],["并从当前参数的值中减掉",{"2":{"613":1}}],["并替换原来的tokenizer函数",{"2":{"717":1}}],["并比较",{"2":{"706":1}}],["并分别对这些区域中的像素做前向传播",{"2":{"866":1}}],["并分别对输入执行卷积运算",{"2":{"701":1}}],["并分别设定填充和步幅的高度和宽度",{"2":{"147":4}}],["并被打包成一个bert输入序列",{"2":{"687":1}}],["并加载glove嵌入来初始化输入词元的向量",{"2":{"680":1}}],["并加权处理图片",{"2":{"157":1}}],["并称之为",{"2":{"672":1}}],["并说明bert如何表示它们的输入并转换为输出标签",{"2":{"656":1}}],["并与上面计算的二阶导数匹配",{"2":{"655":1}}],["并赋予它",{"2":{"651":1}}],["并打印这些梯度",{"2":{"974":1}}],["并打印其中的图像和标签的形状",{"2":{"932":1}}],["并打印所有中心词及其上下文词",{"2":{"774":1}}],["并打印它来监控训练过程",{"2":{"595":1}}],["并打印前10个最常用的",{"2":{"318":1}}],["并编写了计算的代码",{"2":{"591":1}}],["并除以255使得所有像素的数值",{"2":{"583":1}}],["并除以255使得所有像素的数值均在0～1之间",{"2":{"582":1}}],["并讨论基于前向和后向循环计算的双向设计",{"2":{"550":1}}],["并讨论一些有用的启发式方法",{"2":{"240":1}}],["并深刻影响了后来的深度神经网络的设计",{"2":{"500":1}}],["并构成inception块的输出",{"2":{"487":1}}],["并减半通道数",{"2":{"482":1}}],["并观察其输出",{"2":{"1004":1}}],["并观察和分析结果",{"2":{"477":1}}],["并观察模型精度和gpu显存变化",{"2":{"465":1}}],["并观察目标函数值的下降率以及每个迭代轮数消耗的时间",{"2":{"83":1}}],["并以此作为推荐的依据",{"2":{"1187":1}}],["并以此计算关于",{"2":{"605":2}}],["并以它们为中心生成锚框",{"2":{"912":1}}],["并以很大的优势赢得了2012年imagenet图像识别挑战赛",{"2":{"458":1}}],["并以其命名",{"2":{"135":1}}],["并推动了深度学习热潮",{"2":{"457":1}}],["并利用亚马逊众包",{"2":{"456":1}}],["并利用往年的考试题目来测试自己的能力",{"2":{"252":1}}],["并撰写论文是盛极一时的潮流",{"2":{"455":1}}],["并记录输出矩阵的frobenius范数",{"2":{"453":1}}],["并实现了",{"2":{"436":1}}],["并进一步抽取相同形状2×2的特征",{"2":{"938":1}}],["并进一步访问该参数的值",{"2":{"431":1}}],["并进行相应的优化",{"2":{"137":1}}],["并输出分数最高的跨度",{"2":{"660":1}}],["并输出其分类结果",{"2":{"657":1}}],["并输出其未规范化的输出值",{"2":{"423":1}}],["并输出一个",{"2":{"289":1}}],["并包含一些参数",{"2":{"422":1}}],["并慢慢介绍了功能齐全的深度学习模型",{"2":{"421":1}}],["并计算y关于xi的导数",{"2":{"982":1}}],["并计算bleu的最终结果",{"2":{"578":1}}],["并计算它们的bleu分数",{"2":{"376":1}}],["并计算梯度∇fi",{"2":{"113":1}}],["并非所有刺激的影响都是相等的",{"2":{"379":1}}],["并非所有的值都应该被纳入到注意力汇聚中",{"2":{"368":1}}],["并非所有的内存入口都是相等的",{"2":{"77":1}}],["并非感官的所有输入都是一样的",{"2":{"354":1}}],["并重复本节中的实验",{"2":{"337":1}}],["并独立于主人来决定那些直接影响人类生计的事情",{"2":{"301":1}}],["并选择后续操作",{"2":{"298":1}}],["并选择合适的模型族",{"2":{"282":1}}],["并启动地图应用程序",{"2":{"282":1}}],["并特别关注深度学习",{"2":{"281":1}}],["并正确回答该问题",{"2":{"281":1}}],["并不会改变取得最小值时的θ值",{"2":{"1143":1}}],["并不能说明它就一定是一个好的假设函数",{"2":{"1130":1}}],["并不能使用标准方程法",{"2":{"1085":1}}],["并不适合解决这样的问题",{"2":{"1107":1}}],["并不断迭代这一步骤",{"2":{"613":1}}],["并不断测试直到满足用户的需求",{"2":{"281":1}}],["并不是每个实际问题都表现出所有这些复杂性",{"2":{"298":1}}],["并不是所有的架构都是简单的顺序架构",{"2":{"425":1}}],["并不是所有的错误都是均等的",{"2":{"291":1}}],["并不是所有的数据都可以用",{"2":{"284":1}}],["并不一定在",{"2":{"286":1}}],["并不比抽取的第2个样本和第200万个样本的相关性更强",{"2":{"253":1}}],["并通过其",{"2":{"1047":1}}],["并通过预测这些锚框的类别和偏移量检测不同大小的目标",{"2":{"965":1}}],["并通过预测边界框的类别和偏移量来检测大小不同的目标",{"2":{"953":1}}],["并通过前向传播输出抽取的提议区域特征",{"2":{"937":1}}],["并通过最小化损失函数来不断更新合成图像来作为模型参数",{"2":{"928":1}}],["并通过反向传播",{"2":{"917":1}}],["并通过偏置项来进行平移",{"2":{"610":1}}],["并通过我们的模型来获得一组预测",{"2":{"605":1}}],["并通过数据迭代器指定batch",{"2":{"590":1}}],["并通过计算交叉熵损失函数来进行优化",{"2":{"575":1}}],["并通过kernel",{"2":{"278":1}}],["并通过激活函数转换隐藏层的输出",{"2":{"238":1}}],["并在依赖更改时重新执行该函数",{"2":{"1467":1}}],["并在该点是出路这里的概率非常低",{"2":{"1185":1}}],["并在右边也加入一个颜色条",{"2":{"1091":1}}],["并在计算上更有效率",{"2":{"1070":1}}],["并在新的浏览器窗口中显示它",{"2":{"1007":1}}],["并在kaggle提交结果",{"0":{"908":1}}],["并在gpu上将它们拆分",{"2":{"827":1}}],["并在编译器级别进行大量优化以满足快速执行的需要",{"2":{"819":1}}],["并在对模型架构进行最小更改的情况下改善了其中9项任务的最新水平",{"2":{"732":1}}],["并在",{"2":{"663":1,"699":1}}],["并在单词和标点符号之间插入空格",{"2":{"565":1}}],["并在此基础上做了改进",{"2":{"486":1}}],["并在此基础上构建更大的网络",{"2":{"428":1}}],["并在学术界获得了数万引用",{"2":{"475":1}}],["并在预测时使用它们得到确定的输出",{"2":{"471":1}}],["并在命令行中将其报告给用户",{"2":{"452":1}}],["并在以后加载它们",{"2":{"442":1}}],["并在整数或其子集上变化",{"2":{"346":1}}],["并在信息论的在线附录",{"2":{"342":1}}],["并在每个人周围绘制轮廓",{"2":{"281":1}}],["并在测试数据集上进行评估",{"2":{"275":1}}],["并在剩余的一个子集",{"2":{"257":1}}],["并在添加标量偏置之后产生输出",{"2":{"127":1}}],["并应用它们制定一个不同的异常检测算法",{"2":{"1185":1}}],["并应用于许多不同的学习问题",{"2":{"1111":1}}],["并应用于fashion",{"2":{"67":1}}],["并应用其出色的实验结果",{"2":{"464":1}}],["并应用适当的损失函数",{"2":{"228":1}}],["并训练分类器从低分辨率图像中识别10类服装",{"2":{"228":1}}],["并训练和测试模型",{"2":{"206":1}}],["并查看结果",{"2":{"628":1}}],["并查看它对结果有何影响",{"2":{"223":1}}],["并查看此超参数的变化对结果有何影响",{"2":{"223":1}}],["并查看在测试集上的预测与实际房价",{"2":{"213":1}}],["并查看排名",{"2":{"207":1}}],["并为用户提供更好的服务",{"2":{"1058":1}}],["并为其分配所需的初始化值",{"2":{"436":1}}],["并为其创建指示符特征",{"2":{"209":1}}],["并为这些边界情况设计合适的规则",{"2":{"281":1}}],["并为深度学习框架提供一个实现",{"2":{"248":1}}],["并为每个区域包含沃尔多的可能性打分",{"2":{"152":1}}],["并返回",{"2":{"1090":1}}],["并返回输入词元的索引",{"2":{"721":1}}],["并返回输出张量y",{"2":{"126":1}}],["并返回训练集和测试集的dataloader实例",{"2":{"669":1}}],["并返回前向传播中两个网络的串联输出",{"2":{"428":1}}],["并返回下载文件的名称",{"2":{"206":1}}],["并对其依赖项跟踪和更新触发进行逻辑控制",{"2":{"1520":1}}],["并对比",{"2":{"1194":1}}],["并对这个模型进行机器翻译训练",{"2":{"376":1}}],["并对包含和不包含唤醒词的样本进行标记",{"2":{"282":1}}],["并对我们的模型和环境以意想不到的方式纠缠在一起的可能性持开放态度",{"2":{"202":1}}],["并对输入和输出提高和缩减相应的维数",{"2":{"141":4}}],["并继续监控实时系统",{"2":{"202":1}}],["并使特征图中每个单元在输入图像上的感受野变得更广阔",{"2":{"953":1}}],["并使其能够正常工作呢",{"2":{"831":1}}],["并使上下文窗口为m",{"2":{"708":1}}],["并使用adam作为训练的优化算法",{"2":{"883":1}}],["并使用它们在octave中对数据进行更多的操作",{"2":{"1088":1}}],["并使用它们来更新我们的模型",{"2":{"600":1}}],["并使用它为一个输入词寻找语义相似的词",{"2":{"747":1}}],["并使用next从迭代器中获取第一项",{"2":{"590":1}}],["并使用1×1卷积层减少每像素级别上的通道维数从而降低模型复杂度",{"2":{"490":1}}],["并使用步幅为2的平均汇聚层减半高和宽",{"2":{"481":1}}],["并使用困惑度来评估这样的模型",{"2":{"342":1}}],["并使用一个只包含20个样本的小训练集",{"2":{"271":1}}],["并使用了relu激活函数",{"2":{"225":1}}],["并使用验证集",{"2":{"192":1}}],["并使损失函数的值最小化",{"2":{"65":1}}],["并希望优化它到最低点",{"2":{"286":1}}],["并希望将其部署到英国",{"2":{"188":1}}],["并希望利用他们从病人身上采集的血液样本进行研究",{"2":{"185":1}}],["并激发批判性思考",{"2":{"179":1}}],["并拒绝所有穿着运动鞋的申请人",{"2":{"179":1}}],["并总结定性的结论",{"2":{"178":1}}],["并朝着参数的方向努力",{"2":{"164":1}}],["并移位x时",{"2":{"156":1}}],["并将接收到的",{"2":{"1044":1}}],["并将原始数据转换为张量格式的步骤",{"2":{"1010":1}}],["并将所有选择的联合概率聚合在一起",{"2":{"1033":1}}],["并将所有元素值设置为1",{"2":{"1007":1}}],["并将所有权重放到向量w∈rd中",{"2":{"610":1}}],["并将f赋为52",{"2":{"989":1}}],["并将输入特征图的高度和宽度减半",{"2":{"957":1}}],["并将输出通道数记为c",{"2":{"939":1}}],["并将合成的图像视为模型参数",{"2":{"926":1}}],["并将batch",{"2":{"890":1}}],["并将卷积核的高和宽设为64",{"2":{"862":1}}],["并将该网络记为pretrained",{"2":{"862":1}}],["并将类设置为背景",{"2":{"854":3}}],["并将它的行索引和列索引分别表示为i2和j2",{"2":{"851":1}}],["并将它的行索引和列索引分别表示为i1和j1",{"2":{"851":1}}],["并将它们压缩成一行向量化的代码来实现",{"2":{"1093":1}}],["并将它们应用于图像分类",{"2":{"886":1}}],["并将它们应用到简单的图像分类任务中",{"2":{"886":1}}],["并将它们应用到每个图像",{"2":{"881":1}}],["并将它们重新调整为给定的平均值和大小",{"2":{"467":1}}],["并将它们与某个初始矩阵相乘",{"2":{"243":1}}],["并将更新后的参数广播回各个cpu中",{"2":{"843":1}}],["并将结果拼接在一起",{"2":{"999":1}}],["并将结果变换成卷积神经网络接受的输入格式",{"2":{"919":1}}],["并将结果广播给所有gpu",{"2":{"835":1}}],["并将结果存储为变量e",{"2":{"816":1}}],["并将切分后的分块数据复制到devices变量提供的设备列表中",{"2":{"827":1}}],["并将上下文窗口设置为2",{"2":{"783":1}}],["并将位置i的元素设置为1",{"2":{"781":1}}],["并将这些词元表示送入多层双向循环神经网络以获得文本序列表示",{"2":{"712":1}}],["并将训练数据集中所有样本都使用一次",{"2":{"605":1}}],["并将标签转换为int32",{"2":{"584":1}}],["并将基于",{"2":{"572":1}}],["并将偏置初始化为0",{"2":{"601":1}}],["并将偏置项设为0",{"2":{"544":1,"558":1}}],["并将偏置参数设置为0",{"2":{"434":1}}],["并将高和宽减半",{"2":{"502":1}}],["并将文本数据转换为词元索引以供模型操作",{"2":{"365":1}}],["并将第i处的元素设置为1",{"2":{"330":1}}],["并将此讨论作为循环神经网络设计的灵感",{"2":{"305":1}}],["并将手写字符映射到对应的已知字符之上",{"2":{"291":1}}],["并将在之后继续探讨的监督学习情景中",{"2":{"253":1}}],["并将学习率设置为0",{"2":{"221":1}}],["并将使用暂退法和不使用暂退法时获得的结果进行比较",{"2":{"178":1}}],["并将整个图像向右移动一个像素",{"2":{"145":1}}],["并将其提交",{"2":{"1094":1}}],["并将其在输出层之前截断",{"2":{"937":1}}],["并将其初始化为图像x",{"2":{"926":1}}],["并将其卷积核用bilinear",{"2":{"863":1}}],["并将其卷积核初始化为随机张量",{"2":{"129":1}}],["并将其广播到所有gpu",{"2":{"837":3}}],["并将其转换为具有固定形状的编码状态",{"2":{"532":1,"536":1}}],["并将其转换为张量表示",{"2":{"209":1}}],["并将其自动化",{"2":{"284":1}}],["并将其留给读者来改进模型",{"2":{"212":1}}],["并将其代入",{"2":{"192":1}}],["并将其应用于具体的拟合直线的线性回归算法里",{"2":{"1069":1}}],["并将其应用于局部特征",{"2":{"698":1}}],["并将其应用于序列到序列",{"2":{"572":1}}],["并将其应用于马萨诸塞州综合医院的患者数据",{"2":{"253":1}}],["并将其应用于求log⁡",{"2":{"64":1}}],["并将其应用于初始值20次",{"2":{"57":1}}],["并",{"2":{"141":1,"837":1,"854":1}}],["并忽略偏置",{"2":{"129":1}}],["并且没有一个用户给所有的电影都打过分",{"2":{"1187":1}}],["并且没有太多的特征",{"2":{"1184":1}}],["并且没有局部最优值",{"2":{"1109":1}}],["并且我也希望你们通过应用机器学习",{"2":{"1176":1}}],["并且我们不对方差项θ0进行正则化处理",{"2":{"1188":1}}],["并且我们训练集中的因变量也是同样维度的一个向量",{"2":{"1120":1}}],["并且我们将所有的像素视为特征",{"2":{"1097":1}}],["并且我们的训练集是一个特征矩阵而非向量",{"2":{"1121":1}}],["并且我们的训练集结果为向量",{"2":{"1085":1}}],["并且我们的目标是计算p",{"2":{"519":1}}],["并且我们的隐藏层不包括偏置项",{"2":{"162":1}}],["并且对偏差和方差的讨论提供了对算法结果的直观理解",{"2":{"1147":1}}],["并且对于大多数的自然语言处理任务",{"2":{"733":1}}],["并且对于每个通道",{"2":{"470":1}}],["并且为支持向量机",{"2":{"1143":1}}],["并且这两个方程或这两个表达式并不相同",{"2":{"1143":1}}],["并且这里还有一个1",{"2":{"1143":1}}],["并且这些状态只能通过先前时间步的数据来计算",{"2":{"338":1}}],["并且这些模型能很好地泛化到未知数据中",{"2":{"155":1}}],["并且你能够得到大量数据的情况下",{"2":{"1141":1}}],["并且懂得如何运用",{"2":{"1135":1}}],["并且正则化非常小",{"2":{"1134":1}}],["并且也能弄清楚怎样评价一个学习算法",{"2":{"1132":1}}],["并且作为输入提供给alvinn的三层神经网络",{"2":{"1127":1}}],["并且记录驾驶者的驾驶方向",{"2":{"1127":1}}],["并且初始化时",{"2":{"1127":1}}],["并且实际上在神经网络开始学习之前",{"2":{"1127":1}}],["并且希望给你一个更加全面直观的感受",{"2":{"1122":1}}],["并且让代价函数最优化的软件来选择这些惩罚的程度",{"2":{"1115":1}}],["并且参数θ",{"2":{"1108":1}}],["并且根据本身的模型提供一个输出",{"2":{"1099":1}}],["并且有一个输出",{"2":{"1099":1}}],["并且有10个类别",{"2":{"169":1}}],["并且保证你确实能理解它",{"2":{"1093":1}}],["并且保留这种格式是有意义的",{"2":{"640":1}}],["并且如果这种说法是真的",{"2":{"1141":1}}],["并且如果你把",{"2":{"1093":1}}],["并且如何定义和使用方程",{"2":{"1092":1}}],["并且更好地利用你的计算机里可能有的一些并行硬件系统等等",{"2":{"1093":1}}],["并且更新后的梯度完全与g的原始方向对齐",{"2":{"334":1}}],["并且返回的这个值将被存放于变量",{"2":{"1092":1}}],["并且要注意要有end",{"2":{"1092":1}}],["并且把它们设置为999",{"2":{"1092":1}}],["并且把它们放到一起",{"2":{"1089":1}}],["并且定义和使用函数",{"2":{"1091":1}}],["并且用常数c来代替",{"2":{"1143":1}}],["并且用这个余弦图来代替它",{"2":{"1091":1}}],["并且用它来以某种方式更新模型参数",{"2":{"116":1}}],["并且逐元素比较取最大值",{"2":{"1090":1}}],["并且其所有元素均为随机",{"2":{"1088":1}}],["并且其sha",{"2":{"206":1}}],["并且会觉得理解以后会非常有用",{"2":{"1086":1}}],["并且总有人问我有关这方面的问题",{"2":{"1086":1}}],["并且总和为1",{"2":{"388":1}}],["并且能把它应用到线性回归中了",{"2":{"1069":1}}],["并且能够解决了上面列出的问题",{"2":{"539":1}}],["并且它可以在随机实验的一组可能性中取一个值",{"2":{"1028":1}}],["并且它可以有效地应用于广泛的领域中",{"2":{"1025":1}}],["并且它们独立于wij并且彼此独立",{"2":{"247":1}}],["并且它们各自的梯度在执行反向传播时也会消失",{"2":{"171":1}}],["并且输出是一个标量",{"2":{"983":1}}],["并且与x具有相同的形状",{"2":{"974":1}}],["并且足够好",{"2":{"873":1}}],["并且操作之间没有依赖关系",{"2":{"799":1}}],["并且通常是在不同的设备上",{"2":{"789":1}}],["并且通过将这两个值放在一起",{"2":{"1141":1}}],["并且通过用非常大的训练集来保证",{"2":{"1141":1}}],["并且通过另一个可以学习的线性投影进行变换",{"2":{"380":1}}],["并且通过自动微分和随机梯度下降能够学习网络参数就可以了",{"2":{"339":1}}],["并且在这个训练集中训练一个有很多参数的学习算法吗",{"2":{"1141":1}}],["并且在此之后接下来的几个视频中",{"2":{"1114":1}}],["并且在一秒内多次更新所有参数",{"2":{"1021":1}}],["并且在过去二十年中这个数字基本上没变",{"2":{"804":1}}],["并且在两个上下文窗口中以wi为其中心词的上下文词索引是k",{"2":{"742":1}}],["并且在训练期间不要更新这些向量",{"2":{"714":1}}],["并且需要对大量自然语言处理任务进行最小的架构更改",{"2":{"739":1}}],["并且需要大量不同的建模决策",{"2":{"289":1}}],["并且比ptb数据集大了两倍多",{"2":{"723":1}}],["并且比平均汇聚的预测更接近真实",{"2":{"388":1}}],["并且使得log⁡",{"2":{"624":1}}],["并且只考虑到x在y被计算后发挥的作用",{"2":{"976":1}}],["并且只有一个计算神经元",{"2":{"618":1}}],["并且只移动较大的日志",{"2":{"452":1}}],["并且将图像传送给神经网络进行训练",{"2":{"1127":1}}],["并且将输入序列的信息在该上下文变量中进行编码",{"2":{"573":1}}],["并且将其应用于语言建模",{"2":{"317":1}}],["并且丢弃剩余的词元",{"2":{"568":1}}],["并且计算",{"2":{"538":1}}],["并且计算它们的bleu分数",{"2":{"409":1}}],["并且还能方便地使用其他前端编程语言",{"2":{"821":4}}],["并且还可以被认为是单词的特征向量或表示",{"2":{"780":1}}],["并且还拥有可选的额外的参数",{"2":{"535":1}}],["并且还需要超过1000个矩阵的乘积才能得到非常难以捉摸的梯度",{"2":{"306":1}}],["并且仅仅应用于部分场合",{"2":{"522":1}}],["并且网络的反向传播还依赖于前向传播的结果",{"2":{"522":1}}],["并且令隐藏层激活函数为ϕ",{"2":{"521":1}}],["并且学习到的算法往往归于事后的解释",{"2":{"454":1}}],["并且必须存储任何必需的参数",{"2":{"422":1}}],["并且必须选择一个动作",{"2":{"298":1}}],["并且具有一组可调参数",{"2":{"422":1}}],["并且层中使用了残差连接和层规范化",{"2":{"404":1}}],["并且都满足零均值和单位方差",{"2":{"370":1}}],["并且禁用偏置项",{"2":{"369":1}}],["并且同时更新预测x^t和总结ht",{"2":{"347":1}}],["并且同样对输出层的权重进行重排列",{"2":{"244":1}}],["并且",{"2":{"326":1,"1088":1,"1127":1,"1143":1,"1192":1}}],["并且每个时间步的词元对应于一个字符",{"2":{"319":1}}],["并且可以完整地检查下算法是否正常运行",{"2":{"1091":1}}],["并且可以通过易于使用的装饰器tf",{"2":{"818":1}}],["并且可以非常大",{"2":{"810":1}}],["并且可以选择性地并行执行多个不相互依赖的任务以提高速度",{"2":{"795":1}}],["并且可以选择初始化分布",{"2":{"418":1}}],["并且可以为每一层分别设置暂退概率",{"2":{"174":1}}],["并且可视化注意力权重",{"2":{"372":1}}],["并且可能会发生梯度爆炸",{"2":{"308":1}}],["并且所有样本都是独立同分布的",{"2":{"305":1}}],["并且愿意在证明之前尝试",{"2":{"302":1}}],["并且relu减轻了困扰以往神经网络的梯度消失问题",{"2":{"235":1}}],["并且目标数据只包含我们以前见过的类别",{"2":{"192":1}}],["并且暂退法只在训练期间有效",{"2":{"174":1}}],["并且当确定每个隐藏活性值时",{"2":{"155":1}}],["并且u是一个常数",{"2":{"154":1}}],["并且u⋅v有条目uivi",{"2":{"27":1}}],["并且减少模型的过拟合",{"2":{"74":1}}],["并且不时地按给定的参数对学习率做乘法衰减",{"2":{"71":1}}],["并且过拟合更小了",{"2":{"68":1}}],["并展示如何通过学习率调度器",{"2":{"66":1}}],["并有二维向量x=",{"2":{"57":1}}],["并假设η=0",{"2":{"54":1}}],["并集不是",{"2":{"51":1}}],["方案对比",{"2":{"1546":1}}],["方向向量是一个经过原点的向量",{"2":{"1158":1}}],["方向保持不变",{"2":{"50":1}}],["方框表示y=2",{"2":{"1112":1}}],["方阵",{"2":{"1077":1}}],["方式可以应用更多的计算",{"2":{"1018":1}}],["方式实现一次只处理一个小批量的文本序列",{"2":{"568":1}}],["方便在模板中使用",{"2":{"1492":1}}],["方便回退",{"2":{"1318":1}}],["方便开发者构建客户端和服务器",{"2":{"1048":1}}],["方便日后可视化的需要",{"2":{"408":1}}],["方便模型操作",{"2":{"360":1}}],["方法侦听",{"2":{"1494":1}}],["方法等",{"2":{"1452":1}}],["方法如下所示",{"2":{"1116":1}}],["方法",{"0":{"917":1},"2":{"1112":1,"1124":1,"1425":1,"1426":1,"1448":1,"1451":2,"1453":1,"1454":1,"1459":1,"1462":1,"1463":1,"1464":1,"1465":1,"1466":1,"1467":1,"1470":1,"1471":1,"1497":1}}],["方法是做点乘运算a",{"2":{"1090":1}}],["方法是统计单词",{"2":{"316":1}}],["方法是将文本分解为相同长度的子序列",{"2":{"311":1}}],["方法是将文本划分为不同长度的片断",{"2":{"311":1}}],["方法是向梯度添加均值为0",{"2":{"113":1}}],["方法与前面将多类别标签转换为向量的方式相同",{"2":{"209":1}}],["方差在这方面的性质",{"2":{"1148":1}}],["方差问题",{"2":{"1134":1}}],["方差或者等于1的标准偏差",{"2":{"1088":1}}],["方差的平方根被称为标准差",{"2":{"1036":1}}],["方差为1",{"2":{"467":1}}],["方差为1的随机噪声",{"2":{"113":1}}],["方差为d",{"2":{"370":1}}],["方差",{"0":{"1133":1},"2":{"247":1,"1132":1,"1193":1}}],["方差σ2=1",{"2":{"243":1}}],["方差谱的另一端",{"2":{"169":1}}],["方差权衡",{"2":{"169":1}}],["方差增加并且数据效率降低",{"2":{"116":1}}],["方差会减少",{"2":{"78":1}}],["方差显著降低",{"2":{"78":1}}],["方差估计的移动远远慢于动量估计的移动",{"2":{"33":1}}],["黄色",{"2":{"50":1}}],["两种仪器对同一个东西测量的结果不完全相等",{"2":{"1156":1}}],["两种较流行的选择是自回归模型和隐变量自回归模型",{"2":{"352":1}}],["两行三列的矩阵",{"2":{"1088":1}}],["两次连续抛出一个骰子的事件是相互独立的",{"2":{"1034":1}}],["两者通过",{"2":{"1203":1}}],["两者比较",{"2":{"1182":1}}],["两者并没有什么不同",{"2":{"1156":1}}],["两者相乘后",{"2":{"999":1}}],["两者都将随着时间的推移而累加",{"2":{"634":1}}],["两者都存储为单精度浮点数",{"2":{"430":1}}],["两者都是构建有效的深度架构的关键",{"2":{"406":1}}],["两者会略有差异",{"2":{"33":1}}],["两类",{"2":{"291":1}}],["两个注意点",{"0":{"1475":1}}],["两个聚类结果分别是",{"2":{"1154":1}}],["两个向量之间的内积也是负的",{"2":{"1145":1}}],["两个都是二维向量",{"2":{"1145":1}}],["两个",{"2":{"1141":1,"1315":1}}],["两个项的话",{"2":{"1111":1}}],["两个中间层",{"2":{"1103":1}}],["两个权重分别为",{"2":{"1102":1}}],["两个方案中有一个能让你朋友的房子出售得更合理",{"2":{"1060":1}}],["两个随机变量a和b是条件独立的",{"2":{"1034":1}}],["两个张量具有相同的形状",{"2":{"1019":1}}],["两个张量核加速了与深度学习相关的附加操作的狭窄的子集",{"2":{"811":1}}],["两个矩阵的按元素乘法被称为他们的hadamard积",{"2":{"1003":1}}],["两个矩阵的按元素乘法称为hadamard积",{"2":{"994":1}}],["两个提议区域的坐标先按spatial",{"2":{"938":1}}],["两个数据集中的图像都是png格式",{"2":{"888":1}}],["两个子文件夹",{"2":{"872":1}}],["两个子序列是由隐状态所在的时间步的位置之前的序列和之后的序列",{"2":{"573":1}}],["两个处理器都需要等待",{"2":{"810":1}}],["两个操作所需的总时间少于它们各部分操作所需时间的总和",{"2":{"797":1}}],["两个操作的完成时间大致相同",{"2":{"791":1}}],["两个词向量",{"2":{"784":1}}],["两个预训练好的bert模型都包含一个定义词表的",{"2":{"686":1}}],["两个女人在示爱",{"2":{"665":1}}],["两个女人拥抱在一起",{"2":{"665":1}}],["两个可视化数据集的函数",{"2":{"582":1}}],["两个门的输出是由使用sigmoid激活函数的两个全连接层给出",{"2":{"540":1}}],["两个全连接隐藏层和一个全连接输出层",{"2":{"458":1}}],["两个全连接层都是linear类的实例",{"2":{"422":2}}],["两个实例的计算结果应该相同",{"2":{"442":1}}],["两个层都是实例变量",{"2":{"423":1}}],["两个值矩阵是相同的",{"2":{"369":4}}],["两个和三个变量的概率公式分别被称为",{"2":{"317":1}}],["两个隐藏单元采用相同的输入和参数",{"2":{"244":1}}],["两个分布中抽取相同数量的样本",{"2":{"191":1}}],["两个函数",{"2":{"156":1}}],["两个集合",{"2":{"50":1}}],["两个集合内的点",{"2":{"50":1}}],["两条曲线之间的间隙表示过拟合",{"2":{"67":1}}],["θkj+λxk",{"2":{"1189":1}}],["θk",{"2":{"1188":4,"1189":2,"1190":2}}],["θtmθ",{"2":{"1147":1}}],["θtf",{"2":{"1147":2}}],["θtf≥0",{"2":{"1147":1}}],["θtx更深入地理解它们的含义",{"2":{"1145":1}}],["θtx",{"2":{"1107":1,"1108":2,"1109":1,"1117":1,"1143":4,"1144":4,"1145":1}}],["θtxtxθ−θtxty−ytxθ−yty",{"2":{"1086":1}}],["θtxt−yt",{"2":{"1086":1}}],["θ的范数就可以变小了",{"2":{"1145":1}}],["θ3",{"2":{"1124":2}}],["θ30",{"2":{"1099":1}}],["θ+$",{"2":{"1124":1}}],["θ值所对应的代价函数值j",{"2":{"1092":1}}],["θ为n行1列的矩阵",{"2":{"1086":1}}],["θ=inv",{"2":{"1086":1}}],["θ=",{"2":{"1085":1,"1086":2}}],["θ2有关",{"2":{"1145":1}}],["θ2的长度",{"2":{"1145":1}}],["θ2的值",{"2":{"1111":1}}],["θ2−5",{"2":{"1111":1}}],["θ2=5",{"2":{"1111":1}}],["θ2=20",{"2":{"1101":1}}],["θ20",{"2":{"1099":1}}],["θ2进行更新",{"2":{"1093":1}}],["θ2来写方程",{"2":{"1093":1}}],["θ2",{"2":{"1081":1,"1093":3,"1110":2,"1124":2,"1145":2}}],["θji",{"2":{"1120":1}}],["θj",{"2":{"1068":2,"1085":1,"1109":2,"1110":3,"1116":2,"1117":1}}],["θn",{"2":{"1067":1,"1081":1,"1124":2}}],["θ12+θ22",{"2":{"1145":2}}],["θ1−ε1",{"2":{"1124":1}}],["θ1−5",{"2":{"1111":1}}],["θ1+ε1",{"2":{"1124":1}}],["θ1=20",{"2":{"1101":1}}],["θ10",{"2":{"1099":2}}],["θ1也等于0",{"2":{"1092":1}}],["θ1等于1",{"2":{"1092":1}}],["θ1更新的幅度就会更小",{"2":{"1068":1}}],["θ1更新后等于θ1减去一个正数乘以a",{"2":{"1068":1}}],["θ1",{"2":{"1064":5,"1066":1,"1067":6,"1069":4,"1081":2,"1093":5,"1110":2,"1145":1}}],["θ0+θ1x1+θ2x2+θ3x1x2+θ4x12+θ5x22+⋯我们可以用一系列新的特征",{"2":{"1146":1}}],["θ0+θ1x1+θ2x2+θ3x12+θ4x22",{"2":{"1108":1}}],["θ0=0的意思是我们让决策界通过原点",{"2":{"1145":1}}],["θ0不参与其中的任何一个正则化",{"2":{"1117":1}}],["θ0",{"2":{"1064":5,"1066":1,"1067":7,"1069":4,"1081":2,"1092":1,"1100":1,"1116":1,"1117":1}}],["θ",{"2":{"50":1,"1068":3,"1081":1,"1086":7,"1091":1,"1092":1,"1099":2,"1100":1,"1107":1,"1109":8,"1110":4,"1111":16,"1112":1,"1115":1,"1116":1,"1117":3,"1120":1,"1121":3,"1124":5,"1130":1,"1131":3,"1132":2,"1143":3,"1145":9,"1154":1,"1165":2,"1166":2,"1167":1,"1168":1,"1188":7,"1189":10,"1190":12,"1192":1}}],["投影是这个短的红线段",{"2":{"1145":1}}],["投影映射到凸集中最接近原始点的点",{"2":{"51":1}}],["投影的数学定义听起来可能有点抽象",{"2":{"50":1}}],["投影",{"0":{"50":1}}],["许多有能力构建这些系统的科技企业",{"2":{"1187":1}}],["许多不同种类的异常",{"2":{"1182":1}}],["许多不同的学习算法有时倾向于表现出非常相似的表现",{"2":{"1141":1}}],["许多在线网站都有持续不断的用户流",{"2":{"1168":1}}],["许多大型网站或者许多大型网络公司",{"2":{"1168":1}}],["许多特征",{"2":{"1156":1}}],["许多人在大硅谷的公司里做的其实就是",{"2":{"1061":1}}],["许多学习算法的性能都非常类似",{"2":{"1143":1}}],["许多学习算法变得只有几行代码就可实现",{"2":{"1061":1}}],["许多学习算法是相当短的程序",{"2":{"1061":1}}],["许多ai研究者认为",{"2":{"1058":1}}],["许多计算机视觉领域的应用都与我们当前和未来的生活密切相关",{"2":{"886":1}}],["许多动词有40多种变形形式",{"2":{"755":1}}],["许多较新的预训练模型使相同词元的表示适应于不同的上下文",{"2":{"754":1}}],["许多应用都要求我们做出选择",{"2":{"634":1}}],["许多公司有大型的数据库",{"2":{"1061":1}}],["许多公司",{"2":{"588":1}}],["许多现代卷积神经网络的研究都是建立在这一章的基础上的",{"2":{"492":1}}],["许多商业模式也被开发出来去利用这一点",{"2":{"354":1}}],["许多用户都有很强的特定习惯",{"2":{"345":1}}],["许多合理的三个单词组合可能是存在的",{"2":{"316":1}}],["许多使用循环网络的例子都是基于文本数据的",{"2":{"305":1}}],["许多使精确方法在凸情况下的性质",{"2":{"49":1}}],["许多这样的单元可以通过正确连接和正确的学习算法拼凑在一起",{"2":{"619":1}}],["许多这样的进步都归功于深度学习",{"2":{"301":1}}],["许多这样的算法形成了一个环境模型",{"2":{"198":1}}],["许多开创性的论文都是用这些工具写的",{"2":{"300":1}}],["许多重要的任务可以清晰地描述为",{"2":{"289":1}}],["许多令人兴奋的深度学习模型黯然失色",{"2":{"284":1}}],["许多数学家和理论家毕生致力于研究描述这一现象的形式理论",{"2":{"253":1}}],["许多比赛有赞助方",{"2":{"207":1}}],["许多实际问题都属于这一类",{"2":{"196":1}}],["许多失败的机器学习部署",{"2":{"179":1}}],["许可证",{"0":{"18":1}}],["添加远程仓库",{"2":{"1330":1}}],["添加所有改动",{"2":{"1328":1}}],["添加文件到暂存区",{"2":{"1328":1}}],["添加依赖",{"2":{"1285":1,"1289":1}}],["添加路径",{"2":{"1092":1}}],["添加随机噪声",{"2":{"903":3}}],["添加更多的gpu并不能让我们训练更大的模型",{"2":{"832":1}}],["添加缓存是一把双刃剑",{"2":{"810":1}}],["添加elmo改进了六种自然语言处理任务的技术水平",{"2":{"731":1}}],["添加批量轴",{"2":{"577":8}}],["添加批量规范化层",{"2":{"491":1}}],["添加了反向传递信息的隐藏层",{"2":{"520":1}}],["添加通过1×1卷积调整通道和分辨率",{"2":{"501":1}}],["添加层会使网络更具表现力",{"2":{"499":1}}],["添加惩罚是确保近似满足约束的一种好方法",{"2":{"49":1}}],["添加到目标函数f",{"2":{"49":1}}],["除读取外",{"2":{"1020":1}}],["除法",{"2":{"1218":1}}],["除法和指数",{"2":{"989":1}}],["除法法则",{"2":{"981":1}}],["除摄氏度外的另一种温度计量单位",{"2":{"989":1}}],["除输出层外",{"2":{"875":1}}],["除以2来获得半高和半宽",{"2":{"848":3}}],["除非你是数值计算方面的专家",{"2":{"1111":1}}],["除非额外指定",{"2":{"1017":3}}],["除非另有说明",{"2":{"879":1}}],["除非另有明确说明",{"2":{"256":1}}],["除非存框架或操作系统本身支持将多个gpu连接在一起",{"2":{"832":1}}],["除非绝对必要",{"2":{"791":1}}],["除非开发人员认识到问题并更新软件",{"2":{"281":1}}],["除非noutσ2=1",{"2":{"247":1}}],["除非我们能够每秒向处理器传输2×109×128=256×109字节",{"2":{"810":1}}],["除非我们特别想创建一个复制",{"2":{"449":1}}],["除非我们实现一个新的运算符",{"2":{"423":1}}],["除非我们提供某种解决方案",{"2":{"316":1}}],["除非我们很小心",{"2":{"242":1}}],["除非我们在刚刚好的地方",{"2":{"242":1}}],["除非我们再搭建一个复杂的实时标注流程",{"2":{"192":1}}],["除非我们添加另一列填充",{"2":{"142":1}}],["除了画出学习曲线之外",{"2":{"1138":1}}],["除了梯度下降算法以外",{"2":{"1109":1}}],["除了梯度截断",{"2":{"314":1}}],["除了对角线元素外",{"2":{"1090":1}}],["除了对原始序列可以随机抽样外",{"2":{"321":1}}],["除了我教你的内容以外",{"2":{"1059":1}}],["除了我们在这一章中探讨的情感分析之外",{"2":{"657":1}}],["除了为整个variable分配一个值之外",{"2":{"1020":1}}],["除了按元素计算外",{"2":{"1018":1}}],["除了数据",{"2":{"1001":1}}],["除了批量大小这一维度外",{"2":{"956":1}}],["除了坐标刻度不同",{"2":{"863":1}}],["除了需要拆分和聚合数据外",{"2":{"828":1}}],["除了物理大小之外",{"2":{"810":1}}],["除了显式地阻塞操作之外",{"2":{"791":1}}],["除了找到相似的词",{"2":{"751":1}}],["除了用卷积层代替循环神经网络层外",{"2":{"702":1}}],["除了机器翻译",{"2":{"537":1}}],["除了xj",{"2":{"519":1}}],["除了使用略高的学习率外",{"2":{"509":1}}],["除了使用我们刚刚定义的batchnorm",{"2":{"474":1}}],["除了使用优化算法来减少训练误差之外",{"2":{"99":1}}],["除了最后的全局平均汇聚层和最接近输出的全连接层",{"2":{"862":1}}],["除了最后的卷积层",{"2":{"461":4}}],["除了最大限度地减少训练时间",{"2":{"74":1}}],["除了这些障碍",{"2":{"454":1}}],["除了值之外",{"2":{"431":1}}],["除了庞大的数据集和强大的硬件",{"2":{"421":1}}],["除了编码器中描述的两个子层之外",{"2":{"404":1}}],["除了捕获绝对位置信息之外",{"2":{"400":1}}],["除了一元语法词",{"2":{"318":1}}],["除了端到端的训练",{"2":{"302":1}}],["除了权重衰减",{"2":{"280":1}}],["除了训练和测试数据集之外",{"2":{"256":1}}],["除了多层感知机的排列对称性之外",{"2":{"250":1}}],["除了分布偏移",{"2":{"203":1}}],["除了",{"2":{"196":1,"936":1}}],["除了从零开始收集新标签和训练",{"2":{"193":1}}],["除了平均汇聚层和最大汇聚层",{"2":{"150":1}}],["除了高端相机配备了特殊功能来解决这个问题",{"2":{"145":1}}],["除了局部最小值之外",{"2":{"102":1}}],["除了计算效率之外",{"2":{"77":1}}],["除了考虑目标函数的值和梯度",{"2":{"58":1}}],["除了满足ci",{"2":{"49":1}}],["除此之外",{"2":{"34":1,"136":1,"567":1,"811":1}}],["惩罚因子exp⁡",{"2":{"578":1}}],["惩罚",{"0":{"49":1}}],["约束是可以被p",{"2":{"1145":1}}],["约束",{"0":{"47":1},"1":{"48":1,"49":1,"50":1}}],["此前我们说过",{"2":{"1107":1}}],["此导数也是曲线u=f",{"2":{"981":1}}],["此实现是基本的二维转置卷积运算",{"2":{"968":1}}],["此损失的定义为",{"2":{"966":1}}],["此损失称为交叉熵损失",{"2":{"648":1}}],["此基本网络块输出的特征图形状为32×32",{"2":{"958":1}}],["此卷积层的输入和输出的宽度和高度保持不变",{"2":{"954":1}}],["此处的输出包括",{"2":{"959":1}}],["此处的标签也采用图像格式",{"2":{"945":1}}],["此处为均值和方差",{"2":{"472":1}}],["此划分的主要目的是促进对除输出层以外所有层的模型参数进行微调",{"2":{"873":3}}],["此算法在下面的assign",{"2":{"851":1}}],["此算法收敛迅速",{"2":{"62":1}}],["此类寄存器最长可达512位",{"2":{"809":1}}],["此类系统的准确性已经提高到与人类同等水平的程度",{"2":{"301":1}}],["此任务称为掩蔽语言模型",{"2":{"736":1}}],["此超参数通常称为transformer编码器的隐藏大小",{"2":{"734":1}}],["此函数用于正样本",{"2":{"1144":1}}],["此函数不会沿任何轴降低输入张量的维度",{"2":{"996":1}}],["此函数中的参数valid",{"2":{"890":1}}],["此函数在输入图像img上多次运行图像增广方法aug并显示所有结果",{"2":{"878":1}}],["此函数将背景类别的索引设置为零",{"2":{"852":1}}],["此函数返回一个可以在训练期间加载用于计算的小批量",{"2":{"776":1}}],["此函数返回一个形状为",{"2":{"545":1}}],["此函数返回两个词元列表",{"2":{"566":1}}],["此函数初始化卷积层权重",{"2":{"141":4}}],["此步骤可能需要额外的输入",{"2":{"534":1}}],["此代码生成两种类型的网络",{"2":{"501":1}}],["此操作可能不会常用于在任何实际任务中",{"2":{"425":1}}],["此模型主要由基础网络组成",{"2":{"953":1}}],["此模型会收敛到最优结果",{"2":{"389":1}}],["此模型忽略了隐状态的特性及其更新方式的细节",{"2":{"307":1}}],["此刻读者正在阅读本书",{"2":{"354":1}}],["此向量是原始词元的一个独热向量",{"2":{"330":1}}],["此变量还包含其他信息",{"2":{"325":1}}],["此解决方案有助于处理单元素问题",{"2":{"316":1}}],["此数据可以用来尝试预测患者是否会存活",{"2":{"284":1}}],["此数据集由bart",{"2":{"205":1}}],["此后我们还将提到其他类型的非监督学习算法",{"2":{"1150":1}}],["此后新一轮循环开始",{"2":{"298":1}}],["此后",{"2":{"179":1,"1150":1}}],["此时开发者工具中已经有了pinia选项",{"2":{"1489":1}}],["此时这么修改age页面是不变化的",{"2":{"1451":1,"1454":1}}],["此时这么修改name页面是不变化的",{"2":{"1451":1,"1454":1}}],["此时如果你仔细观察代价函数只留下了第二项",{"2":{"1143":1}}],["此时在目标函数中只需有第一项起作用",{"2":{"1143":1}}],["此时的name",{"2":{"1451":1,"1454":1}}],["此时的误差单元也是一个矩阵",{"2":{"1121":1}}],["此时的目标是生成一个模型",{"2":{"290":1}}],["此时模型中的参数是一个n+1维的向量",{"2":{"1080":1}}],["此时已经为这nb个锚框各自分配了一个真实边界框",{"2":{"851":1}}],["此时输出的通道数减为10",{"2":{"481":1}}],["此时选择书是受到了认知和意识的控制",{"2":{"355":1}}],["此时测试集的准确性却下降了",{"2":{"251":1}}],["此时",{"2":{"71":1,"151":1,"418":2,"429":1,"542":1,"843":1,"851":1,"854":1,"912":1}}],["此条成立的条件为",{"2":{"46":1}}],["此外你将听到诸如",{"2":{"1059":1}}],["此外通过反向传播进行计算可能雪上加霜",{"2":{"59":1}}],["此外",{"2":{"19":1,"33":1,"34":1,"38":1,"48":1,"49":1,"54":1,"67":1,"69":1,"72":1,"80":1,"86":1,"102":1,"103":1,"105":1,"113":1,"130":1,"141":1,"145":1,"146":1,"151":1,"158":1,"165":1,"170":1,"185":1,"201":2,"240":1,"242":1,"247":1,"248":1,"253":2,"258":1,"260":1,"270":1,"278":2,"284":2,"292":1,"294":1,"298":2,"301":1,"302":1,"318":1,"325":1,"332":1,"425":1,"429":1,"440":1,"450":1,"454":1,"455":1,"457":1,"459":1,"460":1,"472":1,"475":1,"519":1,"568":1,"578":1,"584":1,"590":1,"631":1,"640":1,"643":1,"644":1,"741":1,"756":1,"773":1,"810":3,"816":1,"821":1,"825":1,"832":4,"842":1,"844":1,"865":1,"869":1,"872":1,"877":1,"882":1,"912":1,"923":1,"938":1,"945":1,"947":1,"966":1,"1007":1,"1059":1,"1143":1,"1176":1}}],["多重继承",{"2":{"1423":1}}],["多重集ci=",{"2":{"742":1}}],["多容器应用编排",{"2":{"1347":1}}],["多版本python环境切换",{"2":{"1294":1}}],["多版本并发控制",{"2":{"1200":1}}],["多种异常捕获",{"0":{"1250":1}}],["多年我一直在研究直升飞机自动驾驶",{"2":{"1156":1}}],["多年来已经提出了其许多变体",{"2":{"561":1}}],["多云",{"2":{"1112":1}}],["多类别分类",{"0":{"1112":1},"2":{"1193":1}}],["多类分类问题",{"2":{"1148":1}}],["多类分类",{"0":{"1103":1},"2":{"1193":1}}],["多变量梯度下降",{"0":{"1081":1},"2":{"1193":1}}],["多变量线性回归的批量梯度下降算法为",{"2":{"1081":1}}],["多变量线性回归",{"0":{"1079":1},"1":{"1080":1,"1081":1,"1082":1,"1083":1,"1084":1,"1085":1,"1086":1},"2":{"1193":1}}],["多维特征",{"0":{"1080":1},"2":{"1193":1}}],["多维函数f",{"2":{"46":1}}],["多模态输入的交互式",{"2":{"1054":1}}],["多轮记忆",{"2":{"1054":1}}],["多轮任务链",{"2":{"1050":1}}],["多步推理",{"2":{"1053":1}}],["多源数据整合",{"2":{"1053":1}}],["多元高斯分布模型",{"2":{"1184":1}}],["多元高斯分布模型与原高斯分布模型的关系",{"2":{"1184":1}}],["多元高斯分布将创建像图中蓝色曲线所示的判定边界",{"2":{"1184":1}}],["多元高斯分布",{"0":{"1184":1},"2":{"1193":1}}],["多元函数通常是复合",{"2":{"984":1}}],["多元梯度下降",{"0":{"57":1}}],["多尺度检测",{"0":{"913":1}}],["多尺度锚框",{"0":{"912":1}}],["多尺度目标检测和用于目标检测的数据集",{"2":{"952":1}}],["多尺度目标检测",{"0":{"911":1},"1":{"912":1,"913":1,"914":1,"915":1}}],["多机训练",{"0":{"843":1}}],["多gpu训练",{"0":{"831":1,"883":1},"1":{"832":1,"833":1,"834":1,"835":1,"836":1,"837":1,"838":1,"839":1}}],["多gpu的简洁实现",{"0":{"825":1},"1":{"826":1,"827":1,"828":1,"829":1,"830":1}}],["多gpu和整体并行处理的关键",{"2":{"32":1}}],["多义词元",{"2":{"727":1}}],["多少信息能够存储一个环中",{"2":{"815":1}}],["多少",{"2":{"639":1}}],["多层",{"2":{"561":1}}],["多层感知机分类器的输出层",{"2":{"737":1}}],["多层感知机和传统的卷积神经网络",{"2":{"475":1}}],["多层感知机中的仿射变换输出",{"2":{"467":1}}],["多层感知机在输出层和输入层之间增加一个或多个全连接隐藏层",{"2":{"238":1}}],["多层感知机是通用近似器",{"2":{"233":1}}],["多层感知机可以通过隐藏神经元",{"2":{"233":1}}],["多层感知机可能需要数十亿个参数来表示网络中的一层",{"2":{"155":1}}],["多层感知机可能是最好的选择",{"2":{"151":1}}],["多层感知机由多层神经元组成",{"2":{"204":1}}],["多层感知机",{"0":{"204":1,"228":1},"1":{"229":1,"230":1,"231":1,"232":1,"233":1,"234":1,"235":1,"236":1,"237":1,"238":1,"239":1}}],["多层感知机的实现与softmax回归的实现相同",{"2":{"226":1}}],["多层感知机的简洁实现",{"0":{"224":1},"1":{"225":1,"226":1,"227":1}}],["多层感知机的训练过程与softmax回归的训练过程完全相同",{"2":{"221":1}}],["多层感知机的从零开始实现",{"0":{"216":1},"1":{"217":1,"218":1,"219":1,"220":1,"221":1,"222":1,"223":1}}],["多层感知机的输入是二维图像x",{"2":{"153":1}}],["多层感知机的限制",{"0":{"153":1},"1":{"154":1,"155":1}}],["多头自注意力用于表示输入序列和输出序列",{"2":{"410":1}}],["多头自注意力和基于位置的前馈网络",{"2":{"407":1}}],["多头注意力融合了来自于多个注意力汇聚的不同知识",{"2":{"383":1}}],["多头注意力输出的形状是",{"2":{"382":1}}],["多头注意力的输出需要经过另一个线性转换",{"2":{"381":1}}],["多头注意力",{"0":{"380":1},"1":{"381":1,"382":1,"383":1,"384":1},"2":{"382":3}}],["多级表示学习",{"2":{"302":1}}],["多阶段设计",{"2":{"300":1}}],["多项分类复杂得多",{"2":{"291":1}}],["多项式核函数",{"2":{"1148":1}}],["多项式对多变量数据的自然扩展称为单项式",{"2":{"269":1}}],["多项式的阶数",{"2":{"268":1}}],["多项式的最大阶数",{"2":{"262":1}}],["多项式回归",{"0":{"261":1},"1":{"262":1,"263":1,"264":1,"265":1,"266":1}}],["多项式衰减的一种替代方案是乘法衰减",{"2":{"70":1}}],["多项式衰减和分段常数表",{"2":{"69":1}}],["多个",{"2":{"1209":1}}],["多个神经网络同时工作",{"2":{"1127":1}}],["多个处理单元组成",{"2":{"789":1}}],["多个gpu能够处理不断变大的网络",{"2":{"832":1}}],["多个gpu同时增加了内存和计算能力",{"2":{"832":1}}],["多个gpu",{"2":{"789":1}}],["多个小操作比一个大操作糟糕得多",{"2":{"450":1}}],["多个输入和输出通道使模型在每个空间位置可以获取图像的多方面特征",{"2":{"159":1}}],["多个通道",{"0":{"148":1}}],["多输出通道并不仅是学习多个单通道的检测器",{"2":{"121":1}}],["多输出通道",{"0":{"121":1}}],["多输入通道的一维互相关等价于单输入通道的二维互相关",{"2":{"705":1}}],["多输入通道的一维互相关等同于单输入通道的二维互相关",{"2":{"699":1}}],["多输入通道",{"0":{"120":1}}],["多输入多输出通道可以用来扩展卷积层的模型",{"2":{"123":1}}],["多输入多输出通道",{"0":{"119":1},"1":{"120":1,"121":1,"122":1,"123":1,"124":1}}],["多因子调度器",{"0":{"71":1}}],["第9周",{"0":{"1177":1},"1":{"1178":1,"1179":1,"1180":1,"1181":1,"1182":1,"1183":1,"1184":1,"1185":1,"1186":1,"1187":1,"1188":1,"1189":1,"1190":1,"1191":1,"1192":1}}],["第8周",{"0":{"1149":1},"1":{"1150":1,"1151":1,"1152":1,"1153":1,"1154":1,"1155":1,"1156":1,"1157":1,"1158":1,"1159":1,"1160":1,"1161":1,"1162":1}}],["第8列和第9列相同",{"2":{"398":1}}],["第7周",{"0":{"1142":1},"1":{"1143":1,"1144":1,"1145":1,"1146":1,"1147":1,"1148":1}}],["第6周",{"0":{"1128":1},"1":{"1129":1,"1130":1,"1131":1,"1132":1,"1133":1,"1134":1,"1135":1,"1136":1,"1137":1,"1138":1,"1139":1,"1140":1,"1141":1}}],["第6列和第7列之间的偏移量",{"2":{"398":1}}],["第5周",{"0":{"1118":1},"1":{"1119":1,"1120":1,"1121":1,"1122":1,"1123":1,"1124":1,"1125":1,"1126":1,"1127":1}}],["第3周",{"0":{"1104":1},"1":{"1105":1,"1106":1,"1107":1,"1108":1,"1109":1,"1110":1,"1111":1,"1112":1,"1113":1,"1114":1,"1115":1,"1116":1,"1117":1}}],["第八",{"0":{"1096":1},"1":{"1097":1,"1098":1,"1099":1,"1100":1,"1101":1,"1102":1,"1103":1}}],["第4周",{"0":{"1095":1},"1":{"1096":1,"1097":1,"1098":1,"1099":1,"1100":1,"1101":1,"1102":1,"1103":1}}],["第2周",{"0":{"1078":1},"1":{"1079":1,"1080":1,"1081":1,"1082":1,"1083":1,"1084":1,"1085":1,"1086":1,"1087":1,"1088":1,"1089":1,"1090":1,"1091":1,"1092":1,"1093":1,"1094":1}}],["第2j列和2j+1列上的元素为",{"2":{"398":1}}],["第",{"2":{"1077":1,"1121":1}}],["第j列的元素",{"2":{"1072":1}}],["第j列的元素xij是锚框ai和真实边界框bj的iou",{"2":{"851":1}}],["第10周",{"0":{"1163":1},"1":{"1164":1,"1165":1,"1166":1,"1167":1,"1168":1,"1169":1,"1170":1,"1171":1,"1172":1,"1173":1,"1174":1,"1175":1,"1176":1}}],["第10个还不到第1个的1",{"2":{"318":1}}],["第1周",{"0":{"1057":1},"1":{"1058":1,"1059":1,"1060":1,"1061":1,"1062":1,"1063":1,"1064":1,"1065":1,"1066":1,"1067":1,"1068":1,"1069":1,"1070":1,"1071":1,"1072":1,"1073":1,"1074":1,"1075":1,"1076":1,"1077":1}}],["第五个模块为全局汇聚层",{"2":{"959":1}}],["第五模块的后面紧跟输出层",{"2":{"488":1}}],["第五模块包含输出通道数为256+320+128+128=832和384+384+128+128=1024的两个inception块",{"2":{"488":1}}],["第i个文本序列的词元列表",{"2":{"566":2}}],["第l个隐藏层的隐状态使用激活函数ϕl",{"2":{"527":1}}],["第四模块中的一致",{"2":{"488":1}}],["第四模块更加复杂",{"2":{"488":1}}],["第四条路径使用3×3最大汇聚层",{"2":{"487":1}}],["第四种选择提供了一个实践上很有用的方案",{"2":{"77":1}}],["第三种修改方式",{"2":{"1491":1}}],["第三种写法",{"2":{"1469":1}}],["第三种选择表面上是最可取的",{"2":{"77":1}}],["第三步",{"2":{"1454":1,"1499":1}}],["第三步是计算协方差矩阵σ的特征向量",{"2":{"1159":1}}],["第三工程队给你五百个特征",{"2":{"1156":1}}],["第三层也就是输出层做出的预测利用的是第二层的特征",{"2":{"1101":1}}],["第三列的最大值是7",{"2":{"1090":1}}],["第三行是9",{"2":{"1090":1}}],["第三行第二列的元素大于等于7",{"2":{"1090":1}}],["第三行采用通过时间的完全反向传播",{"2":{"311":1}}],["第三个模型是一个四次方的模型",{"2":{"1114":1}}],["第三个模块串联两个完整的inception块",{"2":{"488":1}}],["第三个例子",{"2":{"1112":1}}],["第三个例子是触觉皮带",{"2":{"1098":1}}],["第三个例子显示了一种",{"2":{"665":1}}],["第三个性质简单地说范数必须是非负的",{"2":{"1000":1}}],["第三个元素包含标记的输入锚框的类别",{"2":{"853":1}}],["第三类是正确的预测",{"2":{"633":1}}],["第三条路径都会先按比例减小通道数",{"2":{"488":1}}],["第三",{"2":{"311":1,"467":1}}],["第三代工具",{"2":{"300":1}}],["第三维",{"2":{"126":1}}],["第一步",{"2":{"1454":1,"1489":1,"1503":1}}],["第一步是运用主要成分分析将数据压缩至1000个特征",{"2":{"1162":1}}],["第一步是均值归一化",{"2":{"1159":1}}],["第一步是将一个文本序列中的词元与另一个序列中的每个词元对齐",{"2":{"674":1}}],["第一步是计算目标函数j=l+s相对于损失项l和正则项s的梯度",{"2":{"164":1}}],["第一",{"2":{"1187":1}}],["第一件要做的事是选择网络结构",{"2":{"1126":1}}],["第一印象通常是",{"2":{"1122":1}}],["第一行写着",{"2":{"1092":1}}],["第一行的最大值是等于8",{"2":{"1090":1}}],["第一行第一列的元素大于等于7",{"2":{"1090":1}}],["第一行采用随机截断",{"2":{"311":1}}],["第一类第二类或者第三类癌症",{"2":{"1060":1}}],["第一类是正确的预测",{"2":{"633":1}}],["第一种修改方式",{"2":{"1491":1}}],["第一种",{"2":{"1477":1}}],["第一种写法",{"2":{"1469":1}}],["第一种有关锚框类别的损失",{"2":{"962":1}}],["第一种方法",{"2":{"832":1}}],["第一种策略",{"2":{"347":1}}],["第一代tpu支持数量为1",{"2":{"811":1}}],["第一次读取的成本是后续读取的500倍",{"2":{"802":1}}],["第一次存取的额外开销很大",{"2":{"77":1}}],["第一部分主要由卷积层和汇聚层组成",{"2":{"508":1}}],["第一层的单元数即我们训练集的特征数量",{"2":{"1126":1}}],["第一层的卷积窗口形状通常由用户设置",{"2":{"494":1}}],["第一层成为输入层",{"2":{"1099":1}}],["第一层和第三层输出风格特征",{"2":{"917":1}}],["第一层是",{"2":{"225":1}}],["第一作者的名字命名",{"2":{"247":1}}],["第一组照片是在清晨拍摄的",{"2":{"186":1}}],["第一组存在不包含在集合内部的线段",{"2":{"40":1}}],["第一卷积层有6个输出通道",{"2":{"136":1}}],["第一个循环是用于减小c",{"2":{"1152":1}}],["第一个for循环是赋值步骤",{"2":{"1151":1}}],["第一个模型是一个线性模型",{"2":{"1114":1}}],["第一个模块输出特征图的形状为32×32",{"2":{"959":1}}],["第一个模块有64个输出通道",{"2":{"508":1}}],["第一个模块的通道数同输入通道数一致",{"2":{"502":1}}],["第一个模块使用64个通道",{"2":{"488":1}}],["第一个模块类似于alexnet和lenet",{"2":{"488":1}}],["第一个例子",{"2":{"1112":1}}],["第一个值为1或0用于预测是否是行人",{"2":{"1103":1}}],["第一个值是与偏置相对应的常量特征",{"2":{"262":1}}],["第一个房子样本",{"2":{"1089":1}}],["第一个机器学习的定义来自于arthur",{"2":{"1059":1}}],["第一个视频主要讲了什么是机器学习",{"2":{"1058":1}}],["第一个测试更准确",{"2":{"1038":1}}],["第一个被称为联合概率",{"2":{"1030":1}}],["第一个元素是3",{"2":{"1089":1}}],["第一个元素是预测的类索引",{"2":{"854":1}}],["第一个元素的索引是0",{"2":{"1020":1}}],["第一个输出张量的轴",{"2":{"1018":1}}],["第一个性质是",{"2":{"1000":1}}],["第一个文本序列的标记",{"2":{"734":1}}],["第一个样本的预测类别是2",{"2":{"634":1}}],["第一个指定输入特征形状",{"2":{"591":2}}],["第一个是训练样本的代价",{"2":{"1143":1}}],["第一个是基本网络块",{"2":{"959":1}}],["第一个是预测序列与标签序列中匹配的n元语法的数量",{"2":{"578":1}}],["第一个是update函数",{"2":{"57":1}}],["第一个序列的损失应为第二个序列的两倍",{"2":{"575":1}}],["第一个轴对应于时间步",{"2":{"573":3}}],["第一个词元的影响至关重要",{"2":{"538":1}}],["第一个组件是一个编码器",{"2":{"532":1}}],["第一个inception块的输出通道数为64+128+32+32=256",{"2":{"488":1}}],["第一个卷积层是64个通道",{"2":{"488":1}}],["第一个卷积层使用2个像素的填充",{"2":{"136":1}}],["第一个子层",{"2":{"408":1}}],["第一个子层是多头自注意力",{"2":{"404":1}}],["第一个隐藏单元与第二个隐藏单元没有什么特别的区别",{"2":{"244":1}}],["第一个特征是id",{"2":{"208":1}}],["第一个问题是关于区分来自两个分布的数据",{"2":{"191":1}}],["第一个通道的结果与先前输入张量x和多输入单输出通道的结果一致",{"2":{"121":1}}],["第二步",{"2":{"1454":1,"1489":1,"1503":1}}],["第二步是计算协方差矩阵",{"2":{"1159":1}}],["第二工程队给你另外三百个的特征",{"2":{"1156":1}}],["第二点概念上的变化",{"2":{"1143":1}}],["第二列是9",{"2":{"1090":1}}],["第二列就被替换为",{"2":{"1089":1}}],["第二行最大值是7",{"2":{"1090":1}}],["第二行第三列的元素大于等于7",{"2":{"1090":1}}],["第二行采用常规截断",{"2":{"311":1}}],["第二套房子面积为1600",{"2":{"1089":1}}],["第二次测试使我们能够对患病的情况获得更高的信心",{"2":{"1035":1}}],["第二次测试也显示阳性",{"2":{"1035":1}}],["第二到第四个模块为高和宽减半块",{"2":{"959":1}}],["第二到第五个区块都是",{"2":{"959":1}}],["第二部分由全连接层组成",{"2":{"508":1}}],["第二条和第三条路径首先将输入通道的数量分别减少到128",{"2":{"488":1}}],["第二层和第五层卷积层之后",{"2":{"459":1}}],["第二层中的卷积窗口形状被缩减为5×5",{"2":{"459":1}}],["第二层是输出层",{"2":{"225":1}}],["第二种修改方式",{"2":{"1491":1}}],["第二种",{"2":{"1477":1}}],["第二种写法",{"2":{"1469":1}}],["第二种应用就是社交网络的分析",{"2":{"1061":1}}],["第二种有关正类锚框偏移量的损失",{"2":{"962":1}}],["第二种方法",{"2":{"832":1}}],["第二种方法比第一种方法快得多",{"2":{"615":1}}],["第二种策略",{"2":{"347":1}}],["第二种选择相对更有利",{"2":{"77":1}}],["第二个for循环是聚类中心的移动",{"2":{"1151":1}}],["第二个是我们的正则化项",{"2":{"1143":1}}],["第二个是预测序列中n元语法的数量的比率",{"2":{"578":1}}],["第二个例子是有关药物诊断的",{"2":{"1112":1}}],["第二个值用于判断是否为汽车",{"2":{"1103":1}}],["第二个",{"2":{"1092":1}}],["第二个元素2乘以12得到24",{"2":{"1090":1}}],["第二个元素是2",{"2":{"1089":1}}],["第二个元素是预测的边界框的置信度",{"2":{"854":1}}],["第二个原因是",{"2":{"1086":1}}],["第二个输出是这样",{"2":{"1061":1}}],["第二个输出张量的轴",{"2":{"1018":1}}],["第二个测试具有不同的特性",{"2":{"1035":1}}],["第二个性质是熟悉的三角不等式",{"2":{"1000":1}}],["第二个到第四个是高和宽减半块",{"2":{"959":1}}],["第二个句子是从语料库中随机抽取的",{"2":{"737":1}}],["第二个文本序列标记",{"2":{"734":1}}],["第二个样本的预测类别是2",{"2":{"634":1}}],["第二个指定输出特征形状",{"2":{"591":2}}],["第二个组件是解码器",{"2":{"532":1}}],["第二个inception块的输出通道数增加到128+192+96+64=480",{"2":{"488":1}}],["第二个和第三个路径首先将输入通道的数量分别减少到96",{"2":{"488":1}}],["第二个卷积层使用将通道数量增加三倍的3×3卷积层",{"2":{"488":1}}],["第二个卷积层没有填充",{"2":{"136":1}}],["第二个模块使用两个卷积层",{"2":{"488":1}}],["第二个gpu",{"2":{"449":1}}],["第二个gpu上创建一个随机张量",{"2":{"448":1}}],["第二个子块的第一层的偏置项",{"2":{"433":1}}],["第二个子层是基于位置的前馈网络",{"2":{"404":1}}],["第二个最低位和第三个最低位上分别交替",{"2":{"399":1}}],["第二个小批量包含n个矩阵y1",{"2":{"390":1}}],["第二个问题是关于",{"2":{"191":1}}],["第二个维度给出每个样本的平面向量表示",{"2":{"136":1}}],["第二个函数会显示x的轨迹",{"2":{"57":1}}],["第二",{"2":{"46":1,"467":1,"811":1,"835":1}}],["通知vue数据msg变化了",{"2":{"1520":1}}],["通知",{"0":{"1047":1}}],["通信",{"2":{"1047":1,"1377":1}}],["通信机制",{"0":{"1043":1},"1":{"1044":1,"1045":1,"1046":1,"1047":1}}],["通信协议与使用指南笔记",{"0":{"1039":1},"1":{"1040":1,"1041":1,"1042":1,"1043":1,"1044":1,"1045":1,"1046":1,"1047":1,"1048":1}}],["通",{"2":{"849":1}}],["通它要显著地小于穷举搜索",{"2":{"514":1}}],["通用架构",{"0":{"1042":1}}],["通用核心的制造成本非常高",{"2":{"457":1}}],["通用近似定理",{"0":{"233":1}}],["通俗地说",{"2":{"235":1}}],["通道的10222张",{"2":{"900":1}}],["通道的数量从输入时的1个",{"2":{"136":1}}],["通道维包含中心相同的锚框的预测结果",{"2":{"956":1}}],["通道维的输出即该位置对应像素的类别预测",{"2":{"861":1}}],["通道维",{"2":{"699":1}}],["通道维度",{"2":{"120":2}}],["通道最后",{"2":{"147":1,"148":1}}],["通道数为c",{"2":{"923":1}}],["通道数为10的",{"2":{"481":1}}],["通道数量",{"2":{"913":1}}],["通道数量增加",{"2":{"502":1}}],["通道数",{"2":{"136":3,"702":3,"882":1,"932":1,"956":1}}],["通道",{"0":{"158":1},"2":{"129":4,"494":1}}],["通过组合小型组件构建复杂",{"2":{"1527":1}}],["通过点击导航",{"2":{"1475":1}}],["通过ref获取元素",{"2":{"1468":1}}],["通过read",{"2":{"932":1}}],["通过id获取元素",{"2":{"1468":1}}],["通过is",{"2":{"472":1}}],["通过toref将person对象中的gender属性取出",{"2":{"1459":1}}],["通过torefs将person对象中的n个属性批量取出",{"2":{"1459":1}}],["通过totensor实例将图像数据从uint8格式变换成32位浮点数格式",{"2":{"583":1}}],["通过totensor实例将图像数据从pil类型变换成32位浮点数格式",{"2":{"582":1}}],["通过节点",{"2":{"1384":1}}],["通过后才执行",{"2":{"1315":1}}],["通过后端异步处理",{"0":{"790":1}}],["通过学习特征参数",{"2":{"1191":1}}],["通过学习本章",{"2":{"824":1}}],["通过协方差矩阵",{"2":{"1184":4}}],["通过分别计算每个特征对应的几率然后将其累乘起来",{"2":{"1184":1}}],["通过分配新内存",{"2":{"994":3}}],["通过减小学习率",{"2":{"1167":1}}],["通过减少内部协变量偏移",{"2":{"475":1}}],["通过减少空间分辨率以获得更大的通道深度",{"2":{"121":1}}],["通过本周的编程作业",{"2":{"1147":1}}],["通过让间距变大",{"2":{"1145":1}}],["通过误差分析",{"2":{"1138":1}}],["通过画出学习曲线",{"2":{"1138":1}}],["通过观察人类的驾驶来学习驾驶",{"2":{"1127":1}}],["通过观察哪种布局",{"2":{"1059":1}}],["通过求导",{"2":{"1117":1}}],["通过已经确定的参数计算得出hθ",{"2":{"1107":1}}],["通过梯度下降",{"2":{"1100":1}}],["通过梯度下降观察x的轨迹",{"2":{"57":1}}],["通过几句简单的代码",{"2":{"1089":1}}],["通过以上这些操作",{"2":{"1089":1}}],["通过删除某些特征或者是使用某些技术",{"2":{"1086":1}}],["通过接下来几个视频",{"2":{"1070":1}}],["通过它们",{"2":{"1070":1}}],["通过那一部分计算出θ0和θ1的值",{"2":{"1067":1}}],["通过了解如何设计和构建机器学习和人工智能系统",{"2":{"1059":1}}],["通过标准的",{"2":{"1042":1}}],["通过标准的特征提取算法",{"2":{"454":1}}],["通过p",{"2":{"1028":1,"1178":1}}],["通过pytorch的基准输出比较快了几个数量级",{"2":{"790":1}}],["通过适当复制元素来扩展一个或两个数组",{"2":{"1019":1}}],["通过逻辑运算符构建二元张量",{"2":{"1018":1}}],["通过提供包含数值的python列表",{"2":{"1017":1}}],["通过改变张量的形状",{"2":{"1017":1}}],["通过改进模型",{"2":{"215":1}}],["通过位置索引iloc",{"2":{"1012":1}}],["通过广播将a除以sum",{"2":{"996":1}}],["通过指定两个分量m和n来创建一个形状为m×n的矩阵",{"2":{"992":1}}],["通过指定输入序列的有效长度",{"2":{"409":1}}],["通过张量的索引来访问任一元素",{"2":{"990":1}}],["通过张量来进行数据存储和线性代数",{"2":{"588":1}}],["通过令x=1并让h接近0",{"2":{"981":1}}],["通过非极大值抑制来移除相似的预测边界框",{"2":{"964":1}}],["通过参数num",{"2":{"954":1}}],["通过多尺度特征块",{"2":{"953":1}}],["通过多项式拟合来探索这些概念",{"2":{"261":1}}],["通过深度神经网络分层表示图像的多尺度目标检测的设计",{"2":{"953":1}}],["通过深度学习框架的高级api也能更方便地实现softmax回归模型",{"2":{"622":1}}],["通过深度学习框架的高级api能够使实现",{"2":{"622":1}}],["通过深度学习框架的高级api来实现我们的模型只需要相对较少的代码",{"2":{"595":1}}],["通过上面定义的两个常量",{"2":{"945":1}}],["通过上述步骤",{"2":{"367":1}}],["通过全连接层将输出形状变换为n×d",{"2":{"938":1}}],["通过定义特征图的形状",{"2":{"912":1,"914":1}}],["通过定义代码来按需生成任意复杂度的块",{"2":{"422":1}}],["通过微调预训练获得的模型参数",{"2":{"874":1}}],["通过微分",{"2":{"784":1,"786":1}}],["通过元素乘法",{"2":{"853":1}}],["通过细节可以知道",{"2":{"840":1}}],["通过混合式编程加速",{"0":{"820":1}}],["通过z",{"2":{"791":1}}],["通过飞桨的基准输出比较快了几个数量级",{"2":{"790":1}}],["通过mxnet的基准输出比较快了几个数量级",{"2":{"790":1}}],["通过主动地减少计算需求和相互依赖",{"2":{"789":1}}],["通过d2l",{"2":{"740":1}}],["通过掩码下的预测词元mlm",{"2":{"736":1}}],["通过事件s",{"2":{"708":1}}],["通过增加微调迭代轮数",{"2":{"690":1}}],["通过注意力机制",{"2":{"683":1}}],["通过实现",{"2":{"668":1,"722":1,"947":1}}],["通过向量形式表达为o=wx+b",{"2":{"641":1}}],["通过更改它们的值",{"2":{"635":1}}],["通过xiwi相乘来激活或抑制",{"2":{"619":1}}],["通过突触",{"2":{"619":1}}],["通过最大化似然对数来简化",{"2":{"616":1}}],["通过最终迭代获得的数值解可能仅使目标函数局部最优",{"2":{"101":1}}],["通过生成第二个特征features",{"2":{"599":1}}],["通过进行反向传播来计算梯度",{"2":{"595":1}}],["通过调节这些权重超参数",{"2":{"925":1}}],["通过调用反向传播函数来自动计算y关于x每个分量的梯度",{"2":{"974":1}}],["通过调用attach",{"2":{"974":1}}],["通过调用hybridize函数",{"2":{"819":1}}],["通过调用上述两个辅助函数",{"2":{"726":1}}],["通过调用前述的",{"2":{"721":1}}],["通过调用优化器来更新模型参数",{"2":{"595":1}}],["通过调用net",{"2":{"595":1}}],["通过调整超参数",{"2":{"337":1}}],["通过调整λ的值",{"2":{"49":1}}],["通过自动微分来计算梯度",{"2":{"588":1}}],["通过内置数据迭代器",{"2":{"583":1}}],["通过框架中的内置函数将fashion",{"2":{"582":1}}],["通过扩展softmax交叉熵损失函数来遮蔽不相关的预测",{"2":{"575":1}}],["通过零值化屏蔽不相关的项",{"2":{"575":1}}],["通过截断和填充文本序列",{"2":{"570":1}}],["通过num",{"2":{"528":1}}],["通过设置",{"2":{"523":3}}],["通过设计一个基于两个循环神经网络的编码器",{"2":{"373":1}}],["通过概率p",{"2":{"519":1}}],["通过灵活地选择束宽",{"2":{"515":1}}],["通过配置不同的通道数和模块里的残差块数可以得到不同的resnet模型",{"2":{"502":1}}],["通过一系列的",{"2":{"1047":1}}],["通过一系列的卷积层与汇聚层来提取空间结构特征",{"2":{"493":1}}],["通过一个具有两个输出",{"2":{"713":1}}],["通过一个全连接层计算所有vocab",{"2":{"408":1}}],["通过一个隐状态和一个输入",{"2":{"325":1}}],["通过不同窗口大小的卷积层和最大汇聚层来并行抽取信息",{"2":{"492":1}}],["通过autograd来判断当前模式是训练模式还是预测模式",{"2":{"472":1}}],["通过数据集统计规范化",{"2":{"467":1}}],["通过小批量统计数据规范化",{"2":{"467":1}}],["通过μ^b和σ^b",{"2":{"467":1}}],["通过智能地将数组分配给上下文",{"2":{"445":1}}],["通过智能地将数组分配给环境",{"2":{"445":2}}],["通过前向传播函数来生成输出",{"2":{"423":2}}],["通过前一帧的图像",{"2":{"295":1}}],["通过堆叠基于位置编码的自注意力层来表示序列",{"2":{"402":1}}],["通过这样的代价函数选择出的θ3和θ4",{"2":{"1115":1}}],["通过这样做",{"2":{"334":1}}],["通过这个方法",{"2":{"1191":1}}],["通过这个学习过程获得的特征矩阵包含了有关电影的重要数据",{"2":{"1189":1}}],["通过这个小方法",{"2":{"1112":1}}],["通过这个代价函数",{"2":{"1111":1}}],["通过这个过程",{"2":{"282":1}}],["通过这一系列octave的命令",{"2":{"1088":1}}],["通过这些被算法错误分类的垃圾邮件与非垃圾邮件",{"2":{"1138":1}}],["通过这些图形",{"2":{"1066":1}}],["通过这些练习",{"2":{"1059":1}}],["通过这三个用于图形配置的函数",{"2":{"981":1}}],["通过这种方式",{"2":{"698":1,"754":1}}],["通过拉普拉斯平滑法可以有效地处理结构丰富而频率不足的低频词词组",{"2":{"322":1}}],["通过顺序分区",{"2":{"321":1}}],["通过此图我们可以发现",{"2":{"318":1}}],["通过时间反向传播依次计算并存储上述梯度",{"2":{"312":1}}],["通过时间反向传播的细节",{"0":{"312":1}}],["通过时间反向传播",{"0":{"306":1},"1":{"307":1,"308":1,"309":1,"310":1,"311":1,"312":1,"313":1,"314":1},"2":{"306":1,"313":2}}],["通过gpu",{"2":{"303":1}}],["通过取代大部分特定领域的预处理",{"2":{"302":1}}],["通过取ϵ对",{"2":{"59":1}}],["通过平均16名成年男性的脚的长度",{"2":{"299":1}}],["通过平方l2范数",{"2":{"270":1}}],["通过用数据集来确定程序行为",{"2":{"282":1}}],["通过操作参数而生成的所有不同程序",{"2":{"282":1}}],["通过公式p",{"2":{"280":1}}],["通过计算加权和并加上偏置来确定神经元是否应该被激活",{"2":{"234":1}}],["通过使用反向传播学习算法",{"2":{"1127":1}}],["通过使用read",{"2":{"932":1}}],["通过使用符号式编程提高了计算性能",{"2":{"820":3}}],["通过使用paddle",{"2":{"819":1}}],["通过使用tensorflow中的图模式执行方式实现的符号式编程提高了计算性能",{"2":{"820":1}}],["通过使用torch",{"2":{"819":1}}],["通过使用tanh作为激活函数",{"2":{"369":1}}],["通过使用预训练的transformer编码器",{"2":{"733":1}}],["通过使用",{"2":{"722":1,"1513":1}}],["通过使用深度学习框架来简洁地实现",{"2":{"588":1}}],["通过使用语言模型来生成文本",{"2":{"517":1}}],["通过使用循环和子程序",{"2":{"506":1}}],["通过使用任意算法生成数据的能力",{"2":{"300":1}}],["通过使用更深",{"2":{"233":1}}],["通过使用gpu",{"2":{"137":1}}],["通过高级api更简洁地实现多层感知机",{"2":{"224":1}}],["通过对",{"2":{"744":1}}],["通过对几个简单层的组合",{"2":{"526":1}}],["通过对整个序列预测的计算",{"2":{"351":1}}],["通过对k次实验的结果取平均来估计训练和验证误差",{"2":{"257":1}}],["通过对所有超参数",{"2":{"223":1}}],["通过对卷积神经网络一些巧妙的调整",{"2":{"134":1}}],["通过k折交叉验证调整超参数",{"2":{"215":1}}],["通过values属性",{"2":{"209":1}}],["通过亲身实践",{"2":{"205":1}}],["通过人工合成的很容易获得",{"2":{"191":1}}],["通过访问测试数据获取",{"2":{"191":1}}],["通过在宿主机上运行一个完整的操作系统来隔离应用",{"2":{"1353":1}}],["通过在不同设备上创建具有不同值的向量并聚合它们",{"2":{"835":1}}],["通过在测量之前需要预热设备",{"2":{"796":2}}],["通过在输入表示中添加",{"2":{"398":1}}],["通过在最后一个轴上掩蔽元素来执行softmax操作",{"2":{"368":4}}],["通过在一个大的数据集来训练图像分类器",{"2":{"188":1}}],["通过在每一层打印输出的形状",{"2":{"136":1}}],["通过将同步的所有复杂性隐藏在一个简单的push和pull操作背后",{"2":{"844":1}}],["通过将模型参数复制到一个gpu",{"2":{"835":1}}],["通过将jit",{"2":{"819":1}}],["通过将整个序列作为输入",{"2":{"731":1}}],["通过将注意步骤",{"2":{"677":1}}],["通过将softmax和交叉熵结合在一起",{"2":{"624":1}}],["通过将梯度设为0",{"2":{"621":1}}],["通过将它们打印出来可以发现",{"2":{"321":1}}],["通过将特征重新缩放到零均值和单位方差来标准化数据",{"2":{"209":1}}],["通过将基于模型的决策引入环境",{"2":{"179":1}}],["通过将核张量k与k+1",{"2":{"121":1}}],["通过按保留",{"2":{"170":1}}],["通过逐渐聚合信息",{"2":{"145":1}}],["通过下面的lenet代码",{"2":{"136":1}}],["通过空间下采样将维数减少4倍",{"2":{"136":1}}],["通过之前几节",{"2":{"135":1}}],["通过找到像素变化的位置",{"2":{"128":1}}],["通过",{"2":{"126":1,"1200":1,"1246":1,"1319":1,"1347":1,"1394":1,"1494":1}}],["通过泰勒展开",{"2":{"60":1}}],["通过单调性f",{"2":{"46":1}}],["通常应该使用的算法就是异常检测算法",{"2":{"1182":1}}],["通常如果我们认为变量",{"2":{"1179":1}}],["通常这些方面会比你使用逻辑回归还是svm这方面更加重要",{"2":{"1148":1}}],["通常这是自动发生的",{"2":{"423":2}}],["通常都会做相似的事情",{"2":{"1148":1}}],["通常根据训练集数量选择地标",{"2":{"1147":1}}],["通常从一层开始逐渐增加层数",{"2":{"1135":1}}],["通常选择较大的神经网络并采用正则化处理会比采用较小的神经网络效果要好",{"2":{"1135":1}}],["通常选取",{"2":{"1124":1}}],["通常用作其他类的基类",{"2":{"1415":1}}],["通常用于函数返回值",{"2":{"1404":1}}],["通常用np",{"2":{"1183":1}}],["通常用70",{"2":{"1130":1}}],["通常用a⊤来表示矩阵的转置",{"2":{"992":1}}],["通常比梯度下降算法要更加快速",{"2":{"1109":1}}],["通常运行速度就会比你以前用你的for循环快的多",{"2":{"1093":1}}],["通常一件最有用的事情是看看你的结果",{"2":{"1090":1}}],["通常可以考虑尝试些学习率",{"2":{"1083":1}}],["通常可以忽略以",{"2":{"1006":1}}],["通常不太会给算法起名字",{"2":{"1069":1}}],["通常不会改变对象的类别",{"2":{"879":1}}],["通常表示为小写",{"2":{"1063":1}}],["通常采用这些特征",{"2":{"1060":1}}],["通常采用观测数据或与环境交互的形式",{"2":{"281":1}}],["通常来说当n小于10000",{"2":{"1085":1}}],["通常来说",{"2":{"932":1,"1086":1,"1090":1,"1182":1}}],["通常来讲这不是一个明智的做法",{"2":{"462":1}}],["通常需要",{"2":{"1184":1}}],["通常需要更高的学习率才能从头开始训练",{"2":{"873":1}}],["通常需要以适合算法的方式表示数据",{"2":{"302":1}}],["通常编译模型的代码执行速度也比命令式编程更快",{"2":{"821":4}}],["通常执行核心能够同时执行许多操作",{"2":{"808":1}}],["通常在没有歧义时被∇f",{"2":{"983":1}}],["通常在几千次写入之后就已经老化了",{"2":{"805":1}}],["通常在设计架构时考虑的是更粗糙的块",{"2":{"421":1}}],["通常仅限于高端服务器芯片",{"2":{"802":1}}],["通常以更高级的拓扑方式连接",{"2":{"801":1}}],["通常每个核心256",{"2":{"810":1}}],["通常每个cpu核有多个线程",{"2":{"789":1}}],["通常每个样本由一组称为特征",{"2":{"284":1}}],["通常有几十万或数百万个单词",{"2":{"707":1}}],["通常我们会令",{"2":{"1166":1}}],["通常我们会选择非负数作为损失",{"2":{"611":1}}],["通常我们是看交叉验证集的误差",{"2":{"1138":1}}],["通常我们要对数据进行",{"2":{"1130":1}}],["通常我们需要先观察数据然后再决定准备尝试怎样的模型",{"2":{"1084":1}}],["通常我们使用预测概率最高的类别作为输出类别",{"2":{"653":1}}],["通常会遇到以下几种情况",{"2":{"1461":1}}],["通常会减少下采样输入图像的空间维度",{"2":{"967":1}}],["通常会存在大量的负锚框",{"2":{"966":1}}],["通常会通过σ",{"2":{"619":1}}],["通常会优化替代目标",{"2":{"286":1}}],["通常使用的程序语言就是octave",{"2":{"1088":1}}],["通常使用以下名称或概念",{"2":{"810":1}}],["通常使用gddr6模块",{"2":{"802":1}}],["通常使用成对的内存模块来允许多个通道",{"2":{"802":1}}],["通常使用",{"2":{"610":1}}],["通常使用线性递增",{"2":{"73":1}}],["通常能够提供同等的效果",{"2":{"538":1}}],["通常调整的超参数是每层输出通道数",{"2":{"487":1}}],["通常高级api变体运行速度快得多",{"2":{"474":1}}],["通常被表达为范数",{"2":{"1001":1}}],["通常被称为交叉熵损失",{"2":{"646":1}}],["通常被称为套索回归",{"2":{"270":1}}],["通常被分成更大的组",{"2":{"457":1}}],["通常也叫做词表",{"2":{"363":1}}],["通常通过其高级api",{"2":{"300":1}}],["通常称为伪逆矩阵",{"2":{"1090":1}}],["通常称为层",{"2":{"299":1}}],["通常称为测试数据集",{"2":{"286":1}}],["通常对于神经网络",{"2":{"254":1}}],["通常对应于较大梯度的坐标会显著缩小",{"2":{"25":1}}],["通常缩写为mlp",{"2":{"231":1}}],["通常基于训练数据进行训练",{"2":{"192":1}}],["通常是需要根据不同的问题",{"2":{"1154":1}}],["通常是",{"2":{"1133":1}}],["通常是有效的",{"2":{"1129":1}}],["通常是数值计算方面的博士或者专业人士开发的",{"2":{"1093":1}}],["通常是数据",{"2":{"303":1}}],["通常是因为特征之间不独立",{"2":{"1085":1}}],["通常是全带宽",{"2":{"812":1}}],["通常是固态硬盘或网络存储",{"2":{"798":1}}],["通常是近似的",{"2":{"300":1}}],["通常是高维的",{"2":{"182":1}}],["通常是低维",{"2":{"182":1}}],["通常情况下隐藏层单元的个数越多越好",{"2":{"1126":1}}],["通常情况下单个操作符将使用所有cpu或单个gpu上的所有计算资源",{"2":{"795":1}}],["通常情况下",{"2":{"179":1,"193":1,"314":1,"472":1,"980":1,"1021":1,"1091":1,"1092":1}}],["通常情况下多种类型的计算单元以及在它们之间不同的带宽限制",{"2":{"77":1}}],["通常线性模型不会过拟合",{"2":{"169":1}}],["通常该权重是可学习的参数",{"2":{"155":1}}],["通常当我们处理图像时",{"2":{"145":1}}],["通常填充元素是0",{"2":{"141":1}}],["通常同时增加通道的数量",{"2":{"136":1}}],["通常只有经过多次实验后才能找到合适的学习率",{"2":{"117":1}}],["通常带有标签yi",{"2":{"116":1}}],["通常",{"2":{"33":1,"40":1,"48":1,"49":1,"141":1,"142":1,"171":1,"201":1,"217":1,"247":1,"270":1,"282":1,"286":1,"295":1,"303":1,"312":1,"317":1,"338":1,"351":1,"436":1,"469":1,"519":1,"600":1,"609":1,"639":1,"784":1,"875":1,"1016":1,"1086":1}}],["βi",{"2":{"675":1}}],["βi=∑j=1nexp⁡",{"2":{"674":1}}],["βi=1",{"2":{"191":1}}],["βi=defp",{"2":{"191":1,"192":1}}],["βt+1",{"2":{"114":1}}],["βλ−ηβ",{"2":{"95":1}}],["βvt−1+λzt−1",{"2":{"94":1}}],["β",{"2":{"46":2,"95":2,"467":1}}],["β∈",{"2":{"46":1}}],["αδ得到的向量",{"2":{"1093":1}}],["α=0",{"2":{"1083":1}}],["α∂∂θ1j",{"2":{"1067":1}}],["α∂∂θ0j",{"2":{"1067":1}}],["αx",{"2":{"1000":1}}],["αj",{"2":{"675":1}}],["αj=∑i=1mexp⁡",{"2":{"674":1}}],["α通常设置为0",{"2":{"515":1}}],["α中采样",{"2":{"337":1}}],["αi=ηt",{"2":{"115":1}}],["αi≥0",{"2":{"48":1}}],["αn",{"2":{"48":2}}],["α1",{"2":{"48":2}}],["α",{"2":{"46":2,"367":1,"388":1,"743":1,"1093":3,"1110":1,"1111":2,"1167":1}}],["ϵ∼n",{"2":{"616":1}}],["ϵ可以视为模型预测和标签时的潜在观测误差",{"2":{"599":1}}],["ϵ1",{"2":{"316":1}}],["ϵ=−h−1∇f",{"2":{"59":1}}],["ϵ+o",{"2":{"59":1}}],["ϵ2和ϵ3是超参数",{"2":{"316":1}}],["ϵ2",{"2":{"54":1}}],["ϵ2≥0",{"2":{"46":1}}],["ϵ",{"2":{"52":1,"621":1}}],["ϵ是一个为维持数值稳定性而添加的常数",{"2":{"27":1}}],["更爱",{"2":{"1544":1}}],["更是一门艺术和创意的结合",{"2":{"1541":1}}],["更是推动现代软件工程演进的重要力量",{"2":{"1357":1}}],["更推荐写函数",{"2":{"1465":1}}],["更加优雅的组织代码",{"2":{"1449":1}}],["更加强大的方式",{"2":{"1143":1}}],["更适合高并发场景",{"2":{"1359":1}}],["更适合数据库内部存储和网络传输",{"2":{"1197":1}}],["更强的弹性",{"2":{"1357":1}}],["更强调",{"2":{"1050":1}}],["更智能的调度",{"2":{"1357":1}}],["更符合微服务架构的理念",{"2":{"1354":1}}],["更丰富的类型",{"2":{"1197":1}}],["更高的安全性",{"2":{"1357":1}}],["更高级的控制器",{"2":{"1383":1}}],["更高级",{"2":{"1111":1}}],["更高维度",{"2":{"1066":1}}],["更接近传统的网站url",{"2":{"1476":1}}],["更接近全局最低点了",{"2":{"1068":1}}],["更接近于代价函数j$的最小值",{"2":{"1066":1}}],["更接近于代价函数所表达的值是什么样的",{"2":{"1066":1}}],["更直观地感受一下这个算法是做什么的",{"2":{"1068":1}}],["更直观的是",{"2":{"168":1}}],["更自动化的",{"2":{"1052":1}}],["更快的r",{"2":{"936":1}}],["更快的策略是执行按列分配",{"2":{"77":1}}],["更有效的代码",{"2":{"1093":1}}],["更有代表性的数字是1",{"2":{"841":1}}],["更有可能与",{"2":{"741":1}}],["更简洁",{"2":{"836":1}}],["更易于移植",{"2":{"817":1}}],["更常见的数字在4",{"2":{"810":1}}],["更复杂",{"2":{"619":1,"1111":1}}],["更难做到的是找到一组参数",{"2":{"613":1}}],["更具体来说",{"2":{"1063":1}}],["更具体地说",{"2":{"103":1,"115":1,"196":1,"713":1,"783":1,"890":1,"912":1,"938":1,"957":1}}],["更具可读性",{"2":{"613":1}}],["更优雅的向量表示法比系数表示法",{"2":{"613":1}}],["更近似",{"2":{"500":2}}],["更深层的网络很复杂",{"2":{"467":1}}],["更大的内存",{"2":{"811":1}}],["更大的样本量有效地减少了过拟合",{"2":{"461":1}}],["更大或更干净的数据集",{"2":{"454":1}}],["更真实的数据集上训练卷积神经网络的性能和可行性还有待研究",{"2":{"454":1}}],["更好的了解用户",{"2":{"1058":1}}],["更好",{"2":{"372":1,"1141":1}}],["更通俗的解释",{"2":{"356":1}}],["更通常而言",{"2":{"68":1}}],["更仔细地看一下k步预测",{"2":{"351":1}}],["更改顺序划分",{"2":{"337":1}}],["更改超参数num",{"2":{"223":1}}],["更容易计算股票交易的问题等等",{"2":{"1143":1}}],["更容易",{"2":{"349":1}}],["更容易实现",{"2":{"278":1}}],["更容易训练的relu所取代",{"2":{"236":1}}],["更多参数的情况",{"2":{"1066":1}}],["更多延迟",{"0":{"813":1}}],["更多的数据可以被用来训练出更强大的模型",{"2":{"284":1}}],["更多的数据不会有什么坏处",{"2":{"260":1}}],["更多轶事",{"0":{"188":1}}],["更正式地说",{"2":{"251":1}}],["更正式地讲",{"2":{"46":1}}],["更稳定的relu系列函数已经成为从业者的默认选择",{"2":{"242":1}}],["更重要的是掌握怎样有效地利用这些工具来建立强大的机器学习系统",{"2":{"1176":1}}],["更重要的是你将会了解监督学习过程完整的流程",{"2":{"1063":1}}],["更重要的是设计网络的能力",{"2":{"499":1}}],["更重要的是",{"2":{"186":1}}],["更隐蔽的是",{"2":{"179":1}}],["更进一步来说",{"2":{"1063":1}}],["更进一步",{"2":{"142":1}}],["更麻烦的是",{"2":{"116":1}}],["更糟糕的是",{"2":{"77":2,"113":1,"450":1}}],["更新节奏",{"2":{"1548":1}}],["更新之前",{"2":{"1470":1}}],["更新完毕",{"2":{"1470":2}}],["更新阶段",{"2":{"1470":2}}],["更新",{"2":{"1470":1}}],["更新渲染快133",{"2":{"1438":1}}],["更新时触发",{"2":{"1315":1}}],["更新对象θj",{"2":{"1093":1}}],["更新值",{"2":{"1093":1}}],["更新后的参数信息发送到本地一个",{"2":{"843":1}}],["更新后的模型会更加倾向于针对同一个地区",{"2":{"201":1}}],["更新邮件",{"2":{"634":1}}],["更新参数",{"2":{"605":1}}],["更新门打开时",{"2":{"548":1}}],["更新门参数",{"2":{"544":4}}],["更新门有助于捕获序列中的长期依赖关系",{"2":{"542":1,"548":1}}],["更新门zt仅需要在",{"2":{"542":1}}],["更新门zt∈rn×h的计算如下所示",{"2":{"540":1}}],["更新门将允许我们控制新状态中有多少个是旧状态的副本",{"2":{"540":1}}],["更新移动平均的均值和方差",{"2":{"472":3}}],["更新这些参数可以优化某目标函数",{"2":{"422":1}}],["更新的模型",{"2":{"347":1}}],["更新隐状态",{"2":{"333":1}}],["更新模型参数时",{"2":{"278":1}}],["更新方程经常修改为ηt+1←max⁡",{"2":{"70":1}}],["更新它",{"2":{"20":1}}],["更泛化地说",{"2":{"50":1}}],["时写出来",{"2":{"1185":1}}],["时预测",{"2":{"1147":1}}],["时的异常检测算法",{"2":{"1176":1}}],["时的更新式子进行调整可得",{"2":{"1116":1}}],["时的偏导数项",{"2":{"1111":1}}],["时误差为",{"2":{"1109":1}}],["时还是可以接受的",{"2":{"1085":1}}],["时钟",{"2":{"810":1}}],["时输出yt",{"2":{"574":1}}],["时发表了一篇令人难忘的演讲",{"2":{"475":1}}],["时几乎完全相同",{"2":{"473":1}}],["时代价为",{"2":{"1109":1}}],["时代",{"2":{"354":1}}],["时定义了熵",{"2":{"342":1}}],["时光机器数据集中的每个文本行不一定是一个句子或一个段落",{"2":{"364":1}}],["时光机器语料库的词表",{"2":{"364":1}}],["时光机器",{"2":{"319":1}}],["时间日期处理",{"2":{"1263":1}}],["时间",{"2":{"796":2,"1029":1,"1315":1}}],["时间内为不变的标签词元",{"2":{"736":1}}],["时间内对",{"2":{"519":1}}],["时间为随机词元",{"2":{"736":1}}],["时间为特殊的",{"2":{"736":1}}],["时间是向前推进的因果模型在多大程度上适用于文本呢",{"2":{"353":1}}],["时间步为7",{"2":{"573":1}}],["时间步为1",{"2":{"350":1}}],["时间步",{"2":{"408":1}}],["时间步的数目或词元序列的长度",{"2":{"396":1}}],["时间步t的门被定义如下",{"2":{"553":1}}],["时间步t",{"2":{"374":1,"512":1}}],["时间步数或词元数量",{"2":{"568":1}}],["时间步数或序列长度",{"2":{"405":1}}],["时间步数目",{"2":{"407":1}}],["时间步数×批量大小",{"2":{"332":1}}],["时间步数量",{"2":{"332":4}}],["时间步数",{"2":{"325":6,"330":2,"405":1,"573":1,"574":1,"713":9}}],["时间步数为5",{"2":{"320":1}}],["时间步3的隐状态h3的计算",{"2":{"312":1}}],["时间机器",{"2":{"311":1,"1318":1}}],["时看到的那样",{"2":{"170":1}}],["时至今日",{"2":{"135":1,"281":1}}],["时",{"2":{"45":1,"139":1,"265":1,"306":1,"307":1,"392":1,"432":1,"452":1,"577":1,"591":2,"594":1,"611":1,"634":1,"662":1,"743":1,"762":1,"991":1,"997":1,"998":3,"1069":2,"1089":1,"1102":1,"1108":5,"1111":1}}],["∈rn×h",{"2":{"527":1}}],["∈rd",{"2":{"404":2}}],["∈rd根据",{"2":{"396":1}}],["∈rd×h",{"2":{"232":1,"521":2}}],["∈rpo",{"2":{"381":1}}],["∈rpk×dk和",{"2":{"381":1}}],["∈rpq×dq",{"2":{"381":1}}],["∈rpv×dv",{"2":{"381":1}}],["∈rpv",{"2":{"381":1}}],["∈r",{"2":{"367":1,"369":1}}],["∈r1×q",{"2":{"232":1}}],["∈r1×h都是模型参数",{"2":{"521":1}}],["∈r1×h",{"2":{"232":1,"521":1,"527":1}}],["∈rh×h和",{"2":{"527":1}}],["∈rh×h",{"2":{"521":2,"527":1}}],["∈rh×q",{"2":{"232":1}}],["∈rh×d",{"2":{"162":1,"164":1}}],["∈rk$$$$",{"2":{"1120":1}}],["∈rk",{"2":{"192":1}}],["∈rq×h",{"2":{"162":1,"164":1}}],["∈",{"2":{"60":1}}],["∈sb",{"2":{"45":2}}],["∈x∥x−x",{"2":{"50":1}}],["∈x满足f",{"2":{"44":1}}],["∈x使得f",{"2":{"44":1}}],["∈x和所有λ∈",{"2":{"41":1}}],["≤1",{"2":{"1031":1}}],["≤p",{"2":{"1030":1}}],["≤f",{"2":{"1000":1}}],["≤c",{"2":{"60":1}}],["≤0之外",{"2":{"49":1}}],["≤0",{"2":{"47":1,"48":1}}],["≤λg",{"2":{"46":1}}],["≤λf",{"2":{"44":1,"45":1,"46":1}}],["≤b且f",{"2":{"45":1}}],["≤b",{"2":{"45":3}}],["或水位达到50",{"2":{"1467":1}}],["或水位达到20cm",{"2":{"1467":3}}],["或在",{"2":{"1315":1}}],["或自定义",{"2":{"1311":1}}],["或自托管实例",{"2":{"1312":1}}],["或自托管",{"2":{"1310":1}}],["或过去评价过什么电影来判断",{"2":{"1187":1}}],["或itunes",{"2":{"1187":1}}],["或网飞公司或易趣",{"2":{"1187":1}}],["或许更有可能也对电影",{"2":{"1191":1}}],["或许",{"2":{"1168":1}}],["或许是深度学习算法最重要的组成部分",{"2":{"1001":1}}],["或不接受",{"2":{"1168":1}}],["或具有三维数据压缩到一二维表示",{"2":{"1161":1}}],["或具有中等复杂度的各种组件",{"2":{"423":1}}],["或求一个数的平方根等我们只是知道如何去调用库函数来实现这些功能",{"2":{"1148":1}}],["或说投影到θ上",{"2":{"1145":1}}],["或too",{"2":{"1141":1}}],["或几周时间研究这些算法",{"2":{"1111":1}}],["或显示一个变量",{"2":{"1088":1}}],["或机器学习开发人员",{"2":{"1061":1}}],["或平均值",{"2":{"1036":1}}],["或边际分布",{"2":{"1033":1}}],["或p",{"2":{"1028":1}}],["或prelu",{"2":{"239":1}}],["或结果空间",{"2":{"1027":1}}],["或y=",{"2":{"1025":1}}],["或嵌套列表",{"2":{"1017":1}}],["或以单个",{"2":{"1006":1}}],["或m×n",{"2":{"992":1}}],["或分量",{"2":{"990":1}}],["或多个",{"2":{"843":1}}],["或fp16与fp32的混合精度",{"2":{"811":1}}],["或溢出",{"2":{"811":1}}],["或程序员",{"2":{"810":1}}],["或gpu",{"2":{"801":2,"842":1}}],["或异步执行多次将变量递增1会发生什么情况",{"2":{"792":1}}],["或随机词元",{"2":{"721":1}}],["或回归",{"2":{"656":1}}],["或输入特征没有足够的信息来完美地对每一个样本分类",{"2":{"646":1}}],["或同一行",{"2":{"631":1}}],["或视网膜等环境传感器",{"2":{"619":1}}],["或推断",{"2":{"614":1}}],["或截距",{"2":{"610":1}}],["或数据样本",{"2":{"609":1}}],["或训练集",{"2":{"609":1}}],["或跳过",{"2":{"555":1}}],["或简称为单元",{"2":{"552":1}}],["或经典循环神经网络",{"2":{"530":1}}],["或作为在每个像素位置上独立作用的全连接层",{"2":{"494":1}}],["或是写入而不触发更改的特殊方法",{"2":{"1518":1}}],["或是被归结到一起",{"2":{"1061":1}}],["或是你facebook的朋友",{"2":{"1061":1}}],["或是随着时间的推移",{"2":{"467":1}}],["或是稍微改进的特征提取",{"2":{"454":1}}],["或将其记录在numpy",{"2":{"452":1}}],["或括号中的任意整数",{"2":{"446":1}}],["或其他张量",{"2":{"442":1}}],["或循环神经网络",{"2":{"395":1}}],["或参与",{"2":{"373":1}}],["或两者兼而有之",{"2":{"295":1}}],["或伤害",{"2":{"291":1}}],["或称为稠密层",{"2":{"618":1}}],["或称为单层神经网络",{"2":{"618":1}}],["或称为特征维度",{"2":{"618":1}}],["或称为测试集",{"2":{"286":1}}],["或称为训练集",{"2":{"286":1}}],["或cost",{"2":{"286":1}}],["或目标识别",{"2":{"857":1}}],["或目标",{"2":{"284":1,"609":1}}],["或协变量",{"2":{"284":1,"609":1}}],["或任何其他单词",{"2":{"282":1}}],["或从英语映射到中文",{"2":{"282":1}}],["或移动应用程序",{"2":{"281":1}}],["或等价于",{"2":{"247":1}}],["或等价于12",{"2":{"247":1}}],["或至少减轻",{"2":{"245":1}}],["或隐藏变量",{"2":{"232":1}}],["或降低",{"2":{"230":1}}],["或",{"2":{"213":1,"236":1,"289":2,"291":1,"382":4,"634":1,"665":1,"713":1,"997":1,"1042":1,"1060":1,"1093":1,"1106":1,"1264":1,"1304":1,"1465":1,"1475":1,"1479":1,"1527":1}}],["或x=5",{"2":{"1028":1}}],["或x",{"2":{"146":1,"1017":1}}],["或卷积窗口",{"2":{"126":1}}],["或更好的βi=min",{"2":{"191":1}}],["或更广义地说",{"2":{"99":1}}],["或更低",{"2":{"25":1}}],["或突发读取",{"2":{"77":1}}],["或者查准率与查全率之比",{"2":{"1181":1}}],["或者引擎的振动等等",{"2":{"1178":1}}],["或者同一台计算机的不同cpu",{"2":{"1169":1}}],["或者多少个样本",{"2":{"1167":1}}],["或者更好的管理数据中心",{"2":{"1150":1}}],["或者更确切地说与之相关的某些坐标",{"2":{"118":1}}],["或者接近它的值",{"2":{"1148":1}}],["或者接收",{"2":{"450":1}}],["或者不带核函数的支持向量机",{"2":{"1148":1}}],["或者不同的标签来完成这件事",{"2":{"1112":1}}],["或者其实没有人考虑过自己写代码来转换矩阵",{"2":{"1148":1}}],["或者θtx",{"2":{"1145":1}}],["或者等价地",{"2":{"1144":1}}],["或者等于0时",{"2":{"1143":1}}],["或者就是",{"2":{"1143":1}}],["或者简称svm",{"2":{"1143":1}}],["或者用带有许多隐藏单元的神经网络",{"2":{"1141":1}}],["或者用机器学习算法来做产品",{"2":{"1117":1}}],["或者太不完美",{"2":{"1138":1}}],["或者添加更多特征",{"2":{"1138":1}}],["或者告诉你",{"2":{"1138":1}}],["或者加入更多的特征变量是否有用",{"2":{"1138":1}}],["或者别的问题",{"2":{"1138":1}}],["或者构造机器学习应用程序",{"2":{"1138":1}}],["或者是一个监督学习的问题",{"2":{"1182":1}}],["或者是其他的一些信息",{"2":{"1150":1}}],["或者是不是和两个都有关",{"2":{"1132":1}}],["或者是将三个命令一个接一个执行",{"2":{"1091":1}}],["或者再进行土地测量来获得更多有关",{"2":{"1129":1}}],["或者也许你需要用更多的特征",{"2":{"1129":1}}],["或者想试着改进一个机器学习系统的性能",{"2":{"1129":1}}],["或者使用箭头函数",{"2":{"1420":1}}],["或者使用一些模型选择的算法来帮忙",{"2":{"1114":1}}],["或者使用python的内置调试工具都更加简单",{"2":{"817":1}}],["或者下雪天",{"2":{"1112":1}}],["或者得了流感用y=3来代表",{"2":{"1112":1}}],["或者患了感冒",{"2":{"1112":1}}],["或者甚至线性回归中",{"2":{"1111":1}}],["或者计算逆矩阵",{"2":{"1111":1}}],["或者远小于0",{"2":{"1106":1}}],["或者1",{"2":{"1106":2}}],["或者连接另一个神经元树突的神经",{"2":{"1099":1}}],["或者连续的卷积层时",{"2":{"129":1}}],["或者咂舌头",{"2":{"1098":1}}],["或者上千个不同的算法来做这些大脑所完成的成千上万的美好事情",{"2":{"1098":1}}],["或者一些其他的语言",{"2":{"1093":1}}],["或者数值线性代数库",{"2":{"1093":1}}],["或者数据实例",{"2":{"284":1}}],["或者选学材料",{"2":{"1092":1}}],["或者命令quit也可以",{"2":{"1092":1}}],["或者需要知道axis命令",{"2":{"1091":1}}],["或者需要通过识别语义等价的句子来消除句子间冗余时",{"2":{"664":1}}],["或者你是否需要更多的数据",{"2":{"1138":1}}],["或者你可以将a",{"2":{"1090":1}}],["或者你之前对线性代数有所了解",{"2":{"1070":1}}],["或者将数据的",{"2":{"1089":1}}],["或者将要学的机器学习算法",{"2":{"1088":1}}],["或者将代码转换为一个完全等价的片段",{"2":{"817":1}}],["或者找到的其它矩阵是不可逆的",{"2":{"1086":1}}],["或者我们可以画一条更差的决策界",{"2":{"1144":1}}],["或者我们以后在课程中",{"2":{"1085":1}}],["或者我们最终只能得到次优的结果",{"2":{"66":1}}],["或者三次方模型",{"2":{"1084":1}}],["或者没有接触过偏导数",{"2":{"1067":1}}],["或者换句话说",{"2":{"1060":1}}],["或者开关故障",{"2":{"1034":1}}],["或者从特定分布中随机采样的数字",{"2":{"1017":1}}],["或者从不分配内存",{"2":{"817":1}}],["或者设计其它超参数为lr",{"2":{"910":1}}],["或者在不同的gpu上聚合梯度的某些部分",{"2":{"843":1}}],["或者在不同的gpu之间",{"2":{"797":1}}],["或者在多个核心之间共享",{"2":{"810":1}}],["或者在小批量数据的负梯度g方向上",{"2":{"334":1}}],["或者保持不变",{"2":{"721":1}}],["或者棒球队可能获得的胜场数",{"2":{"639":1}}],["或者直到满足某些其他停止条件后",{"2":{"613":1}}],["或者证券的熊市和牛市之间可能会有过渡存在",{"2":{"538":1}}],["或者达到其最大长度t",{"2":{"513":1}}],["或者说长度的平方",{"2":{"1145":1}}],["或者说u的长度",{"2":{"1145":1}}],["或者说一个90度投影将其投影到u上",{"2":{"1145":1}}],["或者说安全的间距因子",{"2":{"1144":1}}],["或者说我们并不知道所选行驶方向",{"2":{"1127":1}}],["或者说可以自动地加上标签",{"2":{"1112":1}}],["或者说让你的结果可视化",{"2":{"1090":1}}],["或者说",{"2":{"1088":1,"1178":1}}],["或者说是有时可能不会使用神经网络的原因是",{"2":{"1148":1}}],["或者说是向量θ的长度",{"2":{"1145":1}}],["或者说是向量v投影到向量u上的量",{"2":{"1145":1}}],["或者说是更压缩的二进制形式",{"2":{"1089":1}}],["或者说是一个3",{"2":{"1088":1}}],["或者说是负样本和正样本现在我们不全部画x",{"2":{"1060":1}}],["或者说线索来做推测",{"2":{"1060":1}}],["或者说良性记为0",{"2":{"1060":1}}],["或者说为了利用我们现有的cpu",{"2":{"473":1}}],["或者说更糟",{"2":{"178":1}}],["或者为了获得科学的理解而进行检查",{"2":{"429":1}}],["或者两者都用",{"2":{"411":1}}],["或者单词非常罕见",{"2":{"316":1}}],["或者所有发布在网络上的文本",{"2":{"316":1}}],["或者任意长度的句子与外语中的对应句子之间的映射",{"2":{"302":1}}],["或者可能函数图表仍然是颠簸不平且不下降的",{"2":{"1167":1}}],["或者可能想知道哪些单词是命名实体",{"2":{"295":1}}],["或者可能不存在一个全局最小值",{"2":{"44":1}}],["或者如果数据的特征不能预测任务目标",{"2":{"284":1}}],["或者完全超出我们的控制",{"2":{"269":1}}],["或者完全不必选择学习率",{"2":{"58":1}}],["或者导致模型输出的减小",{"2":{"230":1}}],["或者试图与其合作",{"2":{"199":1}}],["或者以其他方式对自动驾驶汽车的驾驶方式做出反应",{"2":{"199":1}}],["或者滤波器",{"2":{"155":1}}],["或者",{"2":{"114":1,"309":1,"315":1,"370":4,"493":1,"576":1,"615":1,"968":1,"1061":1,"1076":1,"1077":1,"1084":1,"1088":1,"1089":1,"1110":1,"1183":1,"1187":2,"1284":1}}],["局部优化法",{"2":{"1109":1}}],["局部性意味着计算相应的隐藏表示只需一小部分局部图像像素",{"2":{"159":1}}],["局部性",{"0":{"155":1},"2":{"152":2,"155":1}}],["局部最优不是神经网络所需要解决的一个重大问题",{"2":{"1148":1}}],["局部最优解或其近似解仍然非常有用",{"2":{"103":1}}],["局部最大值或函数梯度为零位置处的鞍点",{"2":{"102":1}}],["局部最小值",{"0":{"56":1,"101":1}}],["局部最小值x∗也是全局最小值",{"2":{"44":1}}],["局部极小值是全局极小值",{"0":{"44":1}}],["不关心值内部的属性变化",{"2":{"1511":1}}],["不太美观",{"2":{"1476":1}}],["不修改",{"2":{"1460":1}}],["不便于维护和复用",{"2":{"1448":1}}],["不建议保存对原始对象的持久引用",{"2":{"1518":1}}],["不建议在已推送的分支使用",{"2":{"1334":1}}],["不建议将固态驱动器用于交换分区文件或大型日志文件",{"2":{"805":1}}],["不做任何事",{"2":{"1227":1}}],["不及格",{"2":{"1223":1}}],["不以数字开头",{"2":{"1215":1}}],["不然的话协方差矩阵σ不可逆的",{"2":{"1184":1}}],["不然便是出现了错误",{"2":{"1152":1}}],["不简化计算",{"2":{"1147":1}}],["不像刚开始的时候",{"2":{"1127":1}}],["不用明确指出监视的数据",{"2":{"1467":1}}],["不用",{"2":{"1110":1,"1467":1}}],["不用担心",{"2":{"472":1,"1067":1,"1092":1}}],["不为",{"2":{"1109":1}}],["不为1时误差随着hθ",{"2":{"1109":1}}],["不仅支持",{"2":{"1394":1}}],["不仅仅改变自己的生活",{"2":{"1176":1}}],["不仅仅要能正确分开输入的样本",{"2":{"1144":1}}],["不仅仅是选择一个好的学习速率",{"2":{"1111":1}}],["不仅仅是在优化一个预测模型",{"2":{"201":1}}],["不仅如此",{"2":{"1089":1}}],["不打印任何东西",{"2":{"1088":1}}],["不等于符号的写法是这个波浪线加上等于符号",{"2":{"1088":1}}],["不适合逻辑回归模型等其他模型",{"2":{"1085":1}}],["不只是线性回归中的代价函数j",{"2":{"1068":1}}],["不听这节课对后续课程理解影响不大",{"2":{"1066":1}}],["不止于问答",{"2":{"1050":1}}],["不必担心",{"2":{"1070":1}}],["不必我们自己做除法",{"2":{"1017":1}}],["不必定义我们的损失函数",{"2":{"595":1}}],["不能用path",{"2":{"1482":1}}],["不能实例化抽象类",{"2":{"1416":1}}],["不能除以0",{"2":{"1236":1}}],["不能捕捉特征之间的相关性",{"2":{"1184":1}}],["不能很好地适应我们的训练集",{"2":{"1114":1}}],["不能有效地处理这么多的特征",{"2":{"1097":1}}],["不能通过分配新内存将a克隆到b",{"2":{"994":1}}],["不能区分假数据和真实数据",{"2":{"300":1}}],["不断地上升",{"2":{"1167":1}}],["不断让i增加",{"2":{"1092":1}}],["不断更新它们",{"2":{"980":1}}],["不断调整神经网络的中间输出",{"2":{"476":1}}],["不使用图像增广时",{"2":{"898":1}}],["不应与",{"2":{"999":1}}],["不应引入图像增广的随机性",{"2":{"892":1}}],["不应用平滑",{"2":{"316":1}}],["不讨论算法的原理",{"2":{"863":1}}],["不可变序列",{"2":{"1216":1}}],["不可能并行化相互依赖的操作",{"2":{"790":3}}],["不可避免地会比产生圣埃克苏佩里的中篇小说",{"2":{"342":1}}],["不会触发视图更新",{"2":{"1518":1}}],["不会执行",{"2":{"1314":1}}],["不会丢掉重要的数据",{"2":{"1162":1}}],["不会出现这种情况",{"2":{"1086":1}}],["不会出现在微调中",{"2":{"736":1}}],["不会影响别的邮件",{"2":{"1059":1}}],["不会需要使用复杂模型架构",{"2":{"205":1}}],["不睡觉",{"2":{"665":1}}],["不停地从中获取一个小批量的输入和相应的标签",{"2":{"595":1}}],["不包括",{"2":{"1115":2,"1315":1}}],["不包括θ0",{"2":{"1115":1}}],["不包括图深度学习",{"2":{"841":1}}],["不包括序列结束词元",{"2":{"576":1}}],["不包括填充词元",{"2":{"575":1}}],["不包括恒等映射的1×1卷积层",{"2":{"502":1}}],["不",{"2":{"518":1}}],["不一定是最佳序列",{"2":{"513":1}}],["不一定是以一种对抗的方式",{"2":{"198":1}}],["不少研究论文基于加州大学欧文分校",{"2":{"456":1}}],["不经意地移动数据可能会显著降低性能",{"2":{"452":1}}],["不要试图手动设计",{"2":{"1187":1}}],["不要担心你的算法太简单",{"2":{"1138":1}}],["不要简单地x加上y",{"2":{"449":1}}],["不要不作任何调整就使用牛顿法",{"2":{"63":1}}],["不论是沿着从输入到输出的层",{"2":{"467":1}}],["不论之前是否已经被初始化",{"2":{"435":1}}],["不论有多少输入通道",{"2":{"121":1}}],["不计算梯度的随机权重参数",{"2":{"425":2}}],["不带有",{"2":{"1476":1}}],["不带核函数的支持向量机就会表现得相当突出",{"2":{"1148":1}}],["不带参数的层",{"0":{"413":1}}],["不带噪声项的真实数据生成函数f",{"2":{"386":1}}],["不过由于这些算法的运行速度通常远远超过梯度下降",{"2":{"1111":1}}],["不过关于它们到底做什么的详细讨论",{"2":{"1111":1}}],["不过让我来告诉你他们的一些特性",{"2":{"1111":1}}],["不过让我和你分享",{"2":{"1098":1}}],["不过现在有失明人士",{"2":{"1098":1}}],["不过能不能假设大脑做所有这些",{"2":{"1098":1}}],["不过",{"2":{"818":1}}],["不过请注意",{"2":{"809":1}}],["不过解码器必须通过掩蔽机制来保留自回归属性",{"2":{"410":1}}],["不过随机抽样和顺序划分使用初始化方法不同",{"2":{"336":1}}],["不由自主地引起人们的注意",{"2":{"355":1}}],["不如尝试正则化处理",{"2":{"1162":1}}],["不如左右图像翻转那样常用",{"2":{"879":1}}],["不如使用隐变量模型",{"2":{"338":1}}],["不如构建系统",{"2":{"302":1}}],["不涉及输出层的计算",{"2":{"325":1}}],["不再等待整个应用编译完成",{"2":{"1444":1}}],["不再与环境交互",{"2":{"297":1}}],["不再成立",{"2":{"49":1}}],["不来梅的城市音乐家",{"2":{"292":1}}],["不确定这些数字或这些矩阵的意思",{"2":{"1070":1}}],["不确定风险的影响远远大于收益",{"2":{"291":1}}],["不确定性",{"2":{"171":1}}],["不是响应式的",{"2":{"1455":1}}],["不是每一步都是朝着",{"2":{"1165":1}}],["不是这种",{"2":{"1069":1}}],["不是恶性",{"2":{"1060":1}}],["不是所有的处理单元都是平等的",{"2":{"808":1}}],["不是来自wc的上下文窗口的事件",{"2":{"708":1}}],["不是可以接受的",{"2":{"657":1}}],["不是问",{"2":{"639":1}}],["不是数字",{"2":{"624":1}}],["不是",{"2":{"291":1,"1305":1}}],["不是吗",{"2":{"183":1,"1059":1}}],["不设置偏置",{"2":{"263":4}}],["不考虑整个的训练集",{"2":{"1069":1}}],["不考虑计算指令的发出时间",{"2":{"791":1}}],["不考虑跨越单词边界的对",{"2":{"757":1}}],["不考虑双胞胎",{"2":{"251":1}}],["不考虑这种偏移可能会成为问题",{"2":{"202":1}}],["不稳定梯度也威胁到我们优化算法的稳定性",{"2":{"241":1}}],["不稳定梯度带来的风险不止在于数值表示",{"2":{"241":1}}],["不激发",{"2":{"236":1}}],["不变",{"2":{"223":1}}],["不变性",{"0":{"152":1}}],["不存在",{"2":{"1433":1}}],["不存在局部最小值",{"2":{"1148":1}}],["不存在误差",{"2":{"1121":2}}],["不存在非线性",{"2":{"247":1}}],["不存在于",{"2":{"206":1}}],["不存在x",{"2":{"44":1}}],["不需要完整的操作系统",{"2":{"1339":1}}],["不需要提前声明变量类型",{"2":{"1214":1}}],["不需要再存储它了",{"2":{"1168":1}}],["不需要用上千个不同的程序去实现",{"2":{"1098":1}}],["不需要",{"2":{"1085":1}}],["不需要梯度下降这种迭代算法",{"2":{"1069":1}}],["不需要共享参数",{"2":{"756":1}}],["不需要定义层或复杂的优化器",{"2":{"606":1}}],["不需要记住整个文本序列",{"2":{"300":1}}],["不需要访问标签y∼p",{"2":{"191":1}}],["不需要在正则化项中包含偏置项",{"2":{"167":1}}],["不管你是想写一个爬虫",{"2":{"1301":1}}],["不管是逻辑回归还是不带核函数的svm",{"2":{"1148":1}}],["不管是将其应用到现代的机器学习问题上",{"2":{"1098":1}}],["不管是监督学习还是无监督学习",{"2":{"297":1}}],["不管python的性能如何",{"2":{"790":1}}],["不管使用的前端编程语言是什么",{"2":{"790":3}}],["不管协变量",{"2":{"189":1}}],["不管检测对象出现在图像中的哪个位置",{"2":{"152":1}}],["不久",{"2":{"179":1}}],["不幸的是",{"2":{"102":1,"114":1,"169":1,"186":1,"241":1,"278":1,"316":1,"707":1,"789":1,"810":1,"819":1,"837":1,"1035":1}}],["不同事情的方法",{"2":{"1098":1}}],["不同尺度下预测输出的形状可能会有所不同",{"2":{"956":1}}],["不同尺度的特征映射是否对应于不同的抽象层次",{"2":{"915":1}}],["不同应用之间的bert所需的",{"2":{"656":1}}],["不同类型的正则化",{"2":{"561":1}}],["不同长度的上下文范围重要性是相同的",{"2":{"518":1}}],["不同之处在于resnet每个卷积层后增加了批量规范化层",{"2":{"502":1}}],["不同之处在于维度",{"2":{"148":1}}],["不同的是监听数据变化的方式不同",{"2":{"1467":1}}],["不同的是tanh函数关于坐标系原点中心对称",{"2":{"237":1}}],["不同的特征",{"2":{"1156":1}}],["不同的习惯所致",{"2":{"1143":1}}],["不同的颜色对应a矩阵中的不同值",{"2":{"1091":1}}],["不同的锚框",{"2":{"912":1}}],["不同的边界框",{"2":{"847":1}}],["不同的模型使用的区域采样方法可能不同",{"2":{"847":1}}],["不同的",{"2":{"843":1}}],["不同的gpu个数在算法寻优方面是相同的",{"2":{"837":1}}],["不同的vgg模型可通过每个块中卷积层数量和输出通道数量的差异来定义",{"2":{"510":1}}],["不同的参数集可以有不同的更新行为",{"2":{"279":1}}],["不同数量的隐藏单元以及不同的激活函数组合的模型",{"2":{"255":1}}],["不同数量的隐藏层",{"2":{"255":1}}],["不同于监督学习的数据的样子",{"2":{"1061":1}}],["不同于resnet中将输入与输出相加",{"2":{"484":1}}],["不同于卷积层中的输入与卷积核之间的互相关计算",{"2":{"146":1}}],["不同于在梯度下降或者随机梯度下降中取步长η",{"2":{"89":1}}],["不同",{"2":{"99":1,"513":1,"1146":1}}],["不同坐标的缩放方式不同",{"2":{"64":1}}],["不切实际的",{"2":{"56":1}}],["不出现为0",{"2":{"1137":1}}],["不出名",{"2":{"665":1}}],["不出所料",{"2":{"41":1,"128":1}}],["不出预料",{"2":{"32":1}}],["−μj",{"2":{"1180":1}}],["−μ",{"2":{"1179":1,"1184":2,"1185":2}}],["−μc",{"2":{"1152":1}}],["−j",{"2":{"1124":1}}],["−v",{"2":{"1090":1}}],["−vec",{"2":{"751":1}}],["−α∑i",{"2":{"1188":1}}],["−α",{"2":{"966":1,"1188":1,"1189":2}}],["−α多项式衰减在第一个分段常数",{"2":{"114":1}}],["−un",{"2":{"709":1}}],["−uhk⊤vit",{"2":{"708":1}}],["−u22",{"2":{"388":1}}],["−∑t=1tlogp",{"2":{"786":1}}],["−∑t=1t∑−m≤j≤m",{"2":{"784":1}}],["−∑j∈vpijlogqij计算全局语料统计的条件分布pij和模型预测的条件分布qij的交叉熵",{"2":{"742":1}}],["−∑j=1qyjoj",{"2":{"647":1}}],["−∑j=1qyjoj=log⁡∑k=1qexp⁡",{"2":{"647":1}}],["−∑i∈vxi∑j∈vpijlogqij",{"2":{"742":1}}],["−∑i∈v∑j∈vxijlogqij",{"2":{"742":1}}],["−∑k=1",{"2":{"708":3}}],["−|ϵ|",{"2":{"621":1}}],["−b",{"2":{"616":1}}],["−w⊤x",{"2":{"616":1}}],["−ycv",{"2":{"1131":2,"1132":1}}],["−yj=softmax",{"2":{"647":1}}],["−y",{"2":{"611":1,"1064":1,"1069":5,"1081":5,"1086":1,"1109":6,"1110":3,"1115":2,"1116":4,"1117":3,"1121":1,"1131":1,"1132":1,"1165":1,"1166":1,"1168":1,"1188":4,"1189":4,"1190":2}}],["−0",{"2":{"434":1}}],["−0=∑j=1nine",{"2":{"247":1}}],["−sin⁡",{"2":{"400":2}}],["−30+20x1+20x2",{"2":{"1101":1}}],["−3",{"2":{"264":1,"599":1}}],["−6nin+nout",{"2":{"247":1}}],["−a1m∑i=1m",{"2":{"1116":1}}],["−a",{"2":{"247":1,"1154":1}}],["−",{"2":{"247":1,"296":1,"1109":6,"1110":2,"1117":1,"1154":1,"1179":1,"1180":1,"1184":1}}],["−hθ",{"2":{"1109":1}}],["−h",{"2":{"191":4}}],["−logqij",{"2":{"743":1}}],["−log⁡",{"2":{"624":2,"1143":1}}],["−log⁡p",{"2":{"42":1,"616":1,"646":1,"708":1}}],["−l2∑t=1tηt2",{"2":{"115":1}}],["−r∗≤r2+l2∑t=1tηt22∑t=1tηt",{"2":{"115":1}}],["−r∗",{"2":{"115":2}}],["−η|b|∑i∈b∂",{"2":{"613":1}}],["−ηg",{"2":{"605":1}}],["−ηt2l2",{"2":{"115":2}}],["−ηf",{"2":{"54":1}}],["−xapprox",{"2":{"1160":1}}],["−xj",{"2":{"1109":2}}],["−x",{"2":{"105":1,"236":2,"242":1,"501":1,"708":1,"709":1,"744":1,"1189":1}}],["−x∗∥2=∥xt−x∗∥2+ηt2∥∂xf",{"2":{"115":1}}],["−x∗表示kth迭代时与最优性的距离",{"2":{"60":1}}],["−x∗|≤p",{"2":{"44":1}}],["−eθtx",{"2":{"1109":2}}],["−e",{"2":{"60":3,"115":1,"1036":2}}],["−2μ2+μ2=σ2",{"2":{"209":1}}],["−2x−3",{"2":{"64":1}}],["−2",{"2":{"57":1}}],["−2f",{"2":{"46":1}}],["−5",{"2":{"57":1,"436":1}}],["−projx",{"2":{"52":1}}],["−f",{"2":{"46":2,"60":2,"115":1,"334":2,"981":2,"982":1}}],["−1的",{"2":{"1145":1}}],["−11+e−θtx",{"2":{"1109":1}}],["−1m∑i=1m",{"2":{"1109":1}}],["−1∗v",{"2":{"1090":1}}],["−1=a−1",{"2":{"1085":1}}],["−1xty",{"2":{"1085":1,"1086":3}}],["−1x⊤y",{"2":{"612":1}}],["−1大约与o",{"2":{"709":1}}],["−1σ",{"2":{"709":1}}],["−1转换为",{"2":{"574":1}}],["−1和上下文变量c",{"2":{"574":1}}],["−10",{"2":{"436":1}}],["−1是查询",{"2":{"374":1}}],["−1时的解码器隐状态st",{"2":{"374":1}}],["−1n∑t=1nlog⁡p",{"2":{"342":1}}],["−12σ2",{"2":{"616":2}}],["−12",{"2":{"68":1,"388":3,"389":3,"1184":1}}],["−1∇f",{"2":{"61":1}}],["−1",{"2":{"44":1,"101":1,"191":2,"374":1,"512":1,"513":2,"515":1,"541":1,"554":1,"556":1,"563":2,"574":5,"781":1,"1085":1}}],["|σ|是定矩阵",{"2":{"1184":1}}],["||",{"2":{"1088":1,"1427":3,"1467":3,"1495":1}}],["|1",{"2":{"1000":1}}],["|2",{"2":{"1000":1}}],["|v|−1",{"2":{"742":1,"783":1}}],["|b|表示每个小批量中的样本数",{"2":{"613":1}}],["|−σ2",{"2":{"597":1}}],["|y−y",{"2":{"597":2}}],["|y|t",{"2":{"512":1,"514":2}}],["|log⁡y−log⁡y^|≤δ",{"2":{"210":1}}],["|这样的条件称为",{"2":{"60":1}}],["|≤lη∥g∥",{"2":{"334":1}}],["|≤l∥x−y∥",{"2":{"334":1}}],["|≤α|e",{"2":{"60":1}}],["|≤c",{"2":{"60":1}}],["|f",{"2":{"60":1,"334":2,"1000":1}}],["|=12",{"2":{"60":1}}],["|e",{"2":{"60":2}}],["|对于一阶泰勒展开式可能太大",{"2":{"55":1}}],["|ηf",{"2":{"55":1}}],["|的幅度足够小或迭代次数达到某个值时",{"2":{"54":1}}],["|x|",{"2":{"966":1}}],["|x|−1",{"2":{"44":1}}],["|x",{"2":{"616":1}}],["|x−x∗|≤p时",{"2":{"44":1}}],["|λx∗+",{"2":{"44":1}}],["|",{"2":{"44":1,"60":1,"334":2,"597":1,"1045":1,"1046":1,"1284":1,"1378":20,"1407":5,"1412":3,"1414":7,"1432":1,"1434":3,"1435":1}}],["则联系服务器",{"2":{"1467":1}}],["则setup优先",{"2":{"1453":1}}],["则对象中的",{"2":{"1452":1}}],["则对于任意i和j",{"2":{"992":1}}],["则取消其他",{"2":{"1315":1}}],["则每部电影都有一个特征向量",{"2":{"1188":1}}],["则每个自变量迭代的计算代价为o",{"2":{"113":1}}],["则满足完整性",{"2":{"1154":1}}],["则满足均一性",{"2":{"1154":1}}],["则使用支持向量机会非常慢",{"2":{"1148":1}}],["则选取",{"2":{"1147":1}}],["则因为p",{"2":{"1145":1}}],["则因变量y∈0",{"2":{"1106":1}}],["则它到θ的投影在这里",{"2":{"1145":1}}],["则p将会是负的",{"2":{"1145":1}}],["则如果将v投影到u上",{"2":{"1145":1}}],["则支持向量机也会将它们恰当分开",{"2":{"1144":1}}],["则你最终会得到这条黑线",{"2":{"1144":1}}],["则最小化代价函数的时候",{"2":{"1144":1}}],["则仅需要θtx",{"2":{"1144":1}}],["则其概率密度函数为",{"2":{"1179":1}}],["则其实我们仅仅要求θtx大于等于0",{"2":{"1144":1}}],["则其一行三列的元素均为随机值",{"2":{"1088":1}}],["则只有在z",{"2":{"1144":1}}],["则表示在这一点上人类驾驶者的操作是慢慢的向左拐",{"2":{"1127":1}}],["则表示有70",{"2":{"1107":1}}],["则是权重导致的误差的和",{"2":{"1121":1}}],["则我们需要k个模型",{"2":{"1148":1}}],["则我们的最小化问题便转变成",{"2":{"1144":1}}],["则我们的目标函数的总体损失是",{"2":{"312":1}}],["则我们得到的判定边界恰好是圆点在原点且半径为1的圆形",{"2":{"1108":1}}],["则当−3+x1+x2≥0",{"2":{"1108":1}}],["则会把所有的参数都最小化了",{"2":{"1115":1}}],["则会有约25002",{"2":{"1097":1}}],["则会有",{"2":{"1097":1}}],["则会引起对程序公平性的合理关注",{"2":{"301":1}}],["则没有输出出任何东西",{"2":{"1091":1}}],["则利用正规方程解出向量",{"2":{"1085":1}}],["则达到收敛所需的迭代次数会非常高",{"2":{"1083":1}}],["则这个代价函数是所有建模误差的平方和",{"2":{"1081":1}}],["则这不会进行任何操作",{"2":{"449":1}}],["则公式转化为",{"2":{"1080":1}}],["则有θ=",{"2":{"1086":1}}],["则有j",{"2":{"1086":1}}],["则有",{"2":{"1077":1}}],["则有256784个可能的图像",{"2":{"252":1}}],["则算法改写成",{"2":{"1069":1}}],["则为0",{"2":{"1035":2}}],["则为1",{"2":{"1035":2}}],["则为f的索引",{"2":{"156":1}}],["则事件a已经发生",{"2":{"1027":1}}],["则新特征",{"2":{"1146":1}}],["则新张量中相应项的值为1",{"2":{"1018":1}}],["则新图像z的输出可能大不相同",{"2":{"145":1}}],["则此函数在此区间中是可微的",{"2":{"981":1}}],["则称f在a处是可微",{"2":{"981":1}}],["则实例分割需要区分像素属于的两条狗中的哪一条",{"2":{"944":1}}],["则越容易抽取图像的全局信息",{"2":{"920":1}}],["则需要将平均值重新加回去",{"2":{"1192":1}}],["则需要将下面的demo变量更改为false",{"2":{"901":1}}],["则需要连接互联网才能下载",{"2":{"873":1}}],["则需要使用set",{"2":{"436":1}}],["则该概率所对应的类别b即为预测的类别",{"2":{"854":1}}],["则被完全保留",{"2":{"773":1}}],["则跳元模型中作为中心词的词w的向量vw是其子词向量的和",{"2":{"756":1}}],["则必须下载该文件",{"2":{"748":1}}],["则在输入中将其替换为",{"2":{"736":1}}],["则将对",{"2":{"675":1}}],["则预测是正确的",{"2":{"653":1}}],["则损失函数不能进一步最小化",{"2":{"646":1}}],["则结果将是一个具有形状",{"2":{"631":1}}],["则第一个序列的第一项和第二个序列的前两项之后的剩余项将被清除为零",{"2":{"575":1}}],["则默认为0",{"2":{"573":2}}],["则过去的记忆元ct−1",{"2":{"555":1}}],["则无论序列的长度如何",{"2":{"542":1}}],["则无法保证新的体系",{"2":{"500":1}}],["则显然是贪心搜索",{"2":{"515":1}}],["则显然是穷举搜索",{"2":{"515":1}}],["则返回true",{"2":{"773":1}}],["则返回",{"2":{"446":4}}],["则返回gpu",{"2":{"446":4}}],["则能更轻松地学习序列中的远距离依赖关系",{"2":{"397":1}}],["则缩放点积注意力",{"2":{"370":1}}],["则上述的考虑仍然有效",{"2":{"347":1}}],["则隐藏层的输出h∈rn×h通过下式计算",{"2":{"339":1}}],["则序列上的分布满足一阶马尔可夫性质",{"2":{"317":1}}],["则要正常得多",{"2":{"315":1}}],["则偏置参数b将不会被衰减",{"2":{"278":1}}],["则",{"2":{"209":1,"334":1,"527":1,"981":1,"1084":1,"1085":1,"1109":1,"1121":1,"1139":1,"1146":2}}],["则可以自定义渲染内容",{"2":{"1452":1}}],["则可以看出在三维空间中存在一个使得j",{"2":{"1064":1,"1066":1}}],["则可以计算表达式c=59",{"2":{"989":1}}],["则可以并行计算h个头",{"2":{"382":1}}],["则可以简单地使用参数化的全连接层",{"2":{"356":1}}],["则可以更好地处理序列信息",{"2":{"305":1}}],["则可以得出",{"2":{"141":1}}],["则可根据训练数据计算均值和标准差",{"2":{"209":1}}],["则很自然有",{"2":{"191":1}}],["则意味着相关的样本可能来自这两个分布中的任何一个",{"2":{"191":1}}],["则汇聚窗口的形状为ph×pw",{"2":{"150":1}}],["则一种可能性是在输入顶部填充",{"2":{"141":1}}],["则输出完成",{"2":{"513":1}}],["则输出形状将简化为",{"2":{"142":1}}],["则输出形状将为",{"2":{"141":1,"142":1}}],["则输出的高度和宽度也是8",{"2":{"141":1}}],["则输出为零",{"2":{"128":1}}],["则参数x被限制为单位球",{"2":{"47":1}}],["则存在",{"2":{"44":1}}],["则存在一个很小的正值p",{"2":{"44":1}}],["则向量空间中的一个集合x是凸",{"2":{"40":1}}],["≥∑t=1tηte",{"2":{"115":1}}],["≥e",{"2":{"115":1}}],["≥2ηt",{"2":{"115":1}}],["≥0意味着f",{"2":{"46":1}}],["≥0可以推导f是凸的",{"2":{"46":1}}],["≥0",{"2":{"46":2,"1000":1,"1027":1}}],["≥−log⁡p",{"2":{"42":1}}],["≥f",{"2":{"41":1,"42":2,"46":4,"115":2}}],["λ是我们之前使用过的正则化参数",{"2":{"1144":1}}],["λ时",{"2":{"1143":1}}],["λ所扮演的角色相同",{"2":{"1143":1}}],["λb",{"2":{"655":2}}],["λa",{"2":{"655":2}}],["λa+",{"2":{"46":2}}],["λ⋅1+",{"2":{"46":1}}],["λ",{"2":{"46":1,"95":2,"105":5,"1115":2,"1133":3,"1143":2,"1144":4,"1147":2}}],["λx∗+",{"2":{"44":1}}],["λx+",{"2":{"41":2,"45":2,"46":1}}],["λ∈",{"2":{"44":1,"46":1}}],["λf",{"2":{"41":1,"44":1,"46":1}}],["∥f2",{"2":{"162":1}}],["∥f2+∥w",{"2":{"162":1}}],["∥w",{"2":{"162":1}}],["∥2=∑j=1n",{"2":{"1146":1}}],["∥22σ2其中",{"2":{"1146":1}}],["∥2≤ηt2l2",{"2":{"115":1}}],["∥2−2ηt",{"2":{"115":1}}],["∥x−l",{"2":{"1146":1}}],["∥x1−x∗∥2≥2",{"2":{"115":1}}],["∥xt+1−x∗∥2",{"2":{"115":1}}],["∥xt+1−x∗∥2=∥xt−ηt∂xf",{"2":{"115":1}}],["∥xt−x∗∥2",{"2":{"115":1}}],["∥xt−x∗∥2−∥xt+1−x∗∥2≥2ηt",{"2":{"115":1}}],["∥x∥p=",{"2":{"1000":1}}],["∥x∥p≤r",{"2":{"52":1}}],["∥x∥≤r",{"2":{"40":1}}],["∥ϵ∥3",{"2":{"59":1}}],["∥ϵ∥2",{"2":{"57":1}}],["∥",{"2":{"50":1,"52":1}}],["∥g∥",{"2":{"50":1}}],["∥c−δ∥2=∥uc−uδ∥2",{"2":{"31":1}}],["且在seo优化方面相对较差",{"2":{"1476":1}}],["且在预测过程中不使用随机操作的图像增广",{"2":{"882":1}}],["且该属性是对象类型的",{"2":{"1465":1}}],["且该属性是基本类型的",{"2":{"1465":1}}],["且该词的相对比率越高",{"2":{"773":1}}],["且默认是开启深度监视的",{"2":{"1464":1}}],["且默认开启了深度监视",{"2":{"1464":1}}],["且依然保持响应式的能力",{"2":{"1459":2}}],["且层级较深",{"2":{"1458":1}}],["且vue3中的模板中可以没有根标签",{"2":{"1445":1}}],["且v=",{"2":{"742":1}}],["且用高斯核函数是在这种情况下",{"2":{"1148":1}}],["且已经有研究者做了很多年数值优化了",{"2":{"1148":1}}],["且我们有一类很好的函数",{"2":{"1141":1}}],["且hθ",{"2":{"1109":2}}],["且h接近0",{"2":{"981":1}}],["且a",{"2":{"1103":1}}],["且当所有i",{"2":{"1027":1}}],["且当我们几乎每天都需要实现模型时",{"2":{"591":1}}],["且转置卷积为每个输入通道分配了一个kh×kw的卷积核张量",{"2":{"969":1}}],["且选择性搜索在此图像上生成了两个提议区域",{"2":{"938":1}}],["且只有单通道",{"2":{"938":1}}],["且宽高比",{"2":{"912":1}}],["且尺寸不一",{"2":{"899":1}}],["且卷积核的高和宽为2s",{"2":{"862":1}}],["且最终输出通道包含了该空间位置像素的类别预测",{"2":{"862":1}}],["且数值越小表示损失越小",{"2":{"611":1}}],["且每个样本损失函数的梯度也可以被并行计算",{"2":{"600":1}}],["且增大输出通道数",{"2":{"461":4}}],["且将偏置参数设置为0",{"2":{"435":1}}],["且运行速度更快",{"2":{"335":1}}],["且更严重地",{"2":{"260":1}}],["且有具体的测试可以用来证明它是错误的",{"2":{"254":1}}],["且f",{"2":{"46":1}}],["且",{"2":{"40":1,"46":1}}],["且因此c=uc",{"2":{"26":1}}],["中可以访问到",{"2":{"1453":1}}],["中是通过",{"2":{"1444":1}}],["中是相同的",{"2":{"754":1}}],["中定义契约的主要方式",{"2":{"1418":1}}],["中定义的fancymlp模型",{"2":{"439":1}}],["中不推荐",{"2":{"1399":1}}],["中执行的单元",{"2":{"1311":1}}],["中断循环",{"2":{"1227":1}}],["中支持多种运算符",{"2":{"1217":1}}],["中用",{"2":{"1184":1}}],["中代码如下",{"2":{"1124":1}}],["中使用",{"2":{"1109":1}}],["中都带的一个最小值优化函数",{"2":{"1109":1}}],["中将两个向量相乘",{"2":{"1093":1}}],["中θ0",{"2":{"1093":1}}],["中每一行的和加起来还是369",{"2":{"1090":1}}],["中把这些命令重新输一遍",{"2":{"1089":1}}],["中移动数据",{"2":{"1089":1}}],["中矩阵转置",{"2":{"1077":1}}],["中计算矩阵的逆矩阵",{"2":{"1077":1}}],["中取值的概率",{"2":{"1028":1}}],["中有",{"2":{"1017":3}}],["中有不同的含义",{"2":{"525":1}}],["中通过均匀采样获得的连续值",{"2":{"879":1}}],["中心坐标分别为",{"2":{"852":1}}],["中心词",{"2":{"774":3}}],["中心词和上下文词的提取",{"0":{"774":1}}],["中心词向量和上下文词向量在数学上是等价的",{"2":{"745":1}}],["中心词偏置bi和上下文词偏置ci",{"2":{"743":1}}],["中找到最大的x92",{"2":{"851":1}}],["中找到最大的x54",{"2":{"851":1}}],["中找到最大的x71",{"2":{"851":1}}],["中央处理器",{"2":{"807":1}}],["中随机采样",{"2":{"1017":1}}],["中随机采样权重",{"2":{"434":1}}],["中随机抽取",{"2":{"775":1}}],["中选择掩蔽和预测",{"2":{"736":1}}],["中性",{"2":{"665":2,"667":2}}],["中推断出来",{"2":{"665":2}}],["中年人",{"2":{"640":1}}],["中没有隐变量",{"2":{"519":1}}],["中所有元素加起来了",{"2":{"1090":1}}],["中所有的λ",{"2":{"46":1}}],["中所说的",{"2":{"619":1}}],["中所述",{"2":{"424":1}}],["中引入",{"2":{"422":1}}],["中认识到",{"2":{"354":1}}],["中讨论了更多的信息论知识",{"2":{"342":1}}],["中讨论权重衰减",{"2":{"170":1}}],["中实现超人性能的重大进步",{"2":{"300":1}}],["中实现线搜索以最小化凸函数",{"2":{"64":1}}],["中提出的六种可选的下一步",{"2":{"1135":1}}],["中提出了",{"2":{"299":1}}],["中提取的",{"2":{"251":1}}],["中进行了说明",{"2":{"298":1}}],["中介绍了",{"2":{"211":1}}],["中的代码组织形式",{"2":{"1234":1}}],["中的元素0",{"2":{"1090":1}}],["中的元素排列起来的",{"2":{"1089":1}}],["中的哪些元素是小于3的",{"2":{"1090":1}}],["中的每一个元素都加上1",{"2":{"1090":1}}],["中的每个数据样本在训练时出现的概率非零",{"2":{"191":1}}],["中的对应元素相乘",{"2":{"1090":1}}],["中的",{"2":{"1089":1}}],["中的传输层为",{"2":{"1043":1}}],["中的方法相同",{"2":{"645":1}}],["中的一个值",{"2":{"1026":1}}],["中的一个",{"2":{"640":1}}],["中的1000张图像组成",{"2":{"582":1}}],["中的6000张图像",{"2":{"582":1}}],["中的常规隐状态更新机制集成",{"2":{"541":1}}],["中的功能不同",{"2":{"467":1}}],["中的循环训练基本相同",{"2":{"350":1}}],["中的frobenius范数",{"2":{"280":1}}],["中的权重向量的某个范数来度量其复杂性",{"2":{"270":1}}],["中的某个值",{"2":{"236":1}}],["中的任意输入压缩到区间",{"2":{"236":1}}],["中的加权经验风险的最小化问题",{"2":{"191":1}}],["中得到了说明",{"2":{"300":1}}],["中得到灵感",{"2":{"152":1}}],["中得出的",{"2":{"191":2}}],["中抽取的未标记样本",{"2":{"180":1}}],["中抽取样本",{"2":{"172":1}}],["中采样",{"2":{"1006":1}}],["中采样k个不是来自这个上下文窗口噪声词",{"2":{"708":1}}],["中采样的",{"2":{"180":1}}],["中采样得到样本xi",{"2":{"116":1}}],["中间一层成为隐藏层",{"2":{"1099":1}}],["中间",{"2":{"858":2,"859":1}}],["中间的两条路径在输入上执行1×1卷积",{"2":{"487":1}}],["中间层的变化幅度不能过于剧烈",{"2":{"467":1}}],["中间层中的变量",{"2":{"467":1}}],["中间四列为黑色",{"2":{"128":1}}],["中间没有非线性激活函数",{"2":{"124":1}}],["中端服务器处理器的带宽可能不超过100gb",{"2":{"77":1}}],["中",{"2":{"40":1,"168":1,"190":1,"191":2,"195":1,"196":1,"206":1,"208":1,"253":1,"269":1,"289":1,"369":1,"408":1,"509":1,"541":1,"559":1,"605":1,"658":1,"713":1,"785":1,"796":1,"851":1,"1028":1,"1085":1,"1089":1,"1117":1,"1121":1,"1124":1,"1214":1,"1348":1,"1530":1}}],["当代码推送到",{"2":{"1315":1}}],["当样本处于洋红色点位置",{"2":{"1146":1}}],["当样本i的预测值为y^",{"2":{"611":1}}],["当c不是非常非常大的时候",{"2":{"1144":1}}],["当ci",{"2":{"120":1}}],["当画出这两条额外的蓝线",{"2":{"1144":1}}],["当θtx大于或者等于0时",{"2":{"1143":1}}],["当θ是一个向量时",{"2":{"1124":1}}],["当最小化代价函数",{"2":{"1143":1}}],["当最后一个语句的结果需要被打印出来时",{"2":{"790":1}}],["当u=5时取得最小值",{"2":{"1143":1}}],["当z",{"2":{"1143":1}}],["当zt接近0时",{"2":{"542":1}}],["当做一类监督学习问题",{"2":{"1141":1}}],["当做一个向量",{"2":{"1090":1}}],["当交叉验证集误差远大于训练集误差时",{"2":{"1134":1}}],["当车辆到达这个十字路口时",{"2":{"1127":1}}],["当网络被训练完成后",{"2":{"1127":1}}],["当第一次看到这种算法时",{"2":{"1122":1}}],["当y=0",{"2":{"1109":1}}],["当y不是标量时",{"2":{"975":1}}],["当实际的",{"2":{"1109":2}}],["当实现解码器时",{"2":{"574":1}}],["当特征太多时",{"2":{"1097":1}}],["当特征数量n大时也能较好适用",{"2":{"1085":1}}],["当开发学习算法时",{"2":{"1091":1}}],["当开始动手尝试并在真实数据集上应用了有效的机器学习模型",{"2":{"1002":1}}],["当计算",{"2":{"1086":1}}],["当计算一个小批量的",{"2":{"797":1}}],["当计算一个小批量的梯度时",{"2":{"797":1}}],["当n",{"2":{"1081":1}}],["当你改变参数",{"2":{"1185":1}}],["当你生产的飞机引擎从生产线上流出时",{"2":{"1178":1}}],["当你应用",{"2":{"1154":1}}],["当你有多达1万",{"2":{"1148":1}}],["当你有非常非常大的训练集",{"2":{"1148":1}}],["当你有了初始的实现之后",{"2":{"1138":1}}],["当你最小化这个关于变量θ的函数的时候",{"2":{"1144":1}}],["当你在研究一个新的机器学习问题时",{"2":{"1138":1}}],["当你在构造学习算法的时候",{"2":{"1138":1}}],["当你需要通过头脑风暴来想出不同方法来尝试去提高精度的时候",{"2":{"1137":1}}],["当你运行一个学习算法时",{"2":{"1132":1}}],["当你运用学习算法时",{"2":{"1059":1}}],["当你想模拟大脑时",{"2":{"1098":1}}],["当你使用不同的内核函数来学习复杂的非线性函数时",{"2":{"1148":1}}],["当你使用向量化地实现线性回归",{"2":{"1093":1}}],["当你使用正确的编程环境",{"2":{"1061":1}}],["当你掌握了这些方法",{"2":{"475":1}}],["当我遇到机器学习问题的时候",{"2":{"1148":1}}],["当我将它投影到横轴x上",{"2":{"1145":1}}],["当我用学习算法时",{"2":{"1091":1}}],["当我第一次学习这个地方时",{"2":{"1068":1}}],["当我走访不同的公司",{"2":{"1059":1}}],["当我们开发一个异常检测系统时",{"2":{"1181":1}}],["当我们开始处理图像时",{"2":{"993":1}}],["当我们绘制这样的图表时",{"2":{"1167":1}}],["当我们认为试图重建从压缩表示",{"2":{"1161":1}}],["当我们认为y导致x时",{"2":{"182":1}}],["当我们把所有的数据都投射到该向量上时",{"2":{"1158":1}}],["当我们仅有两个特征",{"2":{"1145":1}}],["当我们确定学习算法的参数的时候",{"2":{"1130":1}}],["当我们运用训练好了的模型来预测未知数据的时候发现有较大的误差",{"2":{"1129":1}}],["当我们运行迭代时",{"2":{"600":1}}],["当我们对一个较为复杂的模型",{"2":{"1124":1}}],["当我们对图像进行分类时",{"2":{"170":1}}],["当我们打开",{"2":{"1089":1}}],["当我们打印张量或将张量转换为numpy格式时",{"2":{"450":1}}],["当我们讲到分类算法",{"2":{"1085":1}}],["当我们接近局部最低点时",{"2":{"1068":1}}],["当我们处理多个随机变量时",{"2":{"1029":1}}],["当我们处理更复杂的块",{"2":{"432":1}}],["当我们通过更多的实验获得更多的数据时",{"2":{"1026":1}}],["当我们建立推荐系统时",{"2":{"1025":1}}],["当我们构造数组来作为神经网络中的参数时",{"2":{"1017":1}}],["当我们简单地将每个元素cij计算为点积ai⊤bj",{"2":{"999":1}}],["当我们为矩阵a和向量x调用tf",{"2":{"998":1}}],["当我们为矩阵a和向量x调用torch",{"2":{"998":1}}],["当我们为矩阵a和向量x调用np",{"2":{"998":1}}],["当我们交换矩阵的行和列时",{"2":{"992":1}}],["当我们增大环的大小时",{"2":{"842":1}}],["当我们从一个gpu迁移到多个gpu时",{"2":{"840":1}}],["当我们计算一个小批量的",{"2":{"797":1}}],["当我们赋予一个事件较低的概率时",{"2":{"651":1}}],["当我们遍历数据集时",{"2":{"634":1}}],["当我们必须输出硬预测",{"2":{"634":1}}],["当我们不断更新参数时",{"2":{"621":1}}],["当我们想要预测离散的输出值",{"2":{"1063":1}}],["当我们想要从内存中读取一部分内容时",{"2":{"802":1}}],["当我们想要将输出视作二元分类问题的概率时",{"2":{"236":1}}],["当我们想预测一个数值时",{"2":{"608":1}}],["当我们用一个向量加一个标量时",{"2":{"602":1}}],["当我们需要更复杂的模型时",{"2":{"595":1}}],["当我们需要对所有参数执行操作时",{"2":{"432":1}}],["当我们",{"2":{"594":1}}],["当我们实例化trainer时",{"2":{"594":1}}],["当我们第一次尝试通过我们的模型传递数据时",{"2":{"591":2}}],["当我们在octave中调用",{"2":{"1160":1}}],["当我们在构造垃圾邮件分类器时",{"2":{"1138":1}}],["当我们在谈论线性回归的梯度下降法时",{"2":{"1110":1}}],["当我们在计算机上运行代码时",{"2":{"801":1}}],["当我们在",{"2":{"591":1}}],["当我们在k折交叉验证中训练k次后",{"2":{"211":1}}],["当我们跨多个服务器部署作业时",{"2":{"445":3}}],["当我们要读取或写入模型中的所有权重时",{"2":{"441":1}}],["当我们首次实现循环神经网络",{"2":{"306":1}}],["当我们获得了一些数据源及其表示",{"2":{"287":1}}],["当我们取一个二次函数的导数时",{"2":{"270":1}}],["当我们的输入包含d个特征时",{"2":{"610":1}}],["当我们的训练误差明显低于验证误差时要小心",{"2":{"258":1}}],["当我们的网络有很多层时",{"2":{"242":1}}],["当我们比较训练和验证误差时",{"2":{"258":1}}],["当我们有不止两种分类时",{"2":{"1103":1}}],["当我们有了所有的基本组件",{"2":{"595":1}}],["当我们有更复杂的模型和更少的样本时",{"2":{"254":1}}],["当我们有简单的模型和大量的数据时",{"2":{"254":1}}],["当我们逐渐增加数据量",{"2":{"252":1}}],["当我们训练时",{"2":{"467":1}}],["当我们训练模型时",{"2":{"251":1,"253":1}}],["当我们训练容量较大的模型时",{"2":{"204":1}}],["当我们改变搜索引擎的行为时会发生什么",{"2":{"203":1}}],["当我们部署机器学习系统时",{"2":{"201":1}}],["当我们将hθ",{"2":{"1109":1}}],["当我们将来部署该模型时",{"2":{"251":1}}],["当我们将预测转化为行动时",{"2":{"201":1}}],["当我们将暂退法应用到隐藏层",{"2":{"171":1}}],["当我们将动量超参数momentum增加到0",{"2":{"91":1}}],["当我们添加通道时",{"2":{"119":1}}],["当我们使用机器学习时",{"2":{"1137":1}}],["当我们使用x1",{"2":{"1097":1}}],["当我们使用softmax回归时",{"2":{"422":1}}],["当我们使用有限的样本时",{"2":{"251":1}}],["当我们使用学习率为0",{"2":{"108":1}}],["当我们使用带动量法的小批量随机梯度下降时会发生什么",{"2":{"97":1}}],["当我们执行带动量法的随机梯度下降时会有什么变化",{"2":{"97":1}}],["当从该随机变量分布中采样不同值x时",{"2":{"1036":1}}],["当从图像边界像素获取隐藏表示时",{"2":{"160":1}}],["当函数f",{"2":{"1036":1}}],["当函数在零梯度位置处的hessian矩阵的特征值为负值和正值时",{"2":{"102":1}}],["当函数在零梯度位置处的hessian矩阵的特征值全部为负值时",{"2":{"102":1}}],["当函数在零梯度位置处的hessian矩阵的特征值全部为正值时",{"2":{"102":1}}],["当不再需要时",{"2":{"1021":1}}],["当不同层的特征图在输入图像上分别拥有不同大小的感受野时",{"2":{"913":1}}],["当权重为非负数且和为1",{"2":{"997":1}}],["当权重的取值范围较大时",{"2":{"254":1}}],["当矩阵具有相同数量的行和列时",{"2":{"992":1}}],["当用户在看某部电影",{"2":{"1191":1}}],["当用张量表示一个向量",{"2":{"991":1}}],["当用来拟合非线性模式",{"2":{"265":1}}],["当向量表示数据集中的样本时",{"2":{"990":1}}],["当对向量值变量y",{"2":{"975":1}}],["当对上面的fancy",{"2":{"816":1}}],["当指定多个输出通道时",{"2":{"969":1}}],["当它的自信度上升时",{"2":{"1127":1}}],["当它的值较小时",{"2":{"966":1}}],["当它穿过这个十字路口时",{"2":{"1127":1}}],["当它暂停时",{"2":{"1059":1}}],["当它们的长度相同时",{"2":{"371":1}}],["当hθ",{"2":{"1107":2,"1108":2}}],["当hw的值较大时",{"2":{"923":1}}],["当hybridize函数被调用时",{"2":{"818":1}}],["当模型训练结束时",{"2":{"917":1}}],["当模型通过一个词元接一个词元地生成序列进行预测时",{"2":{"568":1}}],["当尺度设置为0",{"2":{"912":1}}],["当lr",{"2":{"895":1}}],["当验证集在超参数调整过程中用于模型评估时",{"2":{"892":1}}],["当目标比图像小得多时",{"2":{"966":1}}],["当目标数据集比源数据集小得多时",{"2":{"870":1}}],["当目标函数l通过ht+1和ot",{"2":{"312":1}}],["当目标函数表现特别好时",{"2":{"115":1}}],["当中心位置给定时",{"2":{"848":1}}],["当添加多个参数服务器以增加带宽时",{"2":{"845":1}}],["当谈及现代深度学习硬件的同步问题时",{"2":{"842":1}}],["当其他梯度参数仍在计算时",{"2":{"832":1}}],["当通道或单元的数量不太小时",{"2":{"832":1}}],["当通过sequential类定义模型时",{"2":{"430":1}}],["当速度很重要时",{"2":{"821":1}}],["当完成这些任务后",{"2":{"819":4}}],["当处理器1上的线程请求数据时",{"2":{"810":1}}],["当处理图像数据时",{"2":{"284":1}}],["当设置了适当的标志时",{"2":{"802":1}}],["当单个操作符的工作量足够小",{"2":{"799":1}}],["当执行分布式优化时",{"2":{"797":1}}],["当执行1×1卷积运算时",{"2":{"122":1}}],["当初始符号词表大小为n时",{"2":{"759":1}}],["当词表非常大时",{"2":{"753":1}}],["当词表大小v很大时",{"2":{"709":1}}],["当词wi出现在词wj的上下文窗口时",{"2":{"743":1}}],["当x=1时",{"2":{"981":2}}],["当x",{"2":{"743":1}}],["当在cpu或gpu上执行操作的时候",{"2":{"1022":1}}],["当在k个gpu上训练时",{"2":{"833":1}}],["当在",{"2":{"733":1,"1143":1}}],["当在带有gpu的服务器上训练神经网络时",{"2":{"445":3}}],["当将高和宽两侧的填充数指定为1时",{"2":{"969":1}}],["当将每个单词或子词视为单个词元时",{"2":{"754":1}}],["当将gpt应用于下游任务时",{"2":{"732":1}}],["当将超参数k设置为较小的值时",{"2":{"708":1}}],["当将太多的概率乘在一起时",{"2":{"241":1}}],["当空间或时间有限时",{"2":{"663":1}}],["当系统接收到查询",{"2":{"662":1}}],["当预测片段时",{"2":{"660":1}}],["当预测结束时",{"2":{"660":1}}],["当预测与标签分类y一致时",{"2":{"634":1}}],["当预测序列与标签序列完全相同时",{"2":{"578":1}}],["当调用函数来实例化张量时",{"2":{"992":1}}],["当调用一个使用gpu的函数时",{"2":{"789":1}}],["当调用sum运算符时",{"2":{"631":1}}],["当调用更新次数时",{"2":{"68":1}}],["当今大多数深度学习的研究几乎没有直接从神经科学中获得灵感",{"2":{"619":1}}],["当今几乎所有的图像识别",{"2":{"134":1}}],["当控制学家",{"2":{"619":1}}],["当深度学习从业者与统计学家交谈时",{"2":{"614":1}}],["当深度学习开始时",{"2":{"302":1}}],["当后面执行net",{"2":{"591":2}}],["当k=2时",{"2":{"578":1}}],["当输出序列的预测遇到序列结束词元",{"2":{"577":1}}],["当输入参数",{"2":{"1111":1}}],["当输入特征为布尔值",{"2":{"1102":1}}],["当输入x和卷积核k都是四维张量时",{"2":{"968":1}}],["当输入维度未知时",{"2":{"418":1}}],["当输入在0附近时",{"2":{"237":1}}],["当输入为文本对时",{"2":{"734":1}}],["当输入为单个文本时",{"2":{"734":1}}],["当输入为gpu上的张量时",{"2":{"451":1}}],["当输入为0时",{"2":{"236":1}}],["当输入为负时",{"2":{"235":1}}],["当输入接近0时",{"2":{"236":1,"237":1}}],["当输入超过阈值时取值1",{"2":{"236":1}}],["当输入值精确等于0时",{"2":{"235":1}}],["当输入高度和宽度两侧的填充数量分别为ph和pw时",{"2":{"142":1}}],["当输入包含多个通道时",{"2":{"120":1}}],["当选择q",{"2":{"573":1}}],["当|y|=10000和t",{"2":{"514":2}}],["当理想映射f",{"2":{"501":1}}],["当alex",{"2":{"457":1}}],["当客人到店的时候",{"2":{"450":1}}],["当运行一个耗时较长的训练过程时",{"2":{"440":1}}],["当参数绑定时",{"2":{"437":2}}],["当参数对象存在时",{"2":{"418":1}}],["当需要决定一个句子是否可以从另一个句子推断出来",{"2":{"664":1}}],["当需要更强的灵活性时",{"2":{"425":1}}],["当需要检测输入特征中更广区域时",{"2":{"132":1}}],["当mysequential的前向传播函数被调用时",{"2":{"424":1}}],["当mysequential实例调用initialize函数时",{"2":{"424":1}}],["当考虑到拥有多个物理存储体时",{"2":{"802":1}}],["当考虑具有多个输出的网络时",{"2":{"422":1}}],["当考虑与多个gpu和多台服务器并行处理时",{"2":{"77":1}}],["当进行最后一个英语到法语的句子翻译工作时",{"2":{"409":1}}],["当进行互相关运算时",{"2":{"128":1}}],["当更新循环神经网络的隐状态时",{"2":{"397":1}}],["当给出一件产品时",{"2":{"1191":1}}],["当给出更多样本而不是特征",{"2":{"169":1}}],["当给定从x的同分布中取样的新样本特征时",{"2":{"610":1}}],["当给定输入数据时",{"2":{"591":1}}],["当给定相同的查询",{"2":{"380":1}}],["当查询和键具有相同的矢量长度时",{"2":{"372":1}}],["当查询和键是不同长度的矢量时",{"2":{"369":1,"371":1}}],["当假设xt仅是离散值时",{"2":{"348":1}}],["当p=q时",{"2":{"652":1}}],["当pn固定时",{"2":{"578":1}}],["当p",{"2":{"348":1,"1180":2}}],["当ph=pw=p时",{"2":{"142":1}}],["当下获得的最直接的好处就是参数的数量总是不变的",{"2":{"347":1}}],["当前组件的父组件实例对象",{"2":{"1502":1}}],["当前分支变基到",{"2":{"1334":1}}],["当前时间",{"2":{"1235":1}}],["当前时间步的输入和前一个时间步的隐状态",{"2":{"553":1}}],["当前时间步t的隐状态ht",{"2":{"340":1}}],["当前时间步隐藏变量由当前时间步的输入",{"2":{"340":1}}],["当前所处路径",{"2":{"1089":1}}],["当前的实现足够快吗",{"2":{"586":1}}],["当前的观察结果可能无法阐述有关当前状态的所有信息",{"2":{"298":1}}],["当α",{"2":{"337":1}}],["当使用梯度下降法来实现逻辑回归时",{"2":{"1110":1}}],["当使用张量时",{"2":{"1017":1}}],["当使用较小的锚框检测较小的物体时",{"2":{"912":1}}],["当使用这些比例和长宽比的所有组合以每个像素为中心时",{"2":{"848":1}}],["当使用随机梯度下降来最小化损失时",{"2":{"784":1}}],["当使用随机抽样时",{"2":{"335":1}}],["当使用小批量随机梯度下降进行训练时",{"2":{"743":1}}],["当使用不同的参数初始化方法时",{"2":{"460":1}}],["当使用卷积神经网络时",{"2":{"417":1}}],["当使用顺序划分时",{"2":{"336":1}}],["当使用顺序分区时",{"2":{"335":1}}],["当解决优化问题时",{"2":{"334":1}}],["当t较大时",{"2":{"334":1}}],["当t=1",{"2":{"307":1}}],["当元素在实数上满足均匀分布时",{"2":{"332":1}}],["当序列变得太长而不能被模型一次性全部处理时",{"2":{"319":1}}],["当ϵ1接近正无穷大时",{"2":{"316":1}}],["当ϵ1=0时",{"2":{"316":1}}],["当基于循环神经网络使用通过时间反向传播",{"2":{"311":1}}],["当没有状态",{"2":{"298":1}}],["当状态不依赖于之前的操作时",{"2":{"298":1}}],["当环境可被完全观察到时",{"2":{"298":1}}],["当智能体失败时",{"2":{"298":1}}],["当智能体获胜时",{"2":{"298":1}}],["当训练较少行数据的时候",{"2":{"1134":1}}],["当训练词嵌入模型时",{"2":{"773":1}}],["当训练语料库很大时",{"2":{"770":1}}],["当训练语言模型时",{"2":{"331":1}}],["当训练我们的神经网络时",{"2":{"319":1}}],["当训练和测试数据不同时",{"2":{"297":1}}],["当训练数据稀缺时",{"2":{"257":1}}],["当训练数据集中有更多样本时",{"2":{"117":1}}],["当训练数据集较大时",{"2":{"113":1}}],["当分类器遇到新的动物时可能会束手无策",{"2":{"292":1}}],["当分布变化缓慢并且模型没有得到充分更新时",{"2":{"187":1}}],["当有一些多余的特征时",{"2":{"1086":1}}],["当有许多锚框时",{"2":{"854":1}}],["当有足够的计算资源时",{"2":{"656":1}}],["当有两个以上的类别时",{"2":{"291":1}}],["当有了更复杂数值的卷积核",{"2":{"129":1}}],["当人们在讨论",{"2":{"1154":1}}],["当人们在市场上寻找新房子时",{"2":{"290":1}}],["当人们谈到梯度下降时",{"2":{"1067":1}}],["当人们和计算机视觉研究人员交谈",{"2":{"454":1}}],["当人们和机器学习研究人员交谈时",{"2":{"454":1}}],["当人们逐渐关注到到基于梯度的学习时",{"2":{"236":1}}],["当试图解决分类问题时",{"2":{"286":1}}],["当任务在试图预测数值时",{"2":{"286":1}}],["当数据采用张量格式后",{"2":{"1013":1}}],["当数据在一级缓存中被找到时",{"2":{"810":1}}],["当数据丰富时",{"2":{"302":1}}],["当数据稀缺时",{"2":{"302":1}}],["当数据不具有充分代表性",{"2":{"284":1}}],["当数据样本包含了x的不同值时",{"2":{"259":1}}],["当每个样本的特征类别数量都是相同的时候",{"2":{"284":1}}],["当买家单击将商品添加到购物车时",{"2":{"281":1}}],["当可调整参数的数量",{"2":{"254":1}}],["当收集到更多的数据时",{"2":{"251":1}}],["当反向传播通过许多层时",{"2":{"242":1}}],["当美军第一次试图在森林中探测坦克时",{"2":{"186":1}}],["当标签取任意数值时",{"2":{"290":1}}],["当标签的定义发生变化时",{"2":{"183":1}}],["当标签是确定的",{"2":{"182":1}}],["当应用或不应用暂退法时",{"2":{"178":1}}],["当面对更多的特征而样本不足时",{"2":{"169":1}}],["当为离散对象时",{"2":{"156":1}}],["当这些准备工作完成",{"2":{"445":1}}],["当这种情况是由于深度网络的初始化所导致时",{"2":{"243":1}}],["当这种偏置与现实相符时",{"2":{"155":1}}],["当这个层执行严格的卷积时",{"2":{"130":1}}],["当图像处理的局部区域很小时",{"2":{"155":1}}],["当然你可以将其写作θ0",{"2":{"1145":1}}],["当然你也可以把这里的参数c",{"2":{"1143":1}}],["当然你也可以把它当成梯度下降",{"2":{"1111":1}}],["当然数据如果不是线性可分的",{"2":{"1144":1}}],["当然有多条不同的直线",{"2":{"1144":1}}],["当然据我所知",{"2":{"1090":1}}],["当然这也是我们第一次使用一个",{"2":{"1092":1}}],["当然这里",{"2":{"1090":1}}],["当然这不是唯一的算法",{"2":{"1060":1}}],["当然matlab也很好",{"2":{"1088":1}}],["当然也可以选择cpu上聚合",{"2":{"841":1}}],["当然",{"2":{"147":4,"298":1,"345":1,"423":1,"512":1,"619":1,"708":1,"933":1,"1066":1,"1089":1,"1090":1,"1110":1,"1127":1,"1143":3,"1144":1,"1150":1,"1168":1,"1176":1}}],["当检测较底层的特征时",{"2":{"145":1}}],["当state中的数据",{"2":{"1493":1}}],["当st的二次矩估计值爆炸时",{"2":{"35":1}}],["当sigmoid激活函数的输出非常接近于0或1时",{"2":{"460":1}}],["当sigmoid函数的输入很大或是很小时",{"2":{"242":1}}],["当sh=sw=s时",{"2":{"142":1}}],["当高度和宽度上的步幅分别为sh和sw时",{"2":{"142":1}}],["当垂直步幅为sh",{"2":{"142":1}}],["当满足",{"2":{"141":1}}],["当时gpu计算比较慢",{"2":{"1148":1}}],["当时为2gb",{"2":{"832":1}}],["当时的数据集仍然相对较小",{"2":{"454":1}}],["当时",{"2":{"135":2}}],["当一个像素被多个区域所覆盖时",{"2":{"866":1}}],["当一个模型在训练集上表现良好",{"2":{"286":1}}],["当一个数据科学家试图解决的问题会随着时间的推移而发生变化时",{"2":{"200":1}}],["当一个特征图中的任意元素需要检测更广区域的输入特征时",{"2":{"131":1}}],["当一个函数的二阶导数f",{"2":{"46":1}}],["当卷积有多个输出通道时",{"2":{"470":1}}],["当卷积核的高度和宽度不同时",{"2":{"141":1}}],["当卷积层对",{"2":{"130":1}}],["当卷积窗口继续向右滑动两列时",{"2":{"142":1}}],["当卷积窗口滑动到新一个位置时",{"2":{"126":1}}],["当卷积窗口不是1×1时",{"2":{"124":1}}],["当以每像素为基础应用时",{"2":{"123":1}}],["当优化问题的数值解接近局部最优值时",{"2":{"101":1}}],["当0",{"2":{"95":1}}],["当批量大小等于100时",{"2":{"80":1}}],["当批量大小为1时",{"2":{"80":1}}],["当涉及到单个gpu甚至cpu时",{"2":{"77":1}}],["当d的值很小且问题很简单时",{"2":{"59":1}}],["当学习率为η=1",{"2":{"55":1}}],["当梯度|f",{"2":{"54":1}}],["当且仅当",{"2":{"1059":1}}],["当且仅当p",{"2":{"1034":1}}],["当且仅当两个随机变量的联合分布是其各自分布的乘积",{"2":{"1034":1}}],["当且仅当向量全由0组成",{"2":{"1000":1}}],["当且仅当其hessian",{"2":{"51":1}}],["当且仅当对于所有x",{"2":{"46":1}}],["当且仅当g",{"2":{"46":1}}],["当且仅当任意二次可微一维函数f",{"2":{"46":1}}],["当λ∈",{"2":{"45":1}}],["当λa+",{"2":{"40":1}}],["当",{"2":{"40":1,"348":1,"1067":1,"1092":1,"1109":1,"1132":2,"1133":1,"1143":1,"1147":1}}],["和用户玩游戏",{"2":{"1539":1}}],["和上一个",{"2":{"1320":1}}],["和上下文变量c作为其输入",{"2":{"574":1}}],["和机器学习",{"2":{"1303":1}}],["和θ",{"2":{"1190":1}}],["和电影",{"2":{"1188":1}}],["和我们的拟合模型",{"2":{"1185":1}}],["和我们还有你如何来实现它们",{"2":{"1061":1}}],["和你估计的参数",{"2":{"1185":1}}],["和你的变量",{"2":{"1185":1}}],["和参数化",{"2":{"1185":1}}],["和μ1",{"2":{"1152":1}}],["和和x^",{"2":{"1145":1}}],["和右边的s型激励函数",{"2":{"1143":1}}],["和eric",{"2":{"1141":1}}],["和查全率",{"2":{"1139":1}}],["和on",{"2":{"1111":1}}],["和与它密切相关的",{"2":{"1111":1}}],["和这些偏导数",{"2":{"1111":1}}],["和这个时间步的标签",{"2":{"341":1}}],["和有限内存局部优化法",{"2":{"1109":1}}],["和正向类",{"2":{"1106":1}}],["和刚才一样",{"2":{"1092":1}}],["和c分别表示行和列",{"2":{"1090":1}}],["和copy",{"2":{"797":1}}],["和r",{"2":{"1088":1}}],["和r的凸性使其满足的e",{"2":{"115":1}}],["和j=1时",{"2":{"1067":1}}],["和j",{"2":{"1064":1,"1067":1}}],["和平均每个星期会从硅谷收到两",{"2":{"1058":1}}],["和平均汇聚层",{"2":{"146":1}}],["和复杂的工作流",{"2":{"1041":1}}],["和连续",{"2":{"1028":1}}],["和按列",{"2":{"1018":1}}],["和张量中元素的总数",{"2":{"1017":1}}],["和房屋价格",{"2":{"1011":1}}],["和房龄",{"2":{"609":1}}],["和多项分布",{"2":{"1006":1}}],["和多层感知机模型",{"2":{"135":1}}],["和列索引",{"2":{"992":1}}],["和u=g",{"2":{"984":1}}],["和ui",{"2":{"784":1}}],["和df",{"2":{"979":1}}],["和汇聚层",{"2":{"967":1}}],["和实例分割",{"2":{"944":1}}],["和边界框",{"2":{"939":1}}],["和l",{"2":{"1111":1}}],["和lr",{"2":{"910":1}}],["和labels的散点图",{"2":{"599":1}}],["和test",{"2":{"901":1}}],["和torch",{"2":{"446":1}}],["和样式迁移",{"2":{"886":1}}],["和色调",{"2":{"880":1}}],["和y",{"2":{"863":1}}],["和系统工程师",{"2":{"844":1}}],["和改进",{"2":{"820":1}}],["和f",{"2":{"816":1}}],["和fill",{"2":{"592":1}}],["和if之类的语句来更改程序的状态",{"2":{"816":1}}],["和读取",{"2":{"815":1}}],["和更高的处理能力",{"2":{"811":1}}],["和更新门",{"2":{"540":1}}],["和无法训练网络",{"2":{"800":1}}],["和网络带宽",{"2":{"798":1}}],["和线程",{"2":{"795":1}}],["和特殊的未知符号",{"2":{"757":1}}],["和特殊子词",{"2":{"756":1}}],["和词wi",{"2":{"742":1}}],["和词元级",{"2":{"663":1}}],["和masklm中的全连接层都使用高斯误差线性单元",{"2":{"740":1}}],["和英语语言包",{"2":{"717":1}}],["和噪声词wk在文本序列的时间步t处的索引",{"2":{"708":1}}],["和噪声项ϵ生成数据集及其标签",{"2":{"599":1}}],["和核张量",{"2":{"699":1}}],["和营销",{"2":{"691":1}}],["和测试精度可以进一步提高",{"2":{"688":1}}],["和测试集",{"2":{"688":1}}],["和测试数据集",{"2":{"582":1}}],["和额外的多层感知机的隐藏层",{"2":{"688":1}}],["和vue2中的watch作用一致",{"2":{"1461":1}}],["和vue2中的computed作用一致",{"2":{"1460":1}}],["和v¯o=",{"2":{"785":1}}],["和vb",{"2":{"676":1}}],["和vocab",{"2":{"364":1}}],["和来自另一序列的对齐的词元送入函数g",{"2":{"675":1}}],["和注意力的精心构建的模型更具可行性",{"2":{"663":1}}],["和b的hadamard积为",{"2":{"994":1}}],["和b=",{"2":{"674":1}}],["和b=b",{"2":{"232":1}}],["和bert",{"2":{"662":1}}],["和问答",{"2":{"661":1}}],["和独热标签向量y",{"2":{"646":1}}],["和模型预测",{"2":{"636":1}}],["和学习率",{"2":{"635":1}}],["和16",{"2":{"812":1}}],["和12个自注意头",{"2":{"726":1}}],["和1",{"2":{"634":1,"1121":1}}],["和10个类的简单分类数据集",{"2":{"217":1}}],["和轴突端子",{"2":{"619":1}}],["和观测值y",{"2":{"611":1}}],["和ankle",{"2":{"582":1}}],["和ati已经开始为通用计算操作优化gpu",{"2":{"457":1}}],["和结束词元",{"2":{"567":1}}],["和其他序列模型",{"2":{"561":1}}],["和预测序列a",{"2":{"578":2}}],["和预测",{"0":{"560":1}}],["和预测函数",{"2":{"387":1}}],["和编码后的状态",{"2":{"534":1}}],["和反向隐状态h←t连接起来",{"2":{"521":1}}],["和之前线性回归的例子一样",{"2":{"630":1}}],["和之前一样",{"2":{"108":1}}],["和之后的部分",{"2":{"515":1}}],["和对输入序列的信息进行编码得到的上下文变量c",{"2":{"512":1}}],["和束搜索",{"2":{"512":1}}],["和带有2×2汇聚窗口",{"2":{"507":1}}],["和残差网络",{"2":{"492":1}}],["和过渡层",{"2":{"479":1}}],["和暂退法一样",{"2":{"471":1}}],["和偏导数项∂∂θjj",{"2":{"1111":2}}],["和偏置bh",{"2":{"521":1}}],["和偏置bq∈r1×q",{"2":{"340":1,"521":1}}],["和偏移量",{"2":{"850":1,"963":2}}],["和偏移",{"2":{"470":1}}],["和高达数mb的三级缓存",{"2":{"457":1}}],["和pricey就是两个存放数据的文档",{"2":{"1089":1}}],["和pricey",{"2":{"1089":1}}],["和pull",{"2":{"844":1}}],["和p",{"2":{"515":2,"1038":2,"1145":1}}],["和paddle",{"2":{"446":1}}],["和pw列填充",{"2":{"141":1}}],["和g",{"2":{"816":1}}],["和gpu",{"2":{"446":2}}],["和g的索引",{"2":{"156":1}}],["和第三个隐藏层",{"2":{"437":1}}],["和前向传播函数",{"2":{"423":1}}],["和前面",{"2":{"329":1}}],["和自注意力",{"2":{"379":1,"403":1}}],["和键",{"2":{"358":1,"385":1}}],["和外推法",{"2":{"352":1}}],["和形状",{"2":{"340":1}}],["和随机性",{"2":{"319":1}}],["和三元语法",{"2":{"317":1}}],["和num",{"2":{"910":1}}],["和not",{"2":{"872":1}}],["和n",{"2":{"316":1}}],["和sift特征提取器",{"2":{"302":1}}],["和假名人脸",{"2":{"300":1}}],["和抽样算法",{"2":{"300":1}}],["和神经编程器",{"2":{"300":1}}],["和图模型",{"2":{"299":1}}],["和公式",{"2":{"299":1}}],["和概率图模型",{"2":{"296":1}}],["和输出序列已经看见的或者生成的词元来预测下一个词元",{"2":{"572":1}}],["和输出通道的数量out",{"2":{"507":1}}],["和输出",{"2":{"282":1}}],["和输出层偏置b",{"2":{"232":1}}],["和h",{"2":{"232":1}}],["和隐藏层偏置b",{"2":{"232":1}}],["和目标分布",{"2":{"192":1}}],["和一组由w∈rd表示的权重",{"2":{"997":1}}],["和一个具有常规带宽的环",{"2":{"842":1}}],["和一个特殊的未知词元",{"2":{"748":1}}],["和一个未标记的测试集",{"2":{"191":1}}],["和一阶导数f",{"2":{"54":1}}],["和q学习",{"2":{"300":1}}],["和q",{"2":{"191":1}}],["和从q",{"2":{"191":1}}],["和whi",{"2":{"553":1}}],["和whh∈rh×h是权重参数",{"2":{"541":1}}],["和whr",{"2":{"540":1}}],["和waymo等公司的产品至少实现了部分自主",{"2":{"301":1}}],["和w",{"2":{"164":1}}],["和z=g",{"2":{"164":1}}],["和以前一样",{"2":{"147":1,"473":1,"489":1,"496":1,"626":1}}],["和xt=",{"2":{"350":1}}],["和x",{"2":{"146":2,"669":1,"938":1,"1191":1}}],["和步幅",{"2":{"134":1,"140":1}}],["和k",{"2":{"128":1}}],["和k+2连接起来",{"2":{"121":1}}],["和矩阵",{"2":{"77":1}}],["和",{"0":{"1224":1,"1349":1,"1350":1,"1351":1},"1":{"1225":1,"1226":1},"2":{"65":1,"120":2,"164":1,"165":1,"169":1,"170":1,"209":2,"282":1,"293":1,"300":2,"315":1,"316":1,"319":1,"340":1,"341":1,"342":1,"369":1,"390":1,"467":1,"513":9,"518":1,"525":1,"546":1,"550":1,"562":1,"568":1,"576":1,"640":1,"667":3,"674":1,"675":1,"681":1,"687":3,"691":1,"699":1,"713":1,"727":2,"731":1,"732":1,"744":3,"750":1,"754":2,"755":5,"756":1,"757":5,"773":1,"803":1,"852":1,"859":1,"1008":1,"1012":3,"1018":1,"1027":1,"1029":1,"1043":1,"1047":2,"1064":1,"1086":1,"1089":1,"1092":3,"1111":2,"1121":1,"1143":1,"1147":1,"1180":2,"1185":5,"1187":1,"1352":1,"1359":2,"1408":1,"1435":1,"1463":1,"1490":1,"1513":1,"1525":2,"1549":1}}],["和先前单变量的情况一样",{"2":{"57":1}}],["和凸函数",{"2":{"39":1}}],["和ϵ",{"2":{"20":1}}],["换言之",{"2":{"38":1,"59":1,"136":1,"170":1,"180":1,"193":1,"241":1,"286":1,"340":1,"572":1,"665":1,"770":1,"977":1}}],["换句话说",{"2":{"25":1,"42":1,"57":1,"89":1,"158":1,"191":1,"196":1,"244":1,"253":1,"282":2,"291":2,"293":1,"295":3,"301":1,"305":1,"351":1,"355":1,"500":1,"647":1,"668":1,"757":1,"842":1,"939":1,"976":1,"1025":1,"1035":1,"1132":1,"1141":1,"1144":1,"1356":1}}],["凸目标的收敛性分析",{"0":{"115":1}}],["凸或非凸",{"2":{"64":1}}],["凸约束可以通过拉格朗日函数来添加",{"2":{"51":1}}],["凸投影的一个用途是计算稀疏权重向量",{"2":{"50":1}}],["凸优化的一个很好的特性是能够让我们有效地处理约束",{"2":{"47":1}}],["凸优化问题有助于分析算法的特点",{"2":{"26":1}}],["凸函数是hessian函数的特征值永远不为负值的函数",{"2":{"102":1}}],["凸函数的主要目的是帮助我们详细了解优化算法",{"2":{"51":1}}],["凸函数的下水平集是凸的",{"0":{"45":1}}],["凸函数的局部极小值同时也是全局极小值这一性质是很方便的",{"2":{"44":1}}],["凸函数的期望不小于期望的凸函数",{"2":{"42":1}}],["凸函数",{"0":{"41":1},"2":{"41":4}}],["凸集的交点是凸的",{"2":{"51":1}}],["凸集",{"0":{"40":1},"2":{"40":1}}],["凸性分析的内容是超出这门课的范围的",{"2":{"1109":1}}],["凸性和二阶导数",{"0":{"46":1}}],["凸性",{"0":{"38":1},"1":{"39":1,"40":1,"41":1,"42":1,"43":1,"44":1,"45":1,"46":1,"47":1,"48":1,"49":1,"50":1,"51":1,"52":1},"2":{"38":1}}],["尝试执行的代码块",{"2":{"1236":1}}],["尝试根据这些特征构建一个模型",{"2":{"1178":1}}],["尝试运行几天",{"2":{"1168":1}}],["尝试增加正则化程度λ",{"2":{"1129":1,"1135":1}}],["尝试增加多项式特征",{"2":{"1129":1,"1135":1}}],["尝试减少正则化程度λ",{"2":{"1129":1,"1135":1}}],["尝试减少特征的数量",{"2":{"1129":1,"1135":1}}],["尝试获得更多的特征",{"2":{"1129":1,"1135":1}}],["尝试从10个训练样本中找到满足101个参数的值",{"2":{"1086":1}}],["尝试从零开始实现两层循环神经网络",{"2":{"531":1}}],["尝试实践你的学习算法的时候",{"2":{"1086":1}}],["尝试实现这种训练方法",{"2":{"770":1}}],["尝试实现并运行它们",{"2":{"491":1}}],["尝试写出函数u=f",{"2":{"986":1}}],["尝试设计一种容错机制来避免重启计算这种解决方案",{"2":{"846":1}}],["尝试此操作",{"2":{"830":2}}],["尝试其他的句子拆分技术",{"2":{"724":1}}],["尝试计算exp⁡",{"2":{"638":1}}],["尝试调整超参数",{"2":{"628":1}}],["尝试一下",{"2":{"477":1}}],["尝试一个计算量更大的任务",{"2":{"453":1}}],["尝试简化模型以加快训练速度",{"2":{"465":1}}],["尝试访问net",{"2":{"418":1}}],["尝试找到另外三种常用的词元化文本的方法",{"2":{"366":1}}],["尝试说明独热编码等价于为每个对象选择不同的嵌入表示",{"2":{"337":1}}],["尝试使用不同的学习率",{"2":{"607":1}}],["尝试使用循环神经网络实现",{"2":{"328":1}}],["尝试使用高级api",{"2":{"328":1}}],["尝试不同的方案来初始化权重",{"2":{"227":1}}],["尝试不同的激活函数",{"2":{"227":1}}],["尝试不同的随机梯度下降学习率计划和不同的迭代次数进行实验",{"2":{"118":1}}],["尝试添加不同数量的隐藏层",{"2":{"227":1}}],["尝试添加更多的隐藏层",{"2":{"223":1}}],["尝试开发一种在fashion",{"2":{"178":1}}],["尝试将fashion",{"2":{"511":1}}],["尝试将最大汇聚层作为卷积层的特殊情况实现",{"2":{"150":1}}],["尝试将平均汇聚层作为卷积层的特殊情况实现",{"2":{"150":1}}],["尝试构建一个基于lenet的更复杂的网络",{"2":{"139":1}}],["尝试构造一个使用adam算法会发散而yogi会收敛的例子",{"2":{"37":1}}],["尝试对适当的深度网络使用adagrad算法",{"2":{"31":1}}],["尝试对函数f",{"2":{"31":1}}],["调颜色",{"2":{"1539":1}}],["调查",{"2":{"1303":1}}],["调",{"2":{"1053":1}}],["调节超参数",{"2":{"868":1}}],["调节学习率",{"2":{"37":1}}],["调度操作的开销可能会变得非常大",{"2":{"792":1}}],["调优其他超参数怎么样",{"2":{"717":1}}],["调参",{"2":{"613":1}}],["调用对应action",{"2":{"1491":1}}],["调用usexxxxxstore得到对应的store",{"2":{"1490":1}}],["调用特定的函数",{"2":{"1470":1}}],["调用它的方式如下",{"2":{"1111":1}}],["调用外部工具",{"2":{"1050":1}}],["调用外部工具并执行操作",{"2":{"1040":1}}],["调用工具",{"2":{"1048":1}}],["调用以下函数将计算矩阵的frobenius范数",{"2":{"1000":1}}],["调用求和函数会沿所有的轴降低张量的维度",{"2":{"995":1}}],["调用backward时",{"2":{"975":1}}],["调用前面定义的函数",{"2":{"890":1}}],["调用编译好的程序执行",{"2":{"817":1}}],["调用nltk",{"2":{"724":1}}],["调用",{"2":{"626":1}}],["调用框架中现有的api来读取数据",{"2":{"590":1}}],["调用父类的",{"2":{"423":1}}],["调用`mlp`的父类layer的构造函数来执行必要的初始化",{"2":{"423":1}}],["调用mlp的父类model的构造函数来执行必要的初始化",{"2":{"423":1}}],["调用mlp的父类module的构造函数来执行必要的初始化",{"2":{"423":1}}],["调用mlp的父类block的构造函数来执行必要的初始化",{"2":{"423":1}}],["调用我们的模型来获得模型的输出",{"2":{"422":4}}],["调用initialize不会真正初始化参数",{"2":{"418":1}}],["调用此算法会发生什么",{"2":{"67":1}}],["调整损失函数中的权重超参数",{"2":{"929":1}}],["调整超参数",{"2":{"706":1}}],["调整和分析超参数对运行时间",{"2":{"549":1,"563":1}}],["调整nin的超参数",{"2":{"498":1}}],["调整模型使之偏向更可能的输出",{"2":{"337":1}}],["调整模型参数以优化目标函数的算法",{"2":{"283":1}}],["调整参数",{"2":{"282":1}}],["调整为最小化预测损失和惩罚项之和",{"2":{"270":1}}],["调整全连接层的数量",{"2":{"139":1}}],["调整卷积层的数量",{"2":{"139":1}}],["调整卷积窗口大小",{"2":{"139":1}}],["调整激活函数",{"2":{"139":1}}],["调整输出通道的数量",{"2":{"139":1}}],["调整学习率和其他训练细节",{"2":{"139":1}}],["调整学习率通常与实际算法同样重要",{"2":{"66":1}}],["调整学习率是很复杂的",{"2":{"63":1}}],["调整ρ的值",{"2":{"23":1}}],["调整后的梯度gt",{"2":{"20":1}}],["作业",{"0":{"1310":1}}],["作出明智的选择",{"2":{"1137":1}}],["作者使用了带有3×3卷积核",{"2":{"507":1}}],["作者将",{"2":{"505":1}}],["作者所说的内部协变量转移类似于上述的投机直觉",{"2":{"475":1}}],["作者除了介绍了其应用",{"2":{"475":1}}],["作者们尽全力",{"2":{"354":1}}],["作者认为",{"2":{"170":1}}],["作者是",{"2":{"86":1}}],["作者还进一步建议用更大的初始批量来初始化动量",{"2":{"35":1}}],["作为props传给detail组件",{"2":{"1483":1}}],["作为默认运行时",{"2":{"1394":1}}],["作为这门课的结束时间",{"2":{"1176":1}}],["作为遇到偏斜类问题的评估度量值",{"2":{"1140":1}}],["作为例子",{"2":{"1134":1}}],["作为其传输格式",{"2":{"1044":1}}],["作为方阵的一种特殊类型",{"2":{"992":1}}],["作为端到端训练的结果",{"2":{"939":1}}],["作为说明性示例",{"2":{"938":1}}],["作为锚框的中心",{"2":{"912":1}}],["作为热身",{"2":{"790":3}}],["作为一种生动的例子",{"2":{"1156":1}}],["作为一种贪心方法",{"2":{"757":1,"758":1}}],["作为一名指导者",{"2":{"1061":1}}],["作为一名",{"2":{"1054":1}}],["作为一个关于$",{"2":{"1110":1}}],["作为一个监督学习问题",{"2":{"1061":1}}],["作为一个演示例子",{"2":{"974":1}}],["作为一个具体的经验案例",{"2":{"663":1}}],["作为一个从零开始的实现",{"2":{"635":1}}],["作为一个预处理器",{"2":{"106":1}}],["作为字节对编码算法的结果",{"2":{"757":1}}],["作为基于连续符号频率的贪心方法",{"2":{"757":1}}],["作为中心词",{"2":{"742":1,"784":1}}],["作为上下文词",{"2":{"742":1,"784":1}}],["作为全连接层的输入",{"2":{"713":3}}],["作为另一种近似训练方法",{"2":{"709":1}}],["作为另一个词元级应用",{"2":{"660":1}}],["作为跨时间步的最重要特征",{"2":{"700":1}}],["作为解码器在下一时间步的输入",{"2":{"577":4}}],["作为数据送入长短期记忆网络的门中",{"2":{"553":1}}],["作为数据量的函数",{"2":{"268":1}}],["作为",{"2":{"501":1,"712":1,"1525":1}}],["作为焦点",{"2":{"475":1}}],["作为额外的健全性检查",{"2":{"413":1}}],["作为输入单个文本的表示",{"2":{"657":1}}],["作为输入",{"2":{"362":1,"721":1}}],["作为新的常态",{"2":{"345":1}}],["作为代替",{"2":{"318":1}}],["作为将图像映射到特征向量的算法",{"2":{"302":1}}],["作为比较",{"2":{"300":1,"1093":1}}],["作为损失函数",{"2":{"291":1}}],["作为机器学习科学家",{"2":{"251":1}}],["作为开发测试的健康对照样本",{"2":{"185":1}}],["作为补偿",{"2":{"185":1}}],["作为样本i的随机梯度下降",{"2":{"86":1}}],["作为优化问题的一部分",{"2":{"59":1}}],["作为深度学习中使用的更强大和有效的优化算法之一",{"2":{"32":1}}],["作用域插槽",{"0":{"1508":1}}],["作用范围",{"2":{"1349":1}}],["作用是对所有序列位置的表示进行转换",{"2":{"410":1}}],["作用",{"2":{"48":1,"1263":1,"1347":1,"1348":1,"1455":1,"1456":1,"1459":1,"1460":1,"1461":1,"1468":1,"1478":1,"1483":4,"1484":1,"1486":1,"1511":1,"1512":1,"1515":1,"1516":1,"1518":1,"1519":1,"1520":1,"1539":1}}],["忘记怎么用的时候",{"2":{"1090":1}}],["忘记门和输出门",{"0":{"553":1}}],["忘记",{"2":{"35":1}}],["yuysada03",{"2":{"1490":1}}],["yuysada02",{"2":{"1490":1}}],["yuysada01",{"2":{"1490":1}}],["yes",{"2":{"1444":2}}],["y坐标向量各自平移到原点后的夹角余弦",{"2":{"1154":1}}],["y$",{"2":{"1141":1,"1181":1}}],["yk",{"2":{"1121":1}}],["y值",{"2":{"1092":1}}],["y为m行1列的矩阵",{"2":{"1086":1}}],["y为例",{"2":{"1018":1}}],["y0y1y2y3",{"2":{"1072":1}}],["y更改为x",{"2":{"1024":1}}],["y来减少操作的内存开销",{"2":{"1021":1}}],["y或x",{"2":{"1021":1,"1024":1}}],["y在该位置处为真",{"2":{"1018":1}}],["y和z",{"2":{"989":1,"990":1,"992":1,"993":1}}],["y关于第i个参数xi的偏导数",{"2":{"982":1}}],["y是什么",{"2":{"1141":1}}],["y是成立的",{"2":{"1092":1}}],["y是",{"2":{"984":1}}],["y是一个向量",{"2":{"975":1}}],["y是典型的未观察到的随机变量",{"2":{"42":1}}],["y已经预先计算好了",{"2":{"923":1}}],["yb−yaha−μyσy",{"2":{"852":1}}],["yb",{"2":{"852":1}}],["yml",{"2":{"1277":2,"1347":1,"1349":2}}],["ymax",{"2":{"848":3}}],["ymin",{"2":{"848":3}}],["y的真实标签mlm",{"2":{"736":1}}],["y的有效长度",{"2":{"569":1}}],["y∈rd",{"2":{"781":1,"997":1}}],["y∈rn",{"2":{"46":3}}],["y∈",{"2":{"640":1,"989":1}}],["y中",{"2":{"610":1}}],["y−μy",{"2":{"1154":3}}],["y−w⊤x−b",{"2":{"616":1}}],["y−y",{"2":{"597":1}}],["y−x",{"2":{"115":1}}],["y3∣a",{"2":{"515":1}}],["y3∣c",{"2":{"515":3}}],["y=i",{"2":{"1112":1}}],["y=i|x",{"2":{"1112":1}}],["y=4",{"2":{"1112":1}}],["y=3",{"2":{"1112":2}}],["y=2",{"2":{"1112":3}}],["y=1的样本",{"2":{"1143":1}}],["y=1$",{"2":{"1110":1}}],["y=1|x",{"2":{"1107":1,"1110":1}}],["y=1",{"2":{"1107":1,"1108":4,"1109":2,"1110":1,"1112":3,"1143":6,"1144":1,"1146":2,"1147":1,"1168":2,"1182":1}}],["y=0or1表示哪一类",{"2":{"1120":1}}],["y=0",{"2":{"1026":4,"1107":1,"1108":3,"1109":1,"1143":1,"1146":1,"1147":1,"1168":1,"1182":1}}],["y=y",{"2":{"986":1}}],["y=none",{"2":{"981":1}}],["y=猫∣x",{"2":{"646":1}}],["y=w⊤x+b+ϵ",{"2":{"616":1}}],["y=xw+b+ϵ",{"2":{"599":1}}],["y=",{"2":{"515":1,"1025":4,"1072":3,"1154":1}}],["y∣y1",{"2":{"513":1}}],["y∣x",{"2":{"181":1,"183":1,"191":5,"616":4,"621":1,"646":4}}],["yscale",{"2":{"635":1,"981":4}}],["yscale=",{"2":{"211":1,"213":1,"263":4,"275":4,"278":4,"318":2,"635":1,"981":1}}],["ys",{"2":{"321":12,"1154":1}}],["york",{"2":{"717":3,"788":1}}],["yoshua",{"2":{"455":1}}],["your",{"2":{"1336":2}}],["yourself",{"2":{"295":1}}],["young",{"2":{"811":1}}],["you",{"2":{"250":1,"295":2,"300":1,"1176":1,"1443":1,"1526":1}}],["yogi提供了这样的替代方案",{"2":{"36":1}}],["yogi",{"0":{"35":1},"2":{"35":8}}],["yamlapiversion",{"2":{"1389":1,"1390":1,"1391":1}}],["yamlname",{"2":{"1315":1}}],["yaml",{"0":{"1388":1},"1":{"1389":1,"1390":1,"1391":1},"2":{"1309":1,"1314":2,"1388":1,"1392":2}}],["ya",{"2":{"852":1}}],["yaxis",{"2":{"582":3}}],["yan",{"2":{"493":1}}],["yann",{"2":{"135":1}}],["yao",{"2":{"198":1}}],["yj",{"2":{"192":2}}],["y^1=猫p",{"2":{"646":1}}],["y^可以视为一个正确的概率分布",{"2":{"643":1}}],["y^2和y^3分别为0",{"2":{"643":1}}],["y^j",{"2":{"624":2}}],["y^j=exp⁡",{"2":{"624":1}}],["y^=h",{"2":{"676":1}}],["y^=softmax",{"2":{"644":1}}],["y^=xw+b这个过程中的求和将使用广播机制",{"2":{"610":1}}],["y^=w⊤x+b",{"2":{"610":1}}],["y^=w1x1+",{"2":{"610":1}}],["y^=∑i=0dxiwi这只是一个线性回归问题",{"2":{"259":1}}],["y^i",{"2":{"192":2}}],["y^",{"2":{"192":3,"611":1,"646":2,"647":2,"655":1}}],["y|x",{"2":{"180":2}}],["y上的z的感受野包括y的所有四个元素",{"2":{"131":1}}],["y2是被立方后的结果",{"2":{"1092":1}}],["y2∣a",{"2":{"515":1}}],["y2∣c",{"2":{"515":3}}],["y2",{"2":{"122":2,"408":8,"441":8,"574":1,"858":5,"956":7,"1091":5,"1092":1,"1154":1}}],["yn",{"2":{"118":1,"190":1,"191":2,"195":1,"386":1,"390":1,"396":1}}],["y1y2y3y4",{"2":{"1072":1}}],["y1和y2",{"2":{"956":1}}],["y1∣c",{"2":{"515":1}}],["y1",{"2":{"118":1,"122":2,"190":1,"191":2,"195":1,"307":1,"386":1,"396":1,"515":1,"574":1,"858":5,"956":7,"1091":5,"1092":1,"1154":1}}],["yi=1表示分到第i类",{"2":{"1120":1}}],["yi=f",{"2":{"396":1}}],["yi=∑i=1nsoftmax",{"2":{"388":1,"389":1}}],["yi=∑i=1nexp⁡",{"2":{"388":1,"389":1}}],["yi=2sin⁡",{"2":{"386":1}}],["yield",{"0":{"1246":1},"2":{"320":1,"321":3,"600":2,"1246":2}}],["yi",{"2":{"116":1,"190":1,"191":3,"192":4,"196":1,"388":4,"389":1}}],["ylim",{"2":{"635":1,"981":4}}],["ylim=none",{"2":{"635":1,"981":1}}],["ylim=",{"2":{"80":4,"81":4,"263":4,"386":1,"635":1,"883":3,"927":1}}],["ylist",{"2":{"566":2}}],["yl∣c",{"2":{"515":1}}],["ylabel=none",{"2":{"635":1,"981":1}}],["ylabel=",{"2":{"80":4,"81":4,"211":1,"213":1,"263":4,"275":4,"278":4,"318":2,"335":4,"357":1,"369":1,"370":1,"376":3,"388":4,"392":8,"399":4,"409":4,"576":4,"616":2,"726":3,"767":3,"927":3}}],["ylabel",{"2":{"57":3,"102":2,"357":3,"566":3,"635":1,"693":1,"981":4,"1026":4}}],["y",{"2":{"42":3,"46":9,"52":1,"67":22,"80":16,"81":16,"102":9,"115":1,"116":3,"122":2,"126":10,"128":2,"129":21,"137":39,"141":12,"146":12,"162":1,"164":2,"180":2,"182":1,"189":1,"190":5,"191":3,"192":13,"195":1,"210":14,"211":15,"220":4,"235":12,"236":12,"237":12,"242":12,"263":10,"270":1,"275":8,"278":8,"320":4,"321":8,"325":21,"332":16,"333":16,"334":1,"335":38,"350":8,"382":6,"386":13,"387":11,"388":20,"390":8,"391":1,"392":33,"406":8,"407":12,"408":12,"413":7,"441":15,"442":12,"448":7,"449":2,"472":14,"480":20,"481":3,"500":1,"501":25,"545":8,"559":8,"569":5,"576":36,"577":8,"582":8,"583":1,"584":7,"595":8,"597":2,"599":9,"600":2,"603":5,"605":9,"610":2,"616":2,"619":1,"633":28,"634":37,"635":44,"636":2,"643":1,"646":5,"647":3,"655":1,"667":2,"669":2,"676":6,"677":6,"681":3,"692":2,"694":9,"699":8,"722":4,"726":44,"736":23,"737":15,"738":17,"757":2,"790":6,"792":3,"797":24,"817":2,"827":4,"828":15,"834":6,"836":9,"837":29,"848":25,"853":1,"854":1,"858":1,"863":11,"878":2,"883":17,"893":4,"896":6,"905":4,"906":4,"912":1,"920":12,"922":12,"923":12,"924":5,"925":16,"926":19,"927":42,"932":1,"938":1,"945":2,"948":6,"954":3,"959":15,"963":6,"966":9,"968":3,"969":1,"970":10,"971":1,"974":19,"975":8,"976":11,"981":11,"986":1,"989":20,"997":16,"1000":1,"1013":8,"1018":37,"1021":23,"1024":1,"1063":6,"1077":1,"1081":2,"1085":4,"1086":1,"1092":5,"1106":4,"1109":16,"1110":4,"1112":1,"1117":5,"1120":2,"1121":1,"1143":4,"1144":2,"1147":1,"1154":2,"1165":2,"1168":1,"1176":1,"1187":1,"1191":1,"1192":1,"1220":3,"1239":2,"1240":2,"1259":2,"1405":1,"1426":1,"1501":3}}],["ytx",{"2":{"1086":1}}],["yt⟶loss",{"2":{"196":1}}],["yticks",{"2":{"102":2}}],["yt",{"2":{"27":2,"196":1,"307":4,"312":3,"512":1,"513":4,"515":2,"574":7}}],["一切皆组件",{"2":{"1527":1}}],["一切都没有改变",{"2":{"418":1}}],["一切都很简单",{"2":{"34":1}}],["一前一后",{"2":{"1470":1}}],["一台",{"2":{"1456":1,"1457":1}}],["一键启动",{"2":{"1347":1}}],["一段",{"2":{"1311":1}}],["一位用户最近看上一件产品",{"2":{"1191":1}}],["一位投资者想要找到一种好的证券来购买",{"2":{"353":1}}],["一千多个特征都在一起",{"2":{"1156":1}}],["一是数据压缩",{"2":{"1156":1}}],["一点一点修改",{"2":{"1143":1}}],["一起来考虑两种情况",{"2":{"1143":1}}],["一起出现在电子邮件中表示垃圾邮件",{"2":{"169":1}}],["一件非常有用的事是误差分析",{"2":{"1138":1}}],["一下",{"2":{"1137":1}}],["一部分人确实掌握了怎样高效有力地运用这些学习算法",{"2":{"1129":1}}],["一对余",{"2":{"1112":1}}],["一对多",{"0":{"1112":1},"2":{"1112":1,"1193":1}}],["一行三列的a矩阵里的元素全部是零",{"2":{"1088":1}}],["一行三列的矩阵",{"2":{"1088":1}}],["一直到x",{"2":{"1150":1}}],["一直到θn",{"2":{"1110":2}}],["一直迭代下去",{"2":{"1068":2}}],["一直写一直写不停的写",{"2":{"1060":1}}],["一直是计算机视觉中监督学习进展的指向标",{"2":{"492":1}}],["一",{"0":{"1040":1,"1213":1,"1238":1,"1296":1,"1308":1,"1359":1},"1":{"1041":1,"1042":1,"1214":1,"1215":1,"1216":1,"1239":1,"1240":1,"1309":1,"1310":1,"1311":1,"1312":1,"1313":1,"1314":1},"2":{"1003":1,"1193":1}}],["一张是内容图像",{"2":{"916":1}}],["一开始",{"2":{"819":1,"1127":1}}],["一开始的大步可能没有好处",{"2":{"66":1}}],["一级缓存很小",{"2":{"810":1}}],["一级缓存是应对高内存带宽要求的第一道防线",{"2":{"810":1}}],["一样的参数同步操作基于不同的策略时间可能在15毫秒到80毫秒之间",{"2":{"841":1}}],["一样的属性",{"2":{"551":1}}],["一样访问这些值",{"2":{"791":1}}],["一词语义最相似的三个词",{"2":{"750":1}}],["一词与",{"2":{"741":1}}],["一词有完全不同的含义",{"2":{"731":1}}],["一词在不同的上下文",{"2":{"525":1}}],["一名学生给我一篇文章关于最顶尖的12个it技能",{"2":{"1058":1}}],["一名吊车司机来了",{"2":{"731":1}}],["一名男子正在运行dive",{"2":{"665":1}}],["一名忠实的用户会对每一部电影都给出评价",{"2":{"345":1}}],["一架飞机正在起飞",{"2":{"658":2}}],["一致性快照",{"2":{"1200":1}}],["一致",{"2":{"653":1}}],["一步更新的大小由学习速率lr决定",{"2":{"604":1}}],["一步一步地更新小批量数据的隐状态",{"2":{"330":1}}],["一本笔记本和一本书",{"2":{"355":1}}],["一杯咖啡",{"2":{"355":1}}],["一篇文章可以被简单地看作一串单词序列",{"2":{"360":1}}],["一篇研究论文",{"2":{"355":1}}],["一篇典型的文章可能会用5～10个标签",{"2":{"292":1}}],["一份报纸",{"2":{"355":1}}],["一阶马尔可夫模型",{"2":{"348":1}}],["一元语法",{"2":{"317":1,"318":1,"323":1}}],["一次构建",{"2":{"1339":1,"1354":1}}],["一次提交",{"2":{"1320":1}}],["一次实现这三个方程",{"2":{"1093":1}}],["一次运算得出",{"2":{"1085":1}}],["一次次越过最低点",{"2":{"1068":1}}],["一次是使用图模式",{"2":{"820":1}}],["一次不使用torchscript",{"2":{"820":1}}],["一次不使用混合式",{"2":{"820":1}}],["一次使用静态图符号式编程",{"2":{"820":1}}],["一次使用动态图命令式编程",{"2":{"820":1}}],["一次使用jit编译的xla",{"2":{"820":1}}],["一次使用eager模式",{"2":{"820":1}}],["一次使用torchscript",{"2":{"820":1}}],["一次使用混合式",{"2":{"820":1}}],["一次记录一个结果",{"2":{"453":1}}],["一次执行几个操作比代码中散布的许多单个操作要好得多",{"2":{"450":1}}],["一次一个时间步的遍历三元组",{"2":{"307":1}}],["一次性直接将384×5×5的表示缩减为10×5×5的表示",{"2":{"498":1}}],["一次性访问所有参数",{"0":{"432":1}}],["一次性调整网络中的全部参数",{"2":{"299":1}}],["一次性计算a=bc",{"2":{"77":4}}],["一头驴",{"2":{"292":1}}],["一只鹤在飞",{"2":{"731":1}}],["一只猫",{"2":{"292":1}}],["一只猫就是一只猫",{"2":{"183":1}}],["一只狗",{"2":{"292":2}}],["一只公鸡",{"2":{"292":2}}],["一家银行希望在其移动应用程序中添加支票扫描功能",{"2":{"291":1}}],["一条简单的经验法则相当有用",{"2":{"254":1}}],["一层叠一层",{"2":{"232":1}}],["一旦变化就更新",{"2":{"1520":1}}],["一旦任意测试失败",{"2":{"1315":1}}],["一旦完成了字符的识别",{"2":{"1172":1}}],["一旦完成后",{"2":{"1172":1}}],["一旦对一个数据的学习完成了",{"2":{"1168":1}}],["一旦做完",{"2":{"1138":1}}],["一旦数据通过网络",{"2":{"827":1}}],["一旦序列结束词元被预测",{"2":{"577":4}}],["一旦给定了有效长度",{"2":{"575":1}}],["一旦输出序列生成此词元",{"2":{"572":1}}],["一旦输出序列包含了",{"2":{"513":1}}],["一旦我们获得了平均值和方差的估计值",{"2":{"1180":1}}],["一旦我们知道输入维数是20",{"2":{"418":1}}],["一旦我们规划整个决策系统",{"2":{"201":1}}],["一旦我们训练了它",{"2":{"195":1}}],["一旦我们有了损失函数",{"2":{"98":1}}],["一旦模型开始根据鞋类做出决定",{"2":{"179":1}}],["一组研究人员通过在随机标记的图像上训练深度网络",{"2":{"169":1}}],["一些如下的标准惯例",{"2":{"1143":1}}],["一些梯度下降算法之外的选择",{"2":{"1109":1}}],["一些这方面的证据",{"2":{"1098":1}}],["一些锚框将彼此重叠",{"2":{"912":1}}],["一些intel",{"2":{"814":1}}],["一些专用于处理整数指令",{"2":{"808":1}}],["一些专家报告说面罩的功效是不确定的",{"2":{"660":1}}],["一些专业的注释员会检查每一篇在pubmed中被索引的文章",{"2":{"292":1}}],["一些词元没有相关的观测值",{"2":{"538":1}}],["一些作者对批量规范化的成功提出了另一种解释",{"2":{"475":1}}],["一些差异是由于两个特征之外的几个因素造成的",{"2":{"290":1}}],["一些数据完全丢失了",{"2":{"208":1}}],["一些研究人员在测试时使用暂退法",{"2":{"171":1}}],["一些神经元",{"2":{"170":1}}],["一些通道专门识别边缘",{"2":{"158":1}}],["一些自动取款机仍在运行yann",{"2":{"135":1}}],["一半在底部",{"2":{"141":1}}],["一般组件通常存放在components文件夹",{"2":{"1475":1}}],["一般的高斯分布模型尝试的是去同时抓住两个特征的偏差",{"2":{"1184":1}}],["一般的高斯分布模型可能不能很好地识别异常数据",{"2":{"1184":1}}],["一般的强化学习问题是一个非常普遍的问题",{"2":{"298":1}}],["一般会使用一些正则化方法来防止过拟合",{"2":{"1133":1}}],["一般就直接用",{"2":{"1090":1}}],["一般用",{"2":{"1076":1}}],["一般我们用1索引向量",{"2":{"1072":1}}],["一般房子的价格会记到美分",{"2":{"1060":1}}],["一般包括以下步骤",{"2":{"817":1}}],["一般每个通道有两个物理存储体",{"2":{"802":1}}],["一般来说",{"2":{"82":1,"232":1,"260":1,"284":1,"298":1,"334":1,"369":1,"448":1,"833":1,"920":1,"990":1}}],["一般而言较大值的β是可取的",{"2":{"95":1}}],["一般而言",{"2":{"26":1}}],["一方面是不同的互连方式的带宽存在极大的区别",{"2":{"840":1}}],["一方面原因",{"2":{"816":1}}],["一方面",{"2":{"65":1,"73":1,"165":1,"460":1,"643":1,"656":1,"718":1,"731":1,"742":1,"802":1,"810":1,"852":1,"1028":1}}],["一种是y等于1的情况",{"2":{"1143":1}}],["一种是当use",{"2":{"501":1}}],["一种基于正规方程",{"2":{"1116":1}}],["一种基于梯度下降",{"2":{"1116":1}}],["一种可能的表达方式为",{"2":{"1063":1}}],["一种可能的方法是首先识别100把普通椅子",{"2":{"869":1}}],["一种学习算法已经学会如何读你信封",{"2":{"1058":1}}],["一种自然的方法是将它出现的次数除以投掷的总次数",{"2":{"1026":1}}],["一种连接多个设备的方式",{"2":{"812":1}}],["一种专用总线",{"2":{"812":1}}],["一种选择是通信和计算交错进行",{"2":{"801":1}}],["一种能够更新模型以提高模型预测质量的方法",{"2":{"610":1}}],["一种模型质量的度量方式",{"2":{"610":1}}],["一种方法是计算f1",{"2":{"1140":1}}],["一种方法是我们利用很多汽车的图片和很多非汽车的图片",{"2":{"1097":1}}],["一种方法是用取hessian的绝对值来修正",{"2":{"59":1}}],["一种方案便是densenet",{"2":{"479":1}}],["一种常用的方法是通过移动平均估算整个训练数据集的样本均值和方差",{"2":{"471":1}}],["一种常见的去噪方法是全变分去噪",{"2":{"924":1}}],["一种常见的描述方式是",{"2":{"804":1}}],["一种常见的策略是执行某种形式的拉普拉斯平滑",{"2":{"316":1}}],["一种常见的问题来自不均衡的数据集",{"2":{"284":1}}],["一种前向传播函数",{"2":{"424":1}}],["一种将块逐个追加到列表中的函数",{"2":{"424":1}}],["一种",{"2":{"316":1}}],["一种简单的方法是通过线性函数",{"2":{"270":1}}],["一种想法是以一种无偏向",{"2":{"170":1}}],["一种至少近似地满足约束优化问题的方法是采用拉格朗日函数l",{"2":{"49":1}}],["一维卷积",{"0":{"699":1}}],["一维卷积神经网络可以处理文本中的局部特征",{"2":{"698":1,"705":1}}],["一维中的梯度下降给我们很好的启发",{"2":{"54":1}}],["一维梯度下降",{"0":{"54":1},"1":{"55":1,"56":1}}],["一个对",{"2":{"1542":1}}],["一个对抗性的设置",{"2":{"297":1}}],["一个漂亮",{"2":{"1528":1}}],["一个包含上述内容的数组",{"2":{"1461":1}}],["一个proxy的实例对象",{"2":{"1456":1}}],["一个refimpl的实例对象",{"2":{"1455":1}}],["一个",{"2":{"1209":1,"1381":1}}],["一个特征向量中可能会包含如",{"2":{"1178":1}}],["一个固定的数据集",{"2":{"1168":1}}],["一个算法来从中学习的时候来模型化问题在线学习算法指的是对数据流而非离线的静态数据集的学习",{"2":{"1168":1}}],["一个常见错误使用主要成分分析的情况是",{"2":{"1162":1}}],["一个常见的问题是一些异常的数据可能也会有较高的p",{"2":{"1183":1}}],["一个常见的功能是它们能够执行单指令多数据",{"2":{"809":1}}],["一个常见的假设是虽然特定值xt可能会改变",{"2":{"347":1}}],["一个常见的技巧是切换到对数空间",{"2":{"241":1}}],["一个簇中只包含一个类别的样本",{"2":{"1154":1}}],["一个能够找到我圈出的这些点集的算法",{"2":{"1150":1}}],["一个非常大的值",{"2":{"1143":1}}],["一个人类专家看到了特征值",{"2":{"1141":1}}],["一个人在说话",{"2":{"658":1}}],["一个相对",{"2":{"1112":1}}],["一个训练实例",{"2":{"1099":1}}],["一个灰度分布图",{"2":{"1091":1}}],["一个5",{"2":{"1091":1}}],["一个平均值为0的高斯分布",{"2":{"1088":1}}],["一个被称为pinv",{"2":{"1086":1}}],["一个dna微观数据的例子",{"2":{"1061":1}}],["一个连续的值",{"2":{"1060":1}}],["一个学生从波特兰俄勒冈州的研究所收集了一些房价的数据",{"2":{"1060":1}}],["一个学生在模拟考试中的分数",{"2":{"286":1}}],["一个程序被认为能从经验e中学习",{"2":{"1059":1}}],["一个随机变量x的期望",{"2":{"1036":1}}],["一个张量可以通过sum和mean沿指定的轴降低维度",{"2":{"1003":1}}],["一个与求和相关的量是平均值",{"2":{"995":1}}],["一个n维向量x=",{"2":{"983":1}}],["一个新的标量变量",{"2":{"975":1}}],["一个较接近顶部的多尺度特征块是用于检测较大目标的",{"2":{"959":1}}],["一个覆盖以黑色为主的嘴和眼睛",{"2":{"944":1}}],["一个面积为原始面积10",{"2":{"879":1}}],["一个显而易见的解决方案是收集更多的数据",{"2":{"869":1}}],["一个预测好的边界框则根据其中某个带有预测偏移量的锚框而生成",{"2":{"854":1}}],["一个例子",{"0":{"853":1}}],["一个是使用这其中任何一个算法",{"2":{"1111":1}}],["一个是求和函数",{"2":{"1090":1}}],["一个是所谓的伪逆",{"2":{"1086":1}}],["一个是与锚框中目标检测的类别",{"2":{"855":1}}],["一个是执行模型计算所需要的程序的json描述文件",{"2":{"821":1}}],["一个是大的二进制参数文件",{"2":{"821":1}}],["一个是可训练权重",{"2":{"702":1}}],["一个网络包从旧金山到阿姆斯特丹的往返旅行需要多长时间",{"2":{"815":1}}],["一个企业级硬盘正在以10000转",{"2":{"815":1}}],["一个专为图深度学习而设计的库",{"2":{"811":1}}],["一个或多个以太网连接",{"2":{"801":1}}],["一个处理器",{"2":{"801":1}}],["一个好的学习问题定义如下",{"2":{"1059":1}}],["一个好的设计可以很容易地在性能上造就数量级的差异",{"2":{"800":1}}],["一个好的语言模型能够用高度准确的词元来预测我们接下来会看到什么",{"2":{"342":1}}],["一个主要原因是独热向量不能准确表达不同词之间的相似度",{"2":{"781":1}}],["一个bert输入序列可以包括一个文本序列或两个文本序列",{"2":{"734":1}}],["一个序列中的所有词元",{"2":{"675":1}}],["一个女人在跳舞",{"2":{"658":1}}],["一个女人在吃肉",{"2":{"658":1}}],["一个女人在吃东西",{"2":{"658":1}}],["一个纳特是1log⁡",{"2":{"650":1}}],["一个标量函数关于向量x的梯度是向量",{"2":{"974":1}}],["一个标量",{"2":{"599":1}}],["一个词元接着一个词元地生成翻译后的序列作为输出",{"2":{"532":1}}],["一个名叫googlenet",{"2":{"486":1}}],["一个稠密块由多个卷积块组成",{"2":{"480":1}}],["一个重大突破出现了",{"2":{"457":1}}],["一个典型的错误如下",{"2":{"452":1}}],["一个块可以由许多块组成",{"2":{"427":1}}],["一个块可以由许多层组成",{"2":{"427":1}}],["一个tuple",{"2":{"424":1}}],["一个单层本身就是模型",{"2":{"422":1}}],["一个拥有两个全连接层的多层感知机",{"2":{"350":1}}],["一个经典方法是使用历史观测来预测下一个未来观测",{"2":{"347":1}}],["一个文本标题",{"2":{"345":1}}],["一个国外的视频网站",{"2":{"345":1}}],["一个更好的语言模型应该能让我们更准确地预测下一个词元",{"2":{"342":1}}],["一个更紧迫的问题是人工智能在日常生活中的应用",{"2":{"301":1}}],["一个简单的效果",{"0":{"1445":1}}],["一个简单的例子",{"0":{"974":1}}],["一个简单的方法是总是用一个特殊的",{"2":{"736":1}}],["一个简单的线性项和一个复杂的非线性项",{"2":{"479":1}}],["一个简单的多层感知机",{"2":{"350":4}}],["一个简单的解决办法是",{"2":{"350":1}}],["一个简单的循环神经网络语言模型包括输入编码",{"2":{"336":1}}],["一个简单的问题",{"0":{"67":1}}],["一个流行的替代方案是通过将梯度g投影回给定半径",{"2":{"334":1}}],["一个init",{"2":{"332":1}}],["一个四元语法需要存储多少个词频和相邻多词频率",{"2":{"323":1}}],["一个理想的语言模型就能够基于模型本身生成自然文本",{"2":{"315":1}}],["一个任务可以是继续预测2",{"2":{"305":1}}],["一个使用时差强化学习的五子棋游戏程序",{"2":{"301":1}}],["一个多层感知机",{"2":{"675":1,"676":1}}],["一个多世纪以来",{"2":{"299":1}}],["一个多变量凸函数的总期望值",{"2":{"51":1}}],["一个清洁机器人发现自己被困在一个许多相同的壁橱的房子里",{"2":{"298":1}}],["一个清醒的现实是",{"2":{"180":1}}],["一个球的运动轨迹可以用球的速度",{"2":{"296":1}}],["一个模型和一个合适的损失函数",{"2":{"287":1}}],["一个模型在训练数据集上的性能",{"2":{"286":1}}],["一个模型是否能很好地泛化取决于很多因素",{"2":{"254":1}}],["一个目标函数",{"2":{"283":1}}],["一个勤奋的学生会努力做好练习",{"2":{"252":1}}],["一个矩阵",{"2":{"243":4}}],["一个将下载并解压缩一个zip或tar文件",{"2":{"206":1}}],["一个交易者发现的套利机会很可能在他开始利用它时就消失了",{"2":{"200":1}}],["一个用于",{"2":{"1347":1}}],["一个用于加载voc数据集的自定义数据集",{"2":{"947":3}}],["一个用于加载香蕉检测数据集的自定义数据集",{"2":{"932":3}}],["一个用于表示权重",{"2":{"414":1}}],["一个用于x",{"2":{"95":1}}],["一个用户在新闻网站上的行为将取决于之前向她展示的内容",{"2":{"198":1}}],["一个深度网络",{"2":{"197":1}}],["一个2009年训练的模型不知道一个叫ipad的不知名新设备刚刚上市",{"2":{"187":1}}],["一个240×240像素的图像",{"2":{"140":1}}],["一个关键部件是",{"2":{"186":1}}],["一个稍微复杂的例子",{"2":{"142":1}}],["一个以可视化的训练进展的回调",{"2":{"137":1}}],["一个sigmoid激活函数和平均汇聚层",{"2":{"136":1}}],["一个受欢迎的选择是α=0",{"2":{"114":1}}],["一个问题可能有很多的鞍点",{"2":{"104":1}}],["一个邪恶的精灵在没通知你的情况下复制了你的数据集",{"2":{"83":1}}],["一个cpu有少量寄存器",{"2":{"77":1}}],["一个二次可微函数是凸函数",{"2":{"51":1}}],["一个圆和一个菱形",{"2":{"50":1}}],["一个有效的解决方法是将gt2−st−1替换为gt2⊙sgn⁡",{"2":{"35":1}}],["实践优先",{"2":{"1548":1}}],["实践为主",{"2":{"1436":1}}],["实践中真实世界的数据集通常要复杂得多",{"2":{"933":1}}],["实践中",{"2":{"854":1}}],["实践中的暂退法",{"0":{"171":1}}],["实用工具类型",{"2":{"1434":1}}],["实用技巧",{"0":{"1336":1}}],["实质上我们要将这替换为cost1",{"2":{"1143":1}}],["实在不知道这些步骤",{"2":{"1122":1}}],["实数标量的空间",{"2":{"989":1}}],["实线箭头方向",{"2":{"917":1}}],["实战手记",{"2":{"1546":1}}],["实战项目和经验心得",{"2":{"1305":1}}],["实战",{"0":{"887":1},"1":{"888":1,"889":1,"890":1,"891":1,"892":1,"893":1,"894":1,"895":1,"896":1,"897":1,"898":1}}],["实战kaggle比赛",{"0":{"205":1,"899":1},"1":{"206":1,"207":1,"208":1,"209":1,"210":1,"211":1,"212":1,"213":1,"214":1,"215":1,"900":1,"901":1,"902":1,"903":1,"904":1,"905":1,"906":1,"907":1,"908":1,"909":1,"910":1}}],["实例",{"2":{"1525":1}}],["实例方法",{"2":{"1525":1}}],["实例分割不仅需要区分语义",{"2":{"944":1}}],["实例分割也叫同时检测并分割",{"2":{"944":1}}],["实例数",{"2":{"883":3}}],["实例化一个sgd实例",{"2":{"594":1}}],["实例化一个带有bahdanau注意力的编码器和解码器",{"2":{"376":1}}],["实例化解码器",{"2":{"574":1}}],["实例化与更新门",{"2":{"544":1}}],["实例化了原始多层感知机模型的一个备份",{"2":{"442":1}}],["实例化多层感知机的层",{"2":{"423":1}}],["实例化网络",{"0":{"418":1}}],["实验室玩具",{"2":{"1051":1}}],["实验中使用了交叉熵损失",{"2":{"966":1}}],["实验中",{"2":{"920":1}}],["实验中为5个",{"2":{"775":1}}],["实验会发生什么",{"2":{"111":1}}],["实施强化学习系统",{"2":{"179":1}}],["实际值",{"2":{"1139":1}}],["实际为假",{"2":{"1139":2}}],["实际为真",{"2":{"1139":2}}],["实际操作的完整流程",{"2":{"1050":1}}],["实际模型",{"2":{"559":1}}],["实际中",{"2":{"501":1,"973":1}}],["实际输出为",{"2":{"369":1}}],["实际上与逻辑回归",{"2":{"1148":1}}],["实际上与简单的树算法相比其唯一的区别是同步路径稍微精细一些",{"2":{"842":1}}],["实际上有恶性肿瘤的病人的百分比",{"2":{"1139":1,"1140":1}}],["实际上你可以想出很多种方法来改进这个算法的性能",{"2":{"1129":1}}],["实际上你最后通常会花费很多天",{"2":{"1111":1}}],["实际上我们可以创建一个",{"2":{"1112":1}}],["实际上就是这个概率值",{"2":{"1110":2}}],["实际上也是一样的效果",{"2":{"1092":1}}],["实际上对于那些算法",{"2":{"1085":1}}],["实际上在数据量较大的情况下",{"2":{"1069":1}}],["实际上唯一的区别是我们指定了层的数量",{"2":{"528":1}}],["实际上是在做什么",{"2":{"1143":1}}],["实际上是一个双样本测试",{"2":{"300":1}}],["实际上是以下两点导致的",{"2":{"300":1}}],["实际上会影响环境",{"2":{"297":1}}],["实际上",{"2":{"117":1,"158":1,"269":1,"270":1,"312":1,"357":1,"515":1,"588":1,"747":1,"821":1,"1059":2,"1061":1,"1069":1,"1086":1,"1089":1,"1092":1,"1093":1,"1110":1,"1111":2,"1137":1,"1145":1}}],["实际上比线性慢一些",{"2":{"27":1}}],["实际实验",{"0":{"90":1},"1":{"91":1,"92":1}}],["实现防抖效果",{"2":{"1520":1}}],["实现祖孙组件直接通信",{"2":{"1503":1}}],["实现细节",{"2":{"1431":2}}],["实现接口",{"2":{"1419":1}}],["实现服务发现和负载均衡",{"2":{"1377":1}}],["实现不同变量组合的并行",{"2":{"1313":1}}],["实现串行依赖",{"2":{"1310":1}}],["实现水平扩展",{"2":{"1210":1}}],["实现出很多版本的学习算法",{"2":{"1138":1}}],["实现alvinn功能的第一步",{"2":{"1127":1}}],["实现注意",{"0":{"1123":1},"2":{"1193":1}}],["实现方法是",{"2":{"1067":1}}],["实现梯度下降算法的微妙之处是",{"2":{"1067":1}}],["实现这个得要多么的复杂",{"2":{"1061":1}}],["实现这个目标最好的方法是通过让机器试着模仿人的大脑学习我会在这门课中介绍一点这方面的内容",{"2":{"1058":1}}],["实现这个想法任重而道远",{"2":{"1058":1}}],["实现这一惩罚最方便的方法是对所有项求平方后并将它们求和",{"2":{"274":1}}],["实现本地集成",{"2":{"1047":1}}],["实现基本的转置卷积运算",{"2":{"968":1}}],["实现的方式更简单",{"2":{"1093":1}}],["实现的",{"2":{"861":1}}],["实现以下multibox",{"2":{"852":1}}],["实现分布式多gpu训练所需要的步骤绝非易事",{"2":{"844":1}}],["实现模型在多gpu下测试精度的计算",{"2":{"839":1}}],["实现交叉熵损失函数",{"2":{"633":1}}],["实现softmax回归模型",{"2":{"632":1}}],["实现softmax回归比较复杂",{"2":{"627":1}}],["实现softmax",{"2":{"631":1}}],["实现多层循环神经网络所需的许多逻辑细节在高级api中都是现成的",{"2":{"528":1}}],["实现densenet论文",{"2":{"485":1}}],["实现起来非常简单",{"2":{"479":1}}],["实现编码器中的一个层",{"2":{"407":1}}],["实现带有bahdanau注意力的循环神经网络解码器",{"2":{"375":1}}],["实现循环神经网络编码器",{"2":{"375":1,"573":1}}],["实现了这样的掩蔽softmax操作",{"2":{"368":1}}],["实现文本词元化",{"2":{"364":1}}],["实现下面的训练代码的方式与前面几节",{"2":{"350":1}}],["实现很多任务的自动化并不再屈从于人类所能考虑到的逻辑",{"2":{"281":1}}],["实现我们的模型",{"2":{"219":1}}],["实现relu激活函数",{"2":{"218":1}}],["实现几个函数来方便下载数据",{"2":{"206":1}}],["实现协变量偏移纠正",{"2":{"203":1}}],["实现一种选择的方法",{"2":{"1191":1}}],["实现一个更高效的allreduce函数用于在不同的gpu上聚合不同的参数",{"2":{"839":1}}],["实现一个能够基于时间序列进行预测而不是基于字符序列进行预测的长短期记忆网络模型",{"2":{"563":1}}],["实现一个函数",{"2":{"428":1}}],["实现一个函数来评估模型在给定数据集上的损失",{"2":{"263":1}}],["实现一个块",{"2":{"428":1}}],["实现一个具有单隐藏层的多层感知机",{"2":{"217":1}}],["实现一个协变量偏移检测器",{"2":{"203":1}}],["实现一下多输入通道互相关运算",{"2":{"120":1}}],["实现汇聚层的前向传播",{"2":{"146":1}}],["实现二维卷积层",{"2":{"127":1}}],["实现该算法并用交叉验证集数据测试这个算法",{"2":{"1138":1}}],["实现该算法",{"2":{"64":1}}],["实现它的方式太昂贵了",{"2":{"62":1}}],["实现",{"0":{"34":1,"382":1},"2":{"1362":1,"1500":1}}],["前后端",{"2":{"1547":1}}],["前后端开发笔记",{"2":{"1546":1}}],["前序知识",{"2":{"1500":1}}],["前三部电影是爱情片",{"2":{"1187":1}}],["前三条路径使用窗口大小为1×1",{"2":{"487":1}}],["前方的双车道将进入其视线",{"2":{"1127":1}}],["前阵子",{"2":{"1060":1}}],["前两者需要对数据传输过程进行严格编排",{"2":{"838":1}}],["前两个维度上的值不影响输出",{"2":{"912":3}}],["前两个卷积层后不使用汇聚层来减小输入的高和宽",{"2":{"461":1}}],["前两个轴与像素的空间位置有关",{"2":{"158":1}}],["前提是a=a已发生",{"2":{"1031":1}}],["前提是这些指令可以独立执行",{"2":{"808":1}}],["前提是λ",{"2":{"655":1}}],["前提和假设形成一对文本序列",{"2":{"687":1}}],["前提和假设之间的词元对齐可以通过注意力机制灵活地完成",{"2":{"673":1}}],["前提和假设之间的关系包括蕴涵关系",{"2":{"670":1}}],["前提和假设",{"2":{"667":1}}],["前提",{"2":{"665":3,"667":1,"670":1}}],["前一章我们提及到一些自然语言处理应用",{"2":{"663":1}}],["前一章中我们介绍了循环神经网络的基础知识",{"2":{"550":1}}],["前一时间步的隐状态为ht−1∈rn×h",{"2":{"553":1}}],["前一节我们描述了过拟合的问题",{"2":{"269":1}}],["前向推断返回编码后的bert表示encoded",{"2":{"738":1}}],["前向",{"2":{"524":1}}],["前向和反向隐状态的更新如下",{"2":{"521":1}}],["前向和后向递归都允许我们对t个隐变量在o",{"2":{"519":1}}],["前向与反向传播及相关的计算图",{"2":{"306":1}}],["前向传播算法",{"2":{"1121":1,"1122":1}}],["前向传播相当简单",{"2":{"307":1}}],["前向传播和反向传播是相互依赖的",{"2":{"166":1}}],["前向传播和反向传播相互依赖",{"2":{"165":1}}],["前向传播在神经网络定义的计算图中按顺序计算和存储中间变量",{"2":{"166":1}}],["前向传播计算图",{"0":{"163":1}}],["前向传播",{"0":{"161":1,"162":1},"1":{"162":1,"163":1,"164":1,"165":1,"166":1,"167":1},"2":{"162":1,"422":2,"595":1,"726":3}}],["前向传播函数调用corr2d函数并添加偏置",{"2":{"127":1}}],["前向传播的计算复杂度是多少",{"2":{"124":1}}],["前向传播的计算成本",{"2":{"124":1}}],["前面有负号",{"2":{"1143":1}}],["前面的一些章节介绍了如何在只有6万张图像的fashion",{"2":{"869":1}}],["前面的章节",{"2":{"857":1}}],["前面的内容将机器学习介绍为",{"2":{"286":1}}],["前面我们学习了如何在文本序列中表示词元",{"2":{"663":1}}],["前面我们学习了许多机器学习的实际应用",{"2":{"179":1}}],["前面唤醒词识别的例子",{"2":{"288":1}}],["前四个和最后两个特征",{"2":{"208":1}}],["前者可以应用于深度学习中的优化问题",{"2":{"985":1}}],["前者包含除输出层以外的模型的所有层",{"2":{"873":1}}],["前者能够编码双向上下文来表示单词",{"2":{"739":1}}],["前者有1",{"2":{"726":1}}],["前者支持隐状态的门控",{"2":{"539":1}}],["前者定义如何连接输入和输出",{"2":{"479":1}}],["前者基于突出性",{"2":{"358":1}}],["前者",{"2":{"345":1}}],["前者关注的功能强大的模型",{"2":{"285":1}}],["前者主要关注的是最小化目标",{"2":{"99":1}}],["前者在实践中效果略好一些",{"2":{"33":1}}],["前端性能优化清单",{"2":{"1547":1}}],["前端能写",{"2":{"1542":1}}],["前端都能带给你无穷的乐趣和挑战",{"2":{"1541":1}}],["前端就是最适合你的舞台",{"2":{"1537":1}}],["前端开发不仅是技术",{"2":{"1541":1}}],["前端开发的核心三剑客",{"0":{"1539":1}}],["前端开发让你把脑洞变成现实",{"2":{"1536":1}}],["前端开发就是让网页",{"2":{"1533":1}}],["前端开发",{"0":{"1532":1},"1":{"1533":1,"1534":1,"1535":1,"1536":1,"1537":1,"1538":1,"1539":1,"1540":1,"1541":1},"2":{"1532":1}}],["前端静态资源服务器",{"2":{"1372":1}}],["前端加载指令并尝试预测将采用哪条路径",{"2":{"808":1}}],["前端命令后端将计算任务y",{"2":{"792":1}}],["前端",{"2":{"12":1,"1056":1,"1347":1}}],["有框架很重要",{"2":{"1539":1}}],["有唯一",{"2":{"1321":1}}],["有大量教程",{"2":{"1300":1}}],["有大量的文献解释如何得出函数l",{"2":{"48":1}}],["有算法可以为你自动学习一套好的特征",{"2":{"1187":1}}],["有足够多的正向类实例",{"2":{"1182":1}}],["有20台异常引擎的数据",{"2":{"1181":1}}],["有2个输出通道数为10的",{"2":{"480":1}}],["有朝一日",{"2":{"1176":1}}],["有几个不同的的原因使你可能想要做降维",{"2":{"1156":1}}],["有几种方法可以在gpu上存储张量",{"2":{"448":1}}],["有几种方法可以做到这一点",{"2":{"431":1}}],["有3个卧室等等",{"2":{"1089":1}}],["有3个卧室",{"2":{"1089":1}}],["有3种可能的输出",{"2":{"677":3}}],["有m等于10个的训练样本也有n等于100的特征数量",{"2":{"1086":1}}],["有ai=ia=a",{"2":{"1076":1}}],["有点抽象",{"2":{"1064":1}}],["有个宴会房间里满是人",{"2":{"1061":1}}],["有个巧妙的解决方案",{"2":{"519":1}}],["有用的理论",{"2":{"1061":1}}],["有趣",{"2":{"1061":1}}],["有趣的是",{"2":{"182":1,"455":1,"551":1}}],["有机器人",{"2":{"1058":1}}],["有很多的网站或系统试图推荐新产品给用户",{"2":{"1187":1}}],["有很多例子可以说明",{"2":{"1093":1}}],["有很多基础的知识",{"2":{"1058":1}}],["有很高的精度",{"2":{"185":1}}],["有完整的课程",{"2":{"1025":1}}],["有120种犬类",{"2":{"900":1}}],["有10",{"2":{"736":1}}],["有热狗",{"2":{"872":1}}],["有多种方法可以在多个gpu上拆分深度网络的训练",{"2":{"838":1}}],["有多少",{"2":{"290":1,"291":1}}],["有两个元素",{"2":{"1111":1}}],["有两个函数可以求解矩阵的逆",{"2":{"1086":1}}],["有两个gpu时",{"2":{"836":1}}],["有两个特定的设计决定",{"2":{"572":1}}],["有torchscript",{"2":{"820":1}}],["有没有其它相关的产品",{"2":{"1191":1}}],["有没有其他方法来设计解码器的输出层",{"2":{"580":1}}],["有没有可能将这两种编程模式的优点结合起来",{"2":{"818":1}}],["有六个链路",{"2":{"812":1}}],["有理由认为gpu制造商的财富由于深度学习而显著增加",{"2":{"811":1}}],["有实际限制的另一个原因",{"2":{"810":1}}],["有助于我们开发更高效的程序",{"2":{"789":1}}],["有助于减轻过拟合的危险",{"2":{"300":1}}],["有鉴于此",{"2":{"743":1,"886":1}}],["有λ−1realsoftmax",{"2":{"655":1}}],["有何优劣呢",{"2":{"531":1}}],["有另一种方法来减少显存消耗吗",{"2":{"485":1}}],["有o",{"2":{"397":2}}],["有什么问题",{"2":{"655":1}}],["有什么方法能改变上下文变量呢",{"2":{"373":1}}],["有什么错误消息",{"2":{"133":1}}],["有价值和稀缺的资源",{"2":{"358":1}}],["有价值的且稀缺的商品",{"2":{"354":1}}],["有选择地引导注意力的焦点",{"2":{"355":1}}],["有限的状态数",{"2":{"519":1}}],["有限的",{"2":{"354":1}}],["有隐状态的循环神经网络",{"0":{"340":1}}],["有九个是由两个停用词组成的",{"2":{"318":1}}],["有着悠远而持久的历史",{"2":{"299":1}}],["有人修改了fullname",{"2":{"1460":1}}],["有人认为得到一个非常小的训练误差一定是一件好事",{"2":{"1130":1}}],["有人一直心存疑虑",{"2":{"297":1}}],["有人会认为初始化方案是理所当然的",{"2":{"240":1}}],["有利于研究人员对文献进行详尽的审查",{"2":{"292":1}}],["有丢失信息的风险",{"2":{"284":1}}],["有许多",{"2":{"1156":1}}],["有许多好的软件库",{"2":{"1148":1}}],["有许多操作用于强制python等待完成",{"2":{"791":1}}],["有许多不同风格的深度循环神经网络",{"2":{"530":1}}],["有许多不同的方法可以构建循环神经网络",{"2":{"340":1}}],["有许多方法都可以用",{"2":{"191":1}}],["有许多证据表明这种速率表现良好",{"2":{"114":1}}],["有问题的例子是人脸充满了整个图像的特写镜头",{"2":{"188":1}}],["有哪些优点和缺点",{"2":{"167":1}}],["有些矩阵可逆",{"2":{"1086":1}}],["有些同学可能会根据你使用的编程语言",{"2":{"1092":1}}],["有些同学曾经问过我",{"2":{"1086":1}}],["有些同学之前可能已经学过高等线性代数",{"2":{"1069":1}}],["有些人不能直接操作",{"2":{"1058":1}}],["有些任务",{"2":{"734":1}}],["有些文献认为记忆元是隐状态的一种特殊类型",{"2":{"552":1}}],["有些文本数据很简短",{"2":{"284":1}}],["有些比较简单",{"2":{"431":1}}],["有些块不需要任何参数",{"2":{"422":1}}],["有些电影因为其极度糟糕只能成为小众电影",{"2":{"345":1}}],["有些分类问题很适合于二项分类或多项分类",{"2":{"292":1}}],["有些目标",{"2":{"286":1}}],["有些目标函数",{"2":{"286":1}}],["有些则长篇大论",{"2":{"284":1}}],["有些违背独立同分布假设的行为肯定会带来麻烦",{"2":{"253":1}}],["有些读者可能会对我们的代码能运行感到惊讶",{"2":{"417":1}}],["有些读者可能会反对这个观点",{"2":{"151":1}}],["有些读者可能在用fashion",{"2":{"251":1}}],["有些研究人员短视地专注于预处理步骤",{"2":{"207":1}}],["有些算法可以检测这种偏移",{"2":{"180":1}}],["有些在技术上很困难",{"2":{"179":1}}],["有些解决方案很简单",{"2":{"179":1}}],["有些方向的进展比其他方向慢得多",{"2":{"86":1}}],["有时带标签的数据",{"2":{"1176":1}}],["有时他们会走掉",{"2":{"1168":1}}],["有时他们甚至已经为此花了六个月之久",{"2":{"1059":1}}],["有时可能有几个不同的工程团队",{"2":{"1156":1}}],["有时它确实不清楚这是否是最好的算法",{"2":{"1148":1}}],["有时这个方法也被称为",{"2":{"1112":1}}],["有时这是有道理的",{"2":{"230":1}}],["有时也有其他类型的梯度下降法",{"2":{"1069":1}}],["有时也称为批量梯度下降",{"2":{"1069":1}}],["有时也称为配分函数",{"2":{"631":1}}],["有时也被称为平方误差代价函数",{"2":{"1064":1}}],["有时在调用函数来",{"2":{"996":1}}],["有时使用不同大小的卷积核组合是有利的",{"2":{"486":1}}],["有时甚至以低于1ghz的时钟频率运行",{"2":{"457":1}}],["有时上下文可能是gpu",{"2":{"445":1}}],["有时环境可能是gpu",{"2":{"445":2}}],["有时我们需要尝试不同的模型",{"2":{"1138":1}}],["有时我们需要曲线来适应我们的数据",{"2":{"1084":1}}],["有时我们使用几十或几百个特征量来计算线性归回",{"2":{"1093":1}}],["有时我们想通过从某个特定的概率分布中随机采样来得到张量中每个元素的值",{"2":{"1017":1}}],["有时我们希望保存训练的模型",{"2":{"440":1}}],["有时我们希望在多个层间共享参数",{"2":{"437":1}}],["有时我们希望提取参数",{"2":{"429":1}}],["有时我们可能希望合并既不是上一层的结果也不是可更新参数的项",{"2":{"425":1}}],["有时我们会遇到或要自己发明一个现在在深度学习框架中还不存在的层",{"2":{"412":1}}],["有时梯度可能很大",{"2":{"334":1}}],["有时仍然被用来解读机器学习算法",{"2":{"299":1}}],["有时任务内的关系可能太复杂",{"2":{"281":1}}],["有时任务可能遵循一种随着时间推移而变化的模式",{"2":{"281":1}}],["有时称为执行器",{"2":{"298":1}}],["有时称为自由度",{"2":{"254":1}}],["有时称为汇聚窗口",{"2":{"146":1}}],["有时候确实需要花很多时间来理解和实现",{"2":{"1129":1}}],["有时候仍然觉得这是一个难以理解的算法",{"2":{"1122":1}}],["有时候可能因为这个算法的名字中出现了",{"2":{"1106":1}}],["有时候",{"2":{"924":1}}],["有时候不同的设备提供了不同的计算能力",{"2":{"830":2}}],["有时候我们即使轻微违背独立同分布假设",{"2":{"253":1}}],["有时候为了高效计算或是缩减采样次数",{"2":{"142":1}}],["有时一组超参数的训练误差可能非常低",{"2":{"212":1}}],["有时模型的部署本身就是扰乱数据分布的催化剂",{"2":{"179":1}}],["有时",{"2":{"140":2,"179":1,"255":1,"289":3,"293":1,"345":1,"436":1,"449":1,"976":1,"1017":1,"1018":1}}],["有时adam算法可能由于方差控制不良而发散",{"2":{"32":1}}],["有效的深度学习框架的开源使得这一点的设计和实现变得非常容易",{"2":{"303":1}}],["有效梯度数为11−β",{"2":{"96":1}}],["有效样本权重",{"0":{"89":1}}],["有最小化器为x∗=−q−1c",{"2":{"94":1}}],["有最小值",{"2":{"87":1}}],["有了算法的评估和误差度量值",{"2":{"1139":1}}],["有了经验e后",{"2":{"1059":1}}],["有了y",{"2":{"633":1}}],["有了这些概念",{"2":{"1111":1}}],["有了这些算法",{"2":{"1111":1}}],["有了这个公理系统",{"2":{"1027":1}}],["有了这个梯度",{"2":{"601":1}}],["有了这一能力",{"2":{"282":1}}],["有了该技术将更加方便",{"2":{"417":1}}],["有了组成transformer编码器的基础组件",{"2":{"407":1}}],["有了注意力机制之后",{"2":{"395":1}}],["有了隐状态后",{"2":{"340":1}}],["有了激活函数",{"2":{"232":1}}],["有了足够大的数据集和合理设置的超参数",{"2":{"212":1}}],["有了如何处理分布变化的知识",{"2":{"194":1}}],["有了每台服务器8个gpu和16台服务器",{"2":{"77":1}}],["有了正确的估计",{"2":{"33":1}}],["有一定学习曲线",{"2":{"1530":1}}],["有一件重要的事情要注意",{"2":{"1139":1}}],["有一系列简单的方法能让你事半功倍",{"2":{"1129":1}}],["有一系列强大的算法表现良好",{"2":{"103":1}}],["有一天能制造出真正的智能机器",{"2":{"1098":1}}],["有一个特征向量x",{"2":{"1191":1}}],["有一个可能会谈及的方法叫作",{"2":{"1154":1}}],["有一个缺点是",{"2":{"1148":1}}],["有一个非常理想的库用于实现这些先进的优化算法",{"2":{"1111":1}}],["有一个",{"2":{"1093":1}}],["有一个局部最小值x=1",{"2":{"44":1}}],["有一半的时间它们确实是标签为",{"2":{"737":1}}],["有一种矩阵起着特殊的作用",{"2":{"1076":1}}],["有一种机制来控制输入和遗忘",{"2":{"555":1}}],["有一种非常有效的方法可以得到几乎与原始方法一样好的结果",{"2":{"191":1}}],["有一份极其专业的工作和一位极其平庸的老板",{"2":{"296":1}}],["有一些设置",{"2":{"1187":1}}],["有一些实用的属性",{"2":{"994":1}}],["有一些分类任务的变体可以用于寻找层次结构",{"2":{"291":1}}],["有一些观点认为",{"2":{"68":1}}],["有一句古语很好地反映了这个现象",{"2":{"284":1}}],["有关获得更多数据的几种方法",{"2":{"1173":1}}],["有关如何使用给定函数或类的更具体说明",{"2":{"1007":1}}],["有关如何在alphago中实现这一点的说明",{"2":{"300":1}}],["有关dataloader的详细介绍",{"2":{"882":2}}],["有关分布式训练分区的详细描述",{"2":{"832":1}}],["有关分析和证明",{"2":{"62":1}}],["有关更多详细信息",{"2":{"519":1}}],["有关更深入的讨论",{"2":{"77":1}}],["有关",{"2":{"318":1,"608":1}}],["有关每一个类别",{"2":{"295":1}}],["有关详细讨论",{"2":{"116":1}}],["有关详细信息",{"2":{"66":1}}],["有关的研究调查",{"2":{"114":1}}],["有关实例的详细信息",{"2":{"86":1}}],["有关学习率调度的更多实验和更详细讨论",{"2":{"73":1}}],["有如下几方面需要考虑",{"2":{"66":1}}],["有",{"2":{"44":1,"1185":1}}],["有f",{"2":{"44":1}}],["相信",{"2":{"1549":1}}],["相信我",{"2":{"1061":1}}],["相较虚拟机占用更少资源",{"2":{"1354":1}}],["相较于之前我用粉色或者绿色画的决策界",{"2":{"1144":1}}],["相加",{"2":{"844":1}}],["相似",{"2":{"1199":1}}],["相似度",{"2":{"1154":1}}],["相似的词",{"2":{"750":1}}],["相似性得分",{"2":{"658":1}}],["相关的单词wk",{"2":{"744":1}}],["相关但与",{"2":{"744":2}}],["相连",{"2":{"618":1}}],["相应的将会给b比给a更大的权重",{"2":{"1143":1}}],["相应的激活函数之前应用的",{"2":{"473":1}}],["相应地y为负向类的几率为1",{"2":{"1107":1}}],["相应地提高了访问速度",{"2":{"77":1}}],["相应地",{"2":{"33":1,"57":1,"553":1}}],["相同的最优值",{"2":{"1143":1}}],["相同的额外的全连接层将把来自位置i的任何词元的bert表示转换成标量分数si",{"2":{"660":1}}],["相同的训练过程几乎一遍又一遍地出现",{"2":{"605":1}}],["相同的数学符号定义搜索问题",{"2":{"512":1}}],["相同的键",{"2":{"392":4}}],["相同",{"2":{"469":1,"995":3,"998":3}}],["相差很大",{"2":{"387":1}}],["相当于组件中的",{"2":{"1490":1}}],["相当于大脑",{"2":{"1381":1}}],["相当于λ较大",{"2":{"1144":1}}],["相当于",{"2":{"1144":1,"1196":1}}],["相当于是第",{"2":{"1122":1}}],["相当于比特",{"2":{"650":1}}],["相当于最小化负对数似然",{"2":{"646":1}}],["相当于xt和ht−1的拼接",{"2":{"340":1}}],["相当于下一层的输入",{"2":{"176":1}}],["相结合的深度学习",{"2":{"301":1}}],["相比传统的",{"2":{"1050":1}}],["相比主内存实现更高的读取带宽和更低的延迟内存访问",{"2":{"807":1}}],["相比于线性回归算法和逻辑回归算法而言",{"2":{"1122":1}}],["相比于提供工具",{"2":{"1059":1}}],["相比于cpu",{"2":{"457":1}}],["相比于小批量随机梯度下降",{"2":{"91":1}}],["相比从零开始实现的循环神经网络",{"2":{"327":1}}],["相比之下",{"2":{"270":1,"773":1,"1034":1}}],["相比",{"2":{"225":1,"968":1,"1359":1}}],["相对虚拟机",{"2":{"1339":1}}],["相对地",{"2":{"1090":1}}],["相对频率作为估计值",{"2":{"1026":1}}],["相对于使用循环来编码",{"2":{"1100":1}}],["相对于x的梯度是一个包含n个偏导数的向量",{"2":{"983":1}}],["相对于x的瞬时",{"2":{"981":1}}],["相对于3",{"2":{"815":1}}],["相对于一次处理一个样本",{"2":{"644":1}}],["相对位置信息",{"0":{"400":1}}],["相对较新的卷积神经网络架构的完整实现",{"2":{"134":1}}],["相对开销较小",{"2":{"77":1}}],["相反的方程为",{"2":{"1161":1}}],["相反的",{"2":{"1098":1,"1145":1}}],["相反地",{"2":{"818":1,"1143":1,"1189":1}}],["相反对于",{"2":{"500":1}}],["相反",{"2":{"22":1,"26":1,"44":1,"55":1,"84":1,"87":1,"88":1,"100":1,"116":1,"136":1,"146":1,"169":1,"193":1,"240":1,"243":1,"247":1,"281":1,"282":1,"296":1,"460":1,"495":1,"500":1,"542":1,"663":1,"664":1,"800":1,"1025":1,"1027":1,"1060":1}}],["就常用于反向代理",{"2":{"1361":1}}],["就意味着原本数据的偏差有99",{"2":{"1160":1}}],["就被称为聚类算法",{"2":{"1150":1}}],["就等于p",{"2":{"1145":1}}],["就等于5的立方125",{"2":{"1092":1}}],["就类似于就类似于u和和v$",{"2":{"1145":1}}],["就将我的决策界从这条黑线变到这条粉线",{"2":{"1144":1}}],["就用它们来代替",{"2":{"1143":1}}],["就对应于将c",{"2":{"1143":1}}],["就能让支持向量机选择右边的决策界",{"2":{"1145":1}}],["就能将该样本恰当分出",{"2":{"1144":1}}],["就能够给我足够的信息来确定出标签",{"2":{"1141":1}}],["就能很轻松地排除掉很多选择",{"2":{"1129":1}}],["就好像一个黑箱",{"2":{"1122":1}}],["就好了",{"2":{"1090":1}}],["就以多项式理解",{"2":{"1114":1}}],["就出现了这个图",{"2":{"1091":1}}],["就把",{"2":{"1090":1}}],["就相当于ones",{"2":{"1090":1}}],["就包括上面的a",{"2":{"1089":1}}],["就打印出来了",{"2":{"1088":1}}],["就这些内容而言我不知道还有哪所大学会介绍到",{"2":{"1059":1}}],["就是一组运行着",{"2":{"1381":1}}],["就是一个5行4列的矩阵",{"2":{"1191":1}}],["就是一个高斯核函数",{"2":{"1146":1}}],["就是一个从1到10的序列",{"2":{"1092":1}}],["就是一个",{"2":{"1089":1}}],["就是一个1×2的矩阵",{"2":{"1089":1}}],["就是一个数据集",{"2":{"1061":1}}],["就是自动帮你管理这些版本的",{"2":{"1318":1}}],["就是依据一个训练样本和选取的地标得到的判定边界",{"2":{"1146":1}}],["就是极小化参数向量θ范数的平方",{"2":{"1145":1}}],["就是第一项和第二项我们依照惯例使用一个不同的参数称为c",{"2":{"1143":1}}],["就是之前所提到的那条线",{"2":{"1143":1}}],["就是使用一个合适的误差度量值",{"2":{"1139":1}}],["就是根本没有用复杂的系统",{"2":{"1138":1}}],["就是字面意义上的24小时",{"2":{"1138":1}}],["就是汽车所看到的前方的路况图像",{"2":{"1127":1}}],["就是其中一些更高级的优化算法",{"2":{"1111":1}}],["就是",{"2":{"1110":2}}],["就是用它自己减去学习率",{"2":{"1110":1}}],["就是用一个",{"2":{"1093":1}}],["就是关于",{"2":{"1110":1}}],["就是a",{"2":{"1094":1}}],["就是让",{"2":{"1093":1}}],["就是计算不同",{"2":{"1092":1}}],["就是参数θ0=0",{"2":{"1145":1}}],["就是参数",{"2":{"1092":1}}],["就是以e为底",{"2":{"1090":1}}],["就是直接把a和",{"2":{"1089":1}}],["就是把",{"2":{"1089":1}}],["就是这个小线段的长度是负的",{"2":{"1145":1}}],["就是这条粉色的线",{"2":{"1144":1}}],["就是这条紫红色的曲线",{"2":{"1143":1}}],["就是这条刚好与函数曲线相切的这条直线",{"2":{"1068":1}}],["就是这里的这条白亮的区段显示的就是人类驾驶者选择的方向",{"2":{"1127":1}}],["就是这里展示的代码",{"2":{"1061":1}}],["就是这样",{"2":{"1110":1}}],["就是这样一条红色的直线",{"2":{"1068":1}}],["就是建模误差",{"2":{"1064":1}}],["就是那个谷歌新闻的例子",{"2":{"1061":1}}],["就是说你要自动地聚类那些个体到各个类",{"2":{"1061":1}}],["就是它在与一些新的对手比赛时",{"2":{"1059":1}}],["就是下棋",{"2":{"1059":1}}],["就是程序上万次的自我练习的经验而任务t",{"2":{"1059":1}}],["就地操作更改一个张量也会同时更改另一个张量",{"2":{"1022":1}}],["就本书而言",{"2":{"802":1}}],["就目的而言",{"2":{"802":1}}],["就目前而言",{"2":{"254":1}}],["就可以使用这个命令",{"2":{"1088":1}}],["就可以使用nvidia",{"2":{"445":1}}],["就可以开始为准备好的参数同步梯度了",{"2":{"841":1}}],["就可以迫使任何估计也只能缓慢地发生改变",{"2":{"200":1}}],["就越接近圆",{"2":{"980":1}}],["就越高",{"2":{"388":1}}],["就越大",{"2":{"145":1}}],["就质量而言",{"2":{"342":1}}],["就如sequential是block的子类一样",{"2":{"818":1}}],["就如我们在",{"2":{"560":1}}],["就如在门控循环单元中一样",{"2":{"553":1}}],["就如当前时间步下神经网络的状态或记忆",{"2":{"340":1}}],["就如何将毕晓普的想法应用于网络的内部层提出了一个想法",{"2":{"170":1}}],["就足以生成一个有意义的对话",{"2":{"315":1}}],["就很容易得出",{"2":{"307":1}}],["就很难理解文章原始的意思",{"2":{"305":1}}],["就我们今天所知",{"2":{"301":1}}],["就需要分别修改",{"2":{"1448":1}}],["就需要在图像上标记和预测超过200万个锚框",{"2":{"911":1}}],["就需要移动数据来聚合多个加速卡上的梯度",{"2":{"797":1}}],["就需要引入一个额外的1×1卷积层来将输入变换成需要的形状后再做相加运算",{"2":{"501":1}}],["就需要弄清楚这一过程中哪些行为导致了晋升",{"2":{"298":1}}],["就需要",{"2":{"296":1}}],["就滑稽至极了",{"2":{"291":1}}],["就算一些深度学习模型在小数据集上能够工作",{"2":{"284":1}}],["就不是那么熟悉了",{"2":{"1129":1}}],["就不太容易变成那些为寻找一个解决方案花费6个月之久的人们的中一员",{"2":{"1059":1}}],["就不太可能识别出",{"2":{"282":1}}],["就不可能在gpu上评估网络",{"2":{"835":1}}],["就不可能再将我们的多层感知机退化成线性模型",{"2":{"232":1}}],["就不那么复杂",{"2":{"254":1}}],["就像盖房子",{"2":{"1539":1}}],["就像搭积木",{"2":{"1533":1}}],["就像你的用户的品味在缓慢变化",{"2":{"1168":1}}],["就像你朋友想出售的房屋",{"2":{"1063":1}}],["就像我之前提到的",{"2":{"1145":1}}],["就像我们在乳腺癌数据中做的一样",{"2":{"1061":1}}],["就像我们从零开始实现线性回归一样",{"2":{"629":1}}],["就像我们所看到的",{"2":{"616":1}}],["就像我们之前随机初始化全连接层一样",{"2":{"127":1}}],["就像这样的一条灰色区段覆盖着整个区域这些均称的灰色区域",{"2":{"1127":1}}],["就像加强版的梯度下降法",{"2":{"1111":1}}],["就像房子和肿瘤的例子中做的那样",{"2":{"1060":1}}],["就像概率一样",{"2":{"1035":1}}],["就像向量是标量的推广",{"2":{"993":1}}],["就像每个数组都有一个长度一样",{"2":{"991":1}}],["就像只在单个gpu上训练一样",{"2":{"833":1}}],["就像半导体设计师从指定晶体管到逻辑电路再到编写代码一样",{"2":{"421":1}}],["就像使用内置的全连接层一样使用自定义层",{"2":{"414":1}}],["就像",{"2":{"355":2,"573":1,"1040":1,"1042":1,"1392":1}}],["就像一个员工升职一样",{"2":{"298":1}}],["就像在任何其他python数组中一样",{"2":{"1020":1}}],["就像在现实生活中",{"2":{"286":1}}],["就像在动量法中我们需要跟踪一个辅助变量一样",{"2":{"27":1}}],["就像生物神经元",{"2":{"242":1}}],["就像有性生殖会破坏共适应的基因一样",{"2":{"170":1}}],["就会得到这样p",{"2":{"1145":1}}],["就会导致下面的优化问题",{"2":{"1144":1}}],["就会导致过拟合",{"2":{"253":1}}],["就会变得很难甚至是不可能实现",{"2":{"1130":1}}],["就会感觉很奇怪",{"2":{"1106":1}}],["就会触发一个神经元给你的肌肉发送脉冲",{"2":{"1099":1}}],["就会分别算出",{"2":{"1090":1}}],["就会发现有些视频讲述了一个令人称奇的孩子",{"2":{"1098":1}}],["就会发现中央的参数服务器成为了瓶颈",{"2":{"843":1}}],["就会发现梯度截断对于确保模型收敛至关重要",{"2":{"306":1}}],["就会由于施加在碟片上的离心力而破碎",{"2":{"804":1}}],["就会无法全速运行",{"2":{"801":1}}],["就会涉及到回归问题",{"2":{"608":1}}],["就会对图像中内容的推断造成极大的困难",{"2":{"305":1}}],["就会出现更微妙的情况",{"2":{"187":1}}],["就会出现这种问题",{"2":{"183":1}}],["就会出现问题",{"2":{"117":1}}],["就会获得一个相当大的初始偏差",{"2":{"33":1}}],["就泄漏平均值而言",{"2":{"107":1}}],["就没有什么进展",{"2":{"58":1}}],["常结合",{"2":{"1239":1}}],["常用",{"2":{"1528":1}}],["常用与",{"2":{"1497":1}}],["常用类型",{"0":{"1406":1},"1":{"1407":1,"1408":1,"1409":1,"1410":1}}],["常用命令",{"0":{"1326":1,"1392":1},"1":{"1327":1,"1328":1,"1329":1,"1330":1},"2":{"1324":1}}],["常用工具包",{"2":{"1297":1}}],["常用于构建新结构",{"2":{"1243":1}}],["常用于条件判断",{"2":{"1216":1}}],["常用函数",{"0":{"1232":1}}],["常用内建函数与输入输出",{"0":{"1231":1},"1":{"1232":1,"1233":1}}],["常用的钩子",{"2":{"1470":1}}],["常用的图像增广方法",{"0":{"878":1},"1":{"879":1,"880":1,"881":1}}],["常用的激活函数包括relu函数",{"2":{"238":1}}],["常用的预处理方法",{"2":{"214":1}}],["常规卷积将填充应用于输入",{"2":{"969":1}}],["常量t是超参数",{"2":{"773":1}}],["常见搭配形式",{"2":{"1496":1}}],["常见应用场景",{"0":{"1366":1},"1":{"1367":1,"1368":1,"1369":1,"1370":1}}],["常见问题与解决方法",{"0":{"1337":1}}],["常见远程仓库命名",{"2":{"1324":1}}],["常见标准库",{"0":{"1263":1}}],["常见数据类型与说明",{"0":{"1216":1}}],["常见",{"0":{"1053":1}}],["常见延迟",{"2":{"813":1}}],["常见的标准算术运算符",{"2":{"1018":1}}],["常见的大小可能是32",{"2":{"810":1}}],["常见的例子包括",{"2":{"608":1}}],["常见的例子包括手写字符识别",{"2":{"291":1}}],["常见的技巧是在靠近输入层的地方设置较低的暂退概率",{"2":{"174":1}}],["常见特征的参数相当迅速地收敛到最佳值",{"2":{"25":1}}],["常数相乘法则",{"2":{"981":1}}],["常数12不会带来本质的差别",{"2":{"611":1}}],["常数学习速度",{"2":{"113":1}}],["常数ϵ",{"2":{"107":1}}],["常将它们设置为β1=0",{"2":{"33":1}}],["k>",{"2":{"1434":1,"1435":2}}],["k8s",{"0":{"1350":1,"1351":1},"2":{"1351":1,"1355":1,"1357":1,"1374":1,"1375":1,"1388":1,"1393":1,"1394":2,"1543":1}}],["k代表聚类数字",{"2":{"1154":1}}],["k+",{"2":{"1120":1}}],["k+1",{"2":{"60":4}}],["k类分类",{"2":{"1120":1}}],["k个gpu并行训练过程如下",{"2":{"833":1}}],["kubeadm",{"2":{"1393":1}}],["kubectl",{"2":{"1392":10}}],["kube",{"2":{"1377":1}}],["kubelet",{"2":{"1377":1,"1378":2}}],["kubernetes",{"0":{"1350":1,"1351":1,"1373":1,"1374":1,"1375":1,"1379":1,"1388":1,"1392":1,"1393":1,"1394":1,"1395":1},"1":{"1374":1,"1375":1,"1376":2,"1377":2,"1378":2,"1379":1,"1380":2,"1381":2,"1382":2,"1383":2,"1384":2,"1385":2,"1386":2,"1387":2,"1388":1,"1389":2,"1390":2,"1391":2,"1392":1,"1393":1,"1394":1,"1395":1},"2":{"1350":2,"1351":1,"1355":1,"1372":1,"1374":1,"1381":2,"1392":3,"1393":1,"1394":1,"1395":1}}],["kung",{"2":{"811":1}}],["kumar",{"2":{"32":1}}],["knn",{"2":{"750":4,"751":1}}],["knd2",{"2":{"397":1}}],["k近邻",{"2":{"750":1}}],["k和k",{"2":{"742":1}}],["klog⁡σ",{"2":{"708":1}}],["klog⁡",{"2":{"708":1}}],["klog⁡p",{"2":{"708":1}}],["kp",{"2":{"708":1}}],["k=3之后就下降得很慢",{"2":{"1154":1}}],["k=4",{"2":{"1121":1}}],["k=k+1",{"2":{"768":3}}],["k=k",{"2":{"750":3}}],["k=10000",{"2":{"775":1}}],["k=1",{"2":{"708":1,"1121":1}}],["k=2",{"2":{"376":2,"409":2,"578":2}}],["k是用于匹配的最长的n元语法",{"2":{"578":1}}],["kt",{"2":{"519":1}}],["k|y|t",{"2":{"515":1}}],["kvpairs",{"2":{"382":4}}],["kj",{"2":{"367":1}}],["kind",{"2":{"1389":1,"1390":1,"1391":1,"1393":1}}],["kingma",{"2":{"32":1}}],["kim",{"2":{"698":1}}],["kiros",{"2":{"404":1,"737":1}}],["ki",{"2":{"367":4}}],["km",{"2":{"367":2}}],["k1",{"2":{"367":2}}],["k步预测",{"2":{"352":1}}],["kolter",{"2":{"1002":1}}],["kolesnikov",{"2":{"411":1}}],["koren",{"2":{"345":1}}],["koebel",{"2":{"299":2}}],["kcj",{"2":{"342":2}}],["kf",{"2":{"300":1}}],["kb",{"2":{"300":2}}],["k−1",{"2":{"269":1}}],["k−1+d",{"2":{"269":1}}],["k−1+dk−1",{"2":{"269":1}}],["k的数据",{"2":{"213":1}}],["k折交叉验证往往对多次测试具有相当的稳定性",{"2":{"212":1}}],["k折交叉验证",{"0":{"211":1,"257":1},"2":{"211":1}}],["karate",{"2":{"1191":1}}],["karras",{"2":{"300":1}}],["ka",{"2":{"1077":1}}],["kasparov",{"2":{"301":1}}],["kaggle是一个当今流行举办机器学习比赛的平台",{"2":{"207":1}}],["kaggle的房价预测比赛是一个很好的起点",{"2":{"205":1}}],["kaggle",{"0":{"207":1,"887":1,"896":1},"1":{"888":1,"889":1,"890":1,"891":1,"892":1,"893":1,"894":1,"895":1,"896":1,"897":1,"898":1},"2":{"204":1,"205":1,"207":3,"208":6,"213":2,"467":1,"485":1,"886":2,"887":4,"888":1,"889":2,"896":1,"899":4,"901":3,"902":1,"903":1,"904":2,"908":2}}],["kale",{"2":{"32":1}}],["krizhevsky和ilya",{"2":{"457":1}}],["krizhevsky的名字命名",{"2":{"455":1}}],["krizhevsky",{"2":{"170":1,"300":1,"455":3,"832":1}}],["kwargs",{"2":{"127":2,"325":12,"332":1,"369":10,"370":10,"375":13,"382":10,"391":9,"398":2,"405":8,"406":10,"407":23,"408":26,"413":2,"414":2,"423":2,"425":4,"442":2,"472":4,"480":2,"481":2,"487":6,"501":2,"502":2,"533":9,"534":9,"535":11,"573":10,"574":10,"674":6,"675":6,"676":6,"677":6,"702":6,"713":6,"734":6,"736":6,"737":6,"821":2,"893":2,"926":6,"959":6,"1230":3,"1244":2}}],["k中每个元素加1",{"2":{"121":1}}],["keepalive",{"2":{"1364":1}}],["keep索引",{"2":{"854":3}}],["keep",{"2":{"773":2,"854":27,"892":1,"904":1}}],["keepdim=true",{"2":{"472":4,"631":3,"996":1,"1026":1}}],["keepdims=true",{"2":{"472":4,"631":3,"996":3,"1026":3}}],["keycode",{"2":{"1498":1,"1525":1}}],["keyof",{"2":{"1410":2,"1432":1,"1433":1,"1434":3,"1435":4}}],["key=",{"2":{"1456":1,"1457":1,"1469":1,"1471":1,"1479":1,"1490":1,"1506":1,"1507":1,"1508":1}}],["key=pairs",{"2":{"757":1}}],["key=lambda",{"2":{"363":1,"721":1,"896":3}}],["key的形状",{"2":{"369":4}}],["keys的形状",{"2":{"370":4,"392":8}}],["keys",{"2":{"357":1,"369":25,"370":13,"382":24,"391":14,"392":16,"757":1,"1371":1,"1443":1}}],["key",{"2":{"356":1,"369":8,"376":3,"382":5,"407":12,"408":35,"409":13,"686":2,"726":1,"734":4,"738":4,"844":3,"1207":1,"1370":2,"1404":1,"1421":1,"1432":2,"1433":2}}],["keskar",{"2":{"73":1}}],["kernels",{"2":{"1146":1,"1147":1}}],["kernel2matrix",{"2":{"970":4}}],["kernel函数初始化",{"2":{"863":1}}],["kernel函数的实现",{"2":{"863":1}}],["kernel函数构造",{"2":{"863":1}}],["kernel=",{"2":{"834":4}}],["kernel",{"2":{"67":12,"81":1,"127":6,"129":3,"136":12,"141":8,"142":8,"155":1,"210":1,"278":1,"299":1,"325":1,"379":1,"386":1,"387":4,"388":7,"392":4,"435":4,"436":1,"461":26,"473":12,"474":12,"480":4,"481":6,"482":6,"487":20,"488":17,"494":16,"495":16,"501":12,"502":7,"507":6,"547":1,"561":1,"592":1,"623":1,"702":12,"813":2,"826":3,"834":4,"862":6,"863":33,"893":4,"954":3,"955":3,"957":3,"968":3,"969":12,"1146":1,"1147":1,"1148":4}}],["keras和cntk采用了符号式编程",{"2":{"818":1}}],["keras的loss默认返回一个批量的平均损失",{"2":{"635":1}}],["keras的表现有点不同",{"2":{"437":1}}],["keras内置的损失接受的是",{"2":{"635":1}}],["keras模块定义了大量神经网络层和常见损耗函数",{"2":{"596":1}}],["keras在optimizers模块中实现了该算法的许多变种",{"2":{"594":1}}],["keras让我们避免了这个问题",{"2":{"592":1}}],["keras是tensorflow的高级api",{"2":{"591":1}}],["keras会自动推断每个层输入的形状",{"2":{"591":1}}],["keras会根据一个范围均匀地初始化权重矩阵",{"2":{"434":1}}],["keras不要求我们为每个层指定输入形状",{"2":{"591":1}}],["keras默认返回一个批量中的平均损失",{"2":{"335":1}}],["keras使用",{"2":{"300":1}}],["keras需要为自定义训练代码手动添加损失",{"2":{"278":1}}],["keras",{"2":{"21":1,"29":1,"34":1,"67":12,"68":3,"81":4,"92":1,"109":1,"127":1,"129":1,"136":9,"137":3,"141":2,"142":2,"147":3,"148":1,"174":5,"175":2,"176":8,"210":5,"225":6,"263":3,"278":5,"325":4,"335":2,"350":5,"369":5,"370":2,"375":5,"382":5,"391":1,"392":2,"398":2,"405":4,"406":5,"407":2,"408":3,"413":3,"414":2,"418":3,"422":3,"423":3,"424":4,"425":10,"429":4,"433":6,"435":15,"436":5,"437":4,"442":4,"451":2,"461":15,"472":1,"473":13,"474":17,"480":6,"481":5,"482":10,"487":9,"488":16,"494":4,"495":8,"501":8,"502":13,"507":3,"508":8,"533":1,"534":1,"535":1,"547":2,"561":2,"573":4,"574":5,"575":2,"576":1,"582":1,"584":1,"591":2,"592":2,"593":1,"594":1,"623":4,"624":1,"625":1,"635":3,"819":2,"820":1}}],["k",{"0":{"1151":1},"2":{"60":31,"120":12,"121":11,"122":9,"126":8,"128":3,"153":3,"158":1,"211":12,"212":4,"300":2,"351":1,"369":9,"370":1,"381":3,"382":8,"388":1,"397":1,"515":1,"578":2,"699":15,"702":6,"708":1,"742":6,"750":5,"757":2,"768":3,"775":2,"848":1,"853":1,"968":16,"969":6,"970":28,"1112":1,"1120":2,"1121":1,"1151":9,"1152":3,"1153":1,"1158":1,"1160":1,"1166":3,"1176":1,"1193":1,"1432":3,"1433":3,"1434":3,"1435":4}}],["简易性能测试",{"0":{"1261":1}}],["简直是太复杂了",{"2":{"1122":1}}],["简化后",{"2":{"1478":1}}],["简化前",{"2":{"1478":1}}],["简化",{"0":{"1378":1}}],["简化多容器的管理",{"2":{"1347":1}}],["简化依赖+环境管理",{"2":{"1294":1}}],["简化的成本函数和梯度下降",{"0":{"1110":1},"2":{"1193":1}}],["简化如下",{"2":{"1109":1}}],["简介",{"0":{"1049":1,"1150":1,"1359":1,"1526":1},"1":{"1050":1,"1051":1,"1052":1,"1053":1,"1054":1,"1055":1,"1056":1,"1527":1,"1528":1,"1529":1,"1530":1,"1531":1},"2":{"1193":1}}],["简称",{"2":{"1456":1}}],["简称ref对象",{"2":{"1455":1}}],["简称ref对象或ref",{"2":{"1455":1}}],["简称均方损失",{"2":{"616":1}}],["简称评分函数",{"2":{"367":1}}],["简明实现",{"0":{"474":1}}],["简历筛选和用于贷款的风险模型",{"2":{"284":1}}],["简要介绍一些常见的激活函数",{"2":{"234":1}}],["简单说",{"2":{"1542":1}}],["简单来说",{"2":{"1533":1}}],["简单易用",{"2":{"1395":1}}],["简单",{"2":{"1351":1}}],["简单网络",{"0":{"826":1,"834":1}}],["简单的说",{"2":{"616":1,"804":1}}],["简单的模型可能更有用",{"2":{"260":1}}],["简单起见",{"2":{"386":1,"528":1}}],["简单地丢弃特征对这项工作来说可能过于生硬",{"2":{"269":1}}],["简单地说",{"2":{"40":1,"169":1,"347":1,"698":1,"1025":1,"1089":1}}],["简单性的另一个角度是平滑性",{"2":{"170":1}}],["简单性以较小维度的形式展现",{"2":{"170":1}}],["简言之",{"2":{"164":1,"185":1,"305":1,"330":1,"842":1,"913":1}}],["简洁实现",{"0":{"29":1,"81":1,"92":1,"109":1,"176":1,"278":1,"528":1,"547":1,"561":1}}],["简而言之",{"2":{"20":1,"48":1,"66":1,"95":1,"102":1,"115":1,"120":1,"155":1,"287":1,"300":1,"342":1,"345":1,"422":4,"424":3,"445":1,"652":1,"811":1,"832":1,"841":1,"854":1,"953":1,"981":1}}],["同类别样本被归类到相同簇中",{"2":{"1154":1}}],["同类别的图像将被放置在同一文件夹下",{"2":{"890":1}}],["同",{"2":{"1143":1}}],["同步更新是更自然的实现方法",{"2":{"1067":1}}],["同步需要高度适应特定的网络基础设施和服务器内的连接",{"2":{"845":1}}],["同步只需要在每个小批量数据处理之后进行",{"2":{"832":1}}],["同步执行",{"2":{"792":1}}],["同一时间都在说话",{"2":{"1061":1}}],["同一中心词在不同的训练迭代轮数可以有不同的上下文词或噪声词",{"2":{"770":1}}],["同一词的不同变形形式直接由不同的向量表示",{"2":{"756":1}}],["同一个词经过训练后",{"2":{"743":1}}],["同一个词可以根据上下文被赋予不同的表示",{"2":{"731":1}}],["同一个词元在不同的上下文中具有不同的bert表示",{"2":{"728":1}}],["同一个模型族应该适合于",{"2":{"282":1}}],["同之前一样",{"2":{"503":1}}],["同之前的章节一样",{"2":{"232":1}}],["同之前在",{"2":{"107":1}}],["同理",{"2":{"141":1,"142":1,"305":1,"1125":1,"1146":1}}],["同时响应式地追踪其依赖",{"2":{"1467":1}}],["同时希望你也能掌握",{"2":{"1191":1}}],["同时最小化x",{"2":{"1190":1}}],["同时最大程度的保持了原有数据的信息",{"2":{"1158":1}}],["同时保持特征1的偏差",{"2":{"1184":1}}],["同时保持特征2的偏差",{"2":{"1184":1}}],["同时保留了内容图像中物体主体的形状",{"2":{"916":1}}],["同时有大量的正向类和负向类",{"2":{"1182":1}}],["同时更深入地介绍",{"2":{"1180":1}}],["同时更新是梯度下降中的一种常用方法",{"2":{"1067":1}}],["同时假定你有一个网站",{"2":{"1168":1}}],["同时画出u的范数",{"2":{"1145":1}}],["同时改为优化目标",{"2":{"1143":1}}],["同时却会增加未能成功预测肿瘤为恶性的情况",{"2":{"1140":1}}],["同时也介绍了建立特征时",{"2":{"1183":1}}],["同时也讨论了误差分析",{"2":{"1176":1}}],["同时也会谈谈如何做些许修改",{"2":{"1143":1}}],["同时也向你展示一些查准率和召回率作为算法评估度量值的更有效的方式",{"2":{"1140":1}}],["同时也有一种很简单的方法",{"2":{"1129":1}}],["同时我用b表示第二项",{"2":{"1143":1}}],["同时我们也讨论了怎样决定接下来怎么做的问题",{"2":{"1176":1}}],["同时我们也将",{"2":{"1124":1}}],["同时我们会试着给出一些关于如何巧妙构建一个复杂的机器学习系统的建议",{"2":{"1137":1}}],["同时我们还要弄清楚如何运用梯度下降法",{"2":{"1110":1}}],["同时我也可以来标记我的两条函数曲线",{"2":{"1091":1}}],["同时这是一个列向量",{"2":{"1088":1}}],["同时让你懂得何时会使用机器学习",{"2":{"1059":1}}],["同时让模型保持",{"2":{"643":1}}],["同时将u作为常数处理",{"2":{"976":1}}],["同时将卷积图层的所有优势保留在中间层",{"2":{"145":1}}],["同时可能还需要相应地提高学习率",{"2":{"833":1}}],["同时在销毁前解绑事件",{"2":{"1499":1}}],["同时在",{"2":{"831":1}}],["同时在各种预测任务中表现良好",{"2":{"235":1}}],["同时能够将大多数程序转换为符号式程序",{"2":{"818":2}}],["同时还能够将程序移植到与python无关的格式中",{"2":{"817":1}}],["同时运行的更快",{"2":{"620":1}}],["同时显著减少nin的参数",{"2":{"497":1}}],["同时确保准确性不会显著下降",{"2":{"465":1}}],["同时使其收敛可能需要数小时或数天的时间",{"2":{"462":1}}],["同时使它相对于x最小化",{"2":{"48":1}}],["同时仍然保持了我们进行底层修改的能力",{"2":{"421":1}}],["同时由于计算预算的增加",{"2":{"300":1}}],["同时每一层也与它的下一层相连",{"2":{"204":1}}],["同时降低对空间降采样表示的敏感性",{"2":{"145":1}}],["同时增加通道数",{"2":{"138":1}}],["同时处理潜在表现可能会更好的下降方向",{"2":{"89":1}}],["同时",{"2":{"77":1,"122":1,"135":1,"136":1,"300":1,"461":4,"487":1,"500":1,"527":1,"598":1,"800":1,"821":4,"1063":1,"1086":2,"1143":1,"1144":1,"1180":1}}],["同时带宽在减少",{"2":{"77":1}}],["同时满足这两个约束等于选择一个球的切片作为约束集",{"2":{"47":1}}],["同动量法一样",{"2":{"28":1}}],["同样重要",{"2":{"1549":1}}],["同样图像处理领域的kl变换使用pca做图像压缩",{"2":{"1158":1}}],["同样也可以让逻辑回归中",{"2":{"1110":1}}],["同样也列出我所有的变量",{"2":{"1089":1}}],["同样还有另一个",{"2":{"1089":1}}],["同样可以拆分输出单元的数量",{"2":{"832":1}}],["同样糟糕的是",{"2":{"804":1}}],["同样的道理",{"2":{"1129":1}}],["同样的",{"2":{"600":1,"1148":1}}],["同样的查询",{"2":{"388":4}}],["同样地我可以加载pricey",{"2":{"1089":1}}],["同样地",{"2":{"53":1,"619":1,"801":1,"1034":1,"1090":2,"1129":1,"1143":2}}],["同样",{"2":{"27":1,"50":1,"77":1,"173":1,"198":1,"262":1,"296":1,"301":2,"305":1,"315":1,"368":1,"422":1,"436":2,"470":1,"479":1,"519":1,"539":1,"622":1,"623":1,"634":1,"674":2,"810":1,"880":1,"901":1,"905":1,"969":1,"970":1,"983":1,"994":1,"995":1,"1017":1,"1018":1,"1089":1}}],["从构建到运行的端到端指标",{"2":{"1547":1}}],["从构造来看",{"2":{"87":1}}],["从状态管理到缓存策略",{"2":{"1546":1}}],["从组件设计到接口契约",{"2":{"1546":1}}],["从缓存到埋点",{"2":{"1543":1}}],["从首屏到交互",{"2":{"1543":1}}],["从value中获取最新的temp值",{"2":{"1467":1}}],["从基础类型声明开始",{"2":{"1436":1}}],["从基本的转置卷积开始",{"2":{"968":1}}],["从虚拟机到容器",{"0":{"1353":1}}],["从简单脚本到小项目",{"2":{"1304":1}}],["从用户读取输入",{"2":{"1232":1}}],["从单机到分布式的存储引擎与架构设计",{"0":{"1194":1},"1":{"1195":1,"1196":1,"1197":1,"1198":1,"1199":1,"1200":1,"1201":1,"1202":1,"1203":1,"1204":1,"1205":1,"1206":1,"1207":1,"1208":1,"1209":1,"1210":1,"1211":1}}],["从单轮问答到任务自动化",{"2":{"1051":1}}],["从x",{"2":{"1178":1}}],["从那个样本中学习",{"2":{"1168":1}}],["从大批的涌入又离开网站的用户身上进行学习",{"2":{"1168":1}}],["从2到3之后",{"2":{"1154":1}}],["从2007年发布的开创性的theano库开始",{"2":{"421":1}}],["从1到2",{"2":{"1154":1}}],["从1开始",{"2":{"1091":1}}],["从逻辑回归模型",{"2":{"1148":1}}],["从黑线变到了粉线",{"2":{"1144":1}}],["从根本上来说",{"2":{"1141":1}}],["从0",{"2":{"1141":1}}],["从0开始",{"2":{"573":1,"854":1}}],["从本质上讲",{"2":{"1101":1}}],["从本质上说",{"2":{"74":1}}],["从某种意义上来说",{"2":{"1098":1}}],["从某种意义上说如果我们想要建立学习系统",{"2":{"1098":1}}],["从课程的网上把代码的副本下载下来",{"2":{"1089":1}}],["从工具调用到多智能体协作",{"2":{"1051":1}}],["从语言理解到智能行动",{"2":{"1051":1}}],["从模型到智能体的跃迁",{"0":{"1049":1},"1":{"1050":1,"1051":1,"1052":1,"1053":1,"1054":1,"1055":1,"1056":1}}],["从创建的csv文件中加载原始数据集",{"2":{"1011":1}}],["从文档中",{"2":{"1007":1}}],["从按元素操作的定义中可以注意到",{"2":{"994":1}}],["从预测类别为目标的预测边界框中移除相似的结果",{"2":{"939":1}}],["从预定义分布p",{"2":{"708":1}}],["从打印出的图像坐标轴可以看出",{"2":{"918":1}}],["从l中选取置信度第二高的预测边界框b2作为又一个基准",{"2":{"854":1}}],["从l中选取置信度最高的预测边界框b1作为基准",{"2":{"854":1}}],["从公共存储中取得某种方式",{"2":{"844":1}}],["从顶部到底部计算所有梯度需要一些时间",{"2":{"841":1}}],["从8位数据类型到16位数据类型",{"2":{"815":1}}],["从定义一个具有参考性的用于测试的工作负载开始",{"2":{"796":1}}],["从前面提到的数据集学习",{"2":{"757":1}}],["从长度为1的符号开始",{"2":{"757":1}}],["从词中提取字符n",{"2":{"756":1}}],["从条件概率比值理解glove模型",{"0":{"744":1}}],["从特定于任务到不可知任务",{"0":{"732":1}}],["从高层次上讲",{"2":{"673":1}}],["从信息检索到开放领域的问答",{"2":{"665":1}}],["从计算的角度来看",{"2":{"627":1}}],["从计算角度来看",{"2":{"624":1}}],["从数据流中学习用户的偏好",{"2":{"1168":1}}],["从数据集中随机抽取小批量样本且在负梯度的方向上更新参数",{"2":{"613":1}}],["从数学的角度上讲",{"2":{"1122":1}}],["从数学上讲",{"2":{"624":1}}],["从数值1开始",{"2":{"1088":1}}],["从线性回归到深度网络",{"0":{"617":1},"1":{"618":1,"619":1}}],["从线性到非线性",{"0":{"232":1}}],["从我们的模型中获得",{"2":{"594":1}}],["从我们的模型net中获得",{"2":{"594":1}}],["从我们有限的样本来看",{"2":{"252":1}}],["从技术上讲",{"2":{"573":1,"959":1}}],["从源序列词元",{"2":{"572":1}}],["从第一个词元开始运行",{"2":{"520":1}}],["从最后一个词元开始从后向前运行",{"2":{"520":1}}],["从这些用户不断产生的数据中来学习",{"2":{"1168":1}}],["从这件事情我看到的东西发生在工业上的事",{"2":{"1156":1}}],["从这三组易混淆的词中",{"2":{"1141":1}}],["从这个意义上说",{"2":{"1098":1}}],["从这个意义上讲",{"2":{"647":1}}],["从这个新的点",{"2":{"1067":1}}],["从这个数据模型上来看",{"2":{"1063":1}}],["从这十个值中选择最大的两个",{"2":{"515":2}}],["从这样的模型中提取的文本",{"2":{"315":1}}],["从另一个角度看",{"2":{"494":1}}],["从不同空间大小中提取信息",{"2":{"487":1}}],["从resnet到densenet",{"0":{"479":1}}],["从零开始定义它",{"2":{"834":1}}],["从零开始实现上述循环神经网络模型",{"2":{"335":1}}],["从零开始实现的循环神经网络模型",{"2":{"332":4}}],["从零开始实现多层感知机会变得很麻烦",{"2":{"222":1}}],["从零开始实现",{"0":{"28":1,"80":1,"91":1,"108":1,"172":1,"272":1,"543":1,"557":1},"1":{"173":1,"174":1,"175":1,"273":1,"274":1,"275":1,"276":1,"277":1,"544":1,"545":1,"546":1,"558":1,"559":1,"560":1}}],["从零实现",{"0":{"472":1}}],["从形式上来看",{"2":{"467":1}}],["从形式上来说",{"2":{"467":1}}],["从对最终模型精度的影响来说",{"2":{"454":1}}],["从像素到分类结果",{"2":{"454":1}}],["从业者永远不会将原始像素作为输入",{"2":{"454":1}}],["从业人员越来越多地使用卷积神经网络",{"2":{"134":1}}],["从均匀分布u",{"2":{"434":1}}],["从嵌套块收集参数",{"0":{"433":1}}],["从编程的角度来看",{"2":{"422":1}}],["从宏观角度来看",{"2":{"404":1}}],["从宏观来看",{"2":{"367":1}}],["从下面的例子中可以看到位置嵌入矩阵的第6列和第7列的频率高于第8列和第9列",{"2":{"398":1}}],["从注意力的角度来看",{"2":{"393":1}}],["从绘制的结果会发现新的模型预测线是平滑的",{"2":{"388":1}}],["从相邻时间步的隐藏变量ht和",{"2":{"340":1}}],["从q",{"2":{"337":1}}],["从q抽取的数据为−1",{"2":{"191":1}}],["从头开始基于循环神经网络实现字符级语言模型",{"2":{"329":1}}],["从头开始实现adam算法并不难",{"2":{"34":1}}],["从随机偏移量开始划分序列",{"2":{"321":3}}],["从随机偏移量开始对序列进行分区",{"2":{"320":1}}],["从原始文本序列获得子序列的所有不同的方式",{"2":{"319":1}}],["从ξt的定义中推导出来e",{"2":{"310":1}}],["从td",{"2":{"301":1}}],["从环境中收集数据的过程类似于",{"2":{"297":1}}],["从已知大量数据样本中随机选取一个子集",{"2":{"289":1}}],["从经验中学习",{"2":{"286":1}}],["从未",{"2":{"284":1}}],["从一张给定的图片中识别文字",{"2":{"1171":1}}],["从一个简单的能快速实现的算法开始",{"2":{"1138":1}}],["从一个随机初始化参数的模型开始",{"2":{"282":1}}],["从一堆不同的方法中",{"2":{"1137":1}}],["从一定程度上来说",{"2":{"260":1}}],["从图像中心裁切224x224大小的图片",{"2":{"903":3}}],["从图像映射到字幕",{"2":{"282":1}}],["从图像数据中学习得到有效的模型",{"2":{"134":1}}],["从多项式特征中选取所有维度",{"2":{"266":1}}],["从多项式特征中选择前2个维度",{"2":{"265":1}}],["从多项式特征中选择前4个维度",{"2":{"264":1}}],["从生成的数据集中",{"2":{"262":1}}],["从pip到uv",{"0":{"1265":1},"1":{"1266":1,"1267":1,"1268":1,"1269":1,"1270":1,"1271":1,"1272":1,"1273":1,"1274":1,"1275":1,"1276":1,"1277":1,"1278":1,"1279":1,"1280":1,"1281":1,"1282":1,"1283":1,"1284":1,"1285":1,"1286":1,"1287":1,"1288":1,"1289":1,"1290":1,"1291":1,"1292":1,"1293":1,"1294":1}}],["从pij=xij",{"2":{"744":1}}],["从p到q的交叉熵是h",{"2":{"652":1}}],["从pandas格式中提取numpy格式",{"2":{"209":1}}],["从p抽取的数据为1",{"2":{"191":1}}],["从中接收输入",{"2":{"204":1}}],["从考虑预测到决策的飞跃不仅提出了新的技术问题",{"2":{"201":1}}],["从健康男性身上获取血样比从系统中已有的病人身上获取要困难得多",{"2":{"185":1}}],["从健康人和病人那里收集数据",{"2":{"185":1}}],["从输出层到输入层",{"2":{"166":1}}],["从输入层到输出层",{"2":{"162":1}}],["从w到v的转换只是形式上的转换",{"2":{"153":1}}],["从全连接层到卷积",{"0":{"151":1},"1":{"152":1,"153":1,"154":1,"155":1,"156":1,"157":1,"158":1,"159":1,"160":1}}],["从上下文词中排除中心词",{"2":{"774":1}}],["从上下文敏感的elmo到任务不可知的gpt和bert",{"2":{"733":1}}],["从上下文无关到上下文敏感",{"0":{"731":1}}],["从上往下的在输入张量内滑动",{"2":{"146":1}}],["从上到下滑动",{"2":{"126":1}}],["从左向右写着",{"2":{"1088":1}}],["从左上角到右下角的对角线",{"2":{"1076":1}}],["从左往右依次分析",{"2":{"1184":1}}],["从左往右",{"2":{"146":1}}],["从左到右",{"2":{"126":1,"732":1}}],["从",{"2":{"118":1,"275":1,"744":1,"858":2}}],["从而让开发者有机会在特定阶段运行自己的代码",{"2":{"1470":1}}],["从而令θ范数的平方变小",{"2":{"1145":1}}],["从而最大间距地分离开正样本和负样本",{"2":{"1144":1}}],["从而你会更快地做出决定",{"2":{"1138":1}}],["从而你自己能实现每个这些算法",{"2":{"1058":1}}],["从而了解内部机理",{"2":{"1058":1}}],["从而提升模型的实用性和自动化能力",{"2":{"1040":1}}],["从而提高模型的泛化能力",{"2":{"877":1}}],["从而提高kaggle的得分",{"2":{"215":1}}],["从而降低分辨率",{"2":{"1025":1}}],["从而降低模型的复杂性",{"2":{"487":1}}],["从而进一步减少内存使用量",{"2":{"1021":1}}],["从而进一步降低模型复杂度",{"2":{"481":1}}],["从而对输入图像的rgb三个通道的值分别做标准化",{"2":{"947":1}}],["从而借助目标的像素级位置进一步提升目标检测的精度",{"2":{"941":1}}],["从而为你节省大量不必要花费的时间",{"2":{"1129":1}}],["从而为具有不同形状的兴趣区域抽取相同形状的特征",{"2":{"941":1}}],["从而为文章中的每个词元位置i分配作为文本片段开始的概率pi",{"2":{"660":1}}],["从而更适于像素级预测",{"2":{"940":1}}],["从而更改程序的状态",{"2":{"816":1}}],["从而在减少了从数据中学习的提议区域的数量的情况下",{"2":{"939":1}}],["从而在神经网络中获得良好的参数设置",{"2":{"299":1}}],["从而实现多尺度目标检测",{"2":{"913":1}}],["从而实例化了",{"2":{"340":1}}],["从而扩大了训练集的规模",{"2":{"877":1}}],["从而预测类别",{"2":{"866":1}}],["从而预测字符并输出它们",{"2":{"333":1}}],["从而将模型转化为线性回归模型",{"2":{"1084":1}}],["从而将其变回输入图像的高和宽",{"2":{"862":1}}],["从而将输入的高度和宽度减半",{"2":{"142":1}}],["从而简化输出",{"2":{"855":1}}],["从而详细说明参数交换和同步",{"2":{"834":1}}],["从而就能提高训练效率",{"2":{"832":1}}],["从而允许程序在非python环境中运行",{"2":{"817":1}}],["从而消除因为多个更快的gpu与单个cpu上的单个python线程搭配使用时产生的性能瓶颈",{"2":{"817":1}}],["从而满足设计更紧凑的芯片和处理良品率问题",{"2":{"811":1}}],["从而获得相关项",{"2":{"791":1}}],["从而赋予过多的权重",{"2":{"742":1}}],["从而把线性模型看作一个神经网络",{"2":{"617":1}}],["从而减少提议区域的生成数量",{"2":{"939":1}}],["从而减少此算法中的计算量",{"2":{"854":1}}],["从而减少了出错的可能性",{"2":{"615":1}}],["从而减少对预先设想假设的依赖",{"2":{"284":1}}],["从而利用线性代数库",{"2":{"615":1}}],["从而初始化参数",{"2":{"596":1}}],["从而无偏见地读取小批量",{"2":{"583":1}}],["从而无法达到最优解",{"2":{"66":1}}],["从而有效地跳过了依赖链条中的时间步t",{"2":{"542":1}}],["从而再次减少通道的数量",{"2":{"484":1}}],["从而与",{"2":{"482":1}}],["从而服务于基本的图形任务",{"2":{"457":1}}],["从而设计出适用于各种任务的架构",{"2":{"412":1}}],["从而得到其对应的预测输出",{"2":{"392":1}}],["从而其softmax输出为0",{"2":{"368":4}}],["从而帮助你的异常检测算法",{"2":{"1183":1}}],["从而帮助吸引新的玩家",{"2":{"354":1}}],["从而帮助我们设计适合于计算机视觉的神经网络架构",{"2":{"152":1}}],["从而优化算法可能无法收敛",{"2":{"334":1}}],["从而可以确定当前的输出",{"2":{"305":1}}],["从而执行推理链中的后续步骤",{"2":{"300":1}}],["从而推断其状态",{"2":{"298":1}}],["从而违反独立性假设",{"2":{"253":1}}],["从而产生形状大于输入的输出",{"2":{"971":1}}],["从而产生大于输入的输出",{"2":{"968":1}}],["从而产生的行为会比单独一个神经元所产生的行为更有趣",{"2":{"619":1}}],["从而产生更有表达能力的模型",{"2":{"232":1}}],["从而产生扰动点x",{"2":{"170":1}}],["从而做得更好",{"2":{"189":1}}],["从而基于这个模型使用较少的参数来学习有用的表示",{"2":{"152":1}}],["从而保持输出大小不变",{"2":{"126":1}}],["从而增加我们在每一步中覆盖的距离",{"2":{"88":1}}],["从而防止一开始发散",{"2":{"73":1}}],["从而证明了凸性",{"2":{"46":1}}],["从而证明我们的定理",{"2":{"40":1}}],["从而使所得的kh×kw张量替换中间张量的一部分",{"2":{"968":1}}],["从而使所有gpu阻塞",{"2":{"452":1}}],["从而使所有特征值都是1",{"2":{"26":1}}],["从而使风景照更加锐利或者令人像更加美白",{"2":{"916":1}}],["从而使它们可以相加",{"2":{"501":1}}],["从而使模型无法得到有效的训练",{"2":{"460":1}}],["从而使模型强制执行所需的行为",{"2":{"282":1}}],["从而使属于不同类别的数据易于区分",{"2":{"455":1}}],["从而使其不需要偏差校正",{"2":{"37":1}}],["6×2",{"2":{"1089":1}}],["6×0",{"2":{"513":1}}],["619",{"2":{"959":1}}],["6最大",{"2":{"938":1}}],["62",{"2":{"854":2}}],["666",{"2":{"1456":1,"1457":1,"1464":1,"1491":1,"1499":1,"1501":1}}],["66",{"2":{"853":1}}],["655",{"2":{"858":1}}],["65",{"2":{"813":1,"1364":1}}],["6b50d中预训练词向量的词表包含400000个词和一个特殊的未知词元",{"2":{"750":1}}],["6b50d",{"2":{"748":4,"750":3,"751":4}}],["6b",{"2":{"680":3,"703":3,"714":1,"748":5}}],["6=0",{"2":{"513":2}}],["6f",{"2":{"392":4}}],["60",{"2":{"290":1,"398":4,"692":1,"858":1,"1223":1}}],["600+次pr",{"2":{"1437":1}}],["6000台正常引擎的数据作为训练集",{"2":{"1181":1}}],["600px",{"2":{"494":1,"887":1}}],["600",{"2":{"290":1,"350":1}}],["6nin+nout",{"2":{"247":1}}],["63",{"2":{"116":1,"853":1}}],["64到1倍的小正方形",{"2":{"891":1}}],["64～1倍的小正方形",{"2":{"891":2}}],["64位cpu应该按照64位边界进行内存对齐",{"2":{"814":1}}],["64mb",{"2":{"813":2}}],["64kb",{"2":{"810":1}}],["64×0",{"2":{"722":1}}],["64=4",{"2":{"488":1}}],["6400",{"2":{"461":2}}],["64",{"2":{"78":4,"212":1,"351":3,"376":1,"409":8,"414":6,"425":6,"482":10,"488":48,"502":13,"508":1,"576":1,"694":3,"698":3,"712":3,"722":1,"725":2,"826":12,"863":3,"891":3,"893":2,"945":7,"948":3,"958":3,"959":4,"1133":1}}],["6",{"0":{"1068":1,"1077":1,"1085":1,"1093":1,"1102":1,"1106":1,"1107":1,"1108":1,"1109":1,"1110":1,"1111":2,"1112":1,"1125":1,"1134":1,"1148":1,"1161":1,"1169":1,"1183":1,"1192":1,"1286":1,"1314":1,"1323":1,"1348":1,"1385":1,"1393":1,"1415":1,"1458":1,"1478":1,"1493":1,"1496":1,"1497":1,"1498":1,"1499":1,"1500":1,"1501":1,"1502":2,"1503":1,"1504":1,"1505":1},"1":{"1287":1,"1288":1,"1289":1,"1416":1,"1417":1,"1497":1,"1498":1,"1499":1,"1500":1,"1501":1,"1502":1,"1503":1,"1504":1,"1505":1,"1506":2,"1507":2,"1508":2},"2":{"27":1,"28":4,"34":4,"35":1,"67":4,"80":1,"87":2,"88":2,"89":1,"95":1,"101":2,"108":5,"120":2,"122":1,"126":1,"128":5,"129":8,"136":4,"146":2,"262":2,"264":1,"305":1,"350":2,"351":3,"357":1,"369":4,"382":2,"390":4,"398":12,"473":8,"474":7,"488":1,"501":12,"515":1,"566":2,"575":4,"631":2,"633":2,"634":1,"699":4,"736":3,"762":1,"813":1,"834":3,"842":2,"852":1,"854":1,"938":1,"964":3,"970":2,"1018":1,"1026":18,"1027":1,"1028":1,"1061":2,"1068":1,"1069":1,"1070":1,"1077":1,"1085":1,"1086":1,"1088":3,"1089":4,"1093":1,"1102":1,"1106":1,"1107":1,"1108":1,"1109":1,"1110":1,"1111":2,"1112":2,"1125":1,"1129":1,"1134":1,"1148":1,"1157":1,"1161":1,"1164":1,"1166":1,"1169":1,"1183":1,"1192":1,"1193":20,"1296":1,"1414":1,"1426":1,"1490":1,"1503":1}}],["可观测性与报警",{"2":{"1546":1}}],["可执行方案",{"2":{"1545":1}}],["可维护",{"2":{"1544":1}}],["可复用的组件与",{"2":{"1544":1}}],["可复用的独立任务单元",{"2":{"1311":1}}],["可提升性能",{"2":{"1513":1}}],["可直接编",{"2":{"1465":1}}],["可直接在模板中使用",{"2":{"1451":1}}],["可直接使用",{"2":{"1041":1}}],["可索引接口",{"0":{"1421":1}}],["可扩展性和稳定性",{"2":{"1352":1}}],["可离线查看",{"2":{"1318":1}}],["可使用",{"2":{"1310":1}}],["可做项目多",{"0":{"1301":1}}],["可变参数",{"2":{"1230":1}}],["可变序列",{"2":{"1216":1}}],["可变长度的文本序列将被转换为固定长度的类别",{"2":{"713":1}}],["可分发到",{"2":{"1209":1}}],["可分解注意模型包括三个步骤来预测前提和假设之间的逻辑关系",{"2":{"683":1}}],["可分解注意力模型",{"2":{"672":1}}],["可考虑先采用下面的几种方法",{"2":{"1129":1}}],["可选参数",{"2":{"1427":1}}],["可选修饰符",{"0":{"1427":1}}],["可选属性",{"2":{"1419":1,"1427":2}}],["可选",{"0":{"1086":1,"1185":1}}],["可选取的单词数目过多可能会带来哪些问题",{"2":{"638":1}}],["可怕的概念",{"2":{"1070":1}}],["可自动调用插件",{"2":{"1050":1}}],["可靠的双向通信",{"2":{"1047":1}}],["可得到p",{"2":{"1032":2}}],["可否允许执行异步通信",{"2":{"846":1}}],["可找到数据的",{"2":{"829":2}}],["可从glove网站下载",{"2":{"748":1}}],["可导的性质",{"2":{"643":1}}],["可学习的函数",{"2":{"520":1}}],["可学习的参数包括",{"2":{"381":1}}],["可见",{"2":{"471":1}}],["可持续加速深层网络的收敛速度",{"2":{"466":1}}],["可通过net",{"2":{"594":2}}],["可通过其反向传播函数进行访问",{"2":{"423":2}}],["可通过x处的函数值f",{"2":{"54":1}}],["可视化编辑器",{"2":{"1529":1}}],["可视化",{"2":{"1297":1}}],["可视化预测的类别",{"2":{"866":1}}],["可视化正态分布",{"2":{"616":1}}],["可视化transformer的注意力权重",{"2":{"409":1}}],["可视化注意力权重",{"2":{"376":1}}],["可视化查询和键之间的注意力权重是可行的",{"2":{"358":1}}],["可微注意力模型",{"2":{"373":1}}],["可微的阈值单元近似",{"2":{"236":1}}],["可加性注意力和缩放的",{"2":{"372":1}}],["可用数据集通常可以分成两部分",{"2":{"286":1}}],["可优化",{"2":{"286":1}}],["可调整参数的数量",{"2":{"254":1}}],["可我们能从中得到什么好处呢",{"2":{"232":1}}],["可伸缩性和效率相关的问题",{"2":{"204":1}}],["可减少空间维度",{"2":{"149":1}}],["可运行的lenet模型",{"2":{"134":1}}],["可降低每次迭代时的计算代价",{"2":{"113":1}}],["可能并不是所有的问题",{"2":{"1187":1}}],["可能并不理想",{"2":{"106":1}}],["可能导致欠拟合",{"2":{"1147":1}}],["可能导致过拟合",{"2":{"1147":1}}],["可能导致不稳定的优化结果",{"2":{"73":1}}],["可能属于的两个类分别称为负向类",{"2":{"1106":1}}],["可能电压值高的点对应一个暗像素电压值低的点",{"2":{"1098":1}}],["可能这些比较复杂一点的索引操作你会经常用到",{"2":{"1089":1}}],["可能你也不会经常使用",{"2":{"1089":1}}],["可能你仍然不知道它的内涵",{"2":{"1064":1}}],["可能更重要的",{"2":{"1059":1}}],["可能所有服务器的分布跨越了多个机架和多个网络交换机",{"2":{"840":1}}],["可能未规范化的",{"2":{"775":1}}],["可能还有更好的",{"2":{"1060":1}}],["可能还会调优其他超参数",{"2":{"690":1}}],["可能还想记住",{"2":{"540":1}}],["可能大于数据类型容许的最大数字",{"2":{"624":1}}],["可能有很多可学习的参数",{"2":{"642":1}}],["可能有些oj−max",{"2":{"624":1}}],["可能有一些辅助html代码与网页传达的情绪无关",{"2":{"538":1}}],["可能有符号",{"2":{"64":1}}],["可能高的惊人",{"2":{"514":1}}],["可能的输出序列中寻找理想的输出",{"2":{"512":1}}],["可能具有更广的变化范围",{"2":{"467":1}}],["可能具有各种各样的特征值",{"2":{"241":1}}],["可能性",{"2":{"436":3}}],["可能性可能性可能性w∼",{"2":{"436":1}}],["可能性要小得多",{"2":{"342":1}}],["可能才是更完美的合理扩展",{"2":{"342":1}}],["可能出现在相关的上下文中",{"2":{"316":1}}],["可能效果会更好",{"2":{"305":1}}],["可能被认为更好",{"2":{"294":1}}],["可能是",{"2":{"1311":1}}],["可能是选择了一个",{"2":{"1141":1}}],["可能是有益的",{"2":{"380":1}}],["可能是估计的评级或购买的概率",{"2":{"294":1}}],["可能是局部最小值",{"2":{"101":1}}],["可能在构建大型的机器学习系统时",{"2":{"1137":1}}],["可能在一个这样的鸡尾酒宴中的两个人",{"2":{"1061":1}}],["可能在不经意间",{"2":{"290":1}}],["可能在参数节约和模型有效性之间进行权衡",{"2":{"231":1}}],["可能需要尝试大量不同的组合",{"2":{"916":1}}],["可能需要8毫秒才能使用请求的数据",{"2":{"804":1}}],["可能需要估计一栋房子的公平市场价值",{"2":{"290":1}}],["可能需要一个完全不同的模型族",{"2":{"282":1}}],["可能类似于",{"2":{"290":1}}],["可能仍然使模型在过简单和过复杂中徘徊",{"2":{"269":1}}],["可能比从100万增加到105万带来更大的还款可能性",{"2":{"230":1}}],["可能会得到一个颠簸不平但是不会明显减少的函数图像",{"2":{"1167":1}}],["可能会得不到预期的效果",{"2":{"1158":1}}],["可能会存在一些不容易察觉的错误",{"2":{"1124":1}}],["可能会存在什么问题",{"2":{"402":1}}],["可能会导致低拟合",{"2":{"1144":1}}],["可能会导致过拟合",{"2":{"1144":1}}],["可能会导致它们效果很差",{"2":{"1114":1}}],["可能会导致矩阵x",{"2":{"1086":1}}],["可能会导致种族",{"2":{"301":1}}],["可能会越过局部最小值导致无法收敛",{"2":{"1083":1}}],["可能会很慢",{"2":{"1068":1}}],["可能会找到不同的局部最小值",{"2":{"1067":1}}],["可能会遇到不止一种特征",{"2":{"1060":1}}],["可能会遇到这样的问题",{"2":{"251":1}}],["可能会用一个向量来表示每个患者",{"2":{"990":1}}],["可能会将每个申请人与一个向量相关联",{"2":{"990":1}}],["可能会输出许多相似的具有明显重叠的预测边界框",{"2":{"854":1}}],["可能会破坏原本高效代码的性能",{"2":{"791":1}}],["可能会在实际问题上陷入麻烦",{"2":{"600":1}}],["可能会完全放弃表征的空间结构",{"2":{"493":1}}],["可能会影响未来发生的事情xt+1",{"2":{"349":1}}],["可能会有过拟合测试数据的风险",{"2":{"256":1}}],["可能会有麻烦",{"2":{"181":1}}],["可能会使所有物体左右移动一个像素",{"2":{"145":1}}],["可能遇到的最隐蔽问题是梯度消失",{"2":{"103":1}}],["可能变得显著了",{"2":{"55":1}}],["可求最优解",{"2":{"49":1}}],["可以确保它们收到的是普通对象",{"2":{"1518":1}}],["可以认为声明过的",{"2":{"1501":1}}],["可以简化路由跳转及传参",{"2":{"1478":1}}],["可以让我们把setup独立出去",{"2":{"1454":1}}],["可以让你更好地理解算法的内容",{"2":{"1091":1}}],["可以传入数组",{"2":{"1433":1}}],["可以访问",{"2":{"1425":2}}],["可以包含一个或多个容器",{"2":{"1380":1}}],["可以有多个",{"2":{"1365":1}}],["可以做什么",{"0":{"1297":1}}],["可以提高代码复用性",{"2":{"1234":1}}],["可以提供可预测的结果",{"2":{"299":1}}],["可以写多个",{"2":{"1223":1}}],["可以替换不同的存储引擎",{"2":{"1203":1}}],["可以证明的是",{"2":{"1184":1}}],["可以避免出现负数结果",{"2":{"1183":1}}],["可以避免反向传播过程中可能会困扰我们的数值稳定性问题",{"2":{"624":1}}],["可以慢慢地调试你所学习到的假设",{"2":{"1168":1}}],["可以达到降维从而简化模型或是对数据进行压缩的效果",{"2":{"1158":1}}],["可以根据特征值x被准确地预测出来",{"2":{"1141":1}}],["可以根据整个数据集精确计算批量规范化所需的平均值和方差",{"2":{"467":1}}],["可以是任意类型",{"2":{"1498":1}}],["可以是任何类型",{"2":{"1404":1}}],["可以是一种有效的方法来获得一个具有良好性能的学习算法",{"2":{"1141":1}}],["可以是手工选择保留哪些特征",{"2":{"1114":1}}],["可以这样想",{"2":{"1112":1}}],["可以这样理解",{"2":{"291":1}}],["可以取一个很小的数值",{"2":{"1112":1}}],["可以猜想如果我们把几乎任何一种传感器接入到大脑的几乎任何一个部位的话",{"2":{"1098":1}}],["可以同时处理视觉",{"2":{"1098":1}}],["可以返回多个值",{"2":{"1092":1}}],["可以帮助确认梯度下降算法是否收敛",{"2":{"1091":1}}],["可以帮你过滤大量的垃圾邮件这也是一种学习算法",{"2":{"1058":1}}],["可以抑制打印输出",{"2":{"1088":1}}],["可以删除这两个重复特征里的其中一个",{"2":{"1086":1}}],["可以指定范围以包含第一个元素和最后一个之前的元素",{"2":{"1020":1}}],["可以指定一个有效序列长度",{"2":{"368":1}}],["可以把正样本和负样本完全分开",{"2":{"1144":1}}],["可以把数据分为训练集",{"2":{"1135":1}}],["可以把所有这些",{"2":{"1110":1}}],["可以把",{"2":{"1100":1}}],["可以把分布",{"2":{"1026":1}}],["可以把张量x从形状为",{"2":{"1017":1}}],["可以把输入形状换成224×224",{"2":{"485":1}}],["可以检查它的大小",{"2":{"1017":1}}],["可以跳过本节",{"2":{"1017":1}}],["可以调用reshape函数",{"2":{"1017":1}}],["可以调用help函数",{"2":{"1007":1}}],["可以调用dir函数",{"2":{"1006":1}}],["可以调用cumsum函数",{"2":{"996":1}}],["可以开始理解矩阵",{"2":{"998":1}}],["可以记为∑i=1dxi",{"2":{"995":1}}],["可以进一步学习本书数学附录中给出的数学基础知识",{"2":{"987":1}}],["可以进一步提高它们的计算性能",{"2":{"824":1}}],["可以知道损失会以多快的速度增加或减少",{"2":{"981":1}}],["可以参阅调查报告",{"2":{"929":1}}],["可以参考线性代数运算的在线附录或其他优秀资源",{"2":{"1002":1}}],["可以参考",{"2":{"942":1}}],["可以参考yolo模型",{"2":{"942":1}}],["可以参考soft",{"2":{"856":1}}],["可以参考vision",{"2":{"411":1}}],["可以参考论文",{"2":{"411":1}}],["可以点击",{"2":{"901":1}}],["可以衡量两组之间的相似性",{"2":{"849":1}}],["可以衡量锚框和真实边界框之间的相似性",{"2":{"849":1}}],["可以双向发送消息",{"2":{"846":1}}],["可以假设距离为10000公里",{"2":{"815":1}}],["可以移动磁头",{"2":{"804":1}}],["可以对高频单词进行下采样",{"2":{"773":1}}],["可以对动量法进行明确而详细的分析",{"2":{"96":1}}],["可以译作银行或者河岸",{"2":{"754":1}}],["可以省略任意xij=0的平方损失项",{"2":{"743":1}}],["可以预先计算此类共现的全局语料库统计数据",{"2":{"741":1}}],["可以预防病毒",{"2":{"660":1}}],["可以设计一种用自然语言推断来评价机器翻译结果的方法吗",{"2":{"671":1}}],["可以设计一个隐变量模型",{"2":{"519":1}}],["可以从前提中的",{"2":{"665":1}}],["可以忽略偏置b",{"2":{"621":1}}],["可以很方便地引用我们整个数据集的n个样本",{"2":{"610":1}}],["可以很容易地得到深度门控循环神经网络或深度长短期记忆神经网络",{"2":{"527":1}}],["可以很容易地在任何现代深度学习框架的代码中实现这些重复的架构",{"2":{"506":1}}],["可以表示为点积x⊤w",{"2":{"997":1}}],["可以表示为特征",{"2":{"610":1}}],["可以表示比简单加权平均值更复杂的函数",{"2":{"381":1}}],["可以追溯到19世纪初",{"2":{"609":1}}],["可以实现任意组件间通信",{"2":{"1499":1}}],["可以实现很大数量级的加速比",{"2":{"814":1}}],["可以实现主要的",{"2":{"605":1}}],["可以实现多头注意力的并行计算",{"2":{"383":1}}],["可以直观观察到两者之间的线性关系",{"2":{"599":1}}],["可以直接写",{"2":{"1465":1}}],["可以直接由神经网络使用",{"2":{"781":1}}],["可以直接在28×28图像上工作",{"2":{"465":1}}],["可以直接调用d2l包的train",{"2":{"221":1}}],["可以观察到什么结果",{"2":{"580":1}}],["可以允许标签成为原始的输出序列",{"2":{"572":1}}],["可以保证所有的文本序列都具有相同的长度",{"2":{"570":1}}],["可以将路由参数作为props传给组件",{"2":{"1483":1}}],["可以将请求分发到多台后端服务器",{"2":{"1362":1}}],["可以将正样本和负样本分开",{"2":{"1144":1}}],["可以将数据集一分为二为正类和负类",{"2":{"1112":1}}],["可以将其表示为x∈rn",{"2":{"991":1}}],["可以将a的偏移量标记为",{"2":{"852":1}}],["可以将任何预训练的文本表示与任何应用的架构相结合",{"2":{"663":1}}],["可以将文本序列",{"2":{"568":1}}],["可以将估计值p^",{"2":{"316":1}}],["可以改进吗",{"2":{"517":1}}],["可以改变",{"2":{"182":1}}],["可以训练出一个有效的深层神经网络",{"2":{"504":1}}],["可以想象在这个过程的早期使用全连接层",{"2":{"493":1}}],["可以想象实例化两个多层感知机",{"2":{"423":1}}],["可以应用细微的更改",{"2":{"658":1}}],["可以应用概率积分变换吗",{"2":{"477":1}}],["可以应用的其他",{"2":{"477":1}}],["可以描述单个层",{"2":{"422":1}}],["可以使$",{"2":{"1115":1}}],["可以使用getters配置",{"2":{"1493":1}}],["可以使用object",{"2":{"1458":1}}],["可以使用volar插件自动添加",{"2":{"1458":1}}],["可以使用",{"2":{"1350":1,"1519":1}}],["可以使用逻辑回归",{"2":{"1112":1}}],["可以使用以下代码",{"2":{"876":1}}],["可以使用全连接的层将该单个文本表示转换为类别",{"2":{"716":1}}],["可以使用softmax来获得分布",{"2":{"575":1}}],["可以使用函数g来表示解码器的隐藏层的变换",{"2":{"574":1}}],["可以使用循环神经网络来设计编码器",{"2":{"573":1}}],["可以使用可加性注意力评分函数",{"2":{"371":1}}],["可以使用加性注意力作为评分函数",{"2":{"369":1}}],["可以使我们把这个特征当作一个独热向量来对待",{"2":{"214":1}}],["可以被子类继承",{"2":{"1416":1}}],["可以被视为作用等同于逻辑非",{"2":{"1102":1}}],["可以被视为作用等同于逻辑或",{"2":{"1102":1}}],["可以被视为作用同于逻辑与",{"2":{"1102":1}}],["可以被认为是将集合映射到真实值的函数",{"2":{"1027":1}}],["可以被认为是文本序列在时间步t处的观测或标签",{"2":{"315":1}}],["可以被想象成",{"2":{"286":1}}],["可以得出一英尺的长度",{"2":{"299":1}}],["可以得到一个行向量",{"2":{"1088":1}}],["可以得到很好的控制",{"2":{"832":1}}],["可以得到的最佳结果是什么",{"2":{"223":1}}],["可以得到",{"2":{"115":1}}],["可以创建一个强化学习智能体",{"2":{"298":1}}],["可以捕捉一个人的偏好",{"2":{"294":1}}],["可以无须架构上的技巧而训练10000层神经网络的可能性",{"2":{"248":1}}],["可以获得与上面的原始卷积操作所得相同的结果y",{"2":{"970":1}}],["可以获得相同的函数",{"2":{"244":1}}],["可以获得更强的最优性理论保证",{"2":{"197":1}}],["可以在子类中访问",{"2":{"1425":1}}],["可以在这组数据中画一条直线",{"2":{"1060":1}}],["可以在调用函数时指定axis=0",{"2":{"995":1}}],["可以在最后访问的节点中找到聚合梯度",{"2":{"842":1}}],["可以在大型语料库上使用word2vec",{"2":{"754":1}}],["可以在保持特征总数不变的情况下合并旧的观察结果吗",{"2":{"353":1}}],["可以在一个迭代周期内流经相邻的子序列",{"2":{"335":1}}],["可以在不离开笔记本的情况下安装pandas",{"2":{"208":1}}],["可以在测试时检测并纠正协变量偏移和标签偏移",{"2":{"202":1}}],["可以通过张量的shape属性来访问张量",{"2":{"1017":1}}],["可以通过调用dir和help函数或在jupyter记事本中使用",{"2":{"1008":1}}],["可以通过以下方程得到",{"2":{"650":1}}],["可以通过矩阵",{"2":{"610":1}}],["可以通过批量规范化来替换暂退法吗",{"2":{"477":1}}],["可以通过pip",{"2":{"445":1}}],["可以通过在",{"2":{"1013":1}}],["可以通过在conv",{"2":{"508":1}}],["可以通过在输入表示中添加位置编码",{"2":{"401":1}}],["可以通过在x中以",{"2":{"153":1}}],["可以通过设计注意力汇聚的方式",{"2":{"356":1}}],["可以通过向量化提供额外效率",{"2":{"32":1}}],["可以聚合这些局部特征",{"2":{"152":1}}],["可以用函数的方式",{"2":{"1449":1}}],["可以用这个模型来识别那些不符合该模式的用户",{"2":{"1178":1}}],["可以用任务流程图来表达这个问题",{"2":{"1171":1}}],["可以用伪逆函数pinv",{"2":{"1086":1}}],["可以用在有大量特征变量的线性回归问题",{"2":{"1085":1}}],["可以用一个聚类算法来聚类这些文章到一起",{"2":{"1061":1}}],["可以用",{"2":{"1020":2}}],["可以用于线性回归的一个原因是",{"2":{"616":1}}],["可以用于演示具有注意力机制的机器学习",{"2":{"385":1}}],["可以用来进行数据压缩",{"2":{"1158":1}}],["可以用来解决多项式回归问题",{"2":{"1117":1}}],["可以用来表明x和y是值只能为0或1的数字",{"2":{"989":1}}],["可以用来检测尺寸较小的目标",{"2":{"953":1}}],["可以用来预测股市的波动",{"2":{"305":1}}],["可以用来学习的数据",{"2":{"283":1}}],["可以用更准确地拟合实际情况的非参数模型来代替",{"2":{"302":1}}],["可以用已知函数替换它吗",{"2":{"150":1}}],["可以用它加快训练",{"2":{"137":1}}],["可以反向考虑一下",{"2":{"116":1}}],["可以分解为朝二次矩阵特征向量方向坐标顺序的优化",{"2":{"94":1}}],["可以看作是",{"2":{"1211":1}}],["可以看出用深度学习框架实现此类模型非常简单",{"2":{"136":1}}],["可以看出",{"2":{"80":1,"1060":1,"1107":1,"1116":1,"1134":2}}],["可以看到参数向量θ事实上是和决策界是90度正交的",{"2":{"1145":1}}],["可以看到这个数据集是线性可分的",{"2":{"1144":1}}],["可以看到图像左边是一只狗",{"2":{"857":1}}],["可以看到此转换会将特征的总数量从79个增加到331个",{"2":{"209":1}}],["可以看到更好的表现",{"2":{"27":1}}],["可以看到",{"2":{"27":1,"57":1,"80":1,"142":1,"634":1,"848":1,"863":1,"966":1}}],["可以说明",{"2":{"1145":1}}],["可以说是",{"2":{"433":1}}],["可以说是由chainer率先推出的",{"2":{"300":1}}],["可以说",{"2":{"77":1,"552":1,"877":1,"886":1}}],["可以试着把优化和采样联系起来吗",{"2":{"75":1}}],["可以导致测试集上不同的泛化和过拟合量",{"2":{"74":1}}],["可惜",{"2":{"26":1}}],["眼下让我们先看看它在二次凸问题中的表现如何",{"2":{"27":1}}],["然而当我们进行正则化处理时",{"2":{"1162":1}}],["然而当实现该算法时",{"2":{"161":1}}],["然而粉线和蓝线离训练样本就非常近",{"2":{"1144":1}}],["然而梯度下降并不是我们可以使用的唯一算法",{"2":{"1111":1}}],["然而对于之前的一个",{"2":{"1112":1}}],["然而对于分类问题",{"2":{"1107":1}}],["然而对于高维感知数据",{"2":{"151":1}}],["然而大概由于近些年计算机的运行速度变快",{"2":{"1098":1}}],["然而大多数矩阵可能不能完全放入缓存中",{"2":{"77":1}}],["然而现实生活中",{"2":{"1026":1}}],["然而全卷积网络中不需要它们",{"2":{"862":1}}],["然而如果这个夹角大于90度",{"2":{"1145":1}}],["然而如果输入和输出图像的空间维度相同",{"2":{"967":1}}],["然而如果有大量的层",{"2":{"222":1}}],["然而如今除了非常特殊的情况",{"2":{"832":1}}],["然而在语义分割中",{"2":{"946":1}}],["然而在多插槽服务器上这个数字可能超过256",{"2":{"792":1}}],["然而在实践中",{"2":{"190":1}}],["然而我们通过训练而得到的神经网络算法却有1",{"2":{"1139":1}}],["然而我们能否将未规范化的预测o直接视作我们感兴趣的输出呢",{"2":{"643":1}}],["然而我们可以很容易找出违反单调性的例子",{"2":{"230":1}}],["然而很长一段时间里这些尝试都未有突破",{"2":{"455":1}}],["然而有一个小问题",{"2":{"351":1}}],["然而事实证明",{"2":{"345":1}}],["然而模型参数的数量也会随之呈指数增长",{"2":{"338":1}}],["然而模型怎么判断得出这种",{"2":{"291":1}}],["然而目前用户的购买习惯往往是遵循推荐算法",{"2":{"294":1}}],["然而那里一栋典型的房子的价值是12",{"2":{"210":1}}],["然而观测值xi是从某些源分布q",{"2":{"191":1}}],["然而也有一些例外",{"2":{"171":1}}],["然而这是一个难以理解",{"2":{"342":1}}],["然而这样的操作可能会使计算和存储的代价都变得昂贵",{"2":{"338":1}}],["然而这样进展太缓慢",{"2":{"73":1}}],["然而这种方法有一个问题",{"2":{"158":1}}],["然而沃尔多的样子并不取决于他潜藏的地方",{"2":{"152":1}}],["然而",{"2":{"27":1,"44":1,"59":1,"62":1,"66":1,"78":1,"120":1,"121":1,"129":1,"146":2,"151":2,"156":1,"158":1,"169":1,"179":1,"183":1,"185":2,"192":1,"202":1,"212":1,"230":1,"231":1,"236":1,"242":1,"252":1,"256":1,"269":1,"270":1,"278":1,"282":1,"284":2,"286":1,"290":1,"302":1,"305":1,"308":1,"316":1,"319":1,"335":1,"347":1,"349":1,"356":1,"373":1,"379":1,"408":1,"422":1,"425":2,"440":1,"446":3,"454":1,"456":1,"457":2,"475":4,"480":1,"493":1,"495":1,"500":1,"513":1,"514":1,"526":1,"561":1,"624":1,"642":1,"660":1,"663":2,"664":1,"688":1,"708":1,"732":2,"734":1,"736":1,"739":1,"756":1,"773":1,"832":2,"857":1,"869":1,"911":1,"975":1,"984":1,"991":1,"1028":1,"1129":1,"1143":2,"1150":1}}],["然后检测新的样本",{"2":{"1180":1}}],["然后检索评级最高的元素",{"2":{"293":1}}],["然后简单说几句想说的话",{"2":{"1176":1}}],["然后丢弃那个样本并继续下去",{"2":{"1168":1}}],["然后丢弃未选择分支的结果",{"2":{"808":1}}],["然后就像我们所看到的",{"2":{"1168":1}}],["然后就牛逼大发了",{"2":{"1059":1}}],["然后保存一个数据集",{"2":{"1168":1}}],["然后他们拒绝购买你的运输服务",{"2":{"1168":1}}],["然后他们告诉你",{"2":{"1168":1}}],["然后他寄给你一张350美元的账单",{"2":{"290":1}}],["然后绘制这些平均值与x次迭代的次数之间的函数图表",{"2":{"1167":1}}],["然后每x次迭代后",{"2":{"1167":1}}],["然后现在我们需要只使用一个实数",{"2":{"1161":1}}],["然后令",{"2":{"1159":1}}],["然后令k个聚类中心分别与这k个训练实例相等",{"2":{"1153":1}}],["然后强烈建议使用高优化软件库中的一个",{"2":{"1148":1}}],["然后做同样地计算",{"2":{"1145":1}}],["然后来观察支持向量机会给出什么结果",{"2":{"1144":1}}],["然后来决定优化的方式",{"2":{"1138":1}}],["然后最小化这个目标函数",{"2":{"1143":1}}],["然后乘以其他项b对吧",{"2":{"1143":1}}],["然后从出现次数最多的情况开始着手优化",{"2":{"1138":1}}],["然后从磁盘加载参数",{"2":{"442":1}}],["然后看应用的整体效果提升了多少",{"2":{"1174":1}}],["然后看分类器对哪一组邮件的预测误差最大",{"2":{"1138":1}}],["然后看看你可以得到什么样的张量",{"2":{"1024":1}}],["然后看看书",{"2":{"355":1}}],["然后启发你如何去提高它",{"2":{"1138":1}}],["然后启动模型",{"2":{"297":1}}],["然后亲自看一看哪些邮件被算法错误地分类",{"2":{"1138":1}}],["然后选择能最好服务于该目的标聚类数",{"2":{"1154":1}}],["然后选择交叉验证集代价最小的神经网络",{"2":{"1135":1}}],["然后选择具有最大输出值的类别argmaxjyj作为我们的预测",{"2":{"643":1}}],["然后也许另一个人说",{"2":{"1129":1}}],["然后花上六个月的时间收集了一大堆数据",{"2":{"1129":1}}],["然后上面的这幅图",{"2":{"1127":1}}],["然后求两个代价的平均",{"2":{"1124":1}}],["然后给出整个训练集的代价函数的定义",{"2":{"1109":1}}],["然后呈递到下一层",{"2":{"1099":1}}],["然后实现它大脑通过自学掌握如何处理这些不同类型的数据",{"2":{"1098":1}}],["然后训练一个逻辑回归算法利用这两个像素的值来判断图片上是否是汽车",{"2":{"1097":1}}],["然后训练算法",{"2":{"185":1}}],["然后利用这些不同的字体配上各种不同的随机背景图片创造出一些用于训练的实例",{"2":{"1173":1}}],["然后利用这些图片上一个个像素的值",{"2":{"1097":1}}],["然后利用该误差运用反向传播法计算出直至第二层的所有误差",{"2":{"1121":1}}],["然后利用交叉熵损失计算模型输出和标签之间的误差",{"2":{"341":1}}],["然后作加和",{"2":{"1093":1}}],["然后除以2m",{"2":{"1092":1}}],["然后设置最大迭代次数",{"2":{"1111":1}}],["然后设置",{"2":{"1092":1}}],["然后当",{"2":{"1092":1}}],["然后开始下面的增量循环",{"2":{"1092":1}}],["然后让alvinn观看",{"2":{"1127":1}}],["然后让",{"2":{"1092":1}}],["然后让处理器1从内存中读取它",{"2":{"810":1}}],["然后运行colormap",{"2":{"1091":1}}],["然后运行",{"2":{"1091":1}}],["然后它会尝试使用这些高级的优化算法",{"2":{"1111":1}}],["然后它就可以为我们最小化这个函数",{"2":{"1111":1}}],["然后它就会立刻告诉你",{"2":{"1094":1}}],["然后它使用第一个格子",{"2":{"1091":1}}],["然后它们的批量矩阵相乘",{"2":{"763":1}}],["然后键入",{"2":{"1090":1}}],["然后键入length",{"2":{"1089":1}}],["然后你的网站开出运输包裹的的服务价格",{"2":{"1168":1}}],["然后你就可以查找课程中提供的程序副本",{"2":{"1089":1}}],["然后你按照自己的判断又迈出一步",{"2":{"1067":1}}],["然后自己在octave",{"2":{"1089":1}}],["然后换行到下面",{"2":{"1089":1}}],["然后得到11",{"2":{"1088":1}}],["然后我来看一看这个线段的长度",{"2":{"1145":1}}],["然后我再画一条同逻辑回归非常相似的直线",{"2":{"1143":1}}],["然后我用θ",{"2":{"1093":1}}],["然后我要用一个",{"2":{"1093":1}}],["然后我要让",{"2":{"1092":1}}],["然后我计算的代价函数",{"2":{"1092":1}}],["然后我做的是v",{"2":{"1090":1}}],["然后我想再梯度下降一步",{"2":{"1068":1}}],["然后我们利用这个新的",{"2":{"1192":1}}],["然后我们也花了很多时间介绍无监督学习",{"2":{"1176":1}}],["然后我们用之前训练识别行人的模型时所采用的图片尺寸在我们要进行行人识别的图片上进行剪裁",{"2":{"1172":1}}],["然后我们将计所的结果汇总在求和",{"2":{"1169":1}}],["然后我们将解释如何使用样式迁移技术来生成像本书封面一样的图像",{"2":{"886":1}}],["然后我们告诉这个算法",{"2":{"1150":1}}],["然后我们选择一个让",{"2":{"1112":1}}],["然后我们选择其中条件概率乘积最高的序列作为输出序列",{"2":{"515":1}}],["然后我们要用",{"2":{"1090":1}}],["然后我们寻找下一个能让代价函数值下降最多的参数组合",{"2":{"1067":1}}],["然后我们会开始学习机器学习的主要问题和算法你会了解一些主要的机器学习的术语",{"2":{"1058":1}}],["然后我们使用此特征作为我们小型自定义输出网络的输入来计算损失",{"2":{"905":1}}],["然后我们通过以下步骤操作排序列表l",{"2":{"854":1}}],["然后我们通过跨层数据通路",{"2":{"501":1}}],["然后我们可以选择只读取一条64位记录还是一长串记录",{"2":{"802":1}}],["然后我们创建一个模型实例",{"2":{"680":1}}],["然后我们打印词表大小",{"2":{"669":1}}],["然后我们",{"2":{"634":1,"853":1}}],["然后我们观察模型在这两部分数据集的性能",{"2":{"286":1}}],["然后我们从零开始实现了softmax回归",{"2":{"228":1}}],["然后我们得出一个估计值f",{"2":{"196":1}}],["然后我们得出了已经准备好在医疗诊断上取得成功的结论",{"2":{"185":1}}],["然后我们得到目标函数",{"2":{"113":1}}],["然后我们保留那些对应样本大于p的节点",{"2":{"172":1}}],["然后我们恰好从x=4开始",{"2":{"103":1}}],["然后同时更新θ0和θ1",{"2":{"1067":1}}],["然后又迈进了一小步",{"2":{"1067":1}}],["然后人工的方法来读出这些点的数值",{"2":{"1066":1}}],["然后输出一个函数",{"2":{"1063":1}}],["然后用javascript加点魔法",{"2":{"1541":1}}],["然后用剩下的正常数据和异常数据混合的数据构成交叉检验集和测试集",{"2":{"1181":1}}],["然后用这个知识",{"2":{"1150":1}}],["然后用逻辑回归或者不带核函数的支持向量机",{"2":{"1148":1}}],["然后用算法推测一个账号是",{"2":{"1060":1}}],["然后用全连接层对其进行处理",{"2":{"135":1}}],["然后成功的机会绝对会高得多所以在本课中",{"2":{"1059":1}}],["然后为它们赋值",{"2":{"1020":1}}],["然后记录目标值的计算",{"2":{"978":1}}],["然后点击",{"2":{"901":1}}],["然后单击",{"2":{"889":1}}],["然后逐步组织",{"2":{"887":1}}],["然后裁剪中央224×224区域作为输入",{"2":{"872":1}}],["然后随机初始化该层的模型参数",{"2":{"870":1}}],["然后向用户推荐购买链接",{"2":{"869":1}}],["然后尝试标记包含该对象的边界框",{"2":{"860":1}}],["然后此函数将返回所有的锚框",{"2":{"848":1}}],["然后判断这些区域中是否包含我们感兴趣的目标",{"2":{"847":1}}],["然后编写与之前相同的代码",{"2":{"819":1}}],["然后与第三个数字相加",{"2":{"809":1}}],["然后由实际的执行核心处理",{"2":{"808":1}}],["然后再计算协方差矩阵",{"2":{"1184":1}}],["然后再把数据输入异常检测算法",{"2":{"1183":1}}],["然后再进行预测",{"2":{"1162":1}}],["然后再分成训练集和测试集",{"2":{"1130":1}}],["然后再一层一层反向求出各层的误差",{"2":{"1121":1}}],["然后再一次想想",{"2":{"1067":1}}],["然后再用temp",{"2":{"1090":1}}],["然后再用这些特征来预测提议区域的类别和边界框",{"2":{"941":1}}],["然后再输入",{"2":{"1089":1}}],["然后再按元素相加",{"2":{"1019":1}}],["然后再将更新后的参数广播给所有gpu",{"2":{"841":1}}],["然后再尝试访问该设备上的参数",{"2":{"829":2}}],["然后再执行程序",{"2":{"822":1}}],["然后再重新写入新的信息",{"2":{"805":1}}],["然后再与位置编码相加",{"2":{"407":5}}],["然后深入查看cpu和gpu",{"2":{"800":1}}],["然后后端将计算结果返回到前端",{"2":{"792":1}}],["然后后端从队列接收计算任务并执行",{"2":{"792":1}}],["然后返回bert输入序列的标记及其相应的片段索引",{"2":{"734":1}}],["然后返回前提",{"2":{"667":1}}],["然后下载punkt语句词元分析器",{"2":{"724":1}}],["然后获得并转换用于下游应用的序列表示",{"2":{"701":1}}],["然后比较和聚合这些信息",{"2":{"673":1}}],["然后读取该层的权重和偏置",{"2":{"595":1}}],["然后分别指定这些序列的有效长度为4",{"2":{"575":1}}],["然后计算比例是否小于1",{"2":{"1160":1}}],["然后计算成本函数或者计算畸变函数j",{"2":{"1154":1}}],["然后计算这个标量变量相对于x的梯度",{"2":{"975":1}}],["然后计算损失函数",{"2":{"927":1}}],["然后计算输出条件概率最高的一个",{"2":{"514":1}}],["然后计算梯度来更新卷积核",{"2":{"129":1}}],["然后观察图形趋势",{"2":{"1130":1}}],["然后观察和分析实验现象",{"2":{"498":1}}],["然后观察实验结果",{"2":{"491":1}}],["然后连接第二个卷积层",{"2":{"488":1}}],["然后才能将其复制到cpu",{"2":{"797":1}}],["然后才能做其他事情",{"2":{"791":1}}],["然后才能继续进行更多的操作",{"2":{"450":1}}],["然后才能执行相加运算",{"2":{"449":1}}],["然后才能访问参数",{"2":{"418":1}}],["然后是一条斜线",{"2":{"1143":1}}],["然后是一个具有10个隐藏单元且不带激活函数的全连接输出层",{"2":{"422":1}}],["然后是3×3",{"2":{"459":1}}],["然后是如何使用多个gpu和多个服务器",{"2":{"445":1}}],["然后展示了如何利用高级api轻松地实现相同的模型",{"2":{"421":1}}],["然后诸如此类",{"2":{"382":4}}],["然后如此复制第二项",{"2":{"382":4}}],["然后继续介绍的是注意力函数",{"2":{"379":1}}],["然后循环神经网络解码器根据生成的词元和上下文变量",{"2":{"373":1}}],["然后把这些插入到梯度下降中",{"2":{"1111":1}}],["然后把这个1向量跟原来的向量相加",{"2":{"1090":1}}],["然后把这个函数的输出结果输入到softmax函数中进行运算",{"2":{"367":1}}],["然后把一个列向量",{"2":{"1089":1}}],["然后把它们读回内存",{"2":{"441":1}}],["然后把坦克开进森林",{"2":{"186":1}}],["然后打印前几个高频词元及其索引",{"2":{"363":1}}],["然后可视化输出注意力权重",{"2":{"359":1}}],["然后可以使用小批量随机梯度下降以及后续小节介绍的其他算法来训练模型",{"2":{"80":1}}],["然后通过如下计算获得要求的新特征向量z",{"2":{"1159":1}}],["然后通过1×1卷积层将通道数变换为类别个数",{"2":{"862":1,"867":1}}],["然后通过求和对它们进行标准化",{"2":{"644":1}}],["然后通过全连接层对特征的表征进行处理",{"2":{"493":1}}],["然后通过一个目标函数在所有t个时间步内",{"2":{"307":1}}],["然后通过某种机制",{"2":{"298":1}}],["然后联合调整它们的性能",{"2":{"302":1}}],["然后对其进行修改",{"2":{"1173":1}}],["然后对其进行微调",{"2":{"685":1}}],["然后对其运行一个学习算法",{"2":{"1168":1}}],["然后对训练集运行学习算法",{"2":{"1162":1}}],["然后对计算结果求平均",{"2":{"1130":1}}],["然后对每一个输入变量",{"2":{"1112":1}}],["然后对该状态进行解码",{"2":{"532":1}}],["然后对比其他替代策略",{"2":{"512":1}}],["然后对这些数据进行调整",{"2":{"300":1}}],["然后对输入张量执行互相关运算",{"2":{"130":1}}],["然后要求用它做一些数据科学研究",{"2":{"296":1}}],["然后根据你开给用户的这个价格",{"2":{"1168":1}}],["然后根据你的cuda版本安装相应的paddlepaddle的gpu版本",{"2":{"445":1}}],["然后根据数值检验的结果来判断哪一种更好",{"2":{"1138":1}}],["然后根据每一个元素与3的大小关系",{"2":{"1090":1}}],["然后根据每个唯一词元的出现频率",{"2":{"363":1}}],["然后根据阈值确定是否为它们分配真实边界框",{"2":{"851":1}}],["然后根据参数计算损失的梯度",{"2":{"604":1}}],["然后根据cuda版本安装相应的mxnet的gpu版本",{"2":{"445":1}}],["然后根据pagerank对包含查询条件的结果进行排序",{"2":{"293":1}}],["然后根据我们的决定",{"2":{"196":1}}],["然后按小时收费",{"2":{"290":1}}],["然后执行k次模型训练和验证",{"2":{"257":1}}],["然后想要用它来监测疗养院中的老人",{"2":{"253":1}}],["然后探索有关该主题的最新出版物",{"2":{"248":1}}],["然后进行主要成分分析",{"2":{"1160":1}}],["然后进行比较",{"2":{"1138":1}}],["然后进行求和来表示两个向量的点积",{"2":{"997":1}}],["然后进行softmax操作",{"2":{"229":1}}],["然后进行二分搜索",{"2":{"62":1}}],["然后这个系统会被安装在客户家中",{"2":{"195":1}}],["然后这家初创公司问我们是否可以帮助他们建立一个用于检测疾病的分类器",{"2":{"185":1}}],["然后",{"2":{"191":1,"195":1,"209":1,"213":1,"287":1,"298":1,"305":1,"306":1,"380":1,"422":1,"423":1,"425":1,"445":1,"472":1,"550":1,"613":1,"633":1,"639":1,"699":2,"713":1,"717":1,"731":1,"750":1,"756":1,"760":1,"840":1,"851":1,"879":1,"903":3,"905":1,"912":1,"917":1,"930":1,"938":2,"963":1,"964":1,"970":1,"1026":1,"1092":1,"1143":1,"1165":1,"1172":1}}],["然后在图片上滑动剪裁区域重新进行剪裁",{"2":{"1172":1}}],["然后在之后的几段视频中",{"2":{"1129":1}}],["然后在利用循环在k​个预测中选择可能性最高的一个",{"2":{"1120":1}}],["然后在计算机上执行大脑学习算法或与之相似的算法",{"2":{"1098":1}}],["然后在下面放上一个",{"2":{"1089":1}}],["然后在收集的图像数据集上训练一个分类模型",{"2":{"869":1}}],["然后在当前时间步将它们和上一隐状态",{"2":{"574":1}}],["然后在时间步3",{"2":{"515":1}}],["然后在给定通道内应用相同的均值和方差",{"2":{"470":1}}],["然后在每次调用前向传播函数时调用这些层",{"2":{"423":1}}],["然后在每个步骤中使用gt",{"2":{"20":1}}],["然后在是或否中生成一个选择作为输出",{"2":{"282":1}}],["然后在2014年",{"2":{"170":1}}],["然后添加一个偏置",{"2":{"132":1}}],["然后将重叠的区域进行合并",{"2":{"1172":1}}],["然后将剪裁得到的切片交给模型",{"2":{"1172":1}}],["然后将数据聚类成不同的组",{"2":{"1151":1}}],["然后将数据发送到下一个gpu",{"2":{"832":1}}],["然后将表示",{"2":{"1102":1}}],["然后将它赋值为10",{"2":{"1089":1}}],["然后将它们的总长度除以16",{"2":{"299":1}}],["然后将我们要预测的房屋的尺寸作为输入变量输入给h",{"2":{"1063":1}}],["然后将锚框的尺度增加到0",{"2":{"912":1}}],["然后将图像移动到按标签分组的子文件夹中",{"2":{"902":1}}],["然后将该区域缩放为224×224输入图像",{"2":{"872":1}}],["然后将该指令转发到cpu或gpu",{"2":{"819":1}}],["然后将所有与b2的iou大于ϵ的非基准预测边界框从l中移除",{"2":{"854":1}}],["然后将所有与b1的iou超过预定阈值ϵ的非基准预测边界框从l中移除",{"2":{"854":1}}],["然后将所有标量汇聚输出连结为向量",{"2":{"701":1}}],["然后将新类别的整数索引递增一",{"2":{"852":1}}],["然后将真实边界框b2分配给锚框a9",{"2":{"851":1}}],["然后将真实边界框b4分配给锚框a5",{"2":{"851":1}}],["然后将真实边界框b1分配给锚框a7",{"2":{"851":1}}],["然后将真实边界框bj1分配给锚框ai1",{"2":{"851":1}}],["然后将指令从汇编代码解码为微指令",{"2":{"808":1}}],["然后将结果除以该通道的标准差",{"2":{"872":1}}],["然后将结果从处理器移回到随机访问存储和持久存储器中",{"2":{"801":1}}],["然后将结果复制回cpu来模拟这个过程",{"2":{"797":1}}],["然后将结果相加",{"2":{"120":1}}],["然后将此输出送入交叉熵损失",{"2":{"624":1}}],["然后将第一层的输出作为第二层的输入",{"2":{"591":1}}],["然后将第三个神经网络层初始化为常量值42",{"2":{"435":1}}],["然后将不同的行为作为知识组合起来",{"2":{"380":1}}],["然后将这些信息发送到轴突y中进一步处理",{"2":{"619":1}}],["然后将这些块组合到更大的块中",{"2":{"433":1}}],["然后将这些用于反向传播",{"2":{"165":1}}],["然后将这两个乘法相加",{"2":{"340":1}}],["然后将其他所有类都标记为负向类",{"2":{"1112":1}}],["然后将其转成卷积层需要的四维格式",{"2":{"964":1}}],["然后将其缩放为高度和宽度均为32像素的正方形",{"2":{"891":3}}],["然后将其加载到内存中",{"2":{"584":4,"777":3}}],["然后将其参数化为通用形式",{"2":{"520":1}}],["然后将其除以整个语料库中的单词总数",{"2":{"316":1}}],["然后将其推荐给用户",{"2":{"294":1}}],["然后将其用作调整学习率",{"2":{"25":1}}],["然后舍去低阶项",{"2":{"115":1}}],["然后使它在多类别分类问题中也能正常运行",{"2":{"1111":1}}],["然后使y指向内存中的这个新位置",{"2":{"1021":1}}],["然后使用这些信息来优化一些关于网站的决策",{"2":{"1168":1}}],["然后使用逻辑回归或不带核函数的支持向量机",{"2":{"1148":1}}],["然后使用比梯度下降更复杂的算法来最小化代价函数",{"2":{"1111":1}}],["然后使用corr2d函数计算卷积输出y",{"2":{"970":1}}],["然后使用cpu进行计算",{"2":{"452":1}}],["然后使用cpu计算它",{"2":{"446":1}}],["然后使用较大的锚框来检测较大的目标",{"2":{"912":1}}],["然后使用该模型提取图像特征",{"2":{"905":1}}],["然后使用聚合后的梯度来更新参数",{"2":{"843":1}}],["然后使用被tensorflow团队称为autograph的特性将它们封装",{"2":{"818":1}}],["然后使用优化算法训练模型",{"2":{"637":1}}],["然后使用weight和bias方法访问参数",{"2":{"592":1}}],["然后使用weight",{"2":{"592":1}}],["然后使用1×1卷积层来改变通道数",{"2":{"487":1}}],["然后使用它",{"2":{"959":1}}],["然后使用它的参数来设置另一个层的参数",{"2":{"437":1}}],["然后使用它们连续迭代x",{"2":{"54":1}}],["然后使用数据集来确定当下的",{"2":{"282":1}}],["然后使其迅速上涨",{"2":{"114":1}}],["然后一次计算a的一个区块",{"2":{"77":1}}],["然后冷却直到优化过程结束",{"2":{"73":1}}],["然后取ϵ=−ηf",{"2":{"54":1}}],["用指标验证改动",{"2":{"1544":1}}],["用法",{"2":{"1511":1,"1512":1,"1515":1,"1516":1}}],["用在组件标签上",{"2":{"1468":2}}],["用在普通dom标签上",{"2":{"1468":2}}],["用watcheffect实现",{"2":{"1467":1}}],["用watch实现",{"2":{"1467":1}}],["用所有的特征一起来计算",{"2":{"1184":1}}],["用厘米表示",{"2":{"1156":1}}],["用c",{"2":{"1151":1}}],["用ci和co分别表示输入和输出通道的数目",{"2":{"121":1}}],["用μ1",{"2":{"1151":1}}],["用相似的方法",{"2":{"1143":1}}],["用数值来判断哪一个模型更好更有效",{"2":{"1138":1}}],["用数学语言描述",{"2":{"367":1}}],["用12个模型分别对交叉验证集计算的出交叉验证误差",{"2":{"1133":1}}],["用10个模型分别对交叉验证集计算得出交叉验证误差",{"2":{"1131":1}}],["用步骤3中选出的模型对测试集计算得出推广误差",{"2":{"1131":1}}],["用剩下30",{"2":{"1130":1}}],["用以解决svm最优化问题的软件很复杂",{"2":{"1148":1}}],["用以估计在",{"2":{"1124":1}}],["用以理解现代深度学习的线性代数",{"2":{"1002":1}}],["用一对多的分类思想",{"2":{"1112":1}}],["用一个叉来表示这个样本x",{"2":{"1145":1}}],["用一个空格替换两个或多个连续的空格",{"2":{"667":1}}],["用一个小例子来",{"2":{"369":1}}],["用一个较简单的表达式约束一个较复杂的表达式",{"2":{"42":1}}],["用类似于鸟类感知方向的方式",{"2":{"1098":1}}],["用这个做预测",{"2":{"1112":1}}],["用这个式子来更新",{"2":{"1110":1}}],["用这个例子说明",{"2":{"1093":1}}],["用这个命令",{"2":{"1091":1}}],["用逗号连接是另一种octave中更便捷的方式",{"2":{"1091":1}}],["用命令close会让这个图像关掉",{"2":{"1091":1}}],["用rand命令建立一个一行三列的矩阵",{"2":{"1088":1}}],["用relu替换本节中使用的激活函数",{"2":{"337":1}}],["用较少的特征来反映尽可能多内容",{"2":{"1086":1}}],["用较小的学习率来补偿带有较大梯度的坐标",{"2":{"30":1}}],["用小碎步尽快下山",{"2":{"1067":1}}],["用小批量随机梯度下降法更新参数",{"2":{"635":1}}],["用术语来讲",{"2":{"1060":2}}],["用二次方程去拟合可能效果会更好",{"2":{"1060":1}}],["用哪种算法更合适",{"2":{"1058":1}}],["用语言模型进行任务选择",{"2":{"1052":1}}],["用其他形状",{"2":{"1024":1}}],["用向量表示物品",{"2":{"1001":1}}],["用行向量ai⊤∈rk表示矩阵a的第i行",{"2":{"999":1}}],["用卷积神经网络对每个提议区域进行前向传播以抽取其特征",{"2":{"937":1}}],["用卷积层代替全连接层的另一个好处是",{"2":{"135":1}}],["用内容图像来初始化合成图像",{"2":{"927":1}}],["用多gpu进行模型训练",{"2":{"883":3}}],["用多gpu进行小批量训练",{"2":{"883":3}}],["用双线性插值的上采样初始化转置卷积层",{"2":{"863":1}}],["用左上角和右下角的坐标进行标记",{"2":{"853":1}}],["用gw表示其长度在3和6之间的所有子词与其特殊子词的并集",{"2":{"756":1}}],["用gpu训练神经网络改变了这一格局",{"2":{"457":1}}],["用gpu训练模型",{"2":{"137":4}}],["用vec",{"2":{"751":1}}],["用权重函数h",{"2":{"743":1}}],["用qij表示词wj的条件概率p",{"2":{"742":1}}],["用bert表示文本",{"0":{"727":1}}],["用随机词替换该词",{"2":{"721":1}}],["用随机变量来代替权重",{"2":{"300":1}}],["用name跳转",{"2":{"1482":1}}],["用name也可以跳转",{"2":{"1481":1}}],["用nk表示噪声词wk",{"2":{"708":1}}],["用n表示训练集中的单词总数",{"2":{"316":1}}],["用s表示上下文词wo来自中心词wc的上下文窗口的事件",{"2":{"708":1}}],["用a=",{"2":{"674":1}}],["用矩阵和向量表示法写出优化问题",{"2":{"621":1}}],["用模型拟合观测数据的过程",{"2":{"980":1}}],["用模型进行预测",{"0":{"614":1}}],["用模型参数声明层",{"2":{"423":4}}],["用符号表示的矩阵x∈rn×d",{"2":{"610":1}}],["用长短期记忆网络替换门控循环单元重新运行实验",{"2":{"580":1}}],["用门控循环单元或长短期记忆网络的隐状态",{"2":{"527":1}}],["用y表示输出词表",{"2":{"512":1}}],["用图中的",{"2":{"479":1}}],["用当前的均值和方差做标准化",{"2":{"472":2}}],["用神经网络来设计注意力机制的框架",{"2":{"356":1}}],["用huber损失代替原损失",{"2":{"597":1}}],["用ht∈rn×h",{"2":{"340":1}}],["用h∈rn×h表示隐藏层的输出",{"2":{"232":1}}],["用可学习的嵌入表示替换独热编码",{"2":{"337":1}}],["用m表示唯一单词的数量",{"2":{"316":1}}],["用l",{"2":{"312":1,"709":1}}],["用概率论术语来说",{"2":{"289":1}}],["用平均值替换缺失值总是好主意吗",{"2":{"215":1}}],["用均值替换缺失值",{"2":{"214":1}}],["用对数几率回归训练二元分类器得到函数h",{"2":{"191":1}}],["用近乎完美的精度来区分健康和患病人群确实很容易",{"2":{"185":1}}],["用来与",{"2":{"1392":1}}],["用来判断某些计算机是不是有可能出错了",{"2":{"1178":1}}],["用来表示这是第",{"2":{"1145":1}}],["用来在类似numpy的环境中实现深度学习开发",{"2":{"1017":1}}],["用来将图像大小调整为另一种形状",{"2":{"584":1}}],["用来将字符串类型的词元映射到从0开始的数字索引中",{"2":{"363":1}}],["用来代替全连接层",{"2":{"492":1}}],["用来量化模型的有效性",{"2":{"283":1}}],["用来度量",{"2":{"190":1}}],["用来预测谁将偿还贷款或违约",{"2":{"179":1}}],["用来确保我们不会除以0",{"2":{"27":1}}],["用于获取一个响应式对象的原始对象",{"2":{"1518":1}}],["用于获取和读取fashion",{"2":{"584":1}}],["用于创建一个对象的深只读副本",{"2":{"1515":1}}],["用于创建pinia",{"2":{"1489":1}}],["用于更新money的方法",{"2":{"1503":1}}],["用于注册模板引用",{"2":{"1468":1}}],["用于为变量",{"2":{"1397":1}}],["用于多租户或资源划分",{"2":{"1387":1}}],["用于持久化存储",{"2":{"1386":1}}],["用于声明式更新应用",{"2":{"1383":1}}],["用于自动化容器化应用的",{"2":{"1374":1}}],["用于自然语言推断的微调bert只需要一个额外的多层感知机",{"2":{"688":1}}],["用于管理大规模容器集群",{"2":{"1350":1}}],["用于构建和运行单个容器",{"2":{"1350":1}}],["用于存储集群状态",{"2":{"1376":1}}],["用于存储镜像",{"2":{"1340":1}}],["用于存储和检索计算结果",{"2":{"801":1}}],["用于打包",{"2":{"1339":1}}],["用于团队协作",{"2":{"1324":1}}],["用于同步",{"2":{"1319":1}}],["用于记录文件的修改历史",{"2":{"1318":1}}],["用于在不修改原函数代码的前提下",{"2":{"1244":1}}],["用于在相邻区域汇聚信息的汇聚层",{"2":{"134":1}}],["用于数据变换与聚合",{"2":{"1240":1}}],["用于简洁表达短小的函数",{"2":{"1239":1}}],["用于简化计算",{"2":{"1147":1}}],["用于判断条件是否满足",{"2":{"1223":1}}],["用于降维的主成分分析",{"2":{"1176":1}}],["用于帮助确定将要生产的t",{"2":{"1151":1}}],["用于帮助组织指令",{"2":{"810":1}}],["用于逻辑回归上的一个方差",{"2":{"1141":1}}],["用于说明我们的确定程度",{"2":{"1025":1}}],["用于表示颜色通道",{"2":{"993":1}}],["用于表示序列的结束",{"2":{"568":1}}],["用于逆转下采样导致的空间尺寸减小",{"2":{"967":1}}],["用于目标检测的数据加载与图像分类的数据加载类似",{"2":{"934":1}}],["用于衡量两个边界框的相似性",{"2":{"855":1}}],["用于取得聚合梯度",{"2":{"844":1}}],["用于累积梯度",{"2":{"844":1}}],["用于测量运行时间",{"2":{"820":1}}],["用于每个通道点到点连接的高带宽需求",{"2":{"812":1}}],["用于连接不同组件",{"2":{"807":1}}],["用于执行机器代码的",{"2":{"807":1}}],["用于系统连接一个或多个gpu",{"2":{"801":1}}],["用于计算机视觉技术的滑动窗口分类算法",{"2":{"1176":1}}],["用于计算条件概率",{"2":{"783":1}}],["用于计算当前时间步t的输出ot",{"2":{"340":1}}],["用于预训练词嵌入的数据集",{"0":{"771":1},"1":{"772":1,"773":1,"774":1,"775":1,"776":1,"777":1,"778":1,"779":1}}],["用于预训练bert的数据集",{"0":{"718":1},"1":{"719":1,"720":1,"721":1,"722":1,"723":1,"724":1}}],["用于下一句预测的多层感知机分类器的隐藏层",{"2":{"738":3}}],["用于分隔",{"2":{"727":1}}],["用于分类",{"2":{"727":1}}],["用于遮蔽语言模型和下一句预测",{"2":{"725":1}}],["用于加载snli数据集的自定义数据集",{"2":{"668":3}}],["用于序列分类",{"2":{"657":1}}],["用于序列到序列的学习",{"2":{"576":1}}],["用于序列到序列学习的循环神经网络解码器",{"2":{"574":4}}],["用于序列到序列学习的循环神经网络编码器",{"2":{"573":4}}],["用于序列到序列学习",{"2":{"373":1}}],["用于对多个变量进行累加",{"2":{"634":1}}],["用于对抗过拟合的技术称为正则化",{"2":{"251":1}}],["用于将两种翻译模型区分开来",{"2":{"564":1}}],["用于将编码器的输出",{"2":{"534":1}}],["用于将输入按追加块的顺序传递给块组成的",{"2":{"424":1}}],["用于机器翻译",{"2":{"522":1}}],["用于命名实体识别",{"2":{"522":1}}],["用于调试",{"2":{"429":1}}],["用于保存那些被保留的词元",{"2":{"363":1}}],["用于训练的代码需要执行几个基本功能才能实现高效并行",{"2":{"828":1}}],["用于训练注意力模型",{"2":{"392":1}}],["用于训练",{"2":{"209":1}}],["用于训练和预测的内存占用",{"2":{"167":1}}],["用于近似真实风险",{"2":{"202":1}}],["用于估计神经网络预测的",{"2":{"171":1}}],["用于汇总过去梯度的历史以加速收敛",{"2":{"32":1}}],["用",{"2":{"115":1,"1060":2,"1110":1,"1112":2,"1543":2}}],["用与时间相关的学习率η",{"2":{"114":1}}],["用不同的学习率和目标函数进行梯度下降实验",{"2":{"64":1}}],["用x∈b表示一个来自小批量b的输入",{"2":{"467":1}}],["用xt表示价格",{"2":{"346":1}}],["用x",{"2":{"60":1}}],["用定制的训练机优化2d目标函数",{"2":{"57":2}}],["用pandas处理缺失的数据时",{"2":{"1014":1}}],["用pn表示n元语法的精确度",{"2":{"578":1}}],["用p",{"2":{"52":1}}],["用每个变量的期望值计算这个函数的总值",{"2":{"51":1}}],["用户执行",{"2":{"1340":1}}],["用户交互入口",{"2":{"1340":1}}],["用户",{"2":{"1188":1}}],["用户多久登录一次",{"2":{"1178":1}}],["用户的第个活动特征x",{"2":{"1178":1}}],["用户选择2项",{"2":{"1168":1}}],["用户有时会接受这个运输服务",{"2":{"1168":1}}],["用户们来向你询问把包裹从a地运到b地的服务",{"2":{"1168":1}}],["用户将文本读入语音识别器",{"2":{"297":1}}],["用户阅读网页的顺序",{"2":{"295":1}}],["用户更倾向于给他们感觉强烈的事物打分",{"2":{"294":1}}],["用户通过web浏览器",{"2":{"281":1}}],["用户可以用各种前端语言编写python程序",{"2":{"790":1}}],["用户可以用各种前端语言编写pytorch程序",{"2":{"790":1}}],["用户可以用各种前端语言编写mxnet程序",{"2":{"790":1}}],["用户可以创建",{"2":{"11":1}}],["用户可能会做什么",{"2":{"203":1}}],["用户认证",{"2":{"11":1}}],["用户还可以注册和登录应用程序",{"2":{"10":1}}],["也避免了读写冲突",{"2":{"1200":1}}],["也谈到了解决方差问题的正则化",{"2":{"1176":1}}],["也采用对训练集学习而来的ureduce",{"2":{"1162":1}}],["也即是对于b项而言",{"2":{"1143":1}}],["也即斜率",{"2":{"1068":1}}],["也相同的",{"2":{"1143":1}}],["也重复进行这个训练过程",{"2":{"1127":1}}],["也希望通过这段视频",{"2":{"1122":1}}],["也希望我展示的这些命令能让你很快地学会怎样把矩阵放到一起",{"2":{"1089":1}}],["也将是下一层的第j个输入变量的下标",{"2":{"1121":1}}],["也将执行类似地操作",{"2":{"816":1}}],["也只有一个因变量y",{"2":{"1120":1}}],["也只有这样才能通过降低学习率来减小参数的固有方差",{"2":{"74":1}}],["也适用于逻辑回归",{"2":{"1110":1}}],["也适用于用神经网络预测",{"2":{"78":1}}],["也叫线性核函数",{"2":{"1148":1}}],["也叫激活单元",{"2":{"1099":1}}],["也叫验证集",{"2":{"256":1}}],["也为",{"2":{"1092":1,"1109":2}}],["也没有电影的特征",{"2":{"1189":1}}],["也没有关系",{"2":{"1086":1,"1089":1}}],["也没什么关系",{"2":{"1066":1}}],["也能写函数",{"2":{"1465":1}}],["也能在分布式场景下支撑互联网级应用",{"2":{"1211":1}}],["也能得到更加厉害的特征值",{"2":{"1102":1}}],["也能得到一样的结果",{"2":{"1092":1}}],["也能解出代价函数j的最小值",{"2":{"1069":1}}],["也能保证模型不会发散",{"2":{"335":1}}],["也许不久以前我也是一个学生",{"2":{"1176":1}}],["也许不是两个分开的特征x1和x2",{"2":{"1156":1}}],["也许便能看出下降的趋势了",{"2":{"1167":1}}],["也许x2可能是飞行员的爱好",{"2":{"1156":1}}],["也许一个工程队给你二百个特征",{"2":{"1156":1}}],["也许在这个体系里",{"2":{"1148":1}}],["也许我最终会得到一条类似这样的决策界",{"2":{"1144":1}}],["也许我们只用1000个训练集也能获得较好的效果",{"2":{"1164":1}}],["也许我们想要做的是减少数据到一维",{"2":{"1156":1}}],["也许我们将选择这样的决策界",{"2":{"1144":1}}],["也许我们需要做的就是找出一些近似的或实际的大脑学习算法",{"2":{"1098":1}}],["也许目前的特征集",{"2":{"1129":1}}],["也许有很多特征",{"2":{"1129":1}}],["也许你是一个很忙的人",{"2":{"1176":1}}],["也许你在数据库中存储了许多客户的信息",{"2":{"1150":1}}],["也许你能想到通过电话调查或上门调查来获取更多的不同的房屋出售数据",{"2":{"1129":1}}],["也许你可以花一点时间从这些特征中仔细挑选一小部分来防止过拟合",{"2":{"1129":1}}],["也许你可以告诉你的朋友",{"2":{"1063":1}}],["也许你可能会深入地探索下去",{"2":{"1086":1}}],["也许超过十年了",{"2":{"1111":1}}],["也许这两个特征将高度相关",{"2":{"1156":1}}],["也许这个方程看起来不是非常熟悉",{"2":{"1143":1}}],["也许这个函数j",{"2":{"1064":1}}],["也许这将是我们向人工智能迈进做出的最好的尝试",{"2":{"1098":1}}],["也许",{"2":{"1098":1}}],["也许它会带我到这个点",{"2":{"1068":1}}],["也许是条直线",{"2":{"1063":1}}],["也许会偶然发现甚至发明一个聪明的想法",{"2":{"248":1}}],["也未告知每个数据点是什么",{"2":{"1061":1}}],["也比较古老",{"2":{"1059":1}}],["也通过平方误差函数衡量合成图像与风格图像在风格上的差异",{"2":{"923":1}}],["也很难增加",{"2":{"804":1}}],["也很容易过拟合只包含一两个样本的数据集",{"2":{"254":1}}],["也等价于求和",{"2":{"611":1}}],["也允许我们创建自定义初始化方法",{"2":{"434":1}}],["也被称为杰卡德系数",{"2":{"855":1}}],["也被称为cpu",{"2":{"801":1}}],["也被称为内部注意力",{"2":{"395":1}}],["也被用于自动调整超参数",{"2":{"198":1}}],["也就等于把",{"2":{"1090":1}}],["也就有很多不同的梯度集合",{"2":{"844":1}}],["也就",{"2":{"388":1}}],["也就是出发地与目的地",{"2":{"1168":1}}],["也就是聚类类别数目的总数",{"2":{"1154":1}}],["也就是代价cost0",{"2":{"1143":1}}],["也就是cost1",{"2":{"1143":1}}],["也就是我用紫红色画的曲线",{"2":{"1143":1}}],["也就是我们这几个简单的训练集",{"2":{"1092":1}}],["也就是我们刚刚所输出的正弦函数",{"2":{"1091":1}}],["也就是我们前面得出的平方误差函数",{"2":{"1068":1}}],["也就是−log⁡",{"2":{"1143":1}}],["也就是相当于θtx增大时",{"2":{"1143":1}}],["也就是到了10亿规模的训练集的样本",{"2":{"1141":1}}],["也就是最小化代价函数j的值",{"2":{"1129":1}}],["也就是最后一个参数1的意思",{"2":{"1091":1}}],["也就是训练一个人驾驶汽车",{"2":{"1127":1}}],["也就是训练样本数的两倍",{"2":{"1092":1}}],["也就是中心稍微向左一点的位置",{"2":{"1127":1}}],["也就是首先计算最后一层的误差",{"2":{"1121":1}}],["也就是上图中红色直线所示的情况",{"2":{"1115":1}}],["也就是每一个数据在输出层都会出现",{"2":{"1103":1}}],["也就是y=1",{"2":{"1103":1}}],["也就是自己写代码更新θ0",{"2":{"1093":1}}],["也就是imagesc",{"2":{"1091":1}}],["也就是设置了右边图的x轴和y轴的范围",{"2":{"1091":1}}],["也就是前两个参数",{"2":{"1091":1}}],["也就是1",{"2":{"1090":1}}],["也就是将",{"2":{"1090":1}}],["也就是对每个元素进行求对数运算",{"2":{"1090":1}}],["也就是",{"2":{"1089":2,"1090":1,"1092":1,"1160":1,"1180":1}}],["也就是用这个命令生成的",{"2":{"1089":1}}],["也就是用来进行预测的函数",{"2":{"1064":1}}],["也就是第一个样本的平方误差",{"2":{"1092":1}}],["也就是第二个格子",{"2":{"1091":1}}],["也就是第",{"2":{"1080":1}}],["也就是新的θ1等于原来的θ1",{"2":{"1068":1}}],["也就是这个任务t的系统性能",{"2":{"1059":1}}],["也就是单步预测",{"2":{"351":1}}],["也就是所谓的不常用单词",{"2":{"318":1}}],["也就是说当你在开发一个机器学习系统时",{"2":{"1176":1}}],["也就是说训练误差有希望接近测试误差",{"2":{"1141":1}}],["也就是说在高方差",{"2":{"1134":1}}],["也就是说在高偏差",{"2":{"1134":1}}],["也就是说使汽车通过学习来自己驾驶",{"2":{"1127":1}}],["也就是说运行速度更快",{"2":{"1093":1}}],["也就是说我取的是a矩阵的第一行和第三行的每一列",{"2":{"1089":1}}],["也就是说它有正导数",{"2":{"1068":1}}],["也就是说∥x∥等同于∥x∥2",{"2":{"1000":1}}],["也就是说",{"2":{"27":1,"33":1,"55":1,"59":1,"62":1,"77":2,"78":2,"94":2,"105":1,"108":1,"113":1,"115":1,"116":1,"130":1,"142":1,"146":1,"154":1,"156":1,"197":1,"254":1,"295":1,"298":1,"302":1,"308":1,"334":1,"347":1,"349":1,"479":1,"522":1,"527":1,"618":1,"621":1,"651":1,"802":2,"805":1,"806":1,"810":1,"816":1,"819":1,"832":2,"835":1,"842":1,"844":1,"848":1,"1017":1,"1027":1,"1035":1,"1090":1,"1107":1,"1110":1,"1129":1,"1150":1,"1182":1}}],["也称为正态分布",{"2":{"1179":1}}],["也称为点击流数据",{"2":{"1058":1}}],["也称为张量",{"2":{"1016":1}}],["也称为高斯分布",{"2":{"616":1}}],["也称为平方l2范数",{"2":{"593":3}}],["也称为数据",{"2":{"354":1}}],["也称为隐藏变量",{"2":{"338":1}}],["也称为反向传播",{"2":{"299":1}}],["也称黑塞矩阵",{"2":{"102":1}}],["也有负样本",{"2":{"1144":1}}],["也有效得多的代码",{"2":{"1093":1}}],["也有一些控制输出长短格式的快捷命令",{"2":{"1088":1}}],["也有一些自动测试是否收敛的方法",{"2":{"1083":1}}],["也有可能是特征数量大于训练集的数量",{"2":{"1085":1}}],["也有两个门用于这样的目的",{"2":{"555":1}}],["也有敏锐的直觉",{"2":{"299":1}}],["也有更多的特征",{"2":{"205":1}}],["也不存在一个被广泛认可的定义来准确定义机器学习是什么或不是什么",{"2":{"1059":1}}],["也不能被赋值",{"2":{"1020":1}}],["也不能保证期末考试成功",{"2":{"286":1}}],["也不必手动实现小批量随机梯度下降",{"2":{"595":1}}],["也不愿错误地分入一个遥远的类别",{"2":{"291":1}}],["也会启发你如何改进你的学习算法",{"2":{"1091":1}}],["也会经常遇到",{"2":{"1000":1}}],["也会显著增加我们模型的复杂性",{"2":{"269":1}}],["也会发生变化",{"2":{"87":1}}],["也仍在继续困扰着学习理论领域最伟大的学者们",{"2":{"253":1}}],["也按元素操作",{"2":{"232":1}}],["也可写成函数",{"2":{"1465":1}}],["也可用于自定义资源管理对象",{"2":{"1252":1}}],["也可用于权限校验",{"2":{"1244":1}}],["也可使用很多的特征来找到很多合适的参数",{"2":{"1086":1}}],["也可指定创建类型为浮点数",{"2":{"1017":2}}],["也可以结合其官方支持的路由",{"2":{"1526":1}}],["也可以更换value",{"2":{"1500":2}}],["也可以分成5个尺寸xs",{"2":{"1154":1}}],["也可以生成新密码",{"2":{"1094":1}}],["也可以用",{"2":{"1350":1}}],["也可以用于异常检测算法的评估",{"2":{"1176":1}}],["也可以用它来调整学习速率α的大小",{"2":{"1167":1}}],["也可以用来生成矩阵",{"2":{"1088":1}}],["也可以用disp命令显示",{"2":{"1088":1}}],["也可以通过",{"2":{"800":1}}],["也可以看作词的特征向量",{"2":{"787":1}}],["也可以只求同一个轴上的元素",{"2":{"631":1}}],["也可以称为梯度",{"2":{"613":1}}],["也可以称为数据点",{"2":{"609":1}}],["也可以写成πt+1=f",{"2":{"519":1}}],["也可以应用到所有层",{"2":{"467":1}}],["也可以使用指定的非零值来替换这些项",{"2":{"575":1}}],["也可以使用二维张量",{"2":{"368":1}}],["也可以使用高级api来实现",{"2":{"335":1}}],["也可以是形状为",{"2":{"858":1}}],["也可以是框架的内置优化函数",{"2":{"635":1}}],["也可以是包含多个句子的一个段落",{"2":{"565":1}}],["也可以是深度学习框架中内置的优化函数",{"2":{"335":1}}],["也可以是部分观察到的",{"2":{"298":1}}],["也可以说是变量幂的乘积",{"2":{"269":1}}],["也可以修改学习率",{"2":{"227":1}}],["也可能",{"2":{"1311":1}}],["也可能是5万",{"2":{"1148":1}}],["也可能是负值",{"2":{"1145":1}}],["也可能有2000维",{"2":{"592":2}}],["也可能非常小",{"2":{"241":1}}],["也可能很大",{"2":{"241":1}}],["也可能已经比不做任何事情好得多",{"2":{"26":1}}],["也来自训练分布",{"2":{"192":1}}],["也发生了类似的事情",{"2":{"186":1}}],["也使它们在图结构数据和推荐系统中发挥作用",{"2":{"134":1}}],["也是有效的",{"2":{"1407":1}}],["也是上面所介绍过的那条线",{"2":{"1143":1}}],["也是能得到正确答案的",{"2":{"1093":1}}],["也是可以的",{"2":{"1089":1}}],["也是一个连续的值",{"2":{"1060":1}}],["也是一个单文本分类的数据集",{"2":{"657":1}}],["也是值",{"2":{"374":1}}],["也是人工智能的一种方法",{"2":{"302":1}}],["也是关于x的最小值",{"2":{"102":1}}],["也是凸函数",{"2":{"52":1}}],["如本",{"2":{"1529":1}}],["如本节前面部分所示",{"2":{"959":1}}],["如密码",{"2":{"1385":1}}],["如环境变量",{"2":{"1385":1}}],["如副本数维护",{"2":{"1376":1}}],["如爬取天气信息",{"2":{"1304":1}}],["如θ",{"2":{"1188":1}}],["如x",{"2":{"1188":1}}],["如x1代表电影的浪漫程度",{"2":{"1188":1}}],["如xor",{"2":{"1088":1}}],["如按",{"2":{"1185":1}}],["如洋红色线所示",{"2":{"1167":1}}],["如你所知",{"2":{"1161":1}}],["如硅谷",{"2":{"1148":1}}],["如0",{"2":{"1140":2}}],["如c++",{"2":{"1093":1}}],["如cpu和gpu",{"2":{"446":1}}],["如房价预测问题",{"2":{"1084":1}}],["如矩阵",{"2":{"1077":1}}],["如同时包含英尺为单位的尺寸和米为单位的尺寸两个特征",{"2":{"1085":1}}],["如同数的乘法中的1",{"2":{"1076":1}}],["如同我们先前在多层感知机中所做的那样",{"2":{"153":1}}],["如m为行",{"2":{"1072":1}}],["如web搜索",{"2":{"1058":1}}],["如w1",{"2":{"613":1}}],["如科研",{"2":{"1054":1}}],["如通过",{"2":{"1042":1}}],["如骰子的每一面",{"2":{"1028":1}}],["如list",{"2":{"1007":1}}],["如l1范数",{"2":{"1003":1}}],["如减半",{"2":{"953":1}}],["如减少到1",{"2":{"586":1}}],["如偏移量",{"2":{"937":1}}],["如锚框也是一种选取方法",{"2":{"937":1}}],["如拉布拉多",{"2":{"900":1}}],["如椅子数据集",{"2":{"870":1}}],["如歹徒或者炸弹",{"2":{"857":1}}],["如以上结果所示",{"2":{"820":4}}],["如云中的c5实例",{"2":{"812":1}}],["如存储和以太网",{"2":{"812":1}}],["如tpu",{"2":{"811":1}}],["如transformer",{"2":{"561":1}}],["如nvidia",{"2":{"802":1}}],["如nvidia的rtx和titan系列",{"2":{"802":1}}],["如n95口罩",{"2":{"660":1}}],["如磁盘驱动器",{"2":{"801":1}}],["如权重向量和激活参数",{"2":{"801":1}}],["如权重衰减",{"2":{"205":1}}],["如一个或者多个gpu",{"2":{"801":1}}],["如一条文本行",{"2":{"362":1}}],["如多个gpu和多个cpu",{"2":{"798":1}}],["如多层感知机",{"2":{"300":1,"663":1}}],["如中心词偏置bi和上下文词偏置cj",{"2":{"744":1}}],["如共现计数",{"2":{"741":1}}],["如elmo和gpt",{"2":{"739":1}}],["如命名实体识别",{"2":{"733":1}}],["如bertlarge",{"2":{"729":1}}],["如情感分析",{"2":{"713":1,"733":1,"734":1}}],["如相邻像素",{"2":{"698":1}}],["如产品研究和品牌管理",{"2":{"691":1}}],["如产品评论",{"2":{"691":1}}],["如市场情绪分析",{"2":{"691":1}}],["如公众对政策的情绪分析",{"2":{"691":1}}],["如前提和假设",{"2":{"681":1}}],["如前所述",{"2":{"302":1,"558":1,"568":1,"828":1}}],["如文本序列或图像",{"2":{"681":1}}],["如文本标注和问答",{"2":{"656":1}}],["如单个文本分类",{"2":{"661":1}}],["如单词和字符",{"2":{"360":1}}],["如单词",{"2":{"347":1,"1001":1}}],["如语义文本相似性",{"2":{"658":1}}],["如选择具有最大概率的标签",{"2":{"643":1}}],["如gdp",{"2":{"1157":1}}],["如gunrock",{"2":{"811":1}}],["如gmail必须将电子邮件分类为",{"2":{"634":1}}],["如gpu",{"2":{"472":1}}],["如我们在",{"2":{"623":1}}],["如我们所见",{"2":{"59":1,"418":1,"574":1,"733":1}}],["如随机初始化",{"2":{"613":1}}],["如噪声遵循正态分布",{"2":{"609":1}}],["如自然语言推断",{"2":{"683":1,"733":1,"734":1}}],["如自然语言处理和语音",{"2":{"422":1}}],["如自动语音识别",{"2":{"550":1}}],["如学习率和修剪",{"2":{"530":1}}],["如长短期记忆网络",{"2":{"530":1}}],["如长短期记忆模型",{"2":{"312":1}}],["如vgg",{"2":{"511":1}}],["如最大汇聚层",{"2":{"507":1}}],["如仿射",{"2":{"501":1}}],["如图中样本x",{"2":{"1161":1}}],["如图表所示",{"2":{"1061":1}}],["如图",{"2":{"501":1,"783":1,"1064":1,"1072":1,"1082":1,"1161":1,"1185":1}}],["如图像",{"2":{"192":1}}],["如翻转",{"2":{"461":1}}],["如线性方法和核方法",{"2":{"456":1}}],["如线性判别分析",{"2":{"299":1}}],["如人的体重和身高",{"2":{"1028":1}}],["如人",{"2":{"455":1}}],["如人脸识别",{"2":{"253":1}}],["如眼睛",{"2":{"455":1}}],["如sift",{"2":{"454":1}}],["如支持向量机",{"2":{"454":1}}],["如全连接层的类",{"2":{"423":1}}],["如迭代周期数",{"2":{"337":1}}],["如苹果的siri",{"2":{"301":1}}],["如pci",{"2":{"798":1}}],["如python和c++",{"2":{"790":2}}],["如python",{"2":{"790":1}}],["如paypal",{"2":{"301":1}}],["如pid的变体",{"2":{"198":1}}],["如dropout",{"2":{"300":1}}],["如费舍尔信息矩阵",{"2":{"299":1}}],["如垃圾邮件过滤或玩游戏",{"2":{"297":1}}],["如上面左下图中红线所示",{"2":{"1167":1}}],["如上面左下图中蓝线所示",{"2":{"1167":1}}],["如上面的mlp类",{"2":{"423":1}}],["如上面的例子所示",{"2":{"351":1}}],["如上图的x2",{"2":{"1080":1}}],["如上这些都是热门的序列学习研究领域",{"2":{"295":1}}],["如上所述重新缩放剩余部分",{"2":{"172":1}}],["如上所述",{"2":{"141":1,"155":1,"209":1,"338":1,"426":1,"742":1,"797":1,"818":2}}],["如上所示",{"2":{"113":1}}],["如今的神经网络对于许多应用来说是最先进的技术",{"2":{"1098":1}}],["如今固态驱动器的控制器和固件已经开发出了缓解这种情况的算法",{"2":{"805":1}}],["如今在深度学习中的灵感同样或更多地来自数学",{"2":{"619":1}}],["如今",{"2":{"293":1}}],["如今人类和机器都能很好地区分猫和狗",{"2":{"151":1}}],["如心率",{"2":{"289":1}}],["如数据",{"2":{"288":1}}],["如错误率",{"2":{"286":1}}],["如平方误差",{"2":{"286":1}}],["如预测性监管",{"2":{"284":1}}],["如年龄",{"2":{"284":1}}],["如这里的三阶多项式函数",{"2":{"265":1}}],["如使用收入的对数作为我们的特征",{"2":{"230":1}}],["如街道类型",{"2":{"208":1}}],["如类别",{"2":{"192":1}}],["如此循环",{"2":{"1172":1}}],["如此循环直至将图片全部检测完",{"2":{"1172":1}}],["如此循环直到收敛",{"2":{"1081":1}}],["如此类推",{"2":{"1160":1}}],["如此严重的过拟合",{"2":{"169":1}}],["如此一来",{"2":{"140":1}}],["如换位和交换输入位置",{"2":{"164":1}}],["如高度和宽度",{"2":{"149":1}}],["如relu",{"2":{"139":1,"507":1}}],["如在序列级",{"2":{"663":1}}],["如在线性回归模型中的权重和偏置",{"2":{"592":1}}],["如在",{"2":{"131":1,"992":1}}],["如何管理大规模容器",{"2":{"1356":1}}],["如何管理成百上千个容器",{"2":{"1355":1}}],["如何把应用打包并运行",{"2":{"1356":1}}],["如何把数据存入矩阵等等",{"2":{"1090":1}}],["如何弹性伸缩",{"2":{"1355":1}}],["如何进行服务发现与负载均衡",{"2":{"1355":1}}],["如何进行一个向量化的计算来对所有的用户和所有的电影进行评分计算",{"2":{"1191":1}}],["如何保证容器的高可用和自动恢复",{"2":{"1355":1}}],["如何保存计算结果",{"2":{"1089":1}}],["如何开始学习",{"0":{"1304":1}}],["如何利用学习曲线识别高方差",{"2":{"1134":1}}],["如何利用学习曲线识别高偏差",{"2":{"1134":1}}],["如何选择地标",{"2":{"1147":1}}],["如何选择更有意义的方法",{"2":{"1129":1}}],["如何选择适当的激活函数",{"2":{"158":1}}],["如何定义和调用函数",{"2":{"1092":1}}],["如何只用一两行代码",{"2":{"1090":1}}],["如何很快地画图",{"2":{"1090":1}}],["如何移动这些数据并用数据进行操作",{"2":{"1089":1}}],["如何对不同的向量进行相加",{"2":{"1093":1}}],["如何对矩阵中的数字进行各种操作",{"2":{"1090":1}}],["如何对矩阵进行相乘",{"2":{"1089":1}}],["如何对猫和狗的图像进行分类呢",{"2":{"230":1}}],["如何计算这个微分项的知识",{"2":{"1067":1}}],["如何决定用直线还是二次方程来拟合",{"2":{"1060":1}}],["如何调整超参数",{"2":{"910":1}}],["如何修改这个算法来柔和地抑制",{"2":{"856":1}}],["如何测量cpu上的缓存大小",{"2":{"815":1}}],["如何训练它们的词向量",{"2":{"788":1}}],["如何扩展字节对编码的思想来提取短语",{"2":{"759":1}}],["如何分别使用负采样和分层softmax训练连续词袋模型",{"2":{"711":1}}],["如何根据一对序列的长度比值截断它们",{"2":{"690":1}}],["如何访问线性回归的梯度",{"2":{"597":1}}],["如何在系统中加载数据和寻找数据",{"2":{"1089":1}}],["如何在自动驾驶和医疗图像诊断中应用语义分割",{"2":{"951":1}}],["如何在多个内存通道中分配数据以获得最大带宽",{"2":{"815":1}}],["如何在连续词袋模型的基础上设计一个子词嵌入模型",{"2":{"759":1}}],["如何在负采样中对噪声词进行采样",{"2":{"711":1}}],["如何在算法设计中应用负采样",{"2":{"662":1}}],["如何在机器翻译中使用两个循环神经网络进行序列到序列学习",{"2":{"572":1}}],["如何在不增加可学习参数的情况下增加系统的记忆和复杂性",{"2":{"300":1}}],["如何更改模型以生成适当的单词",{"2":{"563":1}}],["如何展示机器学习研究",{"2":{"475":1}}],["如何同时保存网络架构和参数",{"2":{"444":1}}],["如何提高transformer的计算速度和内存使用效率",{"2":{"411":1}}],["如何设计一个神经网络模型",{"2":{"525":1}}],["如何设计基于transformer模型的图像分类任务",{"2":{"411":1}}],["如何设计",{"2":{"411":1}}],["如何设计实验来衡量注意力头的重要性呢",{"2":{"384":1}}],["如何学习f来预测任意新输入x的输出y^=f",{"2":{"386":1}}],["如何将文本输入的bert表示转换为输出标签",{"2":{"656":1}}],["如何将超参数添加到非参数的nadaraya",{"2":{"394":1}}],["如何将注意力汇聚的输出计算成为值的加权和",{"2":{"367":1}}],["如何将输出转换为有效的概率分布",{"2":{"228":1}}],["如何生成训练数据",{"2":{"347":1}}],["如何使用这些算法",{"2":{"1111":1}}],["如何使用小数据样本以得到这100或101个参数",{"2":{"1086":1}}],["如何使用矩阵乘法实现卷积",{"2":{"124":1}}],["如何使其实现地更容易",{"2":{"335":1}}],["如何解决这个问题",{"2":{"759":1}}],["如何解决",{"2":{"323":1}}],["如何转换数据的模型",{"2":{"283":1}}],["如何得到带正则化的p",{"2":{"280":1}}],["如何发现可以泛化的模式是机器学习的根本问题",{"2":{"251":1}}],["如何做出合理的网络设计选择",{"2":{"158":1}}],["如何有效地计算输出层",{"2":{"158":1}}],["如何通过基于字符级语言建模的循环神经网络",{"2":{"341":1}}],["如何通过改变输入张量和卷积核张量",{"2":{"133":1}}],["如何通过对整个路径参数求平均值来获得更好的解",{"2":{"66":1}}],["如下图为1索引向量和0索引向量",{"2":{"1072":1}}],["如下图所示的那样",{"2":{"1112":1}}],["如下图所示",{"2":{"387":1}}],["如下表所示",{"2":{"1063":1}}],["如下例子",{"2":{"1019":1}}],["如下例所示",{"2":{"102":1}}],["如下面的等式所示",{"2":{"624":1}}],["如下面的式子",{"2":{"610":1}}],["如下",{"2":{"578":1,"786":1,"981":1}}],["如下式",{"2":{"334":1,"611":1,"643":1}}],["如下是",{"2":{"128":1}}],["如下所示",{"2":{"27":1,"55":1,"72":1,"115":1,"121":1,"126":1,"128":1,"137":1,"148":1,"170":1,"392":1,"425":1,"430":1,"432":1,"467":1,"701":1,"775":1,"819":1,"848":1,"1019":1,"1020":1}}],["如",{"2":{"99":1,"157":1,"183":1,"207":1,"213":1,"282":2,"295":1,"312":3,"321":1,"332":1,"334":1,"335":1,"347":1,"350":1,"355":1,"356":1,"369":1,"388":1,"397":1,"408":1,"422":1,"424":1,"449":1,"458":1,"479":1,"487":1,"488":1,"494":1,"500":1,"501":1,"508":1,"513":1,"518":1,"519":1,"532":1,"540":1,"553":1,"555":1,"572":1,"573":1,"576":1,"611":1,"631":1,"648":1,"657":1,"659":1,"663":1,"672":1,"685":1,"687":1,"688":1,"699":1,"707":1,"736":1,"754":1,"762":1,"785":1,"790":3,"797":1,"801":1,"810":2,"849":1,"851":3,"861":1,"862":1,"870":1,"940":1,"980":1,"1025":1,"1035":1,"1042":1,"1052":1,"1072":1,"1076":1,"1085":1,"1088":2,"1106":1,"1133":1,"1141":1,"1148":1,"1187":1,"1215":1,"1235":1,"1303":1,"1309":1,"1312":1,"1318":1}}],["如果value可以更换",{"2":{"1500":1}}],["如果v是很大的数据",{"2":{"1089":1}}],["如果与vue2冲突",{"2":{"1453":1}}],["如果训练集不是太大",{"2":{"1184":1}}],["如果训练样本",{"2":{"1146":1}}],["如果协方差矩阵只在对角线的单位上有非零的值时",{"2":{"1184":1}}],["如果该值异常地大",{"2":{"1183":1}}],["如果任何学习算法能够表达为",{"2":{"1169":1}}],["如果任何hi可以接受k个不同的值",{"2":{"519":1}}],["如果特征之间在某种程度上存在相互关联的情况",{"2":{"1184":1}}],["如果特征是在不同的数量级上",{"2":{"1159":1}}],["如果特征数量实在太多",{"2":{"1086":1}}],["如果特征数量n较大则运算代价大",{"2":{"1085":1}}],["如果100维的向量最后可以用10维来表示",{"2":{"1158":1}}],["如果n较小",{"2":{"1148":2}}],["如果相较于m而言",{"2":{"1148":1}}],["如果距离较远",{"2":{"1146":1}}],["如果θ0=0",{"2":{"1145":1}}],["如果u和v之间的夹角小于90度",{"2":{"1145":1}}],["如果u是一个类似这样的向量",{"2":{"1145":1}}],["如果样本i是一个负样本",{"2":{"1144":1}}],["如果样本个数不能被批量大小整除",{"2":{"607":1}}],["如果当c=1",{"2":{"1143":1}}],["如果当y=0时",{"2":{"1143":1}}],["如果给定λ",{"2":{"1143":1}}],["如果画出关于z",{"2":{"1143":1}}],["如果每一次你实践新想法的时候",{"2":{"1138":1}}],["如果每个像素可以取256个灰度值中的一个",{"2":{"252":1}}],["如果隐藏层数大于1",{"2":{"1126":1}}],["如果选择的正则化参数λ",{"2":{"1115":1}}],["如果选择较小的学习率",{"2":{"87":1}}],["如果说这些算法有缺点的话",{"2":{"1111":1}}],["如果说卷积神经网络可以有效地处理空间信息",{"2":{"305":1}}],["如果人体有同一块脑组织可以处理光",{"2":{"1098":1}}],["如果人类评估者很难根据文本互动区分机器和人类的回答",{"2":{"299":1}}],["如果只是实现这种算法",{"2":{"1093":1}}],["如果只想知道张量中元素的总数",{"2":{"1017":1}}],["如果只想等待一个特定的变量可用",{"2":{"791":1}}],["如果打开它",{"2":{"1089":1}}],["如果键入plot",{"2":{"1091":1}}],["如果键入",{"2":{"1089":1,"1090":1}}],["如果矩阵x",{"2":{"1086":1}}],["如果这是一个压缩算法",{"2":{"1161":1}}],["如果这是决策界",{"2":{"1145":1}}],["如果这个算法的表现不理想",{"2":{"1132":1}}],["如果这样做可以改善我们算法",{"2":{"1138":1}}],["如果这样做了",{"2":{"1098":1}}],["如果这样说不好理解的话就举一个例子来说明一下",{"2":{"1075":1}}],["如果这些假设成立",{"2":{"290":1}}],["如果a太大",{"2":{"1068":2}}],["如果a​太小了",{"2":{"1068":1}}],["如果我考察这个样本到参数θ的投影",{"2":{"1145":1}}],["如果我将完整定义的假设函数代入这里",{"2":{"1143":1}}],["如果我设置θ",{"2":{"1092":1}}],["如果我用分号来代替逗号",{"2":{"1091":1}}],["如果我要同时表示正弦和余弦曲线",{"2":{"1091":1}}],["如果我要打印该值",{"2":{"1088":1}}],["如果我输入",{"2":{"1090":1}}],["如果我写",{"2":{"1090":2}}],["如果我键入a=1",{"2":{"1091":1}}],["如果我键入subplot",{"2":{"1091":1}}],["如果我键入max",{"2":{"1090":1}}],["如果我键入",{"2":{"1089":1,"1092":1}}],["如果我对w进行赋值",{"2":{"1088":1}}],["如果我想绘制正弦函数",{"2":{"1091":1}}],["如果我想把它们都乘起来",{"2":{"1090":1}}],["如果我想",{"2":{"1088":1}}],["如果我再更新一步",{"2":{"1068":1}}],["如果我更新一步梯度下降",{"2":{"1068":1}}],["如果我有数千件货物",{"2":{"1060":1}}],["如果我们新增一个用户",{"2":{"1192":1}}],["如果我们拥有用户的参数",{"2":{"1189":1}}],["如果我们拥有一张图像",{"2":{"305":1}}],["如果我们令文字侦测部分输出的结果100",{"2":{"1174":1}}],["如果我们令所有的初始参数都为0",{"2":{"1125":1}}],["如果我们得到的曲线如上面右下方所示",{"2":{"1167":1}}],["如果我们一定需要一个大规模的训练集",{"2":{"1165":1}}],["如果我们选择保留95",{"2":{"1160":1}}],["如果我们选择的学习率太大",{"2":{"113":1}}],["如果我们选择的学习率太小",{"2":{"113":1}}],["如果我们仍然要满足这些约束",{"2":{"1145":1}}],["如果我们仍然在同一个设备作用域下调用z2",{"2":{"449":1}}],["如果我们找到了这样的参数",{"2":{"1144":1}}],["如果我们找到p",{"2":{"191":1}}],["如果我们采用了一些容易混淆的词",{"2":{"1141":1}}],["如果我们采用多项式回归模型",{"2":{"1084":1}}],["如果我们初始所有的参数都为一个非0的数",{"2":{"1125":1}}],["如果我们初始化v0=s0=0",{"2":{"33":1}}],["如果我们考虑正则化处理",{"2":{"1121":1}}],["如果我们发现了过拟合问题",{"2":{"1114":1}}],["如果我们发现原始的输入分辨率十分冗余",{"2":{"140":1}}],["如果我们给出一个新的样本",{"2":{"1110":1}}],["如果我们要用新训练出的算法来预测评分",{"2":{"1192":1}}],["如果我们要用线性回归算法来解决一个分类问题",{"2":{"1106":1}}],["如果我们要使用",{"2":{"1121":1}}],["如果我们要使用梯度下降法令这个代价函数最小化",{"2":{"1116":1}}],["如果我们要最小化这个关于θ的函数值",{"2":{"1110":1}}],["如果我们要训练一个神经网络算法来识别路人",{"2":{"1103":1}}],["如果我们要对整个训练集进行计算",{"2":{"1100":1}}],["如果我们要进一步将两两特征组合构成一个多项式模型",{"2":{"1097":1}}],["如果我们要建立一个机器翻译系统",{"2":{"183":1}}],["如果我们预先把θ1放在一个局部的最低点",{"2":{"1068":1}}],["如果我们站在山坡上的这一点",{"2":{"1067":1}}],["如果我们可以把医疗记录变成医学知识",{"2":{"1058":1}}],["如果我们可以自动确定η",{"2":{"58":1}}],["如果我们进行足够精确的测量",{"2":{"1028":1}}],["如果我们进一步假设目标函数f表现良好",{"2":{"334":1}}],["如果我们没有证据表明y=",{"2":{"1025":1}}],["如果我们没有像本节所做的那样标准化连续的数值特征",{"2":{"215":1}}],["如果我们完全肯定图像是一只猫",{"2":{"1025":1}}],["如果我们用批量梯度下降算法来求解大规模数据集的最优解",{"2":{"1169":1}}],["如果我们用的线性代数函数库比较好",{"2":{"1166":1}}],["如果我们用一个新的代价函数来代替",{"2":{"1143":1}}],["如果我们用一个巨大的带标签的数据集",{"2":{"282":1}}],["如果我们用这些数据运行这些算法",{"2":{"1141":1}}],["如果我们用y",{"2":{"1021":1}}],["如果我们按常数因子α缩放向量的所有元素",{"2":{"1000":1}}],["如果我们简单地调用前向传播net",{"2":{"920":1}}],["如果我们增加更多的核心呢",{"2":{"811":1}}],["如果我们添加的运算不仅优化了向量运算",{"2":{"811":1}}],["如果我们添加ph行填充",{"2":{"141":1}}],["如果我们删除两个任务之间的synchronize语句",{"2":{"796":1}}],["如果我们联合编码n个观测值怎么办",{"2":{"655":1}}],["如果我们不知道最小值",{"2":{"1111":1}}],["如果我们不十分确定图像描绘的是一只猫",{"2":{"1025":1}}],["如果我们不原地更新",{"2":{"1021":1}}],["如果我们不过滤出一些不常见的词元",{"2":{"724":1}}],["如果我们不能完全预测每一个事件",{"2":{"651":1}}],["如果我们不指定初始化方法",{"2":{"246":1}}],["如果我们很容易预测下一个数据",{"2":{"651":1}}],["如果我们希望这个比例小于1",{"2":{"1160":1}}],["如果我们希望将数据从n维降至k维",{"2":{"1159":1}}],["如果我们希望提高查全率",{"2":{"1140":1}}],["如果我们希望只在非常确信的情况下预测为真",{"2":{"1140":1}}],["如果我们希望在循环神经网络中拥有一种机制",{"2":{"520":1}}],["如果我们希望一个序列样本是一个完整的句子",{"2":{"323":1}}],["如果我们能够将我们的数据集分配给不多台计算机",{"2":{"1169":1}}],["如果我们能够从方差减少的影响中受益",{"2":{"86":1}}],["如果我们能将数据可视化",{"2":{"1157":1}}],["如果我们能将新添加的层训练成恒等映射",{"2":{"500":1}}],["如果我们能用这些方法来计算代价函数j",{"2":{"1111":1}}],["如果我们能找出大脑的学习算法",{"2":{"1098":1}}],["如果我们尝试编码两个独立的观察结果会发生什么",{"2":{"655":1}}],["如果我们尝试为它设计二进制代码",{"2":{"655":1}}],["如果我们尝试使用大小为1的小批量应用批量规范化",{"2":{"467":1}}],["如果我们尝试了不合理的超参数",{"2":{"212":1}}],["如果我们还是调用z",{"2":{"449":1}}],["如果我们",{"2":{"449":1}}],["如果我们对两个张量求和",{"2":{"447":1}}],["如果我们有一个低方差的模型",{"2":{"1164":1}}],["如果我们有一个3层多层感知机",{"2":{"442":1}}],["如果我们有交叉验证集合测试集",{"2":{"1162":1}}],["如果我们有另一个样本",{"2":{"1143":1}}],["如果我们有100行数据",{"2":{"1134":1}}],["如果我们有非常多的特征",{"2":{"1114":1}}],["如果我们有关于房价",{"2":{"296":1}}],["如果我们改变其中一个参数",{"2":{"437":2}}],["如果我们改变xt",{"2":{"349":2}}],["如果我们处理的是离散的对象",{"2":{"347":1}}],["如果我们通过ηg更新参数向量",{"2":{"334":1}}],["如果我们只选择一个偏移量",{"2":{"319":1}}],["如果我们只需寻找黑白边缘",{"2":{"129":1}}],["如果我们想令θ的范数变小",{"2":{"1145":1}}],["如果我们想要将这个目标函数乘上常数10",{"2":{"1143":1}}],["如果我们想",{"2":{"1020":1}}],["如果我们想沿",{"2":{"996":1}}],["如果我们想说一个向量x由n个实值标量组成",{"2":{"991":1}}],["如果我们想用概率图模型来解决这个问题",{"2":{"519":1}}],["如果我们想将f拓展成超过两部分的信息呢",{"2":{"479":1}}],["如果我们想将其可能产生的影响合并到xt上",{"2":{"338":1}}],["如果我们想处理完全不同的输入或输出",{"2":{"282":1}}],["如果我们想参加kaggle比赛",{"2":{"207":1}}],["如果我们过拟合了训练数据",{"2":{"256":1}}],["如果我们根据从加州大学旧金山分校医学中心的患者数据训练死亡风险预测模型",{"2":{"253":1}}],["如果我们试图预测一个人是否会偿还贷款",{"2":{"230":1}}],["如果我们的模型是低方差的",{"2":{"1173":1}}],["如果我们的学习算法需要有20次迭代",{"2":{"1164":1}}],["如果我们的交叉验证集误差较大",{"2":{"1132":1}}],["如果我们的目标形状是",{"2":{"1017":1}}],["如果我们的权重向量增长的太大",{"2":{"270":1}}],["如果我们的标签通过仿射变换后确实与我们的输入数据相关",{"2":{"229":1}}],["如果我们的数据集大得多",{"2":{"211":1}}],["如果我们的分类器一开始就足够精确",{"2":{"192":1}}],["如果我们的分类器一开始就相当准确",{"2":{"192":1}}],["如果我们在hybrid",{"2":{"823":1}}],["如果我们在没有任何压缩的情况下存储序列",{"2":{"342":1}}],["如果我们在模型选择过程中使用测试数据",{"2":{"256":1}}],["如果我们在加州豪宅区的预测出现同样的10万美元的偏差",{"2":{"210":1}}],["如果我们在俄亥俄州农村地区估计一栋房子的价格时",{"2":{"210":1}}],["如果我们在这里不能做得比随机猜测更好",{"2":{"210":1}}],["如果我们在源分布上有一个相当好的模型",{"2":{"192":1}}],["如果我们正在研究医院患者可能面临的心脏病发作风险",{"2":{"990":1}}],["如果我们正在训练一个模型来预测贷款违约风险",{"2":{"990":1}}],["如果我们正在用jupyter阅读该书",{"2":{"208":1}}],["如果我们正在部署一个医疗诊断系统",{"2":{"201":1}}],["如果我们知道某些项是发散的",{"2":{"250":1}}],["如果我们知道环境可能会瞬间发生变化",{"2":{"200":1}}],["如果我们知道事情只会缓慢地变化",{"2":{"200":1}}],["如果我们将x输入卷积层f来获得输出y=f",{"2":{"971":1}}],["如果我们将x代入卷积层f来输出y=f",{"2":{"969":1}}],["如果我们将梯度分为n个块",{"2":{"842":1}}],["如果我们将权重初始化为零",{"2":{"607":1}}],["如果我们将权重连接到每个空间位置",{"2":{"494":1}}],["如果我们将多个块相互嵌套",{"2":{"433":1}}],["如果我们将wd",{"2":{"278":1}}],["如果我们将隐藏层的所有参数初始化为w",{"2":{"244":1}}],["如果我们将暂退法应用到权重矩阵的各个权重",{"2":{"178":1}}],["如果我们将输入通道ci和输出通道co的数量加倍",{"2":{"124":1}}],["如果我们拍摄黑白之间轮廓清晰的图像x",{"2":{"145":1}}],["如果我们设置了ph=kh−1和pw=kw−1",{"2":{"142":1}}],["如果我们设置γ=1",{"2":{"111":1}}],["如果我们把这个参数增加或减少一个无穷小的量",{"2":{"981":1}}],["如果我们把填充数量翻一番会怎么样",{"2":{"124":1}}],["如果我们把它选得太小",{"2":{"58":1}}],["如果我们需要最大化目标",{"2":{"98":1}}],["如果我们使用两个问号",{"2":{"1007":1}}],["如果我们使用相同的例子",{"2":{"842":1}}],["如果我们使用先进的8",{"2":{"819":1}}],["如果我们使用循环神经网络来预测文本序列中的下一个字符",{"2":{"344":1}}],["如果我们使用∑i|wi|作为我们选择的惩罚",{"2":{"280":1}}],["如果我们使用对数几率回归方法",{"2":{"191":1}}],["如果我们使用形状为",{"2":{"147":1}}],["如果我们使用多项式衰减",{"2":{"114":1}}],["如果我们使用第一个选择",{"2":{"77":1}}],["如果我们使用过高的学习率",{"2":{"55":1}}],["如果我们使用的学习率太小",{"2":{"55":1}}],["如果我们使用",{"2":{"54":1}}],["如果阴性",{"2":{"1035":2}}],["如果阳性",{"2":{"1035":2}}],["如果患者真正感染hiv",{"2":{"1035":1}}],["如果患者健康但测试显示他患病",{"2":{"1035":1}}],["如果两个随机变量a和b是独立的",{"2":{"1034":1}}],["如果两个序列的有效长度",{"2":{"575":1}}],["如果投掷出3点",{"2":{"1027":1}}],["如果骰子是公平的",{"2":{"1026":1}}],["如果让它们相加",{"2":{"1019":1}}],["如果渴望了解有关线性代数的更多信息",{"2":{"1002":1}}],["如果b=a⊤",{"2":{"992":1}}],["如果读者想要深入理解全部数学内容",{"2":{"987":1}}],["如果以其中每个单元为中心生成a个锚框",{"2":{"954":1}}],["如果以每个像素为中心生成五个形状不同的锚框",{"2":{"911":1}}],["如果图像中有两条狗",{"2":{"944":1}}],["如果裁剪的图像只包含物体的一小部分会怎样",{"2":{"935":1}}],["如果为每个像素都生成的锚框",{"2":{"911":1}}],["如果为预测而屏蔽词元",{"2":{"736":1}}],["如果首次使用此模型",{"2":{"873":1}}],["如果非手动",{"2":{"856":1}}],["如果已知目标的真实边界框",{"2":{"849":1}}],["如果已经安装了paddlepaddle的cpu版本",{"2":{"445":1}}],["如果已经安装了mxnet的cpu版本",{"2":{"445":1}}],["如果去掉npx",{"2":{"830":1}}],["如果某个层是从block类而不是从hybridblock类继承的",{"2":{"819":1}}],["如果某些梯度",{"2":{"118":1}}],["如果随机读操作均匀分布在内存中",{"2":{"802":1}}],["如果希望在网络上同步多台计算机",{"2":{"801":1}}],["如果删除两个任务之间的synchronize语句",{"2":{"796":1}}],["如果删除两个任务之间的waitall语句",{"2":{"796":1}}],["如果device参数是none",{"2":{"796":2}}],["如果尚未下载指定的嵌入文件",{"2":{"748":1}}],["如果词表很大",{"2":{"788":1}}],["如果词wi和wj在同一上下文窗口中同时出现",{"2":{"746":1}}],["如果词元的索引是整数i",{"2":{"330":1}}],["如果您的计算资源允许",{"2":{"690":1}}],["如果出现显存不足错误",{"2":{"687":3}}],["如果预测与实际类别",{"2":{"653":1}}],["如果正确地预测实际标签",{"2":{"646":1}}],["如果类别间有一些自然顺序",{"2":{"640":1}}],["如果y=0",{"2":{"1144":1}}],["如果y^1",{"2":{"643":1}}],["如果y",{"2":{"634":1}}],["如果ok中的一些数值非常大",{"2":{"624":1}}],["如果编码器和解码器的层数或者隐藏单元数不同",{"2":{"580":1}}],["如果愿意",{"2":{"575":1}}],["如果未提及状态",{"2":{"573":2}}],["如果遗忘门始终为1且输入门始终为0",{"2":{"555":1}}],["如果仅仅实现门控循环单元的一部分",{"2":{"549":1}}],["如果整个子序列的所有时间步的更新门都接近于1",{"2":{"542":1}}],["如果第一个词元非常重要",{"2":{"539":1}}],["如果第二个约束c2",{"2":{"47":1}}],["如果增加训练数据",{"2":{"531":1}}],["如果计算成本最重要",{"2":{"515":1}}],["如果精度最重要",{"2":{"515":1}}],["如果目标是获得最优序列",{"2":{"514":1}}],["如果想了解更多信息论的细节",{"2":{"648":1}}],["如果想改变通道数",{"2":{"501":1}}],["如果想要压缩文本",{"2":{"342":1}}],["如果想要构建多个超参数的搜索方法",{"2":{"223":1}}],["如果使用octave作为学习工具",{"2":{"1061":1}}],["如果使用octave作为编程环境",{"2":{"1061":1}}],["如果使用全连接层作为输出",{"2":{"954":1}}],["如果使用更深的预训练模型",{"2":{"910":1}}],["如果使用kaggle比赛的完整数据集",{"2":{"901":1}}],["如果使用完整的kaggle竞赛的数据集",{"2":{"889":1}}],["如果使用16个gpu",{"2":{"830":2}}],["如果使用异步编程",{"2":{"792":1}}],["如果使用长短期记忆网络",{"2":{"573":1}}],["如果使用了全连接层",{"2":{"493":1}}],["如果使用梯度下降法",{"2":{"113":1}}],["如果x1是以英尺为尺寸规格计算的房子",{"2":{"1086":1}}],["如果x和y在该位置相等",{"2":{"1018":1}}],["如果x有一个轴",{"2":{"981":1}}],["如果x为真",{"2":{"709":1}}],["如果x是一个形状为",{"2":{"631":1}}],["如果x不在内存上",{"2":{"472":2}}],["如果x¯−x¯0没有改变",{"2":{"26":1}}],["如果是这样的话",{"2":{"1093":1}}],["如果是恶性则记为1",{"2":{"1060":1}}],["如果是夏天",{"2":{"1025":1}}],["如果是桌面服务器则有2个",{"2":{"832":1}}],["如果是f∗∈f",{"2":{"500":1}}],["如果是在预测模式下",{"2":{"472":3}}],["如果是分类问题",{"2":{"339":1}}],["如果模型变得更加复杂",{"2":{"591":1}}],["如果模型参数没有正确初始化",{"2":{"460":1}}],["如果模型不能降低训练误差",{"2":{"258":1}}],["如果变量已经存在于指定的设备中",{"2":{"449":1}}],["如果现在我们还是调用z",{"2":{"449":1}}],["如果存在逆矩阵",{"2":{"1077":1}}],["如果存在",{"2":{"446":4}}],["如果要将这个50维的数据可视化是不可能的",{"2":{"1157":1}}],["如果要将此华氏度值转换为更常用的摄氏度",{"2":{"989":1}}],["如果要照片达到理想中的风格",{"2":{"916":1}}],["如果要在kaggle比赛中使用完整的数据集",{"2":{"901":1}}],["如果要在autograd范围内调整参数",{"2":{"436":1}}],["如果要做好命名实体识别",{"2":{"518":1}}],["如果要求我们输出字母表中的前5个字母",{"2":{"293":1}}],["如果传入的是一个tuple",{"2":{"424":1}}],["如果指定了不匹配的维度会发生什么",{"2":{"420":1}}],["如果指定了第一层的输入尺寸",{"2":{"420":1}}],["如果拥有足够长的序列就丢弃这几项",{"2":{"350":1}}],["如果基于一个马尔可夫模型",{"2":{"349":1}}],["如果基于一个长序列进行反向传播",{"2":{"344":1}}],["如果τ=1",{"2":{"348":1}}],["如果在你的电脑上图标显示的不一样的话",{"2":{"1089":1}}],["如果在octave里",{"2":{"1086":1}}],["如果在后续计算中没有重复使用x",{"2":{"1021":1}}],["如果在训练集中还标注了每个目标在图像上的像素级位置",{"2":{"940":1}}],["如果在一个gpu",{"2":{"816":1}}],["如果在下采样期间保留词元",{"2":{"773":1}}],["如果在循环神经网络模型中增加隐藏层的数量会发生什么",{"2":{"328":1}}],["如果在x处对应的f",{"2":{"101":1}}],["如果rnn是双向的",{"2":{"325":2}}],["如果设置小批量大小为2",{"2":{"320":1}}],["如果python的numpy包也希望使用相同的内存块执行其他操作",{"2":{"1022":1}}],["如果param",{"2":{"874":2}}],["如果p",{"2":{"317":1}}],["如果数据的分布不是高斯分布",{"2":{"1183":1}}],["如果数据不在内存中",{"2":{"450":1}}],["如果数据观察序列的时间步只到604",{"2":{"351":1}}],["如果数据集很小",{"2":{"316":1}}],["如果数据中充满了错误",{"2":{"284":1}}],["如果做了练习题",{"2":{"306":1}}],["如果顺序被随机地重排",{"2":{"305":1}}],["如果把熵h",{"2":{"652":1}}],["如果把人工智能的发展看作一场新的工业革命",{"2":{"304":1}}],["如果把坐标旋转45度会怎么样",{"2":{"64":1}}],["如果自动驱动相应的决策",{"2":{"301":1}}],["如果不是的话再令k=2",{"2":{"1160":1}}],["如果不是所有输入词元都是相关的",{"2":{"377":1}}],["如果不是所有输入词元都相关",{"2":{"373":1}}],["如果不能快速移动矩阵到cpu",{"2":{"801":1}}],["如果不能快速加载图像",{"2":{"801":1}}],["如果不使用异步编程",{"2":{"792":1}}],["如果不使用下采样",{"2":{"779":1}}],["如果不使用卷积神经网络",{"2":{"411":1}}],["如果不同方向使用不同数量的隐藏单位",{"2":{"525":1}}],["如果不加注意地应用统计模型",{"2":{"301":1}}],["如果不对多项式特征xi进行标准化",{"2":{"268":1}}],["如果你喜欢美学又热爱技术",{"2":{"1537":1}}],["如果你考虑网站像亚马逊",{"2":{"1187":1}}],["如果你考察这样一个数据集",{"2":{"1144":1}}],["如果你生产了m个引擎的话",{"2":{"1178":1}}],["如果你跟着我们的课程一路走来",{"2":{"1176":1}}],["如果你得到了一个像上面这样的图",{"2":{"1154":1}}],["如果你伸出你的胳膊",{"2":{"1154":1}}],["如果你看正在发生的事情",{"2":{"1187":1}}],["如果你看到这个幻灯片",{"2":{"1148":1}}],["如果你看过自然语言处理或计算机视觉",{"2":{"1058":1}}],["如果你令θ0不是0的话",{"2":{"1145":1}}],["如果你从几何上画出p的值",{"2":{"1145":1}}],["如果你从来没有接触过向量和矩阵",{"2":{"1070":1}}],["如果你加了这个样本",{"2":{"1144":1}}],["如果你将c设置的不要太大",{"2":{"1144":1}}],["如果你将这一项作为z的函数",{"2":{"1143":1}}],["如果你将j",{"2":{"1111":1}}],["如果你进一步观察逻辑回归的代价函数",{"2":{"1143":1}}],["如果你给这个劣等算法更多的数据",{"2":{"1141":1}}],["如果你选择任意一个算法",{"2":{"1141":1}}],["如果你准备研究机器学习的东西",{"2":{"1138":1}}],["如果你理解了以上几节视频中介绍的内容",{"2":{"1135":1}}],["如果你一直跟着这些视频的进度学习",{"2":{"1129":1}}],["如果你正在构建一个",{"2":{"1531":1}}],["如果你正在做有关天气的机器学习分类问题",{"2":{"1112":1}}],["如果你正在你的机器学习程序中使用一种不同的语言",{"2":{"1111":1}}],["如果你调用它",{"2":{"1111":1}}],["如果你直接调用它自带的库",{"2":{"1111":1}}],["如果你希望代码还要能够监控这些j",{"2":{"1111":1}}],["如果你的特征范围差距很大的话",{"2":{"1110":1}}],["如果你的参数已经处于局部最低点",{"2":{"1068":1}}],["如果你计算一下的话",{"2":{"1110":1}}],["如果你在考虑一些问题",{"2":{"1148":1}}],["如果你在这里有一些正样本或者你在这里有一些负样本",{"2":{"1144":1}}],["如果你在青蛙身上插入第三只眼",{"2":{"1098":1}}],["如果你在实现线性回归的时候",{"2":{"1093":1}}],["如果你把这个更新规则和我们之前用在线性回归上的进行比较的话",{"2":{"1110":1}}],["如果你把它戴在腰上",{"2":{"1098":1}}],["如果你把命令写成字符串的形式load",{"2":{"1089":1}}],["如果你搜索youtube之后",{"2":{"1098":1}}],["如果你做一个和刚才类似的重接实验",{"2":{"1098":1}}],["如果你提交的答案不正确",{"2":{"1094":1}}],["如果你实在不能理解它们数学上等价的原因",{"2":{"1093":1}}],["如果你只在octave中输入a乘以b就是一个非常有效的两个矩阵相乘的程序",{"2":{"1093":1}}],["如果你只有记事本程序",{"2":{"1092":1}}],["如果你也使用微软的windows系统",{"2":{"1092":1}}],["如果你需要退出",{"2":{"1092":1}}],["如果你需要改变坐标轴",{"2":{"1091":1}}],["如果你这样做了",{"2":{"1091":1}}],["如果你用合适的向量化方法来实现",{"2":{"1093":1}}],["如果你用命令",{"2":{"1090":1}}],["如果你用它来实现θ的计算",{"2":{"1086":1}}],["如果你要将你的假设函数放到一组新的房屋样本上进行测试",{"2":{"1129":1}}],["如果你要解这个方程",{"2":{"1093":1}}],["如果你要找到某个octave中的命令",{"2":{"1089":1}}],["如果你要更新这个等式",{"2":{"1067":1}}],["如果你就输入",{"2":{"1089":1}}],["如果你想试试",{"2":{"1541":1}}],["如果你想找5部与电影非常相似的电影",{"2":{"1191":1}}],["如果你想做",{"2":{"1156":1}}],["如果你想测量",{"2":{"1156":1}}],["如果你想活动一块肌肉",{"2":{"1099":1}}],["如果你想保存这幅图像",{"2":{"1091":1}}],["如果你想求这个矩阵的逆矩阵",{"2":{"1090":1}}],["如果你想要计算hθ",{"2":{"1093":1}}],["如果你想要找出整个矩阵a的最大值",{"2":{"1090":1}}],["如果你想要求它的转置",{"2":{"1090":1}}],["如果你想把数据存成一个人能看懂的形式",{"2":{"1089":1}}],["如果你想删除某个变量",{"2":{"1089":1}}],["如果你想打印出变量",{"2":{"1088":1}}],["如果你想分配一个变量",{"2":{"1088":1}}],["如果你不能做到这两者",{"2":{"1141":1}}],["如果你不想看到那个提示",{"2":{"1088":1}}],["如果你不熟悉搜索路径的概念",{"2":{"1092":1}}],["如果你不熟悉线性代数",{"2":{"1070":1}}],["如果你不熟悉微积分",{"2":{"1067":1}}],["如果你会python",{"2":{"1088":1}}],["如果你能把几乎任何传感器接入到大脑中",{"2":{"1098":1}}],["如果你能弄清楚为什么这两个步骤是等价的",{"2":{"1093":1}}],["如果你能好好利用这些线性代数库",{"2":{"1093":1}}],["如果你能够使用matlab",{"2":{"1088":1}}],["如果你能够让那些机器协同工作",{"2":{"1061":1}}],["如果你能让你的学习算法在octave上快速的实现",{"2":{"1088":1}}],["如果你懂一点线性代数的知识",{"2":{"1086":1}}],["如果你十分熟悉这些概念",{"2":{"1070":1}}],["如果你觉得线性代数看上去是一个复杂",{"2":{"1070":1}}],["如果你之前学过线性代数",{"2":{"1069":1}}],["如果你熟悉偏导数和导数",{"2":{"1067":1}}],["如果你已经修过微积分课程",{"2":{"1067":1}}],["如果你已经具有相关经验",{"2":{"1017":1}}],["如果你跳过这段视频的话",{"2":{"1066":1}}],["如果你对反向传播算法也有这种感受的话",{"2":{"1122":1}}],["如果你对动物这样做",{"2":{"1098":1}}],["如果你对",{"2":{"1092":1}}],["如果你对等高线图不太熟悉的话",{"2":{"1066":1}}],["如果你对使用机器学习开发与环境交互并采取行动感兴趣",{"2":{"298":1}}],["如果你朋友的房子是1250平方尺大小",{"2":{"1063":1}}],["如果你有几百个或成千上万的特征",{"2":{"1156":1}}],["如果你有大量的数据",{"2":{"1141":1}}],["如果你有",{"2":{"1110":1}}],["如果你有两个特征量",{"2":{"1093":1}}],["如果你有别的什么文本编辑器也可以",{"2":{"1092":1}}],["如果你有一个变化的用户群",{"2":{"1168":1}}],["如果你有一个由连续的用户流引发的连续的数据流",{"2":{"1168":1}}],["如果你有一个负样本",{"2":{"1144":1}}],["如果你有一个正样本y=1",{"2":{"1144":1}}],["如果你有一个正样本",{"2":{"1144":2}}],["如果你有一个向量",{"2":{"1089":1}}],["如果你有一个机器学习问题",{"2":{"1089":1}}],["如果你有标记好的数据",{"2":{"1061":1}}],["如果你有matlab",{"2":{"1061":1}}],["如果你试图完成这个工作",{"2":{"1061":1}}],["如果你以前从来没见过它",{"2":{"1061":1}}],["如果你真的试图开发机器学习系统",{"2":{"1059":1}}],["如果你很难理解一些数学概念或库函数",{"2":{"1017":1}}],["如果你曾经在餐厅支付餐费",{"2":{"989":1}}],["如果你没有安装pandas",{"2":{"208":1}}],["如果工作没有十分具体的目标",{"2":{"296":1}}],["如果他们在未来24小时内死亡的风险超过某个阈值",{"2":{"295":1}}],["如果用户j给电影",{"2":{"1187":1}}],["如果用户对观测对象有一定的先验知识",{"2":{"1158":1}}],["如果用python的for循环来完成这个任务",{"2":{"1026":1}}],["如果用前一时间步的预测输入到解码器来代替强制教学",{"2":{"580":1}}],["如果用h",{"2":{"337":1}}],["如果用",{"2":{"284":1}}],["如果用q的特征系统来表示",{"2":{"94":1}}],["如果检测器不确定输入的图片中是猫还是狗",{"2":{"282":1}}],["如果输入a",{"2":{"1090":1}}],["如果输入具有不同的维度",{"2":{"420":1}}],["如果输入序列很长",{"2":{"411":1}}],["如果输入的样本之间没有任何关系",{"2":{"295":1}}],["如果输入的高度和宽度可以被垂直和水平步幅整除",{"2":{"142":1}}],["如果输入是狗的图片就会输出一个非常小的负数",{"2":{"282":1}}],["如果输入是猫的图片就输出一个非常大的正数",{"2":{"282":1}}],["如果它看起来像一个正常的引擎",{"2":{"1178":1}}],["如果它的连接是特别完整的",{"2":{"841":1}}],["如果它们之间的夹角大于90度",{"2":{"1145":1}}],["如果它们的序列被我们重排",{"2":{"345":1}}],["如果它们全部来自标准显微镜设备",{"2":{"284":1}}],["如果它一直执行相同的业务逻辑",{"2":{"281":1}}],["如果它太小",{"2":{"66":1}}],["如果它太大",{"2":{"66":1}}],["如果允许的输入集合是离散的并且相当小",{"2":{"252":1}}],["如果有一个",{"2":{"1143":1}}],["如果有多余的就删除掉",{"2":{"1086":1}}],["如果有多个gpu",{"2":{"446":3}}],["如果有四个与参数向量相关的梯度g1",{"2":{"841":1}}],["如果有许多小的线程",{"2":{"815":1}}],["如果有的话",{"2":{"518":1,"731":1,"739":1}}],["如果有足够的数据",{"2":{"389":1}}],["如果有足够多的神经元",{"2":{"251":1}}],["如果有大量的",{"2":{"300":1}}],["如果有人说他使用了线性核的svm",{"2":{"1148":1}}],["如果有人请你估算清理污物的费用",{"2":{"290":1}}],["如果有人设计了一个很棒的算法来预测电影评分",{"2":{"290":1}}],["如果有读者对该主题感兴趣",{"2":{"248":1}}],["如果成功做到了这点",{"2":{"251":1}}],["如果所有隐藏变量和输入都是向量",{"2":{"241":1}}],["如果微妙的边界条件很重要",{"2":{"235":1}}],["如果对命令不清楚",{"2":{"1088":1}}],["如果对这两个术语仍一头雾水",{"2":{"1059":1}}],["如果对应的权重为负",{"2":{"230":1}}],["如果对应的权重为正",{"2":{"230":1}}],["如果对于给定的x",{"2":{"1107":1}}],["如果对于所有x",{"2":{"41":1}}],["如果对于任何a",{"2":{"40":1}}],["如果试图预测价格的对数而不是价格",{"2":{"215":1}}],["如果测试集上的预测与k倍交叉验证过程中的预测相似",{"2":{"213":1}}],["如果一位用户正在观看电影",{"2":{"1189":1}}],["如果一共有k个类",{"2":{"1148":1}}],["如果一些感官",{"2":{"1099":1}}],["如果一个病人因为鼻塞来到你的诊所",{"2":{"1112":1}}],["如果一个随机实验的结果在a中",{"2":{"1027":1}}],["如果一个锚框没有被分配",{"2":{"852":3}}],["如果一个锚框没有被分配真实边界框",{"2":{"852":1}}],["如果一个层的可变值是另一层的100倍",{"2":{"467":1}}],["如果一个设备必须等待另一个设备才能执行其他操作",{"2":{"450":1}}],["如果一个键xi越是接近给定的查询x",{"2":{"388":1}}],["如果一个人住在匹兹堡",{"2":{"290":1}}],["如果一个人住在纽约或旧金山",{"2":{"290":1}}],["如果一个理论能拟合数据",{"2":{"254":1}}],["如果一切顺利",{"2":{"210":1,"282":1}}],["如果一只猪出现在图片顶部",{"2":{"152":1}}],["如果",{"2":{"209":1,"1088":1,"1093":1,"1143":1,"1144":2,"1145":1,"1382":1}}],["如果缓存目录中已经存在此数据集文件",{"2":{"206":1}}],["如果无法区分这两个分布",{"2":{"191":1}}],["如果源分布q",{"2":{"191":1,"192":1}}],["如果没有特殊说明",{"2":{"1016":1}}],["如果没有某种方法来存储数据",{"2":{"1016":1}}],["如果没有给出矩阵a的标量元素",{"2":{"992":1}}],["如果没有参数",{"2":{"835":1}}],["如果没有这种显式定义",{"2":{"819":1}}],["如果没有这样的机制",{"2":{"538":1}}],["如果没有在那里找到",{"2":{"810":1}}],["如果没有偏置项",{"2":{"610":1}}],["如果没有gpu",{"2":{"446":4,"811":1}}],["如果没有噪音",{"2":{"353":1}}],["如果没有数据",{"2":{"284":1}}],["如果没有足够的数据",{"2":{"260":1}}],["如果没有安装pandas",{"2":{"208":3,"1011":1}}],["如果没有方法来适应新的领域",{"2":{"181":1}}],["如果没有任何关于ps和pt之间相互关系的假设",{"2":{"180":1}}],["如果将变量a更改为随机向量或矩阵",{"2":{"979":1}}],["如果将转置卷积层改用xavier随机初始化",{"2":{"868":1}}],["如果将所有的数据发送到cpu",{"2":{"841":1}}],["如果将小批量的总损失替换为小批量损失的平均值",{"2":{"597":1}}],["如果将mysequential中存储块的方式更改为python列表",{"2":{"428":1}}],["如果将查询",{"2":{"382":1}}],["如果将来所有的",{"2":{"180":1}}],["如果将本节中举例的卷积核k应用于x",{"2":{"133":1}}],["如果分布可以以任意方式偏移",{"2":{"180":1}}],["如果同时使用暂退法和权重衰减",{"2":{"178":1}}],["如果交换这两个层",{"2":{"178":1}}],["如果更改第一层和第二层的暂退法概率",{"2":{"178":1}}],["如果通过许多不同的暂退法遮盖后得到的预测结果都是一致的",{"2":{"171":1}}],["如果kh是偶数",{"2":{"141":1}}],["如果转置k会发生什么",{"2":{"133":1}}],["如果转置x会发生什么",{"2":{"133":1}}],["如果水平相邻的两元素相同",{"2":{"128":1}}],["如果卷积核的高度和宽度是kh=kw=1",{"2":{"124":1}}],["如果卷积核的窗口形状是kh×kw",{"2":{"120":1}}],["如果减少的太慢",{"2":{"114":1}}],["如果f在一个区间内的每个数上都是可微的",{"2":{"981":1}}],["如果f的导数存在",{"2":{"981":1}}],["如果f⊈f",{"2":{"500":1}}],["如果f",{"2":{"101":1,"981":1}}],["如果学习率a过大",{"2":{"1083":1}}],["如果学习率a过小",{"2":{"1083":1}}],["如果学习率太小或太大",{"2":{"117":1}}],["如果学习率较高",{"2":{"87":1}}],["如果学习率持续过高",{"2":{"66":1}}],["如果太快",{"2":{"114":1}}],["如果太宽松",{"2":{"84":1}}],["如果太大",{"2":{"58":1}}],["如果衰减速度太快",{"2":{"84":1}}],["如果改变学习率下降的指数",{"2":{"75":1}}],["如果需要的话",{"2":{"1189":1}}],["如果需要",{"2":{"67":1}}],["如果其导数f",{"2":{"54":1}}],["如果算法在凸性条件设定下的效果很差",{"2":{"38":1}}],["如果优化问题的结构相当不均匀",{"2":{"30":1}}],["如果条件编号κ很大",{"2":{"26":1}}],["如果稍微扰动c",{"2":{"26":1}}],["请谨慎使用",{"2":{"1518":1}}],["请输入姓名",{"2":{"1233":1}}],["请务必看视频",{"2":{"1093":1}}],["请仔细看一下这个函数的定义",{"2":{"1092":1}}],["请问",{"2":{"1059":1}}],["请求实现了一个可恢复的",{"2":{"1047":1}}],["请求",{"0":{"1045":1},"2":{"1340":1}}],["请分析一下原因",{"2":{"1004":1}}],["请将下面的变量更改为false",{"2":{"901":1}}],["请不要担心",{"2":{"854":1,"1017":1,"1059":1}}],["请了解一个事实即硬盘驱动器的转速大约为7200rpm",{"2":{"804":1}}],["请记住",{"2":{"699":1,"1020":1}}],["请实现一个函数来将amazon",{"2":{"697":1}}],["请微调一个更大的预训练bert模型",{"2":{"690":1}}],["请减少",{"2":{"687":3}}],["请设计一个更好的代码",{"2":{"655":1}}],["请设计一种可学习的位置编码方法",{"2":{"402":1}}],["请进一步参考",{"2":{"648":1}}],["请想一个解决方案来解决上述两个问题",{"2":{"638":1}}],["请想出一个聪明的策略",{"2":{"223":1}}],["请尝试在这个框架的官方网站上找到文档",{"2":{"1009":1}}],["请尝试进一步提高环同步的性能吗",{"2":{"846":1}}],["请尝试不同的迭代周期数",{"2":{"830":2}}],["请尝试设计一个有注意力机制的模型",{"2":{"684":1}}],["请尝试解决这个问题",{"2":{"621":1}}],["请尝试做这个改进",{"2":{"505":1}}],["请取消下一行的注释",{"2":{"208":4}}],["请先别着急",{"2":{"185":1}}],["请试着用",{"2":{"706":1}}],["请试着写出解析解",{"2":{"621":1}}],["请试着去实现它",{"2":{"505":1}}],["请试着把它划分到多个gpu上",{"2":{"167":1}}],["请试着改变f以尽量减少它需要评估所有局部最小值的方式",{"2":{"118":1}}],["请参考vgg论文",{"2":{"511":1}}],["请参考下面的图表",{"2":{"89":1}}],["请参阅fasttext论文第3",{"2":{"759":1}}],["请参阅练习",{"2":{"116":1}}],["请参阅例如2015年tibshirani的优秀讲义笔记",{"2":{"114":1}}],["请参阅文章",{"2":{"95":1}}],["请参阅此维基百科文章",{"2":{"77":1}}],["请参阅",{"2":{"67":1,"73":1,"78":1,"86":2,"95":1,"519":1,"523":1,"540":1,"827":1,"831":1,"882":2}}],["请参见下面bertclassifier类中的self",{"2":{"688":1}}],["请参见如",{"2":{"300":1}}],["请参见",{"2":{"62":1,"66":1,"209":1,"827":1,"832":1}}],["请看",{"2":{"50":1}}],["请读者参考",{"2":{"26":1}}],["请注意glove和spacy中短语标记的不同形式",{"2":{"717":1}}],["请注意在牛顿法中",{"2":{"59":1}}],["请注意",{"2":{"20":1,"27":1,"41":1,"48":1,"55":1,"60":1,"88":2,"115":2,"122":1,"131":1,"136":2,"141":4,"147":1,"148":2,"191":2,"212":1,"244":1,"247":1,"284":1,"291":1,"298":1,"319":1,"346":1,"397":1,"418":1,"422":1,"423":2,"424":1,"467":4,"474":1,"540":1,"559":1,"565":1,"592":2,"635":2,"674":1,"675":1,"686":1,"700":1,"726":1,"736":1,"757":2,"772":1,"786":1,"790":5,"793":1,"795":1,"797":1,"802":1,"812":1,"835":1,"841":1,"842":1,"844":1,"848":1,"853":1,"854":1,"863":1,"866":1,"938":1,"968":1,"977":1,"991":1,"1017":1,"1028":1,"1030":1,"1032":1,"1035":1,"1088":1,"1092":1}}],["要明确指出监视的数据",{"2":{"1467":1}}],["要写成函数式",{"2":{"1465":1}}],["要手动开启深度监视",{"2":{"1463":1}}],["要用ref",{"2":{"1456":1}}],["要用什么样的函数来表示我们的假设",{"2":{"1107":1}}],["要知道",{"2":{"1185":1}}],["要回顾一下多元高斯分布和多元正态分布",{"2":{"1185":1}}],["要回答这个问题",{"2":{"1110":1}}],["要保证降维后",{"2":{"1158":1}}],["要保证权重向量比较小",{"2":{"270":1}}],["要提醒你c的作用类似于1",{"2":{"1144":1}}],["要是我有两倍甚至十倍数量的训练数据",{"2":{"1129":1}}],["要最小化该代价函数",{"2":{"1117":1}}],["要找到适合的",{"2":{"1086":1}}],["要解决房价预测问题",{"2":{"1063":1}}],["要重点说明一下",{"2":{"1017":1}}],["要",{"2":{"1011":1,"1022":1}}],["要生成矩阵积c=ab",{"2":{"999":1}}],["要生成多个不同形状的锚框",{"2":{"848":1}}],["要在不确定的情况下进行严格的推断",{"2":{"987":1}}],["要学习深度学习",{"2":{"987":1}}],["要配置matplotlib生成图形的属性",{"2":{"981":1}}],["要对msg持续关注",{"2":{"1520":1}}],["要对imagenet数据集的子集进行分类",{"2":{"909":1}}],["要对参数执行任何操作",{"2":{"431":1}}],["要使用kaggle竞赛的完整数据集",{"2":{"889":1}}],["要使其工作",{"2":{"790":3}}],["要标记任何生成的锚框",{"2":{"850":1}}],["要将小批量数据分配到所有设备上",{"2":{"828":1}}],["要将输出视为概率",{"2":{"643":1}}],["要理解后者",{"2":{"804":1}}],["要理解文本",{"2":{"754":1}}],["要形成",{"2":{"774":1}}],["要获得大小为m的词表",{"2":{"759":1}}],["要预测一个掩蔽词元而不使用标签作弊",{"2":{"736":1}}],["要预测的随机词元",{"2":{"721":1}}],["要预测的是一个特殊的属性",{"2":{"284":1}}],["要拆分句子",{"2":{"724":1}}],["要计算线性模型的输出",{"2":{"602":1}}],["要计算x",{"2":{"449":1}}],["要访问参数",{"2":{"595":1}}],["要特别注意训练和推断成本",{"2":{"563":1}}],["要归功于目标受众对它的广泛认可",{"2":{"475":1}}],["要运行此部分中的程序",{"2":{"445":1}}],["要了解混合式编程的工作原理",{"2":{"819":1}}],["要了解动态规划的工作方式",{"2":{"519":1}}],["要了解这为什么是合理的",{"2":{"423":1}}],["要了解为什么这更可取",{"2":{"116":1}}],["要构建它",{"2":{"413":1}}],["要显示的列数",{"2":{"357":1}}],["要显示的行数",{"2":{"357":1}}],["要怎么做才能使分布更均匀",{"2":{"323":1}}],["要想改进一种算法的效果",{"2":{"1129":1}}],["要想改变一个张量的形状而不改变元素数量和元素值",{"2":{"1017":1}}],["要想直观地了解块是如何工作的",{"2":{"423":1}}],["要想将选择偏向于感官输入",{"2":{"356":1}}],["要想找到足够的出现次数来获得准确的估计可能都不容易",{"2":{"316":1}}],["要想在未来获得更多的晋升",{"2":{"298":1}}],["要成为一名优秀的机器学习科学家需要具备批判性思考能力",{"2":{"253":1}}],["要么通过pcie直接连接到cpu",{"2":{"807":1}}],["要么通过树突进入另一个神经元",{"2":{"619":1}}],["要么是过拟合问题",{"2":{"1132":1}}],["要么是方差比较大",{"2":{"1132":1}}],["要么是偏差比较大",{"2":{"1132":1}}],["要么是一个标点符号",{"2":{"566":1}}],["要么是梯度消失",{"2":{"241":1}}],["要么是梯度爆炸",{"2":{"241":1}}],["要么付钱立即变得强大",{"2":{"354":1}}],["要么付钱来隐藏广告",{"2":{"354":1}}],["要么让参数通过",{"2":{"235":1}}],["要么让参数消失",{"2":{"235":1}}],["要么对于不常见特征而言降低太快",{"2":{"25":1}}],["要做到这一点的唯一方式就是选择这条绿线做决策界",{"2":{"1145":1}}],["要做到这一点",{"2":{"231":1}}],["要命名和记录模型的参数",{"2":{"222":1}}],["要实现单层的暂退法函数",{"2":{"172":1}}],["要求一个平方根",{"2":{"1111":1}}],["要求研究人员从100万个样本中训练模型",{"2":{"456":1}}],["要求",{"2":{"179":1}}],["要求函数对输入的随机噪声具有适应性",{"2":{"170":1}}],["要求函数光滑",{"2":{"170":1}}],["要求将其插入到计算图中并在调度过程中处理它",{"2":{"77":1}}],["要如何修改adagrad算法",{"2":{"31":1}}],["要花几页解释",{"2":{"26":1}}],["详见",{"2":{"505":1,"831":1}}],["详细信息",{"2":{"1392":1}}],["详细信息请参阅license文件",{"2":{"18":1}}],["详细说明了应用程序在各种情况下进行的操作",{"2":{"281":1}}],["详情请参见",{"2":{"105":1}}],["详情请参阅",{"2":{"66":1}}],["详尽的分析",{"2":{"26":1}}],["由尤雨溪",{"2":{"1526":1}}],["由该层",{"2":{"1120":1}}],["由该服务器聚合所有梯度",{"2":{"843":1}}],["由sl+1",{"2":{"1120":1}}],["由tom",{"2":{"1059":1}}],["由科尔莫戈罗夫于1933年提出",{"2":{"1027":1}}],["由图像和标签组成",{"2":{"882":1}}],["由矩形左上角的以及右下角的x和y坐标决定",{"2":{"858":1}}],["由hybridsequential和hybridblock类构造的模型能够通过调用hybridize函数将命令式程序转换为符号式程序",{"2":{"822":1}}],["由前端语言发出的操作被传递到后端执行",{"2":{"790":3}}],["由前一层提供",{"2":{"422":1}}],["由多个cpu核",{"2":{"789":1}}],["由多个层组成的组件或整个模型本身",{"2":{"422":1}}],["由跳元模型训练",{"2":{"788":1}}],["由σ",{"2":{"709":1}}],["由阅读段落和问题组成",{"2":{"660":1}}],["由独热标签向量表示",{"2":{"647":1}}],["由num",{"2":{"635":1}}],["由三个步骤组成",{"2":{"631":1}}],["由三个全连接层组成",{"2":{"136":1}}],["由10个类别的图像组成",{"2":{"585":1}}],["由遗忘门",{"2":{"552":1}}],["由一系列卷积层组成",{"2":{"507":1}}],["由一组可调整参数描述",{"2":{"422":1}}],["由指定的有效长度决定",{"2":{"369":1}}],["由下式给出",{"2":{"348":1}}],["由文本序列",{"2":{"341":1}}],["由",{"2":{"312":1,"340":1,"1296":1,"1528":1}}],["由什么构成一个简单的非线性函数可能是一个更复杂的问题",{"2":{"278":1}}],["由此优化数据中心",{"2":{"1150":1}}],["由此找到关系密切的人群",{"2":{"1150":1}}],["由此我们能知道可以用它们来做什么",{"2":{"1098":1}}],["由此我们得出了这一位置的输出张量值",{"2":{"126":1}}],["由此我们得到",{"2":{"21":1}}],["由此",{"2":{"294":1,"457":1,"641":1}}],["由此可以得到的数学公式是",{"2":{"616":1}}],["由此可见",{"2":{"282":1,"744":1}}],["由此可得",{"2":{"153":1}}],["由此卷积相应地调整为",{"2":{"158":1}}],["由两个卷积层组成",{"2":{"136":1}}],["由两个部分组成",{"2":{"136":1}}],["由于误差",{"2":{"1156":1}}],["由于是二维向量",{"2":{"1145":1}}],["由于是不带标签的数据",{"2":{"782":1}}],["由于我的电脑里同时安装了",{"2":{"1089":1}}],["由于我们还需要中间层的输出",{"2":{"920":1}}],["由于我们还没有调用反向传播",{"2":{"431":1}}],["由于我们不关心对背景的检测",{"2":{"853":1}}],["由于我们选择的是gpu0和gpu1",{"2":{"827":1}}],["由于我们仅从单个字符和特殊符号的词开始合并处理",{"2":{"757":1}}],["由于我们有4个特征和3个可能的输出类别",{"2":{"641":1}}],["由于我们使用随机权重初始化net模型",{"2":{"634":1}}],["由于我们只想得到一个标量输出",{"2":{"591":2}}],["由于我们处理的是浮点数",{"2":{"413":1}}],["由于我们的观察已经到了x604",{"2":{"351":1}}],["由于我们的训练和验证误差之间的泛化误差很小",{"2":{"258":1}}],["由于我们已经从零实现过softmax函数",{"2":{"220":1}}],["由于我们通常使用小卷积核",{"2":{"141":1}}],["由于我们将实现多层神经网络",{"2":{"137":1}}],["由于矩阵a是一个3×2的矩阵",{"2":{"1089":1}}],["由于矩阵元素是按顺序对齐的",{"2":{"77":1}}],["由于概念较为深入",{"2":{"1086":1}}],["由于概率论中的事件是来自样本空间的一组结果",{"2":{"1028":1}}],["由于a和b分别是3×1和1×2矩阵",{"2":{"1019":1}}],["由于adagrad算法是一种随机梯度下降算法",{"2":{"26":1}}],["由于sum",{"2":{"996":1}}],["由于softmax操作的性质",{"2":{"707":1}}],["由于softmax和相关的损失函数很常见",{"2":{"647":1}}],["由于记录了y的计算结果",{"2":{"976":1}}],["由于反向传播遵循链式法则和∇xy=w⊤",{"2":{"970":1}}],["由于篇幅限制",{"2":{"966":1,"1005":3}}],["由于类别预测结果放在最后一维",{"2":{"962":3}}],["由于偏移量使用了l1范数损失",{"2":{"962":1}}],["由于以特征图的每个单元为中心有4个锚框生成",{"2":{"959":1}}],["由于接近",{"2":{"953":1}}],["由于数据集中有些图像的尺寸可能小于随机裁剪所指定的输出尺寸",{"2":{"947":1}}],["由于数据迭代器",{"2":{"588":1}}],["由于每张图像上只有一个边界框",{"2":{"932":1}}],["由于每个稠密块都会带来通道数的增加",{"2":{"481":1}}],["由于合成图像是风格迁移所需迭代的模型参数",{"2":{"920":1}}],["由于图像打印函数要求每个像素的浮点数值在0～1之间",{"2":{"919":1}}],["由于锚框",{"2":{"912":1}}],["由于锚框中的",{"2":{"912":1}}],["由于lr",{"2":{"907":1}}],["由于原始的训练集有50000张图像",{"2":{"890":1}}],["由于深度神经网络可以有效地表示多个层次的图像",{"2":{"886":1}}],["由于深度学习框架的高级api对代码进行了更多的优化",{"2":{"326":1}}],["由于深度学习框架中的优化求解器早已构建了动量法",{"2":{"92":1}}],["由于整个模型需要从头开始训练",{"2":{"874":1}}],["由于模型参数是在imagenet数据集上预训练的",{"2":{"873":1}}],["由于模型使用了步幅为32的转置卷积层",{"2":{"866":1}}],["由于模型重点在发生计算的地方",{"2":{"618":1}}],["由于当今的gpu拥有大量的显存",{"2":{"841":1}}],["由于还没有进行任何计算",{"2":{"835":1}}],["由于还没有指定各种门的操作",{"2":{"554":1}}],["由于可用的显存呈线性扩展",{"2":{"832":1}}],["由于减少了数据包的开销",{"2":{"812":1}}],["由于减少了深度学习框架的额外开销",{"2":{"82":1}}],["由于gpu通常有16个通道",{"2":{"812":1}}],["由于内存对齐是64位边界",{"2":{"802":1}}],["由于内存和计算限制",{"2":{"30":1}}],["由于两者都在同一处理器上执行",{"2":{"790":1}}],["由于两个实例具有相同的模型参数",{"2":{"442":1}}],["由于连续词袋模型中存在多个上下文词",{"2":{"785":1}}],["由于连续单词对",{"2":{"316":1}}],["由于任意两个不同词的独热向量之间的余弦相似度为0",{"2":{"781":1}}],["由于上下文窗口大小不同",{"2":{"776":1}}],["由于填充的存在",{"2":{"767":1}}],["由于向量维度",{"2":{"762":1}}],["由于具有相似结构的词之间共享来自子词的参数",{"2":{"756":1}}],["由于初始值不同",{"2":{"743":1}}],["由于h",{"2":{"743":1}}],["由于ht从未被观测到",{"2":{"347":1}}],["由于tensorflow的tensors是不可变的",{"2":{"1021":1}}],["由于tensorflow名称有点长",{"2":{"1017":1}}],["由于tensorflow采用",{"2":{"148":1}}],["由于transformer编码器中的自注意力",{"2":{"737":1}}],["由于语义分割的输入图像和标签在像素上一一对应",{"2":{"950":1}}],["由于语义上的相似性",{"2":{"674":1}}],["由于语言模型的自回归特性",{"2":{"732":1}}],["由于二叉树结构",{"2":{"709":1}}],["由于跳元模型和连续词袋模型的相似性",{"2":{"707":1}}],["由于情感可以被分类为离散的极性或尺度",{"2":{"691":1}}],["由于计算资源有限",{"2":{"688":1}}],["由于计算每个输出o1",{"2":{"641":1}}],["由于它们总是相同的",{"2":{"651":1}}],["由于所有y^j都是预测的概率",{"2":{"646":1}}],["由于y是一个长度为q的独热编码向量",{"2":{"646":1}}],["由于y位于第二个gpu上",{"2":{"449":1}}],["由于等式运算符",{"2":{"634":1}}],["由于精度受限",{"2":{"624":1}}],["由于平方误差函数中的二次方项",{"2":{"611":1}}],["由于预测的序列越短获得的pn值越高",{"2":{"578":1}}],["由于n元语法越长则匹配难度越大",{"2":{"578":1}}],["由于机器翻译数据集由语言对组成",{"2":{"567":1}}],["由于门控循环单元更简单",{"2":{"538":1}}],["由于",{"2":{"532":1,"712":1,"732":1,"862":1,"1012":1}}],["由于使用了长短期记忆网络模型来实例化两个层",{"2":{"529":1}}],["由于使用1s^t+ϵ而不是1s^t+ϵ进行缩放",{"2":{"33":1}}],["由于梯度链更长",{"2":{"524":1}}],["由于梯度从最初开始衰减",{"2":{"27":1}}],["由于双向循环神经网络使用了过去的和未来的数据",{"2":{"523":1}}],["由于p",{"2":{"519":1,"1034":1}}],["由于时间步3所基于的时间步1和2处的输出子序列已从",{"2":{"513":1}}],["由于vgg",{"2":{"509":1}}],["由于该网络使用8个卷积层和3个全连接层",{"2":{"508":1}}],["由于之前已经使用了步幅为2的最大汇聚层",{"2":{"502":1}}],["由于新模型可能得出更优的解来拟合训练数据集",{"2":{"500":1}}],["由于新增的注意力机制",{"2":{"376":1}}],["由于批量规范化在完整的小批量上运行",{"2":{"468":1}}],["由于尚未在理论上明确的原因",{"2":{"467":1}}],["由于在本书中我们将频繁地进行运行时间的基准测试",{"2":{"615":1}}],["由于在训练过程中",{"2":{"467":1}}],["由于在当前时间步中",{"2":{"340":1}}],["由于单位方差",{"2":{"467":1}}],["由于早期gpu显存有限",{"2":{"459":1}}],["由于早期的人工神经网络受到生物神经网络的启发",{"2":{"242":1}}],["由于imagenet中大多数图像的宽和高比mnist图像的多10倍以上",{"2":{"459":1}}],["由于自动微分",{"2":{"422":1}}],["由于解码器自注意力的自回归属性",{"2":{"409":1}}],["由于输出是浮点数",{"2":{"399":1}}],["由于输入矩阵沿0轴降维以生成输出向量",{"2":{"995":1}}],["由于输入维度",{"2":{"417":1}}],["由于输入图像是三维的",{"2":{"158":1}}],["由于输入和卷积核都有ci个通道",{"2":{"120":1}}],["由于查询",{"2":{"395":1}}],["由于键包含的是相同的元素",{"2":{"370":1}}],["由于注意力权重是概率分布",{"2":{"367":1}}],["由于包含了自主性提示",{"2":{"358":1}}],["由于训练样本数量有限",{"2":{"869":1}}],["由于训练数据集并不受我们控制",{"2":{"611":1}}],["由于训练数据中这个文本序列的下一个字符是",{"2":{"341":1}}],["由于训练损失很小",{"2":{"351":1}}],["由于历史原因",{"2":{"342":1,"616":1}}],["由于隐藏层中隐状态的循环计算",{"2":{"341":1}}],["由于下一个小批量数据中的第i个子序列样本",{"2":{"335":1}}],["由于文本序列可以是任意长的",{"2":{"319":1}}],["由于序列的长距离依赖性",{"2":{"561":1}}],["由于序列长度为n",{"2":{"397":1}}],["由于序列长度是n",{"2":{"397":1}}],["由于序列数据本质上是连续的",{"2":{"319":1}}],["由于序列可能相当长",{"2":{"306":1}}],["由于通过时间反向传播是反向传播在循环神经网络中的应用方式",{"2":{"312":1}}],["由于表示学习",{"2":{"302":1}}],["由于更新的权重衰减部分仅依赖于每个参数的当前值",{"2":{"278":1}}],["由于权重衰减在神经网络优化中很常用",{"2":{"278":1}}],["由于不可微性或其他复杂性难以直接优化",{"2":{"286":1}}],["由于不能基于训练误差来估计泛化误差",{"2":{"267":1}}],["由于不知道这个比率",{"2":{"191":1}}],["由于这项原始的研究非常具有影响力",{"2":{"1141":1}}],["由于这是一种较为深入的概念",{"2":{"1086":1}}],["由于这些区域通常有重叠",{"2":{"938":1}}],["由于这个过程是训练机器学习算法的基础",{"2":{"600":1}}],["由于这里使用的是门控循环单元",{"2":{"573":1}}],["由于这里使用的是值范围在−1和1之间的固定位置编码",{"2":{"407":1}}],["由于这里使用了比较深的网络",{"2":{"483":1}}],["由于这里使用fashion",{"2":{"461":4}}],["由于这里的唤醒词是任意选择的自然语言",{"2":{"282":1}}],["由于这只是一个线性回归问题",{"2":{"259":1}}],["由于这种差异必然会收敛到零",{"2":{"115":1}}],["由于泛化是机器学习中的基本问题",{"2":{"253":1}}],["由于激活函数是深度学习的基础",{"2":{"234":1}}],["由于激活函数ϕ是按元素计算的",{"2":{"164":1}}],["由于环境的磨损",{"2":{"193":1}}],["由于真实的注释数据获取成本很高",{"2":{"186":1}}],["由于汇聚层中没有参数",{"2":{"147":1}}],["由于快门的移动而引起的相机振动",{"2":{"145":1}}],["由于完整的数据集位于内存中",{"2":{"137":1}}],["由于卷积核是从数据中学习到的",{"2":{"130":1}}],["由于卷积神经网络的设计是用于探索图像数据",{"2":{"125":1}}],["由于缺乏规范化",{"2":{"106":1}}],["由于优化算法的目标函数通常是基于训练数据集的损失函数",{"2":{"99":1}}],["由于对过去的数据进行了指数降权",{"2":{"96":1}}],["由于o只是一个正交矩阵",{"2":{"94":1}}],["由于q是正定的",{"2":{"94":1}}],["由于相互抵消了对方的振荡",{"2":{"88":1}}],["由于其功效",{"2":{"86":1}}],["由于小批量梯度由正在被平均计算的b",{"2":{"78":1}}],["由于x的高和宽是输入图像高和宽的1",{"2":{"938":1}}],["由于x中的每一行代表一个数据样本",{"2":{"644":1}}],["由于x中的每一行对应于小批量中的一个样本",{"2":{"232":1}}],["由于xt和小批量bt的所有元素都是从训练集中随机抽出的",{"2":{"78":1}}],["由于x=",{"2":{"46":1}}],["由于大多数代码都是标准的",{"2":{"67":1}}],["由于多变量情况下的证明是对以下一维参数情况证明的直接拓展",{"2":{"60":1}}],["由于学习率过大",{"2":{"53":1}}],["由于墙壁的",{"2":{"48":1}}],["由于∫p",{"2":{"42":1}}],["梯度检验",{"0":{"1124":1},"2":{"1193":1}}],["梯度值",{"2":{"1111":1}}],["梯度值应该是一个2×1的向量",{"2":{"1111":1}}],["梯度向量的两个元素对应这里的两个偏导数项",{"2":{"1111":1}}],["梯度是一个向量",{"2":{"985":1}}],["梯度对于设计深度学习中的优化算法有很大用处",{"2":{"983":1}}],["梯度不会向后流经u到x",{"2":{"976":1}}],["梯度i的计算可以定义为",{"2":{"844":1}}],["梯度可以从第一个节点发送到第二个节点",{"2":{"842":1}}],["梯度可以作为一个有效的代理",{"2":{"30":1}}],["梯度在gpu上聚合",{"2":{"832":1}}],["梯度时",{"2":{"797":2}}],["梯度",{"0":{"983":1},"2":{"784":2,"835":1}}],["梯度求解将有一个非常长的链",{"2":{"522":1}}],["梯度会发生什么情况",{"2":{"437":2}}],["梯度会发生什么状况",{"2":{"344":1}}],["梯度和额外信息",{"2":{"431":1}}],["梯度裁剪可以防止梯度爆炸",{"2":{"336":1}}],["梯度裁剪提供了一个快速修复梯度爆炸的方法",{"2":{"334":1}}],["梯度裁剪",{"0":{"334":1}}],["梯度∂ht",{"2":{"310":1}}],["梯度∂x¯f¯",{"2":{"26":1}}],["梯度爆炸可能同样令人烦恼",{"2":{"243":1}}],["梯度爆炸",{"0":{"243":1}}],["梯度消失和梯度爆炸是深度网络中常见的问题",{"2":{"249":1}}],["梯度消失和梯度爆炸",{"0":{"241":1},"1":{"242":1,"243":1,"244":1}}],["梯度消失可能会导致优化停滞",{"2":{"104":1}}],["梯度消失",{"0":{"103":1,"242":1}}],["梯度开始发散",{"2":{"95":1}}],["梯度由∂xf",{"2":{"94":1}}],["梯度由∇f",{"2":{"57":1}}],["梯度还额外享受更有效的好处",{"2":{"86":1}}],["梯度方法的基础",{"2":{"86":1}}],["梯度的自动计算",{"2":{"161":1}}],["梯度的平均值",{"2":{"86":1}}],["梯度的大小取决于λ和与最佳值的差值",{"2":{"26":1}}],["梯度中的每个偏导数元素∂f",{"2":{"57":1}}],["梯度下降收敛更快",{"2":{"1110":1}}],["梯度下降与正规方程的比较",{"2":{"1085":1}}],["梯度下降算法的每次迭代受到学习率的影响",{"2":{"1083":1}}],["梯度下降算法收敛所需要的迭代次数根据模型的不同而不同",{"2":{"1083":1}}],["梯度下降算法需要非常多次的迭代才能收敛",{"2":{"1082":1}}],["梯度下降算法和线性回归算法比较如图",{"2":{"1069":1}}],["梯度下降算法如下",{"2":{"1068":1}}],["梯度下降是很常用的算法",{"2":{"1069":1}}],["梯度下降是一个用来求函数最小值的算法",{"2":{"1067":1}}],["梯度下降法是一个非常有用的算法",{"2":{"1085":1}}],["梯度下降法实践2",{"0":{"1083":1},"2":{"1193":1}}],["梯度下降法实践1",{"0":{"1082":1},"2":{"1193":1}}],["梯度下降法比正规方程要更适用一些",{"2":{"1069":1}}],["梯度下降法会自动采取更小的幅度",{"2":{"1068":1}}],["梯度下降法都会检查每个参数",{"2":{"287":1}}],["梯度下降一步后",{"2":{"1068":1}}],["梯度下降也可以收敛到局部最低点",{"2":{"1068":1}}],["梯度下降中",{"2":{"1067":1}}],["梯度下降背后的思想是",{"2":{"1067":1}}],["梯度下降最简单的用法是计算损失函数",{"2":{"613":1}}],["梯度下降并不是非常",{"2":{"76":1}}],["梯度下降会可能陷入局部极小值",{"2":{"63":1}}],["梯度下降的线性回归",{"0":{"1069":1},"2":{"1193":1}}],["梯度下降的直观理解",{"0":{"1068":1},"2":{"1193":1}}],["梯度下降的一个关键问题是我们可能会超过目标或进展不足",{"2":{"62":1}}],["梯度下降的有效预处理相当于为每个变量选择不同的学习率",{"2":{"61":1}}],["梯度下降和线搜索",{"0":{"62":1}}],["梯度下降",{"0":{"53":1,"1067":1},"1":{"54":1,"55":1,"56":1,"57":1,"58":1,"59":1,"60":1,"61":1,"62":1,"63":1,"64":1},"2":{"287":1,"1085":1,"1193":1}}],["那个样本是x",{"2":{"1145":1}}],["那又是另外一种带有很多参数的学习算法",{"2":{"1141":1}}],["那又该如何编写程序",{"2":{"282":1}}],["那为什么增加的一项λ=∑j=1nθj2",{"2":{"1115":1}}],["那为什么不去模仿我们所认识的最神奇的学习机器",{"2":{"1098":1}}],["那我希望你可以对向量化有一个更好的理解",{"2":{"1093":1}}],["那我们就必须让算法从数据中发现这一切",{"2":{"1061":1}}],["那我们可以轻而易举的训练得到它",{"2":{"500":1}}],["那我们来看一下",{"2":{"40":1}}],["那也能用",{"2":{"1092":1}}],["那对于矩阵x",{"2":{"1086":1}}],["那里有大型的计算机集群",{"2":{"1061":1}}],["那是一个非常常见的体系",{"2":{"1148":1}}],["那是另一个",{"2":{"1061":1}}],["那是鲍勃",{"2":{"251":1}}],["那这两个问题",{"2":{"1060":1}}],["那这就是我们所求的",{"2":{"26":1}}],["那你怎么处理无限多个特征",{"2":{"1060":1}}],["那种算法不仅能处理2种3种或5种特征",{"2":{"1060":1}}],["那基于这组数据",{"2":{"1060":1}}],["那应该如何分配工作",{"2":{"830":2}}],["那些我们在以前的视频看过了",{"2":{"1185":1}}],["那些又长又复杂的编程练习",{"2":{"1176":1}}],["那些计算机经常协作工作",{"2":{"1150":1}}],["那些是第二类的人",{"2":{"1061":1}}],["那些具有非极大值置信度的边界框被抑制了",{"2":{"854":1}}],["那些难以优化的模型效果要更好",{"2":{"613":1}}],["那些在计算上看起来不可行的神经网络算法变得热门起来",{"2":{"300":1}}],["那并不高效",{"2":{"591":1}}],["那可能会赢得100万美元的奈飞奖",{"2":{"290":1}}],["那就监视哪些属性",{"2":{"1467":1}}],["那就能很有力地表明电影i和电影",{"2":{"1191":1}}],["那就意味着我们需要θ的范数非常大",{"2":{"1145":1}}],["那就一定会解决问题的是吧",{"2":{"1129":1}}],["那就请学习接下来的一组视频",{"2":{"1070":1}}],["那就是θ1",{"2":{"1145":1}}],["那就是我们在幻灯片中给出的优化问题",{"2":{"1144":1}}],["那就是",{"2":{"1139":1,"1176":1}}],["那就是使用神经网络来实现自动驾驶",{"2":{"1127":1}}],["那就是它可以允许你定义一个函数",{"2":{"1092":1}}],["那就是监督学习",{"2":{"1060":1}}],["那就是时候把它们上传到kaggle了",{"2":{"213":1}}],["那就麻烦大了",{"2":{"256":1}}],["那很不错",{"2":{"86":1}}],["那通常我们很难在其他条件下看到好的结果",{"2":{"38":1}}],["那么最好写函数式",{"2":{"1465":1}}],["那么最终可能会专注于强化学习",{"2":{"298":1}}],["那么获得更多的数据用于训练模型",{"2":{"1173":1}}],["那么获取数据是没有意义的",{"2":{"1016":1}}],["那么便能将这个任务分配给多台计算机",{"2":{"1169":1}}],["那么算法的总体表现将不受影响",{"2":{"1166":1}}],["那么算法和数据之间的关系是什么",{"2":{"304":1}}],["那么压缩率为90",{"2":{"1158":1}}],["那么压缩幅度也更大",{"2":{"1089":1}}],["那么聚类算法一般用来做什么呢",{"2":{"1150":1}}],["那么内积θtx",{"2":{"1145":1}}],["那么那条红线的长度p是正值",{"2":{"1145":1}}],["那么在让代价函数最小化的过程中",{"2":{"1144":1}}],["那么在知道宽度后",{"2":{"1017":1}}],["那么更多时候",{"2":{"1141":1}}],["那么更新方程会是什么样子",{"2":{"280":1}}],["那么让我们来看一看",{"2":{"1141":1}}],["那么特征捕捉到之后",{"2":{"1141":1}}],["那么得到大量的数据通常是保证我们具有一个高性能算法的最佳方式",{"2":{"1141":1}}],["那么从这些例子中看起来的话",{"2":{"1141":1}}],["那么误差只有0",{"2":{"1139":1}}],["那么多半是出现两种情况",{"2":{"1132":1}}],["那么$",{"2":{"1115":1}}],["那么就可以在组件标签上多次使用v",{"2":{"1500":1}}],["那么就可认为得到一个正确的分类",{"2":{"1112":1}}],["那么就会失去原有的意义",{"2":{"345":1}}],["那么梯度下降所做的就是反复执行这些更新",{"2":{"1111":1}}],["那么梯度下降法更新其实什么都没做",{"2":{"1068":1}}],["那么梯度下降法可能会越过最低点",{"2":{"1068":1}}],["那么应用特征缩放的方法",{"2":{"1110":1}}],["那么应该怎样把数据读入",{"2":{"1089":1}}],["那么应该已经知道一些基本的线性代数",{"2":{"989":1}}],["那么假设函数的输出值可能远大于",{"2":{"1106":1}}],["那么假定第二个维度存储每个类的预测分数",{"2":{"634":1}}],["那么每个像素都被映射到你舌头的某个位置上",{"2":{"1098":1}}],["那么也许存在一种学习算法",{"2":{"1098":1}}],["那么也许在查看许多训练样本后",{"2":{"252":1}}],["那么躯体感觉皮层也能学会",{"2":{"1098":1}}],["那么动物就可以完成视觉辨别任务",{"2":{"1098":1}}],["那么结果表明听觉皮层将会学会",{"2":{"1098":1}}],["那么什么是向量",{"2":{"1093":1}}],["那么什么是交叉熵",{"2":{"652":1}}],["那么你已经可以使用机器学习方法有效的解决实际问题了",{"2":{"1135":1}}],["那么你可能想要区分哪些天是晴天",{"2":{"1112":1}}],["那么你可以自己计算j=0",{"2":{"1093":1}}],["那么你就不需要自己选择",{"2":{"1111":1}}],["那么你就需要用这个式子",{"2":{"1110":1}}],["那么你就可以写成两个向量的内积",{"2":{"1093":1}}],["那么你完全可以跳过这组关于线性代数的选修视频",{"2":{"1070":1}}],["那么通常你会发现",{"2":{"1093":1}}],["那么方法是用a",{"2":{"1090":1}}],["那么可以使用写字板程序",{"2":{"1092":1}}],["那么可以键入",{"2":{"1089":1}}],["那么可能拥有一个100gbe的网卡",{"2":{"841":1}}],["那么用",{"2":{"1089":1}}],["那么用于训练网络的",{"2":{"319":1}}],["那么只需键入a像这样",{"2":{"1088":1}}],["那么m×n即4×2",{"2":{"1072":1}}],["那么mask",{"2":{"940":1}}],["那么请看一看下一组的视频",{"2":{"1070":1}}],["那么我刚刚画红线的这一项就是向量θ的长度或范数",{"2":{"1145":1}}],["那么我想说主要缺点是它们比梯度下降法复杂多了",{"2":{"1111":1}}],["那么我就要使用第二个格子",{"2":{"1091":1}}],["那么我又重新得到矩阵",{"2":{"1090":1}}],["那么我可以这么画",{"2":{"1060":1}}],["那么我们以什么为依据为eve推荐电影呢",{"2":{"1192":1}}],["那么我们学到了些什么呢",{"2":{"1176":1}}],["那么我们就会有一个很方便的方法来度量两部电影之间的相似性",{"2":{"1191":1}}],["那么我们就选k=3",{"2":{"1154":1}}],["那么我们就可以让他们避免过度拟合了",{"2":{"1115":1}}],["那么我们就需要自己编写代码来计算代价函数j",{"2":{"1111":1}}],["那么我们就不可能将这种情景与分布完全没有变化的情景区分开",{"2":{"180":1}}],["那么我们需要做的是编写代码",{"2":{"1111":1}}],["那么我们需要对hwa个锚框进行分类",{"2":{"954":1}}],["那么我们有时可能会感到",{"2":{"651":1}}],["那么我们预测的类别是2",{"2":{"643":1}}],["那么我们将创建一个长度为n的全0向量",{"2":{"330":1}}],["那么我们很可能存在数据处理错误",{"2":{"210":1}}],["那么我们可能会需要选择一个较小的学习率α",{"2":{"1167":1}}],["那么我们可能需要相应地调整我们的阈值",{"2":{"201":1}}],["那么我们可以直接将它运送到客户那里",{"2":{"1178":1}}],["那么我们可以这么做",{"2":{"1090":1}}],["那么我们可以证明p",{"2":{"1027":1}}],["那么我们可以说这两种可能性是相等的",{"2":{"1025":1}}],["那么我们可以说网络发挥更稳定",{"2":{"171":1}}],["那么我们可以得到对这些权重的一致估计",{"2":{"192":1}}],["那么我们的模型本身可能存在一些错误",{"2":{"1167":1}}],["那么我们的情景允许病态的情况",{"2":{"180":1}}],["那么我们的参数化就出现了严重的不匹配",{"2":{"61":1}}],["那么我们是否可以",{"2":{"129":1}}],["那么关于这个问题",{"2":{"1060":1}}],["那么关键的挑战就是如何注入这种噪声",{"2":{"170":1}}],["那么所有六个结果",{"2":{"1026":1}}],["那么矩阵",{"2":{"999":1}}],["那么g",{"2":{"969":1,"971":1}}],["那么gpu的综合性能就是cpu的16×1",{"2":{"457":1}}],["那么gpu比cpu强在哪里呢",{"2":{"457":1}}],["那么相同空间位置可以看作含有c个单元",{"2":{"913":1}}],["那么相应的重要性权重会是无穷大",{"2":{"191":1}}],["那么python解释器产生的开销可能会非常大",{"2":{"816":1}}],["那么有效的随机读操作次数将高达4倍",{"2":{"802":1}}],["那么有一个简单的解决方案",{"2":{"98":1}}],["那么网络就不应该拖累计算速度",{"2":{"801":1}}],["那么cpu",{"2":{"801":1}}],["那么处理器就无事可做",{"2":{"801":1}}],["那么batch",{"2":{"736":3}}],["那么softmax运算可以按行",{"2":{"644":1}}],["那么小批量样本的特征为x∈rn×d",{"2":{"644":1}}],["那么将这个问题转变为回归问题",{"2":{"640":1}}],["那么exp⁡",{"2":{"624":1}}],["那么如何初始化解码器的隐状态",{"2":{"580":1}}],["那么如何使用较大的步幅呢",{"2":{"142":1}}],["那么如果文本序列的词元数目少于num",{"2":{"568":1}}],["那么为什么隐状态需要再次使用tanh函数来确保输出值范围在",{"2":{"563":1}}],["那么为什么googlenet这个网络如此有效呢",{"2":{"487":1}}],["那么编码器和解码器必须是同一类型的神经网络吗",{"2":{"537":1}}],["那么该选取哪种序列搜索策略呢",{"2":{"515":1}}],["那么贪心搜索存在的问题是什么呢",{"2":{"513":1}}],["那么再向前拓展一步",{"2":{"479":1}}],["那么对于这些问题",{"2":{"1182":1}}],["那么对于卷积层",{"2":{"470":1}}],["那么对于标签为yi的任何训练样本i",{"2":{"192":1}}],["那么分配给这个键对应值yi的注意力权重就会越大",{"2":{"388":1}}],["那么分类器在测试数据上很难取得高于10",{"2":{"169":1}}],["那么具有bahdanau注意力的循环神经网络编码器",{"2":{"377":1}}],["那么两个向量的点积的均值为0",{"2":{"370":1}}],["那么令人惊讶",{"2":{"345":1}}],["那么任意输出所需的维度是多少",{"2":{"344":1}}],["那么本章的循环神经网络",{"2":{"305":1}}],["那么机器学习的问题就在于",{"2":{"1060":1}}],["那么机器学习模型可能会无意中捕捉到历史残留的不公正",{"2":{"284":1}}],["那么机器就可以被认为是",{"2":{"299":1}}],["那么无监督学习可以回答什么样的问题呢",{"2":{"296":1}}],["那么给出这两个数据样本",{"2":{"290":1}}],["那么他家的特征向量",{"2":{"290":1}}],["那么观察结果",{"2":{"289":1}}],["那么模型面对这种问题肯定是表现不佳的",{"2":{"316":1}}],["那么模型很可能无效",{"2":{"284":1}}],["那么模型可能做得很糟糕",{"2":{"210":1}}],["那么数据科学毫无用武之地",{"2":{"284":1}}],["那么到底什么是参数呢",{"2":{"282":1}}],["那么它的最小值将是θ1=5",{"2":{"1111":1}}],["那么它的输出就增加为4×4",{"2":{"141":1}}],["那么它就像这样发送电脉冲给大脑的",{"2":{"1099":1}}],["那么它就是好的",{"2":{"254":1}}],["那么它会给你一条消息",{"2":{"1094":1}}],["那么它们的乘积就可以表示为图中所示的形式",{"2":{"1075":1}}],["那么它将不会得到优化",{"2":{"819":1}}],["那么混淆矩阵c将是可逆的",{"2":{"192":1}}],["那么这将是一种用来选择聚类个数的合理方法",{"2":{"1154":1}}],["那么这将会是一个很好的方式",{"2":{"1141":1}}],["那么这就是个正样本",{"2":{"1168":1}}],["那么这就是你的肩关节",{"2":{"1154":1}}],["那么这就有大量的信息来告诉我中间我需要填的词是",{"2":{"1141":1}}],["那么这一项也就是0了",{"2":{"1143":1}}],["那么这种说法在什么时候是真",{"2":{"1141":1}}],["那么这种方法确实足够了",{"2":{"229":1}}],["那么这很难让你做出决定",{"2":{"1138":1}}],["那么这些算法就不太可能会过度拟合",{"2":{"1141":1}}],["那么这些算法就是为我们优化代价函数的不同方法",{"2":{"1111":1}}],["那么这些诊断法则怎样帮助我们判断",{"2":{"1135":1}}],["那么这两种情况",{"2":{"1132":1}}],["那么这个命令就调用fminunc",{"2":{"1111":1}}],["那么这个假设就是0是所有的预测值",{"2":{"1092":1}}],["那么这个数据就很容易压缩",{"2":{"651":1}}],["那么这课件上所有的一切对你来说都是新知识",{"2":{"1070":1}}],["那么这里的",{"2":{"849":1}}],["那么这里的泛化差距就高达90",{"2":{"169":1}}],["那么这样的操作可能会阻塞",{"2":{"450":1}}],["那么这在小批量抽样中会带来怎样的问题",{"2":{"323":1}}],["那么这类单词出现一次的机会可能都找不到",{"2":{"316":1}}],["那么这对应于半空间上所有的x",{"2":{"47":1}}],["那么默认情况下",{"2":{"147":1}}],["那么输出形状将是",{"2":{"140":1}}],["那么以上",{"2":{"129":1}}],["那么当ci=1时",{"2":{"120":1}}],["那么卷积核的输入通道数也需要为ci",{"2":{"120":1}}],["那么仅在50次迭代之后",{"2":{"114":1}}],["那么f",{"2":{"101":2,"501":1}}],["那么x∩y也是凸集的",{"2":{"40":1}}],["那么",{"2":{"20":1,"284":1,"318":1,"469":1,"500":1,"540":1,"785":1,"848":1,"1058":1,"1063":2,"1110":1,"1112":2,"1130":1,"1143":9,"1150":2,"1185":1,"1191":1}}],["因果关系",{"0":{"349":1},"2":{"296":1}}],["因而被算法认为是正常的",{"2":{"1183":1}}],["因而我们的算法可以一次从3个实例中学习并更新模型",{"2":{"1168":1}}],["因而使用较少的计算机内存或磁盘空间",{"2":{"1156":1}}],["因而",{"2":{"1063":1,"1156":1}}],["因而在短期内不可能做到",{"2":{"269":1}}],["因而可以去掉期望",{"2":{"115":1}}],["因其在计算机视觉任务中的高效性能而受到广泛关注",{"2":{"135":1}}],["因此被大量互联网公司选用",{"2":{"1359":1}}],["因此被称为",{"2":{"395":1}}],["因此被称为深度学习",{"2":{"285":1}}],["因此创造出一个比较大的判定边界",{"2":{"1184":1}}],["因此报价",{"2":{"1168":1}}],["因此算法虽然会逐渐走向全局最小值的位置",{"2":{"1165":1}}],["因此可能会丢失非常重要的特征",{"2":{"1162":1}}],["因此可以得到u1×v1+u2×v2",{"2":{"1145":1}}],["因此可以将utv=p⋅",{"2":{"1145":1}}],["因此可以将其删去",{"2":{"1144":1}}],["因此可以用d",{"2":{"977":1}}],["因此可以多次调用",{"2":{"874":1}}],["因此可以共享此实例",{"2":{"702":3}}],["因此可以与其他带有load",{"2":{"321":1}}],["因此可以被过滤掉",{"2":{"318":1}}],["因此可以通过q=o⊤λo分解为正交",{"2":{"94":1}}],["因此结果为k×1维度",{"2":{"1159":1}}],["因此你提出好的软件库和好的软件包来做这样一些事儿",{"2":{"1148":1}}],["因此由于今天我们中的很少人",{"2":{"1148":1}}],["因此由观察可知",{"2":{"388":1}}],["因此唯一的办法就是θ的范数变大",{"2":{"1145":1}}],["因此支持向量机做的全部事情",{"2":{"1145":1}}],["因此支持向量机有时被称为大间距分类器",{"2":{"1144":1}}],["因此utv就是两个实数正常相乘",{"2":{"1145":1}}],["因此p就是长度",{"2":{"1145":1}}],["因此将一些常数乘以你的最小化项",{"2":{"1143":1}}],["因此偏差问题",{"2":{"1141":1}}],["因此我要调用这些",{"2":{"1141":1}}],["因此我们讨论了学习算法的评价法",{"2":{"1176":1}}],["因此我们仅有两个特征x1",{"2":{"1145":1}}],["因此我们的代价函数会比逻辑回归更加复杂一些",{"2":{"1120":1}}],["因此我们真正需要的是编写程序来找出这些最小化代价函数的θ0和θ1的值",{"2":{"1066":1}}],["因此我们使用深度学习框架的函数同时抽取多个样本",{"2":{"1026":1}}],["因此我们创建一个足够长的位置嵌入参数",{"2":{"734":3}}],["因此我们考虑对h1",{"2":{"519":1}}],["因此我们构建了一个通道数较少的网络",{"2":{"509":1}}],["因此我们需要使用更大的学习率",{"2":{"874":1}}],["因此我们需要更好地理解它的计算方式",{"2":{"647":1}}],["因此我们需要指定整个特征的数量",{"2":{"472":1}}],["因此我们需要点积的边界",{"2":{"115":1}}],["因此我们不能像以前在引入其他层时那样忽略批量大小",{"2":{"468":1}}],["因此我们通常包含",{"2":{"467":1}}],["因此我们实现了一个fixedhiddenmlp类",{"2":{"425":1}}],["因此我们期望模型能有很好的工作效果",{"2":{"351":1}}],["因此我们只需要满足某个长度为τ的时间跨度",{"2":{"347":1}}],["因此我们省略了细节",{"2":{"339":1}}],["因此我们省略了多变量情况的证明",{"2":{"60":1}}],["因此我们在处理数据时需要解决这个问题",{"2":{"319":1}}],["因此我们把所有文本行拼接到一起",{"2":{"318":1}}],["因此我们将y",{"2":{"634":1}}],["因此我们将其做为本章剩余部分和",{"2":{"564":1}}],["因此我们将原始序列移位一个词元作为标签",{"2":{"341":1}}],["因此我们将在本章中重点介绍语言模型",{"2":{"305":1}}],["因此我们将主要使用高级api",{"2":{"137":1}}],["因此我们可能需要一个足够丰富的模型族",{"2":{"282":1}}],["因此我们可以为随机变量指定值的可取范围",{"2":{"1028":1}}],["因此我们可以说1发生的概率为16",{"2":{"1026":1}}],["因此我们可以分别为源语言和目标语言构建两个词表",{"2":{"567":1}}],["因此我们可以将缺失值设置为0",{"2":{"209":1}}],["因此我们可以将h重写为",{"2":{"94":1}}],["因此我们可以使用一个",{"2":{"152":1}}],["因此我们有",{"2":{"115":1}}],["因此特征捕捉",{"2":{"1141":1}}],["因此已经有一系列许多不同的研究显示了类似的结果",{"2":{"1141":1}}],["因此他们使用了一个方差",{"2":{"1141":1}}],["因此如果你将u和v交换位置",{"2":{"1145":1}}],["因此如果你有一系列特征比如x1",{"2":{"1129":1}}],["因此如果想使用分布式优化的同步算法就需要同步",{"2":{"843":1}}],["因此总是把时间浪费在毫无意义的尝试上",{"2":{"1129":1}}],["因此总共添加了2行或2列",{"2":{"141":4}}],["因此要把这个应用到逻辑回归",{"2":{"1111":1}}],["因此第一个文件应该符合编程练习中pdf文件的要求",{"2":{"1094":1}}],["因此第3个时间步的损失将取决于下一个字符的概率分布",{"2":{"341":1}}],["因此使用向量化实现方式",{"2":{"1093":1}}],["因此使用此网络产生输出只需要实现隐藏层和输出层的计算",{"2":{"231":1}}],["因此取决于你的数值线性代数库的内容",{"2":{"1093":1}}],["因此v向量从",{"2":{"1090":1}}],["因此现在让我们来说明",{"2":{"1111":1}}],["因此现在",{"2":{"1089":1}}],["因此也许稍微有点难调试",{"2":{"1111":1}}],["因此也就对应",{"2":{"1089":1}}],["因此也被称为增长率",{"2":{"480":1}}],["因此公式可以简化为",{"2":{"1080":1}}],["因此卖出的物品数",{"2":{"1060":1}}],["因此两个随机变量是独立的",{"2":{"1034":1}}],["因此有数百万个随机变量",{"2":{"1029":1}}],["因此有效地使用寄存器取决于编译器",{"2":{"810":1}}],["因此tensorflow没有提供一种明确的方式来原地运行单个操作",{"2":{"1021":1}}],["因此train",{"2":{"890":1}}],["因此训练可以更集中在那些错误分类的困难示例上",{"2":{"966":1}}],["因此训练速度被大大降低了",{"2":{"529":1}}],["因此m=1",{"2":{"932":1}}],["因此通常只需要较小的学习率即可微调这些参数",{"2":{"873":1}}],["因此通过指定输入序列的有效长度可以避免查询与使用填充词元的位置计算注意力",{"2":{"409":1}}],["因此通过学习得到的输入的嵌入表示的值需要先乘以嵌入维度的平方根进行重新缩放",{"2":{"407":1}}],["因此该命令会返回3",{"2":{"1089":1}}],["因此该类别被标记为背景",{"2":{"853":2}}],["因此该模型的精度应接近于随机猜测",{"2":{"634":1}}],["因此对这样的一个数据集",{"2":{"1144":1}}],["因此对于",{"2":{"1090":1}}],["因此对于任何单个卷积",{"2":{"141":1}}],["因此对m个工作节点来说",{"2":{"843":1}}],["因此跨设备同步是个棘手的问题",{"2":{"843":1}}],["因此同步操作总共需要15毫秒",{"2":{"841":1}}],["因此本节将排除其他内容只对其进行介绍",{"2":{"841":1}}],["因此本节将把这个架构转换为接口方便后面的代码实现",{"2":{"532":1}}],["因此权重参数的梯度仍然为零",{"2":{"835":1}}],["因此a",{"2":{"821":1}}],["因此默认情况下是jit编译的",{"2":{"819":1}}],["因此更无法将其可视化",{"2":{"1066":1}}],["因此更新和优化的总时间变为o",{"2":{"843":1}}],["因此更适合大批量数据传输",{"2":{"812":1}}],["因此更简单",{"2":{"68":1}}],["因此比特率只随信息密度的平方根缩放",{"2":{"804":1}}],["因此最大的维度应该是3",{"2":{"1089":1}}],["因此最好将任何数据结构与相同的边界对齐",{"2":{"802":1}}],["因此最优的结果是利用先验知识",{"2":{"134":1}}],["因此一定有其他原因",{"2":{"790":1}}],["因此一个模型如果只是简单地统计先前",{"2":{"316":1}}],["因此跳元模型和连续词袋都是自监督模型",{"2":{"782":1}}],["因此字节对编码将它们合并以产生新符号",{"2":{"757":1}}],["因此词表大小不能预定义",{"2":{"757":1}}],["因此是c​乘以0加上二分之一乘以第二项",{"2":{"1144":1}}],["因此是net中的参数的一部分",{"2":{"688":1}}],["因此是f",{"2":{"103":1}}],["因此输入轴0的维数在输出形状中消失",{"2":{"995":1}}],["因此输入层中的输入数",{"2":{"618":1}}],["因此输出张量在",{"2":{"969":1}}],["因此输出通道数为a",{"2":{"954":1}}],["因此输出层中的输出数是1",{"2":{"618":1}}],["因此输出的计算不再依赖于h2或h5",{"2":{"171":1}}],["因此为1",{"2":{"591":2}}],["因此为有o",{"2":{"397":1}}],["因此实际上不需要sequential",{"2":{"591":1}}],["因此隐状态对整个序列的信息都进行了编码",{"2":{"573":1}}],["因此基于神经网络的方法通常被称为",{"2":{"564":1}}],["因此适用于机器翻译等序列转换问题",{"2":{"536":1}}],["因此双向循环神经网络的训练代价非常高",{"2":{"524":1}}],["因此精度将会很差",{"2":{"522":1}}],["因此分母中的lα用于惩罚长序列",{"2":{"515":1}}],["因此时间步3处的每个词元的条件概率也在",{"2":{"513":1}}],["因此它甚至可以为每次迭代选择不同的学习速率",{"2":{"1111":1}}],["因此它可以使用深度卷积神经网络",{"2":{"953":1}}],["因此它是",{"2":{"837":1}}],["因此它需要像print函数",{"2":{"791":1}}],["因此它通常被称为vgg",{"2":{"508":1}}],["因此它永远不会被反向传播更新",{"2":{"425":1}}],["因此添加层似乎更容易降低训练误差",{"2":{"500":1}}],["因此无法通过常规的学习理论泛化保证来解释它们是否能够泛化到看不见的数据",{"2":{"475":1}}],["因此无论这些层执行严格的卷积运算还是互相关运算",{"2":{"130":1}}],["因此反向传播无法继续更新一些模型参数",{"2":{"460":1}}],["因此state",{"2":{"408":8}}],["因此嵌入值乘以嵌入维度的平方根进行缩放",{"2":{"407":4}}],["因此此类连续表示比二进制表示法更节省空间",{"2":{"399":1}}],["因此循环神经网络层的计算复杂度为o",{"2":{"397":1}}],["因此其在训练期间保持不变",{"2":{"425":2}}],["因此其可学习参数是",{"2":{"381":1}}],["因此其hessian矩阵",{"2":{"102":1}}],["因此获得了",{"2":{"370":1}}],["因此从形状中移除最后那个维度",{"2":{"369":4}}],["因此加权和其本质上是加权平均值",{"2":{"367":1}}],["因此返回的corpus仅处理为单个列表",{"2":{"364":1}}],["因此这意味着通过选择右边的决策界",{"2":{"1145":1}}],["因此这给我们提出了一些可能的条件",{"2":{"1141":1}}],["因此这是一个复杂的问题",{"2":{"1129":1}}],["因此这是一个多尺度目标检测模型",{"2":{"953":1}}],["因此这也反过来验证了我们这里的函数",{"2":{"1092":1}}],["因此这就是",{"2":{"1090":1}}],["因此这样一来",{"2":{"1090":1}}],["因此这样的问题叫作单变量线性回归问题",{"2":{"1063":1}}],["因此这样的隐藏变量被称为隐状态",{"2":{"340":1}}],["因此这点的导数会比在绿点时更小",{"2":{"1068":1}}],["因此这里我们逐层计算",{"2":{"920":1}}],["因此这些中心必须根据其相对空间位置在任何输入图像上均匀分布",{"2":{"912":1}}],["因此这些值介于0和1之间",{"2":{"912":1}}],["因此这种分层表示已成功用于各种计算机视觉任务",{"2":{"886":1}}],["因此这种操作提高了模型的可伸缩性",{"2":{"828":1}}],["因此这种类型不方便模型使用",{"2":{"363":1}}],["因此这个绿色的决策界对应着一个参数向量θ这个方向",{"2":{"1145":1}}],["因此这个函数的第一项为0",{"2":{"1144":1}}],["因此这个问题有点棘手",{"2":{"526":1}}],["因此这个框架下的模型将成为本章的中心",{"2":{"356":1}}],["因此注意力在基于自主性提示去辅助选择时将更为谨慎",{"2":{"355":1}}],["因此读者的注意力是用机会成本",{"2":{"354":1}}],["因此读取单个字节会导致由于更宽的存取而产生的代价",{"2":{"77":1}}],["因此误差可能会相当快地偏离真实的观测结果",{"2":{"351":1}}],["因此需要生成更大的锚框",{"2":{"959":1}}],["因此需要用一个键i来对梯度建索引",{"2":{"844":1}}],["因此需要multiplexer",{"2":{"841":1}}],["因此需要耗费大量的时间",{"2":{"805":1}}],["因此需要指定为false已更新梯度",{"2":{"601":1}}],["因此需要一个近似方法来使这个计算变得容易处理",{"2":{"347":1}}],["因此需要为每个迭代周期重新初始化隐状态",{"2":{"335":1}}],["因此评估模型产生托尔斯泰的巨著",{"2":{"342":1}}],["因此求和时可以应用广播机制",{"2":{"339":1}}],["因此与其将p",{"2":{"338":1}}],["因此与rmsprop算法有所区分",{"2":{"33":1}}],["因此当我们考察优化目标函数的时候",{"2":{"1145":1}}],["因此当输入图像的高或宽无法被32整除时",{"2":{"866":1}}],["因此当小批量词元索引的形状为",{"2":{"762":1}}],["因此当bert微调时",{"2":{"688":1}}],["因此当前小批量数据最后一个样本的隐状态",{"2":{"335":1}}],["因此当从内存中读取它们时",{"2":{"77":1}}],["因此称为顺序分区",{"2":{"321":1}}],["因此标签是移位了一个词元的原始序列",{"2":{"320":1}}],["因此e",{"2":{"310":1}}],["因此依赖关系也可能相当长",{"2":{"306":1}}],["因此深度学习可以称为",{"2":{"302":1}}],["因此即使还在忙着为某些参数计算梯度时",{"2":{"841":1}}],["因此即使是阶数上的微小变化",{"2":{"269":1}}],["因此即使参数是负的",{"2":{"235":1}}],["因此简单地最小化训练误差并不一定意味着泛化误差的减小",{"2":{"267":1}}],["因此容易受到相关谬误的影响",{"2":{"254":1}}],["因此h",{"2":{"241":1}}],["因此极大地降低了训练损失",{"2":{"190":1}}],["因此不在目标模型中使用该层",{"2":{"870":1}}],["因此不同长度的序列可以以相同形状的小批量加载",{"2":{"575":1}}],["因此不需要标准化",{"2":{"171":1}}],["因此不会真正意义上扰动梯度",{"2":{"94":1}}],["因此在我们接下来的推导中去掉θ0不会有影响这意味着我们的目标函数是等于12",{"2":{"1145":1}}],["因此在接下来的一些课程中",{"2":{"1098":1}}],["因此在所有五个尺度下",{"2":{"959":1}}],["因此在实际场景中",{"2":{"841":1}}],["因此在诸多的深度学习框架中",{"2":{"789":1}}],["因此在计算条件概率时对这些上下文词向量进行平均",{"2":{"785":1}}],["因此在反向传播期间第二个隐藏层",{"2":{"437":1}}],["因此在反向传播期间第二个隐藏层和第三个隐藏层的梯度会加在一起",{"2":{"437":1}}],["因此在固定训练数据集的情况下",{"2":{"259":1}}],["因此在这里我们直接使用高级api中的内置函数来计算softmax和交叉熵损失",{"2":{"220":1}}],["因此在这些情况下",{"2":{"117":1}}],["因此在模型使用gpu计算数据集之前",{"2":{"137":1}}],["因此高度和宽度都减少了4个像素",{"2":{"136":1}}],["因此卷积神经网络除了能够高效地采样从而获得精确的模型",{"2":{"134":1}}],["因此选择它至少一次就是",{"2":{"116":1}}],["因此学习率ηt也需要消失",{"2":{"115":1}}],["因此优化算法的学习速率将在每2个迭代后乘以0",{"2":{"907":1}}],["因此优化算法中的梯度不需要除以批量大小",{"2":{"80":1}}],["因此优化器必须至少接触每个参数一次",{"2":{"278":1}}],["因此优化的目标是减少训练误差",{"2":{"99":1}}],["因此梯度的期望保持不变",{"2":{"78":1}}],["因此大多数深度学习框架都有自动应对这个问题的工具",{"2":{"66":1}}],["因此证明了凸集的并集不一定是凸的",{"2":{"40":1}}],["因此线段也不在x∪y中",{"2":{"40":1}}],["因此",{"2":{"26":2,"44":1,"46":1,"54":2,"59":1,"60":1,"80":1,"87":1,"94":1,"95":1,"99":1,"103":1,"106":1,"107":1,"113":1,"115":1,"116":1,"121":1,"131":1,"140":1,"147":1,"154":1,"155":1,"158":2,"165":2,"190":1,"191":2,"201":1,"204":1,"208":2,"210":1,"231":1,"236":2,"241":2,"242":1,"244":1,"256":2,"266":1,"278":1,"284":1,"291":2,"297":1,"298":2,"300":3,"301":1,"302":1,"305":1,"307":4,"308":1,"311":1,"312":1,"319":2,"331":1,"334":1,"340":2,"341":1,"342":2,"345":2,"347":1,"349":2,"350":1,"352":1,"356":1,"375":1,"380":1,"388":1,"390":1,"397":2,"403":1,"404":1,"408":1,"418":1,"437":2,"440":1,"442":2,"454":1,"459":2,"460":1,"470":1,"479":1,"500":1,"502":1,"512":1,"513":2,"519":2,"522":1,"541":1,"553":2,"559":1,"564":1,"574":1,"582":1,"605":1,"610":1,"613":2,"616":2,"623":2,"629":1,"630":1,"634":1,"643":3,"646":1,"650":1,"656":1,"660":1,"667":1,"669":1,"701":1,"707":1,"718":1,"731":2,"737":1,"742":1,"743":3,"744":1,"754":1,"773":1,"776":1,"789":1,"790":4,"795":2,"797":3,"801":1,"804":2,"809":1,"811":1,"814":1,"816":1,"824":1,"832":1,"833":1,"848":1,"853":2,"854":1,"861":1,"862":1,"905":1,"912":1,"913":1,"926":1,"932":1,"938":2,"956":1,"957":1,"970":1,"976":1,"980":1,"981":1,"982":1,"987":1,"992":3,"995":1,"1002":1,"1025":1,"1030":1,"1035":1,"1063":2,"1068":2,"1069":1,"1085":1,"1086":2,"1089":2,"1090":2,"1093":1,"1098":1,"1107":1,"1110":2,"1111":2,"1127":1,"1129":2,"1130":1,"1137":1,"1138":4,"1141":2,"1143":14,"1144":5,"1145":4,"1148":3,"1150":3,"1152":1,"1185":1,"1187":5}}],["因为计算代价太大了",{"2":{"1167":1}}],["因为计算图在小批量内的设备之间没有任何依赖关系",{"2":{"837":1}}],["因为逻辑回归计算",{"2":{"1147":1}}],["因为如果你知道数据中心中",{"2":{"1150":1}}],["因为如果",{"2":{"1145":1}}],["因为如果我们有一个学习算法",{"2":{"1141":1}}],["因为如果我们令",{"2":{"1115":1}}],["因为θtx",{"2":{"1145":1}}],["因为citys被markraw标记了",{"2":{"1518":1,"1519":1}}],["因为c=1",{"2":{"1143":1}}],["因为cpu的pcie通道太少",{"2":{"841":1}}],["因为1",{"2":{"1143":1}}],["因为1×2+",{"2":{"957":1}}],["因为y=1时",{"2":{"1143":1}}],["因为对应的假设函数的输出值趋近0",{"2":{"1143":1}}],["因为对于这些算法",{"2":{"1111":1}}],["因为对于所有的x都有x0=1",{"2":{"259":1}}],["因为对于任何凸函数f",{"2":{"115":1}}],["因为数据有时是唯一能实际起到作用的",{"2":{"1141":1}}],["因为数千个样本可能对应于一个单独的单词",{"2":{"295":1}}],["因为某些原因有了一个突发奇想",{"2":{"1137":1}}],["因为能判断出现的情况是这两种情况中的哪一种",{"2":{"1132":1}}],["因为代价函数的偏导数检验只针对一个参数的改变进行检验",{"2":{"1124":1}}],["因为matlab中的下标从1开始",{"2":{"1093":1}}],["因为操作系统把文件识别为",{"2":{"1089":1}}],["因为使用了rand命令",{"2":{"1088":1}}],["因为使用了最小窗口",{"2":{"122":1}}],["因为标准方程法不适合或者不能用在它们上",{"2":{"1085":1}}],["因为矩阵逆的计算时间复杂度为o",{"2":{"1085":1}}],["因为只含有一个特征",{"2":{"1063":1}}],["因为只有少数的离散值",{"2":{"1060":1}}],["因为只有最有希望的路径才会被继续执行",{"2":{"808":1}}],["因为软件在octave中可以令人难以置信地",{"2":{"1061":1}}],["因为我知道它是0",{"2":{"1144":1}}],["因为我之前把变量v存入了hello",{"2":{"1089":1}}],["因为我只是拿到算法数据",{"2":{"1061":1}}],["因为我会把预测的值",{"2":{"1060":1}}],["因为我们想计算内积",{"2":{"1145":1}}],["因为我们想要正确地将此样本分类",{"2":{"1143":1}}],["因为我们将选择参数使第一项为0",{"2":{"1144":1}}],["因为我们将相关的lr函数设置为常量",{"2":{"113":1}}],["因为我们能够拟合非常复杂的函数",{"2":{"1141":1}}],["因为我们可以先看看算法造成的错误",{"2":{"1138":1}}],["因为我们可以选择任意偏移量来指示初始位置",{"2":{"319":1}}],["因为我们未对θ0​进行正则化",{"2":{"1116":1}}],["因为我们并没有尝试完所有的参数组合",{"2":{"1067":1}}],["因为我们并没有真正地提前停止",{"2":{"68":1}}],["因为我们拥有所有的顾客数据",{"2":{"1061":1}}],["因为我们没有给算法正确答案来回应数据集中的数据",{"2":{"1061":1}}],["因为我们没有提前告知算法一些信息",{"2":{"1061":1}}],["因为我们没有足够的历史记录来描述前τ个数据样本",{"2":{"350":1}}],["因为我们是从一个公平的骰子中生成的数据",{"2":{"1026":1}}],["因为我们经常会成千上万次地更新相同的参数",{"2":{"974":1}}],["因为我们使用转置卷积层的通道来预测像素的类别",{"2":{"865":1}}],["因为我们使用的是自己合成的数据集",{"2":{"605":1}}],["因为我们有很多层",{"2":{"844":1}}],["因为我们有不同的词元",{"2":{"528":1}}],["因为我们不考虑跨越词边界的符号对",{"2":{"757":1}}],["因为我们不知道哪些特征是相关的",{"2":{"209":1}}],["因为我们的数据集有10个类别",{"2":{"630":1}}],["因为我们计算的损失是一个批量样本的总和",{"2":{"604":1}}],["因为我们必须等待数据被发送",{"2":{"450":1}}],["因为我们在数据集中只使用了10000个词元",{"2":{"335":1}}],["因为我们在执行分类任务",{"2":{"136":1}}],["因为我们需要在整个书中可视化许多曲线",{"2":{"981":1}}],["因为我们需要递归整个树来提取每个子块的参数",{"2":{"432":1}}],["因为我们需要循环地计算参数wh对ht的影响",{"2":{"307":1}}],["因为我们需要从计算图的结果开始",{"2":{"164":1}}],["因为我们已经在多项式特征中实现了它",{"2":{"263":1}}],["因为我们已经在多项式中实现了它",{"2":{"263":3}}],["因为我们无法估计训练数据的泛化误差",{"2":{"256":1}}],["因为我们无法看到真实环境下的样本的标签",{"2":{"192":1}}],["因为我们忽略了空间结构",{"2":{"219":1}}],["因为我们观测源数据上的标签",{"2":{"192":1}}],["因为我们从表面上看是在训练过程中丢弃",{"2":{"170":1}}],["因为我们总是可以匹配",{"2":{"156":1}}],["因为我们假设x∩y=∅",{"2":{"40":1}}],["因为你缺少证据",{"2":{"1138":1}}],["因为你知道",{"2":{"1060":1}}],["因为你可以利用功能强大的开源深度学习框架",{"2":{"237":1}}],["因为条件概率需要总和为1",{"2":{"1035":1}}],["因为可能存在灯泡坏掉",{"2":{"1034":1}}],["因为可以依据控制流编写代码",{"2":{"822":1}}],["因为要同时发生a=a和b=b",{"2":{"1030":1}}],["因为3∈",{"2":{"1027":1}}],["因为导入语句",{"2":{"981":1}}],["因为ai1和bj1是所有锚框和真实边界框配对中最相近的",{"2":{"851":1}}],["因为一个像素的的高为1且宽为1",{"2":{"848":1}}],["因为一个像素的高为1且宽为1",{"2":{"848":2}}],["因为一个较长的序列在",{"2":{"515":1}}],["因为不需要服务器端处理路径",{"2":{"1476":1}}],["因为不需要为何时接收哪个梯度进行细粒度的控制",{"2":{"844":1}}],["因为不是同一个对象了",{"2":{"1463":1}}],["因为不同尺度下批量大小仍保持不变",{"2":{"956":1}}],["因为不值得冒20",{"2":{"291":1}}],["因为pcie交换机在所有链路之间提供全带宽操作",{"2":{"841":1}}],["因为4个gpu每个都需要将数据发送到cpu",{"2":{"841":1}}],["因为深度学习框架无法将通信组合成大的突发传输",{"2":{"842":1}}],["因为深度学习框架的内置函数编写代码更方便",{"2":{"836":1}}],["因为深度学习框架自动调度两个gpu设备上的计算",{"2":{"796":1}}],["因为并行化开销的相关性较小",{"2":{"828":1}}],["因为是否采用混合模式将影响代码使用稍微不同的库",{"2":{"821":1}}],["因为编译器在将其转换为机器指令之前可以看到完整的代码",{"2":{"817":1}}],["因为大多数缓存算法将试图向前读取",{"2":{"810":1}}],["因为大学生看起来往往与老年人有很大的不同",{"2":{"253":1}}],["因为高性能线性代数和卷积运算常见于媒体处理和机器学习中",{"2":{"807":1}}],["因为突发读取的速度也快了4倍",{"2":{"802":1}}],["因为前者的成本更高",{"2":{"802":1}}],["因为前者不再依赖于图像中的位置",{"2":{"154":1}}],["因为前端不必等待后端为每个循环返回计算结果",{"2":{"792":1}}],["因为numpy中没有异步的概念",{"2":{"791":1}}],["因为其预测的值可以超越",{"2":{"1107":1}}],["因为其要求变量可用",{"2":{"791":1}}],["因为其产生了一个无意义的续写",{"2":{"342":1}}],["因为共现概率的比值是标量",{"2":{"744":1}}],["因为零是",{"2":{"727":1}}],["因为长短期记忆网络要求其输入的第一个维度是时间维",{"2":{"713":3}}],["因为假设中的",{"2":{"665":1}}],["因为将线性层的输出直接视为概率时存在一些问题",{"2":{"643":1}}],["因为精度的计算不可导",{"2":{"634":1}}],["因为目前分类问题的数量远远超过回归问题的数量",{"2":{"633":1}}],["因为log⁡",{"2":{"624":1}}],["因为l形状是",{"2":{"605":2}}],["因为第一项被消除了",{"2":{"1143":1}}],["因为第一项不依赖于w和b",{"2":{"616":1}}],["因为第一层是输入变量",{"2":{"1121":1}}],["因为第二句的语义很奇怪",{"2":{"315":1}}],["因为算法会使得损失向最小值缓慢收敛",{"2":{"613":1}}],["因为当我们对损失函数求导后常数系数为1",{"2":{"611":1}}],["因为当训练一个有多层的深层网络时",{"2":{"170":1}}],["因为从事深度学习后",{"2":{"605":1}}],["因为从直觉上看",{"2":{"282":1}}],["因为手动计算梯度很枯燥而且容易出错",{"2":{"601":1}}],["因为参数还没有初始化",{"2":{"592":2}}],["因为原始的输出序列",{"2":{"576":1}}],["因为统计机器翻译",{"2":{"564":1}}],["因为机器翻译正是将输入序列转换成输出序列的",{"2":{"564":1}}],["因为符号简化的需要",{"2":{"519":1}}],["因为电影中的一句话",{"2":{"487":1}}],["因为即使在现代gpu上",{"2":{"462":1}}],["因为单个gpu相对运行速度快",{"2":{"450":1}}],["因为模型本身可以包含任意代码",{"2":{"442":1}}],["因为模型在开始生成新序列之前不再需要记住整个序列",{"2":{"300":1}}],["因为层是分层嵌套的",{"2":{"433":1}}],["因为权重尚未初始化",{"2":{"418":1}}],["因为存储精度的原因",{"2":{"413":1}}],["因为填充词元是不携带信息的",{"2":{"409":1}}],["因为位置编码值在",{"2":{"407":4}}],["因为用同一个多层感知机对所有位置上的输入进行变换",{"2":{"405":1}}],["因为两个输入都是经过排序的",{"2":{"388":1}}],["因为两者都使用梯度的平方来缩放系数",{"2":{"110":1}}],["因为时光机器数据集中的每个文本行不一定是一个句子或一个段落",{"2":{"364":1}}],["因为读者的注意力是一种稀缺的资源",{"2":{"354":1}}],["因为新的动力学一定受新的数据影响",{"2":{"347":1}}],["因为词表v需要存储|v|n个数字",{"2":{"338":1}}],["因为已经调用了mean函数",{"2":{"335":3}}],["因为初始条件的微小变化就可能会对结果产生巨大的影响",{"2":{"308":1}}],["因为几乎每种成分都是可以替代的",{"2":{"302":1}}],["因为卡车司机和店员是许多国家最常见的工作之一",{"2":{"301":1}}],["因为响尾蛇是有毒的",{"2":{"291":1}}],["因为越低越好",{"2":{"286":1}}],["因为所有的统计估计都是事后归纳",{"2":{"254":1}}],["因为基因可以唯一确定每个个体",{"2":{"251":1}}],["因为输入的图像很小",{"2":{"826":1}}],["因为输入维数是未知的",{"2":{"418":1}}],["因为输入可能永远都不会是0",{"2":{"235":1}}],["因为输入元素无法填充窗口",{"2":{"142":1}}],["因为隐藏层和输出层都是全连接的",{"2":{"232":1}}],["因为内存在硬件中的分配和寻址方式",{"2":{"217":1}}],["因为作为一个估计",{"2":{"192":1}}],["因为疾病会引起症状",{"2":{"182":1}}],["因为人类很难将输入和随机标记的输出联系起来",{"2":{"169":1}}],["因为在l",{"2":{"1111":1}}],["因为在大多数情况下",{"2":{"1000":1}}],["因为在训练时无须改变预训练的vgg的模型参数",{"2":{"920":1}}],["因为在实践中它的实现相对简单",{"2":{"841":1}}],["因为在每一次更新参数之前",{"2":{"613":1}}],["因为在预测下一个词元时",{"2":{"522":1}}],["因为在这种情况下",{"2":{"348":1}}],["因为在这两个四阶张量的元素之间存在一一对应的关系",{"2":{"153":1}}],["因为在此期间模型会自我更新",{"2":{"333":1}}],["因为在所有函数f中",{"2":{"270":1}}],["因为在t步之后我们可以得到xt=",{"2":{"95":1}}],["因为需要用曲线才能分隔",{"2":{"1108":1}}],["因为需要计算损失函数的梯度",{"2":{"603":1}}],["因为需要有大量的gpu",{"2":{"151":1}}],["因为需要检查的局部最小值的数量可能是指数级的",{"2":{"117":1}}],["因为它几乎无所不能",{"2":{"1297":1}}],["因为它试图极大化这些p",{"2":{"1145":1}}],["因为它努力用一个最大间距来分离样本",{"2":{"1144":1}}],["因为它能很好地解决不同的机器学习问题",{"2":{"1098":1}}],["因为它是开源的",{"2":{"1088":1}}],["因为它是那条切线的斜率",{"2":{"1068":1}}],["因为它是一个平滑的",{"2":{"236":1}}],["因为它可能会导致较差的性能",{"2":{"791":1}}],["因为它可以将参数的量级进行统一",{"2":{"467":1}}],["因为它可以被视为一个输入映射到下一层的空间维度的转换器",{"2":{"131":1}}],["因为它的间距很小",{"2":{"1145":1}}],["因为它的初始参数值更有效",{"2":{"874":1}}],["因为它的每一个输入都通过矩阵",{"2":{"591":1}}],["因为它的代码已编译为c++或cuda",{"2":{"474":1}}],["因为它使用的是编译好的运算符而不是python来处理之前阐述的许多细节",{"2":{"547":1,"561":1}}],["因为它使用变化量本身作为未来变化的校准",{"2":{"19":1}}],["因为它会一点点挪动",{"2":{"1068":1}}],["因为它会影响错误警报的数量",{"2":{"1035":1}}],["因为它会影响所有后续的观测值",{"2":{"538":1}}],["因为它会将估计值偏向更简单和更稳定的模型",{"2":{"309":1}}],["因为它们是同一个对象",{"2":{"1463":1}}],["因为它们是对自己执行回归",{"2":{"347":1}}],["因为它们的处理单元比cpu多得多",{"2":{"802":1}}],["因为它们的性价比不高",{"2":{"457":1}}],["因为它们将变得更加计算密集",{"2":{"451":1}}],["因为它需要",{"2":{"315":1}}],["因为它类似于阈值函数",{"2":{"242":1}}],["因为它实现简单",{"2":{"235":1}}],["因为它所表达的运算其实是互相关运算",{"2":{"126":1}}],["因为这是我们学习的第一个非监督学习算法",{"2":{"1150":1}}],["因为这可以证明",{"2":{"1141":1}}],["因为这个问题对于弄清如何改进学习算法的效果非常重要",{"2":{"1132":1}}],["因为这个问题是由于协变量",{"2":{"181":1}}],["因为这个点的导数是相当陡的",{"2":{"1068":1}}],["因为这几个离散的输出分别对应良性",{"2":{"1060":1}}],["因为这里在处理的是一个向量",{"2":{"1017":1}}],["因为这会导致异常",{"2":{"449":1}}],["因为这样建模的结果会大大高估尾部单词的频率",{"2":{"318":1}}],["因为这些方法让你在开发学习算法时",{"2":{"1129":1}}],["因为这些语言如",{"2":{"1088":1}}],["因为这些语言在开发上比较慢",{"2":{"1088":1}}],["因为这些麦克风在两个地方",{"2":{"1061":1}}],["因为这些技术只在调整gpu核心以获得高吞吐量时才起作用",{"2":{"802":1}}],["因为这些细节对于分析并不重要",{"2":{"307":1}}],["因为这些概念是相互关联的",{"2":{"292":1}}],["因为这些网络特征元素的顺序是不变的",{"2":{"134":1}}],["因为这仍然是一个卷积层",{"2":{"122":1}}],["因为这意味着更新与完整的梯度更接近了",{"2":{"78":1}}],["因为每一层都依赖于所有其他层的结果",{"2":{"832":1}}],["因为每一个这样的操作都需要使用计算图来求得所有的中间结果",{"2":{"791":1}}],["因为每个人都在说话",{"2":{"1061":1}}],["因为每个块的大小是1",{"2":{"842":1}}],["因为每个样本都是在一个随机位置抽样的",{"2":{"335":1}}],["因为每个文本行不一定是一个句子或一个段落",{"2":{"318":1}}],["因为每个通道都向后续层提供一组空间化的学习特征",{"2":{"158":1}}],["因为每个通道不是独立学习的",{"2":{"121":1}}],["因为每个参数都参与更多的乘法",{"2":{"137":1}}],["因为每批工作负载的执行效率变得更低",{"2":{"80":1}}],["因为x¯是优化路径的平滑版本",{"2":{"115":1}}],["因为x和y是凸集",{"2":{"40":1}}],["因为有",{"2":{"115":1}}],["因为总的来说",{"2":{"114":1}}],["因为",{"2":{"113":1,"665":2,"1086":1,"1093":1,"1143":1,"1178":1}}],["因为η是单独控制的",{"2":{"108":1}}],["因为学习率衰减太快",{"2":{"108":1}}],["因为该流程记住了值的完整轨迹",{"2":{"106":1}}],["因为问题通常不是凸的",{"2":{"104":1}}],["因为问题是轴对齐的",{"2":{"26":1}}],["因为逐个样本来计算梯度并不那么有效",{"2":{"80":1}}],["因为线搜索的每一步都需要评估整个数据集上的目标函数",{"2":{"62":1}}],["因为二阶导数是由有限差分的极限给出的",{"2":{"46":1}}],["因为∇2f=1",{"2":{"46":1}}],["因为f",{"2":{"45":1,"59":1}}],["因为主要计算用在l",{"2":{"27":1}}],["因为λ是一个包含q特征值的对角矩阵",{"2":{"26":1}}],["∂θ=0",{"2":{"1086":1}}],["∂θ=12",{"2":{"1086":1}}],["∂∂θ1=j",{"2":{"1124":1}}],["∂∂θ1j",{"2":{"1069":1,"1111":1}}],["∂∂θ2j",{"2":{"1111":1}}],["∂∂θ0j",{"2":{"1069":1}}],["∂∂θjj",{"2":{"1069":1,"1085":1,"1109":1}}],["∂voi=12m",{"2":{"786":1}}],["∂vc=uo−∑j∈vexp⁡",{"2":{"784":1}}],["∂表示偏导数",{"2":{"613":1}}],["∂logp",{"2":{"784":1,"786":1}}],["∂l",{"2":{"312":8}}],["∂l∂ht",{"2":{"312":2}}],["∂l∂ht=∑i=tt",{"2":{"312":1}}],["∂l∂ht=prod",{"2":{"312":2}}],["∂l∂ht+1",{"2":{"312":1}}],["∂l∂whh=∑t=1tprod",{"2":{"312":1}}],["∂l∂whx=∑t=1tprod",{"2":{"312":1}}],["∂l∂wh=1t∑t=1t∂l",{"2":{"307":1}}],["∂l∂wqh=∑t=1tprod",{"2":{"312":1}}],["∂l∂ot",{"2":{"312":3}}],["∂l∂ot=∂l",{"2":{"312":1}}],["∂l∂o",{"2":{"164":1}}],["∂ojl",{"2":{"647":1}}],["∂ot是",{"2":{"312":1}}],["∂ot∂ht",{"2":{"312":2}}],["∂ot∂wqh",{"2":{"312":1}}],["∂ot∂g",{"2":{"307":1}}],["∂o∂h",{"2":{"164":1}}],["∂o∂w",{"2":{"164":1}}],["∂hj−1",{"2":{"307":1}}],["∂ht",{"2":{"312":2}}],["∂ht+1∂ht",{"2":{"312":1}}],["∂ht∈rh",{"2":{"312":2}}],["∂ht−1",{"2":{"307":1}}],["∂ht−1∂ht−1∂wh",{"2":{"307":1,"310":1}}],["∂ht∂whh",{"2":{"312":1}}],["∂ht∂whx",{"2":{"312":1}}],["∂ht∂wh=∂f",{"2":{"307":2}}],["∂ht∂ht∂wh",{"2":{"307":1}}],["∂h∂z",{"2":{"164":1}}],["∂h∈rh由下式给出",{"2":{"164":1}}],["∂z∈rh",{"2":{"164":1}}],["∂z∂w",{"2":{"164":1}}],["∂z∂y",{"2":{"164":1}}],["∂z∂x=prod",{"2":{"164":1}}],["∂s∂w",{"2":{"164":3}}],["∂j∂z",{"2":{"164":1}}],["∂j∂z=prod",{"2":{"164":1}}],["∂j∂h",{"2":{"164":1}}],["∂j∂h=prod",{"2":{"164":1}}],["∂j∂s",{"2":{"164":2}}],["∂j∂o",{"2":{"164":2}}],["∂j∂o=prod",{"2":{"164":1}}],["∂j∂w",{"2":{"164":2}}],["∂j∂l",{"2":{"164":1}}],["∂j∂l=1and∂j∂s=1",{"2":{"164":1}}],["∂j",{"2":{"164":3,"1086":1}}],["∂wqh∈rq×h",{"2":{"312":1}}],["∂wqh",{"2":{"312":1}}],["∂whh时使用",{"2":{"312":1}}],["∂whh∈rh×h",{"2":{"312":1}}],["∂whh和",{"2":{"312":1}}],["∂whx和",{"2":{"312":1}}],["∂whx∈rh×d和∂l",{"2":{"312":1}}],["∂whx",{"2":{"312":1}}],["∂wh得到",{"2":{"310":1}}],["∂wh+ξt∂f",{"2":{"310":1}}],["∂wh+∑i=1t−1",{"2":{"307":1}}],["∂wh+∂f",{"2":{"307":1}}],["∂wh",{"2":{"307":3,"309":1,"310":2}}],["∂wh是使事情变得棘手的地方",{"2":{"307":1}}],["∂wh=1t∑t=1t∂l",{"2":{"307":1}}],["∂w",{"2":{"164":4,"241":1}}],["∂y∂xi=∂y∂u1∂u1∂xi+∂y∂u2∂u2∂xi+⋯+∂y∂um∂um∂xi",{"2":{"984":1}}],["∂y∂xi=∂f∂xi=fxi=fi=dif=dxif",{"2":{"982":1}}],["∂y∂xi=limh→0f",{"2":{"982":1}}],["∂y∂x",{"2":{"164":1}}],["∂xn",{"2":{"983":1}}],["∂xf",{"2":{"115":2}}],["∂xi代表了当输入xi时f在x处的变化率",{"2":{"57":1}}],["∂xd",{"2":{"57":1}}],["∂x2",{"2":{"57":1,"983":1}}],["∂x1",{"2":{"57":1,"983":1}}],["∂x¯f¯",{"2":{"26":1}}],["∂f",{"2":{"57":3,"307":1,"983":3}}],["∂if",{"2":{"25":1}}],["qq",{"2":{"1121":1}}],["q+1",{"2":{"954":2}}],["q是类别的数量",{"2":{"938":1}}],["q是输出单元的数目",{"2":{"521":1}}],["qos",{"2":{"813":4}}],["qpi",{"2":{"813":1}}],["qinghua",{"2":{"1495":1}}],["qij=exp⁡",{"2":{"742":1}}],["qiiqjj",{"2":{"26":1}}],["qa描述了用于问答的微调bert",{"2":{"660":1}}],["qa",{"2":{"660":1}}],["qk",{"2":{"370":1,"397":1}}],["qk⊤d",{"2":{"370":1}}],["qkv函数的操作",{"2":{"382":5}}],["qkv中的注意力机制框架的角度",{"2":{"388":1}}],["qkv中的注意力机制框架",{"2":{"367":1}}],["qkv中的主导地位",{"2":{"356":1}}],["qkv",{"2":{"356":1,"382":16,"385":1}}],["qkv所示",{"2":{"356":1}}],["q∈rq和",{"2":{"367":1}}],["quality",{"2":{"1444":1}}],["question",{"2":{"660":1}}],["queries和attention",{"2":{"391":4}}],["queries的形状",{"2":{"369":4,"370":4}}],["queries",{"2":{"357":1,"369":24,"370":20,"382":25,"391":17,"396":4}}],["query参数",{"0":{"1481":1}}],["query的形状为",{"2":{"375":4}}],["query",{"2":{"293":1,"356":1,"369":8,"375":8,"376":3,"382":5,"407":12,"408":15,"409":13,"686":2,"726":1,"734":4,"738":4,"750":2,"768":6,"1205":1,"1481":2,"1483":1,"1485":1}}],["quot",{"2":{"86":4,"207":2,"208":2,"342":6,"469":2,"518":6,"538":2,"624":2,"651":2,"658":12,"999":2,"1025":10,"1069":4,"1088":2,"1092":7,"1112":8,"1129":2,"1137":2,"1141":8,"1216":2,"1444":4,"1454":4}}],["q和p中分别是源分布",{"2":{"192":1}}],["q~ii=1",{"2":{"26":1}}],["q~=diag−12",{"2":{"26":1}}],["qdiag−12",{"2":{"26":1}}],["q",{"2":{"26":2,"80":2,"81":2,"191":5,"192":7,"298":1,"331":8,"332":8,"367":6,"369":9,"370":1,"381":3,"382":8,"527":1,"544":8,"545":8,"558":8,"559":8,"652":1,"757":2}}],["虽然计算代价比较大",{"2":{"1135":1}}],["虽然代价看上去在不断减小",{"2":{"1124":1}}],["虽然正则化的逻辑回归中的梯度下降和正则化的线性回归中的表达式看起来一样",{"2":{"1117":1}}],["虽然能非常好地适应我们的训练集但在新输入变量进行预测时可能会效果不好",{"2":{"1114":1}}],["虽然得到的梯度下降算法表面上看上去与线性回归的梯度下降算法一样",{"2":{"1109":1}}],["虽然失去了眼球",{"2":{"1098":1}}],["虽然是同样的两个说话人",{"2":{"1061":1}}],["虽然人类很容易以160×160像素的分辨率识别猫和狗",{"2":{"1025":1}}],["虽然人类很容易识判断发音别扭的音频文件",{"2":{"295":1}}],["虽然张量的形状发生了改变",{"2":{"1017":1}}],["虽然求导的计算很简单",{"2":{"973":1}}],["虽然每个gpu上的参数值都是相同且同步的",{"2":{"833":1}}],["虽然每个gpu核心都相对较弱",{"2":{"457":1}}],["虽然它被称为pytorch",{"2":{"1017":1}}],["虽然它只是整个网络显存的一小部分",{"2":{"832":1}}],["虽然它比pcie慢得多",{"2":{"812":1}}],["虽然它并不能完全解决问题",{"2":{"334":1}}],["虽然不同时代的产品和供应商的细节有所不同",{"2":{"808":1}}],["虽然不可能考虑所有类型的序列转换",{"2":{"295":1}}],["虽然并行化通常应用在多个gpu之间",{"2":{"795":1}}],["虽然独热向量很容易构建",{"2":{"781":1}}],["虽然交叉熵损失函数通常用于测量概率分布之间的距离",{"2":{"742":1}}],["虽然文本序列的每个词元经由嵌入层",{"2":{"713":1}}],["虽然卷积神经网络最初是为计算机视觉设计的",{"2":{"698":1}}],["虽然卷积神经网络的参数较少",{"2":{"137":1}}],["虽然直接优化精度可能很困难",{"2":{"634":1}}],["虽然飞机可能受到鸟类的启发",{"2":{"619":1}}],["虽然使许多指数函数的乘积最大化看起来很困难",{"2":{"616":1}}],["虽然推断这个词已经成为深度学习的标准术语",{"2":{"614":1}}],["虽然现代的深度学习框架几乎可以自动化地进行所有这些工作",{"2":{"598":1}}],["虽然alexnet证明深层神经网络卓有成效",{"2":{"506":1}}],["虽然resnet的主体架构跟googlenet类似",{"2":{"502":1}}],["虽然relu和最大汇聚层更有效",{"2":{"136":1}}],["虽然f3比f1更接近f∗",{"2":{"500":1}}],["虽然深度学习领域中很多人都使用这个名字",{"2":{"655":1}}],["虽然深度学习是机器学习的一个子集",{"2":{"302":1}}],["虽然深度神经网络的概念非常简单",{"2":{"492":1}}],["虽然上世纪90年代就有了一些神经网络加速卡",{"2":{"454":1}}],["虽然本章不介绍任何新的模型或数据集",{"2":{"421":1}}],["虽然有指导意义",{"2":{"335":1}}],["虽然有时我们可以在不引用因果关系的情况下对分布偏移进行推断",{"2":{"181":1}}],["虽然",{"2":{"324":1,"351":1,"578":1}}],["虽然随机截断在理论上具有吸引力",{"2":{"311":1}}],["虽然他们的行为可能会给人一种通用智能的错觉",{"2":{"301":1}}],["虽然完全自主还没有完全触手可及",{"2":{"301":1}}],["虽然只触及了皮毛",{"2":{"300":1}}],["虽然许多深度学习方法都是最近才有重大突破",{"2":{"299":1}}],["虽然回归模型可以很好地解决",{"2":{"291":1}}],["虽然监督学习只是几大类机器学习问题之一",{"2":{"289":1}}],["虽然简单的模型能够解决如上简单的问题",{"2":{"285":1}}],["虽然一次编写出完美应用程序的可能性微乎其微",{"2":{"281":1}}],["虽然一个单隐层网络能学习任何函数",{"2":{"233":1}}],["虽然训练损失可以有效地降低",{"2":{"266":1}}],["虽然理想情况下我们只会使用测试数据一次",{"2":{"256":1}}],["虽然小批量随机梯度下降不会打破这种对称性",{"2":{"244":1}}],["虽然在神经科学的角度看起来不太合理",{"2":{"242":1}}],["虽然在大多数学习问题中",{"2":{"197":1}}],["虽然收入与还款概率存在单调性",{"2":{"230":1}}],["虽然排行榜的追逐往往令人失去理智",{"2":{"207":1}}],["虽然输入的分布可能随时间而改变",{"2":{"181":1}}],["虽然我们讨论的是矩阵的索引",{"2":{"1020":1}}],["虽然我们相信给定x预测y的最佳模型会是线性的",{"2":{"610":1}}],["虽然我们可以使用穷举搜索来获得最优序列",{"2":{"514":1}}],["虽然我们可以使用链式法则递归地计算∂ht",{"2":{"307":1}}],["虽然我们仍将一个序列转换成另一个序列",{"2":{"295":1}}],["虽然我们不可能在一节中讨论全部的问题",{"2":{"179":1}}],["虽然我们不可能涵盖所有类型的学习率调度器",{"2":{"69":1}}],["虽然我们在",{"2":{"119":1}}],["虽然这些更奇特的对象确实出现在高级机器学习中",{"2":{"975":1}}],["虽然这些数字令人印象深刻",{"2":{"802":1}}],["虽然这在数学上看起来是正确的",{"2":{"631":1}}],["虽然这是一个典型情景",{"2":{"518":1}}],["虽然这个实验不是一个数学证明",{"2":{"981":1}}],["虽然这个模型可能没有很准确地反映出后续词的语义",{"2":{"342":1}}],["虽然这个性质可以通过数学证明",{"2":{"340":1}}],["虽然这很方便",{"2":{"208":1}}],["虽然这通常适用于凸问题",{"2":{"106":1}}],["虽然这不如完整的牛顿法精确",{"2":{"61":1}}],["虽然由于计算代价的原因",{"2":{"58":1}}],["虽然进展相当顺利",{"2":{"57":1}}],["虽然对l2的球面来说",{"2":{"50":1}}],["虽然准确计算特征值可能会很昂贵",{"2":{"26":1}}],["虽然c的微小变化导致了c¯同样的微小变化",{"2":{"26":1}}],["贵宾",{"2":{"900":1}}],["贵",{"2":{"26":1}}],["计数为1",{"2":{"810":1}}],["计数",{"2":{"726":3}}],["计算属性",{"2":{"1451":1,"1460":2}}],["计算属性等",{"2":{"1448":1}}],["计算异常检验系统的f1值",{"2":{"1181":1}}],["计算代价较高",{"2":{"1184":1}}],["计算代价低",{"2":{"1184":1}}],["计算代价非常大",{"2":{"1169":1}}],["计算代价函数",{"2":{"1067":1,"1081":1}}],["计算偏导数和代价",{"2":{"1169":1}}],["计算样本i到其它簇cj的所有样本的平均距离bij",{"2":{"1154":1}}],["计算样本i到同簇其它样本的平均距离为a",{"2":{"1154":1}}],["计算新特征",{"2":{"1147":1}}],["计算",{"2":{"1130":1,"1184":1,"1490":2,"1493":1}}],["计算出的偏导数存储在矩阵",{"2":{"1124":1}}],["计算出了正确的代价函数",{"2":{"1092":1}}],["计算方法如下",{"2":{"1121":1}}],["计算后添加偏置项",{"2":{"1100":1}}],["计算hθ",{"2":{"1093":1}}],["计算数据",{"0":{"1090":1},"2":{"1193":1}}],["计算数量会增加多少",{"2":{"124":1}}],["计算结果为假",{"2":{"1088":1}}],["计算结果为",{"2":{"1088":1}}],["计算结果时显存带宽如何",{"2":{"465":1}}],["计算所有的预测结果后",{"2":{"1081":1}}],["计算所需时间明显大于同步参数需要的时间",{"2":{"828":1}}],["计算p",{"2":{"1038":1}}],["计算prelu激活函数的导数",{"2":{"239":1}}],["计算总和或均值时保持轴数不变",{"2":{"996":1}}],["计算平均值的函数也可以沿指定轴降低张量的维度",{"2":{"995":1}}],["计算x和x的点积",{"2":{"974":1}}],["计算风格迁移的损失函数",{"2":{"917":1}}],["计算损失",{"2":{"905":1}}],["计算损失对w的梯度",{"2":{"621":1}}],["计算两个锚框或边界框列表中成对的交并比",{"2":{"849":3}}],["计算模型参数的损失和梯度",{"2":{"833":1}}],["计算密集型操作的顺序对拆分来说也是非常重要的",{"2":{"832":1}}],["计算的负荷会非常大",{"2":{"1097":1}}],["计算的性能非常重要",{"2":{"824":1}}],["计算的顺序与前向传播中执行的顺序相反",{"2":{"164":1}}],["计算性能",{"0":{"824":1}}],["计算图就不再是默认行为",{"2":{"819":1}}],["计算图发生了什么",{"2":{"167":1}}],["计算资源",{"2":{"801":1}}],["计算是由后端执行",{"2":{"790":3}}],["计算每一个组的平均值",{"2":{"1151":1}}],["计算每一内部层的同时丢弃一些神经元",{"2":{"177":1}}],["计算每一内部层的同时注入噪声",{"2":{"170":1}}],["计算每个梯度的计算复杂度是多少",{"2":{"788":1}}],["计算余弦相似性",{"2":{"768":3}}],["计算上述结果",{"2":{"765":1}}],["计算下一句子预测任务的损失",{"2":{"726":3}}],["计算遮蔽语言模型损失",{"2":{"726":3}}],["计算softmax",{"2":{"655":1}}],["计算softmax交叉熵损失l",{"2":{"655":1}}],["计算在指定数据集上模型的精度",{"2":{"634":3}}],["计算预测正确的数量",{"2":{"634":2}}],["计算二阶导数时可能会遇到什么问题",{"2":{"607":1}}],["计算二维互相关运算",{"2":{"126":2}}],["计算l关于",{"2":{"605":2}}],["计算梯度并更新参数",{"2":{"635":4}}],["计算梯度g←∂",{"2":{"605":1}}],["计算梯度下降的每次迭代的代价更高",{"2":{"117":1}}],["计算完损失后",{"2":{"605":1}}],["计算均方误差使用的是meansquarederror类",{"2":{"593":1}}],["计算均方误差使用的是mseloss类",{"2":{"593":2}}],["计算bleu",{"2":{"578":1}}],["计算量是多少",{"2":{"498":1}}],["计算nin的资源使用情况",{"2":{"498":1}}],["计算移动方差元平方根的倒数",{"2":{"472":1}}],["计算通道维上",{"2":{"472":3}}],["计算特征维上的均值和方差",{"2":{"472":3}}],["计算特征值和特征向量要比解决实际问题",{"2":{"26":1}}],["计算机和驱动器用来进行自动驾驶的导航试验",{"2":{"1127":1}}],["计算机获得无比丰富的经验",{"2":{"1059":1}}],["计算机由以下关键部件组成",{"2":{"801":1}}],["计算机",{"0":{"801":1}}],["计算机视觉领域还有2个与语义分割相似的重要问题",{"2":{"944":1}}],["计算机视觉",{"0":{"886":1}}],["计算机视觉研究人员相信",{"2":{"454":1}}],["计算机视觉研究人员会告诉一个诡异事实",{"2":{"454":1}}],["计算机视觉流水线是由经过人的手工精心设计的特征流水线组成的",{"2":{"454":1}}],["计算机器与智能",{"2":{"299":1}}],["计算gpu上每个小批量的损失",{"2":{"452":1}}],["计算设备",{"0":{"446":1},"2":{"819":1}}],["计算带有激活函数的隐藏表示",{"2":{"423":1}}],["计算复杂性",{"2":{"397":1}}],["计算为任何以单词",{"2":{"316":1}}],["计算隐状态ht∈rh和",{"2":{"312":1}}],["计算生物学",{"2":{"301":1,"1058":2}}],["计算其应该属于的类",{"2":{"1151":1}}],["计算其元素的和",{"2":{"995":1}}],["计算其输出关于输入的梯度",{"2":{"423":2}}],["计算其输出形状",{"2":{"144":1}}],["计算其混淆矩阵",{"2":{"192":1}}],["计算本节所描述的模型",{"2":{"167":1}}],["计算中间变量z的梯度∂j",{"2":{"164":1}}],["计算最大值或平均值是取决于使用了最大汇聚层还是平均汇聚层",{"2":{"146":1}}],["计算多个通道的输出的互相关函数",{"2":{"121":1}}],["计算和通信之间存在的依赖关系是必须先计算y",{"2":{"797":1}}],["计算和存储神经网络的中间变量和参数的梯度",{"2":{"166":1}}],["计算和存储神经网络中每层的结果",{"2":{"162":1}}],["计算和存储完整的hessian非常昂贵",{"2":{"61":1}}],["计算和统计效率",{"2":{"82":1}}],["计算效率",{"2":{"82":1}}],["计算高效",{"2":{"76":1}}],["计算准确的二阶导数通常是不可行的",{"2":{"30":1}}],["计下了我们截至t时观察到功能i的次数",{"2":{"25":1}}],["修饰符的支持",{"2":{"1525":1}}],["修饰符",{"0":{"1426":1}}],["修改为",{"2":{"1525":2}}],["修改数据",{"0":{"1491":1}}],["修改数据时不覆盖旧数据",{"2":{"1200":1}}],["修改历史链条",{"2":{"1320":1}}],["修改假设为",{"2":{"1147":1}}],["修改后的代价函数如下",{"2":{"1115":1}}],["修改后优化器为x¯=−λ−1c¯且最小值为−12c¯⊤λ−1c¯+b",{"2":{"26":1}}],["修改load",{"2":{"690":1}}],["修改也更方便",{"2":{"502":1}}],["修改批量大小",{"2":{"465":1}}],["修改批量大小和学习率",{"2":{"83":1}}],["修改实验以将加性注意力打分函数替换为缩放点积注意力",{"2":{"378":1}}],["修改小例子中的键",{"2":{"372":1}}],["修改预测函数",{"2":{"337":1}}],["修改",{"2":{"301":1,"1460":1}}],["修复",{"2":{"26":1}}],["κ=λ1λd",{"2":{"26":1}}],["最新的公开版本为",{"2":{"1437":1}}],["最少连接",{"2":{"1362":1}}],["最基础的依赖管理方式",{"2":{"1267":1}}],["最基本的内存主要用于存储需要随时访问的数据",{"2":{"802":1}}],["最优值",{"2":{"1143":1}}],["最优序列",{"2":{"513":1}}],["最正确的道路",{"2":{"1129":1}}],["最左边的区段",{"2":{"1127":1}}],["最里层的循环j循环所有的行",{"2":{"1120":1}}],["最推荐的",{"2":{"1047":1}}],["最外层的列表对应于轴0",{"2":{"1017":1}}],["最重要的机器学习的应用是什么",{"2":{"1187":1}}],["最重要的语义分割数据集之一是pascal",{"2":{"945":1}}],["最重要的是",{"2":{"305":1}}],["最内层维度中的六个元素提供了同一预测边界框的输出信息",{"2":{"854":1}}],["最多可组合64对数字",{"2":{"809":1}}],["最明显的是",{"2":{"791":1}}],["最频繁的连续符号对是",{"2":{"757":1}}],["最直接的想法是选择y∈",{"2":{"640":1}}],["最早由德国数学家高斯",{"2":{"616":1}}],["最先是用于评估机器翻译的结果",{"2":{"578":1}}],["最先进的计算机视觉应用与深度学习几乎是不可分割的",{"2":{"886":1}}],["最先进的模型可能使用更高级的词元化技术",{"2":{"566":1}}],["最先进的技术不仅仅是将可用资源应用于几十年前的算法的结果",{"2":{"300":1}}],["最底层可能检测边缘",{"2":{"455":1}}],["最佳的做法是定期保存中间结果",{"2":{"440":1}}],["最佳参数集",{"2":{"282":1}}],["最流行的词",{"2":{"318":1}}],["最近",{"2":{"1146":1}}],["最近的聚类中心点",{"2":{"1152":1}}],["最近的4个像素",{"2":{"863":1}}],["最近的工作",{"2":{"300":1}}],["最近在深度学习方面取得的许多进展",{"2":{"303":1}}],["最近十年",{"2":{"300":1}}],["最古老的算法之一是唐纳德",{"2":{"299":1}}],["最常用单词的词频对比",{"2":{"318":1}}],["最常用方法是将其范数作为惩罚项加到最小化损失的问题中",{"2":{"270":1}}],["最常见的类别不一定是最终用于决策的类别",{"2":{"291":1}}],["最常见的目标函数是最小化错误率",{"2":{"286":1}}],["最常见的损失函数是平方误差",{"2":{"286":1}}],["最坏也是相等",{"2":{"259":1}}],["最好还是从所有原始特征开始",{"2":{"1162":1}}],["最好的实践方法不是建立一个非常复杂的系统",{"2":{"1138":1}}],["最好的学习方法是",{"2":{"1089":1}}],["最好的预测模型在训练数据上的表现往往比在保留",{"2":{"258":1}}],["最好有一种方法来重置我们的内部状态表示",{"2":{"538":1}}],["最好是为gpu内部的日志分配内存",{"2":{"452":1}}],["最好在使用较高的学习率之前预热优化器",{"2":{"69":1}}],["最初由",{"2":{"1374":1}}],["最初",{"2":{"241":1,"575":1}}],["最初的全卷积网络的论文中",{"2":{"868":1}}],["最初的bert模型使用词表大小为30000的wordpiece嵌入",{"2":{"722":1}}],["最初的bert模型是在两个庞大的图书语料库和英语维基百科",{"2":{"718":1}}],["最初的nin网络是在alexnet后不久提出的",{"2":{"495":1}}],["最初的训练时间是按天为单位的",{"2":{"300":1}}],["最初的值",{"2":{"95":1}}],["最初的更新方向可能也是毫无意义的",{"2":{"66":1}}],["最受欢迎的激活函数是修正线性单元",{"2":{"235":1}}],["最简单的方法是令",{"2":{"1082":1}}],["最简单的方法是考虑a的行向量和b的列向量",{"2":{"999":1}}],["最简单的方法是考虑具有多层的深层网络",{"2":{"819":1}}],["最简单的方法是将许多全连接层堆叠在一起",{"2":{"231":1}}],["最简单的方法就是自己实现一个",{"2":{"423":1}}],["最简单的表示称为独热编码",{"2":{"330":1}}],["最简单的分类问题是只有两类",{"2":{"291":1}}],["最简单的深度网络称为多层感知机",{"2":{"204":1}}],["最简单的形式是",{"2":{"132":1}}],["最可能出现的地方",{"2":{"157":1}}],["最终我所得到的最优值θ都是一样的",{"2":{"1143":1}}],["最终达到改进机器学习系统性能的目的假设我们需要用一个线性回归模型来预测房价",{"2":{"1129":1}}],["最终将得出的这个矩阵同",{"2":{"1124":1}}],["最终可能就用theta",{"2":{"1093":1}}],["最终得到局部最小值",{"2":{"1068":2}}],["最终会发现这个星球上没有两个人具有完全相同的身高",{"2":{"1028":1}}],["最终所有标记的数据",{"2":{"908":1}}],["最终的损失函数是掩蔽语言模型损失函数和下一句预测损失函数的线性组合",{"2":{"738":1}}],["最终的隐藏神经元可以学习图像的综合表示",{"2":{"455":1}}],["最终高度和宽度都为7",{"2":{"508":1}}],["最终使框架初始化参数",{"2":{"418":1}}],["最终输出的预测边界框即是兴趣区域汇聚层所需的提议区域",{"2":{"939":1}}],["最终输出的合成图像应用了风格图像的油画笔触让整体颜色更加鲜艳",{"2":{"916":1}}],["最终输出的形状",{"2":{"382":4}}],["最终输出一个维数与结果分类数相匹配的输出",{"2":{"136":1}}],["最终",{"2":{"152":1,"258":1,"475":1,"980":1}}],["最终实现学习全局表示的目标",{"2":{"145":1}}],["最大的$",{"2":{"1112":1}}],["最大的公开图像数据集包含大约一百万张图像",{"2":{"251":1}}],["最大化不同项目之间的距离",{"2":{"1001":1}}],["最大化分配给观测数据的概率",{"2":{"1001":1}}],["最大化观测数据的似然",{"2":{"652":1}}],["最大序列长度",{"2":{"734":3}}],["最大长度是512",{"2":{"725":1}}],["最大时间汇聚允许在不同通道上使用不同数量的时间步",{"2":{"700":1}}],["最大时间汇聚层允许在不同通道上使用不同数量的时间步长",{"2":{"705":1}}],["最大时间汇聚层没有参数",{"2":{"702":3}}],["最大时间汇聚层",{"0":{"700":1}}],["最大路径长度也是o",{"2":{"397":2}}],["最大路径长度为o",{"2":{"397":1}}],["最大汇聚层会输出该窗口内的最大值",{"2":{"149":1}}],["最大汇聚层和平均汇聚层",{"0":{"146":1}}],["最大限度地减少非线性非凸问题是np困难的",{"2":{"114":1}}],["最大和最小的特征值之比称为优化问题的条件数",{"2":{"26":1}}],["最小的部署单元",{"2":{"1380":1}}],["最小的点",{"2":{"1064":1,"1066":1}}],["最小存储单位",{"2":{"1198":1}}],["最小架构更改",{"2":{"656":1}}],["最小均方损失",{"2":{"350":1}}],["最小化这些代价函数的必要条件是什么",{"2":{"1144":1}}],["最小化的话",{"2":{"1111":1}}],["最小化代价函数的方法",{"2":{"1110":1}}],["最小化预测和真实观测之间的距离",{"2":{"1001":1}}],["最小化传达标签所需的惊异",{"2":{"652":1}}],["最小化目标函数和执行极大似然估计等价",{"2":{"620":1}}],["最小化均方误差等价于对线性模型的极大似然估计",{"2":{"616":1}}],["最小化训练误差并不能保证我们找到最佳的参数集来最小化泛化误差",{"2":{"104":1}}],["最小化器并非如此",{"2":{"26":1}}],["最小值为b−12c⊤q−1c",{"2":{"94":1}}],["最有效的方法是在一个区块中执行整个操作",{"2":{"77":1}}],["最有用的数学工具之一就是詹森不等式",{"2":{"42":1}}],["最陡下降的方向由负梯度−∇f",{"2":{"57":1}}],["最后我想说",{"2":{"1176":1}}],["最后我们计算多元高斯分布的p",{"2":{"1184":1}}],["最后我们手工选择数据",{"2":{"1174":1}}],["最后我们得到一系列的模型简记为",{"2":{"1112":1}}],["最后我们将输出变成二维数组",{"2":{"488":1}}],["最后我们将每条线路的输出在通道维度上连结",{"2":{"487":1}}],["最后的结果只与数据相关",{"2":{"1158":1}}],["最后有别于逻辑回归输出的概率",{"2":{"1143":1}}],["最后通过交叉验证来检验数据",{"2":{"1138":1}}],["最后通过转置卷积层将特征图的高和宽变换为输入图像的尺寸",{"2":{"867":1}}],["最后还有一点",{"2":{"1110":1}}],["最后是输出单元",{"2":{"1099":1}}],["最后是输出层",{"2":{"461":4}}],["最后如果你想",{"2":{"1091":1}}],["最后输入title",{"2":{"1091":1}}],["最后再比较多次运行k",{"2":{"1153":1}}],["最后再讲两个内容",{"2":{"1090":1}}],["最后再展平表示",{"2":{"508":1}}],["最后学习算法被用来理解人类的学习和了解大脑",{"2":{"1058":1}}],["最后调用刚刚定义的用于训练和评估模型的train",{"2":{"883":1}}],["最后打印标注的类别",{"2":{"866":1}}],["最后需要",{"2":{"862":1}}],["最后在结束本章时",{"2":{"886":1}}],["最后在",{"2":{"862":1}}],["最后只输出符合特定条件的预测边界框",{"2":{"850":1}}],["最后可能有几个全连接的层",{"2":{"832":1}}],["最后值得一提的是张量核",{"2":{"811":1}}],["最后得到的是0",{"2":{"624":1}}],["最后放一个全局平均汇聚层",{"2":{"495":1}}],["最后接上全局汇聚层和全连接层来输出结果",{"2":{"482":1}}],["最后将描述仅仅基于注意力机制的transformer架构",{"2":{"379":1}}],["最后将所有结果都叠加在一起",{"2":{"121":1}}],["最后智能体从环境中获得奖励",{"2":{"298":1}}],["最后一点",{"2":{"1145":2}}],["最后一点注意",{"2":{"116":1}}],["最后一个阶段是字符分类阶段",{"2":{"1172":1}}],["最后一个命令",{"2":{"1091":1}}],["最后一个例子",{"2":{"1061":1}}],["最后一个元素索引是",{"2":{"1020":1}}],["最后一个性质要求范数最小为0",{"2":{"1000":1}}],["最后一个模块使用全局最大池将高度和宽度都降到1",{"2":{"959":1}}],["最后一个问题提出了分布偏移",{"2":{"297":1}}],["最后一种方法",{"2":{"832":1}}],["最后一层的单元数是我们训练集的结果的类的数量",{"2":{"1126":1}}],["最后一层的隐状态的输出是一个张量",{"2":{"573":1}}],["最后一层称为输出层",{"2":{"1099":1}}],["最后一层与之前的所有层紧密相连",{"2":{"479":1}}],["最后一轴上被掩蔽的元素使用一个非常大的负值替换",{"2":{"368":4}}],["最后一步是对t∈",{"2":{"115":1}}],["最后定义",{"2":{"115":1}}],["最后让x∗表示最小值",{"2":{"115":1}}],["最后",{"2":{"27":1,"33":2,"46":1,"66":1,"80":1,"136":1,"162":1,"164":1,"201":1,"209":1,"252":1,"257":1,"298":1,"302":1,"305":1,"310":1,"312":1,"316":1,"318":1,"321":1,"335":1,"342":2,"362":1,"367":1,"380":1,"408":1,"422":1,"425":1,"450":1,"479":1,"502":1,"515":1,"521":1,"527":1,"539":1,"556":1,"569":1,"575":1,"578":1,"605":1,"613":1,"634":1,"663":1,"682":1,"695":1,"715":1,"717":1,"721":1,"722":1,"757":1,"777":1,"791":1,"797":1,"800":1,"801":1,"805":1,"807":1,"828":1,"841":1,"851":1,"890":1,"912":1,"917":1,"930":1,"932":1,"938":1,"949":1,"962":1,"963":1,"964":1,"968":1,"987":1,"1035":1,"1061":2,"1089":1,"1090":1,"1091":2,"1092":3,"1112":2,"1148":1,"1150":1,"1156":1,"1176":2}}],["对路由的理解",{"0":{"1473":1}}],["对机器学习来说",{"2":{"1187":1}}],["对推荐系统性能的改善",{"2":{"1187":1}}],["对交叉检验集",{"2":{"1181":1}}],["对训练集的函数的求和",{"2":{"1169":1}}],["对训练数据进行加权",{"2":{"191":1}}],["对α进行调整所耗费的计算通常不值得",{"2":{"1167":1}}],["对么",{"2":{"1144":1}}],["对整个代价函数而言",{"2":{"1143":1}}],["对整个输入序列x1",{"2":{"574":1}}],["对你来讲并不是很有帮助",{"2":{"1129":1}}],["对你们而言",{"2":{"1061":1}}],["对梯度的估计采用的方法是在代价函数上沿着切线的方向选择离两个非常近的点然后计算两个点的平均值用以估计梯度",{"2":{"1124":1}}],["对很多人来说",{"2":{"1122":1}}],["对上面的算法中$",{"2":{"1116":1}}],["对上述所有的例子",{"2":{"1112":1}}],["对上一个例子中稠密块的输出",{"2":{"481":1}}],["对模型的理解",{"2":{"1107":1}}],["对模型进行训练和测试",{"0":{"263":1},"2":{"176":1}}],["对a矩阵的每一个元素与3进行比较",{"2":{"1090":1}}],["对a矩阵进行赋值",{"2":{"1088":1}}],["对变量a赋值为3",{"2":{"1088":1}}],["对j",{"2":{"1086":1}}],["对$",{"2":{"1068":1}}],["对大量机器学习算法",{"2":{"1061":1}}],["对大多数桌面计算机来说",{"2":{"445":1}}],["对我们之前的线性回归问题运用梯度下降法",{"2":{"1069":1}}],["对我们理解这个问题不能提供更多帮助",{"2":{"60":1}}],["对我来说",{"2":{"1058":1}}],["对焦距离和相机类型",{"2":{"1029":1}}],["对生成的数组执行按元素操作",{"2":{"1019":1}}],["对生物学的解释变得不再肤浅",{"2":{"299":1}}],["对张量中的所有元素进行求和",{"2":{"1018":1}}],["对称矩阵",{"2":{"992":1}}],["对非标量调用backward需要传入一个gradient参数",{"2":{"975":1}}],["对所有深层的对象不会做任何处理",{"2":{"1513":1}}],["对所有损失求和",{"2":{"925":1}}],["对所有1≤i≤k成立",{"2":{"192":1}}],["对测试集运用该模型",{"2":{"1130":1}}],["对测试集分类",{"0":{"908":1}}],["对测试集进行分类并提交结果",{"0":{"896":1}}],["对预测结果的影响就比之前要小许多",{"2":{"1115":1}}],["对预测边界框的置信度进行排序",{"2":{"854":3}}],["对预训练transformer编码器的所有参数进行微调",{"2":{"733":1}}],["对预训练bert模型进行微调",{"2":{"663":1}}],["对锚框偏移量的转换",{"2":{"852":1}}],["对那些刚接触该语言的人来说是一个很好的改变",{"2":{"818":1}}],["对设备执行一次传递",{"2":{"796":3}}],["对自动并行计算的讨论主要集中在使用cpu和gpu的并行计算上",{"2":{"795":1}}],["对本节中相同的矩阵乘法操作进行基准测试",{"2":{"794":2}}],["对程序的整体性能几乎没有影响",{"2":{"790":1}}],["对pytorch来说gpu操作在默认情况下是异步的",{"2":{"789":1}}],["对词典中索引为i的词进行训练后",{"2":{"784":1}}],["对输入图像使用选择性搜索来选取多个高质量的提议区域",{"2":{"937":1}}],["对输入的一维张量和卷积核的一维张量执行互相关运算",{"2":{"699":1}}],["对输出单元进行微分",{"2":{"244":1}}],["对net模型进行训练和评估",{"2":{"688":1}}],["对两组比较向量分别求和",{"2":{"676":3}}],["对齐的方式显示了这种对齐方式",{"2":{"674":1}}],["对齐",{"2":{"673":1,"674":5,"675":1}}],["对给定任意输入x的每个类的条件概率",{"2":{"646":1}}],["对图像进行分类预测",{"2":{"636":1}}],["对每个提议区域",{"2":{"938":1}}],["对每个项求幂",{"2":{"631":1}}],["对每一行特征都预测k​个不同结果",{"2":{"1120":1}}],["对每一行求和",{"2":{"631":1}}],["对每一类图像进行预筛选",{"2":{"456":1}}],["对向量相加的两种方法",{"2":{"615":1}}],["对索引为i的样本",{"2":{"609":1}}],["对性能有何影响",{"2":{"580":1}}],["对一个256×256像素的小批量图像x",{"2":{"959":1}}],["对一个单层来说",{"2":{"526":1}}],["对一般的非凸问题",{"2":{"114":1}}],["对下一个输出进行建模",{"2":{"518":1}}],["对随后的深层神经网络设计产生了深远影响",{"2":{"504":1}}],["对inception模块进行调整",{"2":{"491":1}}],["对某些块应用不同的初始化方法",{"2":{"435":1}}],["对的数目",{"2":{"409":1}}],["对的个数",{"2":{"369":12,"370":8,"382":24}}],["对比项",{"2":{"1346":1,"1349":1,"1351":1}}],["对比和团队协作",{"2":{"1318":1}}],["对比",{"0":{"1205":1,"1458":1}}],["对比于逻辑回归而言",{"2":{"1143":1}}],["对比度和饱和度",{"2":{"903":3}}],["对比度",{"2":{"880":2}}],["对比lenet的结果有什么不同",{"2":{"465":1}}],["对比不同维度的层规范化和批量规范化的效果",{"2":{"406":1}}],["对比之前仍然依赖循环神经网络实现输入表示的自注意力模型",{"2":{"403":1}}],["对序列进行编码",{"2":{"395":1}}],["对个数",{"2":{"391":6}}],["对越接近",{"2":{"388":1}}],["对它们的唯一词元进行统计",{"2":{"363":1}}],["对它说道",{"2":{"282":1}}],["对进行注意力计算",{"2":{"409":1}}],["对进行计算",{"2":{"392":1}}],["对进行训练",{"2":{"350":1}}],["对进行x优化的过程可以绘制如下",{"2":{"54":1}}],["对该主题的更多内容做了详尽的解释",{"2":{"349":1}}],["对超出已知观测范围进行预测",{"2":{"345":1,"352":1}}],["对隐状态使用循环计算的神经网络称为循环神经网络",{"2":{"343":1}}],["对参数进行regularization的bias项处理所有参数的平方和",{"2":{"1120":1}}],["对参数进行良好的初始化也可能是有益的",{"2":{"104":1}}],["对参数向量的影响",{"2":{"334":1}}],["对了解循环神经网络的实现方式具有指导意义",{"2":{"324":1}}],["对应",{"2":{"1392":1}}],["对应每一个可能的",{"2":{"1112":1}}],["对应于亮像素",{"2":{"1098":1}}],["对应于contexts",{"2":{"776":2}}],["对应于",{"2":{"640":3}}],["对应于每个空间位置的红",{"2":{"284":1}}],["对应的就是",{"2":{"1392":1}}],["对应的",{"2":{"1143":1}}],["对应的值会变的非常小",{"2":{"1143":1}}],["对应的操作就是向左急转",{"2":{"1127":1}}],["对应的对数损失在",{"2":{"707":1}}],["对应的依赖关系就越长",{"2":{"317":1}}],["对应的特征向量是vi",{"2":{"314":1}}],["对任意时间步t",{"2":{"312":1}}],["对残疾人来说是个福音",{"2":{"301":1}}],["对卡内基梅隆大学机器学习博士生来说",{"2":{"300":1}}],["对统计理论和在遗传学中的应用做出了重大贡献",{"2":{"299":1}}],["对其他道路类型",{"2":{"1127":1}}],["对其有所遗忘",{"2":{"1070":1}}],["对其中的每个个体",{"2":{"1061":1}}],["对其左边的上下文敏感",{"2":{"732":1}}],["对其进行编码",{"2":{"650":1}}],["对其进行优化",{"2":{"147":1}}],["对其余的人取平均值",{"2":{"299":1}}],["对话助手",{"2":{"1053":1}}],["对话中的音频信号以及网站上的浏览行为都是有顺序的",{"2":{"305":1}}],["对话系统",{"2":{"298":1}}],["对话问题对序列的学习更为复杂",{"2":{"295":1}}],["对都称为一个样本",{"2":{"289":1}}],["对日益壮大的机器学习科学家群体来说",{"2":{"281":1}}],["对线性模型的依赖对应于一个隐含的假设",{"2":{"230":1}}],["对体温低于37摄氏度的人来说",{"2":{"230":1}}],["对体温高于37摄氏度的人来说",{"2":{"230":1}}],["对这些复杂问题的讨论",{"2":{"220":1}}],["对数似然的梯度正是由此得出的",{"2":{"647":1}}],["对数似然",{"0":{"646":1}}],["对数据类型很敏感",{"2":{"634":1}}],["对数",{"2":{"391":2}}],["对数对于相对误差很有用",{"2":{"214":1}}],["对数几率回归",{"2":{"191":1}}],["对象内部的嵌套属性仍然是可变的",{"2":{"1516":1}}],["对象内部的嵌套属性则不会变成响应式的",{"2":{"1512":1}}],["对象的所有嵌套属性都将变为只读",{"2":{"1515":1}}],["对象的顶层属性是响应式的",{"2":{"1512":1}}],["对象的表示",{"2":{"296":1}}],["对象中的内容",{"2":{"1451":1}}],["对象类型数据",{"2":{"1458":2}}],["对象类型的响应式数据",{"0":{"1456":1,"1457":1}}],["对象类型别名",{"2":{"1412":1}}],["对象类型",{"2":{"1405":1,"1457":1,"1463":3,"1464":3,"1465":4}}],["对象类型声明",{"2":{"1398":1}}],["对象模型",{"0":{"1320":1}}],["对象",{"2":{"182":1}}],["对",{"2":{"137":1,"339":1,"350":1,"367":1,"634":1,"674":1,"774":1,"1207":1,"1444":1}}],["对二维输入数据和卷积核执行互相关操作",{"2":{"132":1}}],["对来学习由x生成y的卷积核",{"2":{"129":1}}],["对凸问题的分析使我们能够深入了解如何进行优化",{"2":{"117":1}}],["对gt的合理分布来说",{"2":{"106":1}}],["对此",{"2":{"73":1}}],["对深度学习而言",{"2":{"62":1}}],["对角线为1",{"2":{"1090":1}}],["对角线",{"2":{"61":1}}],["对于let",{"2":{"1455":1}}],["对于eve",{"2":{"1192":1}}],["对于用户",{"2":{"1188":1}}],["对于异常检测算法",{"2":{"1183":1}}],["对于很多技术公司可能会遇到的一些问题",{"2":{"1182":1}}],["对于数据集中的每一个数据",{"2":{"1151":1}}],["对于svm你不需要担心局部最优",{"2":{"1148":1}}],["对于snli数据集的下游任务自然语言推断",{"2":{"687":1}}],["对于许多这样的问题",{"2":{"1148":1}}],["对于许多任务",{"2":{"260":1}}],["对于负样本而言我们需要p",{"2":{"1145":1}}],["对于正样本而言",{"2":{"1145":1}}],["对于正定矩阵q≻0",{"2":{"94":1}}],["对于逻辑回归",{"2":{"1143":1}}],["对于逻辑回归模型",{"2":{"1130":1}}],["对于支持向量机",{"2":{"1143":1}}],["对于支持向量机而言",{"2":{"1143":1}}],["对于总代价函数通常会有对所有的训练样本求和",{"2":{"1143":1}}],["对于神经网络中的隐藏层的层数的选择",{"2":{"1135":1}}],["对于交叉验证集",{"2":{"1132":1}}],["对于直线或许你也知道",{"2":{"1112":1}}],["对于直到时间步t的观测序列",{"2":{"352":1}}],["对于直到xt的观测序列",{"2":{"351":1}}],["对于下标是0",{"2":{"1112":1}}],["对于梯度下降来说",{"2":{"1111":1}}],["对于梯度下降我们有",{"2":{"95":1}}],["对于分类",{"2":{"1106":1}}],["对于上图所示的数据",{"2":{"1107":1}}],["对于上图所示的模型",{"2":{"1099":1}}],["对于上下文窗口m",{"2":{"783":1,"785":1}}],["对于上下文敏感的词表示",{"2":{"739":1}}],["对于之前就学过c语言的同学来说",{"2":{"1088":1}}],["对于那些更复杂的学习算法",{"2":{"1085":1}}],["对于那些不可逆的矩阵",{"2":{"1085":1}}],["对于互斥",{"2":{"1027":1}}],["对于我们刚才那个总是预测病人肿瘤为良性的算法",{"2":{"1139":1}}],["对于我们的房价预测问题",{"2":{"1063":1}}],["对于我们从工厂收到的真实骰子",{"2":{"1026":1}}],["对于我们选择的尺度",{"2":{"243":1}}],["对于将两个数组作为输入的函数",{"2":{"1018":1}}],["对于inputs中的类别值或离散值",{"2":{"1012":1}}],["对于inputs中缺少的数值",{"2":{"1012":1}}],["对于矩阵b∈rm×n",{"2":{"994":1}}],["对于矩阵m的投影projx可以写成mx",{"2":{"52":1}}],["对于偏导数的表示",{"2":{"982":1}}],["对于此高和宽减半块的输入和输出特征图",{"2":{"957":1}}],["对于特征图y1和y2",{"2":{"956":1}}],["对于特征集合x",{"2":{"610":1}}],["对于该兴趣区域",{"2":{"938":1}}],["对于该层nin输入xj及其相关权重wij",{"2":{"247":1}}],["对于香蕉数据集而言",{"2":{"932":1}}],["对于测试集",{"2":{"932":1}}],["对于rgb",{"2":{"872":1}}],["对于1×1卷积层",{"2":{"863":1}}],["对于背景",{"2":{"854":1}}],["对于a3",{"2":{"853":1}}],["对于a2",{"2":{"853":1}}],["对于a0",{"2":{"853":1}}],["对于两个边界框",{"2":{"849":1}}],["对于整个输入图像",{"2":{"848":1}}],["对于高阶和高维的y和x",{"2":{"975":1}}],["对于高效的多gpu训练",{"2":{"835":1}}],["对于高维张量",{"2":{"164":1}}],["对于高维度问题",{"2":{"102":1}}],["对于全连接的层",{"2":{"832":1}}],["对于需要分类的小批量训练数据",{"2":{"832":1}}],["对于前几章中实现的那些模型",{"2":{"824":1}}],["对于前者",{"2":{"811":1}}],["对于前向传播",{"2":{"165":1}}],["对于后者",{"2":{"811":1}}],["对于计算机体系结构的深入概述",{"2":{"800":1}}],["对于语义相似的一对词",{"2":{"788":1}}],["对于语言模型",{"2":{"411":1}}],["对于语言建模",{"2":{"320":1}}],["对于字典中索引i的任意词",{"2":{"785":1}}],["对于词典中索引为i的任何词",{"2":{"783":1}}],["对于在语义上有意义的表示",{"2":{"782":1}}],["对于在词典raw",{"2":{"757":1}}],["对于glove中的任意词",{"2":{"745":1}}],["对于共现概率pij",{"2":{"744":1}}],["对于同时与",{"2":{"744":1}}],["对于同样的训练误差而言",{"2":{"74":1}}],["对于与",{"2":{"744":3}}],["对于权重函数",{"2":{"743":1}}],["对于单位矩阵",{"2":{"1076":1}}],["对于单个的",{"2":{"819":1}}],["对于单个词元",{"2":{"773":1}}],["对于单个张量",{"2":{"441":1}}],["对于单词类比a",{"2":{"751":1}}],["对于单文本输入",{"2":{"734":1}}],["对于相同的下游应用",{"2":{"712":1}}],["对于相同的分类问题",{"2":{"226":1}}],["对于软对齐",{"2":{"674":1}}],["对于广泛的自然语言处理应用",{"2":{"663":1}}],["对于广泛的学习率选择",{"2":{"117":1}}],["对于自然语言推断",{"2":{"663":1}}],["对于问答",{"2":{"660":1}}],["对于文本对回归任务",{"2":{"658":1}}],["对于标签y",{"2":{"648":1}}],["对于标准深度学习模型",{"2":{"591":1}}],["对于o的每一行",{"2":{"644":1}}],["对于线性回归的求解",{"2":{"1116":1}}],["对于线性回归假设函数",{"2":{"1110":1}}],["对于线性回归模型",{"2":{"1109":1,"1130":1}}],["对于线性回归",{"2":{"618":1}}],["对于平方损失和仿射变换",{"2":{"613":1}}],["对于预测序列中的任意n元语法",{"2":{"578":1}}],["对于重置门rt中所有接近0的项",{"2":{"541":1}}],["对于给定的数据集",{"2":{"1180":1}}],["对于给定的输入变量",{"2":{"1107":1}}],["对于给定的时间步t",{"2":{"540":1}}],["对于给定数据样本的特征x",{"2":{"641":1}}],["对于给定输入元素",{"2":{"149":1}}],["对于有t个观测值的序列",{"2":{"519":1}}],["对于有限的样本数量",{"2":{"116":1}}],["对于输出序列的每一时间步t",{"2":{"513":1}}],["对于更复杂的屏幕输出",{"2":{"1088":1}}],["对于更复杂的问题",{"2":{"278":1}}],["对于更深层次的网络",{"2":{"505":1}}],["对于非常大的数据集",{"2":{"804":1}}],["对于非嵌套函数",{"2":{"500":1}}],["对于非凸问题",{"2":{"49":1,"63":1}}],["对于卷积层",{"2":{"470":1}}],["对于卷积核张量上的权重",{"2":{"130":1}}],["对于典型的多层感知机或卷积神经网络",{"2":{"467":1}}],["对于这样选择的参数θ",{"2":{"1145":1}}],["对于这些测试图像",{"2":{"866":1}}],["对于这些传统方法",{"2":{"454":1}}],["对于这个简单的例子",{"2":{"1130":1}}],["对于这个问题",{"2":{"1068":1}}],["对于这个例子就是价格",{"2":{"1063":1}}],["对于这个回归问题",{"2":{"962":1}}],["对于这个涉及wo的事件",{"2":{"708":1}}],["对于这个更简单的问题",{"2":{"197":1}}],["对于这种情况",{"2":{"571":1}}],["对于多个输入和输出通道",{"2":{"969":1}}],["对于多个隐藏层",{"2":{"325":1}}],["对于多层感知机而言",{"2":{"422":1}}],["对于序列级和词元级自然语言处理应用",{"2":{"661":1}}],["对于序列中任何位置的任何输入x∈rd",{"2":{"404":1}}],["对于序列数据处理问题",{"2":{"360":1}}],["对于训练集",{"2":{"1132":1}}],["对于训练",{"2":{"391":1}}],["对于h个注意力汇聚输出",{"2":{"380":1}}],["对于点积操作",{"2":{"370":1}}],["对于时间是向前推进的因果模型",{"2":{"352":1}}],["对于时间步t−",{"2":{"338":1}}],["对于时间步t",{"2":{"312":1,"340":1}}],["对于所拥有的序列数据",{"2":{"352":1}}],["对于所有i≠j都有ai∩aj=∅",{"2":{"1027":1}}],["对于所有a∈rn×n",{"2":{"983":1}}],["对于所有a∈rn×m",{"2":{"983":1}}],["对于所有a∈rm×n",{"2":{"983":1}}],["对于所有输出序列",{"2":{"512":1}}],["对于所有f∈f",{"2":{"500":1}}],["对于所有p≥1是凸的",{"2":{"52":1}}],["对于所有的这些不同体系一个设计得很好的神经网络也很有可能会非常有效",{"2":{"1148":1}}],["对于所有的这些问题",{"2":{"1148":1}}],["对于所有的j总有0≤y^j≤1",{"2":{"643":1}}],["对于所有的",{"2":{"46":1}}],["对于某些可加性噪声ϵ",{"2":{"349":1}}],["对于某一层的任意元素x",{"2":{"131":1}}],["对于离散的对象",{"2":{"347":1}}],["对于n个序列样本的小批量",{"2":{"340":1}}],["对于",{"2":{"338":1,"751":1,"991":1,"1138":1}}],["对于长度为t的序列",{"2":{"334":1}}],["对于以后要介绍的一些模型",{"2":{"325":1}}],["对于反向传播算法究竟是如何执行的",{"2":{"1122":1}}],["对于反向传播这种算法",{"2":{"1122":1}}],["对于反向传播",{"2":{"307":1}}],["对于图像数据",{"2":{"305":1}}],["对于监督学习里的每条数据",{"2":{"1061":1}}],["对于监督学习",{"2":{"297":1}}],["对于电影推荐",{"2":{"294":1}}],["对于亚马逊等电子商务网站上的客户评论",{"2":{"284":1}}],["对于刚刚所说的电子商务平台",{"2":{"281":1}}],["对于λ",{"2":{"270":1}}],["对于λ=0",{"2":{"270":1}}],["对于固定的任务和数据分布",{"2":{"260":1}}],["对于固定架构",{"2":{"178":1}}],["对于大多数问题",{"2":{"1064":1}}],["对于大多数算法",{"2":{"252":1}}],["对于大多数激活函数都是这样",{"2":{"232":1}}],["对于中等难度的问题",{"2":{"246":1}}],["对于一对中心词和上下文词",{"2":{"775":1}}],["对于一个",{"2":{"1159":1}}],["对于一个训练样本",{"2":{"1144":1}}],["对于一个多类分类问题",{"2":{"1112":1}}],["对于一个带有参数的模型",{"2":{"987":1}}],["对于一个预测边界框b",{"2":{"854":1}}],["对于一个cpu核心",{"2":{"457":1}}],["对于一个定义域在r中的输入",{"2":{"236":1}}],["对于一组医疗数据",{"2":{"284":1}}],["对于一家想利用机器学习来开发自动驾驶汽车的公司",{"2":{"186":1}}],["对于具有由d维向量表示的n个词元的单个文本序列",{"2":{"701":1}}],["对于具有h个隐藏单元的单隐藏层多层感知机",{"2":{"232":1}}],["对于具有显著差异的梯度",{"2":{"36":1}}],["对于深度神经网络",{"2":{"230":1,"500":1}}],["对于深度学习框架的高级api",{"2":{"176":1}}],["对于深度学习而言",{"2":{"117":1}}],["对于深度学习问题",{"2":{"98":1}}],["对于协变量偏移",{"2":{"191":1}}],["对于向量x",{"2":{"781":1}}],["对于向量",{"2":{"164":1}}],["对于每个值",{"2":{"1026":1}}],["对于每个骰子",{"2":{"1026":1}}],["对于每个位置",{"2":{"1018":1}}],["对于每个参数",{"2":{"981":1}}],["对于每个锚框",{"2":{"851":3}}],["对于每个样本",{"2":{"776":1}}],["对于每个预测",{"2":{"736":1}}],["对于每个通道在不同时间步存储值的多通道输入",{"2":{"700":1}}],["对于每个通道",{"2":{"699":1}}],["对于每个时间步t",{"2":{"574":1}}],["对于每个时间步",{"2":{"549":1}}],["对于每个",{"2":{"307":1}}],["对于每个特征",{"2":{"169":1}}],["对于每一部电影",{"2":{"1189":1}}],["对于每一行特征",{"2":{"1120":1}}],["对于每一个用户",{"2":{"1168":1}}],["对于每一个类k",{"2":{"1151":1}}],["对于每一个样例i",{"2":{"1151":1}}],["对于每一个测试集样本",{"2":{"1130":1}}],["对于每一个账户",{"2":{"1060":1}}],["对于每一个小批量",{"2":{"595":1}}],["对于每一个空间位置",{"2":{"158":1}}],["对于每一层",{"2":{"249":1}}],["对于每一层我们都要记录一个权重矩阵和一个偏置向量",{"2":{"217":1}}],["对于每次参数更新",{"2":{"21":1}}],["对于二维张量",{"2":{"156":1}}],["对于由索引为z的",{"2":{"156":1}}],["对于隐藏表示中任意给定位置",{"2":{"153":1}}],["对于表格数据",{"2":{"151":1}}],["对于音频信号",{"2":{"144":1}}],["对于本节中的最后一个示例",{"2":{"144":1}}],["对于无噪声梯度下降和嘈杂随机梯度下降",{"2":{"96":1}}],["对于ηλ",{"2":{"95":1}}],["对于β=0",{"2":{"88":1}}],["对于嘈杂的梯度",{"2":{"84":1}}],["对于t≥1",{"2":{"307":1}}],["对于t",{"2":{"72":1}}],["对于f",{"2":{"59":1}}],["对于ξ∈",{"2":{"52":1}}],["对于若干半径r",{"2":{"49":1}}],["对于ci",{"2":{"48":1}}],["对于任一中心词",{"2":{"774":1}}],["对于任意事件a",{"2":{"1027":1}}],["对于任意具有相同形状的张量",{"2":{"1018":1}}],["对于任意形状的张量这个函数计算得到什么",{"2":{"1004":1}}],["对于任意形状的张量x",{"2":{"1004":1}}],["对于任意a∈rm×n",{"2":{"992":1}}],["对于任意i=1",{"2":{"984":1}}],["对于任意词w",{"2":{"756":1}}],["对于任意索引i",{"2":{"742":1}}],["对于任意数据迭代器data",{"2":{"634":1}}],["对于任意输入词元的索引i",{"2":{"573":1}}],["对于任意时间步t",{"2":{"521":1}}],["对于任意x和y我们有",{"2":{"334":1}}],["对于任意一种这样的方法",{"2":{"191":1}}],["对于任意二次可微多维函数f",{"2":{"46":1}}],["对于任何矩阵x",{"2":{"983":1}}],["对于任何a和b的取值",{"2":{"1030":1}}],["对于任何a",{"2":{"977":1}}],["对于任何形状为h×w的兴趣区域窗口",{"2":{"938":1}}],["对于任何词元索引i",{"2":{"762":1}}],["对于任何一个词",{"2":{"746":1}}],["对于任何元素",{"2":{"742":1}}],["对于任何标签y和模型预测y^",{"2":{"646":1}}],["对于任何具有多个通道的一维输入",{"2":{"699":1}}],["对于任何具有d个输入和q个输出的全连接层",{"2":{"642":1}}],["对于任何具体的步骤序列",{"2":{"115":1}}],["对于任何随机输入",{"2":{"631":1}}],["对于任何确定的位置偏移δ",{"2":{"400":1}}],["对于任何查询",{"2":{"388":1}}],["对于任何时间步1≤t≤t展开递归计算得",{"2":{"312":1}}],["对于任何给定的用户",{"2":{"294":1}}],["对于任何二维张量x",{"2":{"141":1}}],["对于任何特征向量v",{"2":{"105":1}}],["对于任何目标函数f",{"2":{"101":1}}],["对于任何x",{"2":{"45":1,"59":1}}],["对于x→−∞",{"2":{"44":1}}],["对于x∈rd",{"2":{"26":1}}],["对于凸函数f",{"2":{"44":1}}],["对于凸问题",{"2":{"27":1,"117":1}}],["对小的λi来说",{"2":{"26":1}}],["以开发出一种异常检测算法",{"2":{"1180":1}}],["以我们的文字识别应用为例",{"2":{"1173":1}}],["以我们的垃圾邮件过滤器为例",{"2":{"1138":1}}],["以达到加速处理的目的",{"2":{"1169":1}}],["以线性回归模型为例",{"2":{"1164":1}}],["以一个例子来说明反向传播算法",{"2":{"1121":1}}],["以一对文本序列作为输入",{"2":{"734":1}}],["以一对文本作为输入但输出连续值",{"2":{"658":1}}],["以第",{"2":{"1099":2}}],["以这些元素为幂的运算",{"2":{"1090":1}}],["以这些均匀采样的像素为中心",{"2":{"912":1}}],["以两个参数分别为横纵坐标",{"2":{"1082":1}}],["以房价问题为例",{"2":{"1082":1}}],["以之前的房屋交易问题为例",{"2":{"1063":1}}],["以性能度量值p为标准",{"2":{"1059":1}}],["以任务为核心",{"2":{"1050":1}}],["以适应这100或101个参数",{"2":{"1086":1}}],["以适应不同的部署场景",{"2":{"1043":1}}],["以适应衣服的需要",{"2":{"296":1}}],["以某个概率存在或不存在于某个患者身上",{"2":{"1029":1}}],["以某种方式分割数据到多个设备上",{"2":{"831":1}}],["以作为真实概率的估计",{"2":{"1026":1}}],["以x",{"2":{"1018":1}}],["以x作为输入",{"2":{"737":1}}],["以其他格式存储的数据也可以通过类似的方式进行处理",{"2":{"1011":1}}],["以矩阵为例",{"2":{"995":1}}],["以得到该函数的梯度",{"2":{"983":1}}],["以后我们都将介绍到",{"2":{"1059":1}}],["以后无须重新定义就可以直接调用它们",{"2":{"981":1}}],["以后会在",{"2":{"605":1}}],["以建立计算图",{"2":{"974":1}}],["以步幅为1滑动卷积核窗口",{"2":{"968":1}}],["以类别预测为例",{"2":{"956":1}}],["以特征图的每个像素为中心",{"2":{"939":1}}],["以充分利用所有标记的数据",{"2":{"892":1}}],["以消除评估结果中的随机性",{"2":{"891":1}}],["以方便之后在维度1上的连结",{"2":{"956":1}}],["以方便读取",{"2":{"890":2}}],["以方便本章后面介绍的其他优化算法使用",{"2":{"80":1}}],["以标准化每个通道",{"2":{"872":3}}],["以检查其是否准确",{"2":{"858":1}}],["以生成列表l",{"2":{"854":1}}],["以生成最终的输出",{"2":{"385":1}}],["以同一像素为中心的锚框的数量",{"2":{"848":1}}],["以同一像素为中心的锚框的数量是n+m−1",{"2":{"848":1}}],["以同时获得覆盖性",{"2":{"319":1}}],["以每个像素为中心",{"2":{"847":1}}],["以使并行操作最多有两个步骤重叠",{"2":{"830":1}}],["以利于更精简的执行和更好的性能",{"2":{"821":1}}],["以太网交换机可能以高带宽连接40台服务器",{"2":{"812":1}}],["以太网旨在连接两个设备",{"2":{"812":1}}],["以太网",{"2":{"807":1,"812":1}}],["以保持前端和后端大致同步",{"2":{"793":1}}],["以保存交易历史记录并跟踪每个用户的动态",{"2":{"281":1}}],["以更新模型参数",{"2":{"784":1}}],["以更新x",{"2":{"113":1}}],["以文本序列",{"2":{"783":1}}],["以较低效率的方式",{"2":{"765":1}}],["以发现词内的公共符号",{"2":{"758":1}}],["以发现单词内的公共符号",{"2":{"757":1}}],["以产生另一个新符号",{"2":{"757":1}}],["以产生最终输出",{"2":{"380":1}}],["以将前缀和后缀与其他子词区分开来",{"2":{"756":1}}],["以将其合并到不同的网络架构中",{"2":{"444":1}}],["以单个文本作为输入",{"2":{"734":1}}],["以nltk为例",{"2":{"724":1}}],["以预测任务的标签",{"2":{"732":1}}],["以预测前提和假设之间的逻辑关系",{"2":{"673":1}}],["以预训练bert",{"2":{"719":1}}],["以获取双向循环神经网络",{"2":{"713":1}}],["以获得模型的最终损失函数",{"2":{"962":1}}],["以获得模型变量和参数之间的依赖关系",{"2":{"306":1}}],["以获得当前小批量的随机梯度",{"2":{"833":1}}],["以获得对深度学习效率更精确的洞察",{"2":{"793":1}}],["以获得逻辑关系的分类结果",{"2":{"676":1}}],["以获得假设的表示",{"2":{"674":1}}],["以获得一些注释",{"2":{"295":1}}],["以获得一个非常简化的表达式",{"2":{"94":1}}],["以获得更简洁的输出",{"2":{"847":1}}],["以获得更好的解构和重建质量",{"2":{"198":1}}],["以获得更稳定的下降方向",{"2":{"86":1}}],["以获得更高质量的代理来达到一个良好的局部最小值",{"2":{"71":1}}],["以w",{"2":{"708":1}}],["以显著提高测试精度",{"2":{"686":1}}],["以显示这两个模型的每个隐藏层中激活值的方差是如何随时间变化的",{"2":{"178":1}}],["以输出词元的标签",{"2":{"659":1}}],["以输出所有离散标签值的分布",{"2":{"657":1}}],["以备我们需要评估通过模型输出的概率",{"2":{"624":1}}],["以备将来在各种环境中使用",{"2":{"440":1}}],["以此类推",{"2":{"591":1}}],["以过滤掉损失中填充词元产生的不相关预测",{"2":{"575":1}}],["以返回其特征向量",{"2":{"573":1}}],["以计算输入门",{"2":{"553":1}}],["以长短期记忆网络模型为例",{"2":{"528":1}}],["以防在错误的环境中使用它们",{"2":{"523":1}}],["以实现不同的变体",{"2":{"505":1}}],["以本节开头提到的恒等映射作为我们希望学出的理想映射f",{"2":{"501":1}}],["以本节中的模型为例",{"2":{"178":1}}],["以允许更多的每像素非线性",{"2":{"497":1}}],["以减少总的运行时间",{"2":{"797":1}}],["以减少通道数",{"2":{"487":1}}],["以减少输出的高度和宽度",{"2":{"461":4}}],["以区分1000个不同类别的对象",{"2":{"456":1}}],["以表示更大的特征",{"2":{"455":1}}],["以训练分类器",{"2":{"454":1}}],["以避免对应的设备内存的型号不合适",{"2":{"811":1}}],["以避免数值下溢",{"2":{"811":1}}],["以避免误导自动微分机制",{"2":{"436":1}}],["以避免重复的下载",{"2":{"206":1}}],["以避免重复计算",{"2":{"165":1,"312":1}}],["以决定哪一种可能是表现良好的",{"2":{"353":1}}],["以技术角度来定义",{"2":{"338":1}}],["以观测角度来理解",{"2":{"338":1}}],["以ϵ1为例",{"2":{"316":1}}],["以探讨训练此类网络时可能遇到的问题",{"2":{"305":1}}],["以强化学习在国际象棋的应用为例",{"2":{"298":1}}],["以网络搜索为例",{"2":{"293":1}}],["以最小化损失函数",{"2":{"287":1}}],["以图像数据为例",{"2":{"284":1}}],["以降低学习到的模型的复杂度",{"2":{"279":1}}],["以评估最好的模型或比较一些模型效果",{"2":{"256":1}}],["以相同的方式使用了softmax符号来表示按行操作",{"2":{"232":1}}],["以加深对实现细节的了解",{"2":{"220":1}}],["以查看是否可以在提高性能的同时获得正确的结果",{"2":{"799":1}}],["以查看其他批量规范化的应用",{"2":{"477":1}}],["以查看数据中是否存在有意义的信息",{"2":{"210":1}}],["以查看它是否与实验结果一致",{"2":{"144":1}}],["以取得最大化的预期利益",{"2":{"199":1}}],["以p的概率将隐藏单元置为零时",{"2":{"171":1}}],["以上四张动图原创作者",{"2":{"1449":1}}],["以上便是字符切分阶段",{"2":{"1172":1}}],["以上便是文字侦测阶段",{"2":{"1172":1}}],["以上说的都是多类分类问题",{"2":{"1112":1}}],["以上面的神经网络为例",{"2":{"1100":1}}],["以上讲解的内容都是octave的基本操作",{"2":{"1088":1}}],["以上就是这门课的全部内容",{"2":{"1176":1}}],["以上就是为什么支持向量机最终会找到大间距分类器的原因",{"2":{"1145":1}}],["以上就是我们介绍的偏差和方差问题",{"2":{"1135":1}}],["以上就是无监督学习的视频内容",{"2":{"1061":1}}],["以上就是监督学习的内容",{"2":{"1060":1}}],["以上就是监督学习的例子",{"2":{"1060":1}}],["以上就是gpu设计决策中的两种策略",{"2":{"811":1}}],["以上也是概率论的公理",{"2":{"1027":1}}],["以上这些操作似乎都相当简单",{"2":{"843":1}}],["以上我们知道了如何定义简单的层",{"2":{"414":1}}],["以上例子清楚地说明了当我们试图预测更远的未来时",{"2":{"351":1}}],["以上模型可能完美无缺",{"2":{"295":1}}],["以上大多数问题都具有固定大小的输入和产生固定大小的输出",{"2":{"295":1}}],["以上只是简单的算法",{"2":{"294":1}}],["以上假设有时并不可取",{"2":{"290":1}}],["以上述简单网络为例",{"2":{"165":1}}],["以上所有的权重学习都将依赖于归纳偏置",{"2":{"155":1}}],["以便我们能够得到一个较低偏差的算法",{"2":{"1141":1}}],["以便我们在高级最优化步骤中的使用需要",{"2":{"1123":1}}],["以便我们可以运用我们的推断来实现更好的医疗服务",{"2":{"1029":1}}],["以便我们可以容易地从输出符号序列",{"2":{"757":1}}],["以便读者可以开始自己探索它",{"2":{"1025":1}}],["以便读者能够理解书中的大部分数学内容",{"2":{"987":1}}],["以便最小化相似项目之间的距离",{"2":{"1001":1}}],["以便放在同一个批量中",{"2":{"932":1}}],["以便更好地理解依赖关系图",{"2":{"790":1}}],["以便更灵活地处理此类信息",{"2":{"520":1}}],["以便于连结后输出",{"2":{"938":1}}],["以便于读取图像和应用图像增广",{"2":{"882":2}}],["以便于两个预训练任务",{"2":{"718":1}}],["以便于演示",{"2":{"686":1}}],["以便通道作为第2维",{"2":{"702":3}}],["以便后面任何不相关预测的计算都是与零的乘积",{"2":{"575":1}}],["以便以小批量的方式加载",{"2":{"570":1}}],["以便以相同形状的小批量进行加载",{"2":{"568":1}}],["以便用它在tf",{"2":{"502":1}}],["以便可以引用它的参数",{"2":{"437":3}}],["以便它可以在其他软件中执行",{"2":{"429":1}}],["以便在转换之后",{"2":{"1019":1}}],["以便在指定的gpu执行计算",{"2":{"837":1}}],["以便在需要产品级计算性能和部署时使用",{"2":{"818":3}}],["以便在服务器级cpu上进行深度学习",{"2":{"809":1}}],["以便在训练中加快速度",{"2":{"778":1}}],["以便在snli数据集上进行自然语言推断",{"2":{"685":1}}],["以便在模型预测期间随后使用",{"2":{"472":1}}],["以便在每个空间位置对值进行规范化",{"2":{"470":1}}],["以便在其他环境中复用它们",{"2":{"429":1}}],["以便在计算softmax时过滤掉超出指定范围的位置",{"2":{"368":1}}],["以便在计算∂l",{"2":{"312":1}}],["以便任何查询都只会与解码器中所有已经生成词元的位置",{"2":{"408":1}}],["以便",{"2":{"406":1}}],["以便残差连接满足x+sublayer",{"2":{"404":1}}],["以便同一组词元同时充当查询",{"2":{"395":1}}],["以便从宏观上了解注意力机制在实践中的运作方式",{"2":{"385":1}}],["以便其他轴的形状保持不变",{"2":{"369":1}}],["以便逐时间步更新小批量数据的隐状态h",{"2":{"332":1}}],["以便获得形状为",{"2":{"330":1}}],["以便稍后可以将其用作数据迭代器",{"2":{"321":1}}],["以便将其输入到定制的小规模输出网络中",{"2":{"905":1}}],["以便将其与mesh中的相关术语相关联",{"2":{"292":1}}],["以便将这种表示转换为输出",{"2":{"302":1}}],["以便与任何损失函数结合使用",{"2":{"278":1}}],["以便与输入数据进行互相关运算",{"2":{"120":1}}],["以便及早发现这些情况",{"2":{"179":1}}],["以便探测出在",{"2":{"157":1}}],["以前流行的网络使用小到1×1",{"2":{"486":1}}],["以前",{"2":{"155":1}}],["以在实际应用中平衡参数节约和模型有效性",{"2":{"642":1}}],["以在整个图像级别进行预测",{"2":{"152":1}}],["以在简单的设置中最小化目标函数的人",{"2":{"65":1}}],["以构建具有2个通道的输入",{"2":{"148":1}}],["以提高分类准确性",{"2":{"498":1}}],["以提高其准确性",{"2":{"139":1}}],["以提高深度学习模型的性能",{"2":{"65":1}}],["以ci个输入值转换为co个输出值",{"2":{"122":1}}],["以",{"2":{"120":1,"508":1,"908":1,"917":1,"944":1,"1548":1}}],["以模拟随机梯度下降",{"2":{"113":1}}],["以z表示的梯度下降变成",{"2":{"94":1}}],["以动态的方式来响应优化的进展情况",{"2":{"68":1}}],["以确定五个模块的在不同尺度下的较小值",{"2":{"959":1}}],["以确定输入的影响",{"2":{"619":1}}],["以确定哪个学习率η使f",{"2":{"62":1}}],["以确保你找到一个能很好实现这些算法的库",{"2":{"1111":1}}],["以确保它正常收敛",{"2":{"1110":1}}],["以确保我们永远不会尝试除以零",{"2":{"467":1}}],["以确保我们不会因除以零或步长过大而受到影响",{"2":{"107":1}}],["以确保在服务器电源被不小心断掉时",{"2":{"440":1}}],["以确保更新表达式看起来既漂亮又简单",{"2":{"270":1}}],["以确保梯度和参数可以得到很好的控制",{"2":{"249":1}}],["以确保其操作与我们期望的",{"2":{"136":1}}],["以确保可控",{"2":{"91":1}}],["以确保w不会增长太大",{"2":{"49":1}}],["以及四位用户",{"2":{"1191":1}}],["以及说说有关该算法你可以做的其他事情",{"2":{"1191":1}}],["以及标准公式",{"2":{"1185":1}}],["以及对特征进行一些小小的转换",{"2":{"1183":1}}],["以及特征的分布情况",{"2":{"1180":1}}],["以及特殊分隔词元",{"2":{"734":1}}],["以及大规模机器学习系统",{"2":{"1176":1}}],["以及当你只有一系列无标签数据",{"2":{"1176":1}}],["以及当前时间步的输入x3",{"2":{"312":1}}],["以及包裹要寄到哪里去",{"2":{"1168":1}}],["以及包含尽可能多的其他食物的",{"2":{"872":1}}],["以及k个参数向量θ",{"2":{"1148":1}}],["以及svm的假设函数将会学习什么",{"2":{"1143":1}}],["以及设定误差度量值的重要性",{"2":{"1139":1}}],["以及检验误差",{"2":{"1138":1}}],["以及学习率",{"2":{"1167":1}}],["以及学习曲线为代表的诊断法能够真正帮助你更有效率地应用机器学习",{"2":{"1135":1}}],["以及学习得到的预测函数",{"2":{"386":1}}],["以及诊断该问题的学习曲线方法",{"2":{"1135":1}}],["以及一个预测自信度的参数",{"2":{"1127":1}}],["以及一个通道",{"2":{"993":1}}],["以及一对多的方法",{"2":{"1112":1}}],["以及需要一种方法计算导数项",{"2":{"1111":1}}],["以及需要对循环神经网络分离梯度",{"2":{"306":1}}],["以及j",{"2":{"1111":1}}],["以及该值对应的索引",{"2":{"1090":1}}],["以及你的特征变量的数量",{"2":{"1085":1}}],["以及平方代价函数",{"2":{"1068":1}}],["以及梯度下降算法的更新过程有什么意义",{"2":{"1068":1}}],["以及什么样的假设对应的点",{"2":{"1066":2}}],["以及我们使用它的目的",{"2":{"1064":1}}],["以及我们计划最终如何处理模型的输出",{"2":{"179":1}}],["以及作为原型工具",{"2":{"1061":1}}],["以及作为序列处理流水线中的一个步骤对序列进行编码",{"2":{"522":1}}],["以及分别有哪些我们数据集中的顾客",{"2":{"1061":1}}],["以及步幅为2的2×2最大汇聚层组成",{"2":{"957":1}}],["以及10",{"2":{"938":1}}],["以及不同锚框之间的相似度",{"2":{"849":1}}],["以及再迁移到包含多个gpu的多个服务器时",{"2":{"840":1}}],["以及使用更多的gpu进行计算",{"2":{"830":2}}],["以及训练数据",{"2":{"801":1}}],["以及训练集的词表",{"2":{"669":1}}],["以及计算和通信的并行化内容",{"2":{"795":1}}],["以及正例和负例",{"2":{"778":1}}],["以及num",{"2":{"721":1}}],["以及它们的不可逆性",{"2":{"1086":1}}],["以及它们的标签",{"2":{"667":1}}],["以及它们如何指导我们去设计算法",{"2":{"800":1}}],["以及它们对应的标签y",{"2":{"633":1}}],["以及它旋转45度后的函数即f",{"2":{"31":1}}],["以及优化算法所需的超参数字典",{"2":{"594":2}}],["以及源语言和目标语言的两种词表",{"2":{"569":1}}],["以及序列的开始词元",{"2":{"567":1}}],["以及前缀",{"2":{"546":1}}],["以及应该何时重置隐状态",{"2":{"539":1}}],["以及矩阵连续乘积可以导致梯度消失或梯度爆炸的问题",{"2":{"538":1}}],["以及在哪里添加额外的非线性",{"2":{"526":1}}],["以及全连接层输出",{"2":{"502":1}}],["以及下一次它将对python调用加速",{"2":{"426":1}}],["以及为什么要选择特定的架构",{"2":{"519":1}}],["以及为什么我们使用它而不是自己定义一个python列表",{"2":{"424":3}}],["以及为挽救模型性能可能采取的措施",{"2":{"180":1}}],["以及利用gpu实现显著的加速",{"2":{"421":1}}],["以及如何确保学习算法的正常运行",{"2":{"1176":1}}],["以及如何利用它实现支持向量机的一些特性",{"2":{"1147":1}}],["以及如何得到大间距分类器",{"2":{"1145":1}}],["以及如何选择正则化参数",{"2":{"1143":1}}],["以及如何使用作业提交系统",{"2":{"1094":1}}],["以及如何使用序列的顺序作为补充信息",{"2":{"395":1}}],["以及如何定义和使用函数",{"2":{"1092":1}}],["以及如何构建",{"2":{"440":1}}],["以及如果标签偏移假设成立",{"2":{"192":1}}],["以及代表注意力汇聚的函数f",{"2":{"381":1}}],["以及代码共享",{"2":{"207":1}}],["以及公式ht=g",{"2":{"347":1}}],["以及单词之间的某种程度的相关性",{"2":{"342":1}}],["以及bh的偏置",{"2":{"340":1}}],["以及输出层的权重whq∈rh×q",{"2":{"340":1}}],["以及输出层权重w",{"2":{"232":1}}],["以及隐藏单元的数目为h",{"2":{"339":1}}],["以及其中任何给定的样本",{"2":{"334":1}}],["以及给定前面几个单词后出现某个单词的条件概率",{"2":{"316":1}}],["以及将这些词元可以视为一系列离散的观测",{"2":{"315":1}}],["以及最终时间步的隐状态h2",{"2":{"312":1}}],["以及相关的其它信息",{"2":{"1088":1}}],["以及相关的数学原理",{"2":{"306":1}}],["以及相应标签",{"2":{"208":1}}],["以及廉价计算",{"2":{"300":1}}],["以及",{"2":{"298":1,"303":1,"734":1}}],["以及工作头衔等等",{"2":{"183":1}}],["以及有关现代卷积网络架构的仔细讨论",{"2":{"134":1}}],["以及初始参数值与最优结果的距离",{"2":{"115":1}}],["以及l3缓存",{"2":{"77":1}}],["以及凸目标函数上非常简单的随机梯度下降算法的证明",{"2":{"65":1}}],["以及何时收敛到最小值",{"2":{"55":1}}],["以及f¯的",{"2":{"26":1}}],["以下表示数据为例",{"2":{"1085":1}}],["以下表达式是等价的",{"2":{"981":1}}],["以下bananasdataset类别将允许我们",{"2":{"932":1}}],["以下box",{"2":{"849":1}}],["以下超参数都是可调的",{"2":{"907":1}}],["以下内容不重新训练用于特征提取的预训练模型",{"2":{"905":1}}],["以下nms函数按降序对置信度进行排序并返回其索引",{"2":{"854":1}}],["以下列出维度为50",{"2":{"748":1}}],["以下函数将均匀地对任何输入图像中fmap",{"2":{"912":1}}],["以下函数将bert输入序列",{"2":{"721":1}}],["以下函数的输入num",{"2":{"726":1}}],["以下函数用于在数字标签索引及其文本名称之间进行转换",{"2":{"582":1}}],["以下代码创建一个形状为",{"2":{"1017":1}}],["以下代码可以验证",{"2":{"969":1}}],["以下代码",{"2":{"406":1}}],["以下attentiondecoder类定义了",{"2":{"375":1}}],["以下只是几个例子",{"2":{"297":1}}],["以下训练函数假定从高级api创建的模型作为输入",{"2":{"137":1}}],["以下对凸目标函数的随机梯度下降的收敛性分析是可选读的",{"2":{"115":1}}],["以下是一个使用",{"2":{"1048":1}}],["以下是一些典型例子",{"2":{"187":1}}],["以下是等价的",{"2":{"982":1}}],["以下是非极大值抑制的工作原理",{"2":{"854":1}}],["以下是训练数据集中前",{"2":{"582":1}}],["以下是纠正协变量偏移的典型算法",{"2":{"191":1}}],["以下是随着时间推移调整η时使用的一些基本策略",{"2":{"114":1}}],["以下是adadelta的技术细节",{"2":{"20":1}}],["以下等式成立",{"2":{"31":1}}],["但只作用于对象的顶层属性",{"2":{"1516":1}}],["但只对顶层属性进行响应式处理",{"2":{"1511":1}}],["但嵌套对象的属性不是",{"2":{"1512":1}}],["但根据数据生成的结构需要组件的使用者来决定",{"2":{"1508":1}}],["但torefs可以批量转换",{"2":{"1459":1}}],["但模板中不需要",{"2":{"1455":1}}],["但已成为业界标准",{"2":{"1395":1}}],["但随着业务增长",{"2":{"1355":1}}],["但随着我们应用许多连续卷积层",{"2":{"141":1}}],["但需要先用",{"2":{"1235":1}}],["但更灵活",{"2":{"1199":1}}],["但更重要的是",{"2":{"1059":1}}],["但从某些角度看",{"2":{"1178":1}}],["但从零开始实现可以确保我们真正知道自己在做什么",{"2":{"598":1}}],["但除了这些以外",{"2":{"1176":1}}],["但pca",{"2":{"1158":1}}],["但首先",{"2":{"1156":1}}],["但上述方法不适用",{"2":{"1147":1}}],["但仅仅是勉强分开",{"2":{"1144":1}}],["但仅靠它们还不足以开发出有大量参数的深层多通道多层卷积神经网络",{"2":{"454":1}}],["但事实上",{"2":{"1143":1}}],["但事实上只了解算法",{"2":{"1058":1}}],["但事实证明",{"2":{"1141":1}}],["但代价较大",{"2":{"1129":1}}],["但有时候获得更多的训练数据实际上并没有作用",{"2":{"1129":1}}],["但有一些关键区别",{"2":{"445":1}}],["但有一个主要区别",{"2":{"156":1}}],["但还是希望这段视频能有些许帮助",{"2":{"1122":1}}],["但若λ",{"2":{"1115":1}}],["但相应的预测的能力就可能变差",{"2":{"1114":1}}],["但相当缓慢",{"2":{"57":1}}],["但你想要代价函数找到这个最小值",{"2":{"1111":1}}],["但你能自动地找到数据中的结构吗",{"2":{"1061":1}}],["但hθ",{"2":{"1109":2}}],["但逻辑回归算法实际上是一种分类算法",{"2":{"1106":1}}],["但让我们用向量化的方式来实现",{"2":{"1093":1}}],["但换另一种方式来想想",{"2":{"1093":1}}],["但octave",{"2":{"1092":1}}],["但算法执行的流程是正确的",{"2":{"1086":1}}],["但即便如此",{"2":{"1122":1}}],["但即便只是大致猜测并计算它们",{"2":{"26":1}}],["但即使你没有理解正规方程和线性回归的关系",{"2":{"1086":1}}],["但就目前而言",{"2":{"1069":1}}],["但对你们中从未使用过octave这种编程环境的人",{"2":{"1061":1}}],["但对于支持向量机",{"2":{"1143":2}}],["但对于特征变量不止一个的这种一般情况",{"2":{"1130":1}}],["但对于这个特定的线性回归模型",{"2":{"1085":1}}],["但对于机器却可能是一个艰巨的挑战",{"2":{"1025":1}}],["但对于复杂的模型",{"2":{"973":1}}],["但对于深度学习中遇到的非凸问题",{"2":{"106":1}}],["但借助c++或java的话",{"2":{"1061":1}}],["但因为matlab的下标从1开始",{"2":{"1093":1}}],["但因为计算机有着足够的耐心",{"2":{"1059":1}}],["但因为他太菜了",{"2":{"1059":1}}],["但他们没有办法为百万用户",{"2":{"1058":1}}],["但我要提前说明一点的是",{"2":{"1129":1}}],["但我认为",{"2":{"1127":1}}],["但我在这节课中讲授神经网络的原因",{"2":{"1098":1}}],["但我可以用这个方法很方便地生成一个3行3列的矩阵",{"2":{"1090":1}}],["但我还是输入给你看",{"2":{"1089":1}}],["但我每个星期都跟直升机飞行员",{"2":{"1058":1}}],["但我们会在以后的视频提到它",{"2":{"1156":1}}],["但我们会尝试在下面简要概述常用的策略",{"2":{"69":1}}],["但我们已经知道",{"2":{"1130":1}}],["但我们刚刚讲的选择是对于大多数线性回归问题非常合理的",{"2":{"1064":1}}],["但我们没有提前知道是什么的细分市场",{"2":{"1061":1}}],["但我们没有采取措施来防止这点",{"2":{"631":1}}],["但我们仍然不知道怎么让机器做更有趣的事情",{"2":{"1058":1}}],["但我们仍然使用这个简单的函数来观察x的变化",{"2":{"54":1}}],["但我们选择了一些具有代表性的组合",{"2":{"663":1}}],["但我们在代码实现中有点草率",{"2":{"631":1}}],["但我们最终在计算交叉熵损失时会取它们的对数",{"2":{"624":1}}],["但我们很难找到一个有n个样本的真实数据集",{"2":{"610":1}}],["但我们不知道如何手动计算这么一种表示",{"2":{"230":1}}],["但我们希望揭示一些常见的问题",{"2":{"179":1}}],["但每行的加和不是",{"2":{"1035":1}}],["但每个解决方案仍然依赖于一个特定于任务的架构",{"2":{"732":1}}],["但密度不是0",{"2":{"1028":1}}],["但深度学习框架又比numpy的ndarray多一些重要功能",{"2":{"1016":1}}],["但稍后会看到",{"2":{"981":1}}],["但丢弃计算图中如何计算y的任何信息",{"2":{"976":1}}],["但输出通道数是x中通道数的转置卷积层g",{"2":{"971":1}}],["但输出通道数量是x中通道数的转置卷积层g",{"2":{"969":1}}],["但具有较大的感受野",{"2":{"953":1}}],["但并非所有图像都是这样",{"2":{"879":1}}],["但并不是所有的问题都存在解析解",{"2":{"612":1}}],["但并不方便",{"2":{"324":1}}],["但并不意味着我们应该尝试使用单隐藏层网络来解决所有问题",{"2":{"233":1}}],["但值低于阈值",{"2":{"853":1}}],["但iou低于预定义的阈值",{"2":{"853":1}}],["但计算代价较小使用较大的神经网络",{"2":{"1135":1}}],["但计算复杂性很容易过高",{"2":{"848":1}}],["但计算量最大",{"2":{"516":1}}],["但gpu擅长的高带宽突发读取操作并不适合稀疏的矩阵和向量的访问模式",{"2":{"811":1}}],["但同时",{"2":{"810":1}}],["但基本功能都是标准的",{"2":{"808":1}}],["但增加本地cpu以后还将提高少许性能",{"2":{"795":1}}],["但巨大的时间差距表明一定还有其他原因",{"2":{"790":2}}],["但最终的结果可能并不是最优解",{"2":{"1124":1}}],["但最终它必须在类中选择一个",{"2":{"634":1}}],["但最好是用比它更高级的算法",{"2":{"1111":1}}],["但最大时间汇聚层给出了一个连结的9维向量",{"2":{"701":1}}],["但softmax回归的输出仍然由输入特征的仿射变换决定",{"2":{"643":1}}],["但精度通常是我们最关心的性能衡量标准",{"2":{"634":1}}],["但精度相对较低",{"2":{"516":1}}],["但几个世纪以来",{"2":{"619":1}}],["但却不能在有限的步数内非常精确地达到最小值",{"2":{"613":1}}],["但却没有经常更新",{"2":{"187":1}}],["但解析解对问题的限制很严格",{"2":{"612":1}}],["但注意不要在初始化参数之前尝试访问参数",{"2":{"596":2}}],["但作为基准数据集过于简单",{"2":{"581":1}}],["但其实它就是在电脑屏幕上创造让人惊叹的视觉体验",{"2":{"1532":1}}],["但其实推断这个词有些用词不当",{"2":{"614":1}}],["但其元素值并没有变",{"2":{"1017":1}}],["但其计算量o",{"2":{"514":1}}],["但其效能并不比传统方法高",{"2":{"284":1}}],["但resnet架构更简单",{"2":{"502":1}}],["但f6却离的更远了",{"2":{"500":1}}],["但f的",{"2":{"26":1}}],["但通常我们还是对向量使用",{"2":{"1089":1}}],["但通常我们不会那么幸运",{"2":{"500":1}}],["但通常看上面这样的图表更好",{"2":{"1083":1}}],["但通过随机梯度下降优化的神经网络可以完美地标记训练集中的每一幅图像",{"2":{"169":1}}],["但给我们带来了更好的效果",{"2":{"492":1}}],["但留下了一个有待后续挖掘的问题",{"2":{"475":1}}],["但学习算法最常用两个类型就是监督学习",{"2":{"1059":1}}],["但学习算法并不总是考虑到这一细节",{"2":{"294":1}}],["但学术界花了很多年才接受深度学习这一概念",{"2":{"464":1}}],["但使用数据所遍历出来的结构由app组件决定",{"2":{"1508":1}}],["但使用数据和神经网络编程的核心思想已经研究了几个世纪",{"2":{"299":1}}],["但使用特定于任务的架构",{"2":{"733":1,"739":1}}],["但使用了更多的卷积层和更多的参数来拟合大规模的imagenet数据集",{"2":{"464":1}}],["但也存在显著差异",{"2":{"458":1}}],["但可以通过将特征进行组合的方法来解决",{"2":{"1184":1}}],["但可以使用16个gpu核代替",{"2":{"457":1}}],["但可能你即使看了这段视频",{"2":{"1122":1}}],["但可能效率不高",{"2":{"816":1}}],["但可能有许多更好的策略从未尝试过的",{"2":{"298":1}}],["但庞大的核心数量使gpu比cpu快几个数量级",{"2":{"457":1}}],["但卷积神经网络并没有主导这些领域",{"2":{"454":1}}],["但",{"2":{"422":1,"741":1,"980":1,"1394":1}}],["但后面的高级模型章节在很大程度上依赖于本章的知识",{"2":{"421":1}}],["但权重为空",{"2":{"418":1}}],["但正如本书后面将提及的那样",{"2":{"409":1}}],["但层规范化是基于特征维度进行规范化",{"2":{"406":1}}],["但现在用得不太多",{"2":{"1141":1}}],["但现在只要记住表达式x∈r是表示x是一个实值标量的正式形式",{"2":{"989":1}}],["但现在我们暂时只把每个像素位置看作一个特征",{"2":{"630":1}}],["但现在它已经被广泛用于测量许多应用的输出序列的质量",{"2":{"578":1}}],["但现在已经推广到各种现代的深度学习中",{"2":{"403":1}}],["但现实是验证数据和测试数据之间的边界模糊得令人担忧",{"2":{"256":1}}],["但现实是测试数据很少在使用一次后被丢弃",{"2":{"256":1}}],["但受此启发",{"2":{"388":1}}],["但由于两者的hθ",{"2":{"1117":1}}],["但由于假设的定义发生了变化",{"2":{"1110":1}}],["但由于各种原因",{"2":{"1098":1}}],["但由于隔得久了",{"2":{"1070":1}}],["但由于某种原因",{"2":{"976":1}}],["但由于不同的网络架构和超参数选择",{"2":{"492":1}}],["但由于本例子中每个键都是相同的",{"2":{"369":1}}],["但由于st的累加效果使学习率不断衰减",{"2":{"27":1}}],["但足够我们小试牛刀",{"2":{"361":1}}],["但足以说明要义",{"2":{"67":1}}],["但咖啡杯是红色的",{"2":{"355":1}}],["但超过这个跨度的任何预测几乎都是无用的",{"2":{"351":1}}],["但超过这一点",{"2":{"351":1}}],["但该模型已经能够捕捉到跟在后面的是哪类单词",{"2":{"342":1}}],["但很可能是由于多种因素在实践中并不比常规截断更好",{"2":{"311":1}}],["但当我看着他们所忙碌的事情时",{"2":{"1059":1}}],["但当调用向量的反向计算时",{"2":{"975":1}}],["但当控制流",{"2":{"426":1}}],["但当t很大时这个链就会变得很长",{"2":{"307":1}}],["但当这个模型面对从未见过的例子时",{"2":{"252":1}}],["但令人眼花缭乱的算法和应用程序集让人很难评估深度学习的具体成分是什么",{"2":{"302":1}}],["但设计的基础是规则",{"2":{"301":1}}],["但缺点是资源开销大",{"2":{"1353":1}}],["但缺点是",{"2":{"297":1}}],["但以下特殊情况值得一提",{"2":{"295":1}}],["但三星级却明显很少",{"2":{"294":1}}],["但单纯用它作为预测模型仍存在一些缺陷",{"2":{"294":1}}],["但单独出现则不表示垃圾邮件",{"2":{"169":1}}],["但本节中的一些设计原则和实现细节也适用于其他模型",{"2":{"952":1}}],["但本书中的其他模型却没有",{"2":{"604":1}}],["但本书中关注的问题超出了经典方法的极限",{"2":{"285":1}}],["但本书在这里使用的是fashion",{"2":{"462":1}}],["但本质上",{"2":{"99":1}}],["但如果你使用的是线性回归",{"2":{"1106":1}}],["但如果我载入",{"2":{"1089":1}}],["但如果照此操作",{"2":{"842":1}}],["但如果每个新博客就需要工程师花一个月的时间重新开始编写网页",{"2":{"591":1}}],["但如果把响尾蛇误认为是乌梢蛇可能会是致命的",{"2":{"291":1}}],["但如果模型将狮子狗与恐龙混淆",{"2":{"291":1}}],["但如果模型所有的按钮",{"2":{"282":1}}],["但如果这偏置与现实不符时",{"2":{"155":1}}],["但测试误差减小",{"2":{"277":1}}],["但测试误差没有减少",{"2":{"276":1}}],["但测试损失仍然很高",{"2":{"266":1}}],["但这里我所说的意思是",{"2":{"1143":1}}],["但这样做的确是把时间用在了刀刃上",{"2":{"1129":1}}],["但这样在形式上稍微简单一些",{"2":{"611":1}}],["但这并不总是一个好主意",{"2":{"1086":1}}],["但这并不意味着本书中不涉及数学方面的内容",{"2":{"987":1}}],["但这个名字",{"2":{"1069":1}}],["但这个名字仍然存在",{"2":{"299":1}}],["但这也是分类问题",{"2":{"1060":1}}],["但这也适用于向量和超过2个维度的张量",{"2":{"1020":1}}],["但这两种情况之间有一个关键区别",{"2":{"1025":1}}],["但这一成本仍不能忽视",{"2":{"869":1}}],["但这对计算机来说并不是那么简单",{"2":{"295":1}}],["但这只是一个惯例",{"2":{"286":1}}],["但这种办法很局限",{"2":{"284":1}}],["但这种变化非常罕见",{"2":{"200":1}}],["但这可能成本很高",{"2":{"269":1}}],["但不包括λ",{"2":{"1143":1}}],["但不希望在屏幕上显示结果",{"2":{"1088":1}}],["但不要紧",{"2":{"1066":1}}],["但不一定要等到以后才执行",{"2":{"789":1}}],["但不是所有的预测都是回归问题",{"2":{"608":1}}],["但不是唯一的",{"2":{"518":1}}],["但不会进行预测",{"2":{"333":1}}],["但不能反过来",{"2":{"349":1}}],["但不能应对梯度消失",{"2":{"336":1}}],["但不能推广到测试集时",{"2":{"286":1}}],["但不能过于随意地使用它",{"2":{"267":1}}],["但不完全是",{"2":{"59":1}}],["但泛化误差会增大",{"2":{"254":1}}],["但xavier初始化方法在实践中被证明是有效的",{"2":{"247":1}}],["但暂退法正则化可以",{"2":{"244":1}}],["但实例数量仍然不到imagenet中的十分之一",{"2":{"869":1}}],["但实际中的执行可能会非常慢",{"2":{"613":1}}],["但实际上它们只能说明了一部分故事",{"2":{"802":1}}],["但实际上",{"2":{"233":1}}],["但实验中随机梯度下降的一个迭代轮数耗时更多",{"2":{"80":1}}],["但k折交叉验证的误差要高得多",{"2":{"212":1}}],["但线性模型提供了一种健全性检查",{"2":{"210":1}}],["但一个滤波器通常只能改变照片的某个方面",{"2":{"916":1}}],["但一个客观的平台有巨大的价值",{"2":{"207":1}}],["但一般情况下不需要这样",{"2":{"50":1}}],["但类别条件分布保持不变",{"2":{"192":1}}],["但圣诞节过后很久还会继续推荐圣诞帽",{"2":{"187":1}}],["但应用在一辆真正的汽车里真是一场灾难",{"2":{"186":1}}],["但标签函数",{"2":{"181":1}}],["但标签全部翻转",{"2":{"180":1}}],["但依旧获得高效用的模型",{"2":{"159":1}}],["但mxnet和pytorch的结果从数值上是相同的",{"2":{"148":1}}],["但与深度的多层感知机相比",{"2":{"137":1}}],["但与梯度下降相比",{"2":{"80":1}}],["但没有指定后续层的尺寸",{"2":{"420":1}}],["但没有指定输入维度",{"2":{"417":1}}],["但没有具体的自动化方法",{"2":{"304":1}}],["但没有解释它为什么起作用",{"2":{"112":1}}],["但没有人告诉你",{"2":{"83":1}}],["但整体来看解的质量更差了",{"2":{"87":1}}],["但在setup中不能访问到vue2的配置",{"2":{"1453":1}}],["但在一些方面又有所不同",{"2":{"1141":1}}],["但在一个老虎机问题中",{"2":{"197":1}}],["但在表示表格数据集的矩阵中",{"2":{"992":1}}],["但在此数据集上训练的模型可能会提取更通用的图像特征",{"2":{"869":1}}],["但在实际应用中",{"2":{"743":1}}],["但在使用传统机器学习方法时",{"2":{"454":1}}],["但在云中很容易获得",{"2":{"445":1}}],["但在自然语言处理任务中",{"2":{"406":1}}],["但在自然浏览过程中不太可能遇到的产品",{"2":{"281":1}}],["但在下面我们使用一个简单的代码来说明一下",{"2":{"340":1}}],["但在这个列表最顶部就是机器学习的技能",{"2":{"1058":1}}],["但在这个方向上已经取得了很好的进展",{"2":{"301":1}}],["但在这里可能不是一个好的选择",{"2":{"742":1}}],["但在这里这样做是为了有效使用alexnet架构",{"2":{"462":1}}],["但在这里仅解释它们的功能",{"2":{"70":1}}],["但在强化学习中",{"2":{"298":1}}],["但在大多数情况下",{"2":{"281":1}}],["但在我们认为x导致y的情况下",{"2":{"181":1}}],["但在x2方向将会发散",{"2":{"87":1}}],["但要承受在x1方向的缓慢收敛",{"2":{"87":1}}],["但要比o",{"2":{"66":1}}],["但按随机顺序",{"2":{"82":1}}],["但请注意",{"2":{"72":1,"793":1}}],["但它也让我们加快我们的学习算法",{"2":{"1156":1}}],["但它也被广泛用于自然语言处理",{"2":{"698":1}}],["但它证明了",{"2":{"1061":1}}],["但它仍然显著提高我们的预测概率",{"2":{"1035":1}}],["但它仍然比不使用要好得多",{"2":{"61":1}}],["但它在40×40像素上变得具有挑战性",{"2":{"1025":1}}],["但它要求每张图像含有相同数量的边界框",{"2":{"932":1}}],["但它提供的带宽和延迟相对一般",{"2":{"812":1}}],["但它不是每个人都买得起的",{"2":{"1088":1}}],["但它不能显式地建模文本对之间的逻辑关系",{"2":{"737":1}}],["但它不携带任何用于预测的信息",{"2":{"208":1}}],["但它很难吸引这本书的大多数读者",{"2":{"718":1}}],["但它的通用性和易用性",{"2":{"1305":1}}],["但它的速度很慢",{"2":{"937":1}}],["但它的安装成本非常低",{"2":{"812":1}}],["但它的执行效率很低",{"2":{"600":1}}],["但它的奇特之处在于它不依赖于实际的查询",{"2":{"293":1}}],["但它有助于我们思考为什么要使用深度学习",{"2":{"519":1}}],["但它没有提供一个通用的模板来指导后续的研究人员设计新的网络",{"2":{"506":1}}],["但它是实现深度模型的基础",{"2":{"623":1}}],["但它是从浅层网络到深层网络的关键一步",{"2":{"464":1}}],["但它是众多有效的技术之一",{"2":{"334":1}}],["但它",{"2":{"284":1}}],["但它会记住",{"2":{"198":1}}],["但它们通常不是一个好的选择",{"2":{"781":1}}],["但它们之间仅有一点差距",{"2":{"258":1}}],["但它们不是线性相关的",{"2":{"230":1}}],["但它们在20世纪90年代还没有出现",{"2":{"136":1}}],["但它们为如何设计高级优化算法提供了有用的思维直觉",{"2":{"58":1}}],["但它需要我们存储额外的状态向量",{"2":{"96":1}}],["但了解它是理解下一节随机梯度下降算法的关键",{"2":{"53":1}}],["但是其p",{"2":{"1184":1}}],["但是最好还是将数据转换成高斯分布",{"2":{"1183":1}}],["但是最近",{"2":{"1098":1}}],["但是通常我们不需要这样做便能有非常好的效果了",{"2":{"1167":1}}],["但是通常更加重要的是",{"2":{"1148":1}}],["但是通过推荐系统",{"2":{"1187":1}}],["但是通过一个量化的数值评估",{"2":{"1138":1}}],["但是通过一个库来做内积",{"2":{"1093":1}}],["但是通过打响指",{"2":{"1098":1}}],["但是就如在之前的视频中看到的算法确实很重要",{"2":{"1148":1}}],["但是就如在之前的视频中我简单提到的",{"2":{"1148":1}}],["但是事实证明",{"2":{"1148":1}}],["但是根据你实现的情况",{"2":{"1148":1}}],["但是训练神经网络可能非常慢",{"2":{"1148":1}}],["但是训练出来的模型却不能很好地适应交叉验证集数据或测试集数据",{"2":{"1134":1}}],["但是你也需要做几件事",{"2":{"1148":1}}],["但是大多数支持向量机软件包都有内置的多类分类功能",{"2":{"1148":1}}],["但是真的有很多软件库可以用来做这件事儿",{"2":{"1148":1}}],["但是真正能提高性能的",{"2":{"1141":1}}],["但是听听这节课可能让你对支持向量机中的优化问题",{"2":{"1145":1}}],["但是实际上应用支持向量机的时候",{"2":{"1144":1}}],["但是多多少少这个看起来并不是非常自然是么",{"2":{"1144":1}}],["但是让我们看一下",{"2":{"1144":1}}],["但是也并不全是这样",{"2":{"1143":1}}],["但是也把它运行一遍",{"2":{"1138":1}}],["但是现在比较少用的算法",{"2":{"1141":1}}],["但是只是很快的得到的结果",{"2":{"1138":1}}],["但是我仍然不能完全确定",{"2":{"1148":1}}],["但是我稍后会讨论一点",{"2":{"1141":1}}],["但是我认为我们将要讲到的这些东西是非常有用的",{"2":{"1137":1}}],["但是我们的目标函数是希望找到一个参数θ",{"2":{"1145":1}}],["但是我们可以用这些数据作为给用户推荐电影的依据",{"2":{"1189":1}}],["但是我们可以在不改变目标的前提下",{"2":{"616":1}}],["但是我们可能会正则化的程度太高或太小了",{"2":{"1133":1}}],["但是我们需要为整个训练集计算误差单元",{"2":{"1121":1}}],["但是我们仍然受到这些原始特征的限制",{"2":{"1101":1}}],["但是我们通常又把房价看成实数",{"2":{"1060":1}}],["但是我们怎样才能利用这个权重参数",{"2":{"876":1}}],["但是我们没有讨论如何真正实现深度学习训练的并行化",{"2":{"831":1}}],["但是我们将在这个函数的作用域内重新创建它们",{"2":{"502":1}}],["但是我们应该如何精确地测量一个函数和零之间的距离呢",{"2":{"270":1}}],["但是我们之前的线性模型已经能够表示任何仿射函数",{"2":{"232":1}}],["但是我们不能预先假设任何与特征交互相关的先验结构",{"2":{"151":1}}],["但是随着svm的复杂度增加",{"2":{"1148":1}}],["但是随着",{"2":{"1132":1}}],["但是适应训练数据集并不代表着能推广至一般情况",{"2":{"1131":1}}],["但是知道",{"2":{"1117":1}}],["但是减少参数的大小",{"2":{"1114":1}}],["但是可能无法站到那个最小值的那一点",{"2":{"1165":1}}],["但是可能会不能推广到新的数据",{"2":{"1114":1}}],["但是可以说明的是",{"2":{"1145":1}}],["但是可以通过正则化手段来调整而更加适应数据",{"2":{"1135":1}}],["但是可以证明我们所选的代价值函数会给我们一个凸优化问题",{"2":{"1109":1}}],["但是问题在于",{"2":{"1109":1}}],["但是首先让我告诉你一个",{"2":{"1092":1}}],["但是平方误差代价函数可能是解决回归问题最常用的手段了",{"2":{"1064":1}}],["但是代码中使用torch而不是pytorch",{"2":{"1017":1}}],["但是将其",{"2":{"874":1}}],["但是将该系统部署到真实世界中",{"2":{"188":1}}],["但是当你实践一个非常简单即便不完美的方法时",{"2":{"1138":1}}],["但是当将它们应用到某些特定的机器学习应用时",{"2":{"1114":1}}],["但是当我们考虑多台机器时",{"2":{"843":1}}],["但是当数据分布突然改变时",{"2":{"179":1}}],["但是每个gpu都将独立地维护一组完整的模型参数",{"2":{"833":1}}],["但是执行着相同类型的工作",{"2":{"832":1}}],["但是xla可以使某些大规模的线性代数的运算速度更快",{"2":{"819":1}}],["但是无法对磁盘加速",{"2":{"804":1}}],["但是使用方便且代码简洁",{"2":{"837":1}}],["但是使用全局语料库统计",{"2":{"741":1}}],["但是使用tanh函数作为激活函数",{"2":{"554":1}}],["但是从左到右编码上下文",{"2":{"733":1,"739":1}}],["但是整个序列由双向循环神经网络",{"2":{"713":1}}],["但是一旦你精通了线性回归",{"2":{"1117":1}}],["但是一旦我们接近极小值",{"2":{"60":1}}],["但是一般的分类问题并不与类别之间的自然顺序有关",{"2":{"640":1}}],["但是对数底为e而不是2",{"2":{"650":1}}],["但是对像深度神经网络这样复杂的模型来说",{"2":{"613":1}}],["但是对于神经网络来说是不可行的",{"2":{"1125":1}}],["但是对于某些线性回归问题",{"2":{"1085":1}}],["但是对于当今各种各样的序列学习问题",{"2":{"550":1}}],["但是对于深度神经网络而言",{"2":{"59":1}}],["但是由于以后几乎所有的模型都是多层的",{"2":{"591":1}}],["但是仍需要通过设计更复杂的序列模型来进一步处理它",{"2":{"550":1}}],["但是返回一个维度为256的输出",{"2":{"423":1}}],["但是返回一个维度256的输出",{"2":{"423":1}}],["但是跳过了它们工作的细节",{"2":{"421":1}}],["但是框架仍是按顺序初始化的",{"2":{"418":1}}],["但是因为其计算复杂度是关于序列长度的二次方",{"2":{"397":1,"401":1}}],["但是点积操作要求查询和键具有相同的长度d",{"2":{"370":1}}],["但是序列本身的动力学不会改变",{"2":{"347":1}}],["但是并不方便",{"2":{"335":1}}],["但是不生成任何输出",{"2":{"333":1}}],["但是想根据上下文调整这类模型其实是相当困难的",{"2":{"316":1}}],["但是这些是实际的问题",{"2":{"1168":1}}],["但是这些讨论也适应于其他序列模型",{"2":{"527":1}}],["但是这样的算法存在的问题是",{"2":{"1165":1}}],["但是这一项是影响整个总代价函数中的这一项的",{"2":{"1143":1}}],["但是这里的hθ",{"2":{"1109":1}}],["但是这里有一个应该注意到的细节",{"2":{"592":2}}],["但是这很容易通过语言模型来解决",{"2":{"315":1}}],["但是这次我们将其一次性分为64列的",{"2":{"78":1}}],["但是会截断序列",{"2":{"310":1}}],["但是输入和输出的数量以及相应序列的顺序大都不会相同",{"2":{"295":1}}],["但是很多问题并非如此",{"2":{"291":1}}],["但是模型应该如何平衡这个新的额外惩罚的损失",{"2":{"270":1}}],["但是如果k较大",{"2":{"1153":1}}],["但是如果你有一个非常好的svm实现包",{"2":{"1148":1}}],["但是如果你对这些概念仍有些许的不确定",{"2":{"1070":1}}],["但是如果",{"2":{"1145":1}}],["但是如果c",{"2":{"1144":1}}],["但是如果训练集比参数的数量还大",{"2":{"1141":1}}],["但是如果算法得到的值远大于1或者远小于0的话",{"2":{"1106":1}}],["但是如果我们想保存整个模型",{"2":{"442":1}}],["但是如果我们很少得到大的梯度呢",{"2":{"334":1}}],["但是如果我们过拟合了测试数据",{"2":{"256":1}}],["但是如果输入是连续的",{"2":{"295":1}}],["但是如果图像数据来自互联网",{"2":{"284":1}}],["但是如果它执行地",{"2":{"253":1}}],["但是本节应用于隐藏层的激活函数通常不仅按行操作",{"2":{"232":1}}],["但是它们仍然会有一些慢",{"2":{"1148":1}}],["但是它对于理解支持向量机是有益的",{"2":{"1144":1}}],["但是它被看成一个3行4列的矩阵",{"2":{"1017":1}}],["但是它在测试数据上失败了",{"2":{"188":1}}],["但是它并非没有问题",{"2":{"32":1}}],["但是类别条件分布p",{"2":{"182":1}}],["但是测试数据将包含从不同分布pt",{"2":{"180":1}}],["但是在实际使用中",{"2":{"1179":1}}],["但是在实践中",{"2":{"887":1}}],["但是在其中一个算法应用的地方",{"2":{"1148":1}}],["但是在神经网络中",{"2":{"1120":1}}],["但是在一些学习问题中",{"2":{"1060":1}}],["但是在对下一个词元进行预测的情况中",{"2":{"522":1}}],["但是在更大",{"2":{"454":1}}],["但是在设备",{"2":{"450":1}}],["但是在数据集中却找不到",{"2":{"316":1}}],["但是在工业中",{"2":{"289":1}}],["但是在将预测结果上传到kaggle之后",{"2":{"208":1}}],["但是在眼花缭乱的场景中找到他也如大海捞针",{"2":{"152":1}}],["但是在单个坐标的层面上进行了调整",{"2":{"27":1}}],["但是到目前为止",{"2":{"119":1}}],["但是没有f",{"2":{"44":1}}],["但是请注意",{"2":{"44":1}}],["但是反向是不正确的",{"2":{"40":1}}],["但是直觉和洞察往往会延续",{"2":{"26":1}}],["但是",{"2":{"25":2,"65":1,"68":1,"99":1,"106":1,"110":1,"113":1,"114":1,"116":1,"117":1,"142":2,"152":1,"187":1,"229":1,"230":2,"251":1,"286":1,"404":1,"575":1,"591":1,"613":1,"624":1,"651":1,"656":1,"657":1,"754":1,"755":1,"819":1,"832":1,"841":1,"869":1,"875":1,"879":1,"934":1,"957":1,"962":1,"996":1,"1021":1,"1092":1,"1111":1,"1138":1,"1143":5,"1144":1,"1145":1,"1148":1,"1158":1,"1167":1,"1187":1}}],["使",{"2":{"1203":1}}],["使你感到困惑",{"2":{"1106":1}}],["使读者能够开始构建第一个深度学习模型",{"2":{"1025":1}}],["使f",{"2":{"979":1}}],["使它变为一个标量",{"2":{"995":1}}],["使它们在看到越来越多的数据时变得越来越好",{"2":{"980":1}}],["使它输出的高和宽较大",{"2":{"953":1}}],["使它的预测非常接近实际标签值",{"2":{"290":1}}],["使物体以不同的比例出现在图像的不同位置",{"2":{"879":1}}],["使图像各有50",{"2":{"879":1}}],["使感兴趣的对象出现在不同的位置",{"2":{"877":1}}],["使计算性能有良好的提升",{"2":{"832":1}}],["使计算机能够理解它们以提供帮助或基于人类语言做出决策变得至关重要",{"2":{"754":1}}],["使y^j为零",{"2":{"624":1}}],["使所有像素值介于0和1之间",{"2":{"584":1}}],["使之能够提供与隐马尔可夫模型类似的前瞻能力",{"2":{"520":1}}],["使通道数量减半",{"2":{"482":4}}],["使整个神经网络各层的中间输出值更加稳定",{"2":{"476":1}}],["使电脑游戏玩家受益",{"2":{"457":1}}],["使框架最终初始化参数",{"2":{"419":1}}],["使修改模型架构变得容易",{"2":{"419":1}}],["使多个头并行计算",{"2":{"382":1}}],["使人类得以生存和成功",{"2":{"379":1}}],["使人类的大脑能够更明智地分配资源来生存",{"2":{"354":1}}],["使大规模算力唾手可得",{"2":{"300":1}}],["使模型在这些样本中表现得更好",{"2":{"282":1}}],["使模型多元化",{"2":{"282":1}}],["使其永远不会变成响应式的",{"2":{"1519":1}}],["使其等于一个一行三列的n矩阵",{"2":{"1088":1}}],["使其能够访问实时数据",{"2":{"1040":1}}],["使其能处理更普遍的函数关系类型",{"2":{"231":1}}],["使其在风格上接近风格图像",{"2":{"916":1}}],["使其在给定上下文序列和单词的情况下",{"2":{"525":1}}],["使其获得分布更均匀且易于拟合的偏移量",{"2":{"852":1}}],["使其具有与x相同的num",{"2":{"574":4}}],["使其不会太复杂",{"2":{"479":1}}],["使其不会从计算图中分离隐状态",{"2":{"337":1}}],["使其平均值为0",{"2":{"467":1}}],["使其符号属性能够很好地匹配",{"2":{"296":1}}],["使其达到一个合适的平衡位置",{"2":{"269":1}}],["使其适应数据的变化",{"2":{"193":1}}],["使线性变得更合理",{"2":{"230":1}}],["使k=i+a",{"2":{"153":1}}],["使输出和输入具有相同的高度和宽度",{"2":{"141":1}}],["使输入和输出具有相同的高度和宽度",{"2":{"141":1}}],["使我们能够解决上面描述的梯度下降问题",{"2":{"88":1}}],["使得总的投射误差最小",{"2":{"1158":1}}],["使得第一项等于0",{"2":{"1144":1}}],["使得θtx",{"2":{"1144":1}}],["使得这里最小的u值仍为5",{"2":{"1143":1}}],["使得同一个实例的特征都在同一列里",{"2":{"1100":1}}],["使得返回值是多个值或多个参数",{"2":{"1092":1}}],["使得j",{"2":{"1068":1}}],["使得赋值",{"2":{"1068":1}}],["使得f",{"2":{"977":1}}],["使得命令可以快速地异步插入后端",{"2":{"793":1}}],["使得每个小批量序列将具有相同的形状",{"2":{"668":1}}],["使得每个gpu只负责存储和计算模型的一半参数",{"2":{"459":1}}],["使得最小化∑i",{"2":{"621":1}}],["使得在训练集上的损失达到最小",{"2":{"613":1}}],["使得根据模型做出的预测大体符合数据里的真实价格",{"2":{"610":1}}],["使得一切都得等待python完成",{"2":{"450":1}}],["使得隐状态的梯度计算总是限制在一个小批量数据的时间步内",{"2":{"335":1}}],["使得鉴别器",{"2":{"300":1}}],["使得",{"2":{"44":1,"46":1}}],["使得当x∈x满足0",{"2":{"44":1}}],["使每个坐标都可以单独解出",{"2":{"26":1}}],["使用简洁直观的模板语法",{"2":{"1527":1}}],["使用步骤",{"2":{"1523":1}}],["使用suspense包裹组件",{"2":{"1523":1}}],["使用storetorefs转换countstore",{"2":{"1492":1}}],["使用svg格式在jupyter中显示绘图",{"2":{"981":1}}],["使用countstore",{"2":{"1491":1}}],["使用children配置项",{"2":{"1479":1}}],["使用插件",{"2":{"1489":1}}],["使用原则",{"2":{"1458":1}}],["使用原始bert模型的配置",{"2":{"729":1}}],["使用泛型类",{"2":{"1432":1}}],["使用泛型接口",{"2":{"1431":1}}],["使用方式",{"2":{"1430":1}}],["使用示例",{"2":{"1416":1,"1431":1,"1434":1,"1435":1}}],["使用枚举",{"2":{"1413":1}}],["使用尖括号语法",{"2":{"1399":1}}],["使用文件",{"2":{"1349":1}}],["使用矩阵中定义的操作系统",{"2":{"1315":1}}],["使用矩阵乘法来实现卷积是否有效率",{"2":{"972":1}}],["使用环境配置安装",{"2":{"1277":1}}],["使用黑盒工具格式化",{"2":{"1264":1}}],["使用工具如",{"2":{"1259":1}}],["使用单引号或双引号括起",{"2":{"1216":1}}],["使用单词级词元化时的词表大小",{"2":{"570":1}}],["使用单词级词元化时",{"2":{"567":1}}],["使用内存缓存数据页",{"2":{"1201":1}}],["使用不同版本的在线学习机制算法",{"2":{"1168":1}}],["使用降维的方法将其降至2维",{"2":{"1157":1}}],["使用高斯核函数的支持向量机",{"2":{"1148":1}}],["使用高级api获得相同的结果",{"2":{"968":1}}],["使用高级api",{"2":{"561":1}}],["使用高级api实现可以加速训练",{"2":{"327":1}}],["使用高级api训练模型",{"2":{"326":1}}],["使用支持向量机",{"0":{"1148":1},"2":{"1193":1}}],["使用我们之前的方法",{"2":{"1145":1}}],["使用训练集训练出12个不同程度正则化的模型",{"2":{"1133":1}}],["使用训练集训练出10个模型",{"2":{"1131":1}}],["使用训练好的模型",{"2":{"770":1}}],["使用60",{"2":{"1131":1}}],["使用优化算法来最小化代价函数",{"2":{"1126":1}}],["使用梯度下降算法最小化代价函数",{"2":{"1189":1}}],["使用梯度下降算法时",{"2":{"1124":1}}],["使用梯度下降法迭代x共10次",{"2":{"54":1}}],["使用得相当频繁",{"2":{"1111":1}}],["使用时我们需要提供代价函数和每个参数的求导",{"2":{"1109":1}}],["使用时间动力学可以得到更准确的电影推荐",{"2":{"345":1}}],["使用时间t−1时更新的权重t−1",{"2":{"86":1}}],["使用非线性的多项式项",{"2":{"1097":1}}],["使用非极大值抑制",{"2":{"939":1}}],["使用非极大值抑制来预测边界框",{"2":{"854":3}}],["使用非极大值抑制预测边界框",{"0":{"854":1}}],["使用双",{"2":{"1088":1}}],["使用双线性插值",{"2":{"940":1}}],["使用octave你能快速地实现你的算法",{"2":{"1088":1}}],["使用的",{"2":{"1044":1}}],["使用友元图来展示这些情况",{"2":{"1038":1}}],["使用条件概率的定义",{"2":{"1032":1}}],["使用zeros",{"2":{"1021":2}}],["使用全0",{"2":{"1017":1}}],["使用全连接层将连结后的向量转换为输出类别",{"2":{"701":1}}],["使用全连接层的情况",{"2":{"472":3}}],["使用过python中numpy计算包的读者会对本部分很熟悉",{"2":{"1016":1}}],["使用过多则会过于复杂化模型",{"2":{"481":1}}],["使用其他方法评估目标检测模型",{"2":{"966":1}}],["使用其他超参数组合训练模型",{"2":{"684":1}}],["使用下面的multibox",{"2":{"964":1}}],["使用锚框中心单元长度为c的特征",{"2":{"939":1}}],["使用填充为1的3×3的卷积层变换卷积神经网络的输出",{"2":{"939":1}}],["使用填充为2来使得输入与输出的高和宽一致",{"2":{"461":4}}],["使用图像增广中的随机裁剪",{"2":{"946":1}}],["使用图像增广来训练模型",{"2":{"883":1}}],["使用图像增广进行训练",{"0":{"882":1},"1":{"883":1}}],["使用多元高斯分布进行异常检测",{"0":{"1185":1},"2":{"1193":1}}],["使用多gpu对模型进行训练和评估",{"2":{"883":1}}],["使用多个gpu计算数据集上模型的精度",{"2":{"827":1}}],["使用较小的神经网络",{"2":{"1135":1}}],["使用较小的学习率",{"2":{"874":1}}],["使用较好的",{"2":{"1093":1}}],["使用较大的预训练词向量",{"2":{"717":1}}],["使用requirements",{"2":{"1269":1}}],["使用relu的原因是",{"2":{"235":1}}],["使用rgb通道的均值和标准差",{"2":{"872":3}}],["使用在imagenet数据集上预训练的resnet",{"2":{"862":1}}],["使用在大规模语料库上预训练的文本表示可以减少模型的过拟合",{"2":{"712":1}}],["使用上面定义的multibox",{"2":{"853":1}}],["使用真实边界框来标记锚框的类别",{"2":{"852":3}}],["使用真实边界框标记锚框",{"2":{"852":3}}],["使用真实数据时",{"2":{"467":1}}],["使用调试器跟踪调试寻找性能的瓶颈",{"2":{"814":1}}],["使用闪存持久地存储信息",{"2":{"805":1}}],["使用诸如nvidia的nsight之类的调试器来验证代码是否有效",{"2":{"799":1}}],["使用加载的glove向量",{"2":{"749":1}}],["使用变量pij",{"2":{"743":1}}],["使用这些特征训练出了每一个用户的参数",{"2":{"1189":1}}],["使用这样一个简单的基于反向传播的神经网络",{"2":{"1127":1}}],["使用这样的全局语料库统计",{"2":{"742":1}}],["使用这种系统就能让你我在几十分钟里就学会用我们的舌头",{"2":{"1098":1}}],["使用这两组数据训练的分类器似乎工作得很好",{"2":{"186":1}}],["使用输入tokens的bertencoder的前向推断返回编码结果",{"2":{"734":1}}],["使用了2层",{"2":{"726":1}}],["使用20",{"2":{"1131":1}}],["使用2个gpu进行训练",{"2":{"828":1}}],["使用24层",{"2":{"726":1}}],["使用2×2最大汇聚层",{"2":{"146":1}}],["使用1×1卷积层将输出通道数转换为pascal",{"2":{"862":1}}],["使用12层",{"2":{"726":1}}],["使用1000个隐藏单元的隐藏层也可能不足以学习到良好的图像特征",{"2":{"151":1}}],["使用循环神经网络表示单个文本",{"0":{"713":1}}],["使用循环神经网络",{"0":{"712":1},"1":{"713":1,"714":1,"715":1,"716":1,"717":1}}],["使用循环神经网络编码器最终的隐状态来初始化解码器的隐状态",{"2":{"572":1}}],["使用分层softmax的每个训练步的计算代价显著降低",{"2":{"709":1}}],["使用二进制存储",{"2":{"1197":1}}],["使用二叉树",{"2":{"709":1}}],["使用二维卷积层的情况",{"2":{"472":3}}],["使用一种工具像octave来做第一步的学习算法的原型搭建",{"2":{"1061":1}}],["使用一维卷积和最大时间汇聚",{"2":{"701":1}}],["使用一个或两个以上的特征量",{"2":{"1093":1}}],["使用一个像octave或matlab的工具",{"2":{"1061":1}}],["使用一个函数f来描述循环神经网络的循环层所做的变换",{"2":{"573":1}}],["使用一个相当简单的架构训练模型",{"2":{"350":1}}],["使用一个代理来表示黑塞矩阵",{"2":{"26":1}}],["使用卷积神经网络对每个提议区域执行前向传播以抽取其特征",{"2":{"941":1}}],["使用卷积神经网络",{"0":{"698":1},"1":{"699":1,"700":1,"701":1,"702":1,"703":1,"704":1,"705":1,"706":1}}],["使用4个进程",{"2":{"687":3}}],["使用4个进程来读取数据",{"2":{"583":3}}],["使用模型",{"0":{"682":1}}],["使用模型的输出作为相应标签的预测",{"2":{"289":1}}],["使用mitt代替",{"2":{"1496":1}}],["使用mlp",{"2":{"672":1}}],["使用mujoco",{"2":{"300":1}}],["使用注意力",{"0":{"672":1},"1":{"673":1,"674":1,"675":1,"676":1,"677":1,"678":1,"679":1,"680":1,"681":1,"682":1,"683":1,"684":1}}],["使用lambda函数捕获参数",{"2":{"635":1}}],["使用l2范数的一个原因是它对权重向量的大分量施加了巨大的惩罚",{"2":{"270":1}}],["使用定制的优化器和损失函数",{"2":{"635":2}}],["使用y作为y",{"2":{"633":1}}],["使用exp",{"2":{"631":1}}],["使用深度学习框架的高级api",{"2":{"627":1}}],["使用学习率为0",{"2":{"625":1}}],["使用参数的梯度更新参数",{"2":{"605":4}}],["使用从数据集中随机抽取的一个小批量",{"2":{"604":1}}],["使用框架的预定义好的层",{"2":{"591":1}}],["使用defineexpose将组件中的数据交给外部",{"2":{"1468":1}}],["使用data",{"2":{"590":1}}],["使用dropout层来减轻过度拟合",{"2":{"461":1}}],["使用dropout层来减轻过拟合",{"2":{"461":3}}],["使用空格替换不间断空格",{"2":{"565":1}}],["使用小写字母",{"2":{"1215":1}}],["使用小写字母替换大写字母",{"2":{"565":2}}],["使用小批量矩阵乘法",{"2":{"391":1}}],["使用小批量矩阵乘法来计算小批量数据中的加权平均值",{"2":{"390":1}}],["使用小批量的决策的核心是计算效率",{"2":{"77":1}}],["使用按元素乘法",{"2":{"555":1}}],["使用来自序列两端的信息来估计输出",{"2":{"522":1}}],["使用块可以有效地设计复杂的网络",{"2":{"510":1}}],["使用块的想法首先出现在牛津大学的视觉几何组",{"2":{"506":1}}],["使用块的网络",{"0":{"506":1},"1":{"507":1,"508":1,"509":1,"510":1,"511":1}}],["使用块进行抽象的一个好处是可以将一些块组合成更大的组件",{"2":{"422":1}}],["使用重复块的网络",{"2":{"492":1}}],["使用标签平滑",{"2":{"491":1}}],["使用通道数为3的输入时",{"2":{"480":1}}],["使用相同超参数来训练模型",{"2":{"474":1}}],["使用批量规范化层的",{"0":{"473":1}}],["使用批量规范化的全连接层的输出的计算详情如下",{"2":{"469":1}}],["使用三个连续的卷积层和较小的卷积窗口",{"2":{"461":3}}],["使用三个连续的卷积层和一个较小的卷积窗口",{"2":{"461":1}}],["使用默认初始化方法",{"2":{"429":1}}],["使用tokenembedding",{"2":{"753":1}}],["使用tf",{"2":{"425":1}}],["使用transformer模型",{"2":{"409":1}}],["使用创建的常量参数以及relu和matmul函数",{"2":{"425":1}}],["使用创建的常量参数以及relu和mm函数",{"2":{"425":2}}],["使用创建的常量参数以及relu和dot函数",{"2":{"425":1}}],["使用googlenet的最小图像大小是多少",{"2":{"491":1}}],["使用get",{"2":{"425":1}}],["使用gpu计算模型在数据集上的精度",{"2":{"137":3}}],["使用net",{"2":{"418":1}}],["使用自动微分的一个好处是",{"2":{"977":1}}],["使用自然语言处理技术来处理和分析文本数据是非常常见的",{"2":{"754":1}}],["使用自定义层构建模型",{"2":{"414":1}}],["使用自定义层直接执行前向传播计算",{"2":{"414":1}}],["使用自注意力来设计深度架构是很有吸引力的",{"2":{"403":1}}],["使用残差连接和层规范化",{"2":{"406":1}}],["使用平方损失函数和随机梯度下降",{"2":{"392":1}}],["使用包含7个时间步的4个序列输入的小批量",{"2":{"375":1}}],["使用缩放的",{"2":{"371":1}}],["使用点积可以得到计算效率更高的评分函数",{"2":{"370":1}}],["使用广播方式进行求和",{"2":{"369":3}}],["使用广播的方式进行求和",{"2":{"369":1}}],["使用正弦函数和一些可加性噪声来生成序列数据",{"2":{"350":1}}],["使用动态规划可以沿着马尔可夫链精确地计算结果",{"2":{"348":1}}],["使用动量超参数和学习率的其他组合",{"2":{"97":1}}],["使用当前的和先前的字符预测下一个字符",{"2":{"341":1}}],["使用η",{"2":{"334":1}}],["使用张量来初始化隐状态",{"2":{"325":1}}],["使用顺序分区生成一个小批量子序列",{"2":{"321":3}}],["使用随机抽样生成一个小批量子序列",{"2":{"320":1}}],["使用和蒙特卡洛树抽样",{"2":{"301":1}}],["使用光学字符识别的邮件分拣系统从20世纪90年代开始部署",{"2":{"301":1}}],["使用链式法则产生",{"2":{"307":1}}],["使用链式法则得出",{"2":{"164":1}}],["使用链式规则",{"2":{"299":1}}],["使用数据集来选择参数的元程序被称为学习算法",{"2":{"282":1}}],["使用适当复杂度的模型之外",{"2":{"280":1}}],["使用验证集来找到最佳值λ",{"2":{"280":1}}],["使用权重衰减",{"0":{"277":1}}],["使用权重βi进行",{"2":{"191":1}}],["使用与",{"2":{"270":1}}],["使用与前向传播相同的推断",{"2":{"247":1}}],["使用线性代数的知识",{"2":{"1145":1}}],["使用线性代数",{"2":{"268":1}}],["使用以下三阶多项式来生成训练和测试数据的标签",{"2":{"262":1}}],["使用以下简单的恒等式来进行纠正",{"2":{"191":1}}],["使用provide提供数据",{"2":{"1503":1}}],["使用proxy代替defineproperty实现响应式",{"2":{"1439":1}}],["使用pinv",{"2":{"1086":1}}],["使用pip",{"2":{"445":1}}],["使用paddlepaddle内置的优化器和损失函数",{"2":{"635":1}}],["使用pandas读入并处理数据",{"2":{"208":1}}],["使用pytorch内置的优化器和损失函数",{"2":{"635":1}}],["使用polyscheduler",{"2":{"75":1}}],["使用βi=exp⁡",{"2":{"191":1}}],["使用基于标签偏移假设的方法通常是有利的",{"2":{"182":1}}],["使用更大的批量来训练更深层次的网络更容易导致内存不足",{"2":{"165":1}}],["使用更好的内存定位以及cpu和gpu上的缓存",{"2":{"82":1}}],["使用最大汇聚层以及大于1的步幅",{"2":{"149":1}}],["使用奇数的核大小和填充大小也提供了书写上的便利",{"2":{"141":1}}],["使用v",{"2":{"1500":1}}],["使用vgg层抽取特征时",{"2":{"920":1}}],["使用vt而不是梯度gt可以生成以下更新等式",{"2":{"88":1}}],["使用vitepress生成和预览文档",{"2":{"11":1}}],["使用它的绝对值",{"2":{"64":1}}],["使用对角hessian作为预条件子",{"2":{"64":1}}],["使用预处理实现牛顿方法的轻量版本",{"2":{"64":1}}],["使用预处理可以消除这种情况",{"2":{"61":1}}],["使用约束优化的观点",{"2":{"49":1}}],["使用",{"0":{"14":1,"1262":1},"1":{"15":1,"16":1,"17":1},"2":{"153":1,"192":1,"369":1,"439":1,"481":1,"744":1,"827":1,"913":1,"969":1,"1044":1,"1047":1,"1131":1,"1202":1,"1239":1,"1257":1,"1315":1,"1388":1,"1393":1,"1394":1,"1399":1,"1433":1,"1518":1}}],["在需要将响应式对象传递给非",{"2":{"1518":1}}],["在开发模式下",{"2":{"1515":1}}],["在开始寻找最好的模型参数",{"2":{"610":1}}],["在开始用机器学习算法解决问题之前",{"2":{"282":1}}],["在开始建模之前",{"2":{"209":1}}],["在祖先组件中通过provide配置向后代组件提供数据",{"2":{"1503":1}}],["在合适的时候触发事件",{"2":{"1499":1}}],["在合理地复杂性前提下",{"2":{"455":1}}],["在父组件中",{"2":{"1498":1}}],["在项目最外层",{"2":{"1444":1}}],["在项目目录初始化并安装依赖",{"2":{"1281":1}}],["在泛型约束中使用类型参数",{"2":{"1433":1}}],["在现代软件开发与运维的浪潮中",{"2":{"1352":1}}],["在现有观测值之间进行估计",{"2":{"345":1,"352":1}}],["在全球范围内被广泛使用",{"2":{"1359":1}}],["在全新环境中运行",{"2":{"1312":1}}],["在全卷积网络中",{"2":{"867":1}}],["在协同过滤从算法中",{"2":{"1189":1}}],["在检测数据中心的计算机状况的例子中",{"2":{"1183":1}}],["在论坛发布的帖子数量",{"2":{"1178":1}}],["在蓝色圈内的数据属于该组数据的可能性较高",{"2":{"1178":1}}],["在结束之前",{"2":{"1176":1}}],["在缓慢变化",{"2":{"1168":1}}],["在压缩过数据后",{"2":{"1160":1}}],["在课程的一开始",{"2":{"1150":1}}],["在工业",{"2":{"1148":1}}],["在工程的所有领域",{"2":{"1058":1}}],["在两者之间",{"2":{"1148":1}}],["在竖直轴上取值为x2",{"2":{"1145":1}}],["在内积计算中",{"2":{"1145":1}}],["在内存中向前读比向后读快多少",{"2":{"815":1}}],["在分离样本的时候就会比黑线表现差",{"2":{"1144":1}}],["在分离正样本和负样本上它显得的更好",{"2":{"1144":1}}],["在分类问题中",{"2":{"1106":2,"1107":1}}],["在分类问题中我们可以用另一种方式绘制这些数据点",{"2":{"1060":1}}],["在分类器输出0",{"2":{"643":1}}],["在支持向量机中",{"2":{"1144":1}}],["在代价函数中的这一项会变的非常小",{"2":{"1143":1}}],["在代价函数中",{"2":{"1143":1}}],["在代码中使用张量表示矩阵",{"2":{"998":3}}],["在代码中可以调用计算求和的函数",{"2":{"995":1}}],["在代码中表示为具有两个轴的张量",{"2":{"992":1}}],["在代码中表示为二维张量",{"2":{"153":1}}],["在代码中先import",{"2":{"724":1}}],["在代码中",{"2":{"717":1,"990":1,"995":1,"1000":1}}],["在稍后的课程中",{"2":{"1143":1}}],["在稍后将要介绍的一些模型会需要这个长度信息",{"2":{"568":1}}],["在横轴上代表以百万为单位的训练集大小",{"2":{"1141":1}}],["在算法中放弃什么",{"2":{"1138":1}}],["在算法的每个步骤中",{"2":{"987":1}}],["在改进学习算法的表现时",{"2":{"1135":1}}],["在接下来几节课中",{"2":{"1129":1}}],["在接下来的课程中",{"2":{"1180":1}}],["在接下来的一系列视频中",{"2":{"1178":1}}],["在接下来的一组视频中",{"2":{"1070":1}}],["在接下来的尝试中",{"2":{"1129":1}}],["在接下来的两段视频中",{"2":{"1129":1}}],["在接下来的octave",{"2":{"1092":1}}],["在接下来的几段视频中",{"2":{"1129":1}}],["在接下来的几个视频里",{"2":{"1064":1}}],["在接下来的几个视频中",{"2":{"1059":1}}],["在接下来的几章中",{"2":{"451":1}}],["在接下来的视频中",{"2":{"1058":1,"1067":2,"1068":1,"1088":1,"1090":1,"1106":1,"1137":1,"1143":2,"1161":1,"1187":1}}],["在接下来的内容中",{"2":{"848":1}}],["在接下来的实验中",{"2":{"653":1}}],["在接下来的小节中",{"2":{"342":1}}],["在接下来的章节中",{"2":{"253":1,"266":1}}],["在懂机器学习的人当中依然存在着很大的差距",{"2":{"1129":1}}],["在美国",{"2":{"1127":1}}],["在美国国家医学图书馆",{"2":{"292":1}}],["在图中你依稀能看出一条道路",{"2":{"1127":1}}],["在图像的顶部显示这幅图的标题",{"2":{"1091":1}}],["在图像上添加边界框之后",{"2":{"858":1}}],["在图像上绘制这些预测边界框和置信度",{"2":{"854":1}}],["在图像分类任务中",{"2":{"857":1}}],["在图像中绘制这些真实边界框和锚框",{"2":{"853":1}}],["在图像处理中",{"2":{"159":1,"863":1}}],["在看这段视频之前",{"2":{"1127":1}}],["在看了很多好电影之后",{"2":{"345":1}}],["在利用算法求出最优解后再重新转换回矩阵",{"2":{"1121":1}}],["在求出了δij",{"2":{"1121":1}}],["在求和过程中会触发广播机制",{"2":{"540":1}}],["在求和过程中抵消中间项",{"2":{"115":1}}],["在更为一般的情况中",{"2":{"1121":1}}],["在更新模型参数时",{"2":{"770":1}}],["在写完能够计算这两者的代码之后",{"2":{"1111":1}}],["在先前的视频中",{"2":{"1110":1}}],["在得到这样一个代价函数以后",{"2":{"1109":1}}],["在逻辑回归中我们已经熟悉了这里的假设函数形式",{"2":{"1143":1}}],["在逻辑回归中",{"2":{"1108":1,"1120":1,"1143":2}}],["在逻辑上最连贯的",{"2":{"342":1}}],["在普通的逻辑回归中",{"2":{"1101":1}}],["在神经网络中",{"2":{"1099":1,"1101":1}}],["在神经网络的不同层中也会有所不同",{"2":{"270":1}}],["在很多应用中",{"2":{"1140":1}}],["在很多情况下",{"2":{"198":1}}],["在很大的程度上",{"2":{"1098":1}}],["在90年代的后期应用减少了",{"2":{"1098":1}}],["在右边",{"2":{"1089":1}}],["在左边这里我画出了关于z的代价函数cost1",{"2":{"1144":1}}],["在左边",{"2":{"1089":1}}],["在左侧和右侧填充相同数量的列",{"2":{"141":1}}],["在你得到你的学习参数以后",{"2":{"1129":1}}],["在你想用大量的特征值",{"2":{"1086":1}}],["在你的基础设施内安全地处理数据的最佳实践",{"2":{"1041":1}}],["在octave",{"2":{"1121":1}}],["在octave中点号一般用来表示元素位运算",{"2":{"1090":1}}],["在octave里",{"2":{"1086":2}}],["在octave建软件原型",{"2":{"1061":1}}],["在运行k",{"2":{"1153":1}}],["在运行梯度下降算法之前",{"2":{"1109":1}}],["在运行梯度下降算法前",{"2":{"1084":1}}],["在运行完某个学习算法之后",{"2":{"1090":1}}],["在运行反向传播函数之后",{"2":{"979":1}}],["在矩阵的乘法中",{"2":{"1076":1}}],["在矩阵x的第ith行中找到与ai的iou最大的真实边界框bj",{"2":{"851":1}}],["在矩阵x中找到剩余元素中最大的元素",{"2":{"851":1}}],["在矩阵x中找到最大的元素",{"2":{"851":1}}],["在那个品红色的点初始化",{"2":{"1068":1}}],["在那里你可能需要把1000维的数据压缩100维特征",{"2":{"1161":1}}],["在那里寻找答案",{"2":{"1135":1}}],["在那里通过某种方式",{"2":{"844":1}}],["在那里",{"2":{"210":1}}],["在批量梯度下降中",{"2":{"1067":1,"1167":1}}],["在批量学习",{"2":{"195":1}}],["在我的",{"2":{"1089":1}}],["在我教机器学习将近十年后的现在",{"2":{"1061":1}}],["在我们谈到的最后一个视频",{"2":{"1185":1}}],["在我们的训练集中",{"2":{"1139":1}}],["在我们的垃圾邮件分类器例子中",{"2":{"1138":1}}],["在我们的例子中代表",{"2":{"643":1}}],["在我们的例子中",{"2":{"640":1,"641":1,"1188":1}}],["在我们在训练模型的过程中",{"2":{"1133":1}}],["在我们需要做预测时",{"2":{"1112":1}}],["在我们上面三层的神经网络例子中",{"2":{"1101":1}}],["在我们面对多维特征问题的时候",{"2":{"1082":1}}],["在我们掷骰子的随机实验中",{"2":{"1028":1}}],["在我们计算y关于x的梯度之前",{"2":{"974":1}}],["在我们使用的示例图像中",{"2":{"879":1}}],["在我们看过",{"2":{"635":1}}],["在我们开始考虑如何用模型拟合",{"2":{"611":1}}],["在我们开始用小批量随机梯度下降优化我们的模型参数之前",{"2":{"601":1}}],["在我们确定所有的超参数之前",{"2":{"256":1}}],["在我们目前已探讨",{"2":{"253":1}}],["在我们创建的conv2d自动求导时",{"2":{"133":1}}],["在我们取得进展之前",{"2":{"103":1}}],["在硅谷有很多团体试图建立很好的推荐系统",{"2":{"1187":1}}],["在硅谷",{"2":{"1088":1}}],["在硅谷里",{"2":{"1061":1}}],["在硅谷我住的地方",{"2":{"1059":1}}],["在无监督学习中",{"2":{"1061":1}}],["在无人驾驶里",{"2":{"857":1}}],["在房价问题这个例子中便是直线的斜率和在y",{"2":{"1064":1}}],["在房价的例子中",{"2":{"1060":1}}],["在房价预测比赛页面",{"2":{"207":1}}],["在斯坦福大学",{"2":{"1058":1}}],["在机械应用中",{"2":{"1058":1}}],["在机器翻译数据集上",{"2":{"576":1}}],["在机器翻译中",{"2":{"566":1,"568":1}}],["在机器翻译中通过解码序列词元时",{"2":{"359":1}}],["在机器视觉中",{"2":{"455":1}}],["在机器学习领域大部分人更习惯使用1",{"2":{"1179":1}}],["在机器学习领域中的大多数任务通常都与预测",{"2":{"608":1}}],["在机器学习的应用中",{"2":{"1174":1}}],["在机器学习的术语中",{"2":{"609":1}}],["在机器学习的广泛应用中",{"2":{"288":1}}],["在机器学习中有一种大思想",{"2":{"1187":1}}],["在机器学习中",{"2":{"255":1,"282":1,"286":1,"605":1,"1021":1,"1069":1}}],["在真实的企业和开发者场景中",{"2":{"1051":1}}],["在真实的系统中我们仍然需要数十亿个参数",{"2":{"151":1}}],["在估计一个骰子的公平性时",{"2":{"1026":1}}],["在估计动量和二次矩时",{"2":{"36":1}}],["在强化学习中",{"2":{"1025":1}}],["在强化学习问题中",{"2":{"298":1}}],["在飞机喷气发动机的异常检测中",{"2":{"1025":1}}],["在飞桨中",{"2":{"446":1}}],["在jupyter记事本中",{"2":{"1007":1}}],["在掌握点积和矩阵",{"2":{"999":1}}],["在微分多元函数时经常使用以下规则",{"2":{"983":1}}],["在微分学最重要的应用是优化问题",{"2":{"980":1}}],["在微调bert中",{"2":{"883":1}}],["在微调过程中",{"2":{"689":1}}],["在微调期间",{"2":{"656":1}}],["在控制流的例子中",{"2":{"979":1}}],["在默认情况下",{"2":{"974":2}}],["在转置卷积中",{"2":{"969":2}}],["在损失函数中",{"2":{"966":1}}],["在类别预测时",{"2":{"966":1}}],["在类实例化时也可以指定其他函数参数",{"2":{"423":4}}],["在标签图像中",{"2":{"945":1}}],["在标准化数据之后",{"2":{"209":1}}],["在标准暂退法正则化中",{"2":{"170":1}}],["在2500年前",{"2":{"980":1}}],["在2×2的兴趣区域汇聚层中",{"2":{"938":1}}],["在2012年imagenet挑战赛中取得了轰动一时的成绩",{"2":{"455":1}}],["在2012年前",{"2":{"455":1}}],["在2014年的imagenet图像识别挑战赛中",{"2":{"486":1}}],["在2014年",{"2":{"300":1}}],["在2009年",{"2":{"290":1}}],["在4×4的输入中",{"2":{"938":1}}],["在汇聚层中",{"2":{"938":1}}],["在汇聚窗口到达的每个位置",{"2":{"146":1}}],["在香蕉检测数据集中演示其他带有真实边界框的图像",{"2":{"935":1}}],["在达到m之前",{"2":{"932":1}}],["在风格迁移中",{"2":{"926":1}}],["在当前尺度下根据y生成的锚框",{"2":{"959":1}}],["在当前尺度下",{"2":{"913":1}}],["在当时最先进的图像也就100万像素",{"2":{"454":1}}],["在特征图",{"2":{"912":1}}],["在特征维度上连结",{"2":{"375":4}}],["在获得具有超参数的满意的模型后",{"2":{"896":1}}],["在获得解码器的隐状态之后",{"2":{"574":1}}],["在比较实验中进一步调整finetune",{"2":{"876":1}}],["在比较步骤中",{"2":{"675":1}}],["在测试期间",{"2":{"891":1}}],["在测试集中",{"2":{"888":1}}],["在测试过程中",{"2":{"872":1}}],["在测试时",{"2":{"176":1,"181":1,"202":1}}],["在源数据集",{"2":{"870":1}}],["在目标数据集",{"2":{"870":1}}],["在目标检测中",{"2":{"858":1,"934":1}}],["在目标函数中",{"2":{"1143":1}}],["在目标函数中加入λ2|w|2",{"2":{"49":1}}],["在目标函数前加负号即可",{"2":{"98":1}}],["在执行非极大值抑制前",{"2":{"854":1}}],["在剩下的配对中",{"2":{"853":1}}],["在剩余元素",{"2":{"851":3}}],["在y轴上缩放步长",{"2":{"848":3}}],["在未来",{"2":{"837":1}}],["在未来6小时",{"2":{"290":1}}],["在n−1步之后",{"2":{"842":1}}],["在net",{"2":{"821":1}}],["在nn",{"2":{"820":2}}],["在n个变量上累加",{"2":{"634":1}}],["在hybridsequential的实例调用hybridize函数后",{"2":{"820":1}}],["在验证实验结果之前",{"2":{"814":1}}],["在推断过程中则影响不大",{"2":{"814":1}}],["在桌面级cpu上",{"2":{"812":1}}],["在队列中尽可能地优先读取和写入大的块",{"2":{"805":1}}],["在访问磁盘上的特定扇区时",{"2":{"804":1}}],["在帖子中很好地概述了过去十年的进展",{"2":{"800":1}}],["在cuda和框架代码层之下",{"2":{"811":1}}],["在cpu和gpu这两种设备上使用并行计算和通信",{"2":{"799":1}}],["在cpu上",{"2":{"794":2}}],["在constant",{"2":{"703":1}}],["在重度多线程的系统中",{"2":{"792":1}}],["在小批量中",{"2":{"776":1}}],["在小批量随机梯度下降中",{"2":{"82":1}}],["在提取所有中心词及其上下文词和采样噪声词后",{"2":{"776":1}}],["在提出时",{"2":{"656":1}}],["在提出批量规范化的论文中",{"2":{"475":1}}],["在读取训练集之后",{"2":{"772":1}}],["在非监督学习中",{"2":{"1150":2}}],["在非掩码预测上进行平均",{"2":{"765":1}}],["在非windows的平台上",{"2":{"583":1}}],["在字节对编码的10次迭代之后",{"2":{"757":1}}],["在词表中索引是c",{"2":{"785":1}}],["在词表中索引是o1",{"2":{"785":1}}],["在词嵌入模型训练之后",{"2":{"762":1}}],["在词的开头和末尾添加特殊字符",{"2":{"756":1}}],["在词元化之后",{"2":{"693":1}}],["在词元级别",{"2":{"656":1}}],["在跳元模型中",{"2":{"783":1}}],["在跳元模型中给定词wi",{"2":{"742":1}}],["在跳元模型和连续词袋模型中",{"2":{"756":1}}],["在法语和西班牙语等其他语言中",{"2":{"755":1}}],["在英语中",{"2":{"755":1}}],["在维基百科的子集上预训练",{"2":{"748":1}}],["在维度扩展后",{"2":{"369":4}}],["在fast",{"2":{"938":1}}],["在fasttext中",{"2":{"756":1,"757":1}}],["在fashion",{"2":{"473":1}}],["在f的许多可能的设计中",{"2":{"744":1}}],["在1的位置有5个恶性肿瘤样本",{"2":{"1060":1}}],["在16",{"2":{"833":1}}],["在16通道插槽中的pcie4",{"2":{"812":1}}],["在15",{"2":{"736":1}}],["在1024个gpu上进行训练",{"2":{"300":1}}],["在10次迭代之后",{"2":{"129":1}}],["在加入elmo表示后",{"2":{"731":1}}],["在预训练bert时",{"2":{"738":1}}],["在预训练bert之后",{"2":{"727":1,"728":1}}],["在预训练之后",{"2":{"730":1}}],["在预训练过程中",{"2":{"726":1}}],["在预测住房价格时",{"2":{"1086":1}}],["在预测类别和边界框时",{"2":{"938":1}}],["在预测期间整理测试集",{"2":{"890":2}}],["在预测时也无法保证分割出的区域具有我们希望得到的语义",{"2":{"944":1}}],["在预测时",{"2":{"850":1,"854":1,"866":1,"1146":1,"1162":1}}],["在预测时将net设置为评估模式",{"2":{"577":2}}],["在预测过程中",{"2":{"643":1}}],["在预测阶段",{"2":{"408":1,"964":1}}],["在预测词元时",{"2":{"373":1,"377":1}}],["在预测房价的问题中",{"2":{"295":1}}],["在原始格式中",{"2":{"772":1}}],["在原始bert模型中",{"2":{"725":1}}],["在原始的bert模型中",{"2":{"687":3}}],["在遮蔽语言模型任务中不会预测特殊词元",{"2":{"721":1}}],["在其中θ3和θ4",{"2":{"1115":1}}],["在其它一些机器学习问题中",{"2":{"1060":1}}],["在其输入中",{"2":{"721":1}}],["在其他编程语言中同样可以实现",{"2":{"1093":1}}],["在其他有用的机器学习应用中",{"2":{"1090":1}}],["在其他机器学习问题中",{"2":{"1060":1}}],["在其他一些设计中",{"2":{"572":1}}],["在其他一些情况下",{"2":{"294":1}}],["在其他的领域",{"2":{"422":1}}],["在其他条件不变的情况下",{"2":{"230":1}}],["在wikitext",{"2":{"718":1}}],["在定义训练代码实现之前",{"2":{"726":1}}],["在定义我们自己的块时",{"2":{"422":1}}],["在定制的数据集上对bert进行预训练变得越来越流行",{"2":{"718":1}}],["在负采样的每个训练步处的梯度的计算成本较小",{"2":{"708":1}}],["在embedding中将被训练",{"2":{"703":1}}],["在滑动期间",{"2":{"699":1}}],["在bert的原始实现中",{"2":{"740":1}}],["在bert的输入中",{"2":{"660":1}}],["在bert中",{"2":{"734":3}}],["在bert微调的常见实现中",{"2":{"688":1}}],["在练习中",{"2":{"686":1}}],["在软对齐中",{"2":{"675":1}}],["在较长序列中的前num",{"2":{"668":1}}],["在文本序列",{"2":{"785":1}}],["在文本分类任务",{"2":{"713":1}}],["在文本标注中",{"2":{"659":1}}],["在文本标注任务中",{"2":{"659":1}}],["在文档摘要生成算法中",{"2":{"315":1}}],["在语言学中",{"2":{"755":1}}],["在语义文本相似度基准数据集",{"2":{"658":1}}],["在语音识别中",{"2":{"295":2}}],["在单个gpu上运行",{"2":{"837":1}}],["在单个gpu上训练网络",{"2":{"828":1}}],["在单文本分类应用中",{"2":{"657":1}}],["在单词和标点符号之间插入空格",{"2":{"565":1}}],["在观察一个事件j时",{"2":{"651":1}}],["在信息论中",{"2":{"650":1}}],["在信息检索领域",{"2":{"293":1}}],["在动画中绘制数据",{"2":{"635":1}}],["在动物分类的应用中",{"2":{"291":1}}],["在展示训练函数的实现之前",{"2":{"635":1}}],["在查看代码之前",{"2":{"631":1}}],["在snli数据集上以更少的参数实现了当时的最佳结果",{"2":{"672":1}}],["在softmax回归中",{"2":{"630":1}}],["在st中累加平方梯度意味着st基本上以线性速率增长",{"2":{"27":1}}],["在交叉熵损失函数中传递未规范化的预测",{"2":{"624":1}}],["在减法和规范化步骤之后",{"2":{"624":1}}],["在继续softmax计算之前",{"2":{"624":1}}],["在继续操作之前",{"2":{"208":1}}],["在驻点附近会发生什么情况",{"2":{"621":1}}],["在另一半的时间里",{"2":{"737":1}}],["在另一种方法中",{"2":{"615":1}}],["在另一些情况下",{"2":{"182":1,"189":1}}],["在之后的优化问题中",{"2":{"1143":1}}],["在之后的课程中",{"2":{"1130":1}}],["在之后的章节中",{"2":{"598":1}}],["在之前的基于内容的推荐系统中",{"2":{"1189":1}}],["在之前的一些视频中",{"2":{"1141":1}}],["在之前的课程中",{"2":{"1140":1}}],["在之前的视频中",{"2":{"1068":1,"1141":1}}],["在之前的实验",{"2":{"946":1}}],["在之前所有架构中",{"2":{"502":1}}],["在之前猫狗分类的例子中",{"2":{"151":1}}],["在了解线性回归的关键思想之后",{"2":{"598":1}}],["在了解了上述统计工具后",{"2":{"350":1}}],["在后代组件中通过inject配置来声明接收数据",{"2":{"1503":1}}],["在后续课程中",{"2":{"1064":1}}],["在后来的版本更新中",{"2":{"818":1}}],["在后端执行时",{"2":{"592":2}}],["在后面的课程中",{"2":{"1069":2}}],["在后面的两个视频中",{"2":{"1059":1}}],["在后面的内容中",{"2":{"561":1}}],["在后面的章节中",{"2":{"608":1,"630":1}}],["在后面的章节中我们将会遇到隐状态包含多个变量的情况",{"2":{"332":1}}],["在后面的章节将提供关于使用卷积神经网络处理序列的更多详细信息",{"2":{"397":1}}],["在后面关于循环神经网络的章节中",{"2":{"236":1}}],["在k个gpu上进行训练时",{"2":{"839":1}}],["在keras中最简单的指定初始化方法是在创建层时指定kernel",{"2":{"592":1}}],["在keras中",{"2":{"591":1}}],["在k折交叉验证过程中返回第i折的数据",{"2":{"211":1}}],["在初始化参数之后",{"2":{"601":1}}],["在初始化模型参数后",{"2":{"165":1}}],["在初始时间步被输入到解码器中",{"2":{"577":1}}],["在完成每个小批量数据的训练之后",{"2":{"832":1}}],["在完成所有时间步后",{"2":{"573":1}}],["在完善工作中",{"2":{"32":1}}],["在长短期记忆网络中",{"2":{"555":1,"556":1}}],["在门控循环单元中",{"2":{"555":1}}],["在各种序列学习问题中",{"2":{"550":1}}],["在序列层次上",{"2":{"656":1}}],["在序列中屏蔽不相关的项",{"2":{"575":3}}],["在序列起始时间步的旧隐状态都将很容易保留并传递到序列结束",{"2":{"542":1}}],["在序列学习中",{"2":{"518":1}}],["在多元高斯分布模型中",{"2":{"1184":1}}],["在多变量线性回归中",{"2":{"1081":1}}],["在多尺度目标检测中",{"2":{"915":1}}],["在多个层次上的图像分层表示进行多尺度目标检测",{"2":{"914":1}}],["在多个尺度下",{"2":{"914":1}}],["在多个gpu之间分割数据并传输到gpu的显存中",{"2":{"843":1}}],["在多个gpu之间同步数据将使用刚才讨论的辅助函数allreduce和split",{"2":{"837":1}}],["在多个gpu之间拆分网络",{"2":{"832":1}}],["在多个gpu上设置模型",{"2":{"828":1}}],["在多个",{"2":{"828":1}}],["在多个设备上并行工作",{"2":{"827":1}}],["在多大程度上来自旧的状态ht−1和",{"2":{"542":1}}],["在多项式回归中体现为限制阶数",{"2":{"269":1}}],["在多项式回归的例子",{"2":{"269":1}}],["在学术机器学习中因此",{"2":{"1187":1}}],["在学术界已经提出了许多方法来解决这类问题",{"2":{"538":1}}],["在学习复杂的非线性方程时提供了一种更为清晰",{"2":{"1143":1}}],["在学生放学后社交媒体应用更受欢迎",{"2":{"345":1}}],["在为预训练生成句子对时",{"2":{"737":1}}],["在为文本建模时",{"2":{"531":1}}],["在为给定文本序列生成手写的挑战中",{"2":{"373":1}}],["在双向循环神经网络中",{"2":{"524":1}}],["在双向架构中",{"2":{"521":1}}],["在具有多个隐藏层的深度双向循环神经网络中",{"2":{"521":1}}],["在隐马尔可夫模型中的方程具有特定的统计意义",{"2":{"520":1}}],["在时间序列的上下文中或在语言模型的上下文中",{"2":{"518":1}}],["在时间步t",{"2":{"573":1}}],["在时间步t输入xt将是一个n×d矩阵",{"2":{"341":1}}],["在时间步2",{"2":{"515":1}}],["在时间步2中",{"2":{"513":1}}],["在时间步1",{"2":{"515":2}}],["在正确率和计算代价之间进行权衡",{"2":{"516":1}}],["在正式介绍贪心搜索之前",{"2":{"512":1}}],["在随后的每个时间步",{"2":{"515":1}}],["在随机抽样的迭代过程中",{"2":{"320":1}}],["在随机采样中",{"2":{"320":1}}],["在随机梯度下降中",{"2":{"1167":1}}],["在随机梯度下降法中",{"2":{"1165":1}}],["在随机梯度下降的每次迭代中",{"2":{"113":1}}],["在随机梯度下降的实验中",{"2":{"80":1}}],["在随机梯度朗之万动力学上使用",{"2":{"75":1}}],["在vgg论文中",{"2":{"510":1}}],["在vgg",{"2":{"508":1}}],["在删除了inception块中的一些路径之后",{"2":{"505":1}}],["在resnet的全局平均汇聚层后",{"2":{"873":1}}],["在resnet的后续版本中",{"2":{"505":1}}],["在resnet中加入全局平均汇聚层",{"2":{"502":1}}],["在r上没有取得最小值",{"2":{"44":1}}],["在输出层我们应该有4个值",{"2":{"1103":1}}],["在输出序列上的任意时间步t",{"2":{"574":1}}],["在输出通道数为64",{"2":{"502":1}}],["在输入图像上找到离坐标",{"2":{"863":1}}],["在输入图像的边界填充元素",{"2":{"141":1}}],["在输入表示中添加位置编码",{"2":{"706":1}}],["在输入相同的x时",{"2":{"442":1}}],["在残差块中",{"2":{"501":1}}],["在残差连接的加法计算之后",{"2":{"404":1}}],["在追寻历史的脉络的同时",{"2":{"492":1}}],["在通道维度上连结输出",{"2":{"487":4}}],["在通道维上连结输入与输出",{"2":{"484":1}}],["在inception块中",{"2":{"487":1}}],["在imagenet基准上",{"2":{"301":1}}],["在gpu0上评估模型",{"2":{"837":3}}],["在gpu上建议保持卷积大小对齐",{"2":{"814":1}}],["在gpu上创建的张量只消耗这个gpu的显存",{"2":{"448":1}}],["在gpu仍在运行时就开始使用pci",{"2":{"797":3}}],["在gpu1上运行并复制到cpu",{"2":{"797":3}}],["在gpu1上运行",{"2":{"797":3}}],["在glove模型中",{"2":{"743":1}}],["在glove中的形式是",{"2":{"717":1}}],["在gluon中",{"2":{"591":1,"593":1,"596":1}}],["在googlenet中",{"2":{"487":1}}],["在跨层连接上",{"2":{"484":1}}],["在稠密块之间添加一个转换层",{"2":{"482":4}}],["在模板中均可以直接使用",{"2":{"1452":1}}],["在模型比较时",{"2":{"1138":1}}],["在模型训练过程中",{"2":{"476":1}}],["在模块的参数初始化过程中",{"2":{"424":2}}],["在aws",{"2":{"830":2}}],["在arm上叫做neon",{"2":{"809":1}}],["在alexnet中主要是哪部分需要更多的计算",{"2":{"465":1}}],["在alexnet中主要是哪部分占用显存",{"2":{"465":1}}],["在alexnet的第一层",{"2":{"459":1}}],["在adagrad算法中",{"2":{"27":1}}],["在网络的最底层",{"2":{"455":1}}],["在网络中加入隐藏层",{"0":{"231":1}}],["在网络中那些一开始花费最多时间取得进展的部分",{"2":{"73":1}}],["在早期",{"2":{"454":1}}],["在传统机器学习方法中",{"2":{"454":1}}],["在传统的卷积神经网络中",{"2":{"138":1}}],["在l2范数中常常省略下标2",{"2":{"1000":1}}],["在labels中的元素和contexts",{"2":{"776":1}}],["在load",{"2":{"571":1}}],["在lenet提出后",{"2":{"454":1}}],["在l1范数大于1的条件下",{"2":{"425":1}}],["在pca的计算过程中完全不需要人为的设定参数或是根据任何经验模型对计算进行干预",{"2":{"1158":1}}],["在pca中",{"2":{"1158":1}}],["在pcie4",{"2":{"805":1}}],["在pinv",{"2":{"1086":1}}],["在pytorch和tensorflow中为tensor",{"2":{"1016":1}}],["在pytorch中",{"2":{"445":1,"446":1,"591":1,"596":1,"797":1}}],["在python中常用的数据分析工具中",{"2":{"1010":1}}],["在python中",{"2":{"817":1,"1183":1}}],["在ptb数据集上进行训练时",{"2":{"774":1}}],["在penn树库ii标注集中",{"2":{"659":1}}],["在paddlepaddle中",{"2":{"445":1,"591":1}}],["在prefix后面生成新字符",{"2":{"333":4}}],["在m小于或等于n的时候",{"2":{"1086":1}}],["在multibox",{"2":{"856":1}}],["在masks中的元素和contexts",{"2":{"776":1}}],["在mxnet中为ndarray",{"2":{"1016":1}}],["在mxnet中",{"2":{"445":1,"446":1}}],["在mnist数据集上尝试以上改进的网络",{"2":{"139":1}}],["在选择了架构并设置了超参数后",{"2":{"429":1}}],["在返回输出之前",{"2":{"425":1}}],["在块的参数初始化过程中",{"2":{"424":1}}],["在构造函数参数中使用修饰符",{"2":{"1428":1}}],["在构造自定义块之前",{"2":{"422":1}}],["在构建densenet时",{"2":{"484":1}}],["在构建模型时",{"2":{"202":1}}],["在以前的视频中",{"2":{"1161":1}}],["在以前的视频中我们谈到关于梯度下降算法",{"2":{"1069":1}}],["在以前的一个小测验",{"2":{"1093":1}}],["在以前的所有讨论中",{"2":{"116":1}}],["在以像素级分类的语义分割中将会很方便",{"2":{"967":1}}],["在以下领域尤其火热",{"2":{"1303":1}}],["在以下情况下使用",{"2":{"1047":1}}],["在以下示例中",{"2":{"956":1,"957":1}}],["在以下路径中可以找到整个数据集",{"2":{"889":1}}],["在以下代码段中",{"2":{"734":3}}],["在以后",{"2":{"417":1}}],["在掩蔽多头解码器自注意力层",{"2":{"408":1}}],["在decoderblock类中实现的每个层包含了三个子层",{"2":{"408":1}}],["在解释这些循环神经网络的变体时",{"2":{"550":1}}],["在解释这个设计之前",{"2":{"398":1}}],["在解码器自注意力中",{"2":{"404":1}}],["在编码器接口中",{"2":{"533":1}}],["在编码器的自注意力中",{"2":{"409":1}}],["在编码器",{"2":{"404":1}}],["在编码维度上降低频率",{"2":{"399":1}}],["在二进制表示中",{"2":{"399":1}}],["在二维互相关运算中",{"2":{"126":1}}],["在位置嵌入矩阵p中",{"2":{"398":1}}],["在带参数的注意力汇聚的实验中学习得到的参数w的价值是什么",{"2":{"394":1}}],["在带参数的注意力汇聚模型中",{"2":{"392":1}}],["在尝试拟合带噪声的训练数据时",{"2":{"392":1}}],["在轴0",{"2":{"382":4,"1004":1}}],["在使用net之前",{"2":{"592":1}}],["在使用神经网络进行端到端学习的兴起之前",{"2":{"564":1}}],["在使用批量规范化之前",{"2":{"477":1}}],["在使用上述函数时",{"2":{"364":1}}],["在使用程序时",{"2":{"345":1}}],["在注意力机制的背景中",{"2":{"390":1}}],["在注意力机制的背景下",{"2":{"356":1}}],["在注意力机制中",{"2":{"356":1}}],["在音乐或视频流媒体服务上",{"2":{"354":1}}],["在自然语言处理应用中",{"2":{"784":1}}],["在自然语言处理中",{"2":{"734":1}}],["在自然语言推断中",{"2":{"670":1}}],["在自然语言中一词多义很常见",{"2":{"525":1}}],["在自然科学和社会科学领域",{"2":{"608":1}}],["在自定义层定义完成后",{"2":{"415":1}}],["在自注意力中",{"2":{"397":1,"401":1}}],["在自回归模型的近似法中",{"2":{"348":1}}],["在自动微分之前",{"2":{"161":1}}],["在统计学中",{"2":{"345":1,"614":1,"1026":1}}],["在统计模型",{"2":{"300":1}}],["在市场开放时股市交易软件更常用",{"2":{"345":1}}],["在许多及其学习问题中",{"2":{"1157":1}}],["在许多工作节点和许多gpu中",{"2":{"844":1}}],["在许多任务上",{"2":{"613":1}}],["在许多精彩的电影被看过之后",{"2":{"345":1}}],["在许多情况下使用高速扩展总线连接",{"2":{"801":1}}],["在许多情况下训练和测试分布p",{"2":{"189":1}}],["在许多情况下",{"2":{"141":1,"202":1,"300":1,"349":1,"627":1,"797":1,"1029":1,"1036":1}}],["在基于cifar",{"2":{"885":1}}],["在基于梯度的迭代",{"2":{"244":1}}],["在基线上",{"2":{"342":1}}],["在循环神经网络解码器的最后一层使用全连接层来变换隐状态",{"2":{"574":1}}],["在循环神经网络解码器的初始化时间步",{"2":{"572":1}}],["在循环神经网络模型中",{"2":{"573":3}}],["在循环神经网络编码器",{"2":{"377":1}}],["在循环神经网络中执行",{"2":{"340":1}}],["在循环遍历prefix中的开始字符时",{"2":{"333":1}}],["在介绍完如何存储和操作数据后",{"2":{"988":1}}],["在介绍深度神经网络之前",{"2":{"587":1}}],["在介绍循环神经网络模型之前",{"2":{"338":1}}],["在介绍该模型之前",{"2":{"319":1,"699":1}}],["在tf",{"2":{"820":1}}],["在tensorflow中保存模型的底层api是tf",{"2":{"821":1}}],["在tensorflow中",{"2":{"596":1}}],["在transformer编码器中常见是",{"2":{"734":1}}],["在transformer中使用加性注意力取代缩放点积注意力是不是个好办法",{"2":{"411":1}}],["在transformer中",{"2":{"404":1,"410":1}}],["在train",{"2":{"330":1}}],["在t步之后",{"2":{"95":1}}],["在迭代过程中",{"2":{"320":1,"321":1,"322":1}}],["在十个最频繁的词对中",{"2":{"318":1}}],["在数据并行中",{"2":{"838":1}}],["在数据集上迭代时",{"2":{"828":1}}],["在数据集中的出现次数",{"2":{"316":1}}],["在数学表示法中",{"2":{"990":1,"991":1,"1018":1}}],["在数学或代码中",{"2":{"232":1}}],["在数学中",{"2":{"156":1,"990":1}}],["在数学术语上",{"2":{"40":1}}],["在给定的样本空间s中",{"2":{"1027":1}}],["在给定预训练的文本表示的情况下",{"2":{"663":1}}],["在给定隐藏层维度的情况下",{"2":{"563":1}}],["在给定观测的情况下",{"2":{"518":1}}],["在给定这样的文本序列时",{"2":{"315":1}}],["在给定一组特定的可用数据的情况下",{"2":{"289":1}}],["在任何两个不同高度之间的区间",{"2":{"1028":1}}],["在任何时候都只有一个节点在通信",{"2":{"842":1}}],["在任何时间步骤t",{"2":{"312":1}}],["在任何时间点上",{"2":{"298":1}}],["在任何一次训练迭代中",{"2":{"833":1}}],["在任何一点隐状态的计算",{"2":{"335":1}}],["在任何指数族分布模型中",{"2":{"647":1}}],["在任何解码器时间步中",{"2":{"408":1}}],["在任何解码时间步t",{"2":{"374":1}}],["在任意时间步t",{"2":{"312":1,"340":1,"512":1,"519":1}}],["在讨论包含深度学习的解决方案之前",{"2":{"317":1}}],["在讨论一般性原则之后",{"2":{"312":1}}],["在讨论深度模型的过程中",{"2":{"285":1}}],["在对常用图像增广方法的探索时",{"2":{"878":1}}],["在对网页内容进行情感分析时",{"2":{"538":1}}],["在对过去若干个时间步经过反向传播后",{"2":{"311":1}}],["在对序列数据进行更详细的回顾之后",{"2":{"305":1}}],["在对未来我们的数据可能发生变化的一些限制性假设下",{"2":{"180":1}}],["在扑克游戏中",{"2":{"301":1}}],["在鉴别鸟类或诊断皮肤癌方面也取得了惊人的成果",{"2":{"301":1}}],["在过去几年",{"2":{"1187":1}}],["在过去的几年里",{"2":{"588":1}}],["在过去的日子里",{"2":{"302":1}}],["在过去的十年里占据了至高无上的地位",{"2":{"302":1}}],["在过去的十年中",{"2":{"300":1}}],["在过去的考试题目上取得好成绩并不能保证他会在真正考试时发挥出色",{"2":{"252":1}}],["在过去十年中被",{"2":{"300":1}}],["在经验上",{"2":{"299":1}}],["在上几节视频中",{"2":{"1191":1}}],["在上一节视频里",{"2":{"1147":1}}],["在上一段视频中",{"2":{"1122":1,"1123":1}}],["在上一个视频中",{"2":{"1065":1,"1111":1}}],["在上一章中",{"2":{"421":1}}],["在上述情况下",{"2":{"796":1}}],["在上世纪90年代初到2012年之间的大部分时间里",{"2":{"454":1}}],["在上个世纪末",{"2":{"299":1}}],["在上面这些选项中",{"2":{"1137":1}}],["在上面这个网络中",{"2":{"431":1}}],["在上面",{"2":{"1089":1}}],["在上面的特殊情况中",{"2":{"1121":1}}],["在上面的部分中",{"2":{"1019":1}}],["在上面的例子中",{"2":{"1017":1}}],["在上面的前向传播中",{"2":{"959":1}}],["在上面的evaluate",{"2":{"634":1}}],["在上面的监督学习问题中",{"2":{"284":1}}],["在上面的示例中",{"2":{"113":1}}],["在上面定义的模型里",{"2":{"232":1}}],["在他所描述的图灵测试中",{"2":{"299":1}}],["在监督学习中我们有一个数据集",{"2":{"1063":1}}],["在监督学习中",{"2":{"298":1,"1143":1}}],["在雅达利游戏中仅使用视觉输入就击败了人类",{"2":{"298":1}}],["在欧几里得空间中是否存在一种",{"2":{"296":1}}],["在医学上序列输入和输出就更为重要",{"2":{"295":1}}],["在五分制电影评分中",{"2":{"294":1}}],["在不断发展",{"2":{"1436":1}}],["在不改变两个特征的原有偏差的基础上",{"2":{"1184":2}}],["在不使用图像增广的情况下训练模型",{"2":{"885":1}}],["在不裁剪梯度的情况下运行本节中的代码会发生什么",{"2":{"337":1}}],["在不经意间",{"2":{"290":1}}],["在不同尺度下",{"2":{"912":1}}],["在不同机器上运行训练代码的速度会有细微的差别",{"2":{"843":1}}],["在不同模型组件间共享参数",{"2":{"429":1}}],["在不同的尺度下",{"2":{"956":1}}],["在不同的网络通路上引导不同的分支时",{"2":{"426":1}}],["在不同的领域之间保持不变",{"2":{"182":1}}],["在不同的处理器内核之间共享",{"2":{"77":1}}],["在不同分布偏移中",{"2":{"181":1}}],["在没有大数据集的情况下",{"2":{"284":1}}],["在短短几秒钟的时间里",{"2":{"282":1}}],["在贝叶斯统计中",{"2":{"280":1}}],["在同一个元素身上使用时的优先级发生了变化",{"2":{"1525":1}}],["在同一张图像中",{"2":{"854":1}}],["在同一训练代码实现中",{"2":{"279":1}}],["在同名定理",{"2":{"253":1}}],["在某个尺度下",{"2":{"954":1}}],["在某个时间步表示当前词元的条件概率",{"2":{"344":1}}],["在某种规模上",{"2":{"913":1}}],["在某种程度上有相似",{"2":{"1191":1}}],["在某种程度上",{"2":{"301":1,"302":1}}],["在某种意义上是最简单的",{"2":{"270":1}}],["在某些应用中",{"2":{"294":1,"301":1}}],["在某些方面",{"2":{"237":1,"475":1}}],["在某些问题上",{"2":{"69":1}}],["在某些情况下这种连接的速度可能会慢一个数量级",{"2":{"843":1}}],["在某些情况下",{"2":{"40":1,"73":1,"202":1,"349":1,"368":1,"426":1,"819":1,"1019":1}}],["在该轮中没有用于训练的子集",{"2":{"257":1}}],["在哲学上",{"2":{"254":1}}],["在大数据量场景下依然保持较快响应",{"2":{"1201":1}}],["在大规模的训练集的情况下",{"2":{"1167":1}}],["在大型语料库上预先练的词向量可以应用于下游的自然语言处理任务",{"2":{"752":1}}],["在大型语料库上预先训练的词向量可以应用于下游的自然语言处理任务",{"2":{"747":1}}],["在大型医院系统中",{"2":{"251":1}}],["在大多数情况下",{"2":{"26":1,"252":1,"817":1,"1019":1}}],["在相对休眠了相当长一段时间之后",{"2":{"300":1}}],["在相关资料中查找两个矩阵乘积特征值的解析界",{"2":{"250":1}}],["在相应的假设条件下",{"2":{"202":1}}],["在参数初始化时需要非常小心",{"2":{"249":1}}],["在反向传播期间",{"2":{"244":1}}],["在处理骰子掷出时",{"2":{"1027":1}}],["在处理词元序列时",{"2":{"398":1}}],["在处理任何一个小批量数据之前",{"2":{"335":1}}],["在处理生物医学文献时",{"2":{"292":1}}],["在处理概率时",{"2":{"241":1}}],["在处理多通道输入数据时",{"2":{"148":1}}],["在仿射变换之后对每个隐藏单元应用非线性的激活函数",{"2":{"232":1}}],["在所有实际上有恶性肿瘤的病人中",{"2":{"1139":1,"1140":1}}],["在所有我们预测有恶性肿瘤的病人中",{"2":{"1139":1,"1140":1}}],["在所有情况下都预测肿瘤是良性的",{"2":{"1139":1}}],["在所有的锚框和真实边界框配对中",{"2":{"853":1}}],["在所有其他情况下",{"2":{"1034":1}}],["在所有其他条件相同的情况下",{"2":{"740":1}}],["在所有其他参数保持不变的情况下",{"2":{"223":1}}],["在所有输出通道上执行最大时间汇聚层",{"2":{"701":1}}],["在所有时间步的编码器隐状态同时视为键和值",{"2":{"377":1}}],["在所有侧边填充1个像素",{"2":{"141":1}}],["在撰写本文时",{"2":{"213":1}}],["在将数据提供给模型之前",{"2":{"208":1}}],["在整本书中",{"2":{"206":1}}],["在整个语料库的同一上下文窗口中的全局共现计数",{"2":{"742":1}}],["在整个语料库中",{"2":{"742":1}}],["在整个人类历史中",{"2":{"354":1}}],["在整个训练过程中",{"2":{"212":1}}],["在整个训练过程的每一次迭代中",{"2":{"170":1}}],["在整个卷积块中",{"2":{"136":1}}],["在建模纠正过程中",{"2":{"201":1}}],["在设计决策方式时考虑到这些社会价值",{"2":{"201":1}}],["在环境能够改变的情况下可能不会始终有效",{"2":{"200":1}}],["在静止环境中可能一直有效的相同策略",{"2":{"200":1}}],["在在线学习",{"2":{"196":1}}],["在线性回归中我们有一个像这样的训练集",{"2":{"1064":1}}],["在线性代数中",{"2":{"1000":1}}],["在线",{"2":{"196":1}}],["在线学习的一个优点就是",{"2":{"1168":1}}],["在线学习的算法与随机梯度下降算法有些类似",{"2":{"1168":1}}],["在线学习机制让我们可以模型化问题",{"2":{"1168":1}}],["在线学习",{"0":{"196":1,"1168":1},"2":{"1193":1}}],["在一般的线性回归模型中",{"2":{"1188":1}}],["在一般的高斯分布模型中",{"2":{"1184":1}}],["在一定条件下",{"2":{"1141":1}}],["在一起",{"2":{"1018":1}}],["在一维情况下",{"2":{"699":1}}],["在一种方法中",{"2":{"615":1}}],["在一次迭代中",{"2":{"334":1}}],["在一系列的时间步骤上与环境交互",{"2":{"298":1}}],["在一系列开创性的论文中",{"2":{"253":1}}],["在一对输入上进行基本逻辑操作",{"2":{"233":1}}],["在一些初步研究中",{"2":{"467":1}}],["在一些敏感应用中",{"2":{"284":1}}],["在一些测试数据上应用这个模型",{"2":{"221":1}}],["在一些情况下",{"2":{"189":1}}],["在一天结束时",{"2":{"196":1}}],["在一个基于内容的推荐系统算法中",{"2":{"1188":1}}],["在一个典型的监督学习中",{"2":{"1150":1}}],["在一个英文句子特定的位置",{"2":{"1141":1}}],["在一个小批量上实现多gpu训练",{"2":{"837":1}}],["在一个小批量中使用更大的观测值集",{"2":{"32":1}}],["在一个2",{"2":{"815":1}}],["在一个大型语料库中",{"2":{"741":1}}],["在一个词典上",{"2":{"707":1}}],["在一个数据集上",{"2":{"286":1}}],["在一个倒置图像后依然保留类别的世界里",{"2":{"230":1}}],["在一个问题突然从",{"2":{"193":1}}],["在一个经典的情景中",{"2":{"180":1}}],["在第二种情况下",{"2":{"1025":1}}],["在第二个结点将本地的梯度与传送的梯度相加并发送到第三个节点",{"2":{"842":1}}],["在第二个全连接层之后添加一个dropout层",{"2":{"174":4,"176":4}}],["在第二次迭代中",{"2":{"757":1}}],["在第一种情况中",{"2":{"1025":1,"1143":1}}],["在第一张样本图像中",{"2":{"945":1}}],["在第一次迭代中",{"2":{"757":1}}],["在第一次迭代或使用随机抽样时初始化state",{"2":{"335":4}}],["在第一层",{"2":{"459":1}}],["在第一个分配完成后",{"2":{"851":1}}],["在第一个最低位",{"2":{"399":1}}],["在第一个全连接层之后添加一个dropout层",{"2":{"174":4,"176":4}}],["在第六章定义",{"2":{"137":4}}],["在激活函数之后",{"2":{"174":1}}],["在毕晓普的工作中",{"2":{"170":1}}],["在探究泛化性之前",{"2":{"170":1}}],["在概率角度看",{"2":{"168":1}}],["在前一页幻灯片上",{"2":{"1145":1}}],["在前一时间步生成的词元",{"2":{"534":1}}],["在前向推断中",{"2":{"736":1}}],["在前向传播中",{"2":{"480":1,"535":1,"763":1}}],["在前向传播函数中执行代码",{"0":{"425":1}}],["在前向传播期间",{"2":{"244":1}}],["在前向传播期间计算正则项",{"2":{"165":1}}],["在前面",{"2":{"624":1}}],["在前面的课程中",{"2":{"1139":1}}],["在前面的部分中",{"2":{"246":1}}],["在前面的例子中",{"2":{"142":1}}],["在前面的例子",{"2":{"140":1}}],["在前面的章节中",{"2":{"112":1,"134":1,"251":1}}],["在前两个卷积层之后",{"2":{"461":3}}],["在进一步讨论之前",{"2":{"156":1}}],["在进行特定编程的情况下",{"2":{"1059":1}}],["在进行任何预测之前",{"2":{"336":1}}],["在进行正向和反向传播之前",{"2":{"137":1}}],["在进行凸分析之前",{"2":{"39":1}}],["在计算微分求导项时",{"2":{"1069":1}}],["在计算关于x的梯度后",{"2":{"974":1}}],["在计算仍在进行中",{"2":{"846":1}}],["在计算注意力权重时",{"2":{"683":1}}],["在计算平均值和方差时",{"2":{"470":1}}],["在计算编码器的自注意力时",{"2":{"404":1}}],["在计算期间会缓存中间值",{"2":{"313":1}}],["在计算机视觉里",{"2":{"857":1}}],["在计算机视觉中广泛流行的resnet",{"2":{"422":1}}],["在计算机视觉中",{"2":{"302":1,"454":1}}],["在计算机视觉的背景下",{"2":{"72":1}}],["在计算上",{"2":{"299":1}}],["在计算广告中",{"2":{"193":1}}],["在计算图",{"2":{"164":1}}],["在计算梯度时",{"2":{"161":1}}],["在计算互相关时",{"2":{"142":1}}],["在如下示例中",{"2":{"141":1}}],["在如上例子中",{"2":{"126":1}}],["在底部填充",{"2":{"141":1}}],["在应用越来越复杂的函数序列后",{"2":{"479":1}}],["在应用批量规范化时",{"2":{"467":1}}],["在应用多层卷积时",{"2":{"141":1}}],["在应用了连续的卷积之后",{"2":{"140":1}}],["在下采样之后",{"2":{"773":1}}],["在下游任务的监督学习过程中",{"2":{"733":1}}],["在下游应用的监督学习期间",{"2":{"656":1,"661":1}}],["在下面也就是左下方",{"2":{"1127":1}}],["在下面定义了变量bbox",{"2":{"848":1}}],["在下面",{"2":{"686":1,"757":1,"917":1,"953":1,"954":1,"959":1,"964":1,"981":1}}],["在下面的视频中",{"2":{"1091":1}}],["在下面的birnn类中",{"2":{"713":1}}],["在下面的部分中",{"2":{"606":1}}],["在下面的循环训练过程中",{"2":{"576":1}}],["在下面的解码器接口中",{"2":{"534":1}}],["在下面的几个章节中",{"2":{"506":1}}],["在下面的章节中",{"2":{"451":1}}],["在下面的代码片段中",{"2":{"423":1}}],["在下面的代码中",{"2":{"172":1,"278":3,"507":1,"599":1,"600":1,"601":1,"873":1,"977":1,"999":1}}],["在下面的代码中的pool2d函数",{"2":{"146":1}}],["在下面的查询x和键xi之间的距离乘以可学习参数w",{"2":{"389":1}}],["在下面的讨论中",{"2":{"162":1}}],["在下面的例子中",{"2":{"141":1,"425":1,"436":1,"480":1,"591":1,"1018":1,"1021":1}}],["在下面的实现中",{"2":{"91":1,"382":1,"405":1}}],["在下面的示例中",{"2":{"72":1,"880":1,"970":2}}],["在下一段视频中",{"2":{"1069":1}}],["在下一节我们",{"2":{"1145":1}}],["在下一节课中",{"2":{"1144":1}}],["在下一节视频中",{"2":{"1066":1}}],["在下一节中",{"2":{"335":1,"535":1}}],["在下一个视频",{"2":{"1111":1}}],["在下一个视频中",{"2":{"1061":1,"1109":1,"1150":1}}],["在下一个视频里",{"2":{"1059":1}}],["在下一步中",{"2":{"675":1}}],["在下一章中",{"2":{"134":1}}],["在下文中",{"2":{"306":1,"688":1,"719":1}}],["在每台机器上读取一组",{"2":{"843":1}}],["在每个多尺度特征块上",{"2":{"959":1}}],["在每个gpu上分别更新模型参数",{"2":{"837":3}}],["在每个gpu上分别计算损失",{"2":{"837":3}}],["在每个bert输入序列中",{"2":{"722":1}}],["在每个预测位置",{"2":{"721":1}}],["在每个迭代周期结束时",{"2":{"635":1}}],["在每个迭代周期",{"2":{"605":1}}],["在每个迭代周期里",{"2":{"595":1}}],["在每个时间步",{"2":{"513":1,"575":1}}],["在每个像素的通道上分别使用多层感知机",{"2":{"493":1}}],["在每个模块之间",{"2":{"482":1}}],["在每个解码步中",{"2":{"376":1}}],["在每个解码步骤中仍使用编码相同的上下文变量",{"2":{"373":1}}],["在每个解码时间步骤中",{"2":{"375":1}}],["在每个特定时间点",{"2":{"298":1}}],["在每个步骤中",{"2":{"287":1}}],["在每个样本中",{"2":{"208":1,"687":1}}],["在每一个单独的梯度下降中",{"2":{"1069":1}}],["在每一个小批量之后更新模型f的参数",{"2":{"190":1}}],["在每一步中",{"2":{"604":1}}],["在每一层中多通道",{"2":{"134":1}}],["在每次更新时几乎不会移动",{"2":{"241":1}}],["在每次训练迭代中",{"2":{"170":1,"467":1}}],["在每次迭代中可以随机抽样一个较短的子序列来计算该子序列的",{"2":{"784":1}}],["在每次迭代中",{"2":{"129":1,"583":1,"605":1,"613":1,"694":1,"743":1}}],["在卷积神经网络中",{"2":{"131":1,"138":1}}],["在卷积层中",{"2":{"126":1}}],["在水平和垂直翻转之后将与k相同",{"2":{"130":1}}],["在训练完算法后",{"2":{"1189":1}}],["在训练单发多框检测模型时",{"2":{"965":1}}],["在训练开始之前",{"2":{"893":1}}],["在训练word2vec模型之后",{"2":{"768":1}}],["在训练带负采样的跳元模型之前",{"2":{"764":1}}],["在训练集中",{"2":{"850":1,"855":1}}],["在训练集中训练的模型将不知道来自测试集的任何新词元",{"2":{"669":1}}],["在训练集的损失函数中加入惩罚项",{"2":{"279":1}}],["在训练softmax回归模型后",{"2":{"653":1}}],["在训练我们的模型时",{"2":{"615":1}}],["在训练了预先确定的若干迭代次数后",{"2":{"613":1}}],["在训练中",{"2":{"580":1,"784":1}}],["在训练resnet之前",{"2":{"502":1}}],["在训练之前",{"2":{"489":1}}],["在训练阶段",{"2":{"408":1}}],["在训练模型进行风格迁移时",{"2":{"927":1}}],["在训练模型时",{"2":{"611":1,"963":1}}],["在训练模型之前",{"2":{"326":1,"335":1}}],["在训练模式和预测模式下计算不同",{"2":{"476":1}}],["在训练模式下计算x的均值和方差",{"2":{"406":3}}],["在训练数据中标注锚框",{"0":{"850":1},"1":{"851":1,"852":1,"853":1}}],["在训练数据上表现良好的模型",{"2":{"286":1}}],["在训练数据集中",{"2":{"284":1,"900":1}}],["在训练参数化机器学习模型时",{"2":{"270":1}}],["在训练时始终要尊重其时间顺序",{"2":{"352":1}}],["在训练时",{"2":{"176":1}}],["在训练过程中数据类型过小导致的数值溢出可能是个问题",{"2":{"814":1}}],["在训练过程中可以迭代加载",{"2":{"776":1}}],["在训练过程中",{"2":{"170":1,"341":1,"439":1,"467":1}}],["在训练深度学习模型时",{"2":{"166":1}}],["在训练神经网络时",{"2":{"165":2}}],["在训练基于卷积层的模型时",{"2":{"127":1}}],["在训练期间不要更新它们",{"2":{"876":1}}],["在训练期间存在许多小记录时",{"2":{"806":1}}],["在训练期间",{"2":{"522":1,"872":1,"892":1}}],["在训练期间降低学习率有助于训练",{"2":{"82":1}}],["在训练期间逐步降低学习率可以提高准确性",{"2":{"74":1}}],["在高斯核函数之外我们还有其他一些选择",{"2":{"1148":1}}],["在高斯噪声的假设下",{"2":{"616":1}}],["在高度和宽度上将图像放大到40像素的正方形",{"2":{"891":3}}],["在高度和宽度维度上",{"2":{"122":1}}],["在高端服务器上可能用到更高级的互连",{"2":{"801":1}}],["在高维模型中",{"2":{"63":1}}],["在互相关运算中",{"2":{"121":1}}],["在最终预测之前",{"2":{"892":1}}],["在最初的vgg论文中",{"2":{"507":1}}],["在最坏的情况下",{"2":{"342":1,"815":1}}],["在最好的情况下",{"2":{"342":1}}],["在最后这段视频中",{"2":{"1176":1}}],["在最后一层",{"2":{"713":1}}],["在最后一步中",{"2":{"676":1}}],["在最后一个卷积层后有两个全连接层",{"2":{"459":1}}],["在最后一个迭代周期完成后",{"2":{"265":1}}],["在最后添加一个批处理维度",{"2":{"584":1}}],["在最后的时间步t",{"2":{"312":1}}],["在最早的神经网络中",{"2":{"236":1}}],["在最流行的神经网络架构中",{"2":{"121":1}}],["在最多384位的gpu上",{"2":{"77":1}}],["在谈论随机梯度下降时",{"2":{"116":1}}],["在函数外部定义",{"2":{"114":2}}],["在x上分别标出这两个兴趣区域x",{"2":{"938":1}}],["在x轴上缩放步长",{"2":{"848":3}}],["在x86上被称为avx2",{"2":{"809":1}}],["在x接近0时",{"2":{"479":1}}],["在x中都是凸的",{"2":{"115":1}}],["在x处的值是整个域中目标函数的最小值",{"2":{"101":1}}],["在x1方向上",{"2":{"88":1}}],["在深入使用之前",{"2":{"1360":1}}],["在深入研究形式体系和算法之前",{"2":{"184":1}}],["在深入研究它的数学属性之前",{"2":{"88":1}}],["在深度网络中",{"2":{"841":1}}],["在深度网络中存在许多参数组合能够实现高度精确的预测",{"2":{"605":1}}],["在深度循环神经网络中",{"2":{"530":1}}],["在深度学习框架中查找任何函数或类的文档",{"2":{"1009":1}}],["在深度学习框架中实现的内置迭代器效率要高得多",{"2":{"600":1}}],["在深度学习的早期",{"2":{"832":1}}],["在深度学习的背景下",{"2":{"51":1}}],["在深度学习环境中",{"2":{"426":4}}],["在深度学习研究社区中",{"2":{"155":1}}],["在深度学习问题上",{"2":{"30":1}}],["在深度学习问题中",{"2":{"30":1}}],["在深度学习中",{"2":{"26":1,"27":1,"100":1,"113":1,"192":1,"395":1,"642":1,"824":1,"980":1,"981":1,"982":1,"1001":1,"1003":1}}],["在深层神经网络中",{"2":{"504":1}}],["在梯度下降算法还没有完成一次迭代时",{"2":{"1165":1}}],["在梯度下降算法中",{"2":{"1067":3}}],["在梯度下降法中",{"2":{"1068":1}}],["在梯度下降中",{"2":{"54":1,"1069":1}}],["在梯度振荡的x2方向",{"2":{"88":1}}],["在优化的过程中",{"2":{"262":1}}],["在优化中",{"2":{"98":1}}],["在优化问题条件不佳的情况下",{"2":{"86":1}}],["在优化算法的设计中起到至关重要的作用",{"2":{"38":1}}],["在里面我们执行相同的矩阵",{"2":{"78":1}}],["在凸优化的情况下",{"2":{"114":1}}],["在凸二次问题中",{"2":{"96":1}}],["在凸问题背景下设计和分析算法是非常有启发性的",{"2":{"65":1}}],["在凸集x上的投影被定义为",{"2":{"50":1}}],["在区间",{"2":{"64":1}}],["在此过程中vue会在合适的时机",{"2":{"1470":1}}],["在此之后",{"2":{"1129":1,"1154":1}}],["在此之前",{"2":{"722":1}}],["在此之前已经描述并实现了基于缩放点积多头注意力",{"2":{"404":1}}],["在此等式中",{"2":{"989":1}}],["在此操作期间",{"2":{"810":1}}],["在此实现中",{"2":{"414":1}}],["在此时",{"2":{"235":1}}],["在此表示的基础上建立一个线性模型可能会是合适的",{"2":{"230":1}}],["在此期间学习率将增加至初始最大值",{"2":{"73":1}}],["在此",{"2":{"60":1}}],["在此情况下由于不常出现的问题",{"2":{"30":1}}],["在ϵ的二阶项中",{"2":{"57":1}}],["在本课中",{"2":{"1143":1}}],["在本次课程中",{"2":{"1138":1}}],["在本次视频中",{"2":{"1111":1}}],["在本视频中",{"2":{"1059":1}}],["在本书中也是如此",{"2":{"990":1}}],["在本例子中",{"2":{"357":1}}],["在本例中只有一个输出",{"2":{"618":1}}],["在本例中",{"2":{"50":1,"212":1,"282":1,"340":1}}],["在本质上",{"2":{"345":1}}],["在本情况中",{"2":{"172":8}}],["在本章的结尾",{"2":{"987":1}}],["在本章的其余部分",{"2":{"733":1}}],["在本章的前面几节中",{"2":{"685":1}}],["在本章的前几节中",{"2":{"656":1}}],["在本章的最后",{"2":{"134":1,"204":1}}],["在本章的开始",{"2":{"134":1}}],["在本章中的每一个模型都曾一度占据主导地位",{"2":{"492":1}}],["在本章中",{"2":{"65":1,"66":1,"204":1,"421":1,"658":1,"691":1,"754":1}}],["在本节课中",{"2":{"1145":1}}],["在本节课中关于大间距分类器",{"2":{"1144":1}}],["在本节视频中我想介绍一下怎样用你学过的算法来评估假设函数",{"2":{"1130":1}}],["在本节视频中",{"2":{"1112":1,"1180":1}}],["在本节中",{"2":{"879":1}}],["在本节中的实验中",{"2":{"144":1}}],["在本节定义的run函数中执行了八个操作",{"2":{"799":1}}],["在本节稍后的内容会讲到",{"2":{"646":1}}],["在本节训练模型中",{"2":{"531":1}}],["在本节的其余部分中",{"2":{"1028":1}}],["在本节的hybridnet类的hybrid",{"2":{"823":1}}],["在本节的实验中",{"2":{"366":1}}],["在本节的估计问题中使用λ的值进行实验",{"2":{"280":1}}],["在本节的简单示例中",{"2":{"116":1}}],["在本节讨论之前",{"2":{"32":1}}],["在投影期间保持不变",{"2":{"50":1}}],["在实例化时被随机初始化",{"2":{"425":1}}],["在实现softmax回归模型之前",{"2":{"631":1}}],["在实现中",{"2":{"603":1}}],["在实现编码器和解码器时",{"2":{"579":1}}],["在实现我们自定义块之前",{"2":{"423":1}}],["在实现过程中通常",{"2":{"382":1}}],["在实现多头注意力之前",{"2":{"381":1}}],["在实践的难度上差别很大",{"2":{"352":1}}],["在实践中请注意",{"2":{"833":1}}],["在实践中经常会有这样一个判别",{"2":{"811":1}}],["在实践中这种极端的偏移是罕见的",{"2":{"193":1}}],["在实践中我们执行后者",{"2":{"116":1}}],["在实践中我们选择一个足够大的小批量",{"2":{"78":1}}],["在实践中融合",{"2":{"77":4}}],["在实践中",{"2":{"49":1,"51":1,"142":1,"202":1,"270":1,"308":1,"309":1,"341":1,"370":1,"380":1,"495":1,"752":1,"754":1,"844":1,"848":1,"881":1,"938":1}}],["在实际项目中应用这些概念",{"2":{"1436":1}}],["在实际使用中",{"2":{"1179":1}}],["在实际训练和测试中",{"2":{"890":1}}],["在实际操作中甚至可以在某个gpu上聚合其中一些参数",{"2":{"841":1}}],["在实际中",{"2":{"252":1}}],["在实际应用中",{"2":{"25":1,"256":1,"843":1,"1148":1}}],["在实验中为10−4",{"2":{"773":1}}],["在实验中训练更深的transformer将如何影响训练速度和翻译效果",{"2":{"411":1}}],["在实验中用lstm替换gru",{"2":{"378":1}}],["在实验中调整模型架构或超参数时会发现",{"2":{"251":1}}],["在实验中方便起见",{"2":{"75":1}}],["在实验中",{"2":{"74":1,"110":1,"728":1,"729":1}}],["在聚类中y可能是簇标签",{"2":{"42":1}}],["在",{"0":{"896":1},"2":{"32":5,"40":1,"44":1,"66":1,"78":1,"84":1,"99":1,"100":1,"120":1,"126":1,"127":1,"141":1,"168":1,"208":1,"228":1,"259":1,"270":1,"306":1,"307":1,"315":1,"319":1,"338":1,"339":1,"388":1,"422":1,"445":1,"461":1,"467":1,"491":1,"500":1,"512":2,"513":1,"517":2,"522":1,"538":1,"559":1,"572":2,"579":1,"588":1,"610":1,"618":2,"622":1,"639":3,"644":1,"651":1,"656":1,"663":2,"664":1,"674":1,"675":1,"688":1,"698":1,"721":2,"727":1,"731":1,"732":1,"736":1,"742":2,"743":1,"744":1,"747":1,"763":1,"781":1,"785":1,"811":1,"828":3,"837":3,"840":1,"856":1,"879":1,"886":1,"889":1,"901":1,"905":1,"911":1,"912":1,"913":2,"915":1,"943":1,"952":1,"959":1,"968":1,"972":1,"992":1,"994":1,"1012":1,"1035":1,"1038":1,"1085":1,"1093":1,"1094":1,"1110":1,"1159":1,"1166":1,"1184":1,"1214":1,"1296":1,"1372":1}}],["在这门课程的早些时候",{"2":{"1150":1}}],["在这门课中",{"2":{"1058":3,"1098":1,"1176":1}}],["在这节课中",{"2":{"1140":1,"1180":1}}],["在这节视频和之后的几段视频中",{"2":{"1129":1}}],["在这样的句子中",{"2":{"1141":1}}],["在这样分析之后",{"2":{"1138":1}}],["在这样做时",{"2":{"302":1}}],["在这样做的过程中",{"2":{"94":1}}],["在这条单行道上训练出的网络将被最终用于控制车辆方向",{"2":{"1127":1}}],["在这时候已经选出了一个明确的行驶方向",{"2":{"1127":1}}],["在这部分视频中",{"2":{"1127":1}}],["在这段关于",{"2":{"1089":1}}],["在这段视频中谈谈正规方程",{"2":{"1086":1}}],["在这段视频中我们将定义代价函数的概念",{"2":{"1064":1}}],["在这段视频中",{"2":{"1060":1,"1063":1,"1069":1,"1088":1,"1090":1,"1091":1,"1092":1,"1093":1,"1094":1,"1098":1,"1107":1,"1109":1,"1110":1,"1114":1,"1122":1,"1123":1,"1127":1,"1132":1,"1141":1,"1180":1,"1183":1,"1185":1}}],["在这儿",{"2":{"1068":1}}],["在这五个模块中",{"2":{"959":1}}],["在这场比赛中",{"2":{"899":1}}],["在这场kaggle竞赛中使用完整的cifar",{"2":{"898":1}}],["在这两个向量中可能得到不同的值",{"2":{"743":1}}],["在这两个数据集中",{"2":{"691":1}}],["在这两种情况下",{"2":{"146":1,"1025":1}}],["在这一部分",{"2":{"1144":1}}],["在这一系列的视频中我们将介绍具体的诊断法",{"2":{"1129":1}}],["在这一过程中只使用张量和自动微分",{"2":{"606":1}}],["在这一节中",{"2":{"598":2}}],["在这种email客户端中",{"2":{"1059":1}}],["在这种网络中",{"2":{"499":1}}],["在这种情况下绘制测试的损失图",{"2":{"268":1}}],["在这种情况下",{"2":{"26":1,"55":1,"77":1,"88":1,"101":1,"115":1,"131":1,"160":1,"191":1,"193":1,"198":1,"230":1,"244":2,"247":1,"252":1,"266":1,"291":1,"295":2,"334":2,"342":3,"418":1,"449":1,"538":2,"652":1,"743":1,"783":1,"791":1,"841":1,"842":1,"1028":1,"1034":1,"1098":1,"1141":1}}],["在这本书中",{"2":{"278":1}}],["在这些不同的电影中与我们要找的电影",{"2":{"1191":1}}],["在这些问题里",{"2":{"1168":1}}],["在这些假设下有大量我们认为有用的训练集",{"2":{"1141":1}}],["在这些视频中",{"2":{"1059":1}}],["在这些向量的格拉姆矩阵xx⊤∈rc×c中",{"2":{"923":1}}],["在这些社区中会发现更多的犯罪行为",{"2":{"201":1}}],["在这些情况下",{"2":{"182":1,"281":1,"286":1,"290":1,"295":1,"412":1,"624":1,"1028":1}}],["在这个两个地方",{"2":{"1148":1}}],["在这个决策界之下",{"2":{"1145":1}}],["在这个情形下我们仍然有utv是等于p乘以u的范数",{"2":{"1145":1}}],["在这个等式中u的范数是一个实数",{"2":{"1145":1}}],["在这个以及接下来的几个视频中",{"2":{"1106":1}}],["在这个绿点",{"2":{"1068":1}}],["在这个绿色的点",{"2":{"1068":1}}],["在这个表达式中",{"2":{"1067":1}}],["在这个视频中我将要讨论到为了运行或者运用svm",{"2":{"1148":1}}],["在这个视频中",{"2":{"1109":1,"1141":1,"1150":1,"1168":1,"1179":1}}],["在这个视频里",{"2":{"1065":1}}],["在这个视野变化所导致的结果中",{"2":{"201":1}}],["在这个设定中",{"2":{"1059":1}}],["在这个博客中",{"2":{"1056":1}}],["在这个意义上",{"2":{"991":1}}],["在这个实验中",{"2":{"981":1}}],["在这个数据集中",{"2":{"837":1}}],["在这个系统中",{"2":{"780":1}}],["在这个预训练任务中",{"2":{"736":1}}],["在这个简单的",{"2":{"566":1}}],["在这个简化模型中",{"2":{"307":1}}],["在这个将英语翻译成法语的机器翻译问题中",{"2":{"565":1}}],["在这个fixedhiddenmlp模型中",{"2":{"425":1}}],["在这个mlp实现中",{"2":{"423":1}}],["在这个框架中",{"2":{"355":1}}],["在这个幂中",{"2":{"312":1}}],["在这个过程中",{"2":{"228":1}}],["在这个模型中",{"2":{"198":1}}],["在这个循环中",{"2":{"196":1}}],["在这个游戏中包含了许多充斥着活动的混乱场景",{"2":{"152":1}}],["在这个例子中",{"2":{"80":1,"422":4,"593":1,"853":1,"1141":1}}],["在这个问题中",{"2":{"48":1,"191":1}}],["在这里的监督学习中",{"2":{"1150":1}}],["在这里非常小",{"2":{"1145":1}}],["在这里我将忽略θ0",{"2":{"1145":1}}],["在这里我们将m去掉",{"2":{"1188":1}}],["在这里我们有一系列点",{"2":{"1150":1}}],["在这里我们认为标准假设成立",{"2":{"599":1}}],["在这里我们使用hi",{"2":{"86":1}}],["在这里我们使用了x=ux",{"2":{"26":1}}],["在这里是一条直线",{"2":{"1143":1}}],["在这里具有不同中心的锚框不会重叠",{"2":{"912":1}}],["在这里也可以称为梯度",{"2":{"613":1}}],["在这里使用sequential会让你熟悉",{"2":{"591":1}}],["在这里嵌套",{"2":{"433":4}}],["在这里生成了50个训练样本和50个测试样本",{"2":{"386":1}}],["在这里训练误差增大",{"2":{"277":1}}],["在这里",{"2":{"27":1,"164":1,"293":1,"320":2,"342":1,"350":2,"409":1,"422":1,"436":2,"541":1,"592":2,"613":1,"625":1,"635":1,"669":1,"772":1,"819":1,"837":3,"858":1,"873":1,"882":1,"890":1,"893":1,"905":1,"1017":1,"1018":1,"1063":1,"1143":1,"1144":1}}],["在这里sequential并不是必要的",{"2":{"623":1}}],["在这里s",{"2":{"25":1}}],["在新的坐标系中",{"2":{"26":1}}],["其它",{"0":{"1509":1},"1":{"1510":1,"1511":1,"1512":1,"1513":1,"1514":1,"1515":1,"1516":1,"1517":1,"1518":1,"1519":1,"1520":1}}],["其它情况",{"2":{"597":1}}],["其基本结构如下",{"2":{"1364":1}}],["其基本思想是",{"2":{"1060":1}}],["其每一个单元都是原特征矩阵中一行数据的均值",{"2":{"1184":1}}],["其原因在于",{"2":{"1184":1}}],["其原理如下",{"2":{"467":1}}],["其属于该组数据的可能性就越低",{"2":{"1178":1}}],["其方法为",{"2":{"1151":1}}],["其计算公式为",{"2":{"1140":1}}],["其计算结果为真",{"2":{"1088":1}}],["其查全率是0",{"2":{"1139":1}}],["其类别有四个",{"2":{"1112":1}}],["其尺寸为",{"2":{"1099":1}}],["其尺寸和它所标注的输入图像的尺寸相同",{"2":{"945":1}}],["其矩阵的元素是1",{"2":{"1088":1}}],["其返回值为1",{"2":{"1088":1}}],["其返回词内最频繁的连续符号对",{"2":{"757":1}}],["其目标是推出一组离散的结果",{"2":{"1060":1}}],["其概率表示为p",{"2":{"1028":1}}],["其概率从不会是负数",{"2":{"1027":1}}],["其值在掷骰子的样本空间s=",{"2":{"1028":1}}],["其值为0或1",{"2":{"209":1}}],["其",{"2":{"1000":1}}],["其范数也会按相同常数因子的绝对值缩放",{"2":{"1000":1}}],["其长度",{"2":{"998":3}}],["其长度由超参数num",{"2":{"734":1}}],["其第i个元素是点积ai⊤x",{"2":{"998":1}}],["其第一个词元可能会对最后位置的词元产生重大影响",{"2":{"306":1}}],["其形状与另一个y相同",{"2":{"1021":1}}],["其形状将变为正方形",{"2":{"992":1}}],["其形状为",{"2":{"325":1,"495":4,"573":1,"713":3}}],["其由m行和n列的实值标量组成",{"2":{"992":1}}],["其分量为最近的生命体征",{"2":{"990":1}}],["其分量与其收入",{"2":{"990":1}}],["其分量是多变量函数相对于其所有变量的偏导数",{"2":{"985":1}}],["其后的2×2的最大汇聚层将输入特征图的高度和宽度减少了一半",{"2":{"957":1}}],["其后是几个多尺度特征块",{"2":{"953":1}}],["其语义区域的标注和预测是像素级的",{"2":{"943":1}}],["其有c行和hw列",{"2":{"923":1}}],["其有效带宽为100mb",{"2":{"841":1}}],["其图像大于",{"2":{"903":1}}],["其格式符合kaggle竞赛的要求",{"2":{"896":1}}],["其策略用于处理显存非常小",{"2":{"832":1}}],["其本质仍然是一个困难的问题",{"2":{"832":1}}],["其好处是提高了计算性能",{"2":{"822":1}}],["其访问速度非常快",{"2":{"810":1}}],["其ipc",{"2":{"810":1}}],["其最多可以使用4个pcie通道",{"2":{"805":1}}],["其上下文词context和其噪声词negative组成的样本",{"2":{"776":1}}],["其上下文字向量为un",{"2":{"709":1}}],["其幂为0",{"2":{"775":1}}],["其向量表示可以从嵌入层中的权重矩阵的第i行获得",{"2":{"762":1}}],["其向量与vec",{"2":{"751":1}}],["其取决于x及其上下文c",{"2":{"731":1}}],["其仅将x作为其输入",{"2":{"731":1}}],["其词元数量分别为m和n",{"2":{"674":1}}],["其对数称为对数",{"2":{"631":1}}],["其对应的标签是y",{"2":{"609":1}}],["其正态分布概率密度函数如下",{"2":{"616":1}}],["其相应的真实标签为y",{"2":{"611":1}}],["其通道数为1",{"2":{"582":1}}],["其列数等于特征向量的维度",{"2":{"573":1}}],["其行数等于字典大小",{"2":{"762":1}}],["其行数等于输入词表的大小",{"2":{"573":1}}],["其行为与深度学习框架中的任何现有层不同",{"2":{"415":1}}],["其设计目的是用于记录附加的信息",{"2":{"552":1}}],["其主要原因是网络的前向传播需要在双向层中进行前向和后向递归",{"2":{"522":1}}],["其主要区别是",{"2":{"520":1}}],["其代码主要处理数据移动到训练设备",{"2":{"472":1}}],["其权重",{"2":{"425":1}}],["其具有256个隐藏单元的隐藏层和一个10维输出层",{"2":{"423":1}}],["其掩蔽自注意力设定了参数dec",{"2":{"408":1}}],["其整体架构图在",{"2":{"404":1}}],["其定义为",{"2":{"388":1}}],["其实ref接收的数据可以是",{"2":{"1457":1}}],["其实区别很小",{"2":{"1179":1}}],["其实不想有高度冗余的特征一样",{"2":{"1156":1}}],["其实也可以认为就是正确率",{"2":{"1154":1}}],["其实并没有差别",{"2":{"1145":1}}],["其实是一个很有效的指示器",{"2":{"1132":1}}],["其实我已经使用了很多年了",{"2":{"1122":1}}],["其实我从来都不去刻意记住这个",{"2":{"1090":1}}],["其实怎样标注都不会影响最后的结果",{"2":{"1112":1}}],["其实这是将这三个命令同时执行",{"2":{"1091":1}}],["其实就是预测误差乘以xj",{"2":{"1110":1}}],["其实就是一些微弱的电流",{"2":{"1099":1}}],["其实就是我的房屋价格数据",{"2":{"1089":1}}],["其实就等于",{"2":{"1090":1}}],["其实有好多种办法可以完成",{"2":{"1089":1}}],["其实例数称为其重数",{"2":{"742":1}}],["其实",{"2":{"375":1}}],["其实1×1卷积的唯一计算发生在通道上",{"2":{"122":1}}],["其自主性提示可能是什么",{"2":{"359":1}}],["其输入和输出都是标量",{"2":{"981":1}}],["其输入和输出都是长度可变的序列",{"2":{"532":1}}],["其输入data是长度等于批量大小的列表",{"2":{"776":1}}],["其输入表示为x",{"2":{"609":1}}],["其输入matrices的形状是",{"2":{"357":1}}],["其输出数是目标数据集中的类别数",{"2":{"870":1}}],["其输出通道数等于标签类别的数量",{"2":{"495":1}}],["其输出通道数分别是192+208+48+64=512",{"2":{"488":1}}],["其输出序列的词元是逐个生成的",{"2":{"408":1}}],["其输出序列的所有位置",{"2":{"408":1}}],["其输出由许多参数",{"2":{"282":1}}],["其输出如下",{"2":{"128":1}}],["其输出是标量",{"2":{"102":1}}],["其时间步从",{"2":{"351":6}}],["其在nn",{"2":{"423":2}}],["其在时间步t+k的预测输出是",{"2":{"352":1}}],["其在时间步t+k处的预测输出x^t+k",{"2":{"351":1}}],["其在隐藏层中的激活函数使用恒等映射",{"2":{"312":1}}],["其结果看起来仍然是可信的",{"2":{"351":1}}],["其特征值为λi",{"2":{"314":1}}],["其特征向量是固定长度的",{"2":{"284":1}}],["其研究的重点是如何自动找到合适的数据表示方式",{"2":{"303":1}}],["其一",{"2":{"300":1}}],["其核心是当今大多数网络中都可以找到的几个关键原则",{"2":{"299":1}}],["其性能也会逐步提高",{"2":{"281":1}}],["其元素都取相同的值",{"2":{"244":1}}],["其隐藏单元数为16",{"2":{"573":1}}],["其隐藏单元数是一个超参数h",{"2":{"369":1}}],["其隐藏变量是h",{"2":{"241":1}}],["其隐藏层包含5个隐藏单元",{"2":{"231":1}}],["其隐藏表示h在数学上是一个矩阵",{"2":{"153":1}}],["其余弦值为",{"2":{"1154":1}}],["其余的则用于测试",{"2":{"872":1}}],["其余的被称为正类锚框",{"2":{"852":1}}],["其余四个元素分别是预测边界框左上角和右下角的",{"2":{"854":1}}],["其余四个元素是左上角和右下角的",{"2":{"853":1}}],["其余部分和前面介绍的均方误差是一样的",{"2":{"616":1}}],["其余部分则由工程师进行大量调整",{"2":{"301":1}}],["其余部分作为训练数据",{"2":{"211":1}}],["其余像素为白色",{"2":{"128":1}}],["其他",{"0":{"1525":1}}],["其他改变",{"2":{"1441":1}}],["其他特征为距离",{"2":{"1168":1}}],["其他特征由浮点数表示",{"2":{"208":1}}],["其他元素为0",{"2":{"1090":1}}],["其他元素都会得到0",{"2":{"1090":1}}],["其他引用仍然会指向旧的内存位置",{"2":{"1021":1}}],["其他常量",{"2":{"1017":1}}],["其他教程和示例提供了本书之外的大量文档",{"2":{"1005":3}}],["其他三个维度都具有不同的尺寸",{"2":{"956":1}}],["其他在本质上是一样的",{"2":{"827":1}}],["其他部分是否会使用变量e和f",{"2":{"816":1}}],["其他词向量的梯度可以以相同的方式获得",{"2":{"784":1,"786":1}}],["其他所有分量设置为0",{"2":{"640":1}}],["其他知识以及偶然的发现",{"2":{"454":1}}],["其他的词元组合",{"2":{"318":1}}],["其他学习任务也有序列学习的应用",{"2":{"295":1}}],["其他类别会随着不同时间的用法而发生变化",{"2":{"183":1}}],["其他情况根据此模型的设计",{"2":{"170":1}}],["其他情况的输出为0",{"2":{"128":1}}],["其期望值保持不变",{"2":{"170":1}}],["其大小为2×2",{"2":{"131":1}}],["其感受野",{"2":{"131":1}}],["其标准差降低了b−12",{"2":{"78":1}}],["其任意一个下水平集",{"2":{"45":1}}],["其中μ这一个n维向量和",{"2":{"1185":1}}],["其中μ和σ分别表示均值和标准差",{"2":{"209":1}}],["其中欧式距离",{"2":{"1154":1}}],["其中$",{"2":{"1115":1,"1184":1}}],["其中θ0=−30",{"2":{"1101":1}}],["其中θ就是θ0",{"2":{"1093":1}}],["其中这句命令不打印任何东西",{"2":{"1088":1}}],["其中上标t代表矩阵转置",{"2":{"1080":1}}],["其中按梯度下降最快方向进行",{"2":{"1068":1}}],["其中就有基因学的理解应用",{"2":{"1061":1}}],["其中b只依赖于a",{"2":{"1038":1}}],["其中所有元素都设置为1",{"2":{"1017":1}}],["其中所有元素都设置为0",{"2":{"1017":1}}],["其中所有图像都具有相同的香蕉类",{"2":{"932":3}}],["其中插值法用一个替代值弥补缺失值",{"2":{"1012":1}}],["其中很多数学对于机器学习非常有用",{"2":{"1002":1}}],["其中张量的每个元素都将与标量相加或相乘",{"2":{"994":1}}],["其中张量的最后一个维度存储预测的词元分布",{"2":{"574":1}}],["其中3个轴对应于高度",{"2":{"993":1}}],["其中标量变量由普通小写字母表示",{"2":{"989":1}}],["其中标签是从集合痴呆轻度认知障碍健康",{"2":{"251":1}}],["其中表的行对应样本",{"2":{"987":1}}],["其中∇xf",{"2":{"983":1}}],["其中系数2是切线的斜率",{"2":{"981":1}}],["其中符号ddx和d是微分运算符",{"2":{"981":1}}],["其中后者不使用f",{"2":{"979":1}}],["其中后者通常是一个更简单的表达式",{"2":{"42":1}}],["其中非0元素来自卷积核k",{"2":{"970":1}}],["其中y2的高度和宽度是y1的一半",{"2":{"956":1}}],["其中y^j=exp⁡",{"2":{"643":1}}],["其中y^j是预测的概率分布",{"2":{"624":1}}],["其中y^=softmax",{"2":{"643":1}}],["其中索引为i",{"2":{"954":1}}],["其中索引i的样本由特征向量x",{"2":{"646":1}}],["其中0类是背景",{"2":{"954":1}}],["其中预测类别时使用softmax回归",{"2":{"938":1}}],["其中超参数d取决于模型设计",{"2":{"938":1}}],["其中超参数n可以由我们灵活指定",{"2":{"642":1}}],["其中m是数据集的任何图像中边界框可能出现的最大数量",{"2":{"932":1}}],["其中masks中的0",{"2":{"776":1}}],["其中max",{"2":{"763":1}}],["其中一种办法是使用更多的训练样本",{"2":{"1129":1}}],["其中一些甚至具有画笔笔触的细微纹理",{"2":{"927":1}}],["其中一个仪器测量结果的单位是英寸",{"2":{"1156":1}}],["其中一个可能会比另一个更加有效",{"2":{"1148":1}}],["其中一个选择是",{"2":{"1148":1}}],["其中一个我们要求你编写的文件是warmupexercise",{"2":{"1094":1}}],["其中一个原因是",{"2":{"605":1,"1098":1}}],["其中一个门用来从单元中输出条目",{"2":{"552":1}}],["其中向量xi代表了通道i上的风格特征",{"2":{"923":1}}],["其中ci",{"2":{"1018":1}}],["其中c",{"2":{"915":1}}],["其中c为某个常数",{"2":{"351":1}}],["其中c为某些常数",{"2":{"59":1}}],["其中c为某常数",{"2":{"56":1}}],["其中靠近输出层的特征图单元具有更宽的感受野",{"2":{"913":1}}],["其中不同组锚框具有不同的中心",{"2":{"913":1}}],["其中不同的总线具有不同的带宽",{"2":{"841":1}}],["其中文件夹train",{"2":{"901":1}}],["其中训练集包含50000张",{"2":{"888":1}}],["其中阈值设置为0",{"2":{"854":1}}],["其中常量的默认值为",{"2":{"852":1}}],["其中前者为data的前两列",{"2":{"1012":1}}],["其中前者是与锚框相关的对象的类别",{"2":{"850":1}}],["其中前两个块各有一个卷积层",{"2":{"508":1}}],["其中gijk是在工作节点k的gpuj上拆分的梯度i的一部分",{"2":{"844":1}}],["其中g是一个可以学习的函数",{"2":{"519":1}}],["其中将有40毫秒的惩罚",{"2":{"841":1}}],["其中之一是gpu不太擅长处理稀疏数据和中断",{"2":{"811":1}}],["其中之一是mxnet支持不同的硬件设备",{"2":{"445":1}}],["其中可以省略小于1或大于t的任何时间步",{"2":{"783":1}}],["其中可学习的参数是wq∈rh×q",{"2":{"369":1}}],["其中时间步t处的词表示为w",{"2":{"783":1,"785":1}}],["其中出现次数少于10次的任何单词都将由",{"2":{"772":1}}],["其中词表索引集v=",{"2":{"783":1}}],["其中词来自输入词典token",{"2":{"757":1}}],["其中词的表征取决于它们的上下文",{"2":{"731":1}}],["其中子词是一个字符n",{"2":{"756":1}}],["其中元素j",{"2":{"742":1}}],["其中基本模型有1",{"2":{"728":1}}],["其中在任意标点符号及其前面的词元之间插入空格",{"2":{"718":1}}],["其中函数σ在",{"2":{"709":1}}],["其中函数f是在下面的mlp函数中定义的多层感知机",{"2":{"674":1}}],["其中树的每个叶节点表示词表v中的一个词",{"2":{"709":1}}],["其中σ使用了sigmoid激活函数的定义",{"2":{"708":1}}],["其中卷积核的高度必须与输入张量的高度相同",{"2":{"699":1}}],["其中a$是学习率",{"2":{"1068":1}}],["其中a是学习率",{"2":{"1067":1}}],["其中ai",{"2":{"674":1}}],["其中a表示注意力评分函数",{"2":{"367":1}}],["其中理想情况下较大的权重与要对齐的词元相关联",{"2":{"674":1,"683":1}}],["其中两者都是文本序列",{"2":{"665":1,"670":1}}],["其中两者均基于当前小批量处理",{"2":{"467":1}}],["其中特殊分类标记",{"2":{"657":1}}],["其中特征维度",{"2":{"644":1}}],["其中梯度是观测值y和估计值y^之间的差异",{"2":{"647":1}}],["其中整数分别代表狗猫鸡",{"2":{"640":1}}],["其中噪声服从正态分布",{"2":{"616":1}}],["其中对于所有的1≤i≤n",{"2":{"610":1}}],["其中对齐方式仅向一个方向移动",{"2":{"373":1}}],["其中labels中的1",{"2":{"776":1}}],["其中lenlabel表示标签序列中的词元数和",{"2":{"578":1}}],["其中l是最终候选序列的长度",{"2":{"515":1}}],["其中l是损失函数",{"2":{"190":1}}],["其中隐状态依赖于两个输入子序列",{"2":{"573":1}}],["其中隐状态只依赖于输入子序列",{"2":{"573":1}}],["其中隐藏表示h中的索引d表示输出通道",{"2":{"158":1}}],["其中最简单且最有用的操作是按元素",{"2":{"1018":1}}],["其中最早的方法是",{"2":{"538":1}}],["其中最令人烦恼的是局部最小值",{"2":{"100":1}}],["其中h",{"2":{"743":1}}],["其中h是隐藏单元的数目",{"2":{"521":1}}],["其中ht−1是隐状态",{"2":{"338":1}}],["其中ht−1的计算也依赖于wh",{"2":{"307":1}}],["其中有正样本",{"2":{"1144":1}}],["其中有一些需要由你自己来编辑",{"2":{"1094":1}}],["其中有一个是",{"2":{"515":1}}],["其中有超参数变量conv",{"2":{"508":1}}],["其中有多个特征值",{"2":{"97":1}}],["其中许多模型都是imagenet竞赛的优胜者",{"2":{"492":1}}],["其中许多数据集只有几百至几千张在非自然环境下以低分辨率拍摄的图像",{"2":{"456":1}}],["其中inv",{"2":{"1086":1}}],["其中inception块的通道数分配之比是在imagenet数据集上通过大量的实验得来的",{"2":{"490":1}}],["其中i∈",{"2":{"113":1}}],["其中第一个元素是类别",{"2":{"853":1}}],["其中第一个观测值包含一个校验和",{"2":{"538":1}}],["其中第i行和第j列的元素是bij",{"2":{"994":1}}],["其中第i行",{"2":{"851":1}}],["其中第i个元素μ",{"2":{"192":1}}],["其中第二层输出内容特征",{"2":{"917":1}}],["其中第二",{"2":{"488":1}}],["其中任一输出的形状是",{"2":{"956":1}}],["其中任意xi∈rd",{"2":{"396":1}}],["其中任何超出有效长度的位置都被掩蔽并置为0",{"2":{"368":1}}],["其中k的值取决于输入a",{"2":{"977":1}}],["其中k是核",{"2":{"388":1}}],["其中ki∈rk",{"2":{"367":1}}],["其中ϵ服从均值为0和标准差为0",{"2":{"386":1}}],["其中加入的噪声项为ϵ",{"2":{"386":1}}],["其中查询和键的长度为d",{"2":{"370":1}}],["其中查询",{"2":{"369":1}}],["其中查询q和键ki的注意力权重",{"2":{"367":1}}],["其中包括基于transformer编码器的更深的自监督模型bert",{"2":{"754":1}}],["其中包括专门用于参数绑定",{"2":{"248":1}}],["其中包含从imdb下载的25000个电影评论",{"2":{"691":1}}],["其中包含2个样本在3个类别的预测概率",{"2":{"633":1}}],["其中包含",{"2":{"512":1}}],["其中包含一个具有256个单元和relu激活函数的全连接隐藏层",{"2":{"422":1}}],["其中包含查询",{"2":{"358":1}}],["其中权重是在给定的查询和不同的键之间计算得出的",{"2":{"357":1}}],["其中权重参数为whx∈rh×d",{"2":{"312":1}}],["其中各输入的权重是一样的",{"2":{"357":1}}],["其中批量大小为n",{"2":{"339":1}}],["其中批量大小和通道数都为1",{"2":{"129":4}}],["其中单词xt在时间步t的条件概率仅取决于前面n−1个单词",{"2":{"338":1}}],["其中α是常数",{"2":{"744":1}}],["其中α是刻画分布的指数",{"2":{"318":1}}],["其中αi是满足∑iαi=1的非负实数",{"2":{"42":1}}],["其中n是边界框的数量",{"2":{"858":1}}],["其中na≥nb",{"2":{"851":1}}],["其中n×d矩阵乘以d×n矩阵",{"2":{"397":1}}],["其中n=5",{"2":{"319":1}}],["其中n",{"2":{"316":1}}],["其中nout是该层的输出的数量",{"2":{"247":1}}],["其中∂l",{"2":{"312":2}}],["其中长序列出现的很少",{"2":{"310":1}}],["其中输入可能包含替换的",{"2":{"721":1}}],["其中输入和输出x",{"2":{"164":1}}],["其中输出的数字是表示的是卡号",{"2":{"446":1}}],["其中输出比输入短得多",{"2":{"295":1}}],["其中的s是一个n×n的矩阵",{"2":{"1160":1}}],["其中的最大元素作为该子窗口的输出",{"2":{"938":1}}],["其中的模型参数在训练中无须更新",{"2":{"917":1}}],["其中的关键是梯度的聚合需要在单个gpu",{"2":{"841":1}}],["其中的一个原因是",{"2":{"639":1}}],["其中的每个元素都从均值为0",{"2":{"1017":1}}],["其中的每个文本序列可能具有不同的长度",{"2":{"568":1}}],["其中的每个输入词元或输出词元都由d维向量表示",{"2":{"397":1}}],["其中的每个词元都是一个字符串",{"2":{"362":1}}],["其中的权重是注意力权重",{"2":{"388":4}}],["其中的prefix是一个用户提供的包含多个字符的字符串",{"2":{"333":1}}],["其中的",{"2":{"284":1}}],["其中γ",{"2":{"262":1}}],["其中p由语言模型给出",{"2":{"342":1}}],["其中p",{"2":{"192":1,"310":1,"1032":1}}],["其中每行描述了房间数量",{"2":{"1011":1}}],["其中每行对应一个房子",{"2":{"290":1}}],["其中每组都有a个中心相同的锚框",{"2":{"913":1}}],["其中每个ai⊤∈rn都是行向量",{"2":{"998":1}}],["其中每个元素都是结果",{"2":{"1027":1}}],["其中每个元素都是按元素操作的结果",{"2":{"1018":1}}],["其中每个元素aij属于第i行第j列",{"2":{"992":1}}],["其中每个元素是由中心词center",{"2":{"776":1}}],["其中每个可微分函数ui都有变量x1",{"2":{"984":1}}],["其中每个子窗口的大小约为",{"2":{"938":1}}],["其中每个支持向量机用来判断样本是否属于某一个类别",{"2":{"937":1}}],["其中每个gpu执行自己的前向传播和反向传播",{"2":{"838":1}}],["其中每个中心词由其子词级向量之和表示",{"2":{"756":1}}],["其中每个句子都是词元列表",{"2":{"720":1,"722":3}}],["其中每个问题的答案只是段落中的一段文本",{"2":{"660":1}}],["其中每个词元由向量表示",{"2":{"734":1}}],["其中每个词元由6维向量表示",{"2":{"701":1}}],["其中每个词元是词表的索引",{"2":{"734":1}}],["其中每个词元都被分配了一个标签",{"2":{"659":1}}],["其中每个词元要么是一个词",{"2":{"566":1}}],["其中每个样本都有真实的标签",{"2":{"289":1}}],["其中每个样本具有d个输入特征",{"2":{"232":1}}],["其中每条路径通道数的分配思路和第三",{"2":{"488":1}}],["其中每条文本行都是一个字符串",{"2":{"361":1}}],["其中每一行都是一个表示预定义词表中词的向量",{"2":{"730":1}}],["其中每一行是",{"2":{"408":4}}],["其中每一个大类的数量在数据集近乎是平均的",{"2":{"188":1}}],["其中每列对应于标签类别",{"2":{"192":1}}],["其中计算顺序与计算图的相反",{"2":{"165":1}}],["其中正方形表示变量",{"2":{"163":1}}],["其中矩阵的frobenius范数是将矩阵展平为向量后应用的l2范数",{"2":{"162":1}}],["其中wi是中心词",{"2":{"744":1}}],["其中wi作为它们的中心词出现",{"2":{"742":1}}],["其中wxc∈rd×h和",{"2":{"554":1}}],["其中wxi",{"2":{"553":1}}],["其中wxh∈rd×h",{"2":{"541":1}}],["其中wxr",{"2":{"540":1}}],["其中w",{"2":{"162":1}}],["其中行对应样本",{"2":{"151":1}}],["其中样本数和通道数都是1",{"2":{"147":1}}],["其中r2=def∥x1−x∗∥2是初始选择参数与最终结果之间距离的边界",{"2":{"115":1}}],["其中f是一些可学习的函数",{"2":{"519":1}}],["其中f和g分别是隐藏层和输出层的变换",{"2":{"307":1}}],["其中f",{"2":{"115":1,"773":1}}],["其中学习率随迭代次数的平方根倒数衰减",{"2":{"114":1}}],["其中η是学习率",{"2":{"113":1}}],["其中x为m行n列的矩阵",{"2":{"1086":1}}],["其中x1",{"2":{"990":1,"1099":1}}],["其中x=x",{"2":{"986":1}}],["其中x和y分别是函数f的自变量和因变量",{"2":{"981":1}}],["其中x和h具有相同的形状",{"2":{"153":1}}],["其中xt是输入文本序列中的第t个词元",{"2":{"573":1}}],["其中x−j=",{"2":{"519":1}}],["其中x是n×1维的",{"2":{"1159":1}}],["其中x是多层感知机隐藏层的输出",{"2":{"737":1}}],["其中x是输入",{"2":{"425":1}}],["其中x是查询",{"2":{"388":1}}],["其中x是从正态分布中提取的",{"2":{"118":1}}],["其中x是参数向量",{"2":{"113":1}}],["其中x¯0是f¯的优化器",{"2":{"26":1}}],["其中参数γ",{"2":{"106":1}}],["其中条目mij=mji各自从某种概率分布pij中抽取",{"2":{"105":1}}],["其中",{"2":{"46":1,"73":1,"78":1,"86":1,"153":1,"191":1,"281":1,"299":1,"316":1,"339":1,"346":1,"374":1,"381":1,"396":1,"521":1,"526":1,"527":2,"610":1,"616":1,"640":1,"646":1,"742":1,"775":1,"818":1,"932":1,"1000":1,"1020":1,"1081":2,"1082":1,"1086":1,"1106":1,"1107":1,"1109":1,"1112":2,"1121":2,"1183":1,"1184":1,"1185":1}}],["其中提到",{"2":{"31":1}}],["其中δxt−1是重新缩放梯度的平方gt",{"2":{"20":1}}],["其次是仅含1×1卷积层的第一条路径",{"2":{"488":1}}],["其次",{"2":{"25":1,"33":1,"66":1,"77":1,"209":1,"299":1,"301":1,"311":1,"316":1,"457":1,"471":1,"572":1,"609":1,"733":1,"802":1,"817":1,"1016":1,"1093":1,"1141":2}}],["而集群化是大规模服务的运行方式",{"2":{"1356":1}}],["而手写代码这是目前为止我们常干的",{"2":{"1187":1}}],["而越是偏远的数据",{"2":{"1178":1}}],["而作为这个测试的一部分",{"2":{"1178":1}}],["而红色的区域是被忽略的",{"2":{"1172":1}}],["而主成分分析不作任何预测",{"2":{"1158":1}}],["而线性回归尝试的是最小化预测误差",{"2":{"1158":1}}],["而投射误差是从特征向量向该方向向量作垂线的长度",{"2":{"1158":1}}],["而蓝绿色点因为离三个地标都较远",{"2":{"1146":1}}],["而变成了p",{"2":{"1145":1}}],["而如果正则化参数c",{"2":{"1144":1}}],["而哪些方法可能是无意义的",{"2":{"1135":1}}],["而哪些可能是徒劳的呢",{"2":{"1135":1}}],["而交叉验证集误差则是先减小后增加",{"2":{"1133":1}}],["而交叉验证集误差较大",{"2":{"1133":1}}],["而最右端则对应向右急转的操作",{"2":{"1127":1}}],["而最后一种则是最简单的策略",{"2":{"838":1}}],["而中间的模型似乎最合适",{"2":{"1114":1}}],["而丢失了算法的本质",{"2":{"1114":1}}],["而丢弃蘑菇的损失为0",{"2":{"291":1}}],["而圆形代表负样本",{"2":{"1112":1}}],["而直到几年前我才真正搞清楚共轭梯度法",{"2":{"1111":1}}],["而你的新飞机引擎有特征变量xtest",{"2":{"1178":1}}],["而你的朋友雇了同一个承包商2小时",{"2":{"290":1}}],["而你希望将他们分成不同的客户群",{"2":{"1150":1}}],["而你只需要令变量prediction等于theta转置乘以x",{"2":{"1093":1}}],["而当你向量化我们将在之后的课程里面学到的算法",{"2":{"1093":1}}],["而当你实现机器学习算法时",{"2":{"1093":1}}],["而当输入为正时",{"2":{"235":1}}],["而相反地",{"2":{"1092":1}}],["而有些矩阵不可逆",{"2":{"1086":1}}],["而有些任务",{"2":{"734":1}}],["而房间数量的值则是0",{"2":{"1082":1}}],["而良性的肿瘤危害就没那么大",{"2":{"1060":1}}],["而npx模块包含一组扩展函数",{"2":{"1017":1}}],["而numpy仅支持cpu计算",{"2":{"1016":1}}],["而删除法则直接忽略缺失值",{"2":{"1012":1}}],["而列可能对应于不同的属性",{"2":{"992":1}}],["而z则是作为y和x的函数计算的",{"2":{"976":1}}],["而背景索引为0",{"2":{"945":1}}],["而vue的torefs会转换store中所有内置属性都变成refimp",{"2":{"1492":1}}],["而voc",{"2":{"945":1}}],["而vb",{"2":{"675":1}}],["而jpegimages和segmentationclass路径分别存储着每个示例的输入图像和标签",{"2":{"945":1}}],["而兴趣区域汇聚层对每个区域的输出形状是可以直接指定的",{"2":{"938":1}}],["而没有共享计算",{"2":{"938":1}}],["而没有考虑add函数在fancy",{"2":{"816":1}}],["而风格图像则是一幅主题为秋天橡树的油画",{"2":{"916":1}}],["而风险则是整个数据群的预期损失",{"2":{"99":1}}],["而以下所有超参数都可以调整",{"2":{"895":1}}],["而以前训练这些网络需要研究人员编写数千行的c或fortran代码",{"2":{"237":1}}],["而剩下5000张图像将作为路径train",{"2":{"890":1}}],["而剩下的290000张图像将不会被进行评估",{"2":{"888":1}}],["而r是比率",{"2":{"890":1}}],["而c只依赖于b",{"2":{"1038":1}}],["而cifar",{"2":{"882":1}}],["而cpu的浮点性能到目前为止还没有超过1",{"2":{"457":1}}],["而从头开始训练输出层可以使用更大的学习率",{"2":{"875":1}}],["而所有其他层的参数将根据源模型的参数进行微调",{"2":{"870":1}}],["而box",{"2":{"858":1}}],["而b是一个标量",{"2":{"602":1}}],["而运算顺序在完成向量变换时并不重要",{"2":{"844":1}}],["而即使是高速100gbe以太网也只能提供大约10gb",{"2":{"840":1}}],["而让其他gpu保持空闲",{"2":{"837":1}}],["而模型的计算结果保持不变",{"2":{"819":3}}],["而模型需要的输入是数字",{"2":{"363":1}}],["而消费级gpu",{"2":{"812":1}}],["而张量核是另一个极端",{"2":{"811":1}}],["而反向传播不需要存储中间数据",{"2":{"811":1}}],["而反之则不行",{"2":{"349":1}}],["而速度也更慢",{"2":{"810":1}}],["而复杂的微指令却可以被解码成一组更低级的操作",{"2":{"808":1}}],["而事实上",{"2":{"1069":1}}],["而事实上在分类问题中",{"2":{"1060":1}}],["而事实上受固态驱动器的设计方式",{"2":{"805":1}}],["而事实上它是有益的",{"2":{"467":1}}],["而它们的众多缺点之一是典型的灾难性故障模式和相对较高的读取延迟",{"2":{"804":1}}],["而桌面系统则有1个或2个加速卡",{"2":{"801":1}}],["而并行化对于多个设备就很重要了",{"2":{"795":1}}],["而飞桨矩阵乘法是在gpu上执行的",{"2":{"790":1}}],["而pytorch矩阵乘法是在gpu上执行的",{"2":{"790":1}}],["而pytorch则使用了python自己的调度器来实现不同的性能权衡",{"2":{"789":1}}],["而前端将控制权返回给了python",{"2":{"790":3}}],["而连续词袋模型假设基于上下文词来生成中心单词",{"2":{"787":1}}],["而无需人工标注",{"2":{"737":1}}],["而无须自己编写那么多的计算",{"2":{"615":1}}],["而无须任何调整",{"2":{"59":1}}],["而m大于50000",{"2":{"1148":1}}],["而m较大",{"2":{"1148":1}}],["而m在10",{"2":{"1148":1}}],["而mlp隐藏层的输入是编码后的",{"2":{"737":1}}],["而mnist数据集的60000个手写数字的数据集被认为是巨大的",{"2":{"299":1}}],["而额外的输出层将从头开始训练",{"2":{"733":1}}],["而微调bert只需要一个额外的基于多层感知机的架构",{"2":{"685":1}}],["而微观数据只记录较短期的时间动态",{"2":{"526":1}}],["而特殊标记",{"2":{"668":1}}],["而特殊分类标记",{"2":{"657":1}}],["而预训练bert模型中的所有参数都是微调的",{"2":{"656":1,"661":1}}],["而可以直接使用oj−max",{"2":{"624":1}}],["而训练迭代结果是在独立的验证数据集",{"2":{"613":1}}],["而训练数据的输入相当于键",{"2":{"388":1}}],["而更重要的是",{"2":{"1143":1}}],["而更关心如何高度准确预测参数",{"2":{"605":1}}],["而更高的层可以检测整个物体",{"2":{"455":1}}],["而keras还不知道输入将有多少维",{"2":{"592":1}}],["而gpt是任务无关的",{"2":{"733":1,"739":1}}],["而gpu拥有10倍于cpu的带宽",{"2":{"457":1}}],["而gluon还不知道输入将有多少维",{"2":{"592":1}}],["而非对一个提前定义的训练集进行循环",{"2":{"1168":1}}],["而非修改算法",{"2":{"1141":1}}],["而非输入层中的原始特征",{"2":{"1101":1}}],["而非",{"2":{"1097":1}}],["而非学习词级向量表示",{"2":{"756":1}}],["而非概率分布",{"2":{"743":1}}],["而非预测结果",{"2":{"579":1}}],["而非论文中的1000",{"2":{"461":4}}],["而机器翻译是语言模型最成功的基准测试",{"2":{"564":1}}],["而记忆元完全属于内部信息",{"2":{"562":1}}],["而记忆元ct不直接参与输出计算",{"2":{"559":1}}],["而遗忘门ft控制保留多少过去的",{"2":{"555":1}}],["而束搜索的实际应用则介于这两个极端之间",{"2":{"515":1}}],["而一个vgg块与之类似",{"2":{"507":1}}],["而一些通道专门识别纹理",{"2":{"158":1}}],["而右图虚线框中的部分则需要拟合出残差映射f",{"2":{"501":1}}],["而希望学出的理想映射为f",{"2":{"501":1}}],["而过渡层可以用来控制模型复杂度",{"2":{"481":1}}],["而过拟合一个有数百万个样本的数据集则需要一个极其灵活的模型",{"2":{"254":1}}],["而得来",{"2":{"479":1}}],["而得不到全局最小值",{"2":{"63":1}}],["而批量规范化将每一层主动居中",{"2":{"467":1}}],["而lenet只使用了权重衰减",{"2":{"461":1}}],["而本节只是为了展示数据如何在不同的设备之间传递",{"2":{"445":1}}],["而键和值来自整个编码器的输出",{"2":{"404":1}}],["而自注意力则因为并行计算而放弃了顺序操作",{"2":{"398":1}}],["而自然科学大部分都植根于此",{"2":{"299":1}}],["而任意的序列位置组合之间的路径越短",{"2":{"397":1}}],["而任何实际模型都必须超越这个上限",{"2":{"342":1}}],["而环境中的干扰注意力的信息却并不少",{"2":{"354":1}}],["而忽略了操作参数的具体细节",{"2":{"429":1}}],["而忽略了其他的书",{"2":{"354":1}}],["而忽略其他特征",{"2":{"169":1}}],["而动态规划这些计算工具已经在控制算法和强化学习算法广泛使用",{"2":{"348":1}}],["而后者为data的最后一列",{"2":{"1012":1}}],["而后者则显式地建模文本对之间的逻辑关系",{"2":{"739":1}}],["而后者则控制通道数量",{"2":{"479":1}}],["而后者",{"2":{"345":1}}],["而缺少的可能性值相当于平均数",{"2":{"342":1}}],["而下一个字符是基于特征序列",{"2":{"341":1}}],["而隐状态则是在给定步骤所做的任何事情",{"2":{"338":1}}],["而隐状态形状保持不变",{"2":{"332":1}}],["而隐藏层中的每个神经元又会影响输出层中的每个神经元",{"2":{"231":1}}],["而使用元组可以更容易地处理些",{"2":{"332":1}}],["而对于较大的物体",{"2":{"912":1}}],["而对于其他服务器则未必",{"2":{"845":1}}],["而对于输出门接近0",{"2":{"556":1}}],["而对于三个或者更多的单词组合",{"2":{"316":1}}],["而对于不常见的特征",{"2":{"25":1}}],["而",{"2":{"315":1,"686":1,"1041":1,"1121":1,"1122":1,"1187":1,"1205":1}}],["而接近分类输出的层可以表示用于区分的更抽象的概念",{"2":{"302":1}}],["而计算能力却很弱",{"2":{"299":1}}],["而高斯分布是由卡尔",{"2":{"299":1}}],["而奖励只与所选的动作相对应",{"2":{"298":1}}],["而仅根据最近的测量结果做出预测",{"2":{"295":1}}],["而工业生产的推荐系统要先进得多",{"2":{"294":1}}],["而关于",{"2":{"292":1}}],["而乌梢蛇是无毒的",{"2":{"291":1}}],["而深度学习是机器学习的一个主要分支",{"2":{"282":1}}],["而该测量值与唤醒词难以直接关联",{"2":{"282":1}}],["而较大的λ值对w的约束更大",{"2":{"270":1}}],["而较小的β相对于梯度法只是略有修正",{"2":{"86":1}}],["而将两者都作为特征有些重复",{"2":{"1156":1}}],["而将其他权重清除为零",{"2":{"270":1}}],["而将|e",{"2":{"60":1}}],["而表达能力有限但仍能很好地解释数据的模型可能更有现实用途",{"2":{"254":1}}],["而需要早停",{"2":{"254":1}}],["而输入在任一方向上越远离0点时",{"2":{"236":1}}],["而输入的感受野包括最初所有九个输入元素",{"2":{"131":1}}],["而输出paragraphs",{"2":{"722":3}}],["而输出",{"2":{"232":1}}],["而测试数据集包含1459个样本",{"2":{"208":1}}],["而测试集只包含卡通图片",{"2":{"181":1}}],["而错误地分到另一个类别是无害的",{"2":{"201":1}}],["而通常是在提供一个会被用来",{"2":{"201":1}}],["而标签通常是低维",{"2":{"192":1}}],["而此时输入p",{"2":{"180":1}}],["而我们希望p",{"2":{"1145":1}}],["而我们想要使其最小化",{"2":{"1111":1}}],["而我们不可能用目前所掌握的数据来预测新的动力学",{"2":{"347":1}}],["而我们的假设函数",{"2":{"1064":1}}],["而我们的自定义代码由python实现",{"2":{"474":1}}],["而我们的上述讨论只是其中的冰山一角",{"2":{"349":1}}],["而我们的模型预测为i的样本数量所占的比例",{"2":{"192":1}}],["而我们的机器学习任务通常会跟全局图像的问题有关",{"2":{"145":1}}],["而我们以前所说的",{"2":{"180":1}}],["而信用度却没有相应的提高",{"2":{"179":1}}],["而这取决于初始化的情况",{"2":{"1153":1}}],["而这其实是求解上一页幻灯片上优化问题的结果",{"2":{"1144":1}}],["而这是支持向量机具有鲁棒性的原因",{"2":{"1144":1}}],["而这里的公式x的概率",{"2":{"1185":1}}],["而这里",{"2":{"1143":1}}],["而这种情况往往出现在这些条件对于你的问题都成立",{"2":{"1141":1}}],["而这种泛化性质的数学基础仍然是悬而未决的研究问题",{"2":{"169":1}}],["而这也将使算法更加适合解决大型的机器学习问题",{"2":{"1111":1}}],["而这个变量prediction",{"2":{"1093":1}}],["而这个魔方矩阵这神奇的方形屏幕",{"2":{"1090":1}}],["而这个向前推进的方向恰好也是我们通常感兴趣的方向",{"2":{"349":1}}],["而这些人又经常给哪些人发邮件",{"2":{"1150":1}}],["而这些情况是很难画出图的",{"2":{"1066":1}}],["而这些服务器又只通过相对较低的带宽结构连接",{"2":{"843":1}}],["而这些信息关乎到选择哪个词来填空",{"2":{"518":1}}],["而这些元素无法通过任何查询进行区分",{"2":{"370":1}}],["而这些结构可以被人类和机器学习模型使用",{"2":{"151":1}}],["而其它单元都是0",{"2":{"1160":1}}],["而其他颜色则对应不同的类别",{"2":{"945":1}}],["而其他梯度较小的坐标则会得到更平滑的处理",{"2":{"25":1}}],["而其中v是该卷积层的权重",{"2":{"158":1}}],["而随后的输出将继续以三维张量h作为输入进入下一个卷积层",{"2":{"158":1}}],["而第三个元素",{"2":{"1093":1}}],["而第三个序列的损失应为零",{"2":{"575":1}}],["而第三个轴可以看作每个像素的多维表示",{"2":{"158":1}}],["而第三项∂ht",{"2":{"307":1}}],["而第二个循环则是用于减小μi引起的代价",{"2":{"1152":1}}],["而第二个卷积层有16个输出通道",{"2":{"136":1}}],["而第二组是在中午拍摄的",{"2":{"186":1}}],["而卷积神经网络是包含卷积层的一类特殊的神经网络",{"2":{"155":1}}],["而卷积核只与图像中每个大小完全适合的位置进行互相关运算",{"2":{"126":1}}],["而卷积核窗口",{"2":{"126":1}}],["而沃尔多通常潜伏在一些不太可能的位置",{"2":{"152":1}}],["而填充是解决此问题最有效的方法",{"2":{"140":1}}],["而现实中的文档集合可能会包含数十亿个单词",{"2":{"361":1}}],["而现实可能更为复杂一些",{"2":{"121":1}}],["而现在逻辑函数假设函数",{"2":{"1110":1}}],["而现在卷积神经网络通常只需要几百个参数",{"2":{"155":1}}],["而现在",{"2":{"135":1,"300":1,"1176":1}}],["而1×1卷积显然没有此作用",{"2":{"122":1}}],["而是生成新版本",{"2":{"1200":1}}],["而是一些问题",{"2":{"1187":1}}],["而是一个能够围绕目标完成多步任务",{"2":{"1050":1}}],["而是一个由高度",{"2":{"158":1}}],["而是只需要每次对最后1000个",{"2":{"1167":1}}],["而是通过核函数计算出的新特征",{"2":{"1146":1}}],["而是通过一个运算符选择所有元素",{"2":{"633":1}}],["而是拥有最多数据的人",{"2":{"1141":1}}],["而是花大量的时间来收集大量的数据",{"2":{"1141":1}}],["而是尽可能快地实现你的算法",{"2":{"1138":1}}],["而是构建一个简单的算法",{"2":{"1138":1}}],["而是运用一些机器学习诊断法来帮助我们知道上面哪些方法对我们的算法是有效的",{"2":{"1129":1}}],["而是输出一条白亮的区段",{"2":{"1127":1}}],["而是每次只关注训练集中的一些小的子集",{"2":{"1069":1}}],["而是在最小值点附近徘徊",{"2":{"1165":1}}],["而是在一个无限长的列表里面",{"2":{"1060":1}}],["而是在海量搜索结果中找到用户最需要的那部分",{"2":{"293":1}}],["而是同时运行第一个和第二个测试",{"2":{"1038":1}}],["而是指向新分配的内存处的张量",{"2":{"1021":1}}],["而是指向过去梯度的加权平均值的方向",{"2":{"86":1}}],["而是分量的大小",{"2":{"1000":1}}],["而是专注学习其基础知识",{"2":{"993":1}}],["而是单独计算批量中每个样本的偏导数之和",{"2":{"975":1}}],["而是将重点放在矩阵运算的基本原理及其实现上",{"2":{"987":1}}],["而是将数据放在cpu的缓存上",{"2":{"810":1}}],["而是将它们连接起来",{"2":{"479":1}}],["而是使用l1范数损失",{"2":{"962":1}}],["而是使用突发模式读取和写入",{"2":{"802":1}}],["而是使用差值",{"2":{"156":1}}],["而是线性依赖于k",{"2":{"708":1}}],["而是问",{"2":{"639":1}}],["而是后向计算",{"2":{"519":1}}],["而是",{"2":{"442":1,"624":1}}],["而是会在mxnet内部声明希望初始化参数",{"2":{"418":1}}],["而是还可能期望继续猜测这个序列的后续",{"2":{"305":1}}],["而是编写了一个",{"2":{"282":1}}],["而是学习特征之间的交互",{"2":{"169":1}}],["而是为了共同使用而优化的",{"2":{"121":1}}],["而按序存取",{"2":{"77":1}}],["而另一些人他们可能对我马上要讲的东西",{"2":{"1129":1}}],["而另一些则针对浮点性能进行了优化",{"2":{"808":1}}],["而另一些则比较通用",{"2":{"431":1}}],["而另一个会花费大量时间的任务是了解应用学习算法的实用建议",{"2":{"1059":1}}],["而另一方面",{"2":{"77":1}}],["而另外两组则没有这样的问题",{"2":{"40":1}}],["而由于cpu和gpu无法充分利用向量化",{"2":{"76":1}}],["而且这两个特征的值域范围比较宽",{"2":{"1184":1}}],["而且这次的代码比之前更精简了",{"2":{"626":1}}],["而且如果你对某一种应用有一个连续的数据流",{"2":{"1168":1}}],["而且m大小中等",{"2":{"1148":1}}],["而且你训练了一种带有很多参数的学习算法",{"2":{"1141":1}}],["而且因为我们有非常强大的学习算法",{"2":{"1141":1}}],["而且他们用了一个朴素算法",{"2":{"1141":1}}],["而且他不是亚马逊",{"2":{"290":1}}],["而且我们也学习了过拟合假设函数的例子",{"2":{"1130":1}}],["而且我们难以通过简单的预处理来解决这个问题",{"2":{"230":1}}],["而且通常不需要人工选择学习率",{"2":{"1109":1}}],["而且通常数据写入需要大量的时间还因为块必须被读取",{"2":{"805":1}}],["而且总是朝向北时发出嗡嗡声",{"2":{"1098":1}}],["而且大脑能处理各种不同的令人惊奇的事情",{"2":{"1098":1}}],["而且在10×10像素下几乎是不可能的",{"2":{"1025":1}}],["而且梯度不会通过variable流动",{"2":{"1021":1}}],["而且经常容易出错",{"2":{"973":1}}],["而且事实上它们可以在一台机器内高效地执行",{"2":{"843":1}}],["而且数据集也太小了",{"2":{"837":1}}],["而且删除了最大汇聚层",{"2":{"826":4}}],["而且具有很强的弹性",{"2":{"812":1}}],["而且优化了矩阵运算",{"2":{"811":1}}],["而且不如vgg那样便于修改通道数",{"2":{"488":1}}],["而且不需要改变输入或隐藏表示的维数",{"2":{"155":1}}],["而且它还需要更多的显存",{"2":{"511":1}}],["而且它们在任何单个任务上的性能都相对较差",{"2":{"457":1}}],["而且它的反应将取决于之前发生的事情",{"2":{"198":1}}],["而且由相同的张量表示",{"2":{"437":2}}],["而且自注意力的最大路径长度最短",{"2":{"397":1,"401":1}}],["而且ht还将送入全连接输出层",{"2":{"340":1}}],["而且取代了劳动密集型的特征工程",{"2":{"303":1}}],["而且还便宜",{"2":{"812":1}}],["而且还取代了劳动密集型的特征工程过程",{"2":{"302":1}}],["而且还提出了一系列必须仔细考虑的伦理问题",{"2":{"201":1}}],["而且没有完全观察到",{"2":{"301":1}}],["而且有很强的理论依据",{"2":{"299":1}}],["而且能够与真实环境互动",{"2":{"297":1}}],["而且",{"2":{"233":1,"459":1,"578":1,"805":1,"811":1,"821":1,"832":1,"1063":1,"1088":1,"1111":1}}],["而且卷积也很容易用gpu并行计算",{"2":{"134":1}}],["而且一次处理单个观测值效率较低",{"2":{"80":1}}],["而且对应深度学习框架也要巨大的开销",{"2":{"78":1}}],["而且可能希望最终能用非常小的学习率来",{"2":{"72":1}}],["而且二阶导数不为零",{"2":{"60":1}}],["而只是为了给统计建模者提供足够的信息",{"2":{"800":1}}],["而只是轻柔地降低了学习率",{"2":{"68":1}}],["而只计算",{"2":{"61":1}}],["而改善这个问题的一种方法是",{"2":{"61":1}}],["而在纵轴上",{"2":{"1145":1}}],["而在右边这里我画出了关于z的代价函数cost0",{"2":{"1144":1}}],["而在六个月或者更长时间后",{"2":{"1129":1}}],["而在无监督学习中",{"2":{"1059":1}}],["而在预测过程中不使用带随机操作的图像增广",{"2":{"884":1}}],["而在预测模式下",{"2":{"467":1}}],["而在另一个gpu上聚合另一些参数",{"2":{"841":1}}],["而在芬兰语中",{"2":{"755":1}}],["而在spacy词元化之后的形式是",{"2":{"717":1}}],["而在第二个样本中",{"2":{"633":1}}],["而在机器学习领域",{"2":{"610":1}}],["而在机器翻译中",{"2":{"295":1}}],["而在循环神经网络中",{"2":{"526":1}}],["而在测试期间",{"2":{"522":1}}],["而在大部分时候",{"2":{"251":1}}],["而在现实中",{"2":{"145":1}}],["而在内部更新的全局变量",{"2":{"114":2}}],["而在目标函数较平坦时则采用较大的学习率",{"2":{"59":1}}],["而在应用簇标签时",{"2":{"42":1}}],["而抛物线函数和指数函数为凸的",{"2":{"41":1}}],["而不只是簇",{"2":{"1150":1}}],["而不只是有相同的值",{"2":{"437":2}}],["而不只因为它们在逻辑上行得通",{"2":{"1098":1}}],["而不使用梯度下降法",{"2":{"1085":1}}],["而不用在乎我们需要处理多少工作节点",{"2":{"843":1}}],["而不希望系统中的任何一部分成为主要的瓶颈",{"2":{"801":1}}],["而不考虑词的上下文",{"2":{"731":1,"739":1}}],["而不考虑基于每个坐标应用的缩放",{"2":{"107":1}}],["而不折叠求和的维度",{"2":{"631":1}}],["而不像通过电话预先订购",{"2":{"450":1}}],["而不必关注层的实现细节",{"2":{"591":1}}],["而不必定义自己的类",{"2":{"425":1}}],["而不必分心于其他问题",{"2":{"297":1}}],["而不仅是",{"2":{"297":1,"1545":1}}],["而不仅仅是生成语法合理的内容",{"2":{"315":1}}],["而不仅仅是余弦",{"2":{"73":1}}],["而不仅仅是初始的逐点估计",{"2":{"35":1}}],["而不会复制并分配新内存",{"2":{"449":2}}],["而不会",{"2":{"295":1}}],["而不能对看不见的数据做到很好泛化",{"2":{"253":1}}],["而不需要进一步的测试",{"2":{"1178":1}}],["而不需要首先将所有的训练集求和",{"2":{"1165":1}}],["而不需要真正理解这些算法的内环间在做什么",{"2":{"1111":1}}],["而不需要用户编写复杂的代码",{"2":{"796":1}}],["而不需要昂贵的标签标注",{"2":{"754":1}}],["而不需要更新隐状态",{"2":{"556":1}}],["而不需要查看其他隐藏单元所取的值",{"2":{"232":1}}],["而不需要处理周边的其他维度",{"2":{"192":1}}],["而不关注这些基本问题",{"2":{"179":1}}],["而不知其所以然",{"2":{"161":1}}],["而不在乎它的位置",{"2":{"159":1}}],["而不过度在意图像中相隔较远区域的关系",{"2":{"152":1}}],["而不产生实际计算其梯度的代价",{"2":{"86":1}}],["而不做进一步的详细讨论",{"2":{"67":1}}],["而不是此前的标签数据",{"2":{"1150":1}}],["而不是尝试自己落实一些数据",{"2":{"1148":1}}],["而不是左边的那个",{"2":{"1145":1}}],["而不是将v投影到u上",{"2":{"1145":1}}],["而不是将它们一对放在一起作为输入",{"2":{"674":1}}],["而不是逻辑回归",{"2":{"1143":1}}],["而不是去争辩应该用什么样的算法",{"2":{"1141":1}}],["而不是梯度下降",{"2":{"1111":1}}],["而不是需要运行上千个不同的程序",{"2":{"1098":1}}],["而不是自己去做那些函数库可以做的事情",{"2":{"1093":1}}],["而不是记事本来打开这些文件",{"2":{"1092":1}}],["而不是对矩阵使用",{"2":{"1089":1}}],["而不是等于感叹号加等号",{"2":{"1088":1}}],["而不是看到另一个数字",{"2":{"1026":1}}],["而不是z=x",{"2":{"976":1}}],["而不是输入",{"2":{"969":1}}],["而不是q+1个类别",{"2":{"955":1}}],["而不是再缩放",{"2":{"946":1}}],["而不是各个提议区域",{"2":{"938":1}}],["而不是一个变量",{"2":{"922":2}}],["而不是一个标量",{"2":{"605":2}}],["而不是我们之前使用的fashion",{"2":{"882":1}}],["而不是1000个",{"2":{"873":1}}],["而不是11个结果",{"2":{"511":1}}],["而不是30毫秒",{"2":{"841":1}}],["而不是向后读取",{"2":{"810":1}}],["而不是mn次计算",{"2":{"674":1}}],["而不是仅仅凭直觉",{"2":{"1138":1}}],["而不是仅包含二元项的向量",{"2":{"648":1}}],["而不是仅使用交叉验证中使用的1−1",{"2":{"213":1}}],["而不是通过模型训练得到的",{"2":{"613":1}}],["而不是复用语言模型的预处理程序",{"2":{"564":1}}],["而不是字符序列",{"2":{"563":1}}],["而不是使用单一层这个默认值",{"2":{"528":1}}],["而不是使用多词元列表构成的一个列表",{"2":{"364":1}}],["而不是只有一个在前向模式下",{"2":{"520":1}}],["而不是如resnet的简单相加",{"2":{"479":1}}],["而不是学习算法",{"2":{"454":1}}],["而不是在测试集上",{"2":{"1138":1}}],["而不是在单个gpu上计算64个通道",{"2":{"832":1}}],["而不是在cpu上初始化",{"2":{"827":1}}],["而不是在python中编写开销高昂的for循环",{"2":{"615":1}}],["而不是在gpu上保存日志并仅传输最终结果",{"2":{"453":1}}],["而不是在参数中完成",{"2":{"443":1}}],["而不是简单地依赖预定义的神经网络层",{"2":{"425":1}}],["而不是简单地记住了数据呢",{"2":{"251":1}}],["而不是单词",{"2":{"364":1,"1141":1}}],["而不是原始数据",{"2":{"351":1}}],["而不是xt−1",{"2":{"348":1}}],["而不是连续的数字",{"2":{"347":1}}],["而不是选择最有可能的下一个字符",{"2":{"337":1}}],["而不是长期影响",{"2":{"309":1}}],["而不是用手来求解电子行为的参数近似",{"2":{"302":1}}],["而不是l1范数",{"2":{"270":1}}],["而不是训练误差和验证误差之间的差距",{"2":{"258":1}}],["而不是测试集准确度",{"2":{"256":1}}],["而不是更广",{"2":{"233":1}}],["而不是直接调用内置的relu函数",{"2":{"218":1}}],["而不是绝对误差y−y^",{"2":{"210":1}}],["而不是绝对数量",{"2":{"210":1}}],["而不是考虑基础性问题",{"2":{"207":1}}],["而不是从",{"2":{"1093":1}}],["而不是从那些准备好的张量格式数据开始",{"2":{"1010":1}}],["而不是从零开始创建",{"2":{"583":1}}],["而不是从头开始训练",{"2":{"193":1}}],["而不是从目标分布p",{"2":{"191":1}}],["而不是像train",{"2":{"726":1}}],["而不是像输入",{"2":{"182":1}}],["而不是像卷积层一样在通道上对输入进行汇总",{"2":{"148":1}}],["而不是激活值",{"2":{"178":1}}],["而不是过于依赖少数潜在的虚假关联",{"2":{"168":1}}],["而不是",{"2":{"158":1,"665":1,"1544":1}}],["而不是互相关运算",{"2":{"130":1}}],["而不是卷积运算",{"2":{"126":1}}],["而不是全局最优",{"2":{"101":1}}],["而不是模型的泛化误差",{"2":{"100":1}}],["而不是观测单个数据来更新参数",{"2":{"78":1}}],["而不是它们的更新速率",{"2":{"66":1}}],["而不是实际值",{"2":{"64":1}}],["而不是η=η0t+c",{"2":{"25":1}}],["预备知识",{"0":{"987":1}}],["预训练word2vec",{"0":{"760":1},"1":{"761":1,"762":1,"763":1,"764":1,"765":1,"766":1,"767":1,"768":1,"769":1,"770":1}}],["预训练好的文本表示可以放入各种深度学习架构",{"2":{"754":1}}],["预训练",{"0":{"754":1}}],["预训练词向量可以捕捉到句法信息",{"2":{"751":1}}],["预训练包括两个任务",{"2":{"739":1}}],["预训练包括以下两个任务",{"2":{"735":1}}],["预训练任务",{"0":{"735":1},"1":{"736":1,"737":1}}],["预训练了一个用于表示文本序列的语言模型",{"2":{"732":1}}],["预训练bert",{"0":{"725":1,"726":1},"1":{"726":1,"727":1,"728":1,"729":1}}],["预训练bert编码器",{"2":{"688":1}}],["预训练的源模型实例包含许多特征层和一个输出层fc",{"2":{"873":2}}],["预训练的源模型实例包含两个成员变量",{"2":{"873":1}}],["预训练的词向量可以应用于词的相似性和类比任务",{"2":{"752":1}}],["预训练的词向量可以表示文本序列中的各个词元",{"2":{"716":1}}],["预训练的fasttext嵌入有多种语言",{"2":{"748":1}}],["预训练的bert模型bert被送到用于下游应用的bertclassifier实例net中",{"2":{"688":1}}],["预期风险",{"2":{"291":1}}],["预期是e",{"2":{"170":1}}],["预测为假",{"2":{"1139":2}}],["预测为真",{"2":{"1139":2}}],["预测自信度最高的那个神经网络得到的行驶方向",{"2":{"1127":1}}],["预测新数据",{"2":{"1114":1}}],["预测出该房屋的交易价格作为输出变量输出为结果",{"2":{"1063":1}}],["预测目标",{"0":{"964":1}}],["预测偏移量是一个回归问题",{"2":{"962":1}}],["预测n个提议区域中每个区域的类别和边界框",{"2":{"938":1}}],["预测num",{"2":{"333":4}}],["预测测试图像中所有像素的类别",{"2":{"868":1}}],["预测期间可以使用非极大值抑制",{"2":{"855":1}}],["预测期间需要多少显存",{"2":{"498":1}}],["预测所有锚框的类别和偏移量",{"2":{"850":1}}],["预测所依据的自变量",{"2":{"609":1}}],["预测下一步需要哪个存储设备是优化芯片设计的关键参数之一",{"2":{"810":1}}],["预测下个月股票的价格",{"2":{"289":1}}],["预测使用单隐藏层的多层感知机",{"2":{"736":1}}],["预测文本序列的情感",{"2":{"715":3}}],["预测文本片段的结束与上面相同",{"2":{"660":1}}],["预测前提和假设之间的逻辑关系",{"2":{"682":3}}],["预测标签",{"2":{"636":1}}],["预测总数",{"2":{"634":3}}],["预测值",{"2":{"1139":1}}],["预测值y^∈rn",{"2":{"610":1}}],["预测值应该为多少",{"2":{"610":1}}],["预测值和实际标签值的差异",{"2":{"290":1}}],["预测需求",{"2":{"608":1}}],["预测住院时间",{"2":{"608":1}}],["预测价格",{"2":{"608":1}}],["预测序列的评估",{"0":{"578":1}}],["预测就结束了",{"2":{"577":1}}],["预测输出序列",{"2":{"513":1}}],["预测过程中的批量规范化",{"0":{"471":1}}],["预测模式",{"2":{"467":1}}],["预测模型",{"2":{"297":1}}],["预测阶段",{"2":{"408":4}}],["预测结果绘制",{"2":{"392":1}}],["预测的这些锚框的类别和偏移量",{"2":{"959":1}}],["预测的总数量",{"2":{"827":1}}],["预测的质量是如何变化的",{"2":{"351":1}}],["预测的结果很快就会衰减到一个常数",{"2":{"351":1}}],["预测明天的股价要比过去的股价更困难",{"2":{"345":1}}],["预测",{"0":{"333":1,"351":1,"577":1,"636":1,"866":1},"2":{"422":1,"635":2,"1107":2,"1108":4,"1146":1,"1192":1}}],["预测类别的概率的大小传达了一种模型的不确定性",{"2":{"291":1}}],["预测病人在医院的住院时间也是一个回归问题",{"2":{"290":1}}],["预测用户对一部电影的评分可以被归类为一个回归问题",{"2":{"290":1}}],["预测正确的法语翻译",{"2":{"289":1}}],["预测是否为癌症",{"2":{"289":1}}],["预测房价",{"0":{"205":1},"1":{"206":1,"207":1,"208":1,"209":1,"210":1,"211":1,"212":1,"213":1,"214":1,"215":1}}],["预测算法现在在信息传播中起着巨大的中介作用",{"2":{"201":1}}],["预测f",{"2":{"190":1}}],["预测患者的疾病",{"2":{"182":1}}],["预计计算需要多长时间",{"2":{"167":1}}],["预热设备",{"2":{"796":3}}],["预热期",{"2":{"333":4}}],["预热期结束后",{"2":{"333":1}}],["预热应该持续多长时间",{"2":{"75":1}}],["预热阶段限制了非常深的网络中参数的发散程度",{"2":{"73":1}}],["预热可以应用于任何调度器",{"2":{"73":1}}],["预热",{"0":{"73":1}}],["预处理数据",{"0":{"946":1}}],["预处理数据集",{"0":{"693":1}}],["预处理函数preprocess对输入图像在rgb三个通道分别做标准化",{"2":{"919":1}}],["预处理和后处理",{"0":{"919":1}}],["预处理有助于调节比例",{"2":{"63":1}}],["预处理推动了随机梯度下降优化算法的一些创新",{"2":{"61":1}}],["预处理",{"0":{"26":1,"61":1},"2":{"53":1,"61":1,"565":1}}],["预先条件",{"2":{"25":1}}],["预览构建的文档",{"2":{"17":1}}],["预览",{"0":{"17":1}}],["这让",{"2":{"1201":1}}],["这让我们能够获得一个无限大的训练集",{"2":{"1173":1}}],["这让每个程序员轻易掌握了它",{"2":{"300":1}}],["这虽然很多时候有效果",{"2":{"1162":1}}],["这正是支持向量机中最小化目标函数的目的",{"2":{"1145":1}}],["这正是我们期望从正则化中得到的效果",{"2":{"277":1}}],["这正是我们想要的",{"2":{"270":1}}],["这告诉了我们什么呢",{"2":{"1145":1}}],["这告诉我们想要通过计数统计和平滑来建模单词是不可行的",{"2":{"318":1}}],["这等于什么呢",{"2":{"1145":1}}],["这等于什么呢在前一页幻灯片上",{"2":{"1145":1}}],["这等价于",{"2":{"1090":1}}],["这只有当参数c是非常大的时候是真的",{"2":{"1144":1}}],["这只是c非常大的情形",{"2":{"1144":1}}],["这只是一种不同的方式来控制这种权衡或者一种不同的方法",{"2":{"1143":1}}],["这只是一个简单的人工数据集",{"2":{"933":1}}],["这只是针对训练集中一个训练实例所进行的计算",{"2":{"1100":1}}],["这只是对那些知道",{"2":{"1092":1}}],["这只是基于互相关运算的二维卷积的特例",{"2":{"699":1}}],["这事实上正是支持向量机将会做的",{"2":{"1144":1}}],["这实在是不明智的",{"2":{"1144":1}}],["这实际上和我直接把",{"2":{"1092":1}}],["这实际上得到的就是单位矩阵",{"2":{"1090":1}}],["这实际上是于事无补的",{"2":{"1129":1}}],["这实际上是一个名为brainport的系统",{"2":{"1098":1}}],["这实际上是在同一时间运行三个命令",{"2":{"1091":1}}],["这实际上是求得了",{"2":{"1090":1}}],["这实际上是net",{"2":{"422":4}}],["这仅仅是由于人们使用支持向量机时",{"2":{"1143":1}}],["这还取决于一些细节",{"2":{"1141":1}}],["这件重要的事情就是偏斜类",{"2":{"1139":1}}],["这件事在一个不幸的初创公司身上发生过",{"2":{"185":1}}],["这块土地的信息等等",{"2":{"1129":1}}],["这块红色的脑组织是你的躯体感觉皮层",{"2":{"1098":1}}],["这辆悍马装载了传感器",{"2":{"1127":1}}],["这幅图的第二部分对应的就是学习算法选出的行驶方向",{"2":{"1127":1}}],["这三种算法有许多优点",{"2":{"1111":1}}],["这三种算法的具体细节超出了本门课程的范畴",{"2":{"1111":1}}],["这三个门的值都在",{"2":{"553":1}}],["这张图是用舌头学会",{"2":{"1098":1}}],["这张图非常令人振奋",{"2":{"318":1}}],["这靠的是耳朵",{"2":{"1098":1}}],["这行代码就是利用",{"2":{"1093":1}}],["这第二个元素最后就会变成",{"2":{"1093":1}}],["这给了我们高度冗余表示",{"2":{"1156":1}}],["这给了我恰好45度的斜线",{"2":{"1092":1}}],["这给我们留下了唯一的选择",{"2":{"113":1}}],["这说的就是函数返回值是两个",{"2":{"1092":1}}],["这说明应该尽可能地避免随机内存访问",{"2":{"802":1}}],["这说明了预训练词向量中的语义",{"2":{"751":1}}],["这说明了优化器的普适性",{"2":{"625":1}}],["这说明了游戏取得了令人瞩目的进步以及先进的算法在其中发挥了关键作用的事实",{"2":{"301":1}}],["这说明",{"2":{"376":1}}],["这说明语言中存在相当多的结构",{"2":{"318":1}}],["这表示返回a",{"2":{"1089":1}}],["这表示的是将向量",{"2":{"1089":1}}],["这表明机器学习涉及的问题非常广泛",{"2":{"1058":1}}],["这表明严重的过拟合",{"2":{"258":1}}],["这表明模型过拟合了",{"2":{"212":1}}],["这表明选择大型的小批量bt将是普遍可行的",{"2":{"78":1}}],["这跟刚才的命令效果是相同的",{"2":{"1089":1}}],["这应该能做同逻辑回归中类似的事情",{"2":{"1143":1}}],["这应该打印π的6位小数形式",{"2":{"1088":1}}],["这应该看起来很眼熟",{"2":{"413":1}}],["这次机器学习课的作业也是用matlab的",{"2":{"1088":1}}],["这次升职很可能反映了前一年的大量的行动",{"2":{"298":1}}],["这工作可能会让你花上一阵子时间",{"2":{"1086":1}}],["这条黑线有更大的距离",{"2":{"1144":1}}],["这条黑色的看起来好得多",{"2":{"1144":1}}],["这条线便是我们模型的分界线",{"2":{"1108":1}}],["这条线是可以完美拟合我的数据集的",{"2":{"1092":1}}],["这条线有一个正斜率",{"2":{"1068":1}}],["这条直线的斜率正好是这个三角形的高度除以这个水平长度",{"2":{"1068":1}}],["这段代码意思清晰",{"2":{"1296":1}}],["这段代码的运行速度要快得多",{"2":{"547":1,"561":1}}],["这段视频中",{"2":{"1167":1}}],["这段视频中的某些内容你可能会听不懂",{"2":{"1066":1}}],["这段视频的内容假设你已经认识等高线图",{"2":{"1066":1}}],["这么做也可能不会有明显地改善",{"2":{"1153":1}}],["这么做的原因是",{"2":{"1138":1}}],["这么做octave将矩阵",{"2":{"1090":1}}],["这么做往往可以在计算上更高效",{"2":{"217":1}}],["这么多人同时在聊天",{"2":{"1061":1}}],["这节课我们也看到了",{"2":{"1187":1}}],["这节课我们介绍了监督学习",{"2":{"1060":1}}],["这节课给出了一些关于为什么支持向量机被看做大间距分类器的直观理解",{"2":{"1144":1}}],["这节课中",{"2":{"1066":1}}],["这节省了梯度下降的时间和内存空间",{"2":{"905":1}}],["这叫做回归问题",{"2":{"1060":1}}],["这套房子能卖接近$200",{"2":{"1060":1}}],["这套房子可能卖$150",{"2":{"1060":1}}],["这绝对是令人注目的成果",{"2":{"1059":1}}],["这西洋棋程序明白了什么是好的布局",{"2":{"1059":1}}],["这程序神奇之处在于",{"2":{"1059":1}}],["这点是确定的",{"2":{"1030":1}}],["这6条实体曲线向真实概率收敛",{"2":{"1026":1}}],["这经常会使人感到困惑",{"2":{"991":1}}],["这需要上千次的卷积神经网络的前向传播来执行目标检测",{"2":{"937":1}}],["这需要wc的词向量vc和从根到w3的路径",{"2":{"709":1}}],["这方面的最好研究可参见",{"2":{"832":1}}],["这为tensorflow带来了命令式编程范式",{"2":{"818":1}}],["这为我们提供了另一种访问网络参数的方式",{"2":{"432":1}}],["这适用于ram",{"2":{"814":1}}],["这进一步增加了开销",{"2":{"812":1}}],["这允许tensorflow删除未使用的值",{"2":{"1021":1}}],["这允许这些训练好的模型部署到其他设备上",{"2":{"821":4}}],["这允许更快地访问存储的记录",{"2":{"805":1}}],["这允许在不需要同步时调用方可以绕过同步",{"2":{"797":1}}],["这允许我们并行执行更多的计算",{"2":{"789":1}}],["这允许我们定义灵活的新层",{"2":{"415":1}}],["这能保证得到更多的方差值",{"2":{"1141":1}}],["这能够减少内存开销并提高处理器利用率",{"2":{"789":1}}],["这能提高正确度吗",{"2":{"353":1}}],["这推动了",{"2":{"731":1}}],["这支持bert表示是上下文敏感的",{"2":{"728":1}}],["这支持了bert表示是上下文敏感的",{"2":{"727":1}}],["这句话",{"2":{"727":1}}],["这往往涉及到用来训练的数据有多少",{"2":{"1141":1}}],["这往往是不可能的",{"2":{"646":1}}],["这往往是低效的",{"2":{"633":1}}],["这往往会导致算法收敛之前过早停止",{"2":{"114":1}}],["这组参数能够在我们从未见过的数据上实现较低的损失",{"2":{"613":1}}],["这组参数能最小化在所有训练样本上的总损失",{"2":{"611":1}}],["这组权重向量和偏置能够使得新样本预测标签的误差尽可能小",{"2":{"610":1}}],["这看起来不像是一个好的参数向量θ的选择",{"2":{"1145":1}}],["这看起来非常像一个更新方程",{"2":{"519":1}}],["这看起来就像我们在循环神经网络中讨论的隐变量模型中的更新方程",{"2":{"519":1}}],["这看起来类似于",{"2":{"156":1}}],["这k个词元将分别是k个候选输出序列的第一个词元",{"2":{"515":1}}],["这大于",{"2":{"513":1}}],["这大大提高了长序列的准确性",{"2":{"300":1}}],["这大大加快了收敛速度",{"2":{"96":1}}],["这大大简化了条件数",{"2":{"26":1}}],["这必须是一个将被放入",{"2":{"509":1}}],["这简化了计算",{"2":{"488":1}}],["这四条路径都使用合适的填充来使输入与输出的高和宽一致",{"2":{"487":1}}],["这四个元素为每个汇聚窗口中的最大值",{"2":{"146":1}}],["这篇论文的一个重点是解决了什么样大小的卷积核最合适的问题",{"2":{"486":1}}],["这篇论文的点睛之笔的发现",{"2":{"73":1}}],["这很像a=1",{"2":{"1091":1}}],["这很明显不是一个好办法",{"2":{"1066":1}}],["这很有用",{"2":{"883":1}}],["这很直观",{"2":{"851":1}}],["这很可能得名于电影",{"2":{"487":1}}],["这很方便",{"2":{"441":1}}],["这很简单",{"2":{"164":1}}],["这h组变换后的查询",{"2":{"380":1}}],["这要从当今十分普及的双组件",{"2":{"355":1}}],["这远远超过了大脑能够完全处理的水平",{"2":{"354":1}}],["这两者之间的差异是些许计算过程上的",{"2":{"1086":1}}],["这两者的界限往往很模糊",{"2":{"639":1}}],["这两种方法都不可行了",{"2":{"1189":1}}],["这两种方式是等价的",{"2":{"1145":1}}],["这两种思考角度",{"2":{"1093":1}}],["这两种写法的结果是相同的",{"2":{"1089":1}}],["这两种算法都是值得学习的",{"2":{"1085":1}}],["这两种情况都有一个显而易见的问题",{"2":{"347":1}}],["这两个版本的公式在理论特性和数学特性上稍有不同",{"2":{"1179":1}}],["这两个基本的长度度量",{"2":{"1156":1}}],["这两个公式会给出同样的结果",{"2":{"1145":1}}],["这两个优化目标应当得到相同的值",{"2":{"1143":1}}],["这两个可以合成或合并成之前的录音",{"2":{"1061":1}}],["这两个文件夹都有hotdog",{"2":{"872":1}}],["这两个文本语料库非常庞大",{"2":{"737":1}}],["这两个数字的匹配会产生稳定的伸缩性",{"2":{"843":1}}],["这两个数据的分布可能不完全一样",{"2":{"253":1}}],["这两个类执行了非常相似的函数",{"2":{"821":1}}],["这两个变量分别位于选择的不同设备上",{"2":{"796":1}}],["这两个变量首先通过嵌入层从词元索引转换成向量",{"2":{"763":1}}],["这两个损失函数与微调下游应用无关",{"2":{"688":1}}],["这两个样本的分类精度率为0",{"2":{"634":1}}],["这两个样本的有效长度分别为2和3",{"2":{"368":1}}],["这两个方向可以拥有不同数量的隐藏单元",{"2":{"521":1}}],["这两个1×1卷积层充当带有relu激活函数的逐像素全连接层",{"2":{"494":1}}],["这两个参数的偏导数",{"2":{"1111":1}}],["这两个参数是θ0和θ1",{"2":{"1111":1}}],["这两个参数将在训练过程中更新",{"2":{"472":1}}],["这两个参数都是标量",{"2":{"470":1}}],["这两个巨大的全连接层拥有将近1gb的模型参数",{"2":{"459":1}}],["这两个函数允许我们在不存在所需所有gpu的情况下运行代码",{"2":{"446":1}}],["这两个函数都要求我们提供一个名称",{"2":{"441":1}}],["这两个函数本质上是相同的",{"2":{"286":1}}],["这两个子层都使用了残差连接和紧随的层规范化",{"2":{"407":1}}],["这两个拼接分别产生形状",{"2":{"340":1}}],["这两个点将在下面进行讨论",{"2":{"258":1}}],["这两个层都是全连接的",{"2":{"231":1}}],["这赋予了模型一定程度的稳定性",{"2":{"334":1}}],["这完全类似于之前在",{"2":{"339":1}}],["这完全忽略了单词的意思",{"2":{"316":1}}],["这完全足够了",{"2":{"27":1}}],["这会给你你估计的参数",{"2":{"1185":1}}],["这会变得更坚定",{"2":{"1143":1}}],["这会帮助你尝试新的想法",{"2":{"1138":1}}],["这会帮助你更系统地做出决定",{"2":{"1138":1}}],["这会大大提高你实践算法时的速度",{"2":{"1138":1}}],["这会是一个很好的技巧",{"2":{"1093":1}}],["这会是一个非常无聊的数据流",{"2":{"651":1}}],["这会增加少量的额外延迟",{"2":{"810":1}}],["这会带来真实梯度的近似",{"2":{"309":1}}],["这会导致额外的传输开销",{"2":{"450":1}}],["这会导致学习算法更新步骤中的权重衰减",{"2":{"279":1}}],["这会导致什么样的问题",{"2":{"239":1}}],["这会导致更多的犯罪行为被发现等等",{"2":{"201":1}}],["这反映了物理学在上个世纪中叶随着计算机的出现所经历的进步",{"2":{"302":1}}],["这成为许多电子商务支付系统的支柱",{"2":{"301":1}}],["这同样适用于阅读银行存款支票和对申请者的信用进行评分",{"2":{"301":1}}],["这导致了更高的计算复杂度",{"2":{"756":1}}],["这导致了更精确的模型",{"2":{"302":1}}],["这导致了不同长度序列的加权和",{"2":{"310":1}}],["这导致了计算机在围棋",{"2":{"300":1}}],["这导致与无替换采样相比",{"2":{"116":1}}],["这也许是他们的技能",{"2":{"1156":1}}],["这也会得出同样的",{"2":{"1143":1}}],["这也就解释了",{"2":{"1143":1}}],["这也就是说",{"2":{"1089":1}}],["这也意味着你可以用更少的代码来实现你需要的功能",{"2":{"1093":1}}],["这也意味着执行随机读取仍然不是一个好主意",{"2":{"802":1}}],["这也可以作为我们对定义的代价函数j进行了完整性检查",{"2":{"1092":1}}],["这也可以降低模型对目标位置的敏感性",{"2":{"879":1}}],["这也验证了一个9×9的魔方阵确实每一列加起来都相等",{"2":{"1090":1}}],["这也解释了为什么即使学习速率a保持不变时",{"2":{"1068":1}}],["这也符合imagenet上预训练模型的标准化操作",{"2":{"905":1}}],["这也称为边际化",{"2":{"1033":1}}],["这也称为乘加融合",{"2":{"809":1}}],["这也称为批量大小",{"2":{"613":1}}],["这也使得并行化变得更加困难",{"2":{"450":1}}],["这也被称为平行块",{"2":{"428":1}}],["这也造就了许多深度学习的中流砥柱",{"2":{"300":1}}],["这也是算法的向量化实现如此重要的缘故",{"2":{"1169":1}}],["这也是没关系的",{"2":{"1122":1}}],["这也是我们的感觉和肌肉运转的原理",{"2":{"1099":1}}],["这也是我们在循环神经网络实验中一直在做的",{"2":{"311":1}}],["这也是为什么在本课中",{"2":{"1061":1}}],["这也是为什么在20世纪90年代至21世纪初",{"2":{"457":1}}],["这也是无监督学习",{"2":{"1061":1}}],["这也是机器学习",{"2":{"1058":1}}],["这也是每个gpu连接到交换机的速度",{"2":{"841":1}}],["这也是后续产生的能够训练网络",{"2":{"800":1}}],["这也是极度希望计算和调度是异步和并行的原因",{"2":{"792":1}}],["这也是由于缺乏有效的计算工具",{"2":{"464":1}}],["这也是",{"2":{"295":1}}],["这也是本书主要涉及的一类模型",{"2":{"228":1}}],["这也是比赛中官方用来评价提交质量的误差指标",{"2":{"210":1}}],["这也是训练比单纯的预测需要更多的内存",{"2":{"165":1}}],["这也是在sgd步长函数中添加学习率函数lr的原因",{"2":{"113":1}}],["这通常也能够告诉你",{"2":{"1129":1}}],["这通常得到一个3×3的矩阵",{"2":{"1090":1}}],["这通常是通过添加非线性来实现的",{"2":{"300":1}}],["这通常被称为层次分类",{"2":{"291":1}}],["这通常被称为独立同分布假设",{"2":{"253":1}}],["这主要是因为两个原因",{"2":{"299":1}}],["这主要是由于在这种情况下对算法进行分析和测试要容易",{"2":{"38":1}}],["这提醒我们",{"2":{"299":1}}],["这类算法具有带标签的数据和样本",{"2":{"1176":1}}],["这类问题的方法通常利用图像中像素之间的相关性",{"2":{"944":1}}],["这类设备的编程对深度学习的临时研究员隐藏得很好",{"2":{"811":1}}],["这类关系通常分为三种类型",{"2":{"665":1}}],["这类解叫作解析解",{"2":{"612":1}}],["这类模型也被称为",{"2":{"347":1}}],["这类数据中不含有",{"2":{"296":1}}],["这类似于前面描述的多层感知机训练和测试",{"2":{"175":1}}],["这类似于",{"2":{"146":1,"693":1}}],["这涉及到用属性注释文本序列",{"2":{"295":1}}],["这款应用程序能够自动理解从图像中看到的文本",{"2":{"291":1}}],["这时最小值为",{"2":{"1143":1}}],["这时候我们需要神经网络",{"2":{"1097":1}}],["这时它问我的电子邮件地址",{"2":{"1094":1}}],["这时indices",{"2":{"1092":1}}],["这时你想写一个软件来检验每一个用户的账户",{"2":{"1060":1}}],["这时你想预测接下来的三个月能卖多少件",{"2":{"1060":1}}],["这时我们可能会期望人工智能不仅能够做出预测",{"2":{"297":1}}],["这时",{"2":{"284":1,"854":1,"1107":1,"1139":1}}],["这时优化可能会停止",{"2":{"102":1}}],["这其实只是当我们使用pca算法时候",{"2":{"1185":1}}],["这其实是正常的",{"2":{"1122":1}}],["这其实就是这个微分项",{"2":{"1067":1}}],["这其实很容易实施且不产生额外损耗",{"2":{"25":1}}],["这其中的计算也超出了人类意识理解范畴",{"2":{"281":1}}],["这称为特征选择",{"2":{"270":1}}],["这项任务评估句子的语义相似度",{"2":{"658":1}}],["这项任务只需不到10行代码就能完成",{"2":{"300":1}}],["这项被称为imagenet的挑战赛推动了计算机视觉和机器学习研究的发展",{"2":{"456":1}}],["这项技术通过函数与零的距离来衡量函数的复杂度",{"2":{"270":1}}],["这项工作为统计学习理论奠定了基础",{"2":{"253":1}}],["这项工作用数学证实了",{"2":{"170":1}}],["这项工作代表了十多年来神经网络研究开发的成果",{"2":{"135":1}}],["这与在线性回归",{"2":{"645":1}}],["这与实际标签2一致",{"2":{"634":1}}],["这与实际标签0不一致",{"2":{"634":1}}],["这与隐马尔可夫模型中的动态规划的前向和后向递归没有太大区别",{"2":{"520":1}}],["这与",{"2":{"513":1,"893":1}}],["这与我们在前面看到的情况大不相同",{"2":{"821":1}}],["这与我们在回归中看到的非常相似",{"2":{"647":1}}],["这与我们在线性回归例子中的相同",{"2":{"625":1}}],["这与我们在",{"2":{"341":1}}],["这与自动语音识别相反",{"2":{"295":1}}],["这与波普尔的科学理论的可证伪性标准密切相关",{"2":{"254":1}}],["这与x∗是局部最小值相矛盾",{"2":{"44":1}}],["这取决于输入和输出的类型",{"2":{"289":1}}],["这取决于一个人优化了多少变量",{"2":{"212":1}}],["这取决于我们遇到的ξt",{"2":{"115":1}}],["这包括了怎样理解某个机器学习算法是否正常工作的原因",{"2":{"1176":1}}],["这包括一些琐碎的工作",{"2":{"301":1}}],["这包括诸如",{"2":{"209":1}}],["这包括卷积层本身",{"2":{"134":1}}],["这便已经是非常大的计算代价",{"2":{"1164":1}}],["这便是监督学习问题中的逻辑回归模型的拟合问题",{"2":{"1109":1}}],["这便于每个人都可以学习哪些方法起作用",{"2":{"207":1}}],["这便涉及到小批量随机梯度下降",{"2":{"76":1}}],["这家初创公司向一所大学校园内的学生征集献血",{"2":{"185":1}}],["这听起来可能很简单",{"2":{"1025":1}}],["这听起来比实际情况要复杂得多",{"2":{"295":1}}],["这听起来很奇怪",{"2":{"183":1}}],["这听起来有点抽象",{"2":{"40":1}}],["这已经成为训练神经网络的常用技术",{"2":{"170":1}}],["这已经表明",{"2":{"27":1}}],["这展示了神经网络的极大灵活性",{"2":{"169":1}}],["这常用来使输出与输入具有相同的高和宽",{"2":{"143":1}}],["这一项也等于1",{"2":{"1143":1}}],["这一项",{"2":{"1143":2}}],["这一条白亮的区段显示的就是神经网络在这里选择的行驶方向",{"2":{"1127":1}}],["这一伟大的人工智能梦想在未来能制造出真正的智能机器",{"2":{"1098":1}}],["这一节我们补充一些细节",{"2":{"1147":1}}],["这一节到此结束",{"2":{"1002":1}}],["这一节只触及到了表面知识",{"2":{"606":1}}],["这一损失也按xi加权",{"2":{"742":1}}],["这一事实无法推断出",{"2":{"665":1}}],["这一好处是以微调下游应用的大量bert参数为代价的",{"2":{"663":1}}],["这一好处将变得更加明显",{"2":{"278":1}}],["这一挑战被称为泛化",{"2":{"613":1}}],["这一单层被称为全连接层",{"2":{"591":1}}],["这一步确定新的隐状态ht∈rn×h",{"2":{"542":1}}],["这一小节是用来说明动态规划问题的",{"2":{"519":1}}],["这一状况在2010年前后兴起的大数据浪潮中得到改善",{"2":{"456":1}}],["这一过程通常是递归的",{"2":{"422":1}}],["这一策略可能会出什么问题呢",{"2":{"353":1}}],["这一错误率降低到2",{"2":{"301":1}}],["这一切都可能在不知情的情况下发生",{"2":{"284":1}}],["这一点同时也可以看作是缺点",{"2":{"1158":1}}],["这一点常常会带来很多方便",{"2":{"1092":1}}],["这一点得到了在本节前面的实验的支持",{"2":{"981":1}}],["这一点在",{"2":{"300":1}}],["这一点很重要",{"2":{"254":1}}],["这一点最容易被理解",{"2":{"77":1}}],["这一领域的先驱可以一直追溯到人工神经元的发明者麦卡洛克和皮茨",{"2":{"236":1}}],["这一情况",{"2":{"126":1}}],["这不会导致任何重大问题",{"2":{"819":1}}],["这不是一个非常好的选择",{"2":{"1145":1}}],["这不是巧合",{"2":{"647":1}}],["这不是我们真正做的",{"2":{"116":1}}],["这不同于用户在本书中的实现",{"2":{"635":1}}],["这不太可能有效",{"2":{"253":1}}],["这不太可行",{"2":{"62":1}}],["这使",{"2":{"1210":1}}],["这使梯度计算在实践中变得容易很多",{"2":{"647":1}}],["这使我们避免了在实践中从零开始编写模型时可能遇到的陷阱",{"2":{"627":1}}],["这使我们只需关注使用哪些层来构造模型",{"2":{"591":1}}],["这使我们能够将变量从x更改为z",{"2":{"94":1}}],["这使我们能够实现对单批量计算平均值的大部分好处",{"2":{"86":1}}],["这使得属性的访问变得更快",{"2":{"1513":1}}],["这使得它们非常昂贵",{"2":{"802":1}}],["这使得它们更节能",{"2":{"457":1}}],["这使得模型没有循环层或卷积层",{"2":{"672":1}}],["这使得模型更健壮",{"2":{"461":1}}],["这使得不同长度的文档的性能具有了可比性",{"2":{"342":1}}],["这使得梯度计算变得复杂",{"2":{"335":1}}],["这使得拉普拉斯平滑非常不适合语言建模",{"2":{"318":1}}],["这使得惩罚的导数很容易计算",{"2":{"270":1}}],["这使得我们能够很好地测试测试数据集",{"2":{"1141":1}}],["这使得我们的学习算法偏向于在大量特征上均匀分布权重的模型",{"2":{"270":1}}],["这使得我们进退两难",{"2":{"247":1}}],["这使得我们可以将输入",{"2":{"119":1}}],["这使得优化表现得更好",{"2":{"235":1}}],["这使得预测价格的对数与真实标签价格的对数之间出现以下均方根误差",{"2":{"210":1}}],["这使得鞍点比局部最小值更有可能出现",{"2":{"102":1}}],["这产生了",{"2":{"95":1}}],["这产生了一个类似于余弦的调度",{"2":{"72":1}}],["这产生了一个学习率o",{"2":{"27":1}}],["这显示了在我们将学习率η提高到ηλ=1之前",{"2":{"95":1}}],["这在你刚接触机器学习问题时是一个很好的方法",{"2":{"1138":1}}],["这在机器学习里基本用不上",{"2":{"1090":1}}],["这在硅谷有巨大的市场",{"2":{"1058":1}}],["这在计算上可能非常昂贵",{"2":{"742":1}}],["这在计算上是不可行的",{"2":{"306":1}}],["这在损失平面上只有一个临界点",{"2":{"612":1}}],["这在",{"2":{"534":1}}],["这在概念上很容易",{"2":{"520":1}}],["这在数值上是不稳定的",{"2":{"312":1}}],["这在现实中是可取的",{"2":{"309":1}}],["这在时间序列分析中是相当常见的",{"2":{"305":1}}],["这在动量法中也适用",{"2":{"94":1}}],["这在直觉上是有道理的",{"2":{"73":1}}],["这有时会对于你的学习算法造成非常微妙的影响",{"2":{"1139":1}}],["这有助于我们直观理解svm模型的假设是什么样的",{"2":{"1144":1}}],["这有助于我们弄清楚如何把最有可能的直线与我们的数据相拟合",{"2":{"1064":1}}],["这有助于识别边缘",{"2":{"869":1}}],["这有助于模型识别每个训练样本",{"2":{"208":1}}],["这有点像排队订购咖啡",{"2":{"450":1}}],["这有关系吗",{"2":{"280":1}}],["这有效地将瞬时梯度替换为多个",{"2":{"86":1}}],["这有两个好处",{"2":{"25":1}}],["这相当于每个链路每个方向约300÷8÷2≈18gb",{"2":{"842":1}}],["这相当于每个迭代轮数有1500次更新",{"2":{"80":1}}],["这相当于最小化以下损失函数",{"2":{"784":1}}],["这相当于|ci|",{"2":{"742":1}}],["这相当于两个全连接层共享参数",{"2":{"425":4}}],["这相当于根据半正定矩阵的定义",{"2":{"46":1}}],["这本身就是一件好事",{"2":{"78":1}}],["这既是坏事也是好事",{"2":{"334":1}}],["这既适用于计算梯度以更新参数时",{"2":{"78":1}}],["这既涉及参数最初的设置方式",{"2":{"66":1}}],["这耗费相当大",{"2":{"78":1}}],["这暗示了两者之间可能有折中方案",{"2":{"76":1}}],["这引出了如下表所示的时间表",{"2":{"73":1}}],["这引出了许多adagrad算法的变体",{"2":{"27":1}}],["这比从一份扫描文档中识别文字要复杂的多",{"2":{"1171":1}}],["这比使用pcie总线要好",{"2":{"842":1}}],["这比我们提供的数据样本少了τ个",{"2":{"350":1}}],["这比我们的泛化误差要好得多",{"2":{"252":1}}],["这比恶意超级智能毁灭人类的风险更令人担忧",{"2":{"301":1}}],["这比以前好一些",{"2":{"68":1}}],["这比计算特征值开销小的多",{"2":{"26":1}}],["这超出了本章的范围",{"2":{"66":1}}],["这被认为是一个文本分类问题",{"2":{"696":1}}],["这被称为强制教学",{"2":{"576":1}}],["这被称为编码器",{"2":{"532":1}}],["这被称为预热",{"2":{"333":1}}],["这被称之为二项分类",{"2":{"291":1}}],["这被称之为目标函数",{"2":{"286":1}}],["这被戏称为预热",{"2":{"66":1}}],["这被证明比精确的满意度更可靠",{"2":{"49":1}}],["这就意味着",{"2":{"1154":1}}],["这就意味着当",{"2":{"1143":1}}],["这就意味这他使用了不带有核函数的svm",{"2":{"1148":1}}],["这就等于θ1⋅x1",{"2":{"1145":1}}],["这就相当于在支持向量机中嵌入了一个额外的安全因子",{"2":{"1144":1}}],["这就相当于我们想要最小化a加上正则化参数λ",{"2":{"1143":1}}],["这就得到了在支持向量机中我们的整个优化目标函数",{"2":{"1143":1}}],["这就得出了门控循环单元的最终更新公式",{"2":{"542":1}}],["这就确认了你已经做对了第一部分练习",{"2":{"1094":1}}],["这就确保了ht的值始终在区间",{"2":{"556":1}}],["这就告诉",{"2":{"1092":1}}],["这就表示",{"2":{"1090":1}}],["这就生成了一个3×3的矩阵",{"2":{"1088":1}}],["这就允许我们定义下面两个操作",{"2":{"844":1}}],["这就限制了以全带宽与cpu连接的gpu数量",{"2":{"812":1}}],["这就要求使用循环神经网络实现的编码器和解码器具有相同数量的层和隐藏单元",{"2":{"574":1}}],["这就不是一个大问题",{"2":{"526":1}}],["这就产生了基于x^t=p",{"2":{"347":1}}],["这就使我们能够训练一个上面提及的深度网络",{"2":{"347":1}}],["这就像模型是一个列表一样",{"2":{"430":1}}],["这就像试图确定披萨所需的配料一样困难",{"2":{"302":1}}],["这就像在训练集上评估一样",{"2":{"65":1}}],["这就是你从低维表示z回到未压缩的表示",{"2":{"1161":1}}],["这就是聚类算法",{"2":{"1150":1}}],["这就是利用核函数的支持向量机算法",{"2":{"1147":1}}],["这就是支持向量机如何能有效地产生大间距分类的原因",{"2":{"1145":1}}],["这就是支持向量机数学上的定义",{"2":{"1143":1}}],["这就是相对应的参数θ的方向",{"2":{"1145":1}}],["这就是关于向量内积的知识",{"2":{"1145":1}}],["这就是具体做法",{"2":{"1145":1}}],["这就是向量u即在横轴上",{"2":{"1145":1}}],["这就是他们得到的结果",{"2":{"1141":1}}],["这就是基于神经网络的自动驾驶技术",{"2":{"1127":1}}],["这就是基于图的计算后端进行优化的优势所在",{"2":{"797":1}}],["这就是正则化的基本方法",{"2":{"1115":1}}],["这就是多类别分类问题",{"2":{"1112":1}}],["这就是高级优化的概念",{"2":{"1111":1}}],["这就是逻辑回归的代价函数",{"2":{"1110":1}}],["这就是神经网络的厉害之处",{"2":{"1102":1}}],["这就是神经网络相比于逻辑回归和线性回归的优势",{"2":{"1100":1}}],["这就是and函数",{"2":{"1101":1}}],["这就是所有人类思考的模型",{"2":{"1099":1}}],["这就是所谓的分布偏移",{"2":{"202":1}}],["这就是轴突",{"2":{"1099":1}}],["这就是声纳",{"2":{"1098":1}}],["这就是提交作业的方法",{"2":{"1094":1}}],["这就是2",{"2":{"1092":1}}],["这就是说",{"2":{"1092":1}}],["这就是在线学习机制",{"2":{"1168":1}}],["这就是在",{"2":{"1092":1}}],["这就是if",{"2":{"1092":1}}],["这就是一个决策边界可以把正样本和负样本分开",{"2":{"1144":1}}],["这就是一个while循环的句法结构",{"2":{"1092":1}}],["这就是一个",{"2":{"1092":1}}],["这就是一个监督学习算法的工作方式",{"2":{"1063":1}}],["这就是两个矩阵的元素位运算",{"2":{"1090":1}}],["这就是移动数据这一节课",{"2":{"1089":1}}],["这就是读取和储存数据的方法",{"2":{"1089":1}}],["这就是用于线性回归的梯度下降法",{"2":{"1069":1}}],["这就是梯度下降算法",{"2":{"1068":1}}],["这就是梯度下降的做法",{"2":{"1068":1}}],["这就是我画出的训练样本",{"2":{"1145":1}}],["这就是我的",{"2":{"1092":1}}],["这就是我梯度下降法的更新规则",{"2":{"1068":1}}],["这就是我们先前给出的支持向量机模型中的目标函数",{"2":{"1145":1}}],["这就是我们之前的例子",{"2":{"1135":1}}],["这就是我们通常用的梯度下降法的模板",{"2":{"1110":1}}],["这就是我们通常书写矩阵的形式",{"2":{"1089":1}}],["这就是我们即将学到最有趣的学习算法之一",{"2":{"1060":1}}],["这就是我们需要显式参数值的原因",{"2":{"431":1}}],["这就是我们将特征从xi调整为xii",{"2":{"262":1}}],["这就是0",{"2":{"1063":1}}],["这就是监督学习算法的一个例子",{"2":{"1063":1}}],["这就是机器学习",{"2":{"1059":1}}],["这就是公共抽象值得使用的原因",{"2":{"844":1}}],["这就是显示并行化优势的地方",{"2":{"828":1}}],["这就是显著的进步",{"2":{"154":1}}],["这就是使用缓存的地方",{"2":{"810":1}}],["这就是输出门发挥作用的地方",{"2":{"556":1}}],["这就是为什么我们能够向量化地实现线性回归",{"2":{"1093":1}}],["这就是为什么这里我的",{"2":{"1093":1}}],["这就是为什么这种方法有时被称为权重衰减",{"2":{"270":1}}],["这就是为什么缓存大小",{"2":{"810":1}}],["这就是为什么前端的分支预测单元很重要",{"2":{"808":1}}],["这就是为什么拷贝操作要格外小心",{"2":{"450":1}}],["这就是称前馈网络是基于位置的",{"2":{"405":1}}],["这就是需要机器学习的原因",{"2":{"282":1}}],["这就是现在标准且实用的xavier初始化的基础",{"2":{"247":1}}],["这就是现实让事情变得复杂的地方",{"2":{"208":1}}],["这就是卷积",{"2":{"154":1}}],["这就是",{"2":{"152":1,"1093":1,"1154":2}}],["这就是鞍点的名字由来",{"2":{"102":1}}],["这就是g在半径为θ的球上的投影",{"2":{"50":1}}],["这就是yogi更新",{"2":{"35":1}}],["这种算法的一个有趣之处在于",{"2":{"1178":1}}],["这种算法能很好地拟合训练集",{"2":{"1141":1}}],["这种理念是",{"2":{"1138":1}}],["这种使用不同的线性代数库的方法被称为伪逆",{"2":{"1086":1}}],["这种教法不好",{"2":{"1059":1}}],["这种机制的工作方式如下",{"2":{"1019":1}}],["这种约定将支持常见的深度学习实践",{"2":{"992":1}}],["这种问题在深度学习中是无处不在的",{"2":{"980":1}}],["这种损失类似于l1范数损失",{"2":{"966":1}}],["这种庞大的计算量使得r",{"2":{"937":1}}],["这种适应会严重影响同步所需的时间",{"2":{"845":1}}],["这种转换在下面的",{"2":{"852":1}}],["这种转换正是编译过程的一部分",{"2":{"821":1}}],["这种转变集中体现了现代深度网络的设计原则",{"2":{"520":1}}],["这种魔法并不适用于每一层",{"2":{"819":1}}],["这种硬件和算法的协同进化导致了这样一种情况",{"2":{"811":1}}],["这种代码在多个处理器上运行的速度可能要慢得多",{"2":{"810":1}}],["这种芯片的存储器接口仅支持20",{"2":{"810":1}}],["这种执行方式是通过向量处理单元实现的",{"2":{"809":1}}],["这种驱动器称为nvme",{"2":{"805":1}}],["这种强制说明了之前发生的情况",{"2":{"790":3}}],["这种偶然的噪声鼓励bert在其双向上下文编码中不那么偏向于掩蔽词元",{"2":{"736":1}}],["这种对齐是使用加权平均的软对齐",{"2":{"683":1}}],["这种对齐是使用加权平均的",{"2":{"674":1}}],["这种想法归功于我们对真实生物神经系统的研究",{"2":{"619":1}}],["这种变体叫做小批量随机梯度下降",{"2":{"613":1}}],["这种变化似乎是正则化的一种形式",{"2":{"467":1}}],["这种网络可以更好地处理序列数据",{"2":{"550":1}}],["这种设计是为了支持非常小数量",{"2":{"811":1}}],["这种设计的一个好处是python前端线程不需要执行实际的计算",{"2":{"790":1}}],["这种设计的动机与门控循环单元相同",{"2":{"552":1}}],["这种设计有时会增加训练模型的时间",{"2":{"495":1}}],["这种设计被称为多头注意力",{"2":{"380":1}}],["这种解释只提供了一种不明确的直觉",{"2":{"475":1}}],["这种解释有两个问题",{"2":{"475":1}}],["这种偏移与严格定义的协变量偏移",{"2":{"475":1}}],["这种噪声是一个问题",{"2":{"467":1}}],["这种标准化可以很好地与我们的优化器配合使用",{"2":{"467":1}}],["这种明显的优势也是它的致命弱点",{"2":{"457":1}}],["这种规模是前所未有的",{"2":{"456":1}}],["这种能力可以大大简化定义和修改模型的任务",{"2":{"417":1}}],["这种掩蔽",{"2":{"404":1}}],["这种投影的数学解释是",{"2":{"400":1}}],["这种基于三角函数的设计看起来很奇怪",{"2":{"398":1}}],["这种只将注意力引向感兴趣的一小部分信息的能力",{"2":{"354":1}}],["这种效应会使评分提高半个百分点以上",{"2":{"345":1}}],["这种影响将持续几个月",{"2":{"345":1}}],["这种做法似乎毫无道理",{"2":{"334":1}}],["这种做法在这里是合理的",{"2":{"116":1}}],["这种模型通常被称为resnet",{"2":{"502":1}}],["这种模型被称为自回归模型",{"2":{"347":1}}],["这种模型根本不能输出好的结果",{"2":{"326":1}}],["这种模块化设计使我们能够将与模型架构有关的内容独立出来",{"2":{"225":1}}],["这种策略在基于小批量的迭代过程中保留了拆分的子序列的顺序",{"2":{"321":1}}],["这种性质推导出了许多可以应用于序列建模的近似公式",{"2":{"317":1}}],["这种相似性会导致语音识别中的歧义",{"2":{"315":1}}],["这种截断是通过在给定数量的时间步之后分离梯度来实现的",{"2":{"312":1}}],["这种方式的好处在于",{"2":{"1168":1}}],["这种方式下",{"2":{"832":1}}],["这种方式效率不高",{"2":{"797":3}}],["这种方式提供了一个重要的上限",{"2":{"342":1}}],["这种方式工作得很好",{"2":{"309":1}}],["这种方法称为密度估计",{"2":{"1178":1}}],["这种方法不需要定时地扫描整个训练集",{"2":{"1167":1}}],["这种方法在k较小的时候",{"2":{"1153":1}}],["这种方法的思想是通过估计梯度值来检验我们计算的导数值是否真的是我们要求的",{"2":{"1124":1}}],["这种方法的好处是什么",{"2":{"770":1}}],["这种方法最简单",{"2":{"832":1}}],["这种方法何时会失效",{"2":{"621":1}}],["这种方法几乎可以优化所有深度学习模型",{"2":{"613":1}}],["这种方法几乎从未使用过",{"2":{"308":1}}],["这种方法效果不错",{"2":{"316":1}}],["这种方法通常很有效",{"2":{"246":1}}],["这种方法注定会失败",{"2":{"230":1}}],["这种方法之所以被称为暂退法",{"2":{"170":1}}],["这种在处理统计问题上新发现的经验主义",{"2":{"302":1}}],["这种简单的离线学习有它的魅力",{"2":{"297":1}}],["这种",{"2":{"282":1,"291":1,"532":1}}],["这种集成还有计算上的好处",{"2":{"278":1}}],["这种现象被称为欠拟合",{"2":{"258":1}}],["这种现象早已在梯度下降中出现",{"2":{"53":1}}],["这种架构通常称为多层感知机",{"2":{"231":1}}],["这种表示会考虑到我们在特征之间的相关交互作用",{"2":{"230":1}}],["这种情况下",{"2":{"1184":1}}],["这种情况下误差分析能够帮助我们",{"2":{"1183":1}}],["这种情况下可以获得的最佳模型是什么",{"2":{"75":1}}],["这种情况类似于为自己的博客从零开始编写网页",{"2":{"591":1}}],["这种情况正是我们想要避免或控制的",{"2":{"253":1}}],["这种情况不太可能通过常规方法加以纠正",{"2":{"185":1}}],["这种情况可能会带来灾难性的后果",{"2":{"179":1}}],["这种区别是表面的",{"2":{"156":1}}],["这种缺少结构的网络可能会变得不实用",{"2":{"151":1}}],["这种数据的每个样本都由一个二维像素网格组成",{"2":{"134":1}}],["这种优化以指数速度收敛",{"2":{"95":1}}],["这种改进并不一定成立",{"2":{"72":1}}],["这种分布可以在给定值a=a",{"2":{"1032":1}}],["这种分解技巧导致f只有m+n个次计算",{"2":{"674":1}}],["这种分段恒定学习率调度背后的直觉是",{"2":{"71":1}}],["这种分析要求f在高阶导数上表现良好",{"2":{"60":1}}],["这对应于θtx",{"2":{"1143":1}}],["这对应于inception块中的第二条路径",{"2":{"488":1}}],["这对于一般的逻辑回归来说需要计算的特征太多了",{"2":{"1097":1}}],["这对于本地集成和命令行工具特别有用",{"2":{"1047":1}}],["这对于我们想要估计的模型而言是非常不可取的",{"2":{"308":1}}],["这对实现我们的目标来说是非常好的",{"2":{"844":1}}],["这对实验有什么影响",{"2":{"511":1}}],["这对源语言和目标语言的词表大小有何影响",{"2":{"571":1}}],["这对词表大小有何影响",{"2":{"366":1}}],["这对确保梯度条件合适有什么启示",{"2":{"250":1}}],["这对从渲染引擎中抽取的",{"2":{"186":1}}],["这对检测疾病的分类器可能并不适用",{"2":{"185":1}}],["这对某些高级网络设计来说尤其棘手",{"2":{"73":1}}],["这对某些ξ",{"2":{"60":1}}],["这对自然语言来说很常见",{"2":{"25":1}}],["这似乎违背了初衷",{"2":{"59":1}}],["这发生了惊人的错误",{"2":{"59":1}}],["这些组件可以支持多种类型而不失去类型信息",{"2":{"1429":1}}],["这些是函数式编程中非常重要的高阶函数",{"2":{"1240":1}}],["这些系统会带来很大一部分收入",{"2":{"1187":1}}],["这些推荐系统",{"2":{"1187":1}}],["这些参考会有一些模糊",{"2":{"1148":1}}],["这些参数可以拟合非常复杂的函数",{"2":{"1141":1}}],["这些参数可以通过在合适的数据集上进行训练而获得",{"2":{"500":1}}],["这些参数可以通过内置函数创建",{"2":{"415":1}}],["这些参数可以通过训练进行调整",{"2":{"414":1}}],["这些参数仅用于计算预训练过程中的遮蔽语言模型损失和下一句预测损失",{"2":{"688":1}}],["这些参数是预训练bert模型bert中参数的一部分",{"2":{"688":1}}],["这些参数根据从下一层反向传播的信号进行更新",{"2":{"422":1}}],["这些参数相当准确地描述了人体的形状",{"2":{"296":1}}],["这些参数通过某种性能度量方式来达到完成任务的最佳性能",{"2":{"282":1}}],["这些核函数需要满足mercer",{"2":{"1148":1}}],["这些核函数的目标也都是根据训练集和地标之间的距离来构建新特征",{"2":{"1148":1}}],["这些投影长度是长多了",{"2":{"1145":1}}],["这些决策边界看起来都不是特别好的选择",{"2":{"1144":1}}],["这些学习算法能够拟合非常复杂的函数",{"2":{"1141":1}}],["这些信息可以帮助我们用来准确地预测y",{"2":{"1141":1}}],["这些结果表明",{"2":{"1141":1}}],["这些结构给了我们应用模型的希望",{"2":{"318":1}}],["这些趋势非常明显",{"2":{"1141":1}}],["这些具体算法的细节不那么重要",{"2":{"1141":1}}],["这些不同类型的算法效果都很好",{"2":{"1141":1}}],["这些视频将谈及在设计复杂的机器学习系统时",{"2":{"1137":1}}],["这些诊断法的执行和实现",{"2":{"1129":1}}],["这些高级优化算法需要你自己设计代价函数j",{"2":{"1117":1}}],["这些弱电流也称作动作电位",{"2":{"1099":1}}],["这些都应该是同步更新",{"2":{"1093":1}}],["这些都是三个样本",{"2":{"1185":1}}],["这些都是非常强大的学习算法",{"2":{"1141":1}}],["这些都是我们需要对θ0",{"2":{"1093":1}}],["这些都是我希望讲授的主题",{"2":{"1059":1}}],["这些都是基本的数学运算",{"2":{"1088":1}}],["这些都是聚类的例子",{"2":{"1061":1}}],["这些都是学习算法里面很好的例子",{"2":{"1060":1}}],["这些都是机器学习算法的一员",{"2":{"1059":1}}],["这些库文件都是内置的",{"2":{"1093":1}}],["这些就是我们用简单的训练样本尝试的几次试验",{"2":{"1092":1}}],["这些就是存在里面的数据",{"2":{"1089":1}}],["这些语句",{"2":{"1092":1}}],["这些语言理解或图像理解都是属于ai领域",{"2":{"1058":1}}],["这些元素都是a",{"2":{"1089":1}}],["这些人不得不中途放弃了",{"2":{"1088":1}}],["这些小碎步需要朝什么方向",{"2":{"1067":1}}],["这些聚类算法给出了令人惊讶",{"2":{"1061":1}}],["这些颜色展示了相应的程度",{"2":{"1061":1}}],["这些新闻事件全是同一主题的",{"2":{"1061":1}}],["这些联系我的人都对将学习算法应用于他们自己的问题感兴趣",{"2":{"1058":1}}],["这些通信机制确保了客户端与服务器之间的高效",{"2":{"1047":1}}],["这些通道有时也被称为特征映射",{"2":{"158":1}}],["这些功能使得张量类更适合深度学习",{"2":{"1016":1}}],["这些分解可以显示真实世界数据集中的低维结构",{"2":{"1002":1}}],["这些转换是非常有用的",{"2":{"998":1}}],["这些标量值被称为向量的元素",{"2":{"990":1}}],["这些内容有助于读者了解和实现本书中介绍的大多数模型",{"2":{"988":1}}],["这些预测结果是从生成的锚框及其预测偏移量中获得的",{"2":{"962":1}}],["这些感兴趣的区域需要进一步抽取出形状相同的特征",{"2":{"938":1}}],["这些感官输入远远超过了大脑能够完全处理的程度",{"2":{"379":1}}],["这些感官输入被称为值",{"2":{"356":1}}],["这些形状各异的提议区域在卷积神经网络的输出上分别标出了形状各异的兴趣区域",{"2":{"938":1}}],["这些提议区域通常是在多个尺度下选取的",{"2":{"937":1}}],["这些锚框代表了图像不同区域的样本",{"2":{"911":1}}],["这些图层也称为风格层",{"2":{"920":1}}],["这些图片共涵盖10个类别",{"2":{"888":1}}],["这些图看起来和我们从零开始实现权重衰减时的图相同",{"2":{"278":1}}],["这些方法可以被同时应用",{"2":{"884":1}}],["这些方法不能直接应用于深度学习",{"2":{"58":1}}],["这些类型又是什么",{"2":{"1061":1}}],["这些类型的知识至关重要",{"2":{"200":1}}],["这些类似的特征也可能有效地识别椅子",{"2":{"869":1}}],["这些区域的并集需要完整覆盖输入图像",{"2":{"866":1}}],["这些区域的梯度几乎为0",{"2":{"460":1}}],["这些边界框被称为锚框",{"2":{"847":1}}],["这些机器",{"2":{"843":1}}],["这些机制是可学习的",{"2":{"539":1}}],["这些文件可以被其他前端语言读取",{"2":{"821":1}}],["这些优化电路对深度学习特别有效",{"2":{"811":1}}],["这些优势在预处理环境中很容易被理解",{"2":{"25":1}}],["这些集群构成了高端tu102处理器",{"2":{"811":1}}],["这些处理单元有不同的名称",{"2":{"809":1}}],["这些改进听起来好的难以置信",{"2":{"805":1}}],["这些盘片的磁头可以放置在任何给定的磁道上进行读写",{"2":{"804":1}}],["这些线程不断收集和执行排队的任务",{"2":{"790":3}}],["这些向量能更好地表达不同词之间的相似性和类比关系",{"2":{"782":1}}],["这些非零的xij是预先计算的全局语料库统计数据",{"2":{"743":1}}],["这些任务分为以下几个大类",{"2":{"733":1}}],["这些辅助函数将在稍后将原始文本语料库转换为理想格式的数据集时调用",{"2":{"719":1}}],["这些事件同时涉及正例和负例",{"2":{"710":1}}],["这些词经常在上下文窗口中与许多不同的词共同出现",{"2":{"773":1}}],["这些词嵌入模型都是与上下文无关的",{"2":{"730":1}}],["这些词元表示",{"2":{"703":1}}],["这些词通常",{"2":{"318":1}}],["这些乘法的总和在输出张量的相应位置给出单个标量值",{"2":{"699":1}}],["这些数据不总是人能读懂的",{"2":{"1189":1}}],["这些数据是有关这些东西的特征",{"2":{"1188":1}}],["这些数据具有支持决策过程的巨大潜力",{"2":{"691":1}}],["这些数都是实数",{"2":{"1089":1}}],["这些数字在实践中通常会差一些",{"2":{"842":1}}],["这些数学运算与卷积层的计算惊人地相似",{"2":{"457":1}}],["这些应用没有预训练",{"2":{"663":1}}],["这些违反了",{"2":{"643":1}}],["这些值可能会四舍五入为零",{"2":{"624":1}}],["这些估计值也不会使损失函数真正地达到最小值",{"2":{"613":1}}],["这些可以调整但不在训练过程中更新的参数称为超参数",{"2":{"613":1}}],["这些可能是使用深度学习的主要候选者",{"2":{"304":1}}],["这些框架可以自动化基于梯度的学习算法中重复性的工作",{"2":{"588":1}}],["这些技术可能并不够用",{"2":{"550":1}}],["这些技术系统可能会通过其进行的决定而影响到每个人的生活",{"2":{"201":1}}],["这些设计可以帮助我们处理循环神经网络中的梯度消失问题",{"2":{"542":1}}],["这些设备有多种类型的内存",{"2":{"77":1}}],["这些因素都导致了resnet迅速被广泛使用",{"2":{"502":1}}],["这些神经元",{"2":{"1099":1}}],["这些神经元依赖于每个输入的值",{"2":{"233":1}}],["这些神经网络的性能会发生很大变化",{"2":{"492":1}}],["这些后续版本包括",{"2":{"491":1}}],["这些比例在各个inception块中都略有不同",{"2":{"488":1}}],["这些路径的通道数分配和第三模块中的类似",{"2":{"488":1}}],["这些特定的函数统称为",{"2":{"1470":1}}],["这些特殊词元在自然语言处理任务中比较常用",{"2":{"567":1}}],["这些特性不是必要的",{"2":{"486":1}}],["这些特征会逐渐优化",{"2":{"1100":1}}],["这些特征抽取器被自动调整的滤波器所取代",{"2":{"302":1}}],["这些特征具有零均值和单位方差",{"2":{"209":1}}],["这些特征由各种数据类型组成",{"2":{"208":1}}],["这些理论揭示了为什么批量规范化最适应50∼100范围中的中等批量大小的难题",{"2":{"467":1}}],["这些变量分布中的这种偏移可能会阻碍网络的收敛",{"2":{"467":1}}],["这些变量捕获并保留了序列直到其当前时间步的历史信息",{"2":{"340":1}}],["这些层的索引可以通过打印pretrained",{"2":{"920":1}}],["这些层是由层组",{"2":{"422":1}}],["这些层将输入映射到多个二维特征输出",{"2":{"136":1}}],["这些函数提供一些基本的管理功能",{"2":{"414":1}}],["这些子层也都被残差连接和紧随的层规范化围绕",{"2":{"408":1}}],["这些知识也将适用于目标数据集",{"2":{"870":1}}],["这些知识将为本书其他部分中更复杂的技术奠定基础",{"2":{"587":1}}],["这些知识将使读者从深度学习",{"2":{"421":1}}],["这些知识的不同来源于相同的查询",{"2":{"383":1}}],["这些知识已经让你掌握了一个类似于1990年左右深度学习从业者的工具",{"2":{"237":1}}],["这些步骤通常包括",{"2":{"360":1}}],["这些余震的强度比非大地震后的余震要大得多",{"2":{"345":1}}],["这些隐状态可以用作后续输出层的输入",{"2":{"325":1}}],["这些概率本质上就是语言模型的参数",{"2":{"316":1}}],["这些多层模型能够以以前的工具所不能的方式处理低级的感知数据",{"2":{"302":1}}],["这些算法的性能也都对应地增强了",{"2":{"1141":1}}],["这些算法都是在他们2001年进行研究的时候",{"2":{"1141":1}}],["这些算法实际上在做更复杂的事情",{"2":{"1111":1}}],["这些算法有",{"2":{"1109":1}}],["这些算法更加复杂和优越",{"2":{"1109":1}}],["这些算法在很大程度上受到统计模型固有灵活性的限制",{"2":{"300":1}}],["这些算法不需要数周的训练",{"2":{"299":1}}],["这些算法可以模拟下面概述的算法的许多理想特性",{"2":{"58":1}}],["这些工具允许重复修改深度神经网络的内部状态",{"2":{"300":1}}],["这些工具算法催生了自然科学中的一种实验方法",{"2":{"299":1}}],["这些工具倾向于改进深层网络的泛化性",{"2":{"169":1}}],["这些输入和相应的标签一起构成了训练数据集",{"2":{"289":1}}],["这些样本可以通过自定义的filter函数移除掉",{"2":{"947":1}}],["这些样本可能需要被人工标记",{"2":{"289":1}}],["这些样本将在自然语言推断的训练和测试期间进行小批量读取",{"2":{"687":1}}],["这些样本是随机读取的",{"2":{"600":2}}],["这些样本已有标签",{"2":{"289":1}}],["这些模块可以通过开源框架灵活组合",{"2":{"1052":1}}],["这些模型在有空间或时间限制的情况下是有帮助的",{"2":{"656":1}}],["这些模型在深度学习框架的高级api中都有涵盖",{"2":{"530":1}}],["这些模型包括",{"2":{"492":1}}],["这些模型由神经网络错综复杂的交织在一起",{"2":{"285":1}}],["这些模型的方差很低",{"2":{"169":1}}],["这些模式捕捉到了我们训练集潜在总体的规律",{"2":{"251":1}}],["这些地方sigmoid函数的输入接近于零",{"2":{"242":1}}],["这些问题中的任何一个都可以被归类到标准的",{"2":{"1168":1}}],["这些问题可以如何解决",{"2":{"607":1}}],["这些问题与消费者直接相关",{"2":{"301":1}}],["这些问题是序列学习的实例",{"2":{"295":1}}],["这些问题是成功训练深度网络的关键",{"2":{"204":1}}],["这些问题经常会出现",{"2":{"241":1}}],["这些启发式方法在整个深度学习生涯中都很有用",{"2":{"240":1}}],["这些初始化方案的选择可以与非线性激活函数的选择有趣的结合在一起",{"2":{"240":1}}],["这些经验将有益数据科学家的职业成长",{"2":{"205":1}}],["这些只是在机器学习职业生涯中可能遇到的令人感到",{"2":{"201":1}}],["这些抽样可能会遇到极端的协变量偏移",{"2":{"185":1}}],["这些中间值的大小与网络层的数量和批量的大小大致成正比",{"2":{"165":1}}],["这些操作分别称为最大汇聚层",{"2":{"146":1}}],["这些网络架构涵盖了现代从业者通常使用的大多数经典技术",{"2":{"134":1}}],["这些目标凸函数三次可微",{"2":{"60":1}}],["这将是我们介绍的第一个非监督学习算法",{"2":{"1150":2}}],["这将是我们能做的最好的编码方式",{"2":{"342":1}}],["这将是一个激动人心的时刻",{"2":{"1150":1}}],["这将遵从以下的约束",{"2":{"1144":1}}],["这将给我们一些关于支持向量机模型的直观感受",{"2":{"1144":1}}],["这将意味着我们第二层的所有激活单元都会有相同的值",{"2":{"1125":1}}],["这将我们将得到某个参数$",{"2":{"1110":1}}],["这将影响梯度下降算法寻找全局最小值",{"2":{"1109":1}}],["这将修改该函数以产生5×5的单位矩阵",{"2":{"1094":1}}],["这将会非常令人惊奇",{"2":{"1098":1}}],["这将会是一幅15",{"2":{"1091":1}}],["这将会变成一个101维的矢量",{"2":{"1086":1}}],["这将找出所有a矩阵中大于等于7的元素",{"2":{"1090":1}}],["这将告诉我a",{"2":{"1090":1}}],["这将进行逐元素的运算",{"2":{"1090":1}}],["这将对矩阵a中每一个元素平方",{"2":{"1090":1}}],["这将返回a矩阵中的最大值存入val",{"2":{"1090":1}}],["这将返回a矩阵中的最大值15",{"2":{"1090":1}}],["这将返回",{"2":{"1089":1}}],["这将索引到a",{"2":{"1089":1}}],["这将计算出θ的值",{"2":{"1086":1}}],["这将帮助梯度下降算法更快地收敛",{"2":{"1082":1}}],["这将取决于疾病有多常见",{"2":{"1035":1}}],["这将减少计算时间和节省内存空间",{"2":{"909":1}}],["这将复制源模型上的所有模型设计及其参数",{"2":{"870":1}}],["这将允许在不牺牲模型实现方式的情况下优化计算密集型组件",{"2":{"818":1}}],["这将允许进行大量的优化",{"2":{"817":1}}],["这将产生一个具有形状",{"2":{"631":1}}],["这将产生以下实现",{"2":{"21":1}}],["这将使我们能够使我们的一些学习算法运行也较晚",{"2":{"1156":1}}],["这将使我们能够更方便地通过最外层的维度",{"2":{"330":1}}],["这将使得我们获得一条新的直线",{"2":{"1107":1}}],["这将使梯度下降更加强大",{"2":{"1069":1}}],["这将使训练加速",{"2":{"773":1}}],["这将使分母或分子变为inf",{"2":{"624":1}}],["这将得到每一行的最大值",{"2":{"1090":1}}],["这将得到",{"2":{"519":1,"1089":1}}],["这将有助于研究开发自己的架构",{"2":{"492":1}}],["这将保存模型的参数而不是保存整个模型",{"2":{"442":1}}],["这将引导得出最匹配的值",{"2":{"356":1}}],["这将在后面的",{"2":{"747":1}}],["这将在后面描述",{"2":{"426":1}}],["这将在后续部分中用于评估基于循环神经网络的模型",{"2":{"342":1}}],["这将在",{"2":{"325":1}}],["这将聚合非常对齐的梯度",{"2":{"88":1}}],["这将确保|w|2−r2≤0",{"2":{"49":1}}],["这样既提升了并发能力",{"2":{"1200":1}}],["这样得到的新特征是建立在原有特征与训练集中所有其他特征之间的距离基础上",{"2":{"1147":1}}],["这样来写θ的范数",{"2":{"1145":1}}],["这样当你求解这个优化问题的时候",{"2":{"1144":1}}],["这样当前目录就变为了桌面",{"2":{"1089":1}}],["这样你可以对不同类型的客户分别销售产品或者分别提供更适合的服务",{"2":{"1150":1}}],["这样你可以很快地实现它",{"2":{"1138":1}}],["这样你才能自己掌握这种算法",{"2":{"1122":1}}],["这样你就能给你的用户推荐几部不同的电影了",{"2":{"1191":1}}],["这样你就能更好地理解你使用的学习算法",{"2":{"1090":1}}],["这样你就能节省出大量的时间",{"2":{"1088":1}}],["这样才能更好的应用正则化",{"2":{"1115":1}}],["这样构建的cost",{"2":{"1109":1}}],["这样从眼睛到视神经的信号最终将传到听觉皮层",{"2":{"1098":1}}],["这样向量化的实现更简单",{"2":{"1093":1}}],["这样更容易画示意图",{"2":{"1145":1}}],["这样更容易计算",{"2":{"26":1}}],["这样更有效",{"2":{"1093":1}}],["这样即使你跑到其他路径底下",{"2":{"1092":1}}],["这样在你今后需要编写学习算法时",{"2":{"1089":1}}],["这样在固定住其他层时",{"2":{"170":1}}],["这样组成了",{"2":{"1089":1}}],["这样将删除工作空间中的所有变量",{"2":{"1089":1}}],["这样我将加载了",{"2":{"1089":1}}],["这样我们所得到的只能是一条平行于x$轴的直线",{"2":{"1115":1}}],["这样我们所得到的只能是一条平行于",{"2":{"1115":1}}],["这样我们才能为训练集拟合出参数",{"2":{"1110":1}}],["这样我们才能为训练集拟合出参数的函数",{"2":{"1110":1}}],["这样我们的某些代码可能会无意中引用旧的参数",{"2":{"1021":1}}],["这样我们就得到一个正边界",{"2":{"1112":1}}],["这样我们就得到了一个",{"2":{"1089":1}}],["这样我们就得到了计算记忆元的流程图",{"2":{"555":1}}],["这样我们就可以进行凸组合",{"2":{"540":1}}],["这样我们就可以根据这个预测进行交易",{"2":{"196":1}}],["这样v就被赋值了1至6的六个整数",{"2":{"1088":1}}],["这样一来",{"2":{"953":1,"954":2,"956":1,"1178":1}}],["这样一组隐藏表示可以想象成一些互相堆叠的二维网格",{"2":{"158":1}}],["这样后者可以在减少提议区域数量的情况下仍保证目标检测的精度",{"2":{"941":1}}],["这样它们就可以从输入图像中检测到较大的目标",{"2":{"913":1}}],["这样就计算出这个代价函数",{"2":{"1111":1}}],["这样就得到了a",{"2":{"1090":1}}],["这样就得到每一列的总和",{"2":{"1090":1}}],["这样就将v",{"2":{"1090":1}}],["这样就能很轻松地找到你想使用的命令了",{"2":{"1089":1}}],["这样就会把数据存成一个文本文档",{"2":{"1089":1}}],["这样就需要很多步才能到达最低点",{"2":{"1068":1}}],["这样就各有50",{"2":{"879":1}}],["这样就可以同时传输更多的信息",{"2":{"802":1}}],["这样每个gpu都有相同的工作量",{"2":{"833":1}}],["这样步长大小就不会取决于我们对批量大小的选择",{"2":{"604":1}}],["这样通过基本的线性代数运算得到输出",{"2":{"591":1}}],["这样模型构建",{"2":{"488":1,"509":1}}],["这样做非常不好",{"2":{"1162":1}}],["这样做使得方程看起来有些不同",{"2":{"1143":1}}],["这样做是为了简化此处的表达式",{"2":{"1143":1}}],["这样做我们会减少错误预测病人为恶性肿瘤的情况",{"2":{"1140":1}}],["这样做就是把",{"2":{"1090":1}}],["这样做就是对每一列求最大值",{"2":{"1090":1}}],["这样做会得到每一列的最大值",{"2":{"1090":1}}],["这样做通常可以让你的算法运行得比直接用c++实现更快",{"2":{"1061":1}}],["这样做的好处在于",{"2":{"1166":1}}],["这样做的好处之一是",{"2":{"414":1}}],["这样做的问题在于",{"2":{"1157":1}}],["这样做的结果是返回两个3×3的随机矩阵",{"2":{"1090":1}}],["这样做的结果是在原矩阵的右边附加了一个新的列矩阵",{"2":{"1089":1}}],["这样做的话",{"2":{"1059":1,"1115":1}}],["这样做需要将预测的像素类别重新映射回原始尺寸的输入图像",{"2":{"946":1}}],["这样做导致该模型主要侧重于短期影响",{"2":{"309":1}}],["这样的方法叫做映射简化",{"2":{"1169":1}}],["这样的算法可能会非常值得考虑",{"2":{"1168":1}}],["这样的处理过程可以被用于把任何维度的数据降到任何想要的维度",{"2":{"1156":1}}],["这样的选择是建立在回答",{"2":{"1154":1}}],["这样的初始方法对于逻辑回归来说是可行的",{"2":{"1125":1}}],["这样的结果是得到了一个较为简单的能防止过拟合问题的假设",{"2":{"1115":1}}],["这样的结果毫无意义",{"2":{"708":1}}],["这样的一个线性模型似乎能很好地完成分类任务",{"2":{"1107":1}}],["这样的映射可能不够精确",{"2":{"946":1}}],["这样的推断似乎是轻率和武断的",{"2":{"841":1}}],["这样的行为同样适用于单个gpu",{"2":{"795":1}}],["这样的预训练文本表示可以通过不同模型架构",{"2":{"663":1}}],["这样的设计要求2个卷积层的输出与输入形状一样",{"2":{"501":1}}],["这样的数据存在许多种形式",{"2":{"360":1}}],["这样的假设是合理的",{"2":{"347":1}}],["这样的度量确保了不同长度的序列具有可比性",{"2":{"335":1}}],["这样的操作的目的是",{"2":{"335":1}}],["这样的模型并不是我们所需的",{"2":{"522":1}}],["这样的模型特别棒",{"2":{"348":1}}],["这样的模型将在h",{"2":{"329":1}}],["这样的模型很容易变得无效",{"2":{"316":1}}],["这样的列表还会包含其他信息",{"2":{"325":1}}],["这样的小批量子序列将被输入到模型中",{"2":{"319":1}}],["这样的计算非常缓慢",{"2":{"308":1}}],["这样的迭代永远不会打破对称性",{"2":{"244":1}}],["这样的额外开销可能是非常不利的",{"2":{"77":1}}],["这样",{"2":{"171":1,"335":1,"423":4,"568":1,"781":1,"932":1,"939":1,"1086":1,"1092":1,"1139":1,"1143":1,"1146":1,"1178":1}}],["这样随着我们在神经网络中层叠的上升",{"2":{"145":1}}],["这样可以最大限度地减少tensorflow计算的内存开销",{"2":{"1021":1}}],["这样可以确保输出非负",{"2":{"643":1}}],["这样可以确保不会严重违反约束",{"2":{"49":1}}],["这样可以很容易地将其可视化",{"2":{"599":1}}],["这样可以避免很大的i带来的特别大的指数值",{"2":{"262":1}}],["这样可以加速收敛",{"2":{"249":1}}],["这样可以在构建网络时更容易地预测每个图层的输出形状",{"2":{"141":1}}],["这样卷积核的形状是co×ci×kh×kw",{"2":{"121":1}}],["这样能成为解决凸问题的不错选择",{"2":{"66":1}}],["这样有0≤λa+",{"2":{"46":1}}],["这并不会改变最小化该方程时得到u值",{"2":{"1143":1}}],["这并不是很重要",{"2":{"1143":1}}],["这并不是处理数据的最有效方法",{"2":{"211":1}}],["这并不意味着分布必须是高斯的",{"2":{"247":1}}],["这并不意味着不能有多个全局最小值",{"2":{"44":1}}],["这并不令人惊讶",{"2":{"197":1}}],["这并不能完全解释这种现象",{"2":{"68":1}}],["这并没有明显增加adagrad的计算代价",{"2":{"27":1}}],["这意味着你现在确实要给这个算法提供一个梯度",{"2":{"1111":1}}],["这意味着你已经在局部最优点",{"2":{"1068":1}}],["这意味着逻辑语句x",{"2":{"1018":1}}],["这意味着该函数接收两个输入",{"2":{"1018":1}}],["这意味着该函数从任何实数",{"2":{"1018":1}}],["这意味着预测的边界框即是锚框",{"2":{"854":1}}],["这意味着gpu设备之间的通信更有效",{"2":{"841":1}}],["这意味着初始化是基于每个设备进行的",{"2":{"827":1}}],["这意味着任何python代码",{"2":{"821":1}}],["这意味着最低要求也是fp16",{"2":{"811":1}}],["这意味着cpu每个时钟周期需要消耗4×256",{"2":{"810":1}}],["这意味着高效的程序可以在每个时钟周期内执行多条指令",{"2":{"808":1}}],["这意味着两件事",{"2":{"802":1}}],["这意味着模型有专门的机制来确定应该何时更新隐状态",{"2":{"539":1}}],["这意味着我们可能也会应该投入更多的时间和精力来提高应用的总体表现",{"2":{"1174":1}}],["这意味着我们很可能会希望投入时间精力来提高我们的文字侦测部分",{"2":{"1174":1}}],["这意味着我们的代价函数有许多局部最小值",{"2":{"1109":1}}],["这意味着我们需要考虑在每种可行的行为下获得高奖励的概率",{"2":{"1025":1}}],["这意味着我们需要对kt个项求和",{"2":{"519":1}}],["这意味着我们在实际开发中使用的是hybridblock类或hybridsequential类在构建模型",{"2":{"818":1}}],["这意味着我们不会观察到超过lη∥g∥的变化",{"2":{"334":1}}],["这意味着不同大小的滤波器可以有效地识别不同范围的图像细节",{"2":{"487":1}}],["这意味着正则化变得更加重要",{"2":{"467":1}}],["这意味着飞桨的计算将尝试使用所有cpu核心",{"2":{"446":1}}],["这意味着pytorch的计算将尝试使用所有cpu核心",{"2":{"446":1}}],["这意味着mxnet的计算将尝试使用所有cpu核心",{"2":{"446":1}}],["这意味着可以生成",{"2":{"320":1}}],["这意味着单词的频率满足齐普夫定律",{"2":{"318":1}}],["这意味着统计模型需要提高内存效率",{"2":{"300":1}}],["这意味着出现了严重的过拟合",{"2":{"276":1}}],["这意味着对数据进行采样的过程没有进行",{"2":{"253":1}}],["这意味着对于所有λ∈",{"2":{"40":1}}],["这意味着指甲大小的低分辨率灰度图像的数量比宇宙中的原子要多得多",{"2":{"252":1}}],["这意味着在计算每一层的线性部分之后",{"2":{"232":1}}],["这意味着在|a|",{"2":{"155":1}}],["这意味着广告的分布和受欢迎程度是逐渐变化的",{"2":{"193":1}}],["这意味着检测对象在输入x中的平移",{"2":{"154":1}}],["这意味着网络的每次输入都有一百万个维度",{"2":{"151":1}}],["这意味着汇聚层的输出通道数与输入通道数相同",{"2":{"148":1}}],["这意味着输出的高度和宽度将分别增加ph和pw",{"2":{"141":1}}],["这意味着如果二阶导数是负的",{"2":{"59":1}}],["这意味着如果我们最小化函数",{"2":{"44":1}}],["这意味着",{"2":{"54":1,"113":1,"115":1,"1058":1,"1174":1}}],["这可能100维",{"2":{"1161":1}}],["这可能需要另一个聚类算法",{"2":{"1150":1}}],["这可能需要对学习率进行补偿调整",{"2":{"467":1}}],["这可能会导致繁琐的表示",{"2":{"1028":1}}],["这可能会导致什么问题",{"2":{"638":1}}],["这可能会产生一些像",{"2":{"38":1}}],["这可能具有相当的挑战性",{"2":{"526":1}}],["这可能包括应用到机器人",{"2":{"298":1}}],["这可能说明这些歌曲对此用户不大合适",{"2":{"294":1}}],["这可能使它们对单个变量中的观测误差更为稳定",{"2":{"270":1}}],["这可能意味着模型过于简单",{"2":{"258":1}}],["这可能是1000维的数组",{"2":{"1161":1}}],["这可能是不可取的",{"2":{"1021":1}}],["这可能是深度学习中最常见的损失函数",{"2":{"633":1}}],["这可能是奢侈的",{"2":{"445":1}}],["这可能是人工智能正在影响我们生活的最明显的迹象",{"2":{"301":1}}],["这可能是其他场景下需要的",{"2":{"270":1}}],["这可能是一个不错的预测",{"2":{"210":1}}],["这可能是因为受试者在年龄",{"2":{"185":1}}],["这可以是一个很好的方式来获得非常高性能的学习算法",{"2":{"1141":1}}],["这可以提高训练效率",{"2":{"741":1}}],["这可以大大加快运行速度",{"2":{"426":1}}],["这可以降低复杂性",{"2":{"363":1}}],["这可以想象为感官输入的非自主提示",{"2":{"356":1}}],["这可以从微博上的争吵和辩论中看出",{"2":{"345":1}}],["这可以用来描述实体及其关系",{"2":{"296":1}}],["这可以通过方差来量化",{"2":{"1036":1}}],["这可以通过将小批量设置为1500",{"2":{"80":1}}],["这可以通过稍微不同的初始化和更新条件来修正",{"2":{"33":1}}],["这可以确保我们有效地收敛到一个适当的解",{"2":{"74":1}}],["这里给出的数据集是你如何估计",{"2":{"1185":1}}],["这里顺便提一下",{"2":{"1179":1}}],["这里厘米英寸的例子实际上不是那么不切实际的",{"2":{"1156":1}}],["这里表达的意思是",{"2":{"1145":1}}],["这里第一项是c​乘以0",{"2":{"1144":1}}],["这里第一个元素1乘以11得到11",{"2":{"1090":1}}],["这里就会得到横轴z",{"2":{"1143":1}}],["这里就是一个例子",{"2":{"1092":1}}],["这里同上一张幻灯片一致",{"2":{"1143":1}}],["这里设置梯度目标参数为打开",{"2":{"1111":1}}],["这里设置为0",{"2":{"594":4}}],["这里纵轴cos",{"2":{"1091":1}}],["这里我的最小化问题就变成了",{"2":{"1143":1}}],["这里我的意思是",{"2":{"1143":1}}],["这里我所做的是删去常量m",{"2":{"1143":1}}],["这里我所做的是",{"2":{"1143":1}}],["这里我将向你展示如何使用break语句",{"2":{"1092":1}}],["这里我输入a",{"2":{"1090":1}}],["这里我们用的是之前学过的向量范数的定义",{"2":{"1145":1}}],["这里我们将使用的新的代价函数",{"2":{"1143":1}}],["这里我们将出现次数少于2次的低频率词元",{"2":{"567":1}}],["这里我们称之为逗号连接的命令或函数调用",{"2":{"1091":1}}],["这里我们需要两张输入图像",{"2":{"916":1}}],["这里我们需要保持",{"2":{"472":1}}],["这里我们需要保持x的形状以便后面可以做广播运算",{"2":{"472":2}}],["这里我们介绍其中的一种方法",{"2":{"847":1}}],["这里我们介绍小批量随机梯度下降",{"2":{"604":1}}],["这里我们不使用python的for循环迭代预测",{"2":{"633":1}}],["这里我们不需要随机初始化模型参数",{"2":{"442":1}}],["这里我们设成4",{"2":{"482":1}}],["这里我们使用紧凑的表示法",{"2":{"1032":1}}],["这里我们使用可以从fasttext网站下载300维度的英文版本",{"2":{"748":1}}],["这里我们使用",{"2":{"603":1}}],["这里我们使用iter构造python迭代器",{"2":{"590":1}}],["这里我们使用relu的函数版本",{"2":{"423":2}}],["这里我们使用η=0",{"2":{"34":1}}],["这里我们只为权重设置了weight",{"2":{"278":1}}],["这里我们只需要传递配置参数",{"2":{"34":1}}],["这里我们仍然除以2",{"2":{"270":1}}],["这里我们",{"2":{"206":1}}],["这里我们假设标签边缘概率p",{"2":{"182":1}}],["这里我们假设",{"2":{"181":1}}],["这里我们没有卷积核",{"2":{"146":1}}],["这里我们简略拉格朗日函数l的推导",{"2":{"48":1}}],["这里还有一些其他的方法来生成矩阵",{"2":{"1088":1}}],["这里用0表示",{"2":{"1088":1}}],["这里简单说两句",{"2":{"1059":1}}],["这里有一些机器学习的案例",{"2":{"1058":1}}],["这里有一个隐藏的命令",{"2":{"1088":1}}],["这里有一个问题",{"2":{"437":2}}],["这里有一个小插曲",{"2":{"290":1}}],["这里考虑的大小",{"2":{"1000":1}}],["这里定义一个对称矩阵b",{"2":{"992":1}}],["这里定义一个实用程序类accumulator",{"2":{"634":1}}],["这里可以直接使用d2l",{"2":{"981":1}}],["这里可以分离y来返回一个新变量u",{"2":{"976":1}}],["这里可以看到每个ok按常数进行的移动不会改变softmax的返回值",{"2":{"624":1}}],["这里没有评价测试数据集",{"2":{"963":1}}],["这里没有任何有意义的加速",{"2":{"837":1}}],["这里假设基于风格图像的格拉姆矩阵gram",{"2":{"923":1}}],["这里选取的预训练的神经网络含有3个卷积层",{"2":{"917":1}}],["这里介绍一种常见的变换",{"2":{"852":1}}],["这里需要为每个锚框预测4个偏移量",{"2":{"955":1}}],["这里需要运用小批量随机梯度下降算法",{"2":{"831":1}}],["这里需要使用d2l",{"2":{"462":1}}],["这里主要是",{"2":{"827":1}}],["这里通过在每个加法之间插入wait",{"2":{"792":1}}],["这里通常允许包含观测值的一些噪声",{"2":{"609":1}}],["这里paragraph是句子列表",{"2":{"720":1}}],["这里应用了广播机制",{"2":{"631":2}}],["这里是一条连接到输入神经",{"2":{"1099":1}}],["这里是一个矩阵a",{"2":{"1090":1}}],["这里是和之前相同的三个方程",{"2":{"1093":1}}],["这里是法语",{"2":{"566":1}}],["这里是英语",{"2":{"566":1}}],["这里每个模块使用2个残差块",{"2":{"502":1}}],["这里每边都填充了1行或1列",{"2":{"141":4}}],["这里测试数据的输入相当于查询",{"2":{"388":1}}],["这里不会深入讨论核函数的细节",{"2":{"388":1}}],["这里不是使用",{"2":{"156":1}}],["这里值得注意",{"2":{"318":1}}],["这里所有学习都是在算法与环境断开后进行的",{"2":{"297":1}}],["这里所说的",{"2":{"286":1}}],["这里训练误差有了减少",{"2":{"276":1}}],["这里引用一句古老的谚语",{"2":{"235":1}}],["这里使用一个11",{"2":{"461":3}}],["这里使用tanh函数作为激活函数",{"2":{"332":1}}],["这里使用的是adam优化算法",{"2":{"210":4}}],["这里使用更大的学习率来训练模型",{"2":{"28":1}}],["这里最强的假设",{"2":{"192":1}}],["这里输入和输出具有相同的高度和宽度",{"2":{"122":1}}],["这里的每个点",{"2":{"1178":1}}],["这里的每个样本都将用固定长度的向量表示",{"2":{"630":1}}],["这里的a表示这里的第一项",{"2":{"1143":1}}],["这里的a是一个5行4列的矩阵",{"2":{"999":1}}],["这里的代价函数cost1",{"2":{"1143":1}}],["这里的下标是指在代价函数中",{"2":{"1143":1}}],["这里的这一项就是表示一个训练样本所对应的表达式",{"2":{"1143":1}}],["这里的这些函数比如svm",{"2":{"1061":1}}],["这里的三角形是正样本",{"2":{"1112":1}}],["这里的求和是同样的道理",{"2":{"1093":1}}],["这里的向量我用的下标是0",{"2":{"1093":1}}],["这里的1表示取a矩阵第一个维度的最大值",{"2":{"1090":1}}],["这里的点号还是表示对每一个元素进行操作",{"2":{"1090":1}}],["这里的分号表示把分号后面的东西放到下面",{"2":{"1089":1}}],["这里的百分号命令表示注释",{"2":{"1088":1}}],["这里的标签是一个三维数组",{"2":{"948":1}}],["这里的target包含",{"2":{"932":3}}],["这里的tokens是1d列表或2d列表",{"2":{"363":1}}],["这里的损失函数和准确率计算与图像分类中的并没有本质上的不同",{"2":{"865":1}}],["这里的实现有点复杂",{"2":{"854":1}}],["这里的迭代周期个数num",{"2":{"605":1}}],["这里的主要变化是使用更小的学习速率训练",{"2":{"463":1}}],["这里的force",{"2":{"435":1}}],["这里的诀窍是框架的延后初始化",{"2":{"417":1}}],["这里的数学表示没有像过去那样明确地区分标量",{"2":{"307":1}}],["这里的人工智能是",{"2":{"297":1}}],["这里的线性很荒谬",{"2":{"230":1}}],["这里的中间变量是",{"2":{"162":1}}],["这里的",{"2":{"141":4,"286":1,"1093":1,"1098":1,"1143":1}}],["这里的二维表示的第一个维度索引小批量中的样本",{"2":{"136":1}}],["这里的g不如f平滑",{"2":{"99":1}}],["这里的变量αi",{"2":{"48":1}}],["这里b",{"2":{"94":1}}],["这里η0是初始学习率",{"2":{"72":1}}],["这里f是目标函数",{"2":{"47":1}}],["这里z∈",{"2":{"46":1}}],["这里",{"2":{"42":1,"192":1,"219":2,"257":1,"292":1,"316":1,"423":4,"424":3,"461":5,"521":1,"643":1,"882":1,"973":1,"975":1,"1012":1}}],["这里β1和β2是非负加权参数",{"2":{"33":1}}],["这是自定义异常",{"2":{"1249":1}}],["这是机器学习算法的一个常见应用",{"2":{"1178":1}}],["这是从零开始创造实例",{"2":{"1173":1}}],["这是不现实的",{"2":{"1167":1}}],["这是表示他们是否喜欢飞行",{"2":{"1156":1}}],["这是大间距决策界来区分开正样本和负样本这个间距的值",{"2":{"1145":1}}],["这是p的长度",{"2":{"1145":1}}],["这是计算内积的一种方法",{"2":{"1145":1}}],["这是向量u的长度",{"2":{"1145":1}}],["这是另一个在你军械库里非常强大的工具",{"2":{"1148":1}}],["这是另一条决策边界",{"2":{"1144":1}}],["这是另一种称为正规方程",{"2":{"1069":1}}],["这是支持向量机的一个有趣性质",{"2":{"1144":1}}],["这是为什么能保证低误差的关键所在",{"2":{"1141":1}}],["这是为了兼容mxnet的其他张量处理组件",{"2":{"1017":1}}],["这是为了在数值稳定性和逼真度之间取得良好的平衡",{"2":{"33":1}}],["这是目前最流行使用最广泛的一种学习算法",{"2":{"1106":1}}],["这是第二个例子",{"2":{"1098":1}}],["这是第一类的人",{"2":{"1061":1}}],["这是第一个成功应用的卷积神经网络",{"2":{"134":1}}],["这是你用来处理触觉的",{"2":{"1098":1}}],["这是线性回归算法梯度下降的更新规则",{"2":{"1093":1}}],["这是未向量化的代码实现方式",{"2":{"1093":1}}],["这是什么意思呢",{"2":{"1092":1,"1144":1}}],["这是很容易的",{"2":{"1091":1}}],["这是很有效的",{"2":{"74":1}}],["这是我为什么在这节课讨论它的原因之一",{"2":{"1187":1}}],["这是我的支持向量机模型的代价函数",{"2":{"1144":1}}],["这是我的",{"2":{"1090":1}}],["这是我们的代价函数",{"2":{"1110":1}}],["这是我们到目前为止一直在讨论的内容",{"2":{"309":1}}],["这是我们在逻辑回归中使用代价函数j",{"2":{"1143":1}}],["这是我们在f中的最佳选择",{"2":{"500":1}}],["这是我们在",{"2":{"208":1}}],["这是和其他一些编程语言中不太一样的地方",{"2":{"1088":1}}],["这是octave命令行",{"2":{"1088":1}}],["这是当时的情况",{"2":{"1088":1}}],["这是代价函数j",{"2":{"1068":1}}],["这是正确实现同时更新的方法",{"2":{"1067":1}}],["这是有一堆数据",{"2":{"1061":1}}],["这是有道理的",{"2":{"1000":1}}],["这是螺丝刀",{"2":{"1059":1}}],["这是稍显陈旧的文章",{"2":{"1058":1}}],["这是几乎所有深度学习优化算法的关键步骤",{"2":{"981":1}}],["这是词wj",{"2":{"742":1}}],["这是在计算机上存储此类信息的有效方法",{"2":{"640":1}}],["这是在引入relu激活函数之前训练深度学习模型相当棘手的原因之一",{"2":{"103":1}}],["这是使用图模型进行概率推理的巨大好处之一",{"2":{"519":1}}],["这是基于输入序列生成输出序列的条件概率",{"2":{"513":1}}],["这是深度学习中一个反复出现的主题",{"2":{"467":1}}],["这是深度学习中批量处理背后的推动力",{"2":{"77":1}}],["这是由残差连接和紧随其后的层规范化组成的",{"2":{"406":1}}],["这是由于卷积核的宽度和高度通常大于1所导致的",{"2":{"140":1}}],["这是由于梯度的随机性质",{"2":{"113":1}}],["这是通过一个超参数σ来控制平滑区域的",{"2":{"966":1}}],["这是通过在",{"2":{"861":1}}],["这是通过在整个神经网络中应用噪声注入",{"2":{"300":1}}],["这是通过block类的",{"2":{"422":2}}],["这是通过将上下文变量视为加性注意力池化的输出来实现的",{"2":{"377":1}}],["这是通过将上下文变量视为注意力集中的输出来实现的",{"2":{"373":1}}],["这是以修改和重新发明存在了数十年的工具为代价的",{"2":{"302":1}}],["这是以未能收敛到最优解x=",{"2":{"114":1}}],["这是著名的手写数字mnist数据集的来源",{"2":{"301":1}}],["这是最早且最广泛使用的图像增广方法之一",{"2":{"879":1}}],["这是最早的修剪均值估计的例子之一",{"2":{"299":1}}],["这是最不敏感与最敏感方向的变化量的比率",{"2":{"66":1}}],["这是一种选择",{"2":{"1145":1}}],["这是一种测试法",{"2":{"1129":1}}],["这是一种非常强大",{"2":{"1110":1}}],["这是一种可以使你的",{"2":{"1092":1}}],["这是一种",{"2":{"1088":1}}],["这是一种学习算法",{"2":{"1058":1}}],["这是一种对文本进行分类的应用类型",{"2":{"658":1}}],["这是一种更适合数学和编写代码的形式",{"2":{"641":1}}],["这是一种类似",{"2":{"624":1}}],["这是一种流行且有效的技术",{"2":{"466":1}}],["这是一件完全合理的事情",{"2":{"624":1}}],["这是一张由树突",{"2":{"619":1}}],["这是一类明确考虑与环境交互的问题",{"2":{"297":1}}],["这是一个可以用于临时读取而不引起代理访问",{"2":{"1518":1}}],["这是一个漂亮的与原始数据相当相似",{"2":{"1161":1}}],["这是一个体系",{"2":{"1148":1}}],["这是一个关键的假设",{"2":{"1141":1}}],["这是一个易混淆的单词的例子",{"2":{"1141":1}}],["这是一个未向量化的代码实现方式",{"2":{"1093":1}}],["这是一个常见的线性回归假设函数",{"2":{"1093":1}}],["这是一个9×9的魔方阵",{"2":{"1090":1}}],["这是一个1行4列矩阵",{"2":{"1090":1}}],["这是一个1行11列的矩阵",{"2":{"1088":1}}],["这是一个很特别的语法结构",{"2":{"1089":1}}],["这是一个3行2列的矩阵",{"2":{"1089":1}}],["这是一个回归问题",{"2":{"1063":1}}],["这是一个",{"2":{"1061":1,"1090":1}}],["这是一个分类问题",{"2":{"1060":1}}],["这是一个马尔可夫链",{"2":{"1038":1}}],["这是一个python中流行的绘图库",{"2":{"981":1}}],["这是一个规定的值",{"2":{"922":2}}],["这是一个极大的数",{"2":{"514":1}}],["这是一个相当惊人的结果",{"2":{"842":1}}],["这是一个相当小的语料库",{"2":{"361":1}}],["这是一个相当不切实际的想法",{"2":{"26":1}}],["这是一个十分耗时的过程",{"2":{"292":1}}],["这是一个流行的德国童话故事",{"2":{"292":1}}],["这是一个非负超参数",{"2":{"270":1}}],["这是一个普通的二次函数",{"2":{"94":1}}],["这是一个鞍点",{"2":{"48":1}}],["这是用于二元分类的softmax回归",{"2":{"191":1}}],["这是多通道输入和多输入通道卷积核之间进行二维互相关运算的结果",{"2":{"120":1}}],["这是本书中的默认选择",{"2":{"116":1}}],["这是训练深度网络的常见策略",{"2":{"114":1}}],["这是关于y的最大值",{"2":{"102":1}}],["这是小批量随机梯度下降的有利特性之一",{"2":{"101":1}}],["这是更大范围的可行参数",{"2":{"95":1}}],["这是集两种好处于一身的做法",{"2":{"89":1}}],["这是因为那个点是曲线的肘点",{"2":{"1154":1}}],["这是因为如果θtx",{"2":{"1144":1}}],["这是因为如果我的数据集x",{"2":{"1092":1}}],["这是因为之前有个负号在方程外面",{"2":{"1143":1}}],["这是因为由于",{"2":{"1143":1}}],["这是因为当我们接近局部最低点时",{"2":{"1068":1}}],["这是因为python首先计算y",{"2":{"1021":1}}],["这是因为fashion",{"2":{"882":1}}],["这是因为无论是获取和打印所有的中间变量值",{"2":{"817":1}}],["这是因为无限多的数据样本是一个虚构的对象",{"2":{"252":1}}],["这是因为程序不知道在执行语句e",{"2":{"816":1}}],["这是因为在深度学习中",{"2":{"984":1}}],["这是因为在减去均值之后",{"2":{"467":1}}],["这是因为在一定程度上",{"2":{"289":1}}],["这是因为网络更深更广",{"2":{"463":1}}],["这是因为",{"2":{"454":1}}],["这是因为虽然lenet在小数据集上取得了很好的效果",{"2":{"454":1}}],["这是因为对于任何确定的位置偏移δ",{"2":{"400":1}}],["这是因为输入空间太大了",{"2":{"252":1}}],["这是因为任何像素的重要性都以复杂的方式取决于该像素的上下文",{"2":{"230":1}}],["这是因为这些方法倾向于包含看起来像标签",{"2":{"182":1}}],["这是因为图像中本就拥有丰富的结构",{"2":{"151":1}}],["这是因为我们需要足够的空间在图像上",{"2":{"126":1}}],["这是因为卷积核的宽度和高度大于1",{"2":{"126":1}}],["这是因为随机梯度下降更频繁地更新了参数",{"2":{"80":1}}],["这是因为ηf",{"2":{"54":1}}],["这是这个算法的致命缺陷",{"2":{"59":1}}],["这是",{"2":{"50":1,"1047":1,"1090":1,"1295":1}}],["这是高效的多机",{"2":{"32":1}}],["这个语法糖",{"2":{"1454":1}}],["这个班视频的最后几集我想讨论机器学习中的一些大思想",{"2":{"1187":1}}],["这个在线学习算法",{"2":{"1168":1}}],["这个视频",{"2":{"1156":1,"1161":1}}],["这个没有太大关系",{"2":{"1148":1}}],["这个体系",{"2":{"1148":1}}],["这个的作用是",{"2":{"1145":1}}],["这个间距的值就是p",{"2":{"1145":1}}],["这个绿色的决策界",{"2":{"1145":1}}],["这个绿色的决策界有一个垂直于它的向量θ",{"2":{"1145":1}}],["这个向量和参数向量θ的夹角大于90度",{"2":{"1145":1}}],["这个投影非常短",{"2":{"1145":1}}],["这个短的粉色线段是p",{"2":{"1145":1}}],["这个样本如果它恰好是x",{"2":{"1145":1}}],["这个样本的代价或是代价函数的贡献",{"2":{"1143":1}}],["这个决策界离训练样本的距离很近",{"2":{"1145":1}}],["这个θtx",{"2":{"1145":1}}],["这个一行两列的矩阵乘以v",{"2":{"1145":1}}],["这个距离叫做支持向量机的间距",{"2":{"1144":1}}],["这个距离叫做间距",{"2":{"1144":1}}],["这个因子会导致什么结果",{"2":{"1144":1}}],["这个假设函数会预测1",{"2":{"1143":1}}],["这个看起来复杂很多的代价函数背后的思想还是一样的",{"2":{"1120":1}}],["这个类别来代表",{"2":{"1112":1}}],["这个类本身就是model的子类",{"2":{"422":1}}],["这个特征缩放的方法",{"2":{"1110":1}}],["这个特征向量可能更接近",{"2":{"290":1}}],["这个式子可以写作",{"2":{"1145":1}}],["这个式子可以合并成",{"2":{"1110":1}}],["这个式子正是我们用来做线性回归梯度下降的",{"2":{"1110":1}}],["这个概念能更好地帮助我们理解逻辑回归的假设函数在计算什么",{"2":{"1108":1}}],["这个概率只有1",{"2":{"1035":1}}],["这个概率图模型就是一个隐马尔可夫模型",{"2":{"519":1}}],["这个性质是它的预测值要在0和1之间",{"2":{"1107":1}}],["这个实验和其它一些类似的实验",{"2":{"1098":1}}],["这个方程就实现了返回5x5的单位矩阵",{"2":{"1094":1}}],["这个文件只是为了确保你熟悉提交系统",{"2":{"1094":1}}],["这个文件只有三行",{"2":{"1092":1}}],["这个提交系统可以即时检验你的机器学习程序答案是否正确",{"2":{"1094":1}}],["这个就是算法的代码实现",{"2":{"1093":1}}],["这个就是上界rl",{"2":{"115":1}}],["这个术语的人使用的",{"2":{"1092":1}}],["这个矩阵",{"2":{"1191":1}}],["这个矩阵对角线元素的和确实是369",{"2":{"1090":1}}],["这个矩阵其实没多大作用",{"2":{"1090":1}}],["这个矩阵可以被看作由c个长度为hw的向量x1",{"2":{"923":1}}],["这个意思就是把这两个矩阵直接连在一起",{"2":{"1089":1}}],["这个路径是",{"2":{"1089":1}}],["这个命令意思是取",{"2":{"1089":1}}],["这个命令把数据按照二进制形式储存",{"2":{"1089":1}}],["这个命令会将变量v存成一个叫",{"2":{"1089":1}}],["这个命令会返回a矩阵的第一个元素",{"2":{"1089":1}}],["这个命令将返回最大维度的大小",{"2":{"1089":1}}],["这个集合v是一组值",{"2":{"1088":1}}],["这个该如何理解呢",{"2":{"1088":1}}],["这个公式中有n+1个参数和n个变量",{"2":{"1080":1}}],["这个是4×2矩阵",{"2":{"1072":1}}],["这个是当时的情况",{"2":{"1061":1}}],["这个项需要对所有m个训练样本求和",{"2":{"1069":1}}],["这个其实就像是我们的乳腺癌",{"2":{"1061":1}}],["这个测试是相当准确的",{"2":{"1035":1}}],["这个情况表示为a⊥b∣c",{"2":{"1034":1}}],["这个估计值会越来越接近真实的潜在概率",{"2":{"1026":1}}],["这个估计器确实不够聪明",{"2":{"387":1}}],["这个小的不便实际上是非常重要的",{"2":{"1022":1}}],["这个小型数据集包含数千张包含热狗和不包含热狗的图像",{"2":{"871":1}}],["这个未使用的值将被删除",{"2":{"1021":1}}],["这个新的张量包含与转换前相同的值",{"2":{"1017":1}}],["这个新的基于注意力的模型与",{"2":{"374":1}}],["这个行向量包含以0开始的前12个整数",{"2":{"1017":3}}],["这个轴是什么",{"2":{"1004":1}}],["这个极限被定义为",{"2":{"981":1}}],["这个深度卷积神经网络凭借多个层逐级抽取图像的特征",{"2":{"917":1}}],["这个狗品种数据集是imagenet数据集的子集",{"2":{"903":1}}],["这个对比实验能支持图像增广可以减轻过拟合的论点吗",{"2":{"885":1}}],["这个与dynamo",{"2":{"844":1}}],["这个操作在不同的i之间是独立的",{"2":{"844":1}}],["这个运算的关键在于它是一个交换归约",{"2":{"844":1}}],["这个网络通常会参与训练",{"2":{"938":1}}],["这个网络有多个卷积层和汇聚层",{"2":{"832":1}}],["这个网络与最初的lenet",{"2":{"136":1}}],["这个策略被多个深度学习框架使用",{"2":{"817":1}}],["这个嵌入层不需要训练",{"2":{"702":3}}],["这个任务的性能",{"2":{"1059":1}}],["这个任务的目的是将单个文本序列分类到预定义的类别中",{"2":{"664":1}}],["这个任务显然难于登天",{"2":{"519":1}}],["这个事件毫无信息量",{"2":{"651":1}}],["这个属性叫做校准",{"2":{"643":1}}],["这个数组可能有多个维度",{"2":{"1017":1}}],["这个数字与gpu的能力相比则相形见绌",{"2":{"809":1}}],["这个数字在实践中可能高得令人望而却步",{"2":{"642":1}}],["这个数据集被称训练集",{"2":{"1063":1}}],["这个数据集中每条数据都已经标明是阴性或阳性",{"2":{"1061":1}}],["这个数据集中",{"2":{"1060":1}}],["这个数据集由",{"2":{"1060":1}}],["这个数据集实际上是著名的imagenet的数据集子集",{"2":{"899":1}}],["这个数据集包括了房屋的销售价格",{"2":{"609":1}}],["这个数据集是相当通用的",{"2":{"205":1}}],["这个数据总体通常是无法获得的",{"2":{"202":1}}],["这个临界点对应于整个区域的损失极小点",{"2":{"612":1}}],["这个模块提供了各种模型参数初始化方法",{"2":{"592":1}}],["这个模型记作hθ",{"2":{"1112":1}}],["这个模型就会发出警报",{"2":{"295":1}}],["这个模型就会顿时束手无策",{"2":{"284":1}}],["这个模型可以很轻松地被训练",{"2":{"292":1}}],["这个模型可能倾向于向所有穿着牛津鞋的申请人发放贷款",{"2":{"179":1}}],["这个模型被称为过拟合",{"2":{"286":1}}],["这个模型基本没有",{"2":{"282":1}}],["这个模型发现申请人的鞋子与违约风险相关",{"2":{"179":1}}],["这个模型是由at",{"2":{"135":1}}],["这个子序列是由输入序列的开始位置到隐状态所在的时间步的位置",{"2":{"573":1}}],["这个固定长度是由",{"2":{"568":1}}],["这个研究领域可以追溯到数字计算机发明后不久的20世纪40年代",{"2":{"564":1}}],["这个状态又被解码器作为其输入的一部分",{"2":{"535":1}}],["这个架构是由",{"2":{"527":1}}],["这个结果介于贪心搜索和穷举搜索之间",{"2":{"515":1}}],["这个输出序列的条件概率是",{"2":{"513":1}}],["这个输出高度为2",{"2":{"126":1}}],["这个设计对如何建立深层神经网络产生了深远的影响",{"2":{"500":1}}],["这个代码与我们第一次训练lenet",{"2":{"473":1}}],["这个层将保持适当的参数",{"2":{"472":1}}],["这个例子中我们要将一个三维的特征向量降至一个二维的特征向量",{"2":{"1156":1}}],["这个例子中使用了哪种搜索策略",{"2":{"517":1}}],["这个例子似乎有点做作",{"2":{"1156":1}}],["这个例子是预测住房价格的",{"2":{"1063":1}}],["这个例子说明",{"2":{"513":1}}],["这个例子表明第三个和第五个神经网络层的参数是绑定的",{"2":{"437":1}}],["这个例子表明第二层和第三层的参数是绑定的",{"2":{"437":1}}],["这个例子仅仅是机器学习常见应用的冰山一角",{"2":{"282":1}}],["这个范围是根据输入和输出维度计算出的",{"2":{"434":2}}],["这个全连接层包含两个参数",{"2":{"430":1}}],["这个全连接层也将有106×103=109个参数",{"2":{"151":1}}],["这个权重就是我们所需要的",{"2":{"762":1}}],["这个权重不是一个模型参数",{"2":{"425":1}}],["这个权重将被分配给每一个对应值yi",{"2":{"388":1}}],["这个前向传播函数非常简单",{"2":{"422":2}}],["这个resnet架构赢得了2015年imagenet和coco计算机视觉比赛",{"2":{"422":1}}],["这个咖啡杯在这种视觉环境中是突出和显眼的",{"2":{"355":1}}],["这个框架的出现可以追溯到19世纪90年代的威廉",{"2":{"355":1}}],["这个函数叫",{"2":{"1111":1}}],["这个函数",{"2":{"1092":1}}],["这个函数在多个设备上初始化网络时特别方便",{"2":{"827":1}}],["这个函数还接受一个可选参数resize",{"2":{"584":1}}],["这个函数返回训练集和验证集的数据迭代器",{"2":{"584":1}}],["这个函数必须传递给d2l",{"2":{"473":1}}],["这个函数的返回是一个张量",{"2":{"332":1}}],["这个函数有无穷多个局部最小值",{"2":{"56":1}}],["这个隐状态可以用来初始化顺序分区中一个迭代周期内下一个小批量数据的隐状态",{"2":{"325":1}}],["这个分布不仅适用于一元语法",{"2":{"322":1}}],["这个分数用来为一些真正的期末考试做参考",{"2":{"286":1}}],["这个简单的线性例子已经展现了长序列模型的一些关键问题",{"2":{"312":1}}],["这个想法是由塔莱克和奥利维尔",{"2":{"310":1}}],["这个想法被pytorch",{"2":{"300":1}}],["这个想法被称为暂退法",{"2":{"170":1}}],["这个随机变量是通过使用序列ξt来实现的",{"2":{"310":1}}],["这个算法需要那么多繁杂的步骤",{"2":{"1122":1}}],["这个算法的性质是",{"2":{"1106":1}}],["这个算法对应你刚才知道的那个问题的算法可以就用一行代码来完成",{"2":{"1061":1}}],["这个算法还会区分出两个音频资源",{"2":{"1061":1}}],["这个算法使结果收敛到一个相当高的精度",{"2":{"626":1}}],["这个算法也为当今深度学习的许多随机梯度下降算法奠定了基础",{"2":{"299":1}}],["这个算法后来被改进以处理畸形的脚",{"2":{"299":1}}],["这个算法在实践中的表现如何呢",{"2":{"57":1}}],["这个奖励与原始监督学习问题的损失函数是一致的",{"2":{"298":1}}],["这个镇会有多少降雨量",{"2":{"290":1}}],["这个手术需要多少小时",{"2":{"290":1}}],["这个度量在大多数情况是",{"2":{"286":1}}],["这个长度被称为数据的维数",{"2":{"284":1}}],["这个应用程序的核心",{"2":{"281":1}}],["这个选择在整个统计领域中都是有效的和受欢迎的",{"2":{"270":1}}],["这个多项式回归问题可以准确地解出吗",{"2":{"268":1}}],["这个多层感知机将特殊的",{"2":{"688":1}}],["这个多层感知机中的层数为2",{"2":{"231":1}}],["这个多层感知机有4个输入",{"2":{"231":1}}],["这个过程能启发你构造新的特征变量",{"2":{"1138":1}}],["这个过程也被称为逼近法",{"2":{"980":1}}],["这个过程的复杂程度不亚于模型调参",{"2":{"916":1}}],["这个过程充满了计算与统计的不确定性",{"2":{"306":1}}],["这个过程叫做模型选择",{"2":{"255":1}}],["这个过于复杂的模型会轻易受到训练数据中噪声的影响",{"2":{"266":1}}],["这个观点正好适用于这里",{"2":{"235":1}}],["这个二元组包含数据集的url和验证文件完整性的sha",{"2":{"206":1}}],["这个二维卷积层使用四维输入和输出格式",{"2":{"129":4}}],["这个汇聚层的计算成本是多少",{"2":{"150":1}}],["这个",{"2":{"128":1,"294":1,"1089":1,"1090":1,"1111":2}}],["这个等效的单个卷积核的维数是多少呢",{"2":{"124":1}}],["这个表达式中的重要事实是梯度下降在不同的特征空间之间不会混合",{"2":{"94":1}}],["这个调度方式可能产生改进的结果",{"2":{"72":1}}],["这个问题的基础上作出的",{"2":{"1154":1}}],["这个问题的分数",{"2":{"980":1}}],["这个问题的一个流行的解决方案是采用k折交叉验证",{"2":{"257":1}}],["这个问题已经解决",{"2":{"832":1}}],["这个问题及其解与正态分布有什么关系",{"2":{"621":1}}],["这个问题就是经典的多臂赌博机",{"2":{"298":1}}],["这个问题曾经困扰着深度网络的训练",{"2":{"242":1}}],["这个问题可以通过上限分析来回答",{"2":{"1174":1}}],["这个问题可以轻松计算",{"2":{"67":1}}],["这个问题可能很难被发现",{"2":{"183":1}}],["这个问题将在下一节中讨论",{"2":{"156":1}}],["这个问题",{"2":{"26":1}}],["这个词在不同上下文时往往会有不同的含义",{"2":{"991":1}}],["这个词时发出",{"2":{"282":1}}],["这个词时都会发出",{"2":{"282":1}}],["这个词",{"2":{"282":1}}],["这个词的可能性要小得多",{"2":{"25":1}}],["这个词比",{"2":{"25":1}}],["稀疏特征和学习率",{"0":{"25":1}}],["为原则",{"2":{"1548":1}}],["为应用带来了更高的灵活性",{"2":{"1352":1}}],["为无数编程初学者打开了一扇门",{"2":{"1305":1}}],["为何它成为",{"0":{"1295":1},"1":{"1296":1,"1297":1,"1298":1,"1299":1,"1300":1,"1301":1,"1302":1,"1303":1,"1304":1,"1305":1,"1306":1}}],["为何独热向量是一个糟糕的选择",{"0":{"781":1}}],["为用户",{"2":{"1189":1}}],["为一些随机小值",{"2":{"1189":1}}],["为非负常数",{"2":{"1183":1}}],["为异常",{"2":{"1180":1}}],["为我们其属于一组数据的可能性",{"2":{"1178":1}}],["为我们提供一种合成数据的方法",{"2":{"296":1}}],["为探测刻意的拼写错误",{"2":{"1137":1}}],["为函数求导时迈出的那一丁点微分",{"2":{"1122":1}}],["为你找到最佳的θ值",{"2":{"1111":1}}],["为参数",{"2":{"1110":2}}],["为四维列向量",{"2":{"1072":1}}],["为设备连接各种外设和配件提供了标准化的方式一样",{"2":{"1040":1,"1042":1}}],["为设计和训练深度神经网络提供了重要思想指导",{"2":{"492":1}}],["为结果分配新的内存",{"2":{"1021":1}}],["为多个元素赋值相同的值",{"2":{"1020":1}}],["为linalg",{"2":{"1004":1}}],["为训练集和测试集返回两个数据加载器实例",{"2":{"932":1}}],["为单个小批量执行多gpu训练",{"2":{"837":3}}],["为实现良好的加速比",{"2":{"832":1}}],["为跨多个设备的模型初始化提供原语",{"2":{"829":1}}],["为这些计算提供辅助",{"2":{"807":1}}],["为n",{"2":{"781":1}}],["为提高效率",{"2":{"757":1}}],["为生成上下文词wj的条件概率",{"2":{"744":1}}],["为每把椅子拍摄1000张不同角度的图像",{"2":{"869":1}}],["为每一个自然语言处理任务设计一个特定的架构实际上并不是一件容易的事",{"2":{"732":1}}],["为每个锚框标注类别和偏移量",{"2":{"963":3}}],["为每个锚框预测类别和偏移量",{"2":{"963":3}}],["为每个块定义前向传播",{"2":{"959":1}}],["为每个gpu保留单独的批量规范化参数",{"2":{"833":1}}],["为每个词wi添加两个标量模型参数",{"2":{"743":1}}],["为每个自然语言处理任务设计一个特定的体系架构实际上并不容易",{"2":{"739":1}}],["为每个自然语言处理任务精心设计一个特定的模型实际上是不可行的",{"2":{"656":1}}],["为每个样本获取真实标签",{"2":{"289":1}}],["为遮蔽语言模型任务预测10",{"2":{"722":1}}],["为遮蔽语言模型的输入创建新的词元副本",{"2":{"721":1}}],["为预训练任务定义辅助函数",{"0":{"719":1},"1":{"720":1,"721":1}}],["为该路径上的jth节点",{"2":{"709":1}}],["为自然语言推断的三个输出",{"2":{"688":1}}],["为自动驾驶汽车制造一个控制器",{"2":{"199":1}}],["为bert输入中的",{"2":{"687":3}}],["为便于演示",{"2":{"675":1,"895":1}}],["为d",{"2":{"618":1,"644":1}}],["为条件",{"2":{"513":1}}],["为本节的核回归设计一个新的带参数的注意力汇聚模型",{"2":{"394":1}}],["为",{"2":{"391":1,"982":1,"1040":1,"1042":1,"1077":1,"1092":1,"1120":1,"1152":1}}],["为确保无论向量长度如何",{"2":{"370":1}}],["为矩阵样本中的每一行指定有效长度",{"2":{"368":1}}],["为其分配一个数字索引",{"2":{"363":1}}],["为简单起见",{"2":{"361":1,"722":1,"724":1,"854":1,"866":1}}],["为例获得fasttext中每个中心词的子词",{"2":{"756":1}}],["为例",{"2":{"346":1,"783":1}}],["为处理长序列提供了一种实用的模型",{"2":{"322":1}}],["为处理图像数据而设计的神经网络",{"2":{"134":1}}],["为解决各种问题提供了一套统一的工具",{"2":{"302":1}}],["为数亿在线用户提供服务",{"2":{"300":1}}],["为之后本书的讨论做铺垫",{"2":{"288":1}}],["为0",{"2":{"209":1}}],["为1",{"2":{"209":1}}],["为美国市场建立了一个网络搜索引擎",{"2":{"188":1}}],["为固定形状窗口",{"2":{"146":1}}],["为中心的锚框了",{"2":{"848":1}}],["为中心的第一个锚框",{"2":{"848":1}}],["为中心词且上下文窗口为2的情况下",{"2":{"785":1}}],["为中心对像素进行加权求和得到",{"2":{"153":1}}],["为中心",{"2":{"141":1}}],["为代价的",{"2":{"114":1}}],["为此",{"2":{"67":1,"90":1,"164":1,"380":1,"564":1,"575":1,"1025":1}}],["为什么写博客",{"0":{"1545":1}}],["为什么说前端开发很有趣",{"0":{"1534":1},"1":{"1535":1,"1536":1,"1537":1,"1538":1}}],["为什么初学者适合学习",{"0":{"1298":1},"1":{"1299":1,"1300":1,"1301":1}}],["为什么逻辑回归在观察到正样本y=1时",{"2":{"1143":1}}],["为什么机器学习如此受欢迎呢",{"2":{"1058":1}}],["为什么选择",{"0":{"1041":1}}],["为什么不运行第一个测试两次",{"2":{"1038":1}}],["为什么计算二阶导数比一阶导数的开销要更大",{"2":{"979":1}}],["为什么box",{"2":{"860":1}}],["为什么bert成功了",{"2":{"740":1}}],["为什么会是这样的",{"2":{"1144":1}}],["为什么会这样",{"2":{"823":1}}],["为什么会有这个结果",{"2":{"580":1}}],["为什么从fp16到int8和int4的性能只翻倍",{"2":{"815":1}}],["为什么要这样",{"2":{"815":1}}],["为什么要假设这里是10000t2",{"2":{"794":1}}],["为什么nvidia会在其图灵gpu中添加int4运算",{"2":{"815":1}}],["为什么nin块中有两个1×1卷积层",{"2":{"498":1}}],["为什么2",{"2":{"815":1}}],["为什么它们的词向量",{"2":{"788":1}}],["为什么它不流行",{"2":{"150":1}}],["为什么测试精度会在一段时间后降低",{"2":{"628":1}}],["为什么即使函数类是嵌套的",{"2":{"505":1}}],["为什么呢",{"2":{"485":1,"651":1}}],["为什么我们在过渡层使用平均汇聚层而不是最大汇聚层",{"2":{"485":1}}],["为什么我们首先使用l2范数",{"2":{"270":1}}],["为什么如此有效",{"2":{"475":1}}],["为什么需要批量规范化层呢",{"2":{"467":1}}],["为什么共享参数是个好主意",{"2":{"439":1}}],["为什么新的模型更不平滑了呢",{"2":{"392":1}}],["为什么循环神经网络可以基于文本序列中所有先前的词元",{"2":{"344":1}}],["为什么随机偏移量是个好主意",{"2":{"323":1}}],["为什么在squared",{"2":{"607":1}}],["为什么在可视化注意力权重时",{"2":{"394":1}}],["为什么在这里我们使用平方范数而不是标准范数",{"2":{"270":1}}],["为什么在测试时通常不使用暂退法",{"2":{"178":1}}],["为什么平移不变性可能也不是好主意呢",{"2":{"160":1}}],["为什么最大汇聚层和平均汇聚层的工作方式不同",{"2":{"150":1}}],["为什么",{"0":{"1051":1},"2":{"111":1,"124":1,"160":1,"337":1,"353":1,"372":2,"411":2,"465":1,"477":1,"517":1,"571":1,"729":2,"740":1,"746":1,"815":2,"830":2,"885":1,"915":1,"972":2,"1004":1}}],["为什么以上没有暗示p",{"2":{"105":1}}],["为什么预处理有效呢",{"2":{"61":1}}],["为什么梯度下降算法可以优化目标函数",{"2":{"54":1}}],["为什么这样的效率更高",{"2":{"839":1}}],["为什么这项技术如此有效",{"2":{"475":1}}],["为什么这个算法效果这么差呢",{"2":{"351":1}}],["为什么这个任务可以归类为回归问题呢",{"2":{"290":1}}],["为什么这很难",{"2":{"105":1}}],["为什么这意味着在变量的正交变化之后",{"2":{"31":1}}],["为什么这是个好主意",{"2":{"23":1}}],["为使该条件有意义",{"2":{"41":1}}],["为方便起见",{"2":{"34":1,"79":1,"208":1}}],["为了防止误把mockjs变为响应式对象",{"2":{"1519":1}}],["为了防止学习率衰减到一个合理的下界之下",{"2":{"70":1}}],["为了呈现数据",{"2":{"1500":1}}],["为了学习所有用户",{"2":{"1188":1}}],["为了讲解方便",{"2":{"1145":1}}],["为了描述支持向量机",{"2":{"1143":1}}],["为了检验算法是否过拟合",{"2":{"1130":1}}],["为了做出预测",{"2":{"1112":1}}],["为了做得更好",{"2":{"65":1}}],["为了拟合出参数",{"2":{"1110":1}}],["为了概括概率分布的关键特征",{"2":{"1036":1}}],["为了应用贝叶斯定理",{"2":{"1035":1}}],["为了抽取一个样本",{"2":{"1026":1}}],["为了抽取图像的内容特征和风格特征",{"2":{"920":1}}],["为了处理缺失的数据",{"2":{"1012":1}}],["为了处理这种类型的输入和输出",{"2":{"532":1}}],["为了知道模块中可以调用哪些函数和类",{"2":{"1006":1}}],["为了通过求和所有行的元素来降维",{"2":{"995":1}}],["为了表示不同的运算符",{"2":{"1102":1}}],["为了表示长度为d的向量中元素的总和",{"2":{"995":1}}],["为了表示起来简单",{"2":{"992":1}}],["为了表达风格层输出的风格",{"2":{"923":1}}],["为了清楚起见",{"2":{"991":1}}],["为了微分一个由一些常见函数组成的函数",{"2":{"981":1}}],["为了微调bert进行问答",{"2":{"660":1}}],["为了帮助你判断是否有需要学习接下来的一组视频",{"2":{"1070":1}}],["为了帮助读者在后面的章节中更好地理解优化问题和方法",{"2":{"980":1}}],["为了帮助理解两个文本序列之间的关系",{"2":{"737":1}}],["为了求出曲线形状",{"2":{"980":1}}],["为了代码简洁",{"2":{"963":1}}],["为了较精确地检测目标结果",{"2":{"939":1}}],["为了快速测试目标检测模型",{"2":{"930":1}}],["为了让风格损失不受这些值的大小影响",{"2":{"923":1}}],["为了能给用户推荐5部新电影",{"2":{"1191":1}}],["为了能实现这样的转变",{"2":{"1112":1}}],["为了能进行事件概率求和",{"2":{"1033":1}}],["为了能用深度学习来解决现实世界的问题",{"2":{"1010":1}}],["为了能提交结果",{"2":{"887":1}}],["为了能够完成各种数据操作",{"2":{"1016":1}}],["为了能够利用符号式编程的可移植性和效率",{"2":{"818":2}}],["为了能够",{"2":{"382":1}}],["为了能够快速构建模型并了解其工作原理",{"2":{"306":1}}],["为了能够应用softmax回归和多层感知机",{"2":{"135":1}}],["为了收集imagenet数据集",{"2":{"869":1}}],["为了收集用来训练参数",{"2":{"155":1}}],["为了打印图像",{"2":{"863":1}}],["为了理解发生了什么",{"2":{"821":1}}],["为了满足获取需要",{"2":{"810":1}}],["为了满足机器学习的需要",{"2":{"809":1}}],["为了提高吞吐量",{"2":{"808":1}}],["为了提高计算效率并且充分利用gpu",{"2":{"644":1}}],["为了提高计算效率",{"2":{"568":1,"743":1,"778":1}}],["为了控制流",{"2":{"808":1}}],["为了控制记忆元",{"2":{"552":1}}],["为了达到最高效率可以并行使用它们",{"2":{"798":1}}],["为了区分正反例",{"2":{"776":1}}],["为了区分文本对",{"2":{"734":1}}],["为了根据预定义的分布对噪声词进行采样",{"2":{"775":1}}],["为了根据词向量之间的余弦相似性为输入词查找语义相似的词",{"2":{"750":1}}],["为了直观地演示大型语料库中预训练词向量的语义",{"2":{"747":1}}],["为了直观感受一下",{"2":{"235":1}}],["为了利用整个语料库中的统计信息进行词嵌入",{"2":{"741":1}}],["为了利用我们现有的cpu",{"2":{"488":1,"509":1}}],["为了双向编码上下文以表示每个词元",{"2":{"736":1}}],["为了演示如何在多个尺度下生成锚框",{"2":{"912":1}}],["为了演示在预训练词向量中捕捉到的过去式概念",{"2":{"751":1}}],["为了演示masklm的前向推断",{"2":{"736":1}}],["为了演示bertencoder的前向推断",{"2":{"734":1}}],["为了演示非凸函数的梯度下降",{"2":{"56":1}}],["为了评估一词多义词元",{"2":{"727":1}}],["为了从bert输入序列生成遮蔽语言模型的训练样本",{"2":{"721":1}}],["为了预训练",{"2":{"718":1}}],["为了预测文本片段开始的位置",{"2":{"660":1}}],["为了预测输出词元的概率分布",{"2":{"574":1}}],["为了降低上述计算复杂度",{"2":{"707":1}}],["为了降低计算量",{"2":{"335":1}}],["为了每次处理一小批量这样的评论",{"2":{"693":1}}],["为了允许具有陈旧梯度的参数",{"2":{"688":1}}],["为了加载这些预训练的glove和fasttext嵌入",{"2":{"748":1}}],["为了加速生成用于微调bert的snli数据集",{"2":{"687":1}}],["为了加深理解",{"2":{"120":1}}],["为了便于入门",{"2":{"889":1,"901":1}}],["为了便于观察图像增广的效果",{"2":{"878":1}}],["为了便于讨论",{"2":{"841":1}}],["为了便于演示",{"2":{"674":1,"726":1}}],["为了便于在大多数机器上演示",{"2":{"686":1}}],["为了便于在",{"2":{"408":1}}],["为了研究这个问题",{"2":{"665":1}}],["为了传递数据流的内容",{"2":{"651":1}}],["为了完成这样的工作",{"2":{"1171":1}}],["为了完成这个类比",{"2":{"751":1}}],["为了完成这一目标",{"2":{"643":1}}],["为了完善业务逻辑",{"2":{"281":1}}],["为了得到索引为i的任意词的独热向量表示",{"2":{"781":1}}],["为了得到预测结果",{"2":{"643":1}}],["为了得到正式的卷积运算输出",{"2":{"130":1}}],["为了估计所有可能类别的条件概率",{"2":{"641":1}}],["为了估计目标标签分布",{"2":{"192":1}}],["为了度量模型在整个数据集上的质量",{"2":{"611":1}}],["为了开发一个能预测房价的模型",{"2":{"609":1}}],["为了验证是否正常工作",{"2":{"590":1}}],["为了采用一个接着一个词元的方式预测输出序列",{"2":{"577":1}}],["为了连续生成输出序列的词元",{"2":{"572":1}}],["为了缓解这一问题",{"2":{"567":1,"570":1}}],["为了阐述如何拟合这种类型的数据",{"2":{"550":1}}],["为了逐个地生成长度可变的词元序列",{"2":{"534":1}}],["为了量化计算代价",{"2":{"512":1}}],["为了取得质的突破",{"2":{"499":1}}],["为了恢复模型",{"2":{"442":2}}],["为了易于学习",{"2":{"421":1}}],["为了可视化解码器的自注意力权重和",{"2":{"409":1}}],["为了可视化注意力权重",{"2":{"357":1}}],["为了明白沿着编码维度单调降低的频率与绝对位置信息的关系",{"2":{"399":1}}],["为了多注意力头的并行计算而变换形状",{"2":{"382":4}}],["为了避免这样的问题",{"2":{"1124":1}}],["为了避免这个问题",{"2":{"946":1}}],["为了避免合成图像过多保留内容图像的细节",{"2":{"920":1}}],["为了避免预训练和微调之间的这种不匹配",{"2":{"736":1}}],["为了避免计算代价和参数代价的大幅增长",{"2":{"382":1}}],["为了避免繁琐的符号",{"2":{"59":1}}],["为了",{"2":{"368":1,"370":1,"848":1,"866":1}}],["为了仅将有意义的词元作为值来获取注意力汇聚",{"2":{"368":1}}],["为了对导数的这种解释进行可视化",{"2":{"981":1}}],["为了对从分布p中随机抽取的数据进行编码",{"2":{"650":1}}],["为了对文本进行预处理",{"2":{"365":1}}],["为了对学习到的模型进行评估",{"2":{"221":1}}],["为了实现机器学习算法",{"2":{"1070":1}}],["为了实现我们的模型",{"2":{"623":1}}],["为了实现这一目标",{"2":{"938":1}}],["为了实现这一点",{"2":{"615":1,"967":1}}],["为了实现这些复杂的网络",{"2":{"422":1}}],["为了实现这个预测",{"2":{"347":1}}],["为了实现后者",{"2":{"99":1}}],["为了定义循环神经网络模型",{"2":{"332":1}}],["为了训练目标检测模型",{"2":{"850":1}}],["为了训练语言模型",{"2":{"316":1}}],["为了训练有效的网络",{"2":{"158":1}}],["为了计算代价函数的偏导数∂∂θij",{"2":{"1121":1}}],["为了计算l1范数",{"2":{"1000":1}}],["为了计算∂y∂xi",{"2":{"982":1}}],["为了计算每个中间张量",{"2":{"968":1}}],["为了计算简洁",{"2":{"958":1}}],["为了计算该",{"2":{"784":1}}],["为了计算一个词的表示",{"2":{"756":1}}],["为了计算精度",{"2":{"634":1}}],["为了计算梯度",{"2":{"422":1}}],["为了计算的效率",{"2":{"313":1}}],["为了计算有关这些参数的梯度",{"2":{"312":1}}],["为了计算输出中第一列的第二个元素和第一行的第二个元素",{"2":{"142":1}}],["为了灵活地表示链式法则中不同形状的矩阵",{"2":{"312":1}}],["为了在多个尺度下检测目标",{"2":{"957":1}}],["为了在显示时更容易分辨",{"2":{"912":1}}],["为了在预测过程中得到确切的结果",{"2":{"882":1,"884":1}}],["为了在计算损失时排除填充",{"2":{"776":1}}],["为了在固定大小的词表中允许可变长度的子词",{"2":{"757":1}}],["为了在序列上模型化这种条件概率",{"2":{"574":1}}],["为了在解码器中保留自回归的属性",{"2":{"408":1}}],["为了在",{"2":{"368":1}}],["为了在网络游戏世界的成长",{"2":{"354":1}}],["为了在循环神经网络的计算过程中可视化模型变量和参数之间的依赖关系",{"2":{"312":1}}],["为了在取对数时进一步稳定该值",{"2":{"210":4}}],["为了保持简单",{"2":{"312":1}}],["为了保持记法简单",{"2":{"86":1}}],["为了导出上述梯度",{"2":{"307":1}}],["为了惩罚权重向量的大小",{"2":{"270":1}}],["为了确保最终输出的概率值总和为1",{"2":{"643":1}}],["为了确保读者现在投入的注意力是值得的",{"2":{"354":1}}],["为了确保我们对模型的细节了如指掌",{"2":{"218":1}}],["为了确定候选模型中的最佳模型",{"2":{"255":1}}],["为了进一步说明",{"2":{"611":1}}],["为了进一步包含经过编码的输入序列的信息",{"2":{"574":1}}],["为了进一步扩充数据",{"2":{"461":1}}],["为了进一步讨论这一现象",{"2":{"252":1}}],["为了进行比较",{"2":{"874":1}}],["为了进行序列到序列的学习",{"2":{"409":1}}],["为了进行分析",{"2":{"312":1}}],["为了进行评估",{"2":{"137":1}}],["为了构建这个分类器算法",{"2":{"1137":1}}],["为了构建这个应用",{"2":{"1061":1}}],["为了构建神经网络模型",{"2":{"1099":1}}],["为了构建我们自己的简化的mysequential",{"2":{"424":1}}],["为了构建更通用的多层感知机",{"2":{"232":1}}],["为了构造高性能的卷积神经网络",{"2":{"138":1}}],["为了发挥多层架构的潜力",{"2":{"232":1}}],["为了将样本用最大间距分开",{"2":{"1144":1}}],["为了将这两个预测输出链接起来以提高计算效率",{"2":{"956":1}}],["为了将锚点移动到像素的中心",{"2":{"848":3}}],["为了将所有特征放在一个共同的尺度上",{"2":{"209":1}}],["为了将卷积块的输出传递给稠密块",{"2":{"136":1}}],["为了解释这个概念",{"2":{"1178":1}}],["为了解释这一问题",{"2":{"1129":1}}],["为了解释一些数学知识",{"2":{"1143":1}}],["为了解释双线性插值",{"2":{"863":1}}],["为了解释线性回归",{"2":{"609":1}}],["为了解释得更清楚一些",{"2":{"50":1}}],["为了解决上述问题",{"2":{"869":1}}],["为了解决线性模型的分类问题",{"2":{"641":1}}],["为了解决这样一个问题",{"2":{"1137":1}}],["为了解决这类问题",{"2":{"572":1}}],["为了解决这个问题",{"2":{"462":1,"866":1,"1153":1}}],["为了解决这些问题",{"2":{"204":1}}],["为了解决各种各样的机器学习问题",{"2":{"299":1}}],["为了缩小训练和测试性能之间的差距",{"2":{"170":1}}],["为了支持输入x和隐藏表示h中的多个通道",{"2":{"158":1}}],["为了使cost0",{"2":{"1144":1}}],["为了使cost",{"2":{"1115":1}}],["为了使得公式能够简化一些",{"2":{"1080":1}}],["为了使类别分布更加平衡",{"2":{"966":1}}],["为了使目标函数更有意义",{"2":{"708":1}}],["为了使我们在读取训练集和测试集时更容易",{"2":{"583":1}}],["为了使fashion",{"2":{"488":1}}],["为了使用正则化",{"2":{"1115":1}}],["为了使用形态信息",{"2":{"756":1}}],["为了使用序列的顺序信息",{"2":{"398":1,"401":1}}],["为了使用gpu",{"2":{"137":1}}],["为了使过拟合的效果更加明显",{"2":{"271":1}}],["为了使每个隐藏神经元都能接收到每个输入像素的信息",{"2":{"153":1}}],["为了方便以后复用",{"2":{"836":1}}],["为了方便bert预训练的演示",{"2":{"718":1}}],["为了方便使用",{"2":{"591":2}}],["为了方便理解",{"2":{"153":1}}],["为了方便起见",{"2":{"88":1,"141":4,"472":1}}],["为了与之前softmax回归",{"2":{"216":1}}],["为了与深度学习文献中的标准术语保持一致",{"2":{"130":1}}],["为了与其他出版物和实现的兼容性",{"2":{"20":1}}],["为了获得上图所示的判定边界",{"2":{"1146":1}}],["为了获得一个3行的矩阵",{"2":{"1017":1}}],["为了获得一些解决问题的灵感",{"2":{"518":1}}],["为了获得良好的性能",{"2":{"801":1}}],["为了获得良好的准确性",{"2":{"25":1}}],["为了获得关于w",{"2":{"164":1}}],["为了获得多个通道的输出",{"2":{"121":1}}],["为了澄清这一点",{"2":{"112":1}}],["为了分析动量的收敛情况",{"2":{"95":1}}],["为了说明这样做的好处",{"2":{"792":1}}],["为了说明这一点",{"2":{"41":1,"130":1,"1021":2}}],["为了说明",{"2":{"709":1}}],["为了说明矢量化为什么如此重要",{"2":{"615":1}}],["为了说明一些关于过拟合和模型复杂性的经典直觉",{"2":{"259":1}}],["为了说明上述不同的目标",{"2":{"99":1}}],["为了说明β的不同选择的权重效果如何",{"2":{"89":1}}],["为了更简洁地表达模型",{"2":{"641":1}}],["为了更容易学习",{"2":{"587":1}}],["为了更好的衡量训练效果",{"2":{"595":1}}],["为了更好理解如何",{"2":{"473":1}}],["为了更好地作选择",{"2":{"1135":1}}],["为了更好地解释导数",{"2":{"981":1}}],["为了更好地可视化之后的注意力模式",{"2":{"386":1}}],["为了更好地理解反向传播算法",{"2":{"1122":1}}],["为了更好地理解门控循环单元模型",{"2":{"543":1}}],["为了更好地理解注意力汇聚",{"2":{"388":1}}],["为了更好地理解",{"2":{"318":1,"1100":1}}],["为了更好地理解此问题",{"2":{"306":1}}],["为了更好地说明这一点",{"2":{"243":1}}],["为了更好地了解动量法的几何属性",{"2":{"87":1}}],["为了更有效地计算小批量数据的注意力",{"2":{"390":1}}],["为了更方便地显示学习的注意力权重",{"2":{"375":1}}],["为了更详细地解释",{"2":{"86":1}}],["为了简化符号",{"2":{"1028":1}}],["为了简化输出",{"2":{"854":1}}],["为了简化问题",{"2":{"599":1,"621":1,"662":1}}],["为了简化后面章节中的训练",{"2":{"364":1}}],["为了简化后续部分的训练",{"2":{"341":1}}],["为了简化实现",{"2":{"80":1}}],["为了简洁起见",{"2":{"142":1,"582":1,"785":1}}],["为了简洁实现",{"2":{"21":1}}],["为了简单起见",{"2":{"54":2,"73":1,"129":1,"162":1,"190":1,"191":1,"346":1,"599":1,"718":1}}],["为了证明通过编译获得了性能改进",{"2":{"820":1}}],["为了证明这一点",{"2":{"46":1}}],["为了证明f的凸性意味着g是凸的",{"2":{"46":1}}],["为了证明f",{"2":{"46":1}}],["为了证明凸函数的f",{"2":{"46":1}}],["为了证明第一个不等式",{"2":{"42":1}}],["为了了解它是如何生效的",{"2":{"26":1}}],["的常用配置与排错思路",{"2":{"1547":1}}],["的桌面端组件库",{"2":{"1528":1}}],["的现代状态管理库",{"2":{"1528":1}}],["的现象",{"2":{"201":1}}],["的响应式机制",{"2":{"1527":1}}],["的设计理念是",{"2":{"1526":1}}],["的设计思路",{"2":{"1211":1}}],["的库或外部系统时",{"2":{"1518":1}}],["的配置",{"2":{"1453":1}}],["的返回值",{"0":{"1452":1}}],["的优势",{"0":{"1449":1}}],["的优点",{"2":{"389":1,"822":1}}],["的弊端",{"0":{"1448":1}}],["的修饰符",{"2":{"1441":1}}],["的命令行工具",{"2":{"1392":1}}],["的机器",{"2":{"1381":1}}],["的机器学习的简单演示",{"2":{"379":1}}],["的机器学习问题通常被为无监督学习",{"2":{"296":1}}],["的调度",{"2":{"1376":1}}],["的性能优化可以从以下几个方面入手",{"2":{"1371":1}}],["的性质",{"2":{"282":1}}],["的主配置文件通常是",{"2":{"1364":1}}],["的主要不同",{"2":{"137":1}}],["的工程",{"2":{"1544":1}}],["的工具",{"2":{"1347":1}}],["的工作原理",{"2":{"1100":1}}],["的指针",{"2":{"1321":1,"1322":1}}],["的四个核心区域",{"0":{"1319":1}}],["的区别",{"0":{"1349":1,"1395":1},"2":{"1318":1}}],["的区域和",{"2":{"1108":1}}],["的区域",{"2":{"879":1,"1108":1,"1319":1}}],["的名称",{"2":{"1315":1}}],["的语言",{"2":{"1305":1}}],["的语法机制",{"2":{"1237":1}}],["的语法结构就不一样",{"2":{"1092":1}}],["的语法",{"2":{"148":1}}],["的发展",{"2":{"1357":1}}],["的发展现状",{"0":{"1303":1}}],["的发明",{"2":{"300":1}}],["的结合体",{"2":{"1211":1}}],["的结果最相似",{"2":{"751":1}}],["的结果",{"2":{"41":1}}],["的演进路径",{"2":{"1210":1}}],["的本质",{"0":{"1205":1}}],["的表",{"2":{"1196":1}}],["的评分",{"2":{"1189":1}}],["的评分函数为",{"2":{"369":1}}],["的参数向量",{"2":{"1188":1}}],["的协方差矩阵",{"2":{"1185":1}}],["的估计值",{"2":{"1180":1}}],["的正确率",{"2":{"1174":1}}],["的选取",{"2":{"1167":1}}],["的初始值",{"2":{"1161":1}}],["的偏差",{"2":{"1160":1}}],["的均值被成为聚类结果的轮廓系数",{"2":{"1154":1}}],["的均值和方差",{"2":{"472":3}}],["的时候",{"2":{"1154":1,"1191":1}}],["的时间插入了随机词元",{"2":{"736":1}}],["的时间中",{"2":{"736":1}}],["的时间",{"2":{"721":3}}],["的样本时",{"2":{"1148":1}}],["的样本中时",{"2":{"1143":1}}],["的各个特征与预先选定的地标",{"2":{"1146":1}}],["的各元素都加上这些1",{"2":{"1090":1}}],["的范数",{"2":{"1145":1}}],["的范围",{"2":{"1107":1}}],["的范围内",{"2":{"553":1}}],["的长度是负值",{"2":{"1145":1}}],["的长度或范数",{"2":{"1145":1}}],["的示意图",{"2":{"1145":1}}],["的影响",{"2":{"1144":1,"1147":1}}],["的误差",{"2":{"1139":1}}],["的实践清单",{"2":{"1546":1}}],["的实体",{"2":{"1490":1}}],["的实例是恶性肿瘤",{"2":{"1139":1}}],["的实现与我们实现softmax回归时完全相同",{"2":{"225":1}}],["的增加",{"2":{"1133":1}}],["的增长",{"2":{"1132":2}}],["的意思是",{"2":{"1129":1}}],["的确是一次令人惊讶的成就",{"2":{"1127":1}}],["的代价值",{"2":{"1124":1}}],["的代码来替换前面的",{"2":{"827":1}}],["的代码",{"2":{"422":1,"827":1,"1126":1}}],["的代码中",{"2":{"407":1}}],["的差异",{"0":{"1351":1}}],["的差",{"2":{"1122":1}}],["的激活单元数所决定",{"2":{"1120":1}}],["的次数越高",{"2":{"1114":1}}],["的技术",{"2":{"1114":1}}],["的猜测初始值",{"2":{"1111":1}}],["的导数推出来就是这两个表达式",{"2":{"1111":1}}],["的收敛性",{"2":{"1111":1}}],["的变大而变大",{"2":{"1109":1}}],["的变形形式",{"2":{"755":1}}],["的作用是",{"2":{"1107":1}}],["的作用依然还是把两个矩阵放在一起",{"2":{"1089":1}}],["的算法",{"2":{"1106":1}}],["的神经元进行组合",{"2":{"1102":1}}],["的神经元和表示",{"2":{"1102":1}}],["的临床试验阶段",{"2":{"1098":1}}],["的多次项式进行预测时",{"2":{"1097":1}}],["的多层感知机构造了一个连续的分段线性函数",{"2":{"239":1}}],["的高度优化的数值",{"2":{"1093":1}}],["的高斯分布中采样权重",{"2":{"247":1}}],["的和",{"2":{"1093":1}}],["的平方",{"2":{"1092":1,"1296":1}}],["的前5个元素",{"2":{"1092":1}}],["的前三个元素与上下文不同时的元素不同",{"2":{"727":1}}],["的每个元素增加了1",{"2":{"1090":1}}],["的每一个元素求绝对值",{"2":{"1090":1}}],["的尺寸为",{"2":{"1099":1}}],["的尺寸",{"2":{"1089":1}}],["的推导过程",{"2":{"1086":1}}],["的转置矩阵",{"2":{"1090":1}}],["的转置",{"2":{"1077":1}}],["的转置为一个",{"2":{"1077":1}}],["的转换",{"2":{"302":1}}],["的融合体验",{"2":{"1054":1}}],["的定制",{"2":{"1054":1}}],["的定义与我们前面讨论的一样",{"2":{"559":1}}],["的强大推理和生成能力逐步释放",{"2":{"1049":1}}],["的客户端示例",{"2":{"1048":1}}],["的上限和下限",{"2":{"1038":1}}],["的上下文词是",{"2":{"774":1}}],["的上下文与噪声词索引contexts",{"2":{"763":1}}],["的上下文中",{"2":{"731":1,"732":1}}],["的上下文变量是注意力集中的输出",{"2":{"374":1}}],["的事件",{"2":{"1038":1}}],["的事件发生了",{"2":{"1027":1}}],["的期望值为",{"2":{"1036":1}}],["的一行记录",{"2":{"1196":1}}],["的一节",{"2":{"1028":1}}],["的一个例子",{"2":{"1098":1}}],["的一个小批量序列",{"2":{"319":1}}],["的一个相当原始的变形",{"2":{"316":1}}],["的一个特例",{"2":{"191":1}}],["的任意一个可数序列a1",{"2":{"1027":1}}],["的行向量转换为形状为",{"2":{"1017":1}}],["的行会将",{"2":{"1012":1}}],["的frobenius范数",{"2":{"1000":1}}],["的概念",{"2":{"997":1,"1028":1,"1108":1,"1138":1}}],["的概率",{"2":{"1025":1,"1028":1,"1110":2}}],["的概率取决于先前的输出子序列",{"2":{"574":1}}],["的概率取决于",{"2":{"512":1}}],["的概率为p",{"2":{"105":1}}],["的链式法则",{"2":{"986":1}}],["的起源",{"2":{"980":1}}],["的面积",{"2":{"980":1}}],["的sizes参数传递两个比例值的列表",{"2":{"959":1}}],["的split",{"2":{"681":1}}],["的格式",{"2":{"956":1}}],["的通道代表了索引为i的锚框有关类别索引为j的预测",{"2":{"954":1}}],["的中心分布于特征图",{"2":{"912":1}}],["的中心词索引center和形状为",{"2":{"763":1}}],["的宽度和高度",{"2":{"912":1}}],["的32位浮点数",{"2":{"882":1}}],["的几率y为正向类",{"2":{"1107":1}}],["的几率向上或向下翻转",{"2":{"879":1}}],["的几率使图像向左或向右翻转",{"2":{"879":1}}],["的几何学书籍举例说明",{"2":{"299":1}}],["的相似程度来生成新的特征",{"2":{"1146":1}}],["的相对损失",{"2":{"966":1}}],["的相对距离来计算",{"2":{"863":1}}],["的相同表示",{"2":{"732":1}}],["的关系",{"0":{"1350":1,"1394":1,"1453":1}}],["的关系图",{"2":{"268":1}}],["的关键机制",{"2":{"1051":1}}],["的关注点解耦",{"2":{"844":1}}],["的聚合值",{"2":{"844":1}}],["的抽象",{"2":{"844":1}}],["的gpu",{"2":{"832":1}}],["的glove嵌入",{"2":{"714":1}}],["的大型操作",{"2":{"811":1}}],["的大小",{"2":{"638":1,"1189":1}}],["的大小就足够了",{"2":{"26":1}}],["的需要",{"2":{"811":1}}],["的具体好处是值得的",{"2":{"811":1}}],["的速度工作",{"2":{"804":1}}],["的同时复制y",{"2":{"797":1}}],["的余弦相似度可能很高",{"2":{"788":1}}],["的数值",{"2":{"1112":1}}],["的数量",{"2":{"773":1,"774":1}}],["的数据格式",{"2":{"1197":1}}],["的数据库",{"2":{"1195":1}}],["的数据着手",{"2":{"1181":1}}],["的数据作为交叉验证集",{"2":{"1131":1}}],["的数据作为测试集",{"2":{"1130":1,"1131":1}}],["的数据作为训练集",{"2":{"1130":1,"1131":1}}],["的数据",{"2":{"179":1}}],["的采样率不到1",{"2":{"773":1}}],["的索引基于",{"2":{"1199":1}}],["的索引",{"2":{"762":1}}],["的键是两个连续符号的元组",{"2":{"757":1}}],["的压缩算法来提取子词",{"2":{"757":1}}],["的比喻",{"2":{"751":1}}],["的比较情况",{"2":{"213":1}}],["的类比来测试句法",{"2":{"751":1}}],["的类比",{"2":{"751":3}}],["的共现在训练中更有用",{"2":{"773":1}}],["的共现比与高频单词",{"2":{"773":1}}],["的共现概率及其比值",{"2":{"744":1}}],["的共现频率更高",{"2":{"741":1}}],["的共现频率可能比与",{"2":{"741":1}}],["的间隔内递增",{"2":{"743":1}}],["的连续句子",{"2":{"737":1}}],["的连结",{"2":{"734":2}}],["的过程",{"2":{"726":1}}],["的过去状态的数量",{"2":{"540":1}}],["的计数",{"2":{"722":3}}],["的计算可用来表示逻辑运算",{"2":{"1101":1}}],["的计算机",{"2":{"801":1}}],["的计算方法为",{"2":{"381":1}}],["的计算理论",{"2":{"299":1}}],["的随机词元",{"2":{"721":1}}],["的随机词元进行预测",{"2":{"721":1}}],["的合集上预训练的",{"2":{"718":1}}],["的全连接层",{"2":{"713":1}}],["的情绪",{"2":{"691":1}}],["的情况",{"2":{"501":1,"1143":1}}],["的情况下预测标签",{"2":{"289":1}}],["的情况下",{"2":{"193":1}}],["的情况下实现算法",{"2":{"23":1}}],["的bert表示已经对输入的两个句子进行了编码",{"2":{"737":1}}],["的bert表示",{"2":{"735":1}}],["的bert表示进行了转换",{"2":{"688":1}}],["的bert表示对整个输入文本序列的信息进行编码",{"2":{"657":1}}],["的例子",{"2":{"665":1,"1093":1}}],["的例子都证明了这一进展",{"2":{"300":1}}],["的标签",{"2":{"665":1}}],["的分类算法",{"2":{"1112":1}}],["的分数区间",{"2":{"658":1}}],["的分布p",{"2":{"191":1}}],["的分布可能会因我们的位置不同而得到不同的翻译",{"2":{"183":1}}],["的分布没有任何改变",{"2":{"180":1}}],["的理论基础上",{"2":{"643":1}}],["的二阶导数",{"2":{"655":1}}],["的二维张量",{"2":{"631":1,"858":1}}],["的二进制是",{"2":{"399":1}}],["的向量",{"2":{"631":1,"762":1,"1088":1,"1089":1}}],["的向量表示在",{"2":{"754":1}}],["的向量表示",{"2":{"284":1}}],["的聪明方式",{"2":{"624":1}}],["的y^j",{"2":{"624":1}}],["的信息xi",{"2":{"619":1}}],["的信息论和艾伦",{"2":{"299":1}}],["的加权和",{"2":{"610":1}}],["的文件",{"2":{"1089":1}}],["的文件中",{"2":{"442":1}}],["的文章",{"2":{"772":1}}],["的文本没有单词边界指示符",{"2":{"571":1}}],["的成本是相当高的",{"2":{"561":1}}],["的张量x",{"2":{"1004":1}}],["的张量",{"2":{"545":1,"631":1,"634":1,"968":1,"1004":1,"1017":3}}],["的元素相乘可以减少以往状态的影响",{"2":{"541":1}}],["的隐状态设为ht",{"2":{"527":1}}],["的隐藏的层",{"2":{"338":1}}],["的宏观数据可用",{"2":{"526":1}}],["的循环神经网络",{"2":{"520":2}}],["的求和中会有更多的对数项",{"2":{"515":1}}],["的词元作为预测的掩蔽词元",{"2":{"736":1}}],["的词元是a和c",{"2":{"515":1}}],["的词元都是已知的",{"2":{"408":1}}],["的最佳实践写成可复用模板",{"2":{"1547":1}}],["的最小可行脚手架",{"2":{"1547":1}}],["的最小存储单元",{"2":{"1196":1}}],["的最小k",{"2":{"1160":1}}],["的最小值",{"2":{"57":1,"64":1,"1067":1}}],["的最终结果就是hθ",{"2":{"1093":1}}],["的最大汇聚层",{"2":{"507":1}}],["的卷积层",{"2":{"507":1}}],["的卷积核",{"2":{"129":4}}],["的vgg网络中",{"2":{"506":1}}],["的权重和偏置参数设成0",{"2":{"501":1}}],["的函数绘制的图表",{"2":{"1134":1}}],["的函数映射",{"2":{"1063":1}}],["的函数调用中可以显式地启用tensorflow中的xla",{"2":{"819":1}}],["的函数",{"2":{"488":1,"509":1,"1110":1,"1143":1}}],["的组件库",{"2":{"1528":1}}],["的组件更有价值",{"2":{"422":1}}],["的组合",{"2":{"487":1}}],["的更广泛的讨论中",{"2":{"475":1}}],["的核心价值在于提供类型安全和更好的开发体验",{"2":{"1436":1}}],["的核心特性",{"2":{"1397":1}}],["的核心环节",{"2":{"1354":1}}],["的核心在于",{"2":{"1211":1}}],["的核心设计理念",{"2":{"1194":1}}],["的核心能力模块",{"0":{"1052":1}}],["的核心理念是将",{"2":{"1040":1}}],["的核心问题",{"2":{"564":1}}],["的核心",{"2":{"457":1}}],["的像素值组成的",{"2":{"454":1}}],["的所有元素绕着从第",{"2":{"1077":1}}],["的所有元素",{"2":{"1020":1}}],["的所有元素仍然采用相同的值",{"2":{"244":1}}],["的所有参数都将进行微调",{"2":{"688":1}}],["的所有值求和",{"2":{"519":1}}],["的所有成员",{"2":{"424":1}}],["的识别和检测任务",{"2":{"422":1}}],["的重复模式组成",{"2":{"422":1}}],["的注意力权重都有相同的查询",{"2":{"409":1}}],["的注意力权重",{"2":{"409":1}}],["的开头",{"2":{"408":1}}],["的位置编码可以线性投影位置i处的位置编码来表示",{"2":{"400":1}}],["的线性回归模型w^⊤x+b^",{"2":{"614":1}}],["的线性组合",{"2":{"94":1}}],["的线不如之前非参数模型的平滑",{"2":{"392":1}}],["的启发",{"2":{"379":1}}],["的形状将与x相同",{"2":{"969":1,"971":1}}],["的形状",{"2":{"382":8,"573":6,"574":5,"1017":1}}],["的形状为",{"2":{"375":4}}],["的形状由内核的高度和宽度决定",{"2":{"126":1}}],["的框架开始讲起",{"2":{"355":1}}],["的困难",{"2":{"351":1}}],["的能力",{"2":{"351":1}}],["的量",{"2":{"342":1}}],["的可能性",{"2":{"342":1}}],["的可靠预测呢",{"2":{"282":1}}],["的续写",{"2":{"342":1}}],["的矩阵",{"2":{"340":2,"1017":1,"1089":2}}],["的矩阵乘法链",{"2":{"334":1}}],["的球来裁剪梯度g",{"2":{"334":1}}],["的输出结果是什么",{"2":{"1004":1}}],["的输出和形状为n×4的输出",{"2":{"938":1}}],["的输出层的参数将从零开始学习",{"2":{"688":1}}],["的输出张量",{"2":{"405":1}}],["的输出矩阵",{"2":{"340":1}}],["的输出",{"2":{"330":1,"549":1,"763":1}}],["的输入是从分布p中抽取的随机变量时",{"2":{"1036":1}}],["的输入表示",{"2":{"683":1}}],["的输入来预测时间步t",{"2":{"549":1}}],["的输入",{"2":{"136":2,"338":1,"905":1}}],["的单位矩阵",{"2":{"1090":1}}],["的单词序列频率",{"2":{"316":1}}],["的单隐藏层多层感知机上",{"2":{"161":1}}],["的出现频率要低得多",{"2":{"316":1}}],["的损失函数",{"2":{"312":1}}],["的top",{"2":{"301":1}}],["的普及",{"2":{"300":1}}],["的得名源于生物灵感",{"2":{"299":1}}],["的学习笔记",{"2":{"1305":1}}],["的学习问题",{"2":{"295":1}}],["的学习率η是很棘手的",{"2":{"58":1}}],["的简写",{"2":{"295":1,"422":4}}],["的商品",{"2":{"294":1}}],["的匹配性打分",{"2":{"294":1}}],["的帖子也可能涉及",{"2":{"292":1}}],["的帖子可能会提到",{"2":{"292":1}}],["的图像是",{"2":{"1101":1}}],["的图像",{"2":{"292":1}}],["的死亡风险",{"2":{"291":1}}],["的硬分类预测呢",{"2":{"291":1}}],["的问题叫做分类",{"2":{"291":1}}],["的问题",{"2":{"291":1,"297":1,"299":1,"1114":1,"1139":1,"1356":2}}],["的问题很可能就是回归问题",{"2":{"290":1}}],["的条件概率可以由以下公式建模",{"2":{"785":1}}],["的条件概率可以通过对向量点积的softmax操作来建模",{"2":{"783":1}}],["的条件概率分布",{"2":{"574":1}}],["的条件概率为",{"2":{"513":1}}],["的条件概率",{"2":{"289":1,"513":1,"783":1,"785":1}}],["的系统",{"2":{"285":1}}],["的要求",{"2":{"284":1}}],["的属性组成",{"2":{"284":1}}],["的声音",{"2":{"282":1}}],["的预测边界框后",{"2":{"854":1}}],["的预测序列上的困惑度",{"2":{"546":1}}],["的预测概率",{"2":{"295":1}}],["的预测通常是正确的",{"2":{"282":1}}],["的预测模型能在未知的数据上有很好的表现",{"2":{"170":1}}],["的预测模型",{"2":{"170":1}}],["的集合称为",{"2":{"282":1}}],["的基本特性",{"0":{"1302":1}}],["的基本细节",{"2":{"134":1}}],["的基础上构建代理",{"2":{"1041":1}}],["的基础知识",{"2":{"281":1}}],["的复杂性",{"2":{"254":1}}],["的模型",{"2":{"254":1,"290":1}}],["的模型训练",{"2":{"25":1}}],["的假设在神经网络中很容易被违反",{"2":{"247":1}}],["的方向迈出的",{"2":{"1165":1}}],["的方式输出",{"2":{"1100":1}}],["的方式注入噪声",{"2":{"170":1}}],["的方法是",{"2":{"1184":1}}],["的方法",{"2":{"613":1,"1069":1}}],["的方法可以被看作用数据编程",{"2":{"282":1}}],["的方差为a23",{"2":{"247":1}}],["的乘积",{"2":{"241":1}}],["的生物神经元进行建模",{"2":{"236":1}}],["的网络",{"2":{"233":1}}],["的等价单层模型",{"2":{"232":1}}],["的原始动机似乎不是一个有效的解释",{"2":{"476":1}}],["的原始值为",{"2":{"209":1}}],["的原因",{"2":{"262":1,"405":1}}],["的原因之一",{"2":{"165":1}}],["的道德困境中的一小部分",{"2":{"201":1}}],["的第二列",{"2":{"1089":1}}],["的第0维",{"2":{"699":1}}],["的第0个维度",{"2":{"120":2,"121":1}}],["的第jth元素",{"2":{"192":1}}],["的训练样本作为调整超参数的验证集",{"2":{"890":1}}],["的训练",{"2":{"191":1}}],["的想法很有吸引力",{"2":{"242":1}}],["的想法",{"2":{"186":1}}],["的对象",{"2":{"182":1,"1216":1}}],["的对角线",{"2":{"26":1}}],["的节点的分数进行规范化来消除每一层的偏差",{"2":{"170":1}}],["的精度",{"2":{"169":1}}],["的当前值",{"2":{"165":1}}],["的梯度会加在一起",{"2":{"437":1}}],["的梯度写为下式",{"2":{"241":1}}],["的梯度",{"2":{"164":1,"605":4,"786":1}}],["的梯度将被约束函数的梯度所抵消",{"2":{"48":1}}],["的这一概念系统化",{"2":{"152":1}}],["的汇聚窗口",{"2":{"147":1}}],["的使用",{"2":{"134":1}}],["的边缘检测器足以",{"2":{"129":1}}],["的距离最小",{"2":{"1191":1}}],["的距离",{"2":{"118":1}}],["的不等式求和",{"2":{"115":1}}],["的l2范数受到某个常数l的限制",{"2":{"115":1}}],["的目标是估计序列的联合概率",{"2":{"315":1}}],["的目标是减少泛化误差",{"2":{"99":1}}],["的目标函数",{"2":{"115":1}}],["的瞬间梯度所注入的不确定性的影响",{"2":{"113":1}}],["的无偏估计",{"2":{"113":1}}],["的特征向量",{"2":{"1188":1}}],["的特征图",{"2":{"956":1}}],["的特征和相关的标签经过迭代",{"2":{"190":1}}],["的特征值",{"2":{"31":1}}],["的特性",{"2":{"60":1}}],["的值来告诉我们数据是否真的是异常的",{"2":{"1181":1}}],["的值小于0",{"2":{"1145":1}}],["的值太大了",{"2":{"1115":1}}],["的值很大的话",{"2":{"1115":1}}],["的值就是这样一个集合",{"2":{"1092":1}}],["的值设置为0",{"2":{"1012":1}}],["的值设置为1",{"2":{"1012":1}}],["的值为0",{"2":{"1093":1}}],["的值为",{"2":{"624":1}}],["的值相同与否",{"2":{"146":2}}],["的值",{"2":{"55":1,"154":1,"1089":1,"1115":3}}],["的值可能会下降",{"2":{"54":1}}],["的凸性",{"2":{"52":1}}],["的点",{"2":{"50":1}}],["的",{"2":{"40":2,"190":1,"207":1,"286":2,"302":1,"368":1,"981":1,"984":1,"1092":1,"1122":1,"1144":1,"1206":1,"1314":1,"1436":1,"1456":1,"1494":1,"1546":1}}],["的泄漏平均值",{"2":{"20":1}}],["练习",{"0":{"23":1,"31":1,"37":1,"52":1,"64":1,"75":1,"83":1,"97":1,"105":1,"111":1,"118":1,"124":1,"133":1,"139":1,"144":1,"150":1,"160":1,"167":1,"178":1,"203":1,"215":1,"223":1,"227":1,"239":1,"250":1,"268":1,"280":1,"304":1,"314":1,"323":1,"328":1,"337":1,"344":1,"353":1,"359":1,"366":1,"372":1,"378":1,"384":1,"394":1,"402":1,"411":1,"416":1,"420":1,"428":1,"439":1,"444":1,"453":1,"465":1,"477":1,"485":1,"491":1,"498":1,"505":1,"511":1,"517":1,"525":1,"531":1,"537":1,"549":1,"563":1,"571":1,"580":1,"586":1,"597":1,"607":1,"621":1,"628":1,"638":1,"655":1,"662":1,"671":1,"684":1,"690":1,"697":1,"706":1,"711":1,"717":1,"724":1,"729":1,"740":1,"746":1,"753":1,"759":1,"770":1,"779":1,"788":1,"794":1,"799":1,"815":1,"823":1,"830":1,"839":1,"846":1,"856":1,"860":1,"868":1,"876":1,"885":1,"898":1,"910":1,"915":1,"929":1,"935":1,"942":1,"951":1,"966":1,"972":1,"979":1,"986":1,"1004":1,"1009":1,"1015":1,"1024":1,"1038":1}}],["它负责网页上的一切你能看见和点击的东西",{"2":{"1533":1}}],["它负责计算hθ",{"2":{"1099":1}}],["它最大的特点是",{"2":{"1296":1}}],["它最初产生的目的是制造能模拟大脑的机器",{"2":{"1098":1}}],["它针对一些问题",{"2":{"1187":1}}],["它又类似于一些监督学习问题",{"2":{"1178":1}}],["它虽然主要用于非监督学习问题",{"2":{"1178":1}}],["它并不考虑任何与结果变量有关的信息",{"2":{"1162":1}}],["它并不能代替一门完整的课程",{"2":{"800":1}}],["它实际上会变得非常困难",{"2":{"1156":1}}],["它非常短",{"2":{"1145":1}}],["它非常受欢迎",{"2":{"32":1}}],["它事实上就是一个始于原点",{"2":{"1145":1}}],["它仅仅和θ1",{"2":{"1145":1}}],["它仅仅是记忆元的tanh的门控版本",{"2":{"556":1}}],["它用最大间距将样本区分开",{"2":{"1144":1}}],["它用于组织大型计算机集群",{"2":{"1061":1}}],["它看上去很有可能会其他算法更好",{"2":{"1141":1}}],["它看起来像个马鞍",{"2":{"102":1}}],["它基本上非常直观地告诉你",{"2":{"1138":1}}],["它至少还是一个合理的算法",{"2":{"1122":1}}],["它让算法使用起来更模糊一点",{"2":{"1111":1}}],["它计算出代价函数",{"2":{"1111":1}}],["它计算该窗口中输入子张量的最大值或平均值",{"2":{"146":1}}],["它适用于标签",{"2":{"1106":1}}],["它适用于几乎所有图像分类器",{"2":{"475":1}}],["它含有许多输入",{"2":{"1099":1}}],["它现在正在fda",{"2":{"1098":1}}],["它现在受制于全局解释器锁",{"2":{"450":1}}],["它连接到服务器",{"2":{"1094":1}}],["它运行起来也将更加高效",{"2":{"1093":1}}],["它运行了一个while循环",{"2":{"425":1}}],["它就会使用众多高级优化算法中的一个",{"2":{"1111":1}}],["它就会就通过它的轴突",{"2":{"1099":1}}],["它就能获取你面前事物的低分辨率的灰度图像",{"2":{"1098":1}}],["它就计算出",{"2":{"1092":1}}],["它就像是矩阵形向量的l2范数",{"2":{"1000":1}}],["它告诉了octave这个函数有一个参数",{"2":{"1092":1}}],["它生成了一个颜色图像",{"2":{"1091":1}}],["它显示了当前octave的版本",{"2":{"1088":1}}],["它显著减少了模型所需参数的数量",{"2":{"495":1}}],["它其中的矩阵和向量将有助于帮助我们实现之后更多的机器学习模型",{"2":{"1070":1}}],["它使得θ1不再改变",{"2":{"1068":1}}],["它使用了softmax运算中输出类别的概率分布",{"2":{"654":1}}],["它使用并行连结的网络",{"2":{"492":1}}],["它使用类似于python",{"2":{"300":1}}],["它使用",{"2":{"295":1}}],["它使用指数加权移动平均值来估算梯度的动量和二次矩",{"2":{"33":1}}],["它使用s",{"2":{"25":1}}],["它使用参数本身的变化率来调整学习率",{"2":{"22":1}}],["它已经在一个局部的最优处或局部最低点",{"2":{"1068":1}}],["它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大",{"2":{"1067":1,"1068":1}}],["它被称作监督学习是因为对于每个数据来说",{"2":{"1063":1}}],["它被称为支持向量机",{"2":{"1143":1}}],["它被称为方阵",{"2":{"992":1}}],["它被称为标签",{"2":{"284":1}}],["它似乎是这样",{"2":{"1061":1}}],["它似乎是1占主流",{"2":{"252":1}}],["它再将这些新闻分组",{"2":{"1061":1}}],["它都会给出其他电影或产品或音乐的建议",{"2":{"1058":1}}],["它都保持不变",{"2":{"754":1}}],["它永远不会检测不出",{"2":{"1035":1}}],["它提供了各种功能",{"2":{"1023":1}}],["它给我们提供了内存中引用对象的确切地址",{"2":{"1021":1}}],["它研究如何识别图像中各个目标实例的像素级区域",{"2":{"944":1}}],["它重点关注于如何将图像分割成属于不同语义类别的区域",{"2":{"943":1}}],["它重复使用由卷积层和1×1卷积层",{"2":{"492":1}}],["它表示octave",{"2":{"1111":1}}],["它表示为向量元素的绝对值之和",{"2":{"1000":1}}],["它表示",{"2":{"989":1}}],["它表达了通道i和通道j上风格特征的相关性",{"2":{"923":1}}],["它表现的可能比随机猜测好不到哪去",{"2":{"252":1}}],["它只有在z",{"2":{"1144":1}}],["它只保留需要用到的vgg的所有层",{"2":{"920":1}}],["它只是用这些语言来实现会更加复杂",{"2":{"1061":1}}],["它只是将任务返回到后端队列",{"2":{"790":1}}],["它只是矩阵",{"2":{"164":1}}],["它复制了resnet",{"2":{"862":1}}],["它把许多向量变换成一个向量",{"2":{"844":1}}],["它把这个函数分解成越来越高阶的项",{"2":{"479":1}}],["它依然能够容易地和快速地训练",{"2":{"826":1}}],["它依赖于相对较小的小批量数据来处理",{"2":{"300":1}}],["它按顺序执行函数体的操作",{"2":{"816":1}}],["它为应用程序向",{"2":{"1040":1}}],["它为每条链路提供高达300gbit",{"2":{"812":1}}],["它为系统需要的训练数据和中间检查点需要的存储提供了足够的传输速度",{"2":{"801":1}}],["它为各种技术打开了密度估计的大门",{"2":{"300":1}}],["它除了能够运行操作系统和许多其他功能之外",{"2":{"801":1}}],["它随机采样1到max",{"2":{"774":1}}],["它随n线性增长",{"2":{"113":1}}],["它必须保持f",{"2":{"744":1}}],["它仍然知道在哪里可以找到",{"2":{"1092":1}}],["它仍然存在下面的附加条件",{"2":{"805":1}}],["它仍然比ptb数据集的大两倍以上",{"2":{"722":1}}],["它仍将被复制并保存在新分配的显存中",{"2":{"449":1}}],["它认为基于任意词wc生成词表v中所有词的条件概率总和为1",{"2":{"709":1}}],["它由俄罗斯的",{"2":{"1359":1}}],["它由内容损失",{"2":{"921":1}}],["它由转置卷积层实现",{"2":{"863":1}}],["它由一个训练集和一个测试集组成",{"2":{"691":1}}],["它由三个联合训练的步骤组成",{"2":{"673":1}}],["它应该返回与该查询最相关的新闻文章的排序列表",{"2":{"662":1}}],["它应该允许我们在压缩序列时花费更少的比特",{"2":{"342":1}}],["它属于文本对分类",{"2":{"658":1}}],["它测量给定模型编码数据所需的比特数",{"2":{"654":1}}],["它接受批量大小作为参数",{"2":{"635":1}}],["它接受一个长度可变的序列作为输入",{"2":{"532":1}}],["它要么到达目的地",{"2":{"619":1}}],["它要求我们将所有数据加载到内存中",{"2":{"600":1}}],["它要求我们将循环神经网络的计算图一次展开一个时间步",{"2":{"306":1}}],["它返回训练集和测试集的数据迭代器",{"2":{"949":1}}],["它返回训练和测试数据迭代器以及imdb评论数据集的词表",{"2":{"695":1}}],["它返回一个字典",{"2":{"890":1}}],["它返回输出张量y",{"2":{"699":1}}],["它返回所有样本损失的平均值",{"2":{"593":3}}],["它返回yk=∑i",{"2":{"416":1}}],["它包括学习速率和其他超参数设置",{"2":{"500":1}}],["它包含16个整数单位和16个浮点单位",{"2":{"811":1}}],["它包含一个集成gpu",{"2":{"807":1}}],["它包含一个多层感知机",{"2":{"423":1}}],["它包含256个隐藏单元",{"2":{"217":1}}],["它利用许多重复的神经网络块",{"2":{"492":1}}],["它串联了5个inception块",{"2":{"488":1}}],["它通过移除来抑制预测的边界框",{"2":{"856":1}}],["它通过增加有效的小批量数据量的大小提高了训练效率",{"2":{"838":1}}],["它通过不断地在损失函数递减的方向上更新参数来降低误差",{"2":{"613":1}}],["它通过不同窗口形状的卷积层和最大汇聚层来并行抽取信息",{"2":{"490":1}}],["它通过测量预测序列和标签序列之间的n元语法的匹配度来评估预测",{"2":{"579":1}}],["它通过残差块构建跨层的数据通道",{"2":{"492":1}}],["它通过1×1卷积层来减小通道数",{"2":{"481":1}}],["它通常由8个或更多个核心组成",{"2":{"801":1}}],["它通常被称为截断的通过时间反向传播",{"2":{"309":1}}],["它通常也被称为l2正则化",{"2":{"270":1}}],["它通常与控制权重向量的维数和大小结合使用的",{"2":{"177":1}}],["它作为这些辩论的焦点而产生共鸣",{"2":{"475":1}}],["它不仅被用在线性回归上和线性回归模型",{"2":{"1069":1}}],["它不会改变参数的值",{"2":{"1068":1}}],["它不会得到改善",{"2":{"113":1}}],["它不只是一个回答问题的模型",{"2":{"1050":1}}],["它不如第一个测试那么精确",{"2":{"1035":1}}],["它不出现在图像分类中",{"2":{"934":1}}],["它不需要如sigmoid激活函数那般复杂的求幂运算",{"2":{"460":1}}],["它一举打破了计算机视觉研究的现状",{"2":{"458":1}}],["它首次证明了学习到的特征可以超越手工设计的特征",{"2":{"458":1}}],["它以较低的计算复杂度提供了类似的测试精度",{"2":{"490":1}}],["它以两个块为参数",{"2":{"428":1}}],["它以x作为输入",{"2":{"423":1}}],["它以其提出者",{"2":{"247":1}}],["它维护了一个由layer组成的有序列表",{"2":{"422":1}}],["它维护了一个由model组成的有序列表",{"2":{"422":1}}],["它维护了一个由module组成的有序列表",{"2":{"422":1}}],["它维护block的有序列表",{"2":{"422":1}}],["它对应于一个不同的灰度",{"2":{"1091":1}}],["它对应着h个头连结后的结果",{"2":{"381":1}}],["它对上下文进行双向编码",{"2":{"733":1,"739":1}}],["它对保持数值稳定性至关重要",{"2":{"240":1}}],["它双向对齐并且可以微分",{"2":{"379":1}}],["它如何影响训练效率",{"2":{"378":1}}],["它如何影响性能",{"2":{"75":1}}],["它因语言而异",{"2":{"366":1}}],["它归结为以下两种策略",{"2":{"347":1}}],["它存储了到时间步t−1的序列信息",{"2":{"338":1}}],["它既能作为单机数据库替代",{"2":{"1211":1}}],["它既可以是从头开始实现的d2l",{"2":{"335":1}}],["它既是人工智能的一个分支",{"2":{"302":1}}],["它还引入了兴趣区域汇聚层",{"2":{"941":1}}],["它还提供了哪些其他的图像增广方法",{"2":{"885":1}}],["它还有一个值得拥有的副作用",{"2":{"334":1}}],["它还是研究优化算法的一个很好的工具",{"2":{"102":1}}],["它限制了事情变糟的程度",{"2":{"334":1}}],["它限制了取得进展的速度",{"2":{"334":1}}],["它真的会在文档的序列上实现完美的均匀分布吗",{"2":{"323":1}}],["它真的是最优值吗",{"2":{"280":1}}],["它同时返回数据迭代器和词表",{"2":{"321":1}}],["它陷入到whh⊤的潜在的非常大的幂",{"2":{"312":1}}],["它需要保存e和f的变量值",{"2":{"816":1}}],["它需要两个输入",{"2":{"736":1}}],["它需要的时间和内存都太多了",{"2":{"306":1}}],["它需要更多的时间来达到同样的损失",{"2":{"80":1}}],["它类似于蒸汽机和煤吗",{"2":{"304":1}}],["它结合了统计学",{"2":{"303":1}}],["它能返回代价函数值",{"2":{"1111":1}}],["它能帮助失明人士看见事物",{"2":{"1098":1}}],["它能被用在很多地方",{"2":{"1061":1}}],["它能改变照片的颜色风格",{"2":{"916":1}}],["它能提高测试准确性吗",{"2":{"885":1}}],["它能确保处理器核心不缺乏数据",{"2":{"810":1}}],["它能够在从未见过的数据上表现良好",{"2":{"980":1}}],["它能够把最接近的真实边界框分配给锚框",{"2":{"850":1}}],["它能够简化本书其余部分的代码",{"2":{"635":1}}],["它能够搜索出最佳参数",{"2":{"287":1}}],["它能带来用其他方法很难实现的结果",{"2":{"301":1}}],["它能很好地检测到所有垃圾邮件",{"2":{"187":1}}],["它会变成一个非常有力的工具",{"2":{"1138":1}}],["它会很快地教你一些你需要知道的线性代数的知识",{"2":{"1070":1}}],["它会导致无法收敛",{"2":{"1068":1}}],["它会需要很多步才能到达全局最低点",{"2":{"1068":1}}],["它会让你对学习算法的学习和建原型快上许多",{"2":{"1061":1}}],["它会在train",{"2":{"635":1}}],["它会自动删除重复层",{"2":{"437":1}}],["它会使加权区域更加尖锐",{"2":{"394":1}}],["它会生成荒谬的预测结果",{"2":{"333":1}}],["它会将详细的用户活动和项目特征考虑在内",{"2":{"294":1}}],["它会输出接近于零的数",{"2":{"282":1}}],["它会随梯度的大小自动变化",{"2":{"25":1}}],["它很可能可以",{"2":{"282":1}}],["它与矩阵乘法不同",{"2":{"1003":1}}],["它与图像分类中的有什么不同",{"2":{"935":1}}],["它与我们之前图像分类任务中的相同",{"2":{"932":1}}],["它与我们训练",{"2":{"335":1}}],["它与低频单词",{"2":{"773":1}}],["它与",{"2":{"461":1}}],["它与数据生成函数的阶数相同",{"2":{"264":1}}],["它与梯度以及优化问题的变量具有相同的形状",{"2":{"91":1}}],["它却是导致梯度消失问题的一个常见的原因",{"2":{"242":1}}],["它求导表现得特别好",{"2":{"235":1}}],["它",{"2":{"225":1}}],["它选择第i个切片作为验证数据",{"2":{"211":1}}],["它方便优化",{"2":{"209":1}}],["它比哈里森和鲁宾菲尔德的波士顿房价",{"2":{"205":1}}],["它比没有动量时解将会发散要好得多",{"2":{"88":1}}],["它工作得很好",{"2":{"185":1}}],["它有三个概念",{"2":{"1490":1}}],["它有可能会停留在一个局部最小值处",{"2":{"1153":1}}],["它有可能会反过来将在轴突上的自己的消息传给其他神经元",{"2":{"1099":1}}],["它有大量的训练数据集",{"2":{"1141":1}}],["它有超过1000万的图像和1000类的物体",{"2":{"869":1}}],["它有四个元素",{"2":{"848":1}}],["它有四个维度",{"2":{"147":1}}],["它有非常好的使用范围",{"2":{"812":1}}],["它有3个卷积层",{"2":{"702":1}}],["它有着广泛的应用",{"2":{"665":1}}],["它有许多与门控循环单元",{"2":{"551":1}}],["它有一个超参数",{"2":{"515":1}}],["它有一个隐藏层和两个隐藏单元",{"2":{"244":1}}],["它有一个隐藏层",{"2":{"105":1}}],["它有多好",{"2":{"215":1}}],["它有助于模型选择和超参数调整",{"2":{"211":1}}],["它具有第二高的条件概率",{"2":{"513":1}}],["它具有双重目的",{"2":{"145":1}}],["它具有1个输出通道和形状为",{"2":{"129":4}}],["它在索引i处的值是采样结果中i出现的次数",{"2":{"1026":1}}],["它在其输入a中是分段线性的",{"2":{"977":1}}],["它在零点附近使用平方函数从而更加平滑",{"2":{"966":1}}],["它在训练时不需要有关图像像素的标签信息",{"2":{"944":1}}],["它在不同区域前向传播中转置卷积层输出的平均值可以作为softmax运算的输入",{"2":{"866":1}}],["它在本章中在衡量",{"2":{"820":1}}],["它在广泛应用于政治",{"2":{"691":1}}],["它在回归的各种标准工具中最简单而且最流行",{"2":{"609":1}}],["它在2015年的imagenet图像识别挑战赛夺魁",{"2":{"500":1}}],["它在同一设备上找不到数据会导致失败",{"2":{"449":1}}],["它在",{"2":{"330":1}}],["它在可以减少损失的方向上优化参数",{"2":{"287":1}}],["它在大部分时候被更简单",{"2":{"236":1}}],["它在所有基准测试中都能很好地工作",{"2":{"188":1}}],["它在整个冬天都有效",{"2":{"187":1}}],["它在实际生活中非常具有代表性",{"2":{"93":1}}],["它在计算广告学和个性化协同过滤等其他领域也很常见",{"2":{"25":1}}],["它相当于有效样本数量增加到11−0",{"2":{"91":1}}],["它累加了过去的梯度",{"2":{"86":1}}],["它也经常用于初始化转置卷积层",{"2":{"863":1}}],["它也可以直接将其作为普通的python函数调用",{"2":{"819":1}}],["它也增加了芯片尺寸",{"2":{"810":1}}],["它也是我们所介绍的最后一个监督学习算法",{"2":{"1143":1}}],["它也是函数曲线的切线的斜率",{"2":{"985":1}}],["它也是通用消息传递算法",{"2":{"519":1}}],["它也是全局最小值",{"2":{"44":1}}],["它也有很好的副作用",{"2":{"86":1}}],["它初始化了一个线性回归模型",{"2":{"80":1}}],["它所依据的观点是",{"2":{"72":1}}],["它将这些电影的用户评分数据都存在矩阵里",{"2":{"1191":1}}],["它将决策界",{"2":{"1144":1}}],["它将表现的很差",{"2":{"1114":1}}],["它将输出所有这三个结果",{"2":{"1091":1}}],["它将会绘制一个5",{"2":{"1091":1}}],["它将右图中的横轴的范围调整至0",{"2":{"1091":1}}],["它将图像分为一个1",{"2":{"1091":1}}],["它将边界框表示成matplotlib的边界框格式",{"2":{"858":1}}],["它将如何影响性能",{"2":{"846":1}}],["它将通过对e",{"2":{"816":1}}],["它将使用current",{"2":{"796":2}}],["它将每个词映射到一个固定长度的向量",{"2":{"782":1}}],["它将中心词表示为其子词向量之和",{"2":{"758":1}}],["它将可变长度的文本序列进行转换转换为固定长度的文本类别",{"2":{"696":1}}],["它将可变长度的文本序列转换为固定长度的文本类别",{"2":{"691":1}}],["它将被送入到由全连接",{"2":{"657":1}}],["它将固定形状的编码状态映射到长度可变的序列",{"2":{"532":1}}],["它将返回这四个元素的乘积",{"2":{"1090":1}}],["它将返回z",{"2":{"449":2}}],["它将返回学习率的适当值",{"2":{"68":1}}],["它将列表中的每个块连接在一起",{"2":{"422":3}}],["它将列表中的每个block连接在一起",{"2":{"422":1}}],["它将训练数据集作为输入",{"2":{"289":1}}],["它将范围",{"2":{"236":1}}],["它将巡逻人员分配到预测犯罪率较高的地区",{"2":{"201":1}}],["它将收敛",{"2":{"106":1}}],["它将内存带宽需求减半",{"2":{"77":1}}],["它将完全消除眼下的问题",{"2":{"26":1}}],["它回避了计算整个hessian",{"2":{"61":1}}],["它是完全无参数限制的",{"2":{"1158":1}}],["它是它这往往容易失去你需要的特征",{"2":{"1156":1}}],["它是如何得出大间距分类器的",{"2":{"1144":1}}],["它是如何产生这个大间距分类器的呢",{"2":{"1144":1}}],["它是最有效的技术方法",{"2":{"1098":1}}],["它是最早发布的卷积神经网络之一",{"2":{"135":1}}],["它是个方阵",{"2":{"1076":1}}],["它是学习策略",{"2":{"1061":1}}],["它是以下技术趋势的核心引擎",{"2":{"1051":1}}],["它是b=b的概率",{"2":{"1031":1}}],["它是相交面积与相并面积的比率",{"2":{"855":1}}],["它是否提高了分类精度",{"2":{"717":1}}],["它是否提高了分类的精度",{"2":{"706":1}}],["它是分类问题最常用的损失之一",{"2":{"648":1}}],["它是所有标签分布的预期损失值",{"2":{"648":1}}],["它是由固定数量的训练样本组成的",{"2":{"613":1}}],["它是由x和最小化器之间的距离乘以q所得出的",{"2":{"94":1}}],["它是两个数量的比值",{"2":{"578":1}}],["它是解码器的输入序列的第一个词元",{"2":{"572":1}}],["它是第一个在大规模视觉竞赛中击败传统计算机视觉模型的大型神经网络",{"2":{"492":1}}],["它是",{"2":{"342":1,"1451":2}}],["它是指每个时间步的隐状态",{"2":{"325":1}}],["它是被用作实现人工智能解决方案的一种手段",{"2":{"303":1}}],["它是无监督学习的另一个重要而令人兴奋的领域",{"2":{"296":1}}],["它是一种带有偏置项的线性变换",{"2":{"229":1}}],["它是一个实数",{"2":{"1145":1}}],["它是一个2×1的向量",{"2":{"1111":1}}],["它是一个sequential类的实例",{"2":{"591":1}}],["它是一个长度为q的向量",{"2":{"162":1}}],["它是一个由d个偏导数组成的向量",{"2":{"57":1}}],["它是x中离x最近的点",{"2":{"50":1}}],["它是凸的当且仅当它的hessian∇2f⪰0",{"2":{"46":1}}],["它是凸性定义的一种推广",{"2":{"42":1}}],["它确保约束被正确地执行",{"2":{"48":1}}],["它趋近于0",{"2":{"44":1}}],["它可能会运行得比较快比神经网络快很多",{"2":{"1148":1}}],["它可能是性能度量值p",{"2":{"1059":1}}],["它可能有什么问题",{"2":{"638":1}}],["它可能导致数值不稳定",{"2":{"334":1}}],["它可能无法收敛",{"2":{"35":1}}],["它可以忽略掉一些异常点的影响",{"2":{"1144":1}}],["它可以改善或者减少过度拟合问题",{"2":{"1114":1}}],["它可以自动尝试不同的学习速率",{"2":{"1111":1}}],["它可以自动选择路径",{"2":{"1058":1}}],["它可以使人拥有方向感",{"2":{"1098":1}}],["它可以让你保存为一个文件",{"2":{"1091":1}}],["它可以在不需要多步梯度下降的情况下",{"2":{"1069":1}}],["它可以增加上采样中间层特征图的空间维度",{"2":{"967":1}}],["它可以是d2l",{"2":{"635":1}}],["它可以处理存储在文件中的数据和数据流提供的数据",{"2":{"600":1}}],["它可以用来量化学习大量样本",{"2":{"284":1}}],["它可以推动计算机视觉",{"2":{"281":1}}],["它可以将数据集名称的字符串映射到数据集相关的二元组上",{"2":{"206":1}}],["它可以包含多个卷积层",{"2":{"159":1}}],["它可以提供良好的计算效率同时仍适合gpu的内存",{"2":{"78":1}}],["它可以应用于部分观察到的随机变量的对数似然",{"2":{"42":1}}],["它们共同组成一个分布式系统",{"2":{"1381":1}}],["它们有很多参数",{"2":{"1141":1}}],["它们能够有效地解决许多问题",{"2":{"1114":1}}],["它们需要有一种方法来计算",{"2":{"1111":1}}],["它们需要大量的芯片面积",{"2":{"457":1}}],["它们会计算出两样东西",{"2":{"1111":1}}],["它们负责将数据进行处理",{"2":{"1099":1}}],["它们正是通过脑组织中的这个部分完成的",{"2":{"1098":1}}],["它们所有的行和列和对角线加起来都等于相同的值",{"2":{"1090":1}}],["它们具有以下这样的数学性质",{"2":{"1090":1}}],["它们具有相同的维度",{"2":{"331":1}}],["它们对应的假设是什么样的",{"2":{"1066":2}}],["它们属于分类问题",{"2":{"1060":1}}],["它们提供了一种存储模型参数的方法",{"2":{"1021":1}}],["它们提供了哪些损失函数和初始化方法",{"2":{"597":1}}],["它们默认创建为整数",{"2":{"1017":2}}],["它们默认创建为浮点数",{"2":{"1017":1}}],["它们通常是内部函数",{"2":{"1006":1}}],["它们通过循环计算彼此依赖",{"2":{"307":1}}],["它们和的转置",{"2":{"1004":1}}],["它们转置的和",{"2":{"1004":1}}],["它们表示未知的标量值",{"2":{"989":1}}],["它们表征了同一感受野内的输入图像信息",{"2":{"913":1}}],["它们适合检测较少但较大的物体",{"2":{"953":1}}],["它们不仅被用于预测每个兴趣区域的类别和边界框",{"2":{"940":1}}],["它们不仅值相等",{"2":{"437":2}}],["它们两个定义都拥有许多相似的性质",{"2":{"844":1}}],["它们还需要与其他高带宽外围设备",{"2":{"812":1}}],["它们针对4×4和16×16矩阵之间的小型运算进行了优化",{"2":{"811":1}}],["它们可能是独占的也可能是共享的",{"2":{"810":1}}],["它们可以为我们找到其他类型的结构或者其他的一些模式",{"2":{"1150":1}}],["它们可以为负值",{"2":{"643":1}}],["它们可以看图像",{"2":{"1098":1}}],["它们可以转换为张量格式",{"2":{"1013":1}}],["它们可以用于检测不同大小的目标",{"2":{"913":1}}],["它们可以用各种滤波器尺寸探索图像",{"2":{"487":1}}],["它们可以由我们调整的",{"2":{"527":1}}],["它们由许多关键组件组成",{"2":{"807":1}}],["它们由三个具有sigmoid激活函数的全连接层处理",{"2":{"553":1}}],["它们如果转速再快些",{"2":{"804":1}}],["它们包含许多旋转的盘片",{"2":{"804":1}}],["它们使用截然不同的接口",{"2":{"802":1}}],["它们内存带宽的峰值在40gb",{"2":{"802":1}}],["它们将标准标量运算符应用于数组的每个元素",{"2":{"1018":1}}],["它们将相同的预训练向量赋给同一个词",{"2":{"739":1}}],["它们将输入信号转换为输出的可微运算",{"2":{"234":1}}],["它们分别有8亿个单词和25亿个单词",{"2":{"737":1}}],["它们分别分析单个文本和文本对之间的关系",{"2":{"663":1}}],["它们都与命令式编程中使用block类或sequential类的方式相同",{"2":{"818":1}}],["它们都是在2018年提出的",{"2":{"733":1}}],["它们都必须在同一个设备上",{"2":{"447":1}}],["它们产生4个宽度为11−2+1=10的输出通道和5个宽度为11−4+1=8的输出通道",{"2":{"701":1}}],["它们与隐状态具有相同的形状",{"2":{"552":1}}],["它们仍然非常灵活",{"2":{"475":1}}],["它们非常适合执行各种指令",{"2":{"457":1}}],["它们在边界框和目标方面有什么不同",{"2":{"935":1}}],["它们在非常大的语料库中甚至可能出现数十亿次",{"2":{"773":1}}],["它们在回归中很常见",{"2":{"658":1}}],["它们在深度学习的注意力模型设计中被广泛使用",{"2":{"379":1}}],["它们在不同的随机数据样本上可以得出相似的结果",{"2":{"169":1}}],["它们很难处理好自然语言中的一词多义或复杂语义",{"2":{"739":1}}],["它们很难具有相同的分辨率或形状",{"2":{"284":1}}],["它们很少出现或者从不出现",{"2":{"322":1}}],["它们本身仍然是有意义的",{"2":{"318":1}}],["它们已经被tensorflow",{"2":{"300":1}}],["它们允许我们组织具有不同模式的数据",{"2":{"992":1}}],["它们允许我们对随后的梯度计算平均值",{"2":{"86":1}}],["它们允许统计建模者描述用于推理的迭代方法",{"2":{"300":1}}],["它们遵循独立同分布",{"2":{"284":1}}],["它们似乎是相似的任务",{"2":{"282":1}}],["它们运行得更快",{"2":{"278":1}}],["它们是训练样本到决策边界的距离",{"2":{"1145":1}}],["它们是",{"2":{"1100":1}}],["它们是python中的特殊对象",{"2":{"1006":1}}],["它们是这张图像里的两个主要目标",{"2":{"857":1}}],["它们是怎样重叠的",{"2":{"856":1}}],["它们是最近增加更多优化电路趋势的一个例子",{"2":{"811":1}}],["它们是如何相互关联的",{"2":{"505":1}}],["它们是非负的",{"2":{"388":1}}],["它们是更为一般的lp范数的特殊情况",{"2":{"270":1}}],["它们是由优化算法根据最近迭代的反向传播给出的",{"2":{"165":1}}],["它们互相抵消了吗",{"2":{"178":1}}],["它们只能表示一小类函数",{"2":{"169":1}}],["它们略有不同",{"2":{"130":1}}],["它们差别不大",{"2":{"130":1}}],["它们的value属性是响应式的",{"2":{"1455":1}}],["它们的出现",{"2":{"1352":1}}],["它们的点积",{"2":{"997":1}}],["它们的索引机制",{"2":{"993":1}}],["它们的值具有一定的现实意义",{"2":{"990":1}}],["它们的尺寸并不一样",{"2":{"918":1}}],["它们的准确性还有不同吗",{"2":{"876":1}}],["它们的杰卡德系数通常称为交并比",{"2":{"849":1}}],["它们的带宽可以达到1",{"2":{"805":1}}],["它们的性能与特征大体上是相似的",{"2":{"802":1}}],["它们的训练依赖于条件概率",{"2":{"782":1}}],["它们的余弦相似度是它们之间角度的余弦",{"2":{"781":1}}],["它们的利弊是什么",{"2":{"690":1}}],["它们的计算方法如下",{"2":{"553":1}}],["它们的计算成本仍然很高",{"2":{"137":1}}],["它们的形状不匹配",{"2":{"1019":1}}],["它们的形状与x相同",{"2":{"467":1}}],["它们的形状分别为",{"2":{"340":1}}],["它们的输出也是相同的",{"2":{"405":1}}],["它们的批量矩阵乘法输出的形状为",{"2":{"390":1}}],["它们的批量矩阵乘法得到n个矩阵",{"2":{"390":1}}],["它们的延迟也在增加",{"2":{"77":1}}],["它们的交集∩ixi是凸的",{"2":{"40":1}}],["它们也被称为",{"2":{"1129":1}}],["它们也将使收割作业自动化",{"2":{"301":1}}],["它们也需要包含在x∩y中",{"2":{"40":1}}],["它们也经常在局部极小值附近表现出一些凸性",{"2":{"38":1}}],["它们相当独特的定义使我们移除偏项",{"2":{"33":1}}],["它的畸变值会迅速下降",{"2":{"1154":1}}],["它的长度是p",{"2":{"1145":1}}],["它的范数是小的",{"2":{"1145":1}}],["它的两个分量v1和v2是已知的",{"2":{"1145":1}}],["它的输出值永远在0到",{"2":{"1106":1}}],["它的输出形状是",{"2":{"325":3}}],["它的原理是",{"2":{"1098":2}}],["它的张量类",{"2":{"1016":1}}],["它的值被初始化为0",{"2":{"974":1}}],["它的正向传播和反向传播函数将输入向量分别与w⊤和w相乘",{"2":{"970":1}}],["它的主要计算如下",{"2":{"938":1}}],["它的高度和宽度分别为561和728像素",{"2":{"912":1}}],["它的定义方式与预训练源模型的定义方式相同",{"2":{"873":1}}],["它的所有子词向量都必须求和",{"2":{"756":1}}],["它的中心词偏置和上下文偏置在数学上是等价的吗",{"2":{"746":1}}],["它的参数examples包含来自两个预训练任务的辅助函数",{"2":{"722":1}}],["它的要求判断给定的句子在语法上是否可以接受",{"2":{"657":1}}],["它的分量和类别一样多",{"2":{"640":1}}],["它的计算与上面描述的三个门的计算类似",{"2":{"554":1}}],["它的计算成本很高",{"2":{"492":1}}],["它的任何子类都必须定义一个将其输入转换为输出的前向传播函数",{"2":{"422":1}}],["它的k步预测是x^604+k",{"2":{"351":1}}],["它的形状是",{"2":{"325":1}}],["它的工作原理没有什么新概念",{"2":{"306":1}}],["它的挑战在于",{"2":{"295":1}}],["它的目标是向特定用户进行",{"2":{"294":1}}],["它的特征由每个像素数值的有序列表表示",{"2":{"284":1}}],["它的顺序是从输入层到输出层",{"2":{"166":1}}],["它的鞍点为",{"2":{"102":1}}],["它的一阶和二阶导数在x=0时消失",{"2":{"102":1}}],["它的梯度都会消失",{"2":{"242":1}}],["它的梯度下降非常缓慢",{"2":{"64":1}}],["它的梯度也是多元的",{"2":{"57":1}}],["它的设计灵感很清楚",{"2":{"33":1}}],["它的表现会不同吗",{"2":{"31":1}}],["它遮盖了adagrad固有的一些额外优势",{"2":{"25":1}}],["它促成了计算广告学及其相关问题中非常有效的优化程序",{"2":{"25":1}}],["它允许用户创建",{"2":{"10":1}}],["l表示神经网络层数",{"2":{"1120":1}}],["lbfgs",{"2":{"1109":1}}],["llm",{"2":{"1040":2,"1041":4,"1049":1,"1051":1,"1052":1,"1054":1}}],["l中任意一对预测边界框的iou都小于阈值ϵ",{"2":{"854":1}}],["l中的所有元素被加到一起",{"2":{"605":2}}],["l保留了置信度最高的预测边界框",{"2":{"854":1}}],["lw=0",{"2":{"848":1}}],["lh",{"2":{"821":4}}],["l3",{"2":{"813":4}}],["l3cache",{"2":{"457":1}}],["luo",{"2":{"467":1}}],["ln",{"2":{"406":16}}],["lm的指数",{"2":{"342":1}}],["lm",{"2":{"342":1}}],["lv",{"2":{"301":1}}],["l1范数受异常值的影响较小",{"2":{"1000":1}}],["l1范数",{"2":{"1000":1}}],["l1loss",{"2":{"962":3}}],["l1",{"2":{"813":1,"966":5}}],["l1正则化",{"2":{"280":1}}],["l1正则化线性回归是统计学中类似的基本模型",{"2":{"270":1}}],["l1惩罚会导致模型将权重集中在一小部分特征上",{"2":{"270":1}}],["l1和l2缓存",{"2":{"77":1}}],["l+1",{"2":{"241":3,"1121":1}}],["l−1",{"2":{"241":2,"527":1}}],["ls命令将列出我桌面上的所有路径",{"2":{"1089":1}}],["lstmcell",{"2":{"561":1}}],["lstm中讨论",{"2":{"538":1}}],["lstm中的决策非常相似",{"2":{"528":1}}],["lstm中使用的代码非常相似",{"2":{"528":1}}],["lstm或对于我们从零开始实现的模型是个张量",{"2":{"335":2}}],["lstm以元组作为隐状态",{"2":{"325":2}}],["lstm",{"0":{"551":1},"1":{"552":1,"553":1,"554":1,"555":1,"556":1,"557":1,"558":1,"559":1,"560":1,"561":1,"562":1,"563":1},"2":{"325":2,"523":9,"528":9,"538":1,"550":2,"551":2,"553":1,"554":1,"555":1,"556":1,"558":4,"559":8,"560":9,"561":12,"713":5}}],["ls",{"2":{"210":24,"211":8,"213":3,"726":17,"821":4,"828":2,"837":4,"883":3,"905":2,"906":3,"1089":2,"1345":2}}],["l2范数和frobenius范数",{"2":{"1003":1}}],["l2范数和l1范数都是更一般的lp范数的特例",{"2":{"1000":1}}],["l2范数是向量元素平方和的平方根",{"2":{"1000":1}}],["l2",{"2":{"210":1,"274":4,"275":4,"278":1,"813":1}}],["l2正则化回归的小批量随机梯度下降更新如下式",{"2":{"270":1}}],["l2正则化线性模型构成经典的岭回归",{"2":{"270":1}}],["l2正则化",{"2":{"161":1,"170":1}}],["l2loss",{"2":{"81":1,"210":1,"263":1,"278":1,"350":1,"392":1,"593":2}}],["l=4",{"2":{"1121":1}}],["l=1",{"2":{"527":1}}],["l=1t∑t=1tl",{"2":{"312":1}}],["l=l",{"2":{"162":1}}],["l=j+b",{"2":{"153":1}}],["l=",{"2":{"153":1}}],["l和t",{"2":{"115":1}}],["l和",{"2":{"115":1}}],["lovetalk",{"2":{"1494":1}}],["love",{"2":{"1191":2}}],["loves",{"2":{"783":8,"785":4}}],["low",{"2":{"1191":1}}],["lowerrights",{"2":{"849":9}}],["lower",{"2":{"361":1,"565":1,"577":4,"687":3,"718":1}}],["lowe",{"2":{"302":1,"454":1,"455":1}}],["lots",{"2":{"1173":1}}],["location",{"2":{"1364":2,"1365":1,"1367":1,"1369":1,"1370":1,"1371":1}}],["localstorage",{"2":{"1494":1,"1495":1}}],["locality",{"2":{"152":1}}],["local",{"2":{"101":2,"813":2,"1067":1,"1319":1}}],["lock",{"2":{"813":1,"1281":1}}],["lopyrev",{"2":{"660":1}}],["long",{"2":{"325":1,"335":1,"375":1,"407":1,"538":1,"550":1,"551":1,"573":1,"575":1,"577":2,"687":2,"722":5,"763":2,"851":3,"852":2,"854":1,"861":1,"866":1,"868":1,"945":1,"964":1,"1168":1}}],["lookup",{"2":{"987":1}}],["looked",{"2":{"295":1}}],["loop",{"2":{"282":1,"304":1}}],["loop所示",{"2":{"282":1}}],["loglength",{"2":{"1433":5}}],["log1p就是",{"2":{"1183":1}}],["log1p",{"2":{"1183":1}}],["logp",{"2":{"786":1}}],["logpij",{"2":{"743":1}}],["log2|v|",{"2":{"709":1}}],["log包含与整个词表大小一样多的项的求和",{"2":{"707":1}}],["log给出",{"2":{"707":1}}],["log⁡σ",{"2":{"1147":1}}],["log⁡hθ",{"2":{"1130":1}}],["log⁡hbha−μhσh",{"2":{"852":1}}],["log⁡wbwa−μwσw",{"2":{"852":1}}],["log⁡p",{"2":{"650":1,"784":1}}],["log⁡",{"2":{"624":1,"1109":14,"1110":4,"1117":2,"1120":2,"1147":1}}],["log⁡ni=−αlog⁡i+c",{"2":{"318":1}}],["log⁡yi−log⁡y^i",{"2":{"210":1}}],["login",{"2":{"1329":3}}],["logical",{"2":{"1102":1}}],["logit=inputs",{"2":{"765":1}}],["logit",{"2":{"641":1}}],["logits",{"2":{"495":1,"765":2}}],["logits=true",{"2":{"67":1,"137":1,"175":1,"220":1,"225":1,"335":1,"575":1,"624":1}}],["logistic",{"0":{"1105":1},"1":{"1106":1,"1107":1,"1108":1,"1109":1,"1110":1,"1111":1,"1112":1},"2":{"191":1,"1100":2,"1106":1,"1107":1,"1112":1,"1117":1,"1193":1}}],["logsumexp技巧",{"2":{"624":1}}],["logs",{"2":{"137":3,"1344":1,"1392":1}}],["logs=none",{"2":{"137":1}}],["log",{"2":{"80":1,"210":20,"211":1,"213":2,"263":4,"275":4,"278":4,"318":4,"633":3,"765":1,"784":1,"852":1,"966":3,"1048":7,"1109":2,"1117":2,"1120":2,"1183":1,"1328":2,"1402":1,"1413":2,"1416":3,"1417":3,"1422":3,"1433":1,"1451":2,"1454":2,"1455":2,"1457":1,"1460":1,"1462":1,"1463":1,"1464":2,"1465":2,"1466":1,"1467":4,"1468":8,"1469":1,"1470":7,"1471":1,"1481":1,"1482":1,"1485":4,"1494":1,"1499":3,"1518":4}}],["lost",{"2":{"376":2,"409":2,"578":2}}],["loshchilov",{"2":{"72":1}}],["loss中描述的平方损失",{"2":{"962":1}}],["loss的glove损失函数",{"2":{"744":1}}],["loss函数中需要使用reshape函数",{"2":{"607":1}}],["loss模块定义了许多常见的损失函数",{"2":{"596":1}}],["loss模块定义了各种损失函数",{"2":{"593":1}}],["loss导入它们",{"2":{"275":1}}],["loss=",{"2":{"68":1}}],["loss=loss",{"2":{"67":1,"137":1,"210":1}}],["losses",{"2":{"67":1,"81":1,"137":1,"175":1,"210":1,"220":1,"225":1,"263":1,"278":2,"335":1,"350":1,"392":1,"575":2,"593":1,"624":1,"635":2}}],["loss",{"2":{"67":32,"68":3,"71":3,"72":3,"73":3,"80":29,"81":25,"129":4,"137":17,"175":9,"176":4,"210":11,"220":3,"221":4,"225":6,"263":38,"275":32,"278":29,"286":1,"335":17,"350":29,"392":21,"575":21,"576":14,"593":4,"595":12,"603":1,"605":14,"611":1,"616":1,"624":3,"626":1,"635":19,"645":1,"646":1,"648":1,"681":7,"688":7,"704":7,"715":7,"726":36,"736":7,"737":3,"743":1,"765":5,"767":9,"828":7,"834":4,"837":3,"865":7,"874":7,"883":31,"893":4,"894":9,"905":9,"906":27,"922":3,"923":3,"924":1,"925":4,"927":6,"962":17,"963":3,"966":6,"980":1}}],["loadbalancer",{"2":{"1384":1}}],["load函数可以切分一个小批量数据",{"2":{"827":1}}],["loading中对掩码变量和标签变量的描述",{"2":{"765":1}}],["loading中定义",{"2":{"763":1}}],["loading中进行了解释",{"2":{"534":1}}],["loading",{"2":{"568":1,"776":1}}],["load",{"2":{"67":4,"79":4,"137":1,"175":4,"210":4,"216":1,"225":1,"263":8,"271":2,"321":3,"324":4,"329":2,"350":1,"364":2,"376":1,"409":4,"441":12,"442":5,"462":2,"473":2,"483":1,"489":1,"496":1,"503":1,"509":1,"523":3,"528":3,"543":4,"557":4,"569":3,"576":1,"582":1,"584":6,"590":5,"622":1,"629":1,"669":4,"679":3,"681":2,"686":12,"694":3,"695":9,"698":3,"712":3,"717":1,"722":4,"725":3,"726":1,"748":2,"760":4,"777":4,"827":1,"828":3,"836":5,"837":4,"864":3,"882":3,"883":6,"932":5,"945":2,"949":3,"961":1,"964":1}}],["landmarks",{"2":{"1146":1}}],["land",{"2":{"1127":1}}],["lang=",{"2":{"1444":1,"1445":1,"1451":1,"1454":3,"1455":1,"1456":1,"1457":1,"1459":1,"1460":1,"1462":1,"1463":1,"1464":1,"1465":1,"1466":1,"1467":1,"1468":3,"1469":2,"1470":1,"1471":2,"1474":1,"1490":2,"1492":1,"1497":2,"1500":2,"1501":3,"1503":2,"1508":1}}],["langgraph",{"2":{"1051":1,"1052":1,"1055":1}}],["langchain",{"2":{"1051":1,"1052":1,"1055":2,"1056":1}}],["language",{"0":{"736":1},"2":{"305":1,"315":2,"329":1,"338":1,"341":2,"564":1,"565":2,"566":1,"568":1,"572":1,"663":3,"664":1,"665":1,"666":1,"672":2,"679":2,"685":3,"731":2,"736":1,"754":1,"816":1,"1088":1}}],["launch",{"2":{"813":1}}],["lab",{"2":{"813":2}}],["label2image",{"2":{"866":6}}],["labeling",{"2":{"850":1,"856":1}}],["label=",{"2":{"966":6,"1026":4}}],["label=target",{"2":{"765":1}}],["label=f",{"2":{"89":1,"95":1,"107":1}}],["label的形状",{"2":{"575":4}}],["labels参数",{"2":{"852":1}}],["labels=none",{"2":{"848":1}}],["labels中的每一行都包含一维标签值",{"2":{"599":1}}],["labels的维度",{"2":{"262":1}}],["labels",{"2":{"209":1,"210":30,"212":1,"213":3,"262":5,"263":20,"264":2,"265":2,"266":2,"350":3,"582":9,"589":1,"590":1,"595":4,"599":3,"600":5,"605":8,"636":2,"667":2,"668":6,"687":6,"692":3,"721":11,"722":30,"776":4,"827":3,"828":2,"848":5,"852":35,"853":5,"866":6,"883":15,"890":12,"894":9,"901":2,"902":4,"905":11,"906":11,"932":6,"945":16,"946":3,"947":12,"962":27,"963":26,"1389":1,"1390":1}}],["label",{"2":{"182":1,"284":1,"292":1,"350":1,"491":1,"575":14,"578":12,"609":1,"667":5,"682":9,"692":3,"715":6,"722":12,"765":4,"767":9,"851":4,"852":12,"854":2,"890":18,"896":9,"908":3,"932":3,"933":6,"945":5,"946":12,"947":11,"1029":1}}],["large",{"2":{"691":1,"1026":1,"1144":1,"1145":1,"1163":1,"1164":1,"1193":1,"1407":1}}],["laptop",{"2":{"1432":1}}],["lapata",{"2":{"395":1,"403":1}}],["laplace",{"2":{"316":1}}],["law中的指数α更小",{"2":{"318":1}}],["law",{"2":{"318":2,"1026":1}}],["laine",{"2":{"300":1}}],["lasso",{"2":{"270":1}}],["lastname",{"2":{"1460":5}}],["last=false",{"2":{"892":2,"904":2}}],["last=true",{"2":{"864":2,"892":4,"904":4,"948":2,"949":4}}],["last",{"2":{"71":2,"147":1,"148":1,"892":3,"904":3,"948":1,"949":2,"1191":1}}],["latest",{"2":{"1315":4,"1389":1,"1444":1}}],["latency",{"2":{"803":1,"813":5}}],["latencynumbers进行简单的了解",{"2":{"800":1}}],["latencynumbers",{"2":{"800":1}}],["latent",{"2":{"347":1}}],["late",{"2":{"213":1}}],["layerlist",{"2":{"702":1}}],["layer子类的一个实例",{"2":{"424":1}}],["layernormalization",{"2":{"406":2}}],["layernorm",{"2":{"406":6,"736":3}}],["layer只包含隐藏的循环层",{"2":{"325":1}}],["layer返回的更新后的隐状态",{"2":{"325":1}}],["layer的",{"2":{"325":1}}],["layer函数",{"2":{"172":1}}],["layer覆盖的局部区域δ=0",{"2":{"160":1}}],["layer和",{"2":{"156":1}}],["layer是一个卷积层",{"2":{"155":1}}],["layer中对感受野的定义",{"2":{"913":1}}],["layer中",{"2":{"912":1,"968":1}}],["layer中的原始定义更正确地描述了互相关",{"2":{"156":1}}],["layer中的corr2d函数",{"2":{"146":1}}],["layer中所讨论的边缘",{"2":{"145":1}}],["layer中所概括的那样",{"2":{"140":1}}],["layer",{"2":{"125":1,"127":2,"134":1,"136":12,"137":1,"155":2,"156":1,"158":2,"172":17,"174":13,"225":3,"232":1,"325":21,"326":4,"334":1,"335":2,"340":1,"369":2,"370":2,"382":2,"391":2,"398":2,"404":1,"405":2,"406":5,"407":2,"408":2,"413":8,"414":1,"421":1,"423":1,"424":7,"425":2,"442":1,"461":10,"472":2,"479":1,"480":13,"481":1,"487":1,"488":12,"495":13,"501":1,"502":15,"523":6,"528":6,"533":2,"534":2,"535":1,"547":8,"561":8,"573":1,"591":1,"618":2,"634":1,"635":1,"674":1,"675":1,"676":1,"677":1,"688":1,"702":1,"713":7,"734":1,"736":1,"737":1,"738":1,"765":1,"862":2,"926":1,"959":1,"967":1,"1099":2,"1122":1}}],["layers=num",{"2":{"713":3}}],["layers=2的值分别增加到768",{"2":{"690":1}}],["layers=2",{"2":{"375":8,"573":4,"574":4,"686":4,"726":2}}],["layers的值来设定隐藏层数",{"2":{"528":1}}],["layers的主要优点是",{"2":{"424":1}}],["layers字典中查找需要初始化参数的子块",{"2":{"424":1}}],["layers属性",{"2":{"424":1}}],["layers中",{"2":{"424":1}}],["layers个元素的列表",{"2":{"574":1}}],["layers个decoderblock实例组成的完整的",{"2":{"408":1}}],["layers个encoderblock类的实例",{"2":{"407":1}}],["layers所说",{"2":{"231":1}}],["layers",{"2":{"67":8,"68":1,"81":1,"127":1,"129":1,"136":9,"141":2,"142":2,"147":3,"148":1,"174":4,"176":6,"210":1,"225":3,"263":1,"278":1,"299":1,"325":10,"350":2,"369":5,"370":2,"375":21,"376":3,"382":5,"391":1,"398":2,"405":4,"406":5,"407":10,"408":23,"409":17,"413":1,"418":4,"422":3,"423":2,"424":10,"425":6,"429":3,"430":1,"431":3,"432":1,"433":6,"435":11,"436":8,"437":4,"442":3,"451":3,"461":15,"472":1,"473":14,"474":16,"480":8,"481":5,"482":9,"487":8,"488":11,"494":3,"495":8,"501":5,"502":17,"507":12,"508":7,"523":6,"528":6,"533":1,"534":1,"547":2,"561":2,"573":15,"574":16,"576":3,"591":1,"592":1,"623":2,"642":1,"686":4,"713":8,"734":10,"738":6,"819":1,"920":22,"927":6,"1099":1}}],["lambd=3",{"2":{"277":1}}],["lambd=0",{"2":{"276":1}}],["lambd",{"2":{"275":8}}],["lambdas",{"2":{"95":2}}],["lambda",{"0":{"1239":1},"2":{"41":6,"44":1,"80":4,"95":1,"175":1,"209":1,"221":1,"275":4,"333":4,"335":8,"509":1,"584":2,"635":1,"837":3,"849":3,"896":3,"1115":1,"1120":1,"1121":1,"1239":1,"1240":3}}],["lam",{"2":{"95":3}}],["lagrange",{"2":{"48":1}}],["l",{"2":{"48":1,"67":9,"80":8,"81":8,"115":2,"129":12,"137":18,"153":2,"190":1,"196":1,"210":8,"211":6,"212":4,"241":14,"263":9,"270":2,"275":8,"278":8,"307":3,"312":8,"335":14,"350":8,"392":12,"527":11,"566":4,"568":6,"576":12,"595":16,"605":16,"611":3,"613":1,"635":19,"646":3,"647":2,"648":1,"709":1,"726":52,"736":6,"737":6,"742":3,"757":3,"767":12,"773":4,"828":6,"837":6,"883":16,"890":2,"894":6,"905":15,"906":10,"925":11,"927":24,"963":6,"966":12,"1111":2,"1120":1,"1121":12,"1122":12,"1124":2,"1146":9,"1147":3,"1154":2}}],["lt",{"2":{"44":6,"46":2,"48":1,"95":5,"105":2,"115":1,"312":2,"363":4,"512":3,"513":6,"515":2,"567":4,"568":3,"572":4,"576":2,"577":2,"657":3,"668":1,"688":1,"722":1,"727":3,"734":5,"735":2,"736":4,"737":2,"743":1,"756":3,"772":2,"966":1,"1021":1,"1024":1,"1025":2,"1090":2,"1107":1,"1108":4,"1144":4,"1145":2,"1153":1,"1178":2,"1180":1,"1444":1,"1454":1,"1479":1}}],["let",{"2":{"1398":6,"1399":3,"1401":5,"1404":11,"1407":1,"1408":1,"1426":1,"1430":3,"1451":3,"1454":3,"1455":4,"1456":4,"1457":3,"1459":3,"1460":4,"1462":1,"1463":1,"1464":2,"1465":1,"1466":1,"1467":2,"1468":6,"1469":2,"1470":1,"1471":5,"1493":1,"1495":2,"1501":4,"1503":4,"1508":1,"1518":4,"1519":2,"1520":2}}],["leetcode",{"2":{"1306":1}}],["leetcode刷题",{"2":{"1306":1}}],["lee",{"2":{"726":1,"733":1,"929":1}}],["le",{"2":{"572":2,"832":1}}],["levels=1",{"2":{"1371":1}}],["level",{"2":{"341":1}}],["left|x",{"2":{"1000":1}}],["leftchild",{"2":{"709":1}}],["left",{"2":{"334":1,"727":3,"1068":1,"1110":1,"1112":2,"1120":5,"1160":1,"1165":4,"1413":1}}],["leftarrow",{"2":{"334":1}}],["lehrwerk",{"2":{"295":1}}],["lecun和他的同事leon",{"2":{"135":1}}],["lecun发表了第一篇通过反向传播成功训练卷积神经网络的研究",{"2":{"135":1}}],["lecun",{"2":{"135":1,"300":1,"455":1,"581":1,"832":1}}],["lecun在1989年提出的",{"2":{"135":1}}],["legend",{"2":{"89":1,"95":1,"566":3,"635":3,"894":6,"906":6,"966":6,"981":7,"1026":4,"1091":1}}],["legend=legend",{"2":{"894":3,"906":3}}],["legend=none",{"2":{"635":1,"981":1}}],["legend=",{"2":{"67":3,"80":1,"137":4,"211":1,"242":4,"263":4,"275":4,"278":4,"318":1,"335":4,"351":3,"386":1,"398":4,"616":2,"635":1,"726":3,"883":3,"927":3,"963":3,"981":1}}],["leave",{"2":{"1525":2}}],["least",{"2":{"1362":1}}],["learn",{"2":{"1297":1}}],["learning的编码示例",{"2":{"665":1}}],["learning∣deep",{"2":{"316":2}}],["learningratescheduler",{"2":{"67":1}}],["learningrate中所看到的",{"2":{"58":1}}],["learningrate",{"2":{"55":1,"1117":2}}],["learning",{"0":{"1119":1,"1136":1},"1":{"1120":1,"1121":1,"1122":1,"1123":1,"1124":1,"1125":1,"1126":1,"1127":1,"1137":1,"1138":1,"1139":1,"1140":1,"1141":1},"2":{"21":1,"29":3,"34":3,"55":1,"66":1,"67":3,"68":8,"71":2,"72":1,"73":1,"81":3,"92":3,"109":3,"137":3,"175":2,"176":3,"195":1,"196":1,"199":1,"210":9,"211":2,"221":1,"225":3,"263":3,"278":3,"281":2,"282":2,"285":1,"289":3,"296":1,"297":1,"298":2,"302":1,"316":5,"335":2,"350":2,"392":3,"576":3,"594":3,"613":1,"625":3,"681":2,"688":2,"704":2,"715":2,"726":2,"754":1,"767":2,"828":2,"865":2,"869":1,"874":10,"883":2,"894":4,"906":4,"926":2,"927":3,"961":2,"1059":1,"1060":1,"1061":1,"1067":1,"1068":1,"1083":1,"1128":1,"1134":1,"1141":1,"1150":1,"1163":1,"1164":1,"1168":1,"1182":1,"1193":4}}],["leaky",{"2":{"86":1}}],["lengthwise>",{"2":{"1433":1}}],["lengthwise",{"2":{"1433":1}}],["length",{"2":{"997":1,"1089":3,"1090":2,"1371":1,"1399":2,"1433":6}}],["len在",{"2":{"763":1}}],["len指定预训练期间的bert输入序列的最大长度",{"2":{"720":1}}],["len=512",{"2":{"686":2,"687":3}}],["len=max",{"2":{"686":2,"738":2}}],["len=1000",{"2":{"398":4,"734":3,"738":3}}],["lenpred表示预测序列中的词元数",{"2":{"578":1}}],["len的形状",{"2":{"575":4}}],["lens不包括",{"2":{"722":3}}],["lens的开头",{"2":{"408":4}}],["lens的形状",{"2":{"370":4}}],["lens=none",{"2":{"370":3,"738":3}}],["lens",{"2":{"368":36,"369":16,"370":9,"375":20,"382":28,"396":4,"407":26,"408":35,"687":12,"688":6,"722":17,"726":16,"734":6,"738":3}}],["lenet的evaluate",{"2":{"827":1}}],["lenet的稠密块有三个全连接层",{"2":{"136":1}}],["lenet一样",{"2":{"508":1}}],["lenet中介绍的",{"2":{"834":1}}],["lenet中的lenet相比",{"2":{"463":1}}],["lenet中应用于fashion",{"2":{"31":1}}],["lenet第一层和第二层的激活值",{"2":{"139":1}}],["lenet是最早发布的卷积神经网络之一",{"2":{"138":1}}],["lenet在fashion",{"2":{"137":1}}],["lenet所示",{"2":{"136":1}}],["lenet被广泛用于自动取款机",{"2":{"135":1}}],["lenet取得了与支持向量机",{"2":{"135":1}}],["lenet",{"0":{"135":1,"136":1,"473":1},"1":{"136":1,"137":1,"138":1,"139":1},"2":{"134":1,"135":1,"136":5,"473":2,"493":1,"834":4,"837":6}}],["len",{"2":{"67":3,"80":3,"81":3,"137":3,"320":1,"321":3,"325":9,"326":1,"330":5,"332":8,"335":3,"361":1,"363":4,"364":2,"368":1,"375":8,"376":5,"386":4,"392":1,"398":8,"407":5,"408":4,"409":9,"418":1,"424":1,"437":1,"446":3,"472":7,"482":4,"523":6,"528":6,"546":6,"547":3,"560":6,"561":3,"566":5,"567":1,"568":4,"569":8,"573":1,"574":2,"575":17,"576":22,"577":16,"578":9,"582":4,"583":1,"584":1,"599":1,"600":2,"615":1,"633":2,"634":6,"635":3,"668":9,"669":1,"677":3,"686":9,"687":77,"692":1,"693":1,"694":3,"702":3,"713":1,"718":1,"720":5,"721":2,"722":57,"725":6,"726":6,"727":9,"734":5,"738":3,"748":5,"757":5,"763":2,"767":3,"772":2,"773":1,"774":4,"775":5,"776":15,"777":10,"835":6,"836":1,"837":7,"848":8,"882":1,"883":3,"890":2,"894":3,"896":3,"906":3,"920":1,"932":9,"938":1,"947":9,"958":2,"959":2,"963":3,"975":1,"981":6,"991":3,"1004":2,"1081":1,"1109":1,"1117":2,"1232":1}}],["lru",{"0":{"1201":1},"2":{"1201":1}}],["lr=learning",{"2":{"874":2}}],["lr=lr",{"2":{"67":1,"137":1,"175":1,"176":1,"221":1,"225":1,"278":1,"576":1,"681":1,"688":1,"704":1,"715":1,"767":1,"865":1,"883":1,"894":1,"906":1,"926":1}}],["lr=trainer",{"2":{"71":1}}],["lr=2",{"2":{"70":1}}],["lr=1e",{"2":{"70":2}}],["lr=0",{"2":{"68":2,"70":1,"71":3,"72":8,"73":5,"263":1,"392":1,"594":1,"625":1,"635":1,"726":1,"828":4,"837":2,"883":3,"961":1}}],["lr",{"2":{"28":5,"29":1,"34":6,"35":8,"65":1,"67":14,"68":16,"70":8,"71":22,"72":19,"73":3,"80":7,"81":1,"91":7,"92":1,"108":5,"109":1,"113":5,"114":6,"129":8,"137":7,"175":5,"176":1,"210":1,"212":2,"213":3,"221":6,"225":5,"275":8,"278":5,"326":8,"335":17,"350":6,"376":2,"409":8,"463":2,"473":4,"474":1,"483":2,"489":2,"496":2,"503":2,"509":2,"523":6,"529":2,"546":6,"547":4,"560":6,"561":4,"576":7,"604":8,"605":5,"635":7,"681":3,"688":3,"704":3,"715":3,"767":6,"828":5,"837":12,"865":4,"873":1,"874":1,"883":1,"894":19,"895":18,"896":9,"898":3,"906":19,"907":18,"908":9,"910":1,"926":4,"927":11}}],["li>",{"2":{"1456":1,"1457":1,"1469":1,"1490":1,"1506":1,"1507":1,"1508":1}}],["light",{"2":{"1407":1}}],["limits",{"2":{"1112":1,"1120":2}}],["limit=",{"2":{"981":1}}],["limit=maxlen",{"2":{"575":1}}],["lim",{"2":{"981":3}}],["liberty",{"2":{"842":1}}],["library",{"2":{"292":1}}],["lipton",{"2":{"475":1}}],["lipschitz",{"2":{"334":1}}],["li",{"2":{"300":1,"832":1,"840":1,"842":1,"843":1,"1456":1,"1457":1,"1460":2,"1469":1,"1490":1,"1506":1,"1507":1,"1508":1}}],["liu",{"2":{"300":1,"478":1,"485":1,"486":1,"757":1,"952":1,"953":1,"966":1}}],["link>",{"2":{"1477":2,"1478":2,"1479":2,"1481":1}}],["link",{"2":{"813":2,"1477":2,"1478":2,"1479":2,"1481":1}}],["linguistic",{"2":{"657":1}}],["linux",{"2":{"292":1,"1089":1,"1273":1,"1302":1,"1315":1}}],["linalg",{"2":{"275":1,"278":1,"977":1,"998":2,"1000":2,"1085":1}}],["lin",{"2":{"270":1,"280":1,"301":1,"395":1,"403":1,"493":1,"631":2,"966":1,"995":1,"996":1,"1000":1}}],["lin3",{"2":{"174":4}}],["lin2",{"2":{"174":4}}],["lin1",{"2":{"174":4}}],["linspace",{"2":{"102":4}}],["linreg所示",{"2":{"611":1}}],["linreg和d2l",{"2":{"275":1}}],["linreg",{"2":{"80":4,"270":1,"275":4,"602":1,"605":1,"610":2,"611":1,"613":2}}],["linewidth=2",{"2":{"858":1}}],["linestyle=",{"2":{"1026":4}}],["lines",{"2":{"361":6,"362":5,"364":2,"568":6,"668":6,"718":2,"890":2,"966":9}}],["linear时指定输入和输出尺寸一样",{"2":{"592":2}}],["linear类本身就是layer的子类",{"2":{"422":1}}],["linear类本身就是module的子类",{"2":{"422":1}}],["linear以来",{"2":{"275":1}}],["linear中",{"2":{"228":1,"591":2}}],["linear",{"0":{"1062":1,"1071":1,"1079":1},"1":{"1063":1,"1064":1,"1065":1,"1066":1,"1067":1,"1068":1,"1069":1,"1070":1,"1072":1,"1073":1,"1074":1,"1075":1,"1076":1,"1077":1,"1080":1,"1081":1,"1082":1,"1083":1,"1084":1,"1085":1,"1086":1},"2":{"67":6,"80":1,"81":4,"100":1,"136":6,"137":2,"174":6,"176":7,"210":1,"225":6,"229":1,"235":1,"246":1,"263":2,"270":1,"278":2,"325":10,"347":1,"350":7,"369":6,"375":2,"380":1,"382":8,"405":4,"408":2,"413":1,"414":12,"422":4,"423":4,"424":2,"425":20,"429":4,"433":6,"435":8,"436":2,"437":6,"442":4,"451":2,"461":6,"473":6,"474":6,"482":2,"488":2,"502":2,"508":6,"574":2,"576":1,"587":4,"588":3,"589":1,"590":2,"591":3,"592":1,"598":1,"603":1,"604":1,"608":1,"609":1,"610":2,"622":1,"623":4,"635":4,"639":3,"643":1,"674":4,"676":6,"688":2,"702":4,"713":4,"736":4,"737":2,"738":2,"740":1,"819":7,"826":2,"828":2,"834":6,"873":2,"874":2,"883":2,"905":4,"981":2,"987":1,"988":1,"1018":1,"1097":1,"1116":1,"1147":1,"1193":3}}],["line",{"2":{"7":1,"54":6,"318":2,"361":2,"362":4,"363":2,"364":2,"566":2,"568":5,"668":6,"693":4,"695":12,"718":3,"748":2,"772":2,"773":6,"774":6,"777":6,"981":1,"1111":1}}],["like来分配一个全0的块",{"2":{"1021":2}}],["likelihood",{"2":{"616":1}}],["like",{"2":{"7":1,"172":4,"218":2,"235":2,"236":2,"237":2,"242":2,"575":4,"1021":5,"1121":1}}],["list=",{"2":{"1469":1}}],["list=true",{"2":{"583":1,"584":2,"590":1,"669":2,"679":2,"687":2,"722":1,"725":1,"777":1,"864":2,"932":2,"948":1,"949":2}}],["listen",{"2":{"1364":1,"1367":1,"1369":1,"1370":1}}],["listdir",{"2":{"692":1,"890":2,"908":3}}],["listlayers",{"2":{"480":5}}],["list",{"2":{"5":1,"9":1,"80":2,"137":4,"211":1,"320":2,"362":1,"363":4,"446":3,"472":1,"566":2,"600":2,"681":1,"757":2,"773":1,"774":3,"775":1,"827":2,"848":4,"862":3,"883":2,"896":3,"932":3,"981":1,"1007":2,"1216":1,"1240":2,"1332":1,"1469":5,"1479":1}}],["90",{"2":{"1223":1,"1463":1}}],["9×1",{"2":{"1089":1}}],["97",{"2":{"1035":1}}],["9的边界框",{"2":{"964":1}}],["9最大",{"2":{"938":1}}],["934",{"2":{"876":1}}],["91",{"2":{"854":2}}],["98",{"2":{"853":1,"1035":2}}],["92",{"2":{"853":2,"854":2,"1401":1}}],["99$$",{"2":{"1160":1}}],["99",{"2":{"813":4,"1035":1}}],["9999t1",{"2":{"792":1,"794":1}}],["999",{"2":{"33":1,"34":4,"35":4,"1092":1,"1456":1,"1457":1,"1491":1}}],["94",{"2":{"813":1}}],["94646ad1522d915e7b0f9296181140edcf86a4f5",{"2":{"565":1}}],["9和32",{"2":{"989":1}}],["9和p",{"2":{"775":1}}],["9和β2=0",{"2":{"33":1}}],["9以获得数值稳定性",{"2":{"750":3,"768":3}}],["9fcde07509c7e87ec61c640c1b27509c7e87ec61753d9041758e4",{"2":{"686":1}}],["9fcde07509c7e87ec61c640c1b2753d9041758e4",{"2":{"666":3}}],["9fcde07509c7e87ec61c640c1b277509c7e87ec6153d9041758e4",{"2":{"686":1}}],["961",{"2":{"959":1}}],["96",{"2":{"461":5,"488":21,"495":6,"744":2,"1401":1}}],["9这个数字表达什么意思呢",{"2":{"291":1}}],["9=10",{"2":{"91":1}}],["9时",{"2":{"91":1,"895":1}}],["95",{"2":{"89":1,"99":2,"101":2,"107":1,"854":2}}],["9",{"0":{"1120":1,"1121":1,"1122":1,"1123":1,"1124":1,"1125":1,"1126":1,"1127":1,"1351":1,"1429":1,"1461":1,"1483":1,"1505":1},"1":{"1430":1,"1431":1,"1432":1,"1433":1,"1434":1,"1435":1,"1462":1,"1463":1,"1464":1,"1465":1,"1466":1,"1506":1,"1507":1,"1508":1},"2":{"21":5,"34":4,"35":4,"41":2,"70":1,"89":1,"91":2,"92":4,"107":1,"108":3,"109":4,"120":1,"137":1,"291":2,"472":4,"582":4,"635":1,"736":3,"744":2,"750":3,"768":3,"775":2,"813":2,"853":2,"854":8,"894":3,"895":4,"906":3,"907":5,"927":1,"938":1,"964":3,"970":6,"1000":4,"1020":2,"1061":2,"1066":1,"1072":1,"1076":1,"1082":1,"1083":1,"1090":2,"1117":1,"1120":1,"1121":1,"1122":1,"1123":1,"1124":1,"1125":1,"1126":1,"1127":1,"1140":1,"1158":1,"1188":1,"1190":1,"1192":1,"1193":8,"1277":1}}],["9相当于10个半衰期",{"2":{"21":1}}],["0以上",{"2":{"1443":1}}],["0因此预测",{"2":{"1146":1}}],["0大的话",{"2":{"1144":1}}],["04",{"2":{"1133":1}}],["048",{"2":{"513":1}}],["0时误差随着",{"2":{"1109":1}}],["0的区域分隔开",{"2":{"1108":1}}],["0的mxnet版本",{"2":{"445":1}}],["0或1",{"2":{"1102":1}}],["0或1良性或恶性",{"2":{"1060":1}}],["0判断为假",{"2":{"1088":1}}],["06",{"2":{"1035":1}}],["0长度的总和",{"2":{"1018":1}}],["0长度",{"2":{"1018":1}}],["0≤p",{"2":{"1031":1}}],["0≤j≤q",{"2":{"954":1}}],["0≤x≤2",{"2":{"101":1}}],["0cb91d09b814ecdc07b50f31f8dcad3e81d6a86d",{"2":{"901":1}}],["08到1之间",{"2":{"903":1}}],["08～1之间",{"2":{"903":2}}],["08",{"2":{"853":1,"854":4,"903":3,"1133":1}}],["085",{"2":{"744":2}}],["0代表狗",{"2":{"853":1,"854":1}}],["0进行聚合似乎是个很随便的决定",{"2":{"841":1}}],["0提供32gb",{"2":{"840":1}}],["0及以上版本允许用户使用纯命令式编程进行开发和调试",{"2":{"818":1}}],["0版本",{"2":{"818":1,"1437":1}}],["0上高达32gb",{"2":{"812":1}}],["0上最高可达8gb",{"2":{"805":1}}],["0通道",{"2":{"801":1}}],["0通常设置为10−6",{"2":{"107":1}}],["0b8703943ccdb6eb788e6f091b8946e82231bc4d",{"2":{"748":1}}],["0是",{"2":{"738":3}}],["0表示两个边界框无重合像素",{"2":{"849":1}}],["0表示",{"2":{"692":1}}],["0～1之间的连续值",{"2":{"684":1}}],["0中下载并存储提取的snli数据集",{"2":{"666":1}}],["0中任意x",{"2":{"48":1}}],["03",{"2":{"594":8,"605":2,"1035":1,"1083":1}}],["0所示",{"2":{"553":1}}],["0和α",{"2":{"966":1}}],["0和keras增加了命令式编程",{"2":{"818":1}}],["0和1分别标记片段a和b",{"2":{"734":1}}],["0和gpu是等价的",{"2":{"446":1}}],["0和cuda是等价的",{"2":{"446":1}}],["07",{"2":{"434":2}}],["090b5e7e70c295757f55df93cb0a180b9691891a",{"2":{"361":1}}],["0作为学习率时",{"2":{"334":1}}],["0禁用权重衰减后运行这个代码",{"2":{"276":1}}],["0但q",{"2":{"191":1}}],["0×0+6×1+0×2+0×3=6",{"2":{"142":1}}],["0×0+0×1+1×2+2×3=8",{"2":{"142":1}}],["0×0+0×1+0×2+0×3=0",{"2":{"141":1}}],["0×0+1×1+3×2+4×3=19",{"2":{"126":1}}],["0×0+1×1+3×2+4×3",{"2":{"120":1}}],["00",{"2":{"1315":2}}],["009999999",{"2":{"854":3}}],["002",{"2":{"767":1}}],["0022",{"2":{"744":1}}],["00176955",{"2":{"1035":1}}],["0015",{"2":{"1035":1}}],["001",{"2":{"681":3,"704":3,"865":2,"874":5,"883":3,"1083":1,"1124":1,"1482":1}}],["0013",{"2":{"103":1}}],["000",{"2":{"1060":2,"1148":2}}],["0003",{"2":{"1035":1}}],["00078",{"2":{"744":1}}],["000018",{"2":{"744":1}}],["000017",{"2":{"744":1}}],["000022",{"2":{"744":1}}],["000066",{"2":{"744":1}}],["00019",{"2":{"744":1}}],["000分",{"2":{"658":3}}],["000个单词",{"2":{"323":1}}],["003",{"2":{"275":4,"278":4,"744":1}}],["005会产生良好的收敛性能",{"2":{"91":1}}],["005",{"2":{"80":1,"91":1,"92":4,"376":1,"409":4,"576":1}}],["02",{"2":{"91":1,"895":1,"1035":1,"1133":1}}],["0=f",{"2":{"60":1}}],["0来生成典型的梯度下降算法",{"2":{"57":1}}],["05之间的区间被均匀分成五个部分",{"2":{"959":1}}],["054",{"2":{"513":1}}],["05",{"2":{"55":1,"80":1,"81":2,"99":2,"271":2,"503":1,"509":1,"853":1}}],["05的进度",{"2":{"55":1}}],["011485",{"2":{"1035":1}}],["01ada507287d82875905620988597833ad4e0903",{"2":{"692":1}}],["01随机初始化权重",{"2":{"623":1}}],["01的正态分布中采样随机数来初始化权重",{"2":{"601":1}}],["01的正态分布中随机采样",{"2":{"592":1}}],["01的高斯分布初始化权重",{"2":{"558":1}}],["01的高斯分布中提取权重",{"2":{"544":1}}],["01的高斯随机变量",{"2":{"435":1}}],["01的学习率",{"2":{"34":1}}],["01高斯噪声破坏",{"2":{"271":1}}],["01^2",{"2":{"271":1}}],["01",{"2":{"34":5,"35":4,"41":2,"54":2,"72":3,"73":2,"80":4,"81":6,"91":2,"99":2,"101":2,"102":2,"103":2,"108":2,"109":4,"173":3,"176":3,"217":8,"225":3,"263":4,"271":2,"331":4,"335":1,"350":6,"435":4,"463":1,"544":4,"558":4,"592":6,"599":3,"601":4,"616":2,"623":4,"630":4,"715":3,"726":3,"827":1,"828":3,"834":3,"874":1,"910":1,"966":6,"1035":1,"1083":1,"1133":1}}],["0",{"2":{"21":7,"27":3,"28":1,"29":4,"34":13,"35":12,"40":1,"41":7,"44":3,"45":1,"46":6,"52":1,"54":9,"55":1,"56":1,"57":24,"59":4,"60":1,"67":19,"68":8,"70":2,"71":1,"72":1,"77":8,"78":4,"80":39,"81":37,"86":1,"87":23,"88":5,"89":4,"91":6,"92":8,"95":2,"99":13,"101":21,"102":32,"103":10,"105":5,"106":1,"107":4,"108":6,"109":8,"113":13,"114":5,"118":2,"120":28,"121":2,"122":5,"126":19,"128":4,"129":9,"137":21,"142":3,"146":15,"147":15,"148":6,"170":2,"172":24,"174":8,"175":4,"208":2,"209":2,"210":2,"211":6,"212":1,"213":1,"217":4,"218":2,"221":4,"225":5,"235":15,"236":2,"241":1,"242":11,"243":4,"252":2,"262":3,"263":20,"270":1,"271":6,"273":2,"275":8,"278":22,"291":2,"320":3,"321":6,"325":3,"326":1,"330":4,"331":2,"332":9,"333":4,"335":13,"340":9,"350":10,"357":2,"361":1,"363":4,"364":1,"369":3,"370":4,"375":27,"376":6,"382":20,"386":25,"388":6,"390":6,"391":1,"392":7,"396":4,"398":17,"399":10,"405":4,"406":3,"407":7,"408":17,"409":25,"418":1,"424":2,"432":2,"433":8,"434":1,"435":32,"436":32,"437":14,"445":1,"446":6,"451":6,"461":4,"463":1,"467":1,"472":15,"473":2,"479":4,"483":1,"487":12,"489":1,"495":4,"496":1,"502":4,"503":1,"508":8,"509":3,"513":2,"523":1,"527":1,"529":1,"540":2,"544":2,"545":1,"546":1,"553":2,"558":2,"559":1,"560":1,"565":1,"566":1,"568":1,"573":6,"574":15,"575":5,"576":18,"578":5,"582":5,"583":2,"584":4,"592":11,"594":1,"595":7,"599":6,"600":2,"601":6,"605":1,"616":8,"623":1,"625":1,"630":6,"631":16,"632":1,"633":15,"634":7,"635":17,"636":2,"640":12,"643":1,"648":5,"655":1,"658":1,"666":3,"667":9,"668":3,"669":2,"674":11,"681":3,"682":3,"687":3,"688":3,"692":4,"693":2,"695":6,"699":8,"702":6,"704":3,"713":3,"715":3,"720":1,"721":5,"722":21,"726":22,"727":17,"734":27,"736":15,"737":3,"738":3,"742":1,"743":2,"744":10,"748":4,"751":2,"757":1,"763":2,"765":32,"767":13,"768":3,"773":2,"774":1,"775":3,"776":3,"783":1,"796":10,"797":1,"813":1,"826":3,"827":7,"828":8,"834":9,"835":17,"836":9,"837":15,"841":1,"848":43,"849":6,"851":9,"852":19,"853":32,"854":72,"858":16,"863":19,"865":4,"866":17,"872":20,"873":1,"874":4,"879":6,"880":2,"882":4,"883":23,"890":3,"891":48,"893":1,"894":16,"895":4,"896":2,"898":2,"902":1,"903":55,"905":12,"906":18,"907":3,"908":5,"910":2,"912":9,"919":31,"920":1,"924":1,"927":10,"932":3,"933":15,"938":16,"945":46,"946":9,"947":23,"956":3,"959":25,"961":1,"962":2,"963":3,"964":23,"966":21,"968":12,"970":14,"974":3,"977":4,"981":6,"989":9,"992":6,"995":8,"1000":6,"1012":1,"1017":1,"1018":8,"1020":4,"1026":2,"1032":1,"1035":7,"1044":1,"1045":1,"1046":1,"1047":5,"1048":6,"1060":3,"1082":1,"1083":3,"1088":5,"1090":3,"1091":2,"1092":3,"1093":4,"1106":5,"1107":3,"1108":8,"1109":3,"1110":2,"1111":1,"1115":2,"1124":1,"1133":9,"1140":1,"1144":1,"1145":2,"1146":1,"1183":1,"1188":2,"1191":8,"1225":1,"1226":1,"1235":1,"1236":1,"1240":1,"1246":1,"1315":2,"1332":1,"1335":4,"1364":2,"1368":2,"1369":6,"1371":2,"1413":1,"1422":3,"1425":1,"1437":2,"1444":2,"1456":1,"1457":1,"1460":1,"1462":1,"1467":2,"1470":1,"1471":1,"1503":1}}],["gke",{"2":{"1393":1}}],["gkioxari",{"2":{"936":1,"940":1}}],["gce",{"2":{"1386":1}}],["gca",{"2":{"80":1,"99":2,"981":1,"1026":8}}],["g为sigmoid函数",{"2":{"1122":1}}],["g4",{"2":{"841":1}}],["g4dn",{"2":{"832":1}}],["guanyu",{"2":{"1478":2,"1479":1}}],["guard",{"2":{"660":2}}],["guido",{"2":{"1296":1}}],["gulcehre",{"2":{"538":1,"572":2}}],["gmail做分类时可能在内部估计概率",{"2":{"634":1}}],["gpt和bert之间的差异",{"2":{"733":1}}],["gpt将返回",{"2":{"732":1}}],["gpt只能向前看",{"2":{"732":1}}],["gpt在自然语言推断",{"2":{"732":1}}],["gpt在下游任务的监督学习过程中对预训练transformer解码器中的所有参数进行微调",{"2":{"732":1}}],["gpt建立在transformer解码器的基础上",{"2":{"732":1}}],["gpt",{"2":{"732":1,"733":2,"1051":1,"1055":1}}],["gpgpu",{"2":{"457":1}}],["gpu很好地支持加速计算",{"2":{"1016":1}}],["gpu同步160mb",{"2":{"842":1}}],["gpu函数的替代",{"2":{"827":1}}],["gpu中",{"2":{"843":1}}],["gpu中实现的数据并行的变体",{"2":{"841":1}}],["gpu中展示了如何使用nvidia",{"2":{"831":1}}],["gpu中评估的lenet相比",{"2":{"828":1}}],["gpu中引入的split",{"2":{"827":1}}],["gpu中的相同",{"2":{"825":1}}],["gpu中接受单一输入",{"2":{"681":1}}],["gpu服务器上可以显著地增加小批量数据量的大小",{"2":{"833":1}}],["gpu服务器",{"2":{"819":1}}],["gpu擅长fp16矩阵操作",{"2":{"814":1}}],["gpu的显存曾经是一个棘手的问题",{"2":{"832":1}}],["gpu的数量越多",{"2":{"832":1}}],["gpu的接口之间需要的密集同步可能是很难办的",{"2":{"832":1}}],["gpu的lenet更有意义的网络",{"2":{"826":1}}],["gpu的延迟",{"2":{"813":1}}],["gpu的性能很容易超过该数字100倍",{"2":{"77":1}}],["gpu用于训练",{"2":{"811":1}}],["gpu用于推断和v100",{"2":{"811":1}}],["gpu使用特定的高性能内存",{"2":{"802":1}}],["gpu内存的带宽要求甚至更高",{"2":{"802":1}}],["gpu内核要简单得多",{"2":{"457":1}}],["gpu和其他加速卡",{"0":{"811":1}}],["gpu和其他机器",{"2":{"450":1}}],["gpu和存储",{"2":{"801":1}}],["gpu1",{"2":{"796":18,"797":6}}],["gpu1和x",{"2":{"796":1}}],["gpu2",{"2":{"796":19}}],["gpu操作在飞桨中是异步的",{"2":{"790":1}}],["gpu操作在pytorch中是异步的",{"2":{"790":1}}],["gpu计算热身",{"2":{"790":2}}],["gpu可以在处理几百个样本时",{"2":{"600":1}}],["gpu可优化高吞吐量的4×4矩阵和向量乘法",{"2":{"457":1}}],["gpu设备",{"2":{"473":1,"488":1,"509":1}}],["gpu设备只代表一个卡和相应的显存",{"2":{"446":2}}],["gpu实现了快速卷积运算",{"2":{"457":1}}],["gpu架构为每个芯片提供了高达312",{"2":{"457":1}}],["gpu由100∼1000个小的处理单元组成",{"2":{"457":1}}],["gpus个gpu",{"2":{"837":3}}],["gpus=2",{"2":{"828":2,"837":1}}],["gpus=1",{"2":{"828":2,"837":1}}],["gpus",{"2":{"446":13,"457":1,"680":3,"686":2,"702":3,"713":1,"726":2,"796":3,"824":2,"827":4,"828":7,"835":2,"837":6,"865":3,"874":3,"883":7,"894":1,"895":3,"907":3}}],["gpu==2",{"2":{"445":1}}],["gpu进行计算",{"2":{"445":1}}],["gpu性能每十年增长1000倍",{"2":{"445":1}}],["gpu",{"0":{"445":1},"1":{"446":1,"447":1,"448":1,"449":1,"450":1,"451":1,"452":1,"453":1},"2":{"67":7,"137":8,"326":4,"332":7,"333":1,"335":5,"376":1,"409":4,"421":1,"445":2,"446":27,"448":8,"449":5,"451":3,"457":1,"463":1,"473":2,"474":1,"483":1,"489":1,"496":1,"503":1,"509":1,"523":3,"528":3,"546":3,"547":1,"560":3,"561":1,"576":1,"682":6,"715":3,"767":3,"789":1,"790":1,"796":1,"813":8,"825":1,"828":6,"831":2,"835":5,"836":2,"837":8,"841":1,"883":3,"894":2,"927":3,"961":3}}],["gbps",{"2":{"813":2}}],["gb",{"2":{"300":2,"1346":1}}],["gf",{"2":{"300":1}}],["gitlab",{"2":{"1319":1}}],["git",{"0":{"1316":1,"1317":1,"1318":1,"1319":1,"1320":1,"1325":1,"1326":1,"1331":1,"1336":1},"1":{"1317":1,"1318":2,"1319":2,"1320":2,"1321":2,"1322":2,"1323":2,"1324":2,"1325":2,"1326":1,"1327":2,"1328":2,"1329":2,"1330":2,"1331":1,"1332":2,"1333":2,"1334":2,"1335":2,"1336":1,"1337":1},"2":{"1318":3,"1319":6,"1323":1,"1324":1,"1325":1,"1327":2,"1328":5,"1329":6,"1330":4,"1332":3,"1333":2,"1334":1,"1335":2,"1336":8,"1337":6,"1392":2,"1546":1}}],["github",{"0":{"1307":1},"1":{"1308":1,"1309":1,"1310":1,"1311":1,"1312":1,"1313":1,"1314":1,"1315":1},"2":{"1309":2,"1310":1,"1311":1,"1312":1,"1313":1,"1314":2,"1315":7,"1319":1,"1325":1,"1327":1,"1543":1,"1550":1}}],["gitman",{"2":{"250":1,"300":1}}],["girshick",{"2":{"936":3,"937":1,"938":1,"939":1,"942":1,"966":1}}],["girlfriend",{"2":{"755":1}}],["girl",{"2":{"755":1}}],["gi=∑k∈workers∑j∈gpusgijk",{"2":{"844":1}}],["gist",{"2":{"813":1}}],["gimpel",{"2":{"740":1}}],["ginsburg",{"2":{"250":1,"300":1}}],["gigaflops",{"2":{"77":20,"78":4}}],["gzip",{"2":{"1365":1,"1371":3}}],["gz",{"2":{"206":1,"692":1}}],["glove或子词嵌入模型预先训练每个词元的词元",{"2":{"754":1}}],["glove网站",{"2":{"748":1}}],["glove嵌入",{"2":{"748":1}}],["glove可以从词",{"2":{"745":1}}],["glove使用平方损失来拟合预先计算的全局语料库统计数据",{"2":{"745":1}}],["glove中",{"2":{"744":1}}],["glove根据大量语料库的统计数据",{"2":{"744":1}}],["glove将它们相加作为输出向量",{"2":{"743":1}}],["glove拟合对称概率logxij",{"2":{"743":1}}],["glove模型基于平方损失",{"2":{"743":1}}],["glove模型",{"0":{"743":1}}],["glove",{"0":{"741":1},"1":{"742":1,"743":1,"744":1,"745":1,"746":1},"2":{"680":9,"703":8,"714":3,"741":1,"743":1,"744":6,"748":12,"750":4,"751":4,"754":1}}],["glorotuniform",{"2":{"435":1}}],["glorot",{"2":{"247":1,"325":1,"547":1,"561":1}}],["globalmaxpool2d",{"2":{"959":1}}],["globalmaxpool1d",{"2":{"702":1}}],["global中的相同符号",{"2":{"744":1}}],["globalaveragepooling2d",{"2":{"495":1}}],["globalavgpool2d",{"2":{"482":2,"488":2,"495":1,"502":2,"826":1,"893":1}}],["global",{"2":{"101":2,"114":2,"495":1,"742":1,"813":1,"826":2,"1067":1,"1336":6}}],["gluon数据集提供的transform",{"2":{"882":1}}],["gluon通过提供一个上下文列表",{"2":{"829":1}}],["gluon通过trainer类支持该算法的许多变种",{"2":{"594":1}}],["gluon将模型编译成符号式编程中使用的形式",{"2":{"818":1}}],["gluon将init作为访问initializer包的快捷方式",{"2":{"592":1}}],["gluon让我们避免了这个问题",{"2":{"592":1}}],["gluon会自动推断每个层输入的形状",{"2":{"591":1}}],["gluon并不要求我们为每个层指定输入的形状",{"2":{"591":1}}],["gluon运行时记录正在发生的事情",{"2":{"426":1}}],["gluon这样做的一个方法是允许混合式编程",{"2":{"426":1}}],["gluon知道在",{"2":{"424":1}}],["gluon同时衰减权重和偏置",{"2":{"278":1}}],["gluon",{"2":{"67":4,"68":1,"71":1,"72":1,"73":1,"77":2,"81":2,"126":1,"136":2,"137":2,"141":1,"146":1,"172":2,"175":1,"176":1,"208":2,"210":2,"216":1,"220":1,"224":2,"225":2,"261":2,"263":2,"271":2,"278":2,"324":1,"329":1,"334":1,"335":3,"350":4,"367":1,"374":1,"381":1,"385":2,"392":2,"395":1,"404":1,"413":1,"418":1,"422":1,"429":1,"441":1,"446":1,"461":1,"472":1,"480":1,"487":1,"494":1,"501":1,"507":1,"523":1,"528":1,"533":1,"543":1,"557":1,"572":2,"575":1,"576":1,"581":1,"582":2,"583":2,"584":3,"589":1,"590":2,"591":1,"593":1,"594":2,"622":2,"624":1,"625":1,"629":1,"635":1,"666":1,"668":1,"669":2,"673":2,"681":4,"685":2,"687":3,"688":2,"698":2,"704":2,"712":2,"715":2,"718":1,"722":2,"725":1,"726":3,"733":2,"736":1,"760":2,"765":1,"767":1,"771":1,"777":2,"789":2,"819":1,"825":2,"827":1,"828":2,"833":1,"834":1,"836":3,"847":1,"861":2,"862":1,"865":2,"871":2,"872":11,"873":2,"874":5,"877":2,"879":3,"880":3,"881":2,"882":8,"883":2,"887":2,"891":9,"892":4,"893":1,"894":1,"899":2,"903":12,"904":4,"905":2,"906":1,"918":2,"920":1,"926":1,"931":1,"932":3,"945":1,"947":1,"948":1,"949":2,"954":2,"961":1,"962":2,"967":1}}],["goldfarb",{"2":{"1109":1}}],["gonzalez",{"2":{"840":1}}],["goyal",{"2":{"757":1,"966":1}}],["gordon",{"2":{"519":1}}],["good",{"2":{"682":1}}],["goodfellow",{"2":{"300":1}}],["google+",{"2":{"1150":1}}],["googlenet中",{"2":{"946":1}}],["googlenet在后面接了4个由inception块组成的模块",{"2":{"502":1}}],["googlenet有一些后续版本",{"2":{"491":1}}],["googlenet和它的后继者们一度是imagenet上最有效的模型之一",{"2":{"490":1}}],["googlenet将多个设计精细的inception块与其他层",{"2":{"490":1}}],["googlenet一共使用9个inception块和全局平均汇聚层的堆叠来生成其估计值",{"2":{"488":1}}],["googlenet模型的计算复杂",{"2":{"488":1}}],["googlenet模型",{"0":{"488":1}}],["googlenet吸收了nin中串联网络的思想",{"2":{"486":1}}],["googlenet",{"0":{"486":1},"1":{"487":1,"488":1,"489":1,"490":1,"491":1},"2":{"486":1,"492":2,"857":1}}],["google",{"2":{"456":1,"813":1,"1061":1,"1303":1,"1374":1,"1393":1}}],["gool",{"2":{"454":1,"455":1}}],["go",{"2":{"376":2,"409":2,"487":1,"578":2,"751":2,"754":2}}],["goh",{"2":{"86":1,"95":1}}],["gotmare",{"2":{"73":1}}],["geq0",{"2":{"1160":1}}],["gevers",{"2":{"937":1}}],["gelu",{"2":{"740":1}}],["geometry",{"2":{"506":1}}],["geoff",{"2":{"455":1}}],["gender",{"2":{"1459":4}}],["genericrepository",{"2":{"1432":2}}],["genericresponse",{"2":{"1431":5}}],["generic",{"2":{"1416":1}}],["generator",{"2":{"775":4,"1048":1}}],["generative",{"2":{"296":1,"732":1}}],["general",{"2":{"457":1}}],["generalization",{"2":{"252":1,"613":1,"980":1}}],["genius",{"2":{"1058":1,"1187":1}}],["gen3链路上的带宽为16gb",{"2":{"841":1}}],["gen中的求和计算",{"2":{"309":1}}],["gen中的全部总和",{"2":{"308":1}}],["gen",{"2":{"307":1,"926":12}}],["genfromtxt",{"2":{"79":4}}],["getdog",{"2":{"1471":5}}],["getelementbyid",{"2":{"1467":1,"1468":1}}],["getemail",{"2":{"1428":1}}],["getproperty",{"2":{"1433":4}}],["getatalk",{"2":{"1495":2}}],["getatalk函数相当于action",{"2":{"1495":1}}],["getattr",{"2":{"959":12}}],["getall",{"2":{"1432":1}}],["getbyid",{"2":{"1432":2}}],["getbasesalary",{"2":{"1425":2}}],["getsalaryinfo",{"2":{"1425":1}}],["gettoy",{"2":{"1497":4}}],["gettoy=",{"2":{"1497":1}}],["getters",{"0":{"1493":1},"2":{"1490":2,"1493":1}}],["getter",{"2":{"1490":1}}],["getter函数",{"2":{"1461":1}}],["getteaminfo",{"2":{"1425":1}}],["getting",{"2":{"1173":1}}],["getinfo",{"2":{"1425":1}}],["getitem",{"2":{"363":2,"634":1,"668":4,"687":3,"722":4,"748":1,"777":2,"932":3,"947":4,"1495":1}}],["get",{"2":{"21":1,"28":1,"34":1,"35":4,"68":1,"71":5,"72":2,"79":4,"80":1,"81":4,"91":1,"108":1,"127":2,"129":2,"206":1,"209":1,"210":3,"211":3,"213":1,"263":1,"278":1,"325":2,"331":4,"332":12,"333":12,"335":3,"350":8,"363":1,"391":1,"414":3,"418":5,"425":1,"432":2,"446":1,"472":2,"544":4,"546":3,"558":4,"560":3,"582":7,"583":3,"595":2,"636":2,"669":3,"687":6,"720":6,"721":1,"722":11,"726":7,"727":8,"734":2,"748":1,"750":4,"751":5,"757":3,"768":6,"774":3,"775":2,"777":9,"819":8,"820":5,"821":1,"827":1,"835":5,"837":3,"882":3,"890":1,"893":3,"895":3,"896":3,"905":3,"907":3,"908":3,"920":8,"926":4,"927":9,"946":2,"948":3,"949":3,"959":6,"1012":1,"1047":1,"1168":1,"1392":2,"1416":3,"1431":3,"1460":1,"1471":1,"1495":1,"1520":1}}],["game>",{"2":{"1508":1}}],["game",{"2":{"1508":3}}],["games=",{"2":{"1508":1}}],["games",{"2":{"1456":3,"1457":3,"1506":1,"1507":1,"1508":3}}],["gammon开始",{"2":{"301":1}}],["gamma=",{"2":{"966":3}}],["gamma=self",{"2":{"472":1}}],["gamma=0",{"2":{"71":2,"927":1}}],["gamma1",{"2":{"109":1}}],["gamma",{"2":{"107":5,"108":22,"262":2,"472":18,"473":4,"966":15}}],["gammas",{"2":{"107":2}}],["gas",{"2":{"744":1}}],["gasthaus",{"2":{"316":1}}],["gauss",{"2":{"616":1}}],["gaussian略有不同",{"2":{"389":1}}],["gaussian是",{"2":{"388":1}}],["gaussian中",{"2":{"388":1}}],["gaussian中的",{"2":{"367":1}}],["gaussian",{"2":{"388":2,"389":2,"391":1,"616":1,"740":1,"1146":1,"1179":1,"1184":1,"1185":1}}],["gatys",{"2":{"916":1,"920":1}}],["gather",{"2":{"600":2}}],["gate",{"2":{"540":2,"552":3}}],["gated",{"2":{"538":1,"550":1}}],["garry",{"2":{"301":1}}],["garbage",{"2":{"284":2}}],["garipov",{"2":{"38":1,"66":1}}],["grid",{"2":{"848":9,"981":1}}],["great",{"2":{"704":1,"715":1,"724":2,"736":6}}],["greater",{"2":{"334":1}}],["greet",{"2":{"1229":1,"1257":2,"1398":1}}],["greeting",{"2":{"1048":7}}],["green",{"2":{"518":1,"1413":2}}],["greedy",{"2":{"512":1}}],["gru中所做的一样",{"2":{"560":1}}],["gru的不同实现对运行时间",{"2":{"549":1}}],["grucell",{"2":{"375":1,"547":1,"573":1,"574":1}}],["gru",{"0":{"538":1},"1":{"539":1,"540":1,"541":1,"542":1,"543":1,"544":1,"545":1,"546":1,"547":1,"548":1,"549":1},"2":{"375":3,"538":2,"540":2,"541":4,"542":2,"545":9,"546":6,"547":12,"550":2,"551":1,"573":3,"574":3,"576":1}}],["gru是个张量",{"2":{"335":2}}],["gru以张量作为隐状态",{"2":{"325":2}}],["ground",{"2":{"847":1,"851":9,"853":5}}],["group=false",{"2":{"874":2}}],["group=true",{"2":{"874":4}}],["groups",{"2":{"67":1,"68":2,"422":1,"1026":4}}],["group",{"2":{"67":2,"506":1,"874":2}}],["growth",{"2":{"480":1,"482":12}}],["grossartige",{"2":{"295":1}}],["grand",{"2":{"1501":1,"1503":1}}],["grandchild",{"2":{"1501":4,"1503":1}}],["gray",{"2":{"1091":3}}],["grave",{"2":{"756":1,"759":1}}],["graves设计了一种可微注意力模型",{"2":{"373":1}}],["graves",{"2":{"300":1,"356":1,"373":1,"521":1}}],["gram将在训练前预先计算好",{"2":{"926":1}}],["gram所示",{"2":{"783":1}}],["gram函数的输出形状",{"2":{"763":1}}],["gram中的跳元模型",{"2":{"741":1}}],["gram",{"0":{"783":1},"1":{"784":1},"2":{"707":4,"709":1,"756":2,"763":6,"767":3,"782":1,"783":3,"784":4,"923":10,"925":2,"926":9,"927":6}}],["grams",{"2":{"578":1}}],["graph模式",{"2":{"820":1}}],["graph说明了数据流",{"2":{"816":1}}],["graphics",{"2":{"457":1}}],["graphical",{"2":{"296":1}}],["graph",{"2":{"299":1,"816":1,"973":1,"1328":1}}],["graph=true",{"2":{"235":2,"236":2,"237":2}}],["gradapprox",{"2":{"1124":1}}],["gradobj",{"2":{"1109":1,"1111":2}}],["grad来为一个张量的梯度分配内存",{"2":{"974":1}}],["grad中的计算需要词典中以wc为中心词的所有词的条件概率",{"2":{"784":1}}],["grad中跳元模型的梯度计算和",{"2":{"707":1}}],["grad=true在step函数d2l",{"2":{"688":1}}],["grad=true",{"2":{"80":2,"217":4,"235":1,"242":1,"273":2,"391":1,"601":2,"630":2,"883":1,"974":1,"977":1}}],["grad=false",{"2":{"425":1}}],["grad=f",{"2":{"57":1,"113":1,"114":2}}],["grad=none",{"2":{"57":2}}],["gradientdescentforlinearregression",{"2":{"1069":1}}],["gradient多次",{"2":{"976":1}}],["gradient中的连续词袋模型的梯度计算都包含求和",{"2":{"707":1}}],["gradient默认为true",{"2":{"601":1}}],["gradient=zeros",{"2":{"1111":1}}],["gradient=true",{"2":{"335":2}}],["gradient=false",{"2":{"80":2,"331":1,"630":2,"974":1,"977":1}}],["gradients",{"2":{"81":1,"129":1,"210":1,"278":1,"335":1,"350":1,"392":1,"576":5,"595":1,"635":1}}],["gradienttape",{"2":{"80":1,"81":1,"129":1,"210":1,"235":1,"236":1,"237":1,"242":1,"275":1,"278":1,"335":1,"350":1,"392":1,"576":1,"595":1,"605":1,"635":1,"974":2,"975":1,"976":1,"977":1}}],["gradient",{"2":{"53":1,"76":1,"80":2,"81":1,"103":2,"112":1,"129":1,"210":1,"217":4,"235":2,"236":2,"237":2,"241":2,"242":6,"273":2,"275":1,"278":1,"287":1,"334":1,"335":1,"350":1,"392":1,"472":1,"544":1,"558":1,"576":1,"595":1,"601":2,"604":1,"605":1,"613":2,"635":2,"703":1,"714":1,"786":1,"835":1,"876":1,"905":1,"906":1,"974":3,"975":2,"976":5,"977":1,"983":1,"1067":2,"1068":1,"1081":1,"1082":1,"1083":1,"1109":3,"1110":2,"1111":4,"1124":2,"1165":1,"1166":1,"1167":1}}],["grads",{"2":{"21":2,"28":2,"34":2,"35":2,"80":2,"81":2,"91":2,"108":2,"210":2,"275":2,"278":2,"334":2,"335":4,"350":2,"392":2,"595":2,"604":2,"635":4}}],["grad",{"2":{"21":13,"28":10,"34":13,"35":17,"54":7,"55":2,"56":2,"57":8,"59":3,"67":4,"80":9,"81":2,"91":7,"108":10,"113":6,"114":2,"129":5,"137":6,"173":1,"210":2,"217":1,"235":8,"236":8,"237":8,"242":4,"273":2,"278":2,"331":2,"334":30,"335":8,"350":2,"392":2,"431":2,"472":2,"544":2,"558":2,"576":8,"595":2,"601":2,"604":8,"605":2,"630":2,"634":2,"635":2,"703":2,"714":2,"726":2,"767":2,"784":1,"828":2,"835":3,"837":5,"876":2,"883":2,"905":1,"906":3,"927":2,"963":2,"974":19,"975":4,"976":10,"977":7,"983":1}}],["gd中观察到的梯度下降中观察到的轨迹嘈杂得多",{"2":{"113":1}}],["gd中描述了梯度下降的基本原则",{"2":{"112":1}}],["gd中使用了f",{"2":{"87":1}}],["gd中使用完整数据集来计算梯度并更新参数",{"2":{"76":1}}],["gd",{"2":{"53":1,"54":6,"55":4,"56":1,"57":3,"58":1,"59":2,"65":1,"80":3,"87":9}}],["g←g⋅min",{"2":{"50":1}}],["g2",{"2":{"27":3,"57":2,"108":3,"113":6}}],["g1",{"2":{"27":3,"57":2,"108":3,"113":6}}],["g",{"2":{"21":16,"28":3,"41":4,"46":5,"52":2,"80":2,"81":2,"91":2,"99":3,"108":3,"129":3,"156":4,"300":1,"329":1,"334":3,"335":2,"337":1,"350":2,"361":1,"605":2,"635":1,"675":9,"757":2,"816":2,"817":2,"848":1,"981":6,"1107":3,"1108":3,"1121":3,"1443":1,"1456":3,"1457":3,"1506":3,"1507":3,"1508":3}}],["gtx580",{"2":{"457":1}}],["gt=∂w1|bt|∑i∈btf",{"2":{"78":1}}],["gt=∂wf",{"2":{"78":1}}],["gt=∂wl",{"2":{"27":1}}],["gt",{"2":{"20":2,"33":2,"54":3,"57":1,"60":1,"72":1,"86":1,"95":1,"105":3,"106":1,"107":1,"120":1,"155":2,"191":1,"270":1,"334":1,"337":1,"341":1,"347":1,"363":4,"467":1,"512":3,"513":6,"515":2,"549":1,"567":4,"568":3,"572":4,"576":2,"577":2,"597":1,"655":3,"657":3,"668":1,"688":1,"722":1,"727":3,"734":5,"735":2,"736":4,"737":2,"756":3,"772":2,"773":1,"792":1,"794":1,"813":2,"848":1,"851":15,"966":3,"1021":1,"1024":1,"1027":1,"1032":1,"1081":1,"1090":1,"1103":1,"1107":1,"1108":4,"1120":1,"1143":2,"1144":6,"1145":5,"1146":1,"1148":1,"1178":1,"1180":1,"1184":2,"1444":1,"1454":1,"1479":1,"1498":1,"1530":1}}],["gt2+γgt−12+γ2gt−2+",{"2":{"107":1}}],["gt2+γst−1=",{"2":{"107":1}}],["gt2⊙sgn⁡",{"2":{"35":1}}],["gt2−st−1",{"2":{"35":3}}],["gt2",{"2":{"20":1,"33":1,"106":1,"107":1}}],["+μi",{"2":{"1192":1}}],["+λθk",{"2":{"1188":1,"1189":1}}],["+λ2m∑l=1l−1∑i=1sl∑j=1sl+1",{"2":{"1120":1}}],["+λ2m∑j=1nθj2",{"2":{"1117":1}}],["+λ2∥w∥2",{"2":{"270":1}}],["+λmθj",{"2":{"1116":1,"1117":1}}],["+y",{"2":{"1109":1}}],["+x99x100",{"2":{"1097":1}}],["+x2x3+x2x4+",{"2":{"1097":1}}],["+xi0",{"2":{"386":1}}],["+5w因此",{"2":{"1093":1}}],["+θ3",{"2":{"1100":1}}],["+θ1",{"2":{"1100":1}}],["+θ13",{"2":{"1099":1}}],["+θ12",{"2":{"1099":1}}],["+θ11",{"2":{"1099":1}}],["+θ2⋅x2",{"2":{"1145":1}}],["+θ2size",{"2":{"1084":1}}],["+θ2",{"2":{"1084":1,"1100":1}}],["+θnxn",{"2":{"1080":2,"1081":2,"1086":1,"1110":1}}],["+p",{"2":{"1035":4}}],["+prod",{"2":{"164":2,"312":1}}],["+ddxg",{"2":{"981":1}}],["+g",{"2":{"981":2}}],["+j",{"2":{"954":1}}],["+vo2m",{"2":{"785":3}}],["+vec",{"2":{"751":1}}],["+σ",{"2":{"709":1}}],["+wdxd+b",{"2":{"610":1}}],["+ht−1",{"2":{"527":1}}],["+h←t+1whh",{"2":{"521":1}}],["+h→t−1whh",{"2":{"521":1}}],["+hϵ=0",{"2":{"59":1}}],["+str",{"2":{"407":1,"408":1}}],["+sin⁡",{"2":{"400":1}}],["+cos⁡",{"2":{"400":1}}],["+c的学习率",{"2":{"25":1}}],["+αmin",{"2":{"235":1}}],["+bh",{"2":{"521":2,"527":1}}],["+b",{"2":{"232":11,"610":1}}],["+b−y",{"2":{"270":2,"611":1,"613":2}}],["+b−12c⊤q−1c",{"2":{"94":1}}],["+b−xb−af",{"2":{"46":1}}],["+q",{"2":{"191":1}}],["+1=2sigmoid",{"2":{"239":1}}],["+1",{"2":{"146":1}}],["+12∑j=1nθj2在具体实施时",{"2":{"1147":1}}],["+12∑i=1nθj2",{"2":{"1144":1}}],["+12σ2",{"2":{"616":1}}],["+12",{"2":{"60":1}}],["+12ϵ⊤∇2f",{"2":{"59":1}}],["+12ϵ2f",{"2":{"52":1}}],["+12f",{"2":{"46":1}}],["+exp⁡",{"2":{"64":1,"655":1}}],["+ϵ",{"2":{"349":1}}],["+ϵ3",{"2":{"316":1}}],["+ϵ3p^",{"2":{"316":1}}],["+ϵ2",{"2":{"316":1}}],["+ϵ2p^",{"2":{"316":1}}],["+ϵ1",{"2":{"316":1}}],["+ϵ⊤∇f",{"2":{"57":1,"59":1}}],["+ϵf",{"2":{"52":1,"54":1}}],["+ones",{"2":{"1090":1}}],["+o",{"2":{"54":2,"57":1}}],["+∑i=1nαici",{"2":{"48":1}}],["+f",{"2":{"46":1,"479":1,"1000":1}}],["+=10",{"2":{"1166":1}}],["+=",{"2":{"27":2,"28":3,"34":3,"35":4,"80":4,"81":4,"113":4,"114":2,"211":2,"262":1,"436":2,"482":4,"501":3,"578":2,"599":3,"726":3,"734":2,"757":1,"774":1,"775":1,"776":4,"821":1,"835":3,"866":3,"894":3,"905":6,"906":3,"946":3,"968":1,"1021":2,"1226":1,"1422":3,"1445":1,"1451":1,"1454":1,"1455":1,"1456":1,"1457":1,"1459":2,"1462":1,"1463":2,"1464":2,"1465":2,"1466":2,"1467":2,"1470":1,"1471":1,"1491":1,"1503":3}}],["+",{"0":{"1201":1,"1266":1,"1315":2},"1":{"1267":1,"1268":1,"1269":1},"2":{"21":16,"25":1,"27":3,"28":5,"34":12,"35":12,"41":1,"44":2,"45":1,"46":6,"57":3,"67":7,"68":1,"72":3,"79":4,"87":4,"88":2,"91":4,"99":1,"108":13,"113":1,"114":1,"115":2,"120":1,"121":2,"126":8,"127":4,"129":4,"137":13,"141":5,"145":1,"146":14,"148":3,"174":3,"208":2,"211":3,"213":1,"219":8,"236":1,"237":1,"262":5,"263":8,"271":2,"275":12,"278":9,"296":1,"320":3,"321":18,"332":12,"335":8,"340":2,"350":10,"351":30,"361":2,"362":1,"363":1,"369":4,"375":2,"376":3,"386":8,"392":8,"398":4,"406":4,"408":4,"409":1,"414":4,"425":4,"436":2,"446":4,"449":2,"472":18,"480":2,"501":1,"545":32,"559":40,"565":2,"568":2,"574":2,"576":8,"577":4,"578":7,"595":4,"599":2,"600":2,"602":1,"605":4,"615":4,"632":1,"634":1,"635":2,"636":2,"668":9,"686":4,"687":15,"699":4,"720":3,"722":18,"726":9,"734":11,"748":5,"750":4,"751":1,"757":1,"765":5,"767":9,"768":3,"772":1,"774":2,"775":1,"776":6,"790":3,"792":3,"816":2,"817":6,"821":2,"828":3,"834":6,"835":3,"837":3,"848":12,"849":3,"852":4,"854":5,"858":4,"863":3,"866":6,"872":2,"883":12,"889":1,"890":1,"893":1,"894":15,"896":3,"901":1,"906":15,"908":15,"919":3,"920":4,"924":1,"925":2,"927":7,"931":1,"932":6,"945":16,"946":3,"947":6,"954":3,"957":1,"959":4,"962":3,"963":3,"968":4,"981":1,"989":4,"994":8,"1018":5,"1019":1,"1021":13,"1026":12,"1048":2,"1050":2,"1053":1,"1054":3,"1088":1,"1090":1,"1107":1,"1109":4,"1110":2,"1117":1,"1120":2,"1121":1,"1124":1,"1130":1,"1144":1,"1147":1,"1154":1,"1167":1,"1198":1,"1210":1,"1211":2,"1215":1,"1218":1,"1229":1,"1230":2,"1233":1,"1239":1,"1240":1,"1259":1,"1294":8,"1302":1,"1304":1,"1315":1,"1320":1,"1347":2,"1378":14,"1398":1,"1460":4,"1530":5,"1547":1}}],["zustand",{"2":{"1530":1}}],["z轴为根据两个特征的值所估计p",{"2":{"1180":1}}],["z为1维",{"2":{"1161":1}}],["z远大于0时",{"2":{"1143":1}}],["z^",{"2":{"1121":1}}],["zone=my",{"2":{"1371":1}}],["zod",{"2":{"1048":1}}],["zoo",{"2":{"862":1,"873":2,"874":1,"905":1,"920":1}}],["z之后的其他计算才可能很好地继续",{"2":{"791":1}}],["zisserman",{"2":{"507":1,"511":1}}],["zipf",{"2":{"318":3}}],["zipfile",{"2":{"206":3}}],["zip",{"2":{"21":4,"28":4,"34":4,"35":4,"41":2,"57":3,"80":2,"81":1,"91":4,"108":4,"120":2,"206":1,"210":1,"278":1,"318":2,"335":1,"350":1,"357":2,"376":2,"392":1,"409":2,"565":1,"576":1,"578":2,"582":3,"595":1,"604":1,"634":1,"635":3,"636":1,"666":3,"667":1,"681":1,"686":6,"687":3,"692":1,"699":1,"702":3,"718":1,"726":1,"748":4,"750":1,"772":1,"774":1,"776":1,"777":1,"827":1,"828":1,"837":3,"872":1,"883":2,"889":1,"901":2,"905":1,"906":1,"908":3,"925":2,"931":1,"933":3,"966":6,"981":1,"1315":3}}],["z2",{"2":{"449":2}}],["z会发生什么",{"2":{"449":1}}],["z和y都在",{"2":{"449":1}}],["za",{"2":{"361":1}}],["zaheer",{"2":{"32":1,"35":1}}],["zheng",{"2":{"942":1}}],["zhao",{"2":{"942":1}}],["zhangsan",{"2":{"1419":1}}],["zhang",{"2":{"231":2,"235":1,"422":1,"500":1,"505":2,"642":2,"660":1,"795":1,"826":1,"1445":1,"1451":1,"1455":1,"1460":1}}],["zhuye",{"2":{"1478":1,"1479":1}}],["zhu",{"2":{"300":1,"301":1,"737":1}}],["z=ureducetx",{"2":{"1161":1}}],["z=θtx",{"2":{"1108":1,"1143":1}}],["z=0",{"2":{"1108":1}}],["z=z",{"2":{"986":1}}],["z=−1∣x",{"2":{"191":1}}],["z=1∣x",{"2":{"191":3}}],["z=w",{"2":{"162":1}}],["z是任意形状的张量",{"2":{"164":1}}],["zt",{"2":{"310":1}}],["zt=σ",{"2":{"540":1}}],["zt=∂f",{"2":{"310":1}}],["zt=zt−1−λzt−1=",{"2":{"94":1}}],["zticks",{"2":{"102":2}}],["zt−1−ηβvt−1",{"2":{"94":1}}],["zt−1",{"2":{"94":1}}],["z∈",{"2":{"46":1}}],["zx+",{"2":{"46":2}}],["z",{"2":{"46":2,"94":1,"102":4,"156":1,"162":1,"164":1,"361":1,"408":12,"449":11,"544":8,"545":20,"757":2,"790":6,"970":4,"976":8,"986":1,"1021":24,"1048":3,"1100":6,"1107":4,"1108":5,"1121":3,"1122":1,"1143":8,"1144":5,"1159":1}}],["zemel",{"2":{"737":1}}],["zerodivisionerror",{"2":{"1236":1,"1250":1}}],["zerowidthspace",{"2":{"1057":1,"1128":1,"1142":1,"1149":1,"1163":1,"1177":1}}],["zero",{"2":{"21":2,"28":2,"34":2,"35":2,"67":1,"80":1,"81":1,"91":2,"108":2,"129":1,"137":1,"210":1,"236":1,"237":1,"278":1,"335":1,"350":1,"392":1,"472":1,"576":1,"595":1,"604":1,"635":1,"726":1,"767":1,"828":1,"883":1,"906":1,"927":1,"963":1,"974":1,"975":1,"976":2}}],["zeros",{"2":{"21":16,"28":8,"34":16,"77":4,"80":4,"91":6,"108":6,"126":2,"127":2,"128":1,"146":2,"172":4,"173":3,"217":8,"218":2,"262":1,"273":4,"325":8,"331":8,"332":4,"350":2,"351":6,"375":4,"398":8,"414":1,"435":6,"441":4,"472":8,"544":8,"545":4,"558":8,"559":8,"573":4,"599":1,"601":4,"615":3,"630":4,"699":2,"834":12,"852":6,"863":3,"912":3,"945":3,"956":6,"957":3,"958":3,"959":3,"968":1,"970":4,"1017":4,"1021":5,"1109":1}}],["zeiler",{"2":{"19":1}}],["5999",{"2":{"1432":1}}],["582",{"2":{"1287":1}}],["585e9cc93e70b39160e7921475f9bcd7d31219ce",{"2":{"208":1}}],["5+",{"0":{"1259":1}}],["5更小的阀值",{"2":{"1140":1}}],["5更大的阀值",{"2":{"1140":1}}],["5作为阀值来预测肿瘤是良性还是恶性便不合适了",{"2":{"1107":1}}],["5时",{"2":{"1107":2,"1108":2}}],["5停止",{"2":{"1092":1}}],["5到1",{"2":{"1091":1}}],["5将上舍入变为最接近的整数",{"2":{"1090":1}}],["5将被下舍入变成0",{"2":{"1090":1}}],["54=0",{"2":{"959":1}}],["54",{"2":{"959":2}}],["5最大",{"2":{"938":1}}],["5de26c8fce5ccdea9f91267273464dc968d20d72",{"2":{"931":1}}],["5～2之间随机取值",{"2":{"879":1}}],["5e",{"2":{"874":3,"895":3,"907":1,"961":1}}],["516",{"2":{"858":1}}],["512kb",{"2":{"810":1}}],["512",{"2":{"332":4,"488":6,"502":6,"508":2,"687":3,"722":1,"725":2,"760":3,"777":1,"819":7,"820":1,"826":5,"862":2,"893":1}}],["512向量化的2ghz",{"2":{"77":1}}],["561×728×5",{"2":{"911":1}}],["56",{"2":{"854":2,"1133":1}}],["57",{"2":{"853":1}}],["55",{"2":{"853":1,"854":2}}],["5毫秒",{"2":{"841":1}}],["5英寸的硬盘上",{"2":{"815":1}}],["5英寸硬盘和5",{"2":{"815":1}}],["5英寸硬盘在商用服务器上越来越流行",{"2":{"815":1}}],["5μs",{"2":{"812":1}}],["5f",{"2":{"615":4,"981":2}}],["5×8",{"2":{"1088":1}}],["5×3=7",{"2":{"841":1}}],["5×0",{"2":{"513":2}}],["5×5和3×3的卷积层",{"2":{"495":1}}],["5的彩色格图",{"2":{"1091":1}}],["5的矩阵",{"2":{"1091":1}}],["5的边界框",{"2":{"856":1}}],["5的所有样本中",{"2":{"643":1}}],["5的正态分布",{"2":{"386":1}}],["5的多项式衰减",{"2":{"114":1}}],["5gram中选择哪一个呢",{"2":{"319":1}}],["5gram",{"2":{"319":1}}],["5gram画出了",{"2":{"319":1}}],["5错误率",{"2":{"301":1}}],["5万美元",{"2":{"210":1}}],["5和1",{"2":{"172":1}}],["5或7",{"2":{"141":1}}],["5模型",{"2":{"137":1}}],["5一致",{"2":{"136":1}}],["528",{"2":{"488":2}}],["52",{"2":{"102":2,"853":1,"854":2}}],["50d",{"2":{"748":3}}],["50模型在imagenet数据集上的训练时间减少到不到7分钟",{"2":{"300":1}}],["5000",{"2":{"1368":1,"1371":1,"1427":1}}],["50000",{"2":{"889":1}}],["500μs",{"2":{"813":1}}],["500",{"2":{"326":4,"335":2,"523":3,"529":1,"546":3,"560":3,"693":1,"813":3,"927":3,"1026":3}}],["500px",{"2":{"299":1,"404":1}}],["500样本",{"2":{"79":1}}],["50美元上门服务费",{"2":{"290":1}}],["50",{"2":{"67":3,"70":2,"335":4,"386":4,"638":1,"669":1,"679":2,"693":1,"726":2,"796":3,"834":6,"898":1,"927":3,"1148":1,"1201":1,"1422":1,"1467":3}}],["5",{"0":{"1067":1,"1076":1,"1084":1,"1088":1,"1089":1,"1090":1,"1091":1,"1092":2,"1093":1,"1094":1,"1101":1,"1110":1,"1124":1,"1133":1,"1141":1,"1147":1,"1154":1,"1160":1,"1168":1,"1182":1,"1191":1,"1282":1,"1313":1,"1322":1,"1337":1,"1347":1,"1384":1,"1392":1,"1411":1,"1457":1,"1477":1,"1487":1,"1488":1,"1489":1,"1490":1,"1491":1,"1492":2,"1493":1,"1494":1,"1495":1,"1501":1},"1":{"1283":1,"1284":1,"1285":1,"1412":1,"1413":1,"1414":1,"1488":1,"1489":1,"1490":1,"1491":1,"1492":1,"1493":1,"1494":1,"1495":1},"2":{"21":5,"41":6,"57":8,"59":3,"67":4,"68":1,"71":9,"81":2,"88":1,"91":1,"99":13,"102":2,"103":2,"105":1,"114":1,"120":2,"126":1,"136":5,"137":3,"141":4,"142":4,"146":3,"172":4,"174":5,"175":4,"176":1,"212":2,"235":16,"236":16,"237":16,"242":8,"262":4,"264":2,"271":1,"275":8,"278":8,"318":1,"320":1,"330":4,"340":2,"350":4,"351":1,"357":2,"370":4,"382":8,"386":14,"392":12,"396":8,"398":4,"399":4,"406":3,"407":7,"408":3,"409":8,"413":4,"414":6,"436":5,"461":8,"465":1,"472":5,"487":1,"495":4,"508":8,"515":1,"575":4,"578":2,"582":3,"616":5,"631":4,"633":2,"634":2,"635":3,"658":1,"688":3,"699":4,"702":6,"704":3,"715":2,"720":1,"721":1,"736":6,"757":1,"760":6,"762":1,"767":4,"774":1,"775":1,"777":2,"813":4,"834":11,"836":3,"842":2,"848":19,"851":5,"852":1,"853":1,"854":8,"858":4,"863":3,"865":3,"874":1,"878":1,"879":3,"880":20,"883":3,"894":3,"906":3,"912":3,"920":1,"924":1,"927":3,"932":1,"933":6,"938":1,"945":3,"956":3,"959":17,"964":6,"966":10,"970":6,"981":5,"989":1,"992":8,"994":4,"1022":4,"1025":3,"1026":4,"1027":4,"1028":1,"1048":2,"1061":2,"1067":1,"1076":1,"1081":1,"1082":1,"1084":1,"1088":1,"1089":5,"1090":3,"1091":3,"1092":3,"1093":1,"1094":2,"1101":1,"1108":3,"1110":1,"1111":4,"1124":1,"1133":2,"1139":2,"1140":1,"1141":1,"1147":1,"1154":2,"1160":1,"1168":1,"1176":1,"1182":1,"1187":1,"1191":6,"1193":22,"1218":2,"1219":1,"1239":1,"1242":1,"1243":1,"1296":1,"1398":1,"1402":1,"1414":1,"1426":1,"1443":1}}],["e98219e14",{"2":{"1469":1}}],["e98219e13",{"2":{"1469":1}}],["e98219e12",{"2":{"1469":1}}],["eks",{"2":{"1393":1}}],["ekj",{"2":{"674":1}}],["ebs",{"2":{"1386":1}}],["eθtx",{"2":{"1109":4}}],["e−θtx",{"2":{"1109":1}}],["ecker",{"2":{"916":1,"920":1}}],["ec2的多gpu实例",{"2":{"445":1}}],["edge",{"2":{"932":1,"933":3}}],["edgecolor=color",{"2":{"858":1}}],["edu",{"2":{"445":1,"666":3,"692":1,"748":1}}],["etcd",{"2":{"1376":1,"1378":1}}],["etc",{"2":{"1370":2}}],["ethernet",{"2":{"813":1}}],["eta=1",{"2":{"59":1}}],["eta",{"2":{"27":4,"54":4,"57":3,"59":1,"87":13,"88":4,"95":2,"108":3,"113":9}}],["e5",{"2":{"813":4}}],["eslint",{"2":{"1444":1}}],["eshelman",{"2":{"813":1}}],["estimated",{"2":{"1026":4,"1107":1}}],["estimates",{"2":{"1026":8}}],["estimation",{"2":{"299":1}}],["est",{"2":{"376":2,"409":2,"578":2}}],["err",{"2":{"963":12,"1471":2}}],["error中",{"2":{"259":1}}],["error",{"2":{"252":2,"259":1,"286":1,"740":1,"963":3,"1046":1,"1048":1,"1064":1,"1122":1,"1131":4,"1132":2,"1138":2,"1139":1,"1158":1,"1404":1,"1412":1,"1431":2,"1471":1}}],["erhan",{"2":{"952":1,"953":1,"966":1}}],["er",{"2":{"757":7}}],["ere",{"2":{"756":1}}],["evan",{"2":{"1526":1}}],["evaluating",{"2":{"1130":1,"1181":1}}],["evaluation",{"2":{"578":1}}],["evaluate",{"2":{"67":3,"80":4,"81":4,"137":8,"263":11,"275":8,"278":8,"350":4,"634":4,"635":1,"827":1,"828":3,"837":3,"883":3,"894":3,"905":3,"906":3}}],["eval",{"2":{"137":2,"369":2,"370":2,"375":4,"382":2,"396":2,"398":2,"405":2,"406":1,"407":3,"408":1,"442":2,"573":2,"574":2,"577":2,"634":2,"682":2,"962":6,"963":6,"964":2}}],["eve",{"2":{"1192":2}}],["eventname",{"2":{"1414":1}}],["eventhandler",{"2":{"1412":1}}],["eventsource",{"2":{"1047":1}}],["events",{"2":{"1047":1,"1364":1,"1365":1}}],["event",{"2":{"1026":1,"1027":1,"1315":1,"1405":2,"1412":1}}],["even",{"2":{"681":2,"726":1,"1240":1}}],["evoke",{"2":{"817":2}}],["e的形状",{"2":{"674":3}}],["e中的函数f和",{"2":{"680":1}}],["e中的维数预定义为100",{"2":{"680":1}}],["e中的注意力权重进行规范化",{"2":{"674":1}}],["e中",{"2":{"674":1}}],["eigenvectors",{"2":{"1159":1}}],["eik",{"2":{"674":1}}],["eij",{"2":{"674":2}}],["eij=f",{"2":{"674":1}}],["ei∇fi",{"2":{"113":1}}],["efficacy",{"2":{"660":1}}],["e∣c",{"2":{"515":2}}],["emit",{"2":{"1499":3,"1500":4}}],["emitter",{"2":{"1499":15}}],["employee",{"2":{"1425":2}}],["empirical",{"2":{"99":1,"190":5,"191":3,"192":1}}],["email",{"2":{"1336":2,"1410":1,"1419":2,"1428":6,"1431":2,"1434":2,"1435":5}}],["embed类似",{"2":{"750":1}}],["embeds",{"2":{"680":6,"703":9,"714":5}}],["embedding中将被固定",{"2":{"703":1}}],["embeddings=len",{"2":{"766":2}}],["embeddings=20",{"2":{"762":2}}],["embeddings",{"2":{"702":12,"713":6,"731":1}}],["embedding",{"2":{"375":12,"404":1,"407":12,"408":12,"573":13,"574":12,"677":12,"680":9,"702":18,"703":15,"713":11,"714":8,"734":25,"748":6,"754":2,"762":7,"766":6,"767":2}}],["embed",{"2":{"375":25,"376":3,"573":19,"574":18,"576":3,"674":9,"677":6,"680":5,"702":16,"713":10,"750":4,"751":4,"762":9,"763":18,"766":1,"768":7}}],["eos>",{"2":{"567":1,"568":1,"569":2,"577":8}}],["eos",{"2":{"363":1,"512":3,"513":6,"515":2,"567":1,"568":2,"572":2,"576":1,"577":1}}],["eye",{"2":{"355":6,"357":1,"392":8,"1090":2,"1094":1}}],["ey∼p",{"2":{"42":1}}],["elmo",{"2":{"733":2}}],["elmo对上下文进行双向编码",{"2":{"733":1,"739":1}}],["elmo的表示将作为附加特征添加到下游任务的现有监督模型中",{"2":{"731":1}}],["elmo将来自预训练的双向长短期记忆网络的所有中间层表示组合为输出表示",{"2":{"731":1}}],["elmo是为输入序列中的每个单词分配一个表示的函数",{"2":{"731":1}}],["elems",{"2":{"748":6}}],["elem",{"2":{"726":2,"748":2}}],["elementwise",{"2":{"1018":1}}],["element",{"2":{"77":4,"573":2,"990":1,"1017":3,"1528":1}}],["elif",{"0":{"1223":1},"2":{"146":2,"206":1,"211":1,"362":1,"848":1,"959":5,"981":1,"1223":2}}],["else",{"0":{"1223":1},"2":{"57":2,"67":3,"71":1,"137":2,"206":2,"211":1,"321":1,"325":4,"334":5,"335":10,"362":1,"368":8,"408":8,"424":1,"446":5,"472":10,"501":3,"502":4,"565":1,"575":1,"582":2,"583":1,"584":1,"634":1,"635":5,"667":1,"668":3,"682":6,"687":3,"692":2,"715":3,"720":1,"721":2,"738":3,"757":1,"826":3,"848":1,"863":3,"874":2,"883":2,"889":1,"890":2,"893":2,"901":1,"902":1,"932":9,"945":3,"959":3,"966":2,"977":4,"981":2,"1092":1,"1223":2}}],["enum",{"2":{"1413":2}}],["enums",{"0":{"1413":1}}],["enumerate",{"2":{"67":3,"137":3,"334":1,"350":1,"357":2,"363":1,"407":4,"408":4,"424":2,"482":4,"565":1,"566":1,"582":3,"595":1,"604":1,"635":1,"686":3,"721":1,"748":1,"767":3,"836":1,"837":1,"848":1,"883":3,"894":3,"906":3,"945":6,"964":3}}],["env",{"2":{"1277":2,"1315":1}}],["environments",{"2":{"1315":1}}],["environment",{"2":{"204":1,"298":2,"1277":2}}],["en",{"2":{"717":4,"748":3,"753":1}}],["enabled",{"2":{"472":1}}],["enabled来判断当前模式是训练模式还是预测模式",{"2":{"472":1}}],["engine",{"2":{"1359":1}}],["eng",{"2":{"376":6,"409":6,"565":3,"578":6}}],["engs",{"2":{"376":7,"409":4,"578":4}}],["encoded",{"2":{"688":6,"727":24,"734":6,"736":3,"737":9,"738":12}}],["encoderblock",{"2":{"407":14,"734":3,"740":1}}],["encoderdecoder",{"2":{"376":1,"409":4,"535":8,"576":1}}],["encoder",{"2":{"375":10,"376":2,"404":1,"407":22,"408":3,"409":9,"532":5,"533":8,"535":16,"550":1,"572":1,"573":14,"574":4,"576":2,"577":4,"688":10,"713":9,"734":6,"738":6}}],["encoding中原有的字节对编码算法稍作修改",{"2":{"722":1}}],["encoding=",{"2":{"565":1}}],["encoding",{"0":{"757":1},"2":{"330":1,"379":1,"395":1,"398":29,"399":4,"400":1,"404":2,"407":8,"408":8,"640":1,"702":6,"713":6,"727":5,"757":2}}],["enc",{"2":{"375":48,"408":40,"409":4,"534":5,"535":16,"574":8,"577":28}}],["enter",{"2":{"820":1,"1252":1,"1525":2}}],["entailment",{"2":{"665":1,"667":1,"682":3}}],["entity",{"2":{"295":1}}],["ent",{"2":{"295":4}}],["entropy来定义损失l",{"2":{"648":1}}],["entropy中定义的熵",{"2":{"651":1}}],["entropy中",{"2":{"647":1}}],["entropy中的损失函数",{"2":{"646":1}}],["entropy是根据交叉熵损失函数的定义实现的",{"2":{"638":1}}],["entropy",{"2":{"291":1,"633":6,"635":1,"646":2,"648":1,"650":2,"765":2,"865":2}}],["end=8",{"2":{"242":1}}],["end",{"2":{"23":4,"31":4,"37":4,"52":4,"64":4,"75":4,"83":4,"97":4,"105":4,"111":4,"118":4,"124":4,"133":4,"137":2,"139":4,"144":4,"147":5,"148":2,"150":4,"178":4,"215":4,"223":4,"227":4,"239":4,"250":4,"268":4,"278":3,"280":4,"323":4,"325":3,"328":4,"337":4,"344":4,"353":4,"359":4,"366":4,"372":3,"378":3,"384":3,"394":3,"402":3,"411":3,"414":3,"416":4,"418":3,"420":4,"422":4,"423":2,"424":3,"426":4,"428":4,"431":1,"434":4,"436":5,"437":2,"439":4,"444":4,"445":3,"446":3,"449":3,"453":4,"465":4,"477":4,"485":4,"491":4,"498":4,"505":4,"507":2,"511":4,"525":3,"531":3,"537":3,"549":3,"563":3,"571":3,"580":3,"586":4,"591":4,"592":7,"593":4,"594":4,"596":3,"597":4,"607":4,"621":4,"628":4,"638":4,"671":3,"684":3,"690":3,"697":3,"706":3,"717":3,"724":3,"729":3,"740":3,"753":3,"757":7,"759":3,"770":3,"779":3,"790":9,"791":2,"792":1,"793":1,"794":6,"796":6,"797":3,"799":3,"818":4,"819":8,"820":8,"821":10,"822":1,"823":6,"827":5,"829":2,"830":5,"839":3,"856":3,"860":3,"868":3,"873":3,"876":3,"882":2,"885":3,"893":5,"897":3,"898":3,"910":3,"915":3,"929":3,"935":3,"942":3,"951":3,"966":3,"972":3,"979":4,"986":4,"998":3,"1004":4,"1005":3,"1009":4,"1015":4,"1017":6,"1020":2,"1021":4,"1022":2,"1024":4,"1038":4,"1092":4,"1109":1,"1111":1,"1444":2}}],["e",{"2":{"60":5,"115":5,"209":1,"247":4,"293":2,"515":6,"578":2,"674":10,"757":2,"813":2,"816":3,"817":2,"1036":1,"1076":1,"1250":2}}],["eponymous",{"2":{"253":1}}],["epoch+1",{"2":{"67":2}}],["epochs指定",{"2":{"635":1}}],["epochs和学习率lr都是超参数",{"2":{"605":1}}],["epochs=5",{"2":{"874":3}}],["epochs=1500",{"2":{"266":1}}],["epochs=400",{"2":{"263":4}}],["epochs=4",{"2":{"81":2}}],["epochs=2",{"2":{"80":5,"81":2,"91":1}}],["epochs=num",{"2":{"67":2,"137":1}}],["epochs",{"2":{"67":21,"68":6,"71":12,"72":8,"73":8,"80":9,"81":8,"91":1,"137":22,"175":8,"176":4,"210":8,"211":4,"212":2,"213":5,"221":8,"225":5,"263":8,"275":16,"278":16,"326":8,"335":19,"350":8,"376":2,"409":8,"463":2,"473":4,"474":1,"483":2,"489":2,"496":2,"503":2,"509":2,"523":6,"529":2,"546":6,"547":4,"560":6,"561":4,"576":14,"595":8,"605":5,"626":2,"635":6,"681":6,"688":6,"704":6,"715":6,"767":11,"828":9,"837":9,"865":6,"874":3,"883":12,"894":12,"895":6,"896":3,"898":1,"906":12,"907":6,"908":3,"910":1,"927":9,"963":9}}],["epoch",{"2":{"54":2,"57":2,"59":1,"67":12,"71":2,"72":7,"80":8,"81":8,"129":4,"137":21,"210":4,"211":1,"213":1,"263":24,"275":12,"278":12,"335":25,"350":12,"392":20,"576":16,"595":12,"605":13,"635":8,"767":9,"828":9,"837":9,"883":12,"894":14,"906":14,"927":17,"963":9}}],["ep",{"2":{"190":1}}],["eps=1e",{"2":{"472":4,"852":1}}],["epsilon",{"2":{"262":2,"271":2}}],["eps",{"2":{"21":12,"27":3,"28":8,"34":8,"35":8,"108":11,"472":11,"852":1,"1124":3,"1125":2}}],["equation",{"2":{"1085":1,"1086":2}}],["equations",{"2":{"1069":1}}],["eqref",{"2":{"55":1,"59":1,"115":8,"130":1,"155":1,"156":4,"158":1,"160":2,"165":2,"190":2,"191":2,"192":2,"270":1,"307":5,"308":1,"309":1,"310":1,"312":4,"318":1,"338":1,"339":1,"340":7,"342":1,"367":1,"369":1,"374":2,"388":9,"389":2,"391":1,"396":1,"397":1,"400":1,"467":2,"515":1,"519":1,"527":1,"541":4,"578":2,"610":3,"613":1,"644":1,"646":1,"647":2,"648":1,"651":1,"674":2,"675":1,"680":3,"707":5,"708":4,"709":2,"711":1,"742":3,"744":3,"784":2,"785":1,"981":2,"992":2,"994":1,"998":2}}],["eq",{"2":{"42":1,"115":9,"130":1,"155":2,"156":5,"158":2,"160":2,"162":1,"164":1,"165":2,"190":4,"191":3,"192":2,"270":1,"307":10,"308":1,"309":1,"310":1,"312":8,"318":2,"338":2,"340":1,"342":2,"367":3,"369":2,"370":1,"374":2,"387":1,"388":12,"389":3,"391":1,"396":1,"397":1,"398":1,"400":1,"467":3,"515":2,"519":2,"527":2,"574":1,"578":3,"610":5,"611":1,"613":2,"643":1,"644":2,"646":2,"647":2,"648":1,"650":1,"651":1,"674":3,"675":2,"680":3,"707":5,"708":7,"709":3,"711":1,"742":5,"743":1,"744":5,"783":1,"784":4,"786":1,"981":3,"990":1,"992":3,"994":1,"998":2}}],["eqlabel",{"2":{"42":1,"54":2,"57":1,"59":1,"115":5,"155":1,"156":1,"158":1,"162":1,"164":1,"190":2,"191":1,"307":5,"312":4,"318":1,"338":1,"339":1,"340":1,"342":1,"367":2,"369":1,"370":1,"387":1,"388":3,"389":1,"398":1,"467":1,"515":1,"519":1,"527":1,"541":1,"574":1,"578":1,"610":2,"611":1,"613":1,"643":1,"644":1,"646":1,"650":1,"674":1,"675":1,"708":3,"709":1,"742":2,"743":1,"744":2,"783":1,"784":2,"785":1,"786":1,"981":1,"990":1,"992":1}}],["eager模式",{"2":{"820":1}}],["eating",{"2":{"658":2}}],["early",{"2":{"254":1}}],["ea",{"2":{"32":1,"35":1,"38":1,"66":1,"73":1,"86":1,"135":1,"170":1,"198":1,"231":1,"235":1,"248":1,"300":9,"301":3,"316":1,"341":1,"345":1,"349":1,"356":1,"380":1,"395":3,"397":1,"398":1,"403":2,"411":2,"422":1,"467":1,"475":1,"478":1,"485":1,"486":1,"491":3,"500":1,"505":2,"538":2,"564":2,"572":2,"578":1,"581":1,"642":1,"658":1,"660":1,"666":1,"672":1,"700":1,"712":1,"718":1,"722":1,"726":1,"731":3,"732":1,"733":1,"737":1,"756":1,"757":2,"759":1,"773":1,"775":1,"782":2,"788":1,"795":1,"811":2,"826":1,"832":3,"840":2,"842":1,"843":1,"844":1,"856":1,"929":1,"936":3,"937":2,"939":1,"940":1,"942":2,"952":1,"953":1,"966":2,"1002":1}}],["ex1如果我想确保我已经实现了程序",{"2":{"1094":1}}],["ex1",{"2":{"1094":1}}],["exercises",{"2":{"1094":1}}],["exec",{"2":{"817":2,"1344":1,"1392":1}}],["ex∼p",{"2":{"1036":1}}],["exhaustion",{"2":{"980":1}}],["exhaustive",{"2":{"512":1,"514":1}}],["exitflag",{"2":{"1109":1,"1111":1}}],["exit",{"2":{"820":1,"1252":1}}],["exists",{"2":{"206":1}}],["exist",{"2":{"206":1,"890":1,"1011":1}}],["exc",{"2":{"1252":3}}],["exclusive",{"2":{"1027":1}}],["exclude",{"2":{"775":1,"1313":1,"1434":1,"1435":2}}],["excel",{"2":{"1297":2,"1301":1}}],["excellent",{"2":{"295":2}}],["exception",{"2":{"1249":1}}],["except",{"2":{"827":1,"1236":2,"1250":1}}],["example",{"0":{"1170":1},"1":{"1171":1,"1172":1,"1173":1,"1174":1},"2":{"284":1,"289":1,"1047":2,"1193":1,"1364":1,"1367":1,"1370":3,"1419":1,"1431":1}}],["examples参数值",{"2":{"571":1}}],["examples=600",{"2":{"569":1}}],["examples=none",{"2":{"566":1}}],["examples个文本序列对进行词元",{"2":{"566":1}}],["examples",{"0":{"0":1,"6":1},"1":{"1":1,"2":1,"3":1,"4":1,"5":1,"7":1,"8":1,"9":1},"2":{"67":3,"137":6,"566":2,"569":1,"599":4,"600":8,"668":3,"687":3,"722":21,"883":3,"894":3,"906":3,"932":6,"947":3,"963":3,"1101":1,"1102":1}}],["extends",{"2":{"1409":1,"1416":2,"1417":1,"1423":3,"1425":1,"1432":1,"1433":3,"1434":4,"1435":2}}],["extend",{"2":{"722":3,"896":3,"908":3,"1454":2}}],["extensions",{"2":{"6":1,"9":1}}],["extension",{"0":{"6":1},"1":{"7":1,"8":1,"9":1},"2":{"1017":1}}],["extrapolation",{"2":{"345":1}}],["extractall",{"2":{"206":1}}],["extract",{"2":{"206":1,"565":1,"666":3,"667":3,"669":3,"679":1,"686":3,"687":3,"692":1,"695":3,"722":3,"725":1,"748":1,"772":1,"864":1,"866":3,"872":1,"889":1,"901":1,"920":7,"927":3,"932":3,"945":1,"949":3}}],["ext",{"2":{"206":3}}],["ex",{"2":{"42":2}}],["expires",{"2":{"1371":1}}],["expm1",{"2":{"1183":1}}],["expectation",{"2":{"1036":1}}],["experiments",{"2":{"1026":4}}],["experimental",{"2":{"80":1,"81":1,"137":1,"446":3}}],["experts",{"2":{"660":1}}],["expression",{"2":{"1021":1}}],["express",{"2":{"798":1,"813":1,"1543":1}}],["express总线带宽来移动数据对我们是有利的",{"2":{"797":1}}],["express总线带宽来移动数据是有利的",{"2":{"797":2}}],["expansion",{"2":{"479":1}}],["expand",{"2":{"369":4,"375":4,"388":7,"390":4,"391":5,"392":8,"399":4,"574":1,"575":2,"577":4,"584":1,"727":3,"848":1,"852":1,"853":2,"854":5,"863":1,"866":1,"919":1,"932":1,"964":1}}],["exploding",{"2":{"241":1}}],["exponential",{"2":{"114":3}}],["export",{"2":{"7":1,"821":1,"1277":1,"1444":1,"1445":1,"1451":1,"1454":2,"1469":2,"1471":3,"1474":1,"1479":1,"1490":2,"1491":1,"1493":1,"1495":1,"1499":1,"1520":1}}],["exp⁡",{"2":{"64":1,"191":2,"342":1,"578":1,"624":6,"655":1,"744":1}}],["exp",{"2":{"41":2,"114":1,"236":1,"237":2,"335":4,"578":1,"616":1,"631":8,"765":1,"784":1,"854":1,"1018":4,"1107":1}}],["h4>汽车",{"2":{"1503":2}}],["h4>资产",{"2":{"1503":2}}],["h4>y",{"2":{"1501":1}}],["h4>x",{"2":{"1501":1}}],["h4>d",{"2":{"1501":1}}],["h4>c",{"2":{"1501":1}}],["h4>b",{"2":{"1501":1}}],["h4>a",{"2":{"1501":1}}],["h4>父给我的车",{"2":{"1497":1}}],["h4>我的玩具",{"2":{"1497":1}}],["h4>我的车",{"2":{"1497":1}}],["h4>儿子给的玩具",{"2":{"1497":1}}],["h4>",{"2":{"1497":4,"1501":6,"1503":4}}],["hmr",{"2":{"1444":1}}],["hmm所示",{"2":{"519":1}}],["hmm",{"2":{"519":4}}],["hθ",{"2":{"1063":1,"1064":2,"1069":5,"1080":3,"1081":7,"1084":6,"1086":2,"1093":2,"1099":1,"1100":2,"1101":2,"1107":2,"1108":1,"1109":16,"1110":11,"1112":4,"1115":4,"1116":4,"1117":4,"1120":5,"1131":3,"1132":2,"1143":1,"1146":2,"1165":1,"1166":1,"1168":1}}],["h表示一个函数",{"2":{"1063":1}}],["h来表示感染艾滋病病毒的状态",{"2":{"1035":1}}],["h的数值结果接近2",{"2":{"981":1}}],["h的梯度计算",{"2":{"165":1}}],["h行和fmap",{"2":{"912":1}}],["hpc",{"2":{"813":1}}],["hbm2或者gddr6",{"2":{"811":1}}],["hdd正迅速降级为归档存储和低级存储",{"2":{"804":1}}],["hdd",{"2":{"804":1,"813":1}}],["hc",{"2":{"558":8,"559":8}}],["hf",{"2":{"558":8,"559":8}}],["hr>",{"2":{"1464":1,"1471":1}}],["href=",{"2":{"1507":1}}],["href",{"2":{"1048":1}}],["hr",{"2":{"544":8,"545":8}}],["hz",{"2":{"544":8,"545":8}}],["h中的rt和ht−1",{"2":{"541":1}}],["h中的隐状态进行计算",{"2":{"527":1}}],["h~t=tanh⁡",{"2":{"541":1}}],["h~t∈rn×h",{"2":{"541":1}}],["h←t=ϕ",{"2":{"521":1}}],["h←t∈rn×h",{"2":{"521":1}}],["h→t=ϕ",{"2":{"521":1}}],["h→t∈rn×h和",{"2":{"521":1}}],["hj",{"2":{"519":2}}],["hj−1",{"2":{"307":1}}],["h3>加载中",{"2":{"1523":1}}],["h3>我是app组件",{"2":{"1523":1}}],["h3>我是孙组件",{"2":{"1503":1}}],["h3>孙组件",{"2":{"1501":1}}],["h3>子组件",{"2":{"1497":1,"1501":1}}],["h3>父组件",{"2":{"1497":1,"1501":1,"1503":1}}],["h3>",{"2":{"1468":1,"1497":2,"1501":3,"1503":2,"1506":2,"1507":2,"1523":2}}],["h3",{"2":{"519":1,"834":12,"1468":1}}],["h3∣h2",{"2":{"519":1}}],["h和w分别是特征图的通道数",{"2":{"915":1}}],["h和w",{"2":{"340":1}}],["hq",{"2":{"331":8,"332":8,"544":8,"545":8,"558":8,"559":8}}],["hh",{"2":{"331":8,"332":8,"340":8,"544":8,"545":8,"573":3,"574":3}}],["htm",{"2":{"1364":1}}],["htmlinputelement>$event",{"2":{"1500":1}}],["htmlelement>t1",{"2":{"1468":1}}],["htmlelement",{"2":{"1468":1}}],["html后",{"2":{"1444":1}}],["html",{"2":{"1306":1,"1363":1,"1364":2,"1367":1,"1370":2,"1444":1,"1498":1,"1522":1,"1533":1,"1539":1}}],["ht∈rn×h",{"2":{"556":1}}],["ht的形状会发生怎样的变化",{"2":{"525":1}}],["ht的依次求和",{"2":{"519":1}}],["ht−2",{"2":{"519":1}}],["ht−2∏t=1t−2p",{"2":{"519":1}}],["ht−1和h~t",{"2":{"542":1}}],["ht−1∈rn×h",{"2":{"540":1}}],["ht−1∣ht−2",{"2":{"519":1}}],["ht−1∏t=1t−1p",{"2":{"519":1}}],["ht−1之间的关系可知",{"2":{"340":1}}],["ht−1whh",{"2":{"340":1}}],["ht−1",{"2":{"307":7,"310":2,"338":1,"347":1,"519":3,"573":1}}],["ht∏t=1t−1p",{"2":{"519":1}}],["ht∏t=1tp",{"2":{"519":1}}],["ht+1",{"2":{"519":1}}],["ht+1∣ht",{"2":{"519":2}}],["htp",{"2":{"519":2}}],["ht选择构成的",{"2":{"519":1}}],["ht∣ht−1",{"2":{"519":10}}],["ht中看到",{"2":{"312":1}}],["ht=ot⊙tanh⁡",{"2":{"556":1}}],["ht=zt⊙ht−1+",{"2":{"542":1}}],["ht=ϕ",{"2":{"340":1}}],["ht=whxxt+whhht−1",{"2":{"312":1}}],["ht=f",{"2":{"307":1,"338":1,"573":1}}],["ht既依赖于ht−1又依赖于wh",{"2":{"307":1}}],["ht",{"2":{"307":10,"308":1,"309":1,"310":1,"312":6,"338":2,"340":1,"374":2,"519":10,"527":2,"573":2}}],["http2",{"2":{"1371":1}}],["http",{"2":{"206":1,"692":1,"1047":4,"1359":1,"1364":2,"1365":1,"1368":1,"1369":1,"1371":2}}],["https",{"0":{"1370":1},"2":{"86":1,"207":1,"445":1,"666":3,"686":2,"718":1,"748":2,"1121":1,"1284":1,"1306":4,"1327":1,"1444":1,"1471":1,"1495":1}}],["hsu",{"2":{"301":1}}],["h也被称为隐藏层变量",{"2":{"232":1}}],["hooks",{"2":{"1471":2,"1530":1,"1544":1}}],["hold",{"2":{"1091":1}}],["horse",{"2":{"945":1}}],["hosted",{"2":{"1310":1}}],["hosts",{"2":{"1042":1}}],["host",{"2":{"813":1,"1368":1,"1427":5}}],["hop",{"2":{"813":2}}],["however",{"2":{"660":1}}],["ho",{"2":{"558":8,"559":8}}],["hog",{"2":{"455":1}}],["hochreiter",{"2":{"397":1,"538":1,"551":1}}],["home",{"2":{"376":2,"409":2,"578":2,"1474":5,"1477":2,"1478":2,"1479":2}}],["hoyer",{"2":{"349":1}}],["hoane",{"2":{"301":1}}],["house中描述的方式提在kaggle上提交",{"2":{"908":1}}],["house中的方法类似",{"2":{"896":1}}],["house中的房价预测任务",{"2":{"485":1}}],["house",{"2":{"204":1,"205":1,"207":3,"208":7,"467":1,"1011":2}}],["hotfix",{"2":{"1325":1}}],["hotdogs",{"2":{"872":4}}],["hotdog",{"2":{"872":4,"876":6}}],["hot函数将这样一个小批量数据转换成三维张量",{"2":{"330":1}}],["hot",{"2":{"59":2,"325":4,"330":9,"332":4,"575":3,"633":2,"640":1}}],["h是一个参数化函数",{"2":{"191":1}}],["h2>我是一个弹窗",{"2":{"1522":1}}],["h2>今日游戏榜单",{"2":{"1508":1}}],["h2>水位",{"2":{"1467":1}}],["h2>汽车",{"2":{"1465":1,"1466":1}}],["h2>汽车信息",{"2":{"1456":1,"1457":1}}],["h2>当前求和为",{"2":{"1462":1,"1470":1,"1471":1,"1490":1,"1492":1}}],["h2>性别",{"2":{"1459":1}}],["h2>测试",{"2":{"1456":1,"1457":1,"1464":1}}],["h2>游戏列表",{"2":{"1456":1,"1457":1}}],["h2>年龄",{"2":{"1445":1,"1451":1,"1454":1,"1455":1,"1459":1,"1463":1,"1464":1,"1465":1,"1466":1}}],["h2>",{"2":{"1445":2,"1451":2,"1454":2,"1455":2,"1456":3,"1457":3,"1459":3,"1462":1,"1463":2,"1464":3,"1465":3,"1466":3,"1467":2,"1468":1,"1470":1,"1471":1,"1474":1,"1490":1,"1492":1,"1508":1,"1522":1}}],["h2>姓名",{"2":{"1445":1,"1451":1,"1454":1,"1455":1,"1459":1,"1463":1,"1464":1,"1465":1,"1466":1}}],["h2∣h1",{"2":{"519":1}}],["h2",{"2":{"174":12,"519":2,"834":24,"938":1,"1467":1,"1468":1,"1474":1}}],["h1>需求",{"2":{"1467":1}}],["h1>情况五",{"2":{"1466":1}}],["h1>情况四",{"2":{"1465":1}}],["h1>情况三",{"2":{"1464":1}}],["h1>情况二",{"2":{"1463":1}}],["h1>情况一",{"2":{"1462":1}}],["h1>",{"2":{"1444":1,"1462":1,"1463":1,"1464":1,"1465":1,"1466":1,"1467":1,"1468":1}}],["h1>你好啊",{"2":{"1444":1}}],["h1∣h0",{"2":{"519":1}}],["h1⋮hh",{"2":{"381":1}}],["h1",{"2":{"174":12,"519":10,"573":2,"834":12,"1468":1}}],["h5的任何一个元素",{"2":{"171":1}}],["h=0",{"2":{"1035":6}}],["h=",{"2":{"981":1}}],["h=1∣d1=1",{"2":{"1035":3}}],["h=1",{"2":{"912":1,"1035":9}}],["h=2",{"2":{"912":1}}],["h=4",{"2":{"912":1,"915":1}}],["h=σ",{"2":{"232":1}}],["h=xw",{"2":{"232":1}}],["h=ϕ",{"2":{"162":1,"339":1,"469":1}}],["h=def∇2f",{"2":{"46":1}}],["hiv",{"2":{"1035":2,"1038":1}}],["hierarchy",{"2":{"841":1}}],["hierarchical",{"2":{"291":1,"709":1}}],["hit",{"2":{"813":6}}],["him",{"2":{"783":1,"785":1}}],["his",{"2":{"783":3,"785":2}}],["history模式",{"2":{"1476":2}}],["history",{"2":{"1474":1,"1479":1}}],["histogram",{"2":{"1148":1}}],["hist",{"2":{"566":3,"693":1,"773":1}}],["hi",{"2":{"558":8,"559":8,"709":6,"711":1,"1088":1}}],["hid",{"2":{"686":2,"726":1,"738":4}}],["hidens",{"2":{"408":1}}],["hidden和self",{"2":{"423":1,"688":1}}],["hiddenlayer",{"2":{"423":1}}],["hidden",{"2":{"232":3,"307":1,"325":2,"338":2,"340":2,"341":1,"369":4,"375":36,"423":8,"442":8,"519":1,"541":1,"688":10,"738":6,"821":2,"1099":1}}],["hidden2",{"2":{"174":2}}],["hidden1",{"2":{"174":2}}],["hiddens定义",{"2":{"734":1}}],["hiddens定义隐藏单元的数量",{"2":{"544":1,"558":1}}],["hiddens参数指定",{"2":{"674":1}}],["hiddens指定的",{"2":{"382":1}}],["hiddens=128",{"2":{"726":2}}],["hiddens=16",{"2":{"375":8,"573":4,"574":4}}],["hiddens=512",{"2":{"686":2,"690":1}}],["hiddens=256",{"2":{"686":2,"690":1,"726":2}}],["hiddens=ffn",{"2":{"686":2}}],["hiddens=num",{"2":{"674":1,"675":1,"676":1}}],["hiddens=8",{"2":{"369":4}}],["hiddens是一个可调的超参数",{"2":{"331":1}}],["hiddens的值",{"2":{"223":1}}],["hiddens",{"2":{"217":16,"325":22,"331":24,"332":36,"335":3,"369":18,"375":49,"376":3,"382":76,"396":19,"398":16,"405":10,"407":57,"408":66,"409":24,"523":6,"528":6,"544":24,"545":8,"546":6,"547":4,"558":24,"559":12,"560":6,"561":4,"573":14,"574":17,"576":3,"674":20,"675":6,"676":8,"677":12,"680":6,"686":12,"713":10,"734":32,"736":13,"737":5,"738":18}}],["hiddens2",{"2":{"173":6,"174":11}}],["hiddens1",{"2":{"173":6,"174":11}}],["hi=f",{"2":{"381":1}}],["hi−1",{"2":{"307":1}}],["hinton提出了一种新的卷积神经网络变体alexnet",{"2":{"455":1}}],["hinton",{"2":{"106":1,"170":1,"300":1,"404":1,"455":3,"832":1}}],["highlighted",{"2":{"7":2}}],["highlighting",{"0":{"7":1},"2":{"7":2}}],["hue",{"2":{"880":1}}],["hue=0",{"2":{"880":7}}],["hu",{"2":{"301":1,"929":1}}],["huang",{"2":{"300":1,"301":1,"478":1,"485":1}}],["hub下载到缓存目录中",{"2":{"206":1}}],["hub中的所有文件",{"2":{"206":1}}],["hub中的文件",{"2":{"206":1}}],["hub中的相匹配",{"2":{"206":1}}],["hub",{"2":{"79":4,"206":6,"208":2,"361":1,"565":1,"666":3,"686":6,"692":1,"718":1,"748":4,"772":1,"872":1,"889":1,"901":1,"931":1,"945":1,"1055":1,"1340":1}}],["hutter",{"2":{"72":1}}],["handler",{"2":{"1405":1}}],["ha=",{"2":{"848":1}}],["hadamard积",{"2":{"999":1}}],["hadamard",{"2":{"994":1}}],["hadjis",{"2":{"795":1}}],["haddow",{"2":{"757":1}}],["hardware中所述的真实的4路gpu服务器",{"2":{"841":1}}],["hardware中所述的真实的物理硬件",{"2":{"841":1}}],["hardware",{"2":{"800":1,"824":1}}],["hard",{"2":{"634":1,"804":1,"1333":1,"1337":1}}],["happy",{"2":{"518":1}}],["haben",{"2":{"295":1}}],["hastorun",{"2":{"844":1}}],["hasattr",{"2":{"635":2,"981":2}}],["has",{"2":{"295":1,"981":3}}],["hash模式",{"2":{"1476":2}}],["hashed",{"2":{"1207":1}}],["hash",{"2":{"206":2,"1362":1}}],["hashlib",{"2":{"206":2}}],["hat和下一句预测nsp",{"2":{"738":1}}],["hat和y分别作为预测的概率分布和标签",{"2":{"634":1}}],["hat是矩阵",{"2":{"634":1}}],["hat中概率的索引",{"2":{"633":1}}],["hat的数据类型转换为与y的数据类型一致",{"2":{"634":1}}],["hat的形状相同",{"2":{"603":1}}],["hat的每个元素都是值的加权平均值",{"2":{"388":4}}],["hatch",{"2":{"566":1}}],["hat",{"2":{"67":9,"129":9,"137":9,"210":2,"220":2,"335":8,"386":2,"387":8,"388":8,"392":8,"472":9,"576":8,"603":3,"633":18,"634":16,"635":13,"676":6,"677":6,"726":12,"736":17,"737":9,"738":16,"834":6,"896":6,"922":6,"923":6,"924":5,"925":8,"927":12}}],["hazan",{"2":{"25":1,"26":1}}],["hypotheses",{"2":{"667":2,"668":6,"677":6,"1097":1}}],["hypothesis",{"2":{"665":1,"668":9,"682":12,"687":19,"1063":1,"1107":1,"1130":1}}],["hyperparameter",{"2":{"613":2}}],["hyperparams",{"2":{"21":8,"28":8,"34":19,"35":20,"80":16,"81":8,"91":12,"108":12}}],["hybrid",{"2":{"821":3,"893":1}}],["hybridblock",{"2":{"821":1,"893":1}}],["hybridnet",{"2":{"821":3}}],["hybridization",{"2":{"426":1}}],["hybridize",{"2":{"67":1,"426":1,"816":1,"819":1,"820":1,"821":1,"824":1,"874":1,"895":1,"896":1,"907":1,"908":1}}],["hybridsequential类是hybridblock的子类",{"2":{"818":1}}],["hybridsequential",{"2":{"67":1,"819":1,"862":1,"893":2,"905":1}}],["hello",{"2":{"1089":5,"1216":1,"1229":1,"1244":3,"1257":1,"1401":1,"1407":1,"1430":1,"1433":1}}],["help函数",{"2":{"1090":1}}],["help",{"2":{"755":1,"1007":3,"1090":1}}],["helping",{"2":{"755":1}}],["helped",{"2":{"755":1}}],["helps",{"2":{"755":1}}],["height值",{"2":{"1467":1}}],["height=bbox",{"2":{"858":1}}],["height",{"2":{"848":15,"946":7,"1433":2,"1467":7}}],["her",{"2":{"756":1}}],["hennessy",{"2":{"800":1}}],["hendrycks",{"2":{"740":1}}],["hence",{"2":{"59":1,"191":1}}],["header",{"2":{"1368":2,"1371":1}}],["head~3",{"2":{"1334":1}}],["heads=2",{"2":{"726":2}}],["heads=4和num",{"2":{"690":1}}],["heads=4",{"2":{"686":4}}],["heads次",{"2":{"382":4}}],["heads",{"2":{"382":96,"396":8,"407":16,"408":20,"409":17,"686":4,"734":10,"738":6}}],["head",{"0":{"1323":1},"2":{"379":1,"380":3,"404":1,"409":12,"821":1,"1323":4,"1333":1}}],["heatmaps",{"2":{"357":2,"369":1,"370":1,"376":3,"388":4,"392":4,"399":4,"409":4}}],["heatmaps函数来显示注意力权重",{"2":{"357":1}}],["heatmaps函数",{"2":{"357":1}}],["heess",{"2":{"356":1}}],["hedonic",{"2":{"345":1}}],["hebb",{"2":{"299":2}}],["hey",{"2":{"282":5}}],["he",{"2":{"235":1,"300":1,"376":2,"409":2,"422":1,"500":1,"505":2,"578":2,"682":2,"727":3,"826":1,"936":2,"939":1,"940":1}}],["hexdigest",{"2":{"206":1}}],["hess",{"2":{"59":3}}],["hessian",{"2":{"26":1}}],["h很容易计算",{"2":{"59":1}}],["h⪰0",{"2":{"46":1}}],["h",{"2":{"41":4,"61":1,"94":3,"122":3,"126":6,"146":8,"153":3,"154":2,"155":3,"158":1,"162":1,"164":1,"170":1,"191":3,"219":8,"232":1,"241":5,"331":8,"332":28,"339":2,"340":12,"341":2,"381":1,"382":1,"436":4,"527":2,"541":4,"544":8,"545":48,"559":32,"582":1,"585":1,"650":1,"676":7,"687":27,"743":1,"757":2,"848":40,"858":5,"912":19,"938":1,"964":9,"968":3,"981":9,"982":1,"1063":6,"1080":1,"1112":1,"1120":2,"1165":1}}],["1k",{"2":{"1371":1}}],["1kb",{"2":{"813":1}}],["1p",{"2":{"1154":1}}],["1个百万到1000百万",{"2":{"1141":1}}],["1m∑i=1m",{"2":{"1116":1,"1117":1,"1160":2}}],["1mb",{"2":{"813":7}}],["1到4或者其它数值",{"2":{"1112":1}}],["1到1",{"2":{"1091":1}}],["1到1之间",{"2":{"1082":1}}],["1直到",{"2":{"1111":1}}],["1一直到10",{"2":{"1092":1}}],["1==2",{"2":{"1088":2}}],["1离散输出的问题",{"2":{"1063":1}}],["1长度的总和",{"2":{"1018":1}}],["1长度",{"2":{"1018":1}}],["1来调用此自动计算出维度的功能",{"2":{"1017":1}}],["1为例",{"2":{"890":1}}],["1x",{"2":{"874":4}}],["1x1conv=true",{"2":{"501":4,"502":4,"826":3,"893":1}}],["1x1conv=true时",{"2":{"501":1}}],["1x1conv=false时",{"2":{"501":1}}],["1x1conv=false",{"2":{"501":4,"893":1}}],["1x1conv",{"2":{"501":4,"893":1}}],["1x1",{"2":{"122":3}}],["1x1展示了使用1×1卷积核与3个输入通道和2个输出通道的互相关计算",{"2":{"122":1}}],["1x1卷积层后接5x5卷积层",{"2":{"487":4}}],["1x1卷积层后接3x3卷积层",{"2":{"487":4}}],["1x1卷积",{"2":{"122":1}}],["1x12+2x22来观察rmsprop算法的轨迹",{"2":{"108":1}}],["1x12+2x22的2d示例似乎相当牵强",{"2":{"93":1}}],["1x12+2x22",{"2":{"27":1,"31":1,"87":1}}],["1类别",{"2":{"854":1}}],["1代表猫",{"2":{"853":1,"854":1}}],["1代表从黑色到白色的边缘",{"2":{"128":1}}],["1插入队列",{"2":{"792":1}}],["1亿个参数",{"2":{"726":1,"728":1}}],["1亿和3",{"2":{"656":1}}],["1和0的或运算",{"2":{"1088":1}}],["1和2",{"2":{"853":1}}],["1和d",{"2":{"701":1}}],["1和1之间",{"2":{"407":4}}],["1表示用于填充的非法边界框",{"2":{"932":1}}],["1表示背景或在非极大值抑制中被移除了",{"2":{"854":1}}],["1表示两个边界框完全重合",{"2":{"849":1}}],["1表示",{"2":{"692":1}}],["1表示参数维度仍然未知",{"2":{"418":1}}],["1|b|∑i∈bl",{"2":{"605":1}}],["1所示",{"2":{"554":1}}],["1lαlog⁡p",{"2":{"515":1}}],["1中的图1",{"2":{"505":1}}],["1416",{"2":{"1080":1}}],["14会降低bleu",{"2":{"578":1}}],["144",{"2":{"488":4}}],["14",{"0":{"1156":1,"1157":1,"1158":1,"1159":1,"1160":1,"1161":1,"1162":1,"1471":1},"2":{"436":1,"1061":1,"1074":1,"1088":1,"1089":1,"1093":1,"1111":1,"1126":1,"1140":1,"1156":1,"1157":1,"1158":1,"1159":1,"1160":1,"1161":1,"1162":1,"1169":1,"1174":1,"1184":1,"1185":1,"1193":7,"1216":1,"1255":1,"1315":1}}],["1402191137182194914371471448",{"2":{"1072":1}}],["140000",{"2":{"1011":1}}],["140",{"2":{"436":1,"945":1}}],["1460",{"2":{"299":1}}],["1≤x≤3",{"2":{"1028":3}}],["1≤i≤n",{"2":{"396":1}}],["1≤t≤t",{"2":{"315":1}}],["1d或2d张量",{"2":{"368":4}}],["110",{"2":{"1121":1}}],["11+e−θtx",{"2":{"1109":1}}],["115",{"2":{"945":1}}],["116",{"2":{"813":1}}],["11使用可复用的卷积块构造网络",{"2":{"510":1}}],["11比alexnet计算量更大",{"2":{"509":1}}],["112",{"2":{"488":8,"858":1}}],["112+288+64+64=528和256+320+128+128=832",{"2":{"488":1}}],["11的更大窗口来捕捉对象",{"2":{"461":4}}],["11",{"0":{"1137":1,"1138":1,"1139":1,"1140":1,"1141":1,"1468":1,"1485":1},"2":{"362":1,"508":2,"945":1,"1040":1,"1065":1,"1067":1,"1075":1,"1077":1,"1089":4,"1109":1,"1116":1,"1121":6,"1125":1,"1133":1,"1137":1,"1138":1,"1139":1,"1140":1,"1141":2,"1144":1,"1193":5}}],["111",{"2":{"102":2,"1121":1}}],["18作为源模型",{"2":{"873":1}}],["18中大部分的预训练层",{"2":{"862":1}}],["18的模型要复杂得多",{"2":{"828":1}}],["18模型的最后几层包括全局平均汇聚层和全连接层",{"2":{"862":1}}],["18模型来提取图像特征",{"2":{"862":1}}],["18模型",{"2":{"826":3,"883":1,"893":3}}],["18",{"0":{"1171":1,"1172":1,"1173":1,"1174":1},"2":{"502":2,"582":5,"826":1,"830":2,"1171":1,"1172":1,"1173":1,"1174":1,"1193":4,"1445":1,"1451":1,"1454":1,"1455":1,"1459":1,"1463":1,"1464":1,"1465":1,"1466":1,"1468":1,"1469":2,"1518":1}}],["18保持一致",{"2":{"482":1}}],["1890",{"2":{"299":1}}],["1855",{"2":{"299":1}}],["1的目标是在给定问题和段落的情况下预测段落中文本片段的开始和结束",{"2":{"660":1}}],["1的小批量随机梯度下降作为优化算法",{"2":{"625":1}}],["1的paddlepaddle版本",{"2":{"445":1}}],["1的对应关系",{"2":{"295":1}}],["1的正态分布",{"2":{"262":1}}],["1^2",{"2":{"262":1}}],["178100",{"2":{"1011":1}}],["1795年",{"2":{"619":1}}],["1777",{"2":{"299":1}}],["1705",{"2":{"299":1}}],["17",{"0":{"1164":1,"1165":1,"1166":1,"1167":1,"1168":1,"1169":1},"2":{"230":1,"813":1,"1164":1,"1165":1,"1166":1,"1167":1,"1168":1,"1169":1,"1193":6}}],["13888888888",{"2":{"1445":1,"1451":1,"1454":1,"1455":1}}],["1306",{"2":{"1035":1}}],["130",{"2":{"945":1}}],["13",{"0":{"1150":1,"1151":1,"1152":1,"1153":1,"1154":1,"1470":1},"2":{"230":1,"655":3,"1089":1,"1090":1,"1092":1,"1122":1,"1138":1,"1150":1,"1151":2,"1152":1,"1153":1,"1154":1,"1160":1,"1162":1,"1165":1,"1168":1,"1181":1,"1193":5}}],["1与存储在data",{"2":{"206":1}}],["1密钥",{"2":{"206":1}}],["1f",{"2":{"137":4,"335":8,"576":4,"726":3,"767":3,"828":3,"837":3,"883":3,"894":3,"906":3,"963":3,"966":6}}],["1f77b4",{"2":{"57":3}}],["1×2",{"2":{"1089":1}}],["1×2和2×2的目标可以分别以4",{"2":{"912":1}}],["1×0+2×1+4×2+5×3=25",{"2":{"126":1}}],["1×1仍然十分流行",{"2":{"122":1}}],["1×1卷积层",{"2":{"488":1}}],["1×1卷积层通常用于调整网络层的通道数量和控制模型复杂性",{"2":{"123":1}}],["1×1卷积层相当于全连接层",{"2":{"123":1}}],["1×1卷积层需要的权重维度为co×ci",{"2":{"122":1}}],["1×1卷积失去了卷积层的特有能力",{"2":{"122":1}}],["1×1卷积",{"2":{"122":1}}],["1×1",{"0":{"122":1},"2":{"912":1}}],["1×1+2×2+4×3+5×4",{"2":{"120":1}}],["1+β2",{"2":{"1154":1}}],["1+eθtx",{"2":{"1109":9}}],["1+e−θtx",{"2":{"1109":3}}],["1+exp⁡",{"2":{"191":2,"236":1,"242":1}}],["1+0",{"2":{"880":1}}],["1+sin⁡x",{"2":{"118":1}}],["1+cos⁡",{"2":{"72":1}}],["1n∑t=1n−log⁡p",{"2":{"342":1}}],["1n∑i=1n",{"2":{"210":1}}],["1n",{"2":{"116":1}}],["19模型来抽取图像特征",{"2":{"920":1}}],["192=1",{"2":{"488":2}}],["192",{"2":{"488":19,"945":6}}],["1943",{"2":{"300":1}}],["1949",{"2":{"299":1}}],["1988",{"2":{"564":1,"811":1}}],["1987",{"2":{"302":1}}],["1980",{"2":{"300":1}}],["1985",{"2":{"299":1}}],["1970",{"2":{"300":1}}],["1904",{"2":{"299":1}}],["1950",{"2":{"299":1}}],["1954",{"2":{"299":1}}],["1958",{"2":{"105":1}}],["1912",{"2":{"299":1}}],["1916",{"2":{"299":1}}],["1964提出了一个更好的想法",{"2":{"388":1}}],["1964提出的",{"2":{"86":1}}],["1964和",{"2":{"388":1}}],["1964年提出的nadaraya",{"2":{"385":1}}],["1964年的nadaraya",{"2":{"379":1}}],["1962",{"2":{"299":1}}],["199",{"2":{"1432":1}}],["1991",{"2":{"1296":1}}],["1993",{"2":{"1002":1}}],["1994",{"2":{"891":6}}],["1997",{"2":{"538":1,"551":1}}],["1997提出的",{"2":{"521":1}}],["1992",{"2":{"300":1}}],["1998或alexnet",{"2":{"832":1}}],["1998",{"2":{"300":1,"581":1}}],["1998中的手写数字",{"2":{"135":1}}],["1990实际上是循环神经网络中反向传播技术的一个特定应用",{"2":{"306":1}}],["1990",{"2":{"300":1,"564":1}}],["1995",{"2":{"170":1,"300":1}}],["1995年",{"2":{"170":1}}],["19",{"0":{"1176":1},"2":{"95":1,"511":1,"920":1,"1176":1,"1193":1,"1469":1}}],["167",{"2":{"1026":5}}],["16gb",{"2":{"841":1}}],["16通道的pcie4",{"2":{"840":1}}],["16xlarge和nvidia",{"2":{"842":1}}],["16xlarge上有16个",{"2":{"832":1}}],["16xlarge上有8个",{"2":{"832":1}}],["16xlarge实例上",{"2":{"830":2}}],["16或vgg",{"2":{"511":1}}],["160",{"2":{"488":12}}],["160+224+64+64=512",{"2":{"488":1}}],["16名成年男子被要求脚连脚排成一行",{"2":{"299":1}}],["1654",{"2":{"299":1}}],["16",{"0":{"1187":1,"1188":1,"1189":1,"1190":1,"1191":1,"1192":1},"2":{"67":4,"136":4,"147":3,"172":4,"350":1,"351":2,"425":6,"433":1,"473":8,"474":5,"488":8,"813":1,"938":3,"956":5,"958":3,"969":6,"1085":1,"1089":2,"1146":1,"1147":1,"1173":1,"1187":1,"1188":1,"1189":1,"1190":1,"1191":1,"1192":1,"1193":6,"1235":1,"1315":1}}],["123",{"2":{"1404":1,"1433":1}}],["127",{"2":{"1364":1,"1368":1,"1369":3,"1371":1}}],["127500",{"2":{"1011":1}}],["12∑j=1nu∑i",{"2":{"1188":1,"1190":1}}],["12∑i",{"2":{"1188":1}}],["12xlarge上有4个",{"2":{"832":1}}],["12mui⊤",{"2":{"785":1}}],["12muc⊤",{"2":{"785":1}}],["12和12",{"2":{"690":1}}],["12",{"0":{"1143":1,"1144":1,"1145":1,"1146":1,"1147":1,"1148":1,"1469":1,"1486":1},"2":{"472":1,"488":1,"813":1,"1017":8,"1018":4,"1020":2,"1060":1,"1068":1,"1089":4,"1099":1,"1100":1,"1121":1,"1124":1,"1131":1,"1133":1,"1134":1,"1139":1,"1143":1,"1144":1,"1145":2,"1146":1,"1147":1,"1148":1,"1167":1,"1180":1,"1183":1,"1193":6}}],["12u",{"2":{"436":1}}],["128个隐藏单元和2个自注意头",{"2":{"726":1}}],["128+256+64+64=512",{"2":{"488":1}}],["128",{"2":{"413":3,"462":1,"488":45,"489":1,"496":1,"502":5,"508":1,"509":1,"669":1,"687":3,"726":1,"819":6,"826":5,"834":9,"890":1,"893":1,"898":1,"902":1,"945":23,"959":15}}],["120",{"2":{"67":6,"136":6,"473":9,"474":8,"813":2,"905":3}}],["12f",{"2":{"46":1}}],["15的magic方阵值的图",{"2":{"1091":1}}],["150",{"2":{"813":1}}],["150px",{"2":{"811":1}}],["1500",{"2":{"80":1}}],["152",{"2":{"502":1}}],["152架构就有数百层",{"2":{"422":1}}],["1533",{"2":{"299":1}}],["15",{"0":{"1178":1,"1179":1,"1180":1,"1181":1,"1182":1,"1183":1,"1184":1,"1185":1},"2":{"56":1,"59":1,"71":4,"721":1,"722":4,"813":1,"853":1,"854":2,"912":2,"1089":1,"1090":2,"1091":1,"1108":1,"1133":1,"1143":1,"1159":1,"1172":1,"1178":1,"1179":1,"1180":1,"1181":1,"1182":1,"1183":1,"1184":1,"1185":1,"1188":1,"1193":8}}],["1时的ai=∅",{"2":{"1027":1}}],["1时优化变量x的轨迹",{"2":{"57":1}}],["1时",{"2":{"55":1,"95":1,"120":1,"910":1}}],["10px",{"2":{"1444":2}}],["10m",{"2":{"1371":1}}],["10n​",{"2":{"1184":1}}],["10共12个",{"2":{"1133":1}}],["10之间的呈现2倍关系的值",{"2":{"1133":1}}],["10的值",{"2":{"1092":1}}],["10的语句结构",{"2":{"1092":1}}],["102",{"2":{"1089":1}}],["1024个隐藏单元和16个自注意头",{"2":{"726":1}}],["1024",{"2":{"488":2,"734":2,"1364":1}}],["106000",{"2":{"1011":1}}],["10+1",{"2":{"956":2}}],["105",{"2":{"945":1}}],["10图像尺寸大",{"2":{"909":1}}],["10图像分类竞赛网页上的",{"2":{"889":1}}],["10图像分类问题的kaggle竞赛",{"2":{"887":1}}],["10类似",{"2":{"901":1}}],["10357张jpeg图像",{"2":{"900":1}}],["10是计算机视觉领域中的一个重要的数据集",{"2":{"887":1}}],["10数据集的图像",{"2":{"903":1}}],["10数据集的模型训练中结合多种不同的图像增广方法",{"2":{"885":1}}],["10数据集做了一个实验",{"2":{"887":1}}],["10数据集上训练",{"2":{"883":1}}],["10数据集中的图像不同",{"2":{"899":1}}],["10数据集中的前32个训练图像如下所示",{"2":{"882":1}}],["10数据集中对象的颜色和大小差异更明显",{"2":{"882":1}}],["10数据集",{"2":{"882":1,"898":1}}],["10gbe范围内",{"2":{"841":1}}],["1048576",{"2":{"206":1}}],["101",{"2":{"102":4,"1089":1}}],["100kb",{"2":{"1530":1}}],["100n",{"2":{"1404":1}}],["100×100像素的图片进行某个计算机视觉的机器学习",{"2":{"1162":1}}],["100和300的预训练glove嵌入",{"2":{"748":1}}],["100d",{"2":{"680":3,"703":3,"714":1,"748":2}}],["1000之间",{"2":{"1148":1}}],["10000之间",{"2":{"1148":1}}],["10000张图像将被用于评估",{"2":{"888":1}}],["100002j",{"2":{"400":1}}],["10000",{"2":{"398":4,"615":1,"734":2,"792":2}}],["1000",{"2":{"350":5,"351":3,"589":1,"599":1,"693":1,"790":22,"820":8,"876":2,"905":2,"977":4,"1026":8,"1148":1,"1499":1}}],["100",{"2":{"80":1,"212":1,"243":4,"262":2,"271":1,"275":4,"278":4,"300":5,"382":4,"396":4,"407":10,"408":4,"437":2,"680":3,"702":12,"713":2,"766":2,"813":2,"898":1,"977":4,"1089":1,"1092":1,"1109":1,"1111":1,"1166":1,"1262":1,"1422":1,"1456":1,"1457":1,"1467":1,"1501":1,"1503":2}}],["10",{"0":{"887":1,"1129":1,"1130":1,"1131":1,"1132":1,"1133":1,"1134":1,"1135":1,"1467":1,"1484":1},"1":{"888":1,"889":1,"890":1,"891":1,"892":1,"893":1,"894":1,"895":1,"896":1,"897":1,"898":1},"2":{"54":6,"59":3,"67":4,"68":1,"71":1,"80":3,"81":4,"95":1,"102":4,"129":4,"136":4,"137":1,"173":3,"175":4,"176":4,"217":4,"221":4,"225":8,"263":4,"290":1,"300":5,"305":1,"318":3,"326":4,"330":4,"333":2,"335":8,"350":6,"357":3,"361":1,"363":2,"369":11,"370":1,"376":1,"390":8,"398":8,"409":4,"418":2,"422":4,"423":3,"424":3,"433":1,"436":9,"437":1,"442":3,"446":4,"461":4,"463":1,"473":6,"474":4,"480":4,"481":3,"482":4,"483":1,"488":4,"489":1,"495":9,"496":1,"502":3,"503":1,"508":4,"509":1,"568":1,"575":4,"576":9,"590":1,"600":1,"623":4,"626":1,"630":4,"635":1,"721":2,"736":5,"757":1,"774":1,"775":1,"790":9,"813":4,"817":1,"827":3,"828":3,"834":6,"837":3,"852":1,"854":1,"873":1,"874":2,"883":6,"887":1,"889":5,"893":3,"907":3,"910":1,"912":3,"920":1,"925":2,"927":6,"933":6,"938":4,"956":12,"957":3,"966":3,"969":8,"1026":8,"1061":2,"1083":1,"1089":3,"1091":1,"1092":3,"1097":1,"1102":3,"1110":1,"1114":1,"1115":1,"1121":4,"1125":1,"1129":1,"1130":1,"1131":1,"1132":1,"1133":1,"1134":1,"1135":1,"1137":1,"1148":1,"1151":1,"1153":1,"1156":1,"1165":1,"1179":1,"1189":1,"1193":7,"1216":1,"1218":1,"1236":1,"1247":1,"1322":1,"1422":1,"1433":1,"1456":1,"1457":1,"1462":1,"1467":1,"1491":1,"1493":1}}],["1−",{"2":{"1120":1}}],["1−hθ",{"2":{"1109":5,"1110":4,"1117":1}}],["1−ytest",{"2":{"1130":1}}],["1−yk",{"2":{"1120":1}}],["1−y",{"2":{"1109":10,"1110":4,"1117":1,"1143":1,"1144":1,"1147":1}}],["1−pj",{"2":{"966":1}}],["1−0",{"2":{"880":1}}],["1−tf",{"2":{"773":1}}],["1−σ",{"2":{"708":1,"1147":1}}],["1−6",{"2":{"578":1}}],["1−lenlabellenpred",{"2":{"578":1}}],["1−sigmoid",{"2":{"236":1}}],["1−11+e−z",{"2":{"1143":2}}],["1−11+e−θtx",{"2":{"1109":1}}],["1−1n",{"2":{"116":2}}],["1−1",{"2":{"116":1}}],["1−γ",{"2":{"106":1,"107":3,"108":1}}],["1−ηλ",{"2":{"95":3,"270":1}}],["1−b",{"2":{"46":2}}],["1−aλm",{"2":{"1116":1}}],["1−a",{"2":{"46":2,"1121":1}}],["1−zt",{"2":{"542":1}}],["1−z",{"2":{"46":2}}],["1−λa−",{"2":{"46":1}}],["1−λ",{"2":{"40":1,"41":3,"44":4,"45":3,"46":15}}],["1−β2",{"2":{"33":1,"35":2}}],["1−β1",{"2":{"33":1}}],["1−ρ",{"2":{"20":2}}],["1v有条目1vi",{"2":{"27":1}}],["1e3",{"2":{"925":1}}],["1e6",{"2":{"368":4}}],["1e2",{"2":{"263":4}}],["1e",{"2":{"21":4,"27":1,"28":4,"34":4,"35":4,"80":1,"108":5,"122":1,"263":4,"688":3,"726":3,"750":3,"768":3,"773":1,"865":3,"907":5}}],["1",{"0":{"1058":2,"1059":1,"1060":1,"1061":1,"1063":1,"1072":1,"1080":1,"1088":1,"1097":1,"1106":1,"1114":1,"1120":1,"1129":1,"1137":1,"1143":1,"1150":1,"1156":1,"1164":1,"1171":1,"1176":1,"1178":1,"1187":1,"1214":1,"1218":1,"1223":1,"1229":1,"1239":1,"1246":1,"1254":1,"1261":1,"1266":1,"1309":1,"1317":1,"1318":2,"1319":1,"1320":1,"1321":1,"1322":1,"1323":1,"1324":1,"1325":1,"1327":1,"1332":1,"1339":1,"1361":1,"1367":1,"1374":1,"1376":1,"1380":1,"1389":1,"1397":1,"1437":1,"1438":2,"1439":1,"1440":1,"1441":1,"1443":1,"1447":1,"1473":1,"1488":1,"1497":1,"1506":1,"1510":1,"1522":1,"1535":1},"1":{"1215":1,"1267":1,"1268":1,"1269":1,"1318":1,"1319":1,"1320":1,"1321":1,"1322":1,"1323":1,"1324":1,"1325":1,"1398":1,"1399":1,"1438":1,"1439":1,"1440":1,"1441":1,"1448":1,"1449":1,"1511":1,"1512":1,"1513":1},"2":{"21":24,"27":1,"28":9,"29":4,"31":1,"34":36,"35":24,"40":1,"41":7,"44":3,"45":1,"46":6,"47":1,"50":1,"55":2,"57":15,"67":9,"68":7,"70":2,"72":1,"77":8,"79":16,"80":14,"81":8,"86":1,"87":4,"91":6,"95":4,"99":16,"101":8,"102":12,"103":2,"107":1,"108":13,"111":1,"113":12,"114":7,"115":2,"120":4,"121":1,"122":8,"126":10,"127":4,"128":3,"129":40,"136":10,"137":25,"141":28,"142":15,"145":1,"146":13,"147":13,"148":6,"162":3,"164":10,"165":1,"172":19,"174":3,"191":2,"206":1,"208":5,"209":2,"210":10,"211":10,"213":6,"219":4,"221":5,"225":4,"232":16,"235":4,"236":4,"237":4,"242":4,"243":4,"244":4,"252":4,"262":8,"263":30,"264":1,"268":1,"271":2,"273":10,"275":8,"278":14,"290":2,"291":1,"298":1,"300":8,"318":4,"320":4,"321":18,"325":12,"326":4,"332":1,"333":20,"334":1,"335":28,"337":1,"340":15,"341":1,"350":18,"351":22,"357":4,"363":2,"364":1,"368":30,"369":40,"370":15,"375":41,"376":10,"382":36,"386":5,"388":3,"390":15,"391":25,"392":51,"397":3,"398":28,"399":1,"406":5,"407":2,"408":25,"409":18,"413":4,"414":5,"418":1,"422":2,"425":8,"429":4,"430":1,"431":7,"432":2,"433":8,"435":13,"436":10,"437":6,"445":2,"446":8,"447":4,"448":4,"449":8,"451":5,"461":10,"472":21,"473":19,"474":7,"475":1,"480":1,"482":12,"483":1,"487":45,"488":17,"489":1,"495":16,"496":1,"502":14,"508":12,"509":2,"515":1,"523":3,"529":1,"540":4,"541":1,"545":5,"546":3,"553":1,"554":2,"556":1,"559":1,"560":3,"563":2,"565":1,"566":2,"568":1,"573":5,"574":21,"575":24,"576":41,"577":1,"578":9,"582":2,"588":1,"591":4,"592":2,"595":5,"599":10,"601":8,"605":6,"610":1,"613":1,"615":1,"616":5,"625":4,"631":11,"632":1,"633":5,"634":10,"635":12,"636":1,"640":7,"643":2,"648":2,"660":1,"666":4,"667":7,"668":3,"669":2,"674":9,"681":1,"682":15,"686":2,"687":1,"688":1,"692":2,"694":3,"695":6,"699":8,"702":11,"709":1,"713":3,"715":9,"718":1,"720":2,"721":2,"722":3,"726":35,"733":1,"734":35,"736":29,"737":5,"742":3,"743":1,"744":1,"748":2,"750":5,"751":2,"757":3,"762":1,"763":8,"765":28,"767":27,"768":5,"773":1,"774":2,"775":6,"776":8,"781":1,"783":1,"790":6,"792":2,"796":10,"797":1,"813":3,"816":1,"817":2,"819":4,"820":1,"821":1,"826":4,"827":4,"828":11,"834":9,"835":20,"836":2,"837":9,"842":4,"843":1,"848":34,"849":6,"851":11,"852":22,"853":6,"854":58,"858":6,"862":3,"863":39,"865":7,"866":11,"872":1,"874":1,"876":1,"879":6,"883":25,"889":2,"890":7,"891":9,"894":21,"896":6,"898":2,"902":1,"903":4,"906":24,"912":6,"919":8,"920":2,"923":2,"924":4,"925":1,"927":11,"928":1,"932":7,"933":9,"938":12,"945":15,"946":6,"947":7,"954":3,"956":3,"958":2,"959":14,"962":9,"963":12,"964":14,"966":18,"968":23,"969":13,"970":12,"977":1,"981":5,"989":1,"992":6,"993":1,"995":4,"1000":1,"1004":1,"1016":1,"1017":15,"1018":17,"1019":8,"1020":7,"1025":1,"1026":13,"1027":3,"1028":2,"1035":1,"1047":2,"1048":2,"1058":2,"1059":1,"1060":6,"1061":6,"1063":1,"1072":1,"1077":2,"1080":1,"1083":2,"1085":1,"1088":15,"1089":10,"1090":19,"1091":10,"1092":15,"1093":3,"1094":1,"1097":1,"1099":14,"1100":2,"1106":8,"1107":3,"1108":5,"1109":4,"1111":6,"1112":5,"1114":1,"1117":4,"1120":4,"1121":6,"1129":1,"1133":1,"1135":2,"1137":1,"1140":1,"1143":3,"1144":1,"1145":13,"1146":8,"1147":2,"1148":3,"1150":2,"1151":5,"1152":2,"1154":4,"1156":1,"1158":1,"1161":3,"1164":1,"1165":1,"1171":1,"1176":1,"1178":3,"1180":1,"1183":1,"1185":1,"1187":1,"1188":3,"1189":6,"1190":13,"1191":1,"1193":24,"1216":4,"1218":1,"1221":1,"1225":1,"1226":1,"1240":1,"1246":1,"1296":2,"1309":1,"1313":1,"1321":1,"1335":1,"1364":1,"1368":1,"1369":3,"1371":1,"1390":1,"1398":1,"1402":1,"1413":1,"1414":1,"1419":1,"1420":1,"1425":1,"1426":1,"1431":1,"1432":3,"1433":1,"1444":1,"1445":1,"1451":1,"1454":1,"1455":1,"1459":1,"1460":1,"1462":1,"1463":1,"1464":1,"1465":1,"1466":1,"1467":1,"1470":1,"1471":3,"1483":1,"1491":1,"1493":1,"1501":1,"1503":2}}],["nfs",{"2":{"1386":1}}],["n2|σ|12exp",{"2":{"1184":1}}],["n2d",{"2":{"397":1}}],["n×n维度的矩阵",{"2":{"1159":1}}],["n×m",{"2":{"1077":1}}],["n维向量x和y的夹角记做θ",{"2":{"1154":1}}],["n维数组",{"2":{"1023":1}}],["n要大许多",{"2":{"1148":1}}],["n个参数同时更新",{"2":{"1110":1}}],["n$",{"2":{"1093":1,"1116":1}}],["n为特征数",{"2":{"1148":1}}],["n为特征个数",{"2":{"1086":1}}],["n为列",{"2":{"1072":1}}],["n3",{"2":{"1085":1}}],["n+1",{"2":{"1080":1,"1086":1,"1093":1,"1110":1,"1116":2}}],["n+m−1",{"2":{"848":1}}],["n是任意实数",{"2":{"981":1}}],["n是一个大于1的整数",{"2":{"143":1}}],["nr",{"2":{"890":1}}],["nrows",{"2":{"635":2}}],["nrows=1",{"2":{"635":1}}],["nm",{"2":{"1187":1,"1189":3,"1190":6}}],["nms中修改变量anchors",{"2":{"856":1}}],["nms",{"2":{"854":17,"855":1,"856":1}}],["nmt函数中尝试不同的num",{"2":{"571":1}}],["nmt函数来返回数据迭代器",{"2":{"569":1}}],["nmt函数对前num",{"2":{"566":1}}],["nmt",{"2":{"376":1,"409":4,"565":4,"566":2,"568":1,"569":7,"576":1}}],["ns",{"2":{"813":19}}],["nsp的输入形状",{"2":{"737":2}}],["nsp的描述",{"2":{"720":1}}],["nsp",{"2":{"686":2,"720":4,"722":21,"726":52,"737":27,"738":16}}],["nvme",{"2":{"813":6}}],["nvlink中的结构",{"2":{"842":1}}],["nvlink可以通过设置实现跨6条链路的高达100gb",{"2":{"840":1}}],["nvlink",{"2":{"812":1,"813":4,"842":3}}],["nvidia优化了turing",{"2":{"811":1}}],["nvidia的rtx",{"2":{"802":1,"809":1}}],["nvidia最近一代的ampere",{"2":{"457":1}}],["nvidia称之为warps",{"2":{"457":1}}],["nvidia",{"2":{"300":2,"301":1,"445":1,"457":2,"813":3,"814":2}}],["nk近似条件概率",{"2":{"708":1}}],["nk的这些事件是相互独立的",{"2":{"708":1}}],["nltk",{"2":{"724":3}}],["nli",{"2":{"672":2,"673":2,"674":4,"675":3,"680":3,"685":2}}],["nlp",{"2":{"663":5,"666":3,"672":2,"685":2,"698":3,"712":2,"727":1,"733":1,"747":1,"748":1,"754":5}}],["nlabel",{"2":{"599":1}}],["n95",{"2":{"660":2}}],["n=2",{"2":{"1093":1}}],["n=6",{"2":{"636":1}}],["n=1500",{"2":{"79":4}}],["ncols=2",{"2":{"927":3}}],["ncols=1",{"2":{"635":1}}],["ncols",{"2":{"635":2}}],["nu",{"2":{"1187":1,"1188":1,"1189":2,"1190":7}}],["null",{"2":{"703":1,"714":1,"876":1,"1404":2,"1434":1}}],["nucleus",{"2":{"619":1,"1099":1}}],["numrooms",{"2":{"1011":2}}],["numref",{"2":{"19":1,"20":2,"26":1,"28":1,"30":1,"31":1,"32":5,"40":3,"49":1,"50":3,"58":1,"59":1,"66":4,"67":1,"76":2,"78":1,"80":1,"84":1,"87":1,"99":2,"100":1,"103":1,"106":1,"107":1,"108":1,"112":1,"113":1,"119":1,"120":2,"121":1,"122":1,"126":3,"130":4,"131":3,"135":2,"136":2,"137":4,"140":2,"141":1,"142":1,"145":1,"146":3,"152":1,"157":1,"163":1,"164":1,"168":1,"170":2,"171":2,"173":1,"181":2,"183":1,"191":1,"192":1,"207":2,"208":2,"209":1,"211":1,"213":1,"216":3,"220":2,"221":1,"225":1,"228":4,"229":2,"231":2,"232":1,"242":1,"246":1,"259":1,"269":1,"270":2,"275":1,"280":1,"282":2,"289":1,"291":4,"292":1,"294":1,"295":1,"297":1,"298":1,"299":1,"300":1,"304":1,"306":3,"307":1,"309":1,"311":1,"312":10,"315":1,"316":1,"317":1,"318":1,"319":3,"321":1,"324":1,"325":2,"326":1,"328":1,"329":2,"330":1,"332":1,"334":1,"335":3,"338":3,"339":2,"340":1,"341":4,"342":1,"346":1,"347":2,"348":1,"350":1,"355":4,"356":2,"360":1,"367":3,"368":1,"373":1,"374":4,"376":2,"380":1,"381":1,"385":1,"388":1,"397":4,"403":1,"404":6,"406":2,"408":1,"409":1,"413":1,"422":3,"424":1,"426":1,"434":1,"439":1,"445":1,"449":1,"455":1,"458":1,"461":3,"463":1,"466":1,"467":1,"473":2,"479":2,"480":1,"482":1,"485":1,"487":1,"488":1,"491":2,"494":2,"500":3,"501":6,"502":1,"505":1,"508":2,"509":1,"512":2,"513":14,"515":1,"517":2,"519":1,"520":1,"522":2,"523":1,"526":1,"527":1,"528":2,"531":1,"532":2,"534":1,"538":2,"540":3,"541":1,"542":1,"543":1,"545":1,"546":1,"550":1,"551":1,"553":1,"554":1,"555":1,"556":1,"557":1,"560":2,"564":2,"566":1,"568":1,"572":8,"573":3,"574":2,"575":1,"576":1,"577":2,"588":2,"589":1,"590":2,"591":2,"601":1,"602":1,"603":1,"604":1,"605":1,"610":1,"611":1,"618":4,"619":1,"622":2,"623":1,"624":1,"626":1,"629":1,"631":2,"633":1,"635":2,"639":3,"641":1,"643":1,"645":1,"656":2,"657":2,"658":2,"659":2,"660":1,"662":1,"663":7,"664":1,"672":2,"673":1,"674":1,"675":1,"679":2,"681":1,"685":4,"686":3,"687":2,"688":2,"693":1,"698":3,"699":12,"701":1,"702":1,"703":1,"706":2,"707":1,"709":4,"712":2,"718":3,"720":1,"721":2,"722":1,"725":3,"726":1,"727":2,"731":2,"733":2,"734":2,"736":1,"741":1,"742":1,"744":3,"747":2,"750":1,"754":5,"760":2,"762":1,"763":2,"765":2,"771":2,"781":1,"783":1,"785":1,"790":5,"795":2,"797":1,"800":1,"801":1,"807":1,"808":1,"809":1,"810":2,"811":5,"813":2,"816":1,"825":1,"826":2,"827":4,"828":1,"831":4,"832":2,"833":2,"834":1,"841":5,"842":3,"843":2,"847":1,"849":1,"851":3,"856":2,"857":2,"861":2,"862":3,"863":1,"864":2,"870":1,"877":1,"879":1,"882":2,"883":4,"886":2,"887":2,"888":1,"889":1,"893":4,"896":1,"899":2,"901":2,"902":1,"903":1,"904":2,"905":2,"908":2,"911":1,"912":1,"913":5,"915":2,"916":1,"917":2,"920":1,"936":1,"937":1,"938":3,"939":1,"940":1,"943":3,"944":1,"945":2,"946":2,"947":1,"951":1,"952":2,"953":4,"954":1,"957":1,"959":3,"961":1,"962":1,"967":2,"968":3,"969":3,"972":1,"973":1,"980":2,"992":1,"1013":1,"1018":1,"1025":1,"1035":2,"1038":1}}],["nums",{"2":{"702":6,"1221":2,"1230":1,"1240":4}}],["numel",{"2":{"263":1,"635":2,"767":2,"854":5,"883":2,"905":2,"963":4,"995":2,"1017":2}}],["numeric",{"2":{"209":5}}],["numerical",{"2":{"66":1,"204":1,"240":1,"334":1,"434":1,"827":2,"981":3,"1124":1}}],["num",{"2":{"67":22,"68":8,"70":1,"71":12,"72":8,"73":8,"80":14,"81":12,"91":2,"137":35,"173":19,"174":44,"175":7,"176":4,"210":8,"211":4,"212":2,"213":5,"217":35,"219":4,"221":7,"225":5,"263":12,"266":1,"271":2,"273":4,"275":12,"278":15,"320":12,"321":43,"324":8,"325":44,"326":7,"329":3,"331":44,"332":36,"333":8,"335":22,"357":5,"369":26,"375":98,"376":13,"382":180,"396":30,"398":28,"405":23,"407":89,"408":135,"409":88,"446":5,"463":2,"472":19,"473":16,"474":1,"480":25,"481":8,"482":54,"483":2,"489":2,"494":8,"496":2,"501":22,"502":22,"503":2,"507":12,"508":12,"509":2,"523":28,"528":22,"529":2,"543":8,"544":44,"545":8,"546":12,"547":12,"557":8,"558":44,"559":12,"560":12,"561":12,"566":3,"568":7,"569":6,"573":41,"574":44,"575":9,"576":31,"577":12,"578":5,"582":18,"583":3,"584":6,"595":7,"599":4,"600":8,"605":5,"626":2,"630":19,"635":6,"668":12,"669":18,"674":28,"675":10,"676":18,"677":26,"679":9,"680":6,"681":6,"686":36,"687":7,"688":6,"690":2,"693":2,"695":9,"702":8,"704":6,"713":18,"715":6,"721":4,"722":18,"725":1,"726":30,"734":58,"736":29,"737":9,"738":34,"757":2,"760":6,"762":2,"766":2,"767":23,"773":2,"777":11,"826":15,"828":19,"834":2,"835":2,"837":17,"848":12,"851":24,"852":9,"854":9,"862":10,"863":6,"864":2,"865":5,"874":6,"878":6,"882":3,"883":24,"893":17,"894":24,"895":6,"896":3,"898":1,"906":24,"907":6,"908":9,"923":3,"927":9,"938":2,"948":3,"949":9,"954":16,"955":10,"957":2,"958":10,"959":25,"961":3,"962":4,"963":8,"1230":2,"1402":3,"1404":1}}],["numpy==1",{"2":{"1281":1}}],["numpy的语法相较于octave来说",{"2":{"1088":1}}],["numpy的语法来描述模型",{"2":{"300":1}}],["numpy或者r语言",{"2":{"1088":1}}],["numpy和octave",{"2":{"1088":1}}],["numpy点积是在cpu上执行的",{"2":{"790":2}}],["numpy",{"2":{"38":3,"54":3,"68":1,"77":3,"79":1,"80":1,"81":1,"89":1,"95":1,"99":3,"107":1,"137":1,"208":3,"213":1,"235":8,"236":8,"237":8,"242":9,"243":1,"261":3,"262":1,"263":2,"275":1,"278":1,"333":2,"334":1,"351":7,"357":1,"390":1,"395":1,"404":1,"436":2,"441":1,"473":2,"575":1,"576":1,"577":2,"582":3,"589":3,"599":2,"615":3,"734":1,"768":2,"789":3,"790":9,"791":1,"795":1,"847":1,"848":1,"852":4,"854":10,"896":2,"908":2,"945":1,"966":1,"981":3,"995":1,"1013":6,"1017":2,"1022":4,"1026":4,"1085":1,"1088":1,"1093":1,"1107":1,"1109":1,"1117":1,"1235":2,"1277":1,"1297":1}}],["number>",{"2":{"1405":1,"1409":1,"1426":1,"1430":1}}],["numberlist",{"2":{"1405":1}}],["number=10000",{"2":{"1262":1}}],["numbers",{"2":{"813":3,"1026":1,"1048":1,"1398":1,"1402":2}}],["numbers和",{"2":{"813":1}}],["number",{"2":{"26":1,"1045":1,"1046":2,"1048":2,"1154":1,"1160":1,"1315":2,"1398":6,"1399":2,"1401":5,"1402":1,"1404":1,"1405":8,"1407":1,"1408":1,"1410":1,"1412":1,"1417":4,"1419":2,"1421":1,"1422":5,"1423":2,"1425":7,"1426":5,"1427":3,"1428":3,"1431":2,"1432":2,"1433":3,"1434":1,"1435":1,"1469":1,"1491":2,"1493":1,"1503":2,"1520":2}}],["nginxproxy",{"2":{"1371":1}}],["nginxlisten",{"2":{"1371":1}}],["nginxlocation",{"2":{"1368":1,"1371":1}}],["nginxgzip",{"2":{"1371":1}}],["nginxworker",{"2":{"1371":1}}],["nginxupstream",{"2":{"1369":1}}],["nginxserver",{"2":{"1367":1,"1370":1}}],["nginx",{"0":{"1358":1,"1359":1,"1364":1,"1372":1},"1":{"1359":1,"1360":1,"1361":1,"1362":1,"1363":1,"1364":1,"1365":2,"1366":1,"1367":1,"1368":1,"1369":1,"1370":1,"1371":1,"1372":1},"2":{"1342":1,"1359":3,"1361":1,"1362":1,"1363":1,"1364":4,"1370":2,"1371":2,"1372":1,"1389":1,"1390":2,"1543":1,"1546":1,"1547":1}}],["ng",{"2":{"455":1,"1176":1}}],["nbatch",{"2":{"406":3}}],["n批量规范化",{"2":{"406":1}}],["ndarray",{"2":{"987":1,"1016":1,"1022":2}}],["ndarray或symbol",{"2":{"821":1}}],["ndarray中引入的那些张量函数来进一步操作",{"2":{"1013":1}}],["ndarray中",{"2":{"452":1}}],["ndarray转换为tensor",{"2":{"262":1}}],["nd2",{"2":{"397":1}}],["ndim",{"2":{"368":1,"981":2}}],["n元语法通过截断相关性",{"2":{"322":1}}],["ny",{"2":{"320":1,"321":1}}],["nij=|xi∩yi|",{"2":{"1154":1}}],["ni+mi对于不同的i是不同的",{"2":{"776":1}}],["nin一节介绍的使用卷积层的通道来输出类别预测的方法",{"2":{"954":1}}],["nin的设计影响了许多后续卷积神经网络的设计",{"2":{"497":1}}],["nin的想法是在每个像素位置",{"2":{"494":1}}],["nin去除了容易造成过拟合的全连接层",{"2":{"497":1}}],["nin设计的一个优点是",{"2":{"495":1}}],["nin使用由一个卷积层和多个1×1卷积层组成的块",{"2":{"497":1}}],["nin使用一个nin块",{"2":{"495":1}}],["nin使用窗口形状为11×11",{"2":{"495":1}}],["nin和alexnet之间的一个显著区别是nin完全取消了全连接层",{"2":{"495":1}}],["nin模型",{"0":{"495":1}}],["nin说明了vgg和nin及它们的块之间主要架构差异",{"2":{"494":1}}],["nin块以一个普通卷积层开始",{"2":{"494":1}}],["nin块",{"0":{"494":1}}],["nin",{"0":{"493":1},"1":{"494":1,"495":1,"496":1,"497":1,"498":1},"2":{"492":2,"493":2,"494":5,"495":16}}],["nin+nout",{"2":{"247":1}}],["ni∝1iα",{"2":{"318":1}}],["nice",{"2":{"315":1}}],["n−1",{"2":{"262":1,"338":1,"842":1}}],["n−1=nn−1",{"2":{"116":1}}],["naive",{"2":{"1528":1}}],["nav>",{"2":{"1479":1}}],["nav",{"2":{"1479":1}}],["navigate",{"2":{"1474":1}}],["nasa",{"2":{"1303":1}}],["nanoid",{"2":{"1495":3}}],["nan",{"2":{"1012":7}}],["narayanamurthy",{"2":{"840":1}}],["narasimhan",{"2":{"732":1}}],["native",{"2":{"1374":1}}],["national",{"2":{"292":1}}],["natural",{"2":{"663":3,"664":1,"665":1,"666":1,"672":2,"679":2,"685":3}}],["nat",{"2":{"650":1}}],["nadaraya",{"0":{"385":1},"1":{"386":1,"387":1,"388":1,"389":1,"390":1,"391":1,"392":1,"393":1,"394":1},"2":{"367":2,"379":1,"385":1,"388":11,"389":3,"391":1,"393":2}}],["na=true",{"2":{"209":2,"1012":1}}],["na",{"2":{"208":1,"209":1,"1011":5}}],["name变化了",{"2":{"1465":1}}],["name和age是一个refimpl的实例对象",{"2":{"1455":1}}],["name不是响应式的",{"2":{"1455":2}}],["nameable",{"2":{"1408":2}}],["namespace",{"0":{"1387":1}}],["names",{"2":{"576":1,"713":1,"776":2,"777":1,"1398":1}}],["namedcoordinate",{"2":{"1405":1}}],["named",{"2":{"432":2,"436":2,"713":1,"874":2}}],["name=f",{"2":{"433":1}}],["name=name",{"2":{"433":1}}],["name=",{"2":{"127":2,"414":2,"472":4,"820":1,"1454":1,"1455":1,"1456":1,"1457":1,"1459":1,"1460":1,"1462":1,"1463":1,"1464":1,"1465":1,"1466":1,"1467":1,"1468":3,"1469":2,"1470":1,"1474":1,"1490":2,"1492":1,"1497":2,"1500":2,"1501":3,"1503":2,"1507":2,"1508":1}}],["name",{"2":{"67":6,"81":2,"136":4,"137":8,"206":8,"326":3,"332":3,"335":1,"424":3,"432":4,"433":1,"436":6,"461":4,"488":4,"495":4,"502":4,"508":4,"546":3,"547":3,"560":3,"561":3,"667":2,"692":3,"718":2,"748":4,"776":2,"777":2,"874":4,"890":2,"932":9,"1047":2,"1048":6,"1196":1,"1214":1,"1215":1,"1229":2,"1233":1,"1244":2,"1315":12,"1336":2,"1364":1,"1367":1,"1370":1,"1389":2,"1390":2,"1391":1,"1398":5,"1405":1,"1408":3,"1410":1,"1412":1,"1416":7,"1419":2,"1421":1,"1425":7,"1428":5,"1431":3,"1432":3,"1433":4,"1434":2,"1435":1,"1444":2,"1445":4,"1451":6,"1454":4,"1455":8,"1456":5,"1457":5,"1459":4,"1463":4,"1464":4,"1465":4,"1466":4,"1468":3,"1469":6,"1471":1,"1478":4,"1479":5,"1481":1,"1482":1,"1483":1,"1506":1,"1507":1,"1508":5,"1518":5,"1519":4}}],["nw+kw−1",{"2":{"968":1}}],["nw+sw−1",{"2":{"142":1}}],["nwkernelregression",{"2":{"391":4,"392":4}}],["nw",{"2":{"142":1}}],["nw−kw+pw+sw",{"2":{"142":1}}],["nw−kw+pw+1",{"2":{"141":1}}],["nw−kw+1",{"2":{"126":1,"140":1}}],["nh+kh−1",{"2":{"968":1}}],["nh+sh−1",{"2":{"142":1}}],["nh",{"2":{"142":1}}],["nh−kh+ph+sh",{"2":{"142":1}}],["nh−kh+ph+1",{"2":{"141":1}}],["nh−kh+1",{"2":{"126":1,"140":1}}],["n≈1",{"2":{"842":1}}],["n≈1−e−1≈0",{"2":{"116":1}}],["n≈e−1≈0",{"2":{"116":1}}],["n1",{"2":{"116":1,"708":2}}],["never",{"2":{"1404":1,"1434":1}}],["nev",{"2":{"1404":1}}],["neon128的例子中",{"2":{"811":1}}],["neon128所示的矢量化",{"2":{"811":1}}],["neon128",{"2":{"809":1}}],["neon128显示了如何在arm上的一个时钟周期中完成8个整数加法",{"2":{"809":1}}],["negtive",{"2":{"1139":2}}],["neg",{"2":{"692":1,"775":3}}],["negatives中通过一个labels变量将上下文词与噪声词分开",{"2":{"776":1}}],["negatives中的上下文词的正例",{"2":{"776":1}}],["negatives中的元素之间也存在一一对应关系",{"2":{"776":1}}],["negatives中的元素之间存在一一对应关系",{"2":{"776":1}}],["negatives中的填充",{"2":{"776":1}}],["negatives个变量中将其上下文词和噪声词连结起来",{"2":{"776":1}}],["negatives",{"2":{"763":7,"775":10,"776":4,"777":19}}],["negative",{"2":{"662":1,"708":7,"715":3,"765":1,"767":6,"776":3,"1106":1,"1139":2}}],["neumann",{"2":{"731":1}}],["neutral",{"2":{"665":1,"667":1,"682":3}}],["neurons",{"2":{"1098":1}}],["neuron所示的神经网络中",{"2":{"618":1}}],["neuron",{"2":{"618":1,"619":2}}],["neuron中的输出层",{"2":{"618":1}}],["neuron中的单层网络架构",{"2":{"591":1}}],["neuron中神经网络的层数为1",{"2":{"618":1}}],["neuron中",{"2":{"618":1}}],["neural",{"0":{"1096":1,"1119":1},"1":{"1097":1,"1098":1,"1099":1,"1100":1,"1101":1,"1102":1,"1103":1,"1120":1,"1121":1,"1122":1,"1123":1,"1124":1,"1125":1,"1126":1,"1127":1},"2":{"134":1,"151":1,"299":1,"305":1,"338":1,"340":1,"564":1,"886":1,"1100":1,"1127":1,"1193":2}}],["needs",{"2":{"1310":1,"1315":1}}],["need",{"2":{"487":1,"675":1}}],["nested",{"2":{"500":2,"504":1}}],["nesterov",{"2":{"86":1,"115":1}}],["nestmlp",{"2":{"425":8}}],["newslist",{"2":{"1479":1}}],["news",{"2":{"1474":3,"1478":3,"1479":11,"1481":6,"1482":6}}],["newheight",{"2":{"1467":2}}],["newtemp",{"2":{"1467":2}}],["newton",{"2":{"59":4}}],["newvalue",{"2":{"1462":3,"1463":4,"1464":4,"1465":4,"1466":2}}],["newradius",{"2":{"1426":2}}],["new",{"2":{"325":12,"332":12,"334":9,"659":1,"717":3,"757":5,"788":1,"835":12,"905":7,"906":2,"908":1,"1047":4,"1048":5,"1404":1,"1416":2,"1427":1,"1428":2,"1431":2,"1432":1}}],["nextsentencepred实例的前向推断返回每个bert输入序列的二分类预测",{"2":{"737":1}}],["nextsentencepred",{"2":{"737":9,"738":3}}],["next",{"0":{"737":1},"2":{"137":3,"582":2,"590":1,"720":12,"722":12,"932":1,"1070":1,"1129":1,"1135":1,"1174":1}}],["nempirical",{"2":{"99":2}}],["net实例获取",{"2":{"920":1}}],["net之前的参数设置为源模型的参数",{"2":{"876":1}}],["net和scratch",{"2":{"876":1}}],["net的超参数",{"2":{"876":1}}],["net的学习率",{"2":{"876":1}}],["net的前向传播将输入的高和宽减小至原来的1",{"2":{"862":1}}],["net中成员变量features的参数被初始化为源模型相应层的模型参数",{"2":{"873":1}}],["netherlands",{"2":{"813":1}}],["net=net",{"2":{"451":1}}],["net1和net2",{"2":{"423":1}}],["netflix",{"2":{"345":1,"1303":1}}],["networks",{"0":{"1096":1,"1119":1},"1":{"1097":1,"1098":1,"1099":1,"1100":1,"1101":1,"1102":1,"1103":1,"1120":1,"1121":1,"1122":1,"1123":1,"1124":1,"1125":1,"1126":1,"1127":1},"2":{"151":1,"296":1,"299":1,"338":1,"1100":1,"1193":2}}],["network",{"2":{"134":1,"298":1,"305":1,"340":1,"404":1,"861":1,"939":1,"1127":1,"1345":1}}],["net",{"2":{"67":38,"68":10,"71":10,"72":10,"73":10,"80":12,"81":20,"136":10,"137":43,"174":12,"175":5,"176":12,"210":38,"211":3,"213":4,"219":4,"221":5,"225":10,"263":31,"275":16,"278":33,"326":15,"332":12,"333":18,"334":12,"335":49,"350":43,"351":7,"376":4,"392":20,"409":11,"413":8,"414":9,"418":17,"422":11,"423":6,"424":8,"425":15,"429":11,"430":3,"431":13,"432":9,"433":16,"435":38,"436":23,"437":22,"442":12,"451":12,"461":10,"463":1,"473":13,"474":5,"480":7,"482":17,"483":1,"488":11,"489":1,"495":9,"496":1,"502":9,"503":1,"508":16,"509":3,"576":22,"577":22,"578":2,"591":6,"592":6,"594":2,"595":18,"605":9,"623":9,"625":2,"626":1,"632":1,"634":11,"635":17,"636":3,"674":26,"680":7,"681":5,"682":9,"688":10,"702":8,"703":9,"704":7,"713":3,"714":5,"715":13,"726":21,"727":9,"766":3,"767":17,"768":3,"819":39,"820":22,"821":8,"826":21,"827":9,"828":21,"862":20,"863":4,"865":6,"866":3,"873":18,"874":27,"876":6,"883":36,"893":15,"894":17,"895":10,"896":12,"905":29,"906":17,"907":10,"908":13,"920":9,"927":3,"958":6,"959":9,"961":6,"963":7,"964":5,"1121":1}}],["nnp",{"2":{"659":2}}],["nn模块定义了大量的神经网络层和常见损失函数",{"2":{"596":1}}],["nn模块定义了大量的神经网络层",{"2":{"596":1}}],["nn是神经网络的缩写",{"2":{"591":3}}],["nn",{"2":{"67":39,"77":3,"81":12,"126":3,"127":5,"129":3,"136":37,"137":10,"141":9,"142":6,"146":3,"147":9,"148":3,"172":3,"174":10,"175":2,"176":29,"208":3,"210":5,"216":2,"217":4,"220":1,"224":3,"225":19,"235":3,"236":3,"237":2,"242":2,"261":3,"263":8,"271":3,"278":10,"324":5,"325":16,"329":4,"334":2,"335":6,"350":20,"367":3,"368":6,"369":16,"370":6,"374":3,"375":8,"381":3,"382":15,"385":3,"388":3,"391":7,"392":2,"395":3,"398":6,"404":3,"405":11,"406":15,"407":9,"408":12,"413":12,"414":9,"418":5,"422":20,"423":10,"424":9,"425":36,"429":15,"433":23,"435":21,"436":5,"437":20,"441":5,"442":10,"446":3,"451":6,"461":62,"472":9,"473":38,"474":50,"480":22,"481":15,"482":31,"487":30,"488":53,"494":22,"495":21,"501":25,"502":30,"507":15,"508":24,"523":4,"528":4,"533":6,"534":3,"535":3,"543":3,"547":2,"557":3,"561":2,"572":3,"573":5,"574":8,"575":2,"576":4,"591":9,"592":3,"593":2,"622":3,"623":12,"624":1,"634":2,"635":2,"659":1,"666":2,"673":5,"674":26,"675":3,"676":6,"677":6,"681":2,"685":3,"688":8,"691":2,"698":3,"702":32,"704":2,"712":3,"713":20,"715":2,"725":2,"726":2,"733":3,"734":14,"736":19,"737":6,"738":10,"747":2,"760":3,"762":3,"765":4,"766":6,"767":4,"789":3,"819":19,"821":3,"825":3,"826":25,"828":9,"833":4,"834":2,"836":3,"861":5,"862":8,"863":3,"871":3,"873":4,"874":4,"877":3,"883":9,"887":3,"893":15,"894":1,"899":3,"905":15,"906":1,"908":2,"918":4,"920":2,"926":4,"954":8,"955":3,"957":15,"958":3,"959":6,"962":4,"967":3,"968":4,"969":12}}],["n",{"2":{"47":1,"48":1,"54":6,"79":8,"80":16,"81":16,"113":3,"116":2,"143":1,"209":3,"243":8,"262":9,"264":4,"265":4,"266":4,"271":5,"314":1,"316":3,"318":2,"350":3,"351":12,"386":19,"387":3,"388":22,"390":3,"392":76,"397":3,"527":1,"566":1,"578":10,"600":1,"615":9,"634":2,"635":4,"636":5,"674":1,"675":1,"676":1,"692":1,"709":3,"713":2,"757":2,"772":1,"775":1,"776":2,"835":12,"842":1,"843":2,"858":1,"866":9,"890":5,"894":3,"905":9,"906":3,"908":6,"923":3,"945":11,"946":6,"984":1,"992":1,"1011":5,"1077":1,"1080":1,"1093":2,"1110":2,"1111":1,"1116":1,"1117":1,"1120":1,"1160":1,"1165":1,"1166":1,"1168":1,"1184":1,"1246":4,"1277":1,"1404":1,"1437":1,"1491":1}}],["nosql",{"2":{"1194":1}}],["nodes",{"2":{"1392":1}}],["nodeport",{"2":{"1384":1,"1391":2}}],["node",{"0":{"1377":1},"2":{"1048":1,"1196":1,"1313":1,"1315":8,"1363":1,"1375":1,"1376":1,"1378":2,"1381":2,"1543":1}}],["norvig",{"2":{"619":1}}],["norm函数提供3个或更多轴的张量",{"2":{"1004":1}}],["norms",{"2":{"280":1,"980":1,"1000":1,"1001":1}}],["norms中",{"2":{"270":1}}],["norm",{"2":{"275":4,"278":4,"334":14,"406":15,"407":17,"408":18,"409":9,"466":1,"472":9,"481":2,"492":1,"686":2,"726":1,"734":6,"738":4,"977":4,"1000":10}}],["norm中的批量规范化也需要调整",{"2":{"833":1}}],["norm中将介绍",{"2":{"491":1}}],["norm中解释了在一个小批量的样本内基于批量规范化对数据进行重新中心化和重新缩放的调整",{"2":{"406":1}}],["norm中",{"2":{"78":1}}],["normaleqn",{"2":{"1085":1}}],["normalize",{"2":{"866":3,"872":12,"891":6,"903":6,"919":2,"947":8}}],["normalized",{"2":{"406":6}}],["normalization",{"2":{"404":1,"466":1,"491":1,"492":1,"1192":1}}],["normal",{"2":{"77":4,"80":4,"81":4,"113":4,"122":4,"127":1,"173":3,"176":3,"217":4,"225":3,"243":8,"262":2,"273":4,"278":4,"331":18,"335":1,"340":8,"350":2,"369":4,"370":4,"386":4,"414":1,"435":8,"544":18,"558":18,"592":5,"599":4,"601":4,"616":5,"623":3,"630":4,"631":2,"645":1,"702":2,"790":5,"819":2,"821":1,"827":1,"828":5,"834":4,"962":1,"977":2,"1006":1,"1017":2,"1069":1,"1085":1,"1086":2}}],["note",{"2":{"1123":1}}],["notes",{"2":{"813":2}}],["notx2",{"2":{"1102":3}}],["notx1",{"2":{"1102":3}}],["notimplementederror",{"2":{"375":1,"533":4,"534":8}}],["not",{"2":{"137":3,"206":1,"210":4,"325":3,"334":1,"335":2,"363":3,"382":4,"472":3,"501":1,"502":4,"518":1,"635":6,"724":2,"726":3,"734":1,"738":3,"775":1,"826":3,"827":1,"848":1,"872":2,"874":2,"890":1,"893":1,"894":9,"906":10,"981":1,"1102":1,"1220":1,"1221":1,"1431":2}}],["noise",{"2":{"79":4,"467":1,"760":6,"777":6}}],["now",{"2":{"68":4,"1235":1}}],["nonnullable",{"2":{"1434":1}}],["nonstop",{"2":{"1191":1}}],["nonstationary",{"2":{"187":1}}],["noninvertibility",{"2":{"1086":1}}],["nonzero",{"2":{"851":3,"852":3,"854":3}}],["non",{"2":{"500":1,"565":1,"631":1,"797":2,"813":2,"854":10,"996":1,"1097":1,"1109":1}}],["nonparametric",{"2":{"388":1}}],["none",{"2":{"67":9,"80":1,"81":2,"137":9,"175":2,"210":4,"211":3,"213":2,"220":1,"225":2,"263":1,"278":1,"335":8,"350":2,"363":2,"368":4,"375":4,"382":4,"392":2,"407":4,"408":19,"431":1,"501":5,"575":10,"624":1,"635":5,"668":3,"681":2,"688":2,"704":2,"715":2,"721":1,"734":4,"736":2,"738":6,"765":2,"834":2,"848":1,"849":9,"865":2,"874":2,"883":11,"893":3,"894":18,"896":3,"905":2,"906":15,"908":3,"959":9,"962":4,"981":2}}],["nonconvex",{"2":{"40":2}}],["nonconvex中连接a和b的线段需要包含一部分既不在x也不在y中",{"2":{"40":1}}],["no",{"2":{"21":2,"28":2,"34":2,"35":2,"67":2,"80":1,"91":2,"108":2,"129":1,"137":4,"334":1,"565":2,"576":2,"604":2,"605":2,"634":2,"837":2,"885":2,"1444":6}}],["npm",{"2":{"1315":3,"1443":2,"1444":1,"1454":1,"1489":1}}],["np函数",{"2":{"1017":1}}],["np模块包含numpy支持的函数",{"2":{"1017":1}}],["np中都这样做",{"2":{"790":1}}],["npy",{"2":{"441":6}}],["npx",{"2":{"21":2,"27":2,"34":2,"38":2,"54":2,"67":2,"77":2,"87":2,"99":2,"107":2,"112":2,"120":2,"126":2,"136":2,"141":2,"146":2,"172":2,"174":2,"208":2,"216":2,"224":2,"234":2,"235":1,"236":1,"242":3,"261":2,"271":2,"318":2,"324":2,"325":1,"329":2,"330":1,"332":1,"340":2,"350":2,"357":2,"367":2,"368":3,"369":1,"370":2,"374":2,"381":2,"385":2,"388":1,"390":2,"391":2,"395":2,"404":2,"413":2,"414":1,"418":2,"422":2,"425":1,"429":2,"441":8,"446":11,"461":2,"472":2,"480":2,"487":2,"494":2,"501":4,"507":2,"523":2,"528":2,"543":2,"545":2,"557":2,"559":3,"564":2,"572":2,"575":3,"589":2,"598":2,"622":2,"629":2,"666":2,"673":2,"674":5,"685":2,"691":2,"698":2,"712":2,"718":2,"725":2,"726":1,"733":2,"747":2,"750":1,"760":2,"763":1,"768":1,"789":2,"790":1,"791":2,"792":1,"795":2,"796":4,"797":4,"819":2,"820":2,"821":1,"825":2,"828":1,"833":2,"834":7,"836":2,"837":1,"847":2,"857":2,"861":2,"871":2,"877":2,"887":2,"893":2,"899":2,"908":1,"912":3,"918":2,"931":2,"938":2,"945":2,"954":2,"956":1,"964":1,"966":1,"967":2,"974":2,"981":2,"989":2,"1017":2,"1026":2}}],["np",{"2":{"21":5,"27":2,"28":2,"34":4,"35":4,"38":5,"41":2,"54":5,"56":1,"59":1,"67":2,"73":1,"77":11,"78":1,"79":4,"80":2,"87":2,"99":7,"107":2,"108":2,"112":2,"120":2,"126":2,"136":3,"141":3,"146":2,"172":6,"173":6,"174":3,"208":5,"210":4,"213":1,"216":2,"217":4,"218":1,"219":2,"224":1,"234":2,"235":1,"237":1,"242":3,"243":3,"261":5,"262":8,"271":2,"273":2,"275":1,"278":1,"318":2,"324":2,"325":1,"329":2,"330":1,"331":1,"332":5,"340":2,"350":2,"357":2,"367":2,"368":2,"369":5,"374":2,"375":4,"381":2,"385":2,"386":1,"388":2,"390":2,"391":2,"392":6,"395":3,"398":13,"399":2,"404":3,"405":1,"407":1,"408":4,"409":2,"413":4,"414":3,"418":3,"422":3,"425":3,"429":3,"436":2,"437":1,"441":11,"442":1,"446":2,"447":1,"448":2,"461":3,"472":6,"480":4,"487":3,"488":1,"494":2,"495":1,"501":3,"502":1,"507":2,"508":1,"523":1,"528":1,"543":2,"544":3,"545":10,"557":2,"558":3,"559":14,"564":2,"572":2,"574":1,"575":6,"576":2,"577":5,"589":5,"598":2,"601":2,"615":5,"616":3,"622":1,"629":2,"630":2,"666":2,"668":2,"673":2,"675":2,"676":1,"682":3,"685":2,"687":4,"691":2,"695":2,"698":2,"702":3,"712":2,"713":1,"715":2,"718":2,"722":7,"725":2,"727":6,"733":2,"734":2,"736":4,"737":1,"747":2,"750":4,"760":2,"763":2,"768":4,"771":1,"789":2,"790":7,"791":4,"795":3,"796":3,"819":3,"821":1,"825":2,"827":1,"833":2,"834":10,"835":1,"836":1,"847":4,"848":10,"849":2,"851":7,"852":3,"853":2,"854":12,"857":2,"861":2,"862":1,"863":7,"866":2,"871":2,"876":1,"877":2,"887":1,"899":1,"912":4,"918":2,"919":3,"922":1,"923":1,"931":2,"932":2,"938":4,"945":4,"947":2,"954":2,"956":3,"957":1,"958":1,"959":2,"962":1,"964":2,"966":3,"967":2,"969":1,"974":4,"977":2,"981":6,"989":4,"990":1,"992":2,"993":1,"994":2,"995":1,"997":2,"998":1,"999":2,"1000":3,"1006":2,"1007":1,"1013":3,"1017":3,"1018":6,"1019":2,"1021":1,"1022":2,"1026":9,"1081":2,"1085":2,"1107":2,"1109":9,"1117":11}}],["是调用emit时所提供的数据",{"2":{"1498":1}}],["是包含事件相关信息的对象",{"2":{"1498":1}}],["是旧值",{"2":{"1463":1}}],["是新值",{"2":{"1463":1}}],["是新一代前端构建工具",{"2":{"1444":1}}],["是分散在",{"2":{"1448":1}}],["是项目的入口文件",{"2":{"1444":1}}],["是只读的",{"2":{"1419":1}}],["是自动化流程的顶层描述",{"2":{"1309":1}}],["是自然变化还是响应我们的自动化工具而发生变化",{"2":{"297":1}}],["是开启编程世界的一把钥匙",{"0":{"1305":1}}],["是编程的基础",{"2":{"1222":1}}],["是目前最广泛使用的文档型",{"2":{"1194":1}}],["是目标语言",{"2":{"566":1}}],["是第一个用户的模型的参数",{"2":{"1188":1}}],["是第一部电影的特征向量为",{"2":{"1188":1}}],["是你的训练样本的平均值",{"2":{"1185":1}}],["是你能够给一个算法大量的训练数据",{"2":{"1141":1}}],["是逆矩阵",{"2":{"1184":1}}],["是不受到任何打扰的",{"2":{"1503":1}}],["是不是异常的",{"2":{"1178":1}}],["是不同的",{"2":{"189":1,"293":1}}],["是能够有更好的效果的",{"2":{"1173":1}}],["是能为一个或多个自变量与因变量之间关系建模的一类方法",{"2":{"608":1}}],["是用英寸表示同一物体的长度",{"2":{"1156":1}}],["是用比如梯度下降这些算法",{"2":{"1111":1}}],["是要最小化所有的数据点与其所关联的聚类中心点之间的距离之和",{"2":{"1152":1}}],["是要找出使得代价函数最小的一系列参数",{"2":{"1081":1}}],["是提出参数c的选择",{"2":{"1148":1}}],["是根据选择的核函数不同而变化的矩阵",{"2":{"1147":1}}],["是我们的一个特征",{"2":{"1168":1}}],["是我们刚刚做的证明的推广",{"2":{"1145":1}}],["是我们模型预测测试集中i的总预测分数",{"2":{"192":1}}],["是在相反的方向",{"2":{"1145":1}}],["是在y=1的前提下的",{"2":{"1143":1}}],["是等于1",{"2":{"1144":1}}],["是等价的",{"2":{"446":1}}],["是使得训练样本拟合的更好",{"2":{"1143":1}}],["是使用梯度下降法",{"2":{"1110":1}}],["是需要花些时间的",{"2":{"1129":1}}],["是稍微的左转",{"2":{"1127":1}}],["是受到权重矩阵中第i行影响的下一层中的误差单元的下标",{"2":{"1121":1}}],["是过拟合",{"2":{"1114":1}}],["是代价函数对于theta",{"2":{"1111":1}}],["是代表段落的句子列表",{"2":{"722":3}}],["是代表段落的句子字符串列表",{"2":{"722":3}}],["是向量",{"2":{"1108":1}}],["是向下四舍五入",{"2":{"1090":1}}],["是离散的值",{"2":{"1106":1}}],["是未向量化的",{"2":{"1093":1}}],["是列向量",{"2":{"1090":1}}],["是浮点数",{"2":{"1089":1}}],["是默认的octave提示",{"2":{"1088":1}}],["是特征矩阵中的第i行",{"2":{"1080":1}}],["是没那么陡的",{"2":{"1068":1}}],["是这样的线性函数形式",{"2":{"1064":1}}],["是免费的开源软件",{"2":{"1061":1}}],["是吧",{"2":{"1061":1}}],["是的",{"2":{"1061":2}}],["是良性或恶性了",{"2":{"1061":1}}],["是教你如何使用这些工具",{"2":{"1059":1}}],["是让",{"2":{"1051":1}}],["是两个我想解决的机器学习问题",{"2":{"1089":1}}],["是两个输入张量轴",{"2":{"1018":2}}],["是两个突出强化学习的例子",{"2":{"298":1}}],["是矩阵元素平方和的平方根",{"2":{"1000":1}}],["是相同位置的按元素乘积的和",{"2":{"997":1}}],["是描述具有任意数量轴的n维数组的通用方法",{"2":{"993":1}}],["是集合中的成员",{"2":{"989":1}}],["是2",{"2":{"981":1}}],["是和整个模型一起训练得到的",{"2":{"939":1}}],["是仅在整张图象上执行卷积神经网络的前向传播",{"2":{"938":1}}],["是实数",{"2":{"863":1}}],["是实体",{"2":{"295":1}}],["是常用的上采样方法之一",{"2":{"863":1}}],["是pcie的替代品",{"2":{"812":1}}],["是任何计算机的核心",{"2":{"807":1}}],["是wi的词数与数据集中的总词数的比率",{"2":{"773":1}}],["是对它进行训练",{"2":{"1127":1}}],["是对",{"2":{"751":2}}],["是对完整梯度∇f",{"2":{"113":1}}],["是词表的索引集",{"2":{"742":1}}],["是整个输入语句的bert表示",{"2":{"727":1}}],["是节点n的左子节点",{"2":{"709":1}}],["是d维的词向量",{"2":{"674":1}}],["是d×d矩阵",{"2":{"59":1}}],["是平衡的",{"2":{"667":1}}],["是可以接受的",{"2":{"657":1}}],["是可取的",{"2":{"284":1}}],["是额外的全连接层",{"2":{"656":1}}],["是当分配的概率真正匹配数据生成过程时的信息量的期望",{"2":{"651":1}}],["是选择超参数的过程",{"2":{"613":1}}],["是图像分类中广泛使用的数据集之一",{"2":{"581":1}}],["是源语言",{"2":{"566":1}}],["是单一语言的语言模型问题存在不同",{"2":{"564":1}}],["是输出层的模型参数",{"2":{"521":1}}],["是贪心搜索的一个改进版本",{"2":{"515":1}}],["是训练神经网络的理想情况",{"2":{"504":1}}],["是训练样本f",{"2":{"115":1}}],["是计算机视觉中最流行的体系架构",{"2":{"492":1}}],["是众所周知的",{"2":{"426":4}}],["是每个点的训练数据的距离",{"2":{"391":1}}],["是x",{"2":{"391":1}}],["是键值对",{"2":{"388":1}}],["是均匀的",{"2":{"369":1}}],["是通过注意力评分函数a将两个向量映射成标量",{"2":{"367":1}}],["是通过以输入x",{"2":{"141":1}}],["是文本的基本单位",{"2":{"362":1}}],["是来自预训练bert的整个句子对的编码结果",{"2":{"727":1}}],["是来自",{"2":{"351":3}}],["是来自x的观测",{"2":{"351":3}}],["是保留一些对过去观测的总结ht",{"2":{"347":1}}],["是具有隐状态的神经网络",{"2":{"338":1}}],["是因为误差平方代价函数",{"2":{"1064":1}}],["是因为我们需要考虑标签",{"2":{"320":1}}],["是因为在训练参数时",{"2":{"289":1}}],["是影响数值稳定性的关键量",{"2":{"312":1}}],["是由500000多个带标签的英语句子对组成的集合",{"2":{"666":1}}],["是由于正弦函数和余弦函数的交替",{"2":{"398":1}}],["是由",{"2":{"312":1,"1040":1}}],["是如何进一步缓解这一问题的",{"2":{"312":1}}],["是rosenblatt感知器学习算法的原型",{"2":{"299":1}}],["是应该利用当前最好的策略",{"2":{"298":1}}],["是非常难的",{"2":{"1138":1}}],["是非常热门的研究领域",{"2":{"298":1}}],["是非凸的",{"2":{"52":1}}],["是二维布局分析问题",{"2":{"295":1}}],["是机器学习最令人兴奋的应用之一",{"2":{"295":1}}],["是机器学习利用自然图像中一些已知结构的创造性方法",{"2":{"151":1}}],["是亚马逊基于个性化算法推荐的深度学习书籍",{"2":{"294":1}}],["是最常见的降维算法",{"2":{"1158":1}}],["是最简单的监督学习任务之一",{"2":{"290":1}}],["是最广泛使用的正则化的技术之一",{"2":{"270":1}}],["是权重和偏置参数",{"2":{"270":1}}],["是样本i的标签",{"2":{"270":1}}],["是样本i的特征",{"2":{"270":1}}],["是上述问题的一个特例",{"2":{"197":1}}],["是k维标签分布向量p",{"2":{"192":1}}],["是",{"2":{"191":1,"192":1,"282":3,"291":1,"848":1,"1108":1,"1121":1,"1197":1,"1392":1,"1418":1}}],["是为了提高计算效率",{"2":{"893":1}}],["是为了近似",{"2":{"190":1}}],["是为了保持数字稳定性而加入的",{"2":{"20":1}}],["是与上述简单网络相对应的计算图",{"2":{"163":1}}],["是隐藏层的权重参数",{"2":{"162":1}}],["是否添加prettiert代码格式化",{"2":{"1444":1}}],["是否添加pinia环境",{"2":{"1444":1}}],["是否添加eslint语法检查",{"2":{"1444":1}}],["是否添加端到端测试方案",{"2":{"1444":1}}],["是否添加单元测试",{"2":{"1444":1}}],["是否添加路由环境",{"2":{"1444":1}}],["是否添加jsx支持",{"2":{"1444":1}}],["是否添加typescript支持",{"2":{"1444":1}}],["是否区分大小写",{"2":{"1138":1}}],["是否能将这些邮件按照类分组",{"2":{"1138":1}}],["是否达到了算法的目的",{"2":{"1091":1}}],["是否总是对应于x特定轴的长度",{"2":{"1004":1}}],["是否存在一种可能",{"2":{"856":1}}],["是否一种方法",{"2":{"831":1}}],["是否可以通过spacy词元化来提高分类精度",{"2":{"717":1}}],["是否可以从",{"2":{"670":1}}],["是否可以从前提",{"2":{"665":1}}],["是否可以将不同作者的源数据合并",{"2":{"531":1}}],["是否会影响读取性能",{"2":{"586":1}}],["是否会带来更好的表现",{"2":{"337":1}}],["是否立即进行初始化",{"2":{"420":1}}],["是否包含自主性提示",{"2":{"356":1}}],["是否包含了过去4个以上的观测结果",{"2":{"353":1}}],["是否对相应的偏置b2进行惩罚在不同的实践中会有所不同",{"2":{"270":1}}],["是否过拟合或欠拟合可能取决于模型复杂性和可用训练数据集的大小",{"2":{"258":1}}],["是否有其它函数可以考虑",{"2":{"150":1}}],["是否需要导数来进行二分搜索",{"2":{"64":1}}],["是一款高度灵活",{"2":{"1531":1}}],["是一款用于构建用户界面的",{"2":{"1526":1}}],["是一般的高斯分布模型获得的判定边界",{"2":{"1184":1}}],["是一样",{"2":{"1092":1}}],["是一样的",{"2":{"1089":1}}],["是一种能够将我们的组件html结构移动到指定位置的技术",{"2":{"1522":1}}],["是一种",{"2":{"1296":1}}],["是一种n×n的矩阵",{"2":{"1185":1}}],["是一种凸优化问题",{"2":{"1148":1}}],["是一种具备自主感知",{"2":{"1050":1}}],["是一种实用的机器学习策略",{"2":{"190":1}}],["是一组给定样本空间的随机结果",{"2":{"1027":1}}],["是一个值得信赖的首选框架",{"2":{"1531":1}}],["是一个高性能的",{"2":{"1359":1}}],["是一个开源的容器编排平台",{"2":{"1374":1}}],["是一个开源的容器化平台",{"2":{"1339":1}}],["是一个开放协议",{"2":{"1040":1}}],["是一个n维向量",{"2":{"1185":1}}],["是一个一般的高斯分布模型",{"2":{"1184":1}}],["是一个基于神经网络的智能系统",{"2":{"1127":1}}],["是一个维度为k的向量",{"2":{"1120":1}}],["是一个常用的逻辑函数为s形函数",{"2":{"1107":1}}],["是一个实数",{"2":{"1093":1}}],["是一个列矩阵",{"2":{"1089":1}}],["是一个含有两列数据的文件",{"2":{"1089":1}}],["是一个向量",{"2":{"1080":1,"1093":1,"1184":1}}],["是一个",{"2":{"1077":1,"1195":1,"1318":1,"1375":1}}],["是一个从x",{"2":{"1063":1}}],["是一个条件分布",{"2":{"1032":1}}],["是一个联合分布",{"2":{"1032":1}}],["是一个元素组",{"2":{"991":1}}],["是一个具有n个变量的函数",{"2":{"982":1}}],["是一个词的类比",{"2":{"751":1}}],["是一个数量级",{"2":{"709":1}}],["是一个数值",{"2":{"290":1}}],["是一个小版本",{"2":{"686":1}}],["是一个稍微简化的变体",{"2":{"538":1}}],["是一个主观的选择",{"2":{"467":1}}],["是一个简单但完整的例子",{"2":{"385":1}}],["是一个相当匪夷所思的语句",{"2":{"315":1}}],["是一个训练模型的过程",{"2":{"282":1}}],["是一个人类认知上的非凡壮举",{"2":{"281":1}}],["是一个单调的非递减函数",{"2":{"46":1}}],["是一类特殊的神经网络",{"2":{"159":1}}],["是一类使用卷积层的网络",{"2":{"138":1}}],["是一类强大的可以从经验中学习的技术",{"2":{"281":1}}],["是一类强大的",{"2":{"134":1}}],["是指想制造出与人类大脑作用效果相同的机器",{"2":{"1098":1}}],["是指小批量数据的最后时间步的隐状态",{"2":{"325":1}}],["是指自主提高模型完成某些任务的效能",{"2":{"286":1}}],["是指",{"2":{"252":2}}],["是指在前向传播期间可能影响x计算的所有元素",{"2":{"131":1}}],["是指函数的所有梯度都消失但既不是全局最小值也不是局部最小值的任何位置",{"2":{"102":1}}],["是多少",{"2":{"124":1}}],["是关于索引i的训练样本的损失函数",{"2":{"113":1}}],["是学习率按预定时间表o",{"2":{"106":1}}],["是全局最小值",{"2":{"101":1}}],["是梯度下降中的一种常用技术",{"2":{"53":1}}],["是半正定的",{"2":{"51":1}}],["是所谓的拉格朗日乘数",{"2":{"48":1}}],["是凸集",{"2":{"52":1}}],["是凸的当且仅当对于所有x",{"2":{"46":1}}],["是凸的",{"2":{"45":1,"46":2}}],["是凸性的基础",{"2":{"40":1}}],["是生成模型",{"2":{"42":1}}],["是将y积分后的分布",{"2":{"42":1}}],["是它可能如何分布的最佳猜测",{"2":{"42":1}}],["是什么",{"0":{"1339":1,"1347":1,"1348":1},"2":{"20":1,"989":1}}],["2给定θ",{"2":{"1190":1}}],["2对代价函数求偏导数的结果如下",{"2":{"1189":1}}],["2但是如果我们既没有用户的参数",{"2":{"1189":1}}],["2如果我们要用梯度下降法来求解最优解",{"2":{"1188":1}}],["2其中",{"2":{"1188":1}}],["2其中μc",{"2":{"1152":1}}],["2π",{"2":{"1184":1}}],["2πσ2",{"2":{"616":1}}],["2∑i=1n",{"2":{"1154":1}}],["2这里的",{"2":{"1146":1}}],["2prp+r",{"2":{"1140":1}}],["2ε最后我们还需要对通过反向传播方法计算出的偏导数进行检验",{"2":{"1124":1}}],["2个",{"2":{"1097":1}}],["2v",{"2":{"1093":1}}],["2等等的所有值",{"2":{"1093":1}}],["2的二次方",{"2":{"1092":1}}],["2的一次方",{"2":{"1092":1}}],["2的格子",{"2":{"1091":1}}],["2矩阵",{"2":{"1090":1}}],["2分别表示矩阵sz的维度",{"2":{"1089":1}}],["2^6等等",{"2":{"1088":1}}],["2最小",{"2":{"1064":1}}],["2表示第2类癌症",{"2":{"1060":1}}],["2表示完全连接层",{"2":{"472":2}}],["2上的求和输出是什么形状",{"2":{"1004":1}}],["2i−1",{"2":{"992":1,"993":1}}],["272",{"2":{"959":2}}],["2e",{"2":{"895":2,"963":6}}],["21m∑i=1m",{"2":{"1160":1}}],["21",{"2":{"862":3,"1148":1,"1281":1}}],["21类",{"2":{"862":1}}],["2是整数",{"2":{"862":1}}],["2服务器是最佳的",{"2":{"845":1}}],["2实例中的连接都使用了",{"2":{"842":1}}],["2690v4",{"2":{"813":4}}],["29762941",{"2":{"1121":1}}],["29",{"2":{"813":1}}],["2minx",{"2":{"1190":1}}],["2m",{"2":{"785":1,"786":1,"1120":1,"1188":1}}],["2节末尾",{"2":{"759":1}}],["2节",{"2":{"746":1}}],["2语料库中的一对句子生成的预训练",{"2":{"723":1}}],["2语料库的一对句子生成的预训练样本",{"2":{"722":1}}],["2数据集作为小批量的预训练样本",{"2":{"725":1}}],["2数据集上对bert进行预训练",{"2":{"725":1}}],["2数据集上预训练bert",{"2":{"686":1}}],["2数据集生成的预训练样本",{"2":{"725":1}}],["2数据集保留了原来的标点符号",{"2":{"723":1}}],["2数据集",{"2":{"722":5,"725":1}}],["2数据集中",{"2":{"718":1}}],["2ns",{"2":{"802":1}}],["2n",{"2":{"578":2}}],["2说明了应用重置门之后的计算流程",{"2":{"541":1}}],["231",{"2":{"1121":1}}],["23=32",{"2":{"958":1}}],["23",{"2":{"481":1}}],["2+λ2∑i=1nm∑k=1n",{"2":{"1189":2,"1190":1}}],["2+λ2∑j=1nu∑k=1n",{"2":{"1188":1,"1189":1,"1190":2}}],["2+λ2",{"2":{"1188":1}}],["2+λ∑j=1nθj2",{"2":{"1115":1,"1116":1}}],["2+10最小的值u",{"2":{"1143":1}}],["2+1000θ32+10000θ42",{"2":{"1115":1}}],["2+1取得最小值时的u值",{"2":{"1143":1}}],["2+ϵ",{"2":{"467":1}}],["2+2β时动量收敛",{"2":{"95":1}}],["2+2",{"2":{"31":1,"111":1,"118":1}}],["24xlarge实例",{"2":{"819":1}}],["24",{"2":{"407":31,"408":14,"488":8,"993":4,"994":4}}],["2jpi+δ",{"2":{"400":1}}],["2jpi",{"2":{"400":1}}],["2j+1",{"2":{"400":4}}],["2j+1=cos⁡",{"2":{"398":1}}],["2j",{"2":{"400":2}}],["2j=sin⁡",{"2":{"398":1}}],["2×2矩阵",{"2":{"1090":1}}],["2×2投影矩阵不依赖于任何位置的索引i",{"2":{"400":1}}],["2×0",{"2":{"959":1}}],["2×0+0",{"2":{"291":1}}],["2×∞+0",{"2":{"291":1}}],["2会抵消",{"2":{"270":1}}],["2和3中绘制10个随机变量x",{"2":{"775":1}}],["2和32",{"2":{"488":1}}],["2和apache",{"2":{"300":1}}],["2和1种可能的方式出现在2×2图像上",{"2":{"912":1}}],["2和16",{"2":{"488":1}}],["2和1",{"2":{"270":1,"959":1}}],["2和0",{"2":{"174":1,"575":1}}],["2=1−σi=1ksiiσi=1msii≤1",{"2":{"1160":1}}],["2=",{"2":{"743":1}}],["2=∑j=1nine",{"2":{"247":1}}],["2=sigmoid",{"2":{"236":1}}],["2xtxθ−xty−xty−0",{"2":{"1086":1}}],["2xtxθ−xty−",{"2":{"1086":1}}],["2x",{"2":{"237":2,"239":1,"262":1}}],["2x1",{"2":{"57":1}}],["2行",{"2":{"141":1}}],["28英尺",{"2":{"1086":1}}],["288",{"2":{"488":4}}],["28×28像素",{"2":{"462":1}}],["28×28=784个灰度像素值组成",{"2":{"217":1}}],["28",{"2":{"136":8,"330":4,"473":2,"474":2,"582":4,"623":2,"636":2,"827":2,"920":1,"1086":1,"1133":1,"1408":1}}],["2相比",{"2":{"95":1}}],["2而言",{"2":{"95":1}}],["25英寸硬盘",{"2":{"815":1}}],["25gb",{"2":{"802":1}}],["255",{"2":{"584":1,"863":1,"919":1,"933":3,"947":3}}],["2500个特征",{"2":{"1097":1}}],["250",{"2":{"376":1,"848":10}}],["25",{"2":{"88":1,"101":2,"236":1,"301":1,"813":2,"848":4,"920":1,"1196":1,"1218":1,"1315":1,"1390":1,"1398":1,"1419":1}}],["25会导致一条几乎没有收敛的轨迹",{"2":{"88":1}}],["256mb",{"2":{"813":2}}],["256kb或更大",{"2":{"805":1}}],["256=1",{"2":{"488":2}}],["256",{"2":{"67":4,"77":36,"78":4,"137":1,"173":6,"175":4,"176":12,"216":1,"217":4,"225":10,"325":4,"418":2,"422":6,"423":5,"424":3,"442":5,"461":8,"473":2,"474":2,"483":1,"488":14,"495":6,"502":5,"503":1,"508":1,"523":3,"528":3,"546":3,"560":3,"583":4,"622":1,"629":1,"679":2,"686":2,"688":2,"819":6,"826":5,"872":4,"883":3,"893":1,"903":3,"905":5,"932":4,"945":15,"958":7,"959":6,"964":2}}],["22σj2",{"2":{"1180":1,"1184":1}}],["22σ2",{"2":{"1179":1}}],["221",{"2":{"1121":1}}],["220",{"2":{"1121":1}}],["225",{"2":{"872":3,"903":6,"919":3,"947":3}}],["225d66f04cae318b841a13d32af3acc165f253ac",{"2":{"686":1}}],["229",{"2":{"872":3,"903":6,"919":3,"947":3}}],["224",{"2":{"461":8,"488":4,"495":8,"502":8,"508":8,"872":9,"903":12,"919":3,"947":3}}],["22",{"2":{"80":4,"81":4}}],["20px",{"2":{"1444":1}}],["2068874e4b9a9f0fb07ebe0ad2b29754449ccacd",{"2":{"889":1}}],["2080ti",{"2":{"812":1}}],["2080ti拥有4352个cuda核心",{"2":{"809":1}}],["2080ti有一条352位宽的总线",{"2":{"802":1}}],["208",{"2":{"488":4,"813":1}}],["2024",{"2":{"1040":1}}],["2023",{"2":{"891":6}}],["2021",{"2":{"231":1,"411":1,"642":1}}],["2020年9月18日",{"2":{"1437":1}}],["2020",{"2":{"198":1,"300":1,"411":1,"929":1,"1394":1}}],["2008",{"2":{"1002":2}}],["200~800",{"2":{"813":1}}],["200mb",{"2":{"804":1}}],["2006",{"2":{"455":1}}],["2006或其他手动调整的流水线来输入数据",{"2":{"454":1}}],["2007中引入的键",{"2":{"844":1}}],["2007",{"2":{"355":1}}],["2009年",{"2":{"456":1}}],["2009",{"2":{"345":1,"349":1}}],["2003",{"2":{"341":1}}],["2002",{"2":{"301":1,"309":1,"578":1}}],["2005",{"2":{"300":1,"455":1,"521":1}}],["2001",{"2":{"299":1,"397":1,"519":1}}],["200px",{"2":{"291":1}}],["200×200彩色照片由200×200×3=120000个数值组成",{"2":{"284":1}}],["2000台正常引擎和10台异常引擎的数据作为测试集",{"2":{"1181":1}}],["2000台正常引擎和10台异常引擎的数据作为交叉检验集",{"2":{"1181":1}}],["2000平方英尺",{"2":{"1082":1}}],["2000多年后",{"2":{"980":1}}],["2000的一个非常特殊的例子",{"2":{"519":1}}],["2000",{"2":{"115":1,"300":1}}],["200",{"2":{"80":4,"81":4,"271":1,"407":4,"409":4,"680":3,"813":1,"879":6,"946":3,"1501":1}}],["2004和surf",{"2":{"454":1}}],["2004",{"2":{"62":1,"302":1,"455":1,"1359":1}}],["20",{"2":{"71":1,"73":2,"95":1,"262":1,"263":4,"271":1,"369":5,"390":4,"418":2,"422":6,"423":2,"424":1,"425":20,"437":1,"442":6,"736":3,"773":1,"813":1,"834":9,"836":3,"895":3,"927":1,"938":6,"956":6,"957":6,"963":3,"969":5,"992":4,"994":4,"1102":5,"1131":1,"1145":1,"1467":2,"1469":1}}],["2013和连续词袋",{"2":{"782":1}}],["2013",{"2":{"493":1,"773":1,"775":1,"782":1,"788":1,"937":1}}],["2013中找到灵感",{"2":{"373":1}}],["2013的讨论",{"2":{"86":1}}],["2016的设计",{"2":{"942":1}}],["2016中的方法",{"2":{"966":1}}],["2016中的resnet",{"2":{"826":1}}],["2016中的表1",{"2":{"505":1}}],["2016则把结合gpu和cpu的训练应用到计算机视觉模型中",{"2":{"795":1}}],["2016作为激活函数",{"2":{"740":1}}],["2016",{"2":{"300":1,"301":1,"395":2,"403":1,"404":1,"422":1,"491":2,"500":1,"505":1,"619":1,"660":1,"672":1,"718":1,"722":1,"811":1,"916":1,"920":1,"952":1,"953":1,"967":1}}],["2016提出的一种启发式算法",{"2":{"72":1}}],["2019中的图2",{"2":{"942":1}}],["2019等自然语言处理预训练模型中的输入表示",{"2":{"757":1}}],["2019和roberta",{"2":{"757":1}}],["2019",{"2":{"300":1,"657":1}}],["2019表明",{"2":{"32":1}}],["2010在分布式隐变量模型的背景下引入的",{"2":{"840":1}}],["2010",{"2":{"247":1,"300":1,"301":1,"891":6}}],["2010年期间亚利桑那州埃姆斯市的房价",{"2":{"205":1}}],["2015提出将选择性搜索替换为区域提议网络",{"2":{"939":1}}],["2015对r",{"2":{"938":1}}],["2015和掩码r",{"2":{"936":1}}],["2015和英文维基百科的连接上进行了预训练",{"2":{"737":1}}],["2015还使用了某些卷积神经网络中间层的输出",{"2":{"868":1}}],["2015的网络架构大放异彩",{"2":{"486":1}}],["2015",{"2":{"235":1,"300":2,"466":1,"491":1,"666":1,"757":1,"861":1,"936":1}}],["2015了解详细分析",{"2":{"95":1}}],["2014然后",{"2":{"937":1}}],["2014也是将深度模型应用于目标检测的开创性工作之一",{"2":{"936":1}}],["2014中描述了系统和开源库",{"2":{"840":1}}],["2014中的表1改编",{"2":{"744":1}}],["2014中的表1构建其他常见模型",{"2":{"511":1}}],["2014对跳元模型做了三个修改",{"2":{"743":1}}],["2014的第4",{"2":{"746":1}}],["2014的卷积神经网络架构",{"2":{"698":1}}],["2014的设计中",{"2":{"572":1}}],["2014的速度明显更快",{"2":{"538":1}}],["2014进行训练",{"2":{"356":1}}],["2014",{"0":{"1193":1},"2":{"170":1,"300":3,"373":1,"507":1,"538":1,"572":3,"832":1,"843":1,"1526":1}}],["2014将所有这些技术汇总到一个高效的学习算法中",{"2":{"32":1}}],["2012中描述了push和pull的语义",{"2":{"840":1}}],["2012中提出的",{"2":{"19":1}}],["2012",{"2":{"832":1,"945":1}}],["2012年",{"2":{"458":1}}],["2012复制的",{"2":{"455":1}}],["2012的第一作者",{"2":{"455":1}}],["2012建议以rmsprop算法作为将速率调度与坐标自适应学习率分离的简单修复方法",{"2":{"106":1}}],["2017能够有效地利用这些详尽的标注信息进一步提升目标检测的精度",{"2":{"940":1}}],["2017和elmo",{"2":{"731":1}}],["2017表1所示的不同densenet版本",{"2":{"485":1}}],["2017在某种程度上是resnet的逻辑扩展",{"2":{"478":1}}],["2017提出的",{"2":{"310":1}}],["2017年",{"2":{"169":1}}],["2017了解精彩动画",{"2":{"95":1}}],["2017",{"2":{"78":1,"86":2,"250":1,"300":4,"301":1,"345":1,"349":1,"380":1,"395":3,"398":1,"403":3,"491":1,"581":1,"658":1,"731":1,"756":1,"759":1,"811":1,"832":1,"856":1,"936":1,"966":1}}],["2018的研究结果表明最优的同步策略是将网络分解成两个环",{"2":{"842":1}}],["2018只需要最少的架构改变",{"2":{"733":1}}],["2018有两个不同模型尺寸的版本",{"2":{"726":1}}],["2018中声称的行为是相反的",{"2":{"475":1}}],["2018分别将批量规范化的性质与贝叶斯先验相关联",{"2":{"467":1}}],["2018和",{"2":{"467":1}}],["2018在凸优化的背景下进行了详细的理论讨论",{"2":{"86":1}}],["2018",{"2":{"73":1,"248":1,"300":1,"301":2,"475":1,"731":1,"732":1,"841":1}}],["2018来了解个中细节",{"2":{"66":1}}],["2018这样比较有意思的新优化变体",{"2":{"38":1}}],["2018为st提出了的改进更新和参数初始化",{"2":{"35":1}}],["2018给adam算法提供了一个称为yogi的热补丁来解决这些问题",{"2":{"32":1}}],["2011或关于该主题的最新课程",{"2":{"800":1}}],["2011的结果",{"2":{"75":1}}],["2011",{"2":{"26":1,"205":1,"316":1,"700":1,"712":1}}],["2011通过将粗略的计数器s",{"2":{"25":1}}],["2|f",{"2":{"60":1}}],["2f",{"2":{"60":3,"68":3,"89":1,"95":1,"107":1,"583":1,"828":3,"837":3,"964":3}}],["2使用adagrad算法",{"2":{"31":1}}],["2d中的单输入通道二维互相关",{"2":{"699":1}}],["2d",{"2":{"27":10,"57":13,"87":28,"88":9,"108":6,"113":2,"114":4,"130":1,"156":2,"160":1,"409":8,"699":1,"1297":1}}],["2来调整学习率",{"2":{"25":1}}],["2",{"0":{"1059":1,"1063":1,"1064":2,"1065":1,"1066":1,"1067":1,"1068":1,"1069":1,"1070":1,"1073":1,"1081":1,"1089":1,"1098":1,"1107":1,"1115":1,"1121":1,"1130":1,"1138":1,"1144":1,"1151":1,"1157":1,"1165":1,"1172":1,"1179":1,"1188":1,"1216":1,"1219":1,"1224":1,"1230":1,"1240":1,"1247":1,"1255":1,"1262":1,"1270":1,"1310":1,"1319":1,"1326":1,"1327":1,"1328":2,"1329":1,"1330":1,"1333":1,"1340":1,"1362":1,"1368":1,"1375":1,"1376":1,"1377":2,"1378":1,"1381":1,"1390":1,"1400":1,"1439":1,"1442":1,"1443":1,"1444":2,"1445":1,"1450":1,"1474":1,"1489":1,"1498":1,"1507":1,"1514":1,"1523":1,"1536":1},"1":{"1225":1,"1226":1,"1271":1,"1272":1,"1273":1,"1327":1,"1328":1,"1329":1,"1330":1,"1376":1,"1377":1,"1378":1,"1401":1,"1402":1,"1443":1,"1444":1,"1445":1,"1451":1,"1452":1,"1453":1,"1454":1,"1515":1,"1516":1},"2":{"20":1,"27":7,"41":6,"44":2,"54":9,"55":1,"56":1,"57":6,"59":3,"60":1,"64":2,"65":1,"67":6,"70":1,"72":1,"77":8,"78":4,"80":1,"81":6,"87":16,"88":1,"99":5,"101":2,"102":10,"103":4,"108":6,"111":1,"113":4,"115":1,"118":1,"120":4,"121":1,"122":2,"126":2,"128":3,"129":24,"134":1,"137":14,"141":8,"146":7,"147":8,"162":3,"164":10,"165":1,"172":4,"174":4,"204":1,"208":2,"209":1,"210":2,"232":17,"235":8,"236":8,"237":8,"242":4,"262":5,"263":3,"264":2,"265":2,"270":1,"274":8,"282":1,"291":2,"300":1,"305":1,"307":1,"318":2,"325":4,"330":8,"334":4,"335":4,"350":6,"357":2,"368":24,"369":26,"370":11,"375":9,"376":1,"379":1,"382":20,"386":4,"388":11,"389":3,"390":16,"391":8,"396":4,"398":16,"405":4,"406":19,"407":15,"408":32,"409":13,"413":4,"414":9,"418":2,"421":1,"422":6,"425":4,"429":4,"430":2,"431":10,"432":2,"435":5,"436":3,"437":7,"442":4,"445":2,"447":4,"448":8,"472":21,"473":1,"475":1,"479":1,"480":4,"482":8,"487":24,"488":1,"492":1,"502":16,"508":3,"515":1,"523":3,"528":3,"529":1,"541":1,"550":1,"555":2,"566":1,"573":2,"574":7,"575":21,"576":5,"578":1,"582":4,"587":1,"588":1,"589":2,"591":2,"592":1,"597":1,"599":4,"601":4,"603":2,"610":1,"611":2,"613":1,"616":11,"621":1,"631":5,"633":4,"634":3,"635":9,"640":1,"648":1,"650":1,"663":1,"667":6,"668":3,"674":11,"686":2,"687":6,"699":6,"702":8,"709":1,"713":7,"715":1,"718":6,"722":6,"725":2,"726":6,"727":2,"733":1,"734":11,"736":3,"737":3,"743":2,"751":1,"754":1,"757":1,"762":3,"763":9,"765":11,"767":3,"774":2,"775":2,"776":7,"790":9,"813":1,"816":1,"817":2,"819":4,"821":1,"824":1,"826":12,"827":1,"828":2,"834":27,"835":7,"837":3,"842":2,"847":3,"848":12,"849":18,"852":6,"853":5,"854":15,"858":5,"862":3,"863":15,"865":1,"866":11,"872":1,"873":2,"874":2,"879":3,"883":9,"886":1,"893":4,"894":15,"906":3,"907":3,"912":6,"919":5,"927":3,"928":1,"932":2,"933":6,"938":7,"945":15,"946":12,"947":3,"956":9,"957":9,"958":3,"959":3,"961":3,"962":2,"963":3,"964":13,"966":16,"968":14,"970":10,"974":4,"976":4,"977":8,"981":8,"984":1,"987":1,"989":4,"992":8,"993":4,"994":8,"1004":2,"1011":1,"1012":2,"1016":1,"1017":22,"1018":32,"1019":8,"1020":6,"1027":1,"1028":3,"1036":3,"1044":1,"1045":1,"1046":1,"1047":1,"1059":1,"1060":1,"1061":2,"1063":1,"1064":2,"1065":1,"1066":1,"1067":1,"1068":1,"1069":2,"1070":1,"1073":1,"1080":4,"1081":5,"1084":1,"1086":3,"1088":7,"1089":15,"1090":8,"1091":4,"1092":6,"1093":1,"1098":1,"1099":11,"1100":19,"1103":1,"1107":1,"1109":2,"1111":6,"1112":4,"1115":1,"1116":2,"1117":3,"1120":3,"1121":4,"1124":1,"1125":1,"1130":1,"1131":3,"1132":2,"1133":1,"1138":2,"1139":1,"1144":1,"1145":15,"1146":2,"1147":2,"1148":2,"1150":1,"1151":2,"1152":1,"1153":1,"1154":4,"1157":1,"1158":1,"1160":1,"1161":1,"1165":3,"1166":1,"1172":1,"1178":1,"1179":2,"1180":2,"1184":1,"1185":1,"1188":1,"1189":1,"1191":1,"1193":27,"1216":3,"1218":3,"1221":2,"1225":1,"1240":3,"1242":1,"1243":1,"1247":1,"1255":1,"1296":1,"1314":1,"1371":2,"1398":1,"1402":2,"1413":1,"1414":1,"1417":1,"1419":1,"1426":1,"1432":1,"1433":1,"1443":1,"1444":1,"1483":1,"1501":1}}],["x中的mixin",{"2":{"1471":1}}],["x中的值根据权重w的加权和",{"2":{"997":1}}],["xxx",{"2":{"1444":1,"1455":2}}],["xk",{"2":{"1188":2,"1189":4,"1190":1}}],["x∼n",{"2":{"1179":1}}],["x为2维",{"2":{"1161":1}}],["x以$",{"2":{"1110":1}}],["x则",{"2":{"1100":1}}],["x版本",{"2":{"1088":1}}],["xθ−y",{"2":{"1086":4}}],["x将是不可逆的",{"2":{"1086":1}}],["x等价于x",{"2":{"1085":1}}],["x值来得出",{"2":{"1063":1}}],["x后",{"2":{"1021":1}}],["x∈rm×n",{"2":{"1000":1}}],["x∈rd",{"2":{"162":1}}],["x关于的x的导数",{"2":{"976":1}}],["x关于x的偏导数",{"2":{"976":2}}],["xu",{"2":{"942":1}}],["xb−xawa−μxσx",{"2":{"852":1}}],["xb",{"2":{"852":1}}],["xmax",{"2":{"848":3}}],["xmin",{"2":{"848":3}}],["x和y的元素个数为",{"2":{"1154":1}}],["x和y的小批量损失",{"2":{"605":4}}],["x和",{"2":{"1092":1}}],["x和eargetensor的发布",{"2":{"819":1}}],["xeon",{"2":{"814":1}}],["x表示2个bert输入序列",{"2":{"736":1}}],["xappox≈x",{"2":{"1161":1}}],["xappox=ureduce⋅z",{"2":{"1161":1}}],["xa",{"2":{"852":1}}],["xaxis",{"2":{"582":3}}],["xa0",{"2":{"565":1}}],["xavier中描述的xavier初始化",{"2":{"893":1}}],["xavier中介绍的xavier随机初始化模型参数",{"2":{"137":1}}],["xavier初始化表明",{"2":{"249":1}}],["xavier初始化从均值为零",{"2":{"247":1}}],["xavier初始化",{"0":{"247":1}}],["xavieruniform",{"2":{"137":1,"350":1,"435":1,"436":1,"573":2,"574":3,"702":1,"713":2,"767":1,"873":1,"883":1}}],["xavier",{"2":{"67":2,"137":2,"247":1,"350":2,"435":6,"576":5,"680":1,"702":2,"713":3,"726":1,"767":1,"863":1,"873":2,"874":1,"883":2,"893":1,"905":1,"961":1}}],["xcv",{"2":{"1131":2,"1132":1}}],["xc组合而成的",{"2":{"923":1}}],["xc",{"2":{"558":8,"559":8}}],["xo",{"2":{"558":8,"559":8}}],["xr",{"2":{"544":8,"545":8,"1154":1}}],["xz",{"2":{"544":8,"545":8}}],["x→",{"2":{"479":1}}],["x→r是凸的",{"2":{"41":1}}],["x604",{"2":{"351":4}}],["x603",{"2":{"351":3}}],["x602",{"2":{"351":2}}],["x601",{"2":{"351":1}}],["xh和w",{"2":{"340":1}}],["xh",{"2":{"331":8,"332":9,"340":7,"544":8,"545":9}}],["x4∣x2",{"2":{"317":1}}],["x4∣x3",{"2":{"317":1}}],["x4",{"2":{"317":4,"640":1}}],["x3等等",{"2":{"1129":1}}],["x3是输入单元",{"2":{"1099":1}}],["x3=x33",{"2":{"1084":1}}],["x3和x4",{"2":{"641":1}}],["x3∣h3",{"2":{"519":1}}],["x3∣x1",{"2":{"317":1}}],["x3∣x2",{"2":{"317":1}}],["x3+",{"2":{"479":1}}],["x3",{"2":{"317":5,"640":1,"1080":1,"1099":3}}],["x3c",{"2":{"0":8,"13":1,"72":2,"122":1,"172":9,"351":3,"363":2,"567":3,"568":4,"569":6,"575":3,"576":4,"577":16,"634":1,"635":3,"668":6,"687":12,"693":2,"695":6,"720":3,"721":7,"722":18,"726":3,"727":5,"734":3,"738":3,"748":1,"757":3,"773":2,"774":1,"775":1,"854":6,"890":1,"964":3,"966":2,"977":4,"1219":1,"1226":1,"1324":1,"1330":1,"1342":1,"1343":2,"1344":2,"1398":1,"1399":1,"1405":1,"1409":3,"1410":4,"1412":3,"1426":1,"1430":4,"1431":15,"1432":4,"1433":2,"1434":7,"1435":6,"1444":10,"1445":16,"1451":16,"1454":19,"1455":16,"1456":22,"1457":22,"1459":18,"1460":15,"1462":12,"1463":18,"1464":23,"1465":24,"1466":24,"1467":16,"1468":29,"1469":19,"1470":11,"1471":21,"1474":22,"1477":6,"1478":6,"1479":16,"1481":6,"1482":6,"1484":2,"1490":14,"1491":1,"1492":8,"1497":27,"1498":5,"1500":30,"1501":40,"1503":31,"1506":15,"1507":22,"1508":20,"1522":10,"1523":15}}],["x∣w",{"2":{"280":1}}],["x∣y",{"2":{"42":3,"182":1,"192":4}}],["x^608",{"2":{"351":1}}],["x^608=f",{"2":{"351":1}}],["x^609=f",{"2":{"351":1}}],["x^607",{"2":{"351":2}}],["x^607=f",{"2":{"351":1}}],["x^606",{"2":{"351":3}}],["x^606=f",{"2":{"351":1}}],["x^605",{"2":{"351":4}}],["x^605=f",{"2":{"351":1}}],["x^3",{"2":{"262":1,"264":1}}],["x^2",{"2":{"262":1,"264":1}}],["xj=xj−μj",{"2":{"1159":1}}],["xj−μj",{"2":{"1180":1,"1184":1}}],["xj−lj",{"2":{"1146":1}}],["xj−1",{"2":{"519":1}}],["xj∣hj",{"2":{"519":1}}],["xj∣x−j",{"2":{"519":3}}],["xj+1",{"2":{"519":1}}],["xj2",{"2":{"247":1}}],["xj",{"2":{"247":1,"307":1,"1080":1,"1109":11,"1110":3,"1116":2,"1117":1,"1165":1,"1166":1,"1168":1,"1180":2,"1184":1}}],["xw+b的求和会使用广播机制",{"2":{"644":1}}],["xwxh+bh",{"2":{"339":1}}],["xw",{"2":{"232":3}}],["x←x−μσ",{"2":{"209":1}}],["x←x−ηdiag",{"2":{"61":1}}],["x←x−η∇fi",{"2":{"113":1}}],["x←x−η∇f",{"2":{"57":1}}],["x←x−ηf",{"2":{"54":1}}],["xnor",{"2":{"1102":1}}],["xnor=",{"2":{"1102":1}}],["xn=xn−μnsn",{"2":{"1082":1}}],["xn是向量的元素",{"2":{"990":1}}],["xn的函数",{"2":{"984":1}}],["xn看作常数",{"2":{"982":1}}],["xn∈r",{"2":{"621":1}}],["xnyn",{"2":{"390":1}}],["xn",{"2":{"118":1,"190":1,"191":3,"195":1,"386":1,"390":1,"396":3,"982":3,"983":1,"984":1,"1000":1,"1080":1,"1101":1}}],["xs",{"2":{"321":15}}],["xstar得到边界",{"2":{"115":1}}],["xstar我们在时间t+1时获得参数之间距离的边界",{"2":{"115":1}}],["xstar代入",{"2":{"115":1}}],["xstar",{"2":{"115":3}}],["xscale=",{"2":{"318":2,"635":1,"981":1}}],["xscale",{"2":{"80":1,"635":1,"981":4}}],["xyz=",{"2":{"1500":1}}],["xyz事件被触发",{"2":{"1499":1}}],["xyz",{"2":{"1499":2}}],["xy=",{"2":{"858":1}}],["xy=xy",{"2":{"99":2}}],["xytext=xytext",{"2":{"99":2}}],["xytext",{"2":{"99":2}}],["xy",{"2":{"99":2,"441":2,"836":6,"848":2,"852":2,"854":2}}],["x0+θ31",{"2":{"1099":1}}],["x0+θ21",{"2":{"1099":1}}],["x0+θ11",{"2":{"1099":1}}],["x0=1",{"2":{"1085":1}}],["x0",{"2":{"95":2,"667":2,"1081":1,"1116":1,"1117":1}}],["xl",{"2":{"1154":1}}],["xla可以进一步优化jit的编译代码",{"2":{"819":1}}],["xlabel=none",{"2":{"635":1,"981":1}}],["xlabel=",{"2":{"67":3,"80":4,"81":4,"137":4,"211":1,"213":1,"263":4,"275":4,"278":4,"318":2,"335":4,"357":1,"369":1,"370":1,"376":3,"388":4,"392":8,"398":4,"399":4,"409":4,"576":4,"616":2,"635":1,"726":3,"767":3,"883":3,"894":3,"906":3,"927":3,"963":3}}],["xlabel",{"2":{"57":3,"89":1,"95":1,"102":2,"107":1,"357":3,"566":3,"635":1,"693":1,"981":4,"1026":4}}],["xlim",{"2":{"635":1,"981":4}}],["xlim=none",{"2":{"635":1,"981":1}}],["xlim=",{"2":{"67":3,"80":5,"81":4,"137":4,"211":1,"213":1,"263":4,"275":4,"278":4,"335":4,"350":2,"351":3,"386":1,"392":4,"576":4,"635":1,"726":3,"767":3,"828":3,"837":3,"883":3,"894":3,"906":3,"927":3,"963":3}}],["xlist",{"2":{"566":2}}],["xd",{"2":{"57":1,"618":1}}],["x超出了最优解x=0并逐渐发散",{"2":{"55":1}}],["x的概率值",{"2":{"1180":1}}],["x的平方以及x的立方",{"2":{"1092":1}}],["x的结果是奇异矩阵",{"2":{"1086":1}}],["x的结果是不可逆的",{"2":{"1086":2}}],["x的结果是不可逆的情况咋办呢",{"2":{"1086":1}}],["x的不可逆的问题很少发生",{"2":{"1086":1}}],["x的所有掩蔽位置mlm",{"2":{"736":1}}],["x的任一输入序列中预测的3个指示",{"2":{"736":1}}],["x的每一行是一个样本",{"2":{"610":1}}],["x的有效长度",{"2":{"569":1}}],["x的形状保持不变",{"2":{"734":3}}],["x的形状以便后面可以做广播运算",{"2":{"472":1}}],["x的形状",{"2":{"332":4,"737":3}}],["x的目标函数的梯度计算为",{"2":{"113":1}}],["x的值接近其位于",{"2":{"57":1}}],["x的值最终将接近最优解",{"2":{"54":1}}],["x的迭代不能保证降低f",{"2":{"55":1}}],["x|wx=b",{"2":{"52":1}}],["x|x∈x",{"2":{"45":1}}],["x|x∈rd",{"2":{"40":1,"52":1}}],["xf",{"2":{"47":1,"558":8,"559":8}}],["x+1",{"2":{"1183":1}}],["x+c",{"2":{"1183":1}}],["x+y",{"2":{"1000":1}}],["x+h",{"2":{"981":2}}],["x+f",{"2":{"479":1}}],["x+ξ",{"2":{"52":1}}],["x+",{"2":{"46":1}}],["x+ϵ2+x−ϵ2",{"2":{"46":1}}],["x+ϵ",{"2":{"46":2,"52":1,"54":2,"57":1,"59":2}}],["x=log",{"2":{"1183":1}}],["x=layer",{"2":{"461":2}}],["x=frontage∗depth=area",{"2":{"1084":1}}],["x=a",{"2":{"1028":1}}],["x=5",{"2":{"1028":3}}],["x=h2",{"2":{"834":1}}],["x=h1",{"2":{"834":2}}],["x=xc",{"2":{"1183":1}}],["x=x",{"2":{"834":1,"1036":1}}],["x=3",{"2":{"775":1}}],["x=2",{"2":{"775":1}}],["x=1",{"2":{"775":1,"981":1,"1028":1}}],["x=tf",{"2":{"559":1}}],["x=outputs",{"2":{"332":1}}],["x=",{"2":{"46":1,"172":2,"480":1,"487":1,"990":1,"998":1,"1146":1,"1154":1}}],["x−e",{"2":{"1036":1}}],["x−xj",{"2":{"388":2,"389":1}}],["x−xi",{"2":{"388":3,"389":2}}],["x−μx",{"2":{"1154":3}}],["x−μ^b",{"2":{"467":1}}],["x−μ",{"2":{"209":1,"616":1,"1179":1,"1184":4}}],["x−μσ",{"2":{"209":1}}],["x−z",{"2":{"156":1}}],["x−q−1c",{"2":{"94":4}}],["x−ηg",{"2":{"334":1}}],["x−η∇f",{"2":{"62":1}}],["x−ηf",{"2":{"54":2}}],["x−y",{"2":{"46":2}}],["x−ab−af",{"2":{"46":1}}],["x−a",{"2":{"46":1}}],["x−ϵ",{"2":{"46":2}}],["x−1",{"2":{"44":1}}],["x⊤y=∑i=1dxiyi",{"2":{"997":1}}],["x⊤y",{"2":{"997":1}}],["x⊤y∥x∥∥y∥∈",{"2":{"781":1}}],["x⊤x",{"2":{"612":1}}],["x⊤hx≥0",{"2":{"46":1}}],["x⊤qx可以被简化为∥z∥2",{"2":{"26":1}}],["x∗−xt",{"2":{"115":1}}],["x∗",{"2":{"44":7,"60":1,"115":2}}],["x是不可逆的",{"2":{"1086":2}}],["x是一个长度为4的向量",{"2":{"974":1}}],["x是模型参数",{"2":{"115":1}}],["x是随机变量",{"2":{"42":1}}],["x是凸集的要求是必要的",{"2":{"41":1}}],["xiang",{"2":{"1479":1,"1481":1,"1482":1,"1483":1}}],["xiao",{"2":{"248":1,"581":1}}],["xiao等人演示了通过使用精心设计的初始化方法",{"2":{"248":1}}],["xinwen",{"2":{"1478":1,"1479":1}}],["xi+1",{"2":{"982":2}}],["xi+h",{"2":{"982":1}}],["xi−1",{"2":{"982":2}}],["xi−b",{"2":{"621":1}}],["xi开始",{"2":{"744":1}}],["xik",{"2":{"631":1}}],["xij=xji",{"2":{"743":1}}],["xij",{"2":{"631":1,"743":2}}],["xiong",{"2":{"73":1,"301":1,"395":1,"403":1,"718":1,"731":1}}],["xi",{"2":{"42":1,"52":1,"78":1,"86":2,"115":2,"116":1,"190":2,"191":11,"196":2,"307":1,"386":1,"388":4,"389":1,"396":1,"558":8,"559":9,"742":1,"982":1}}],["x2的乘积",{"2":{"1129":1}}],["x2的平方",{"2":{"1129":1}}],["x2+θ33",{"2":{"1099":1}}],["x2+θ23",{"2":{"1099":1}}],["x2+θ13",{"2":{"1099":1}}],["x2+f",{"2":{"479":1}}],["x2是以平方米为尺寸规格计算的房子",{"2":{"1086":1}}],["x2=x22",{"2":{"1084":1}}],["x2=depth",{"2":{"1084":1}}],["x26",{"2":{"796":3,"1315":1,"1408":1,"1435":2,"1481":2}}],["x2∣h2",{"2":{"519":2}}],["x2∣x1",{"2":{"317":2}}],["x2−w2",{"2":{"118":1}}],["x2方向的梯度比水平x1方向的梯度大得多",{"2":{"87":1}}],["x2",{"2":{"27":6,"57":39,"87":20,"88":3,"108":6,"113":10,"118":1,"315":2,"316":1,"317":5,"408":8,"441":15,"609":1,"640":1,"641":1,"858":5,"982":1,"983":1,"984":2,"1036":1,"1080":1,"1081":1,"1093":1,"1097":1,"1099":1,"1101":1,"1129":1,"1145":1,"1146":2,"1154":1,"1156":1,"1188":1}}],["x1andx2",{"2":{"1102":1}}],["x1∼x3",{"2":{"1100":1}}],["x1+θ32",{"2":{"1099":1}}],["x1+θ22",{"2":{"1099":1}}],["x1+θ12",{"2":{"1099":1}}],["x1+x2",{"2":{"31":1,"111":1}}],["x1x2+x1x3+x1x4+",{"2":{"1097":1}}],["x1x2⋮xn",{"2":{"990":1}}],["x1=x2∗",{"2":{"1086":1}}],["x1=frontage",{"2":{"1084":1}}],["x16",{"2":{"813":2}}],["x1∣h1",{"2":{"519":2}}],["x1∣x0",{"2":{"348":1}}],["x1和x5处于",{"2":{"397":1}}],["x1y1",{"2":{"390":1}}],["x1来估计xt",{"2":{"348":1}}],["x1可能是不必要的",{"2":{"347":1}}],["x1本身因t而异",{"2":{"347":1}}],["x12x2和x3x52都是3次单项式",{"2":{"269":1}}],["x1−w1",{"2":{"118":1}}],["x1−x2",{"2":{"31":1,"111":1}}],["x1方向上的收敛有所改善",{"2":{"87":1}}],["x1",{"2":{"27":6,"57":39,"87":20,"88":3,"108":6,"113":10,"115":2,"118":2,"190":1,"191":3,"195":1,"307":1,"315":2,"316":1,"317":7,"337":2,"338":1,"342":2,"346":1,"347":4,"348":2,"349":2,"386":1,"396":2,"519":6,"609":1,"667":2,"858":5,"982":3,"983":1,"984":1,"1080":1,"1081":1,"1093":1,"1129":1,"1146":2,"1154":1,"1156":2}}],["xtest",{"2":{"1130":2,"1178":1}}],["xta",{"2":{"1100":1}}],["xtx",{"2":{"1085":3,"1086":3}}],["xtype",{"2":{"575":2}}],["xt进行编码",{"2":{"574":1}}],["xt和ht−1",{"2":{"573":1}}],["xtwxc+ht−1whc+bc",{"2":{"554":1}}],["xtwxo+ht−1who+bo",{"2":{"553":1}}],["xtwxf+ht−1whf+bf",{"2":{"553":1}}],["xtwxi+ht−1whi+bi",{"2":{"553":1}}],["xtwxz+ht−1whz+bz",{"2":{"540":1}}],["xtwxr+ht−1whr+br",{"2":{"540":1}}],["xtwxh+",{"2":{"541":1}}],["xtwxh+ht−1whh的计算",{"2":{"340":1}}],["xtwxh+ht−1whh+bh",{"2":{"340":1}}],["xtwxh",{"2":{"521":2}}],["xt∈rn×d",{"2":{"521":1,"527":1,"540":1}}],["xt∈rd和yt",{"2":{"312":1}}],["xt∼p",{"2":{"346":1}}],["xt是在时间步t从该序列中观察到的实际词元",{"2":{"342":1}}],["xt的每一行对应于来自该序列的时间步t处的一个样本",{"2":{"340":1}}],["xt中的函数f",{"2":{"338":1}}],["xt∣ht",{"2":{"347":1,"519":13}}],["xt∣ht−1",{"2":{"338":1}}],["xt∣xt+1",{"2":{"349":2}}],["xt∣xt−1",{"2":{"315":1,"337":2,"338":2,"342":2,"346":1,"347":3,"348":2}}],["xt∣x1",{"2":{"316":1}}],["xt⟶estimate",{"2":{"196":1}}],["xt+1∣xt−1",{"2":{"348":2}}],["xt+1∣xt",{"2":{"317":2,"348":4,"349":1}}],["xt+1",{"2":{"115":2,"348":1}}],["xt+1=xt−ηt∂xf",{"2":{"115":1}}],["xt+1=xt−ηλxt=",{"2":{"95":1}}],["xt−τ",{"2":{"347":1,"348":1,"350":1}}],["xt−n+1",{"2":{"338":1}}],["xt−1∣ht−1",{"2":{"519":1}}],["xt−1",{"2":{"307":1,"316":1,"347":2,"348":6,"350":1}}],["xt−x∗",{"2":{"115":1}}],["xt−q−1c",{"2":{"94":1}}],["xticks",{"2":{"102":2}}],["xt←xt−1−ηst+ϵ⊙gt",{"2":{"107":1}}],["xt←xt−1−ηtvt",{"2":{"88":1}}],["xt←xt−1−gt",{"2":{"33":1}}],["xt",{"2":{"27":2,"78":1,"95":1,"115":12,"196":2,"307":9,"310":2,"315":3,"316":1,"338":2,"340":1,"347":1,"348":3,"349":4,"519":8,"573":2}}],["xt=xt−1−gt",{"2":{"20":1}}],["x¯=def∑t=1tηtxt∑t=1tηt",{"2":{"115":1}}],["x¯−x¯0",{"2":{"26":1}}],["x¯i的变化可能是剧烈的",{"2":{"26":1}}],["x¯",{"2":{"26":4,"115":3}}],["x",{"2":{"25":1,"26":2,"27":1,"31":2,"41":23,"42":5,"44":17,"45":8,"46":13,"47":4,"48":6,"49":3,"50":1,"52":4,"54":48,"55":3,"56":8,"57":11,"59":34,"60":13,"61":1,"62":2,"64":1,"67":16,"80":24,"81":17,"87":2,"89":3,"93":1,"94":3,"95":1,"97":2,"99":16,"101":17,"102":20,"103":14,"105":1,"107":3,"108":1,"111":1,"113":13,"115":13,"116":3,"118":2,"120":12,"121":4,"122":9,"126":10,"127":6,"128":9,"129":13,"136":15,"137":40,"141":32,"142":8,"145":1,"146":13,"147":22,"148":13,"153":3,"154":1,"155":1,"156":1,"158":2,"162":1,"164":1,"170":1,"172":36,"174":20,"180":5,"189":1,"190":5,"191":22,"192":2,"195":2,"209":4,"210":8,"211":17,"218":10,"219":16,"235":41,"236":38,"237":36,"239":1,"241":1,"242":20,"262":2,"263":6,"264":1,"270":2,"271":1,"275":16,"278":8,"312":1,"316":19,"318":4,"320":5,"321":9,"325":17,"330":7,"332":36,"334":2,"335":14,"340":5,"348":1,"350":18,"351":11,"363":2,"368":28,"375":46,"382":84,"386":36,"387":1,"388":30,"389":2,"390":7,"392":28,"396":8,"398":42,"404":2,"405":8,"406":20,"407":50,"408":57,"413":9,"414":10,"418":3,"422":16,"423":11,"424":19,"425":51,"429":8,"433":4,"435":3,"436":1,"437":5,"441":34,"442":21,"447":7,"448":7,"449":6,"451":1,"461":13,"467":1,"472":51,"479":11,"480":30,"481":8,"487":20,"488":15,"495":15,"500":2,"501":38,"502":19,"508":16,"533":4,"534":4,"535":16,"545":18,"559":21,"569":5,"573":35,"574":39,"575":30,"576":24,"577":24,"582":8,"583":1,"584":8,"591":2,"595":9,"599":7,"600":2,"602":2,"605":9,"616":13,"631":27,"632":2,"634":6,"635":24,"636":3,"646":1,"669":3,"677":6,"681":5,"688":24,"692":2,"694":9,"699":15,"708":1,"709":3,"721":2,"722":10,"726":85,"727":6,"731":4,"734":30,"736":24,"737":15,"738":13,"742":2,"743":4,"744":3,"750":12,"751":2,"757":2,"762":2,"765":2,"768":12,"776":4,"790":5,"792":3,"796":34,"797":12,"819":12,"820":12,"821":12,"827":8,"828":12,"834":3,"836":9,"837":33,"848":23,"853":1,"854":1,"858":1,"862":5,"863":11,"866":23,"883":22,"893":5,"896":18,"905":4,"906":4,"912":1,"920":24,"923":8,"925":2,"926":9,"927":27,"932":1,"938":10,"948":6,"954":3,"956":6,"959":21,"963":6,"964":14,"966":28,"968":16,"969":15,"970":6,"971":1,"974":48,"975":19,"976":32,"979":6,"981":76,"983":8,"984":1,"986":4,"989":21,"990":11,"991":7,"992":1,"993":9,"994":12,"995":11,"997":13,"998":11,"1000":10,"1004":2,"1013":8,"1017":26,"1018":41,"1020":15,"1021":14,"1022":4,"1028":1,"1036":12,"1060":1,"1061":5,"1063":4,"1064":2,"1069":5,"1077":1,"1080":5,"1081":10,"1084":6,"1085":10,"1086":5,"1091":1,"1092":5,"1093":8,"1099":2,"1100":5,"1101":5,"1107":7,"1108":3,"1109":35,"1110":16,"1112":8,"1114":1,"1115":4,"1116":4,"1117":13,"1120":8,"1121":2,"1126":1,"1130":1,"1131":1,"1132":1,"1141":1,"1143":4,"1146":7,"1147":1,"1150":1,"1151":1,"1152":1,"1154":2,"1159":4,"1160":3,"1161":3,"1165":3,"1166":1,"1168":2,"1176":1,"1178":7,"1179":3,"1180":10,"1181":1,"1183":1,"1184":8,"1185":5,"1188":1,"1189":8,"1190":8,"1220":3,"1236":1,"1239":2,"1240":6,"1242":2,"1243":3,"1247":2,"1259":2,"1359":1,"1368":1,"1405":1,"1426":1,"1443":3,"1501":3,"1503":1}}],["即以",{"2":{"1314":1}}],["即以序列开始词元",{"2":{"409":1}}],["即像上图中的第1",{"2":{"1184":1}}],["即这个测试数据不属于该组数据的几率如何",{"2":{"1178":1}}],["即这条从0点开始的水平直线",{"2":{"1143":1}}],["即总共有10000",{"2":{"1162":1}}],["即聚类中心点的个数要小于所有训练集实例的数量",{"2":{"1153":1}}],["即θ0=0",{"2":{"1145":1}}],["即n=2时",{"2":{"1145":1}}],["即向量u的欧几里得长度",{"2":{"1145":1}}],["即向量或轴的元素数量",{"2":{"991":1}}],["即u的长度",{"2":{"1145":1}}],["即努力将正样本和负样本用最大的间距分开",{"2":{"1144":1}}],["即用参数来决定是更关心第一项的优化",{"2":{"1143":1}}],["即用于深度学习的命令式工具",{"2":{"300":1}}],["即最小化a",{"2":{"1143":1}}],["即最好不要基于未来的数据进行训练",{"2":{"352":1}}],["即要求当",{"2":{"1143":1}}],["即位于右边的水平部分和位于左边的直线部分",{"2":{"1143":1}}],["即y=0",{"2":{"1143":1}}],["即y可以表示为x中元素的加权和",{"2":{"609":1}}],["即到了该图的右边",{"2":{"1143":1}}],["即首先用正向传播方法计算出每一层的激活单元",{"2":{"1121":1}}],["即x1+x2≥3时",{"2":{"1108":1}}],["即hθ",{"2":{"1107":1}}],["即便没学过编程也能大致猜到它在干什么",{"2":{"1296":1}}],["即便θ0不等于0",{"2":{"1145":2}}],["即便不是那么完美的算法",{"2":{"1138":1}}],["即便运行得不完美",{"2":{"1138":1}}],["即便效果不好",{"2":{"1138":1}}],["即便我们只采用两两特征的组合",{"2":{"1097":1}}],["即便矩阵x",{"2":{"1086":1}}],["即b=",{"2":{"1077":1}}],["即b的概率相当于计算a的所有可能选择",{"2":{"1033":1}}],["即4行2列",{"2":{"1072":1}}],["即线性回归算法",{"2":{"1068":1}}],["即我的学习速率太小",{"2":{"1068":1}}],["即我们希望更高的查准率",{"2":{"1140":1}}],["即我们在选择λ的值时也需要思考与刚才选择多项式模型次数类似的问题",{"2":{"1133":1}}],["即我们不做任何正则化处理时有",{"2":{"1121":2}}],["即我们可以用x",{"2":{"1017":1}}],["即我们可以使用大小为ηi=η0s",{"2":{"25":1}}],["即我们有替换地从离散分布中采样n个观测值",{"2":{"116":1}}],["即我们最初开始向着解决方案迈进的速度有多快",{"2":{"66":1}}],["即告诉我们",{"2":{"1063":1}}],["即每组里的人们彼此都熟识",{"2":{"1061":1}}],["即每个观测发生两次",{"2":{"83":1}}],["即每个观测值只处理一次",{"2":{"82":1}}],["即无监督学习中没有任何的标签或者是有相同的标签或者就是没标签",{"2":{"1061":1}}],["即是良性或恶性肿瘤",{"2":{"1061":1}}],["即是正确的",{"2":{"634":1}}],["即房子的价格",{"2":{"1060":1}}],["即掷骰子",{"2":{"1026":1}}],["即此事件",{"2":{"1026":1}}],["即形状的所有元素乘积",{"2":{"1017":1}}],["即形状为",{"2":{"882":1}}],["即形状为3×3",{"2":{"126":1}}],["即a⊤+b⊤=",{"2":{"1004":1}}],["即加法",{"2":{"989":1}}],["即考虑如何把事情做到最好",{"2":{"980":1}}],["即自动微分",{"2":{"973":1}}],["即访问self",{"2":{"959":3}}],["即赋值语句self",{"2":{"959":3}}],["即有特别亮或者特别暗的颗粒像素",{"2":{"924":1}}],["即chw",{"2":{"923":1}}],["即ck−1+dk−1=",{"2":{"269":1}}],["即内容层",{"2":{"920":1}}],["即得到",{"2":{"1077":1}}],["即得到最终的合成图像",{"2":{"917":1}}],["即得到属于每个类别的概率",{"2":{"639":1}}],["即不仅仅要求θtx",{"2":{"1144":1}}],["即不同的个体是否有着一个特定的基因",{"2":{"1061":1}}],["即不可能发生事件的概率是0",{"2":{"1027":1}}],["即不断更新合成图像",{"2":{"917":1}}],["即不到处理器满负荷所需的十分之一",{"2":{"77":1}}],["即风格迁移所需迭代的模型参数",{"2":{"917":1}}],["即风格迁移",{"2":{"916":1}}],["即提取的特征",{"2":{"905":2}}],["即图像分割",{"2":{"944":1}}],["即图像增广和微调",{"2":{"886":1}}],["即图像的分辨率",{"2":{"417":1}}],["即应用在图像上",{"2":{"882":1}}],["即目标模型",{"2":{"870":1}}],["即目标函数f",{"2":{"57":1}}],["即源模型",{"2":{"870":1}}],["即两个边界框相交面积与相并面积之比",{"2":{"849":1}}],["即按gpu的数量进行扩展",{"2":{"839":1}}],["即代码通常只在完全定义了过程之后才执行计算",{"2":{"817":1}}],["即执行加法计算并将结果存储为变量",{"2":{"816":1}}],["即训练集数据量不够支持我们训练一个复杂的非线性模型",{"2":{"1148":1}}],["即训练过程中需要存储所有的中间结果用来计算梯度",{"2":{"811":1}}],["即训练示例",{"2":{"116":1}}],["即它可能是正值",{"2":{"1145":1}}],["即它们实际的售价然后运用学习算法",{"2":{"1060":1}}],["即它们可能只能由给定的核心访问",{"2":{"810":1}}],["即它使我们能够解决以下形式的约束优化",{"2":{"47":1}}],["即它使用状态变量",{"2":{"33":1}}],["即少了一个数量级",{"2":{"810":1}}],["即极大似然估计",{"2":{"784":1}}],["即条件独立性",{"2":{"783":1}}],["即条件分布p",{"2":{"181":1}}],["即跳元模型",{"2":{"782":1}}],["即概率向量是",{"2":{"655":1}}],["即观察到的不仅仅是一个结果",{"2":{"648":1}}],["即属于哪个类别",{"2":{"639":1}}],["即同一列",{"2":{"631":1}}],["即下溢",{"2":{"624":1}}],["即上采样",{"2":{"863":1}}],["即上溢",{"2":{"624":1}}],["即上一时间步的隐状态",{"2":{"573":1}}],["即梯度不更新",{"2":{"601":1}}],["即ϵ服从均值为0的正态分布",{"2":{"599":1}}],["即其它情况l",{"2":{"597":1}}],["即其导数是单位矩阵",{"2":{"46":1}}],["即2",{"2":{"591":2,"976":1}}],["即2×2",{"2":{"126":1}}],["即当前步的隐状态",{"2":{"573":1}}],["即当输入为0时导数为0",{"2":{"235":1}}],["即门控循环单元",{"2":{"550":1}}],["即vocab",{"2":{"528":1}}],["即python语句if和for",{"2":{"823":1}}],["即p",{"2":{"515":1,"574":1,"1025":1,"1027":3,"1035":1}}],["即3×3",{"2":{"510":1}}],["即增长率",{"2":{"482":1}}],["即变量值的分布在训练过程中会发生变化",{"2":{"475":1}}],["即通过这些p",{"2":{"1145":1}}],["即通过回归来推出一个连续的输出",{"2":{"1060":1}}],["即通过减去其均值并除以其标准差",{"2":{"467":1}}],["即通过学习和自动确定代码中所做的设计选择来改进",{"2":{"304":1}}],["即第二个样本到我的参数向量θ的投影",{"2":{"1145":1}}],["即第五个神经网络层",{"2":{"437":1}}],["即第三个神经网络层",{"2":{"431":1,"437":1}}],["即第i个最常用单词的频率ni为",{"2":{"318":1}}],["即如果训练集有",{"2":{"1147":1}}],["即如果实际标签p",{"2":{"646":1}}],["即如何根据输入`x`返回所需的模型输出",{"2":{"423":1}}],["即如何根据输入x返回所需的模型输出",{"2":{"423":3}}],["即如下的算法更新",{"2":{"61":1}}],["即模型构建",{"2":{"421":1}}],["即直到数据第一次通过模型传递时",{"2":{"417":1}}],["即直到该查询位置为止",{"2":{"408":1}}],["即词元的个数",{"2":{"368":1}}],["即词表的大小",{"2":{"331":1}}],["即注意力权重",{"2":{"367":1}}],["即人类的注意力被视为可以交换的",{"2":{"354":1}}],["即余震通常发生在很短的时间跨度和很近的距离内",{"2":{"345":1}}],["即大地震发生后",{"2":{"345":1}}],["即限制任何给定的小批量数据",{"2":{"334":1}}],["即函数具有任意数量的变量的情况",{"2":{"984":1}}],["即函数f在常数l下是利普希茨连续的",{"2":{"334":1}}],["即函数不应该对其输入的微小变化敏感",{"2":{"170":1}}],["即len",{"2":{"330":1}}],["即从原始训练集中拆分验证集",{"2":{"902":1}}],["即从序列开始起的超过t个时间步",{"2":{"312":1}}],["即从其真实分布p",{"2":{"190":1}}],["即初始条件的很小变化就会导致结果发生不成比例的变化",{"2":{"308":1}}],["即只显示每个输入如何连接到输出",{"2":{"618":1}}],["即只使用非自主性提示",{"2":{"356":1}}],["即只要有可能尝试很多东西来了解它们之间的关系",{"2":{"300":1}}],["即只在偶尔出现的特征",{"2":{"25":1}}],["即一个衡量",{"2":{"980":1}}],["即一个从环境观察映射到行动的功能",{"2":{"298":1}}],["即一次计算一个样本",{"2":{"232":1}}],["即需要向模型提供巨大数据集",{"2":{"296":1}}],["即需要将结果的概率乘以与之相关的收益",{"2":{"291":1}}],["即标签",{"2":{"290":1}}],["即预测值和真实值之差的绝对值",{"2":{"962":1}}],["即预测值与实际值之差的平方",{"2":{"286":1}}],["即预测",{"2":{"289":1}}],["即预测与实际情况不符的样本比例",{"2":{"286":1}}],["即欧几里得距离",{"2":{"270":1}}],["即防止泛化误差过大",{"2":{"267":1}}],["即10和15",{"2":{"862":1}}],["即1和x",{"2":{"265":1}}],["即1",{"2":{"264":1}}],["即表达能力不足",{"2":{"258":1}}],["即较少训练迭代周期",{"2":{"254":1}}],["即很容易找出假设失效的情况",{"2":{"253":1}}],["即区分猫和狗的唯一要求是评估单个像素的强度",{"2":{"230":1}}],["即可查看结果",{"2":{"213":1}}],["即可将该值分配给a",{"2":{"77":1}}],["即将空间维度中的每个像素视为单个样本",{"2":{"494":1}}],["即将数值表示的压力从尾数转移到指数",{"2":{"241":1}}],["即将δ",{"2":{"210":1}}],["即将其权重分散到许多特征中",{"2":{"168":1}}],["即新新闻的出现",{"2":{"193":1}}],["即输入的分布保持不变",{"2":{"180":1}}],["即实际应用",{"2":{"179":1}}],["即实数的d",{"2":{"40":1}}],["即e",{"2":{"170":1}}],["即权重的值取自均值为0的高斯分布",{"2":{"168":1}}],["即为原本的高斯分布模型了",{"2":{"1184":1}}],["即为恒等映射",{"2":{"501":1}}],["即为常量参数",{"2":{"425":2}}],["即为",{"2":{"152":1,"1101":1}}],["即tensorflow中输入的最后维度是通道",{"2":{"147":1}}],["即z",{"2":{"145":1}}],["即利用相近像素之间的相互关联性",{"2":{"134":1}}],["即kh=kw=1",{"2":{"122":1}}],["即逐步降低学习率",{"2":{"117":1}}],["即凸环境下的学习率",{"2":{"114":1}}],["即st←γst−1+",{"2":{"106":1}}],["即st和δxt",{"2":{"21":1}}],["即分布是对称的",{"2":{"105":1}}],["即对于某个特定的",{"2":{"1124":1}}],["即对于任意权重值",{"2":{"232":1}}],["即对于具有正特征值的矩阵",{"2":{"94":1}}],["即对于所有x∈rn",{"2":{"46":1}}],["即速度",{"2":{"91":1}}],["即中度扭曲的椭球目标",{"2":{"87":1}}],["即平均梯度减小了方差",{"2":{"86":1}}],["即在",{"2":{"1143":1}}],["即在所有位置上进行求和",{"2":{"497":1}}],["即在paddlepaddle中表示一个块的类",{"2":{"422":1}}],["即在pytorch中表示一个块的类",{"2":{"422":1}}],["即在keras中表示一个块的类",{"2":{"422":1}}],["即在gluon中表示块的类",{"2":{"422":1}}],["即在时间上是前进的",{"2":{"349":1}}],["即在时间步",{"2":{"346":1}}],["即在深层网络的所有层上应用权重衰减",{"2":{"278":1}}],["即在只有嘈杂的梯度可用的情况下执行优化时会发生什么",{"2":{"84":1}}],["即在一阶近似中",{"2":{"54":1}}],["即样本总数",{"2":{"80":1}}],["即ηt+1←ηt⋅α其中α∈",{"2":{"70":1}}],["即η=0",{"2":{"27":1}}],["即决定选择多少层以及决定每层分别有多少个单元",{"2":{"1126":1}}],["即决定选择",{"2":{"64":1}}],["即确保f在如何变化它的值方面没有任何",{"2":{"60":1}}],["即∥x−y∥≥∥projx",{"2":{"52":1}}],["即f",{"2":{"52":1,"60":1,"97":1}}],["即球不接触壁",{"2":{"48":1}}],["即重力",{"2":{"48":1}}],["即非凸",{"2":{"40":1}}],["即使这从数学上讲是不合适的",{"2":{"1138":1}}],["即使这些预测的时间步超过了600+4",{"2":{"351":1}}],["即使更新参数的规则看起来基本相同",{"2":{"1110":1}}],["即使所有训练样本的标签",{"2":{"1106":1}}],["即使依靠它现在的功能",{"2":{"1098":1}}],["即使我现在在不同的目录下",{"2":{"1092":1}}],["即使我们现在使用的是8个gpu",{"2":{"842":1}}],["即使我们只关心硬类别",{"2":{"639":1}}],["即使我们的函数确实是线性的且无噪声",{"2":{"613":1}}],["即使我们随后引入了多层感知机",{"2":{"422":1}}],["即使我们不知道如何编写计算机程序来识别",{"2":{"282":1}}],["即使我们不知道怎样明确地告诉计算机如何从输入映射到输出",{"2":{"282":1}}],["即使我们可能遇到这样的数据",{"2":{"252":1}}],["即使我们有比特征多得多的样本",{"2":{"169":1}}],["即使我们接近最小值",{"2":{"113":1}}],["即使x",{"2":{"1086":1}}],["即使得代价函数",{"2":{"1064":1}}],["即使有无限多种特征都可以处理",{"2":{"1060":1}}],["即使你有一个相对较小的训练集",{"2":{"1086":1}}],["即使你之前没有看过微积分",{"2":{"1067":1}}],["即使你将状态持久存储在variable中",{"2":{"1021":1}}],["即使你以前从未使用过机器学习",{"2":{"290":1}}],["即使形状不同",{"2":{"1019":1}}],["即使构建函数的计算图需要通过python控制流",{"2":{"977":1}}],["即使输入是ndarray类型",{"2":{"821":1}}],["即使普通笔记本电脑也有4个或更多线程",{"2":{"792":1}}],["即使确信特征与标签的潜在关系是线性的",{"2":{"610":1}}],["即使现实中不会有任何房子的面积是0或房龄正好是0年",{"2":{"610":1}}],["即使该变量已经存在于目标设备",{"2":{"449":1}}],["即使不需要将经过训练的模型部署到不同的设备上",{"2":{"444":1}}],["即使并非所有输入",{"2":{"373":1}}],["即使用观测序列xt−1",{"2":{"347":1}}],["即使用三脚架拍摄一个静止的物体",{"2":{"145":1}}],["即使训练过程中某个点上发生了梯度爆炸",{"2":{"335":1}}],["即使结果集是相同的",{"2":{"293":1}}],["即使使用简单的描述给定输入特征的预测标签",{"2":{"289":1}}],["即使标签是未知的",{"2":{"289":1}}],["即使成绩令人鼓舞",{"2":{"286":1}}],["即使人类的眼睛能毫不费力地完成这些难以提出完美解决方案的任务",{"2":{"281":1}}],["即使模型很简单",{"2":{"254":1}}],["即使认为独立同分布假设是理所当然的",{"2":{"253":1}}],["即使是我接触反向传播这么多年了",{"2":{"1122":1}}],["即使是现在",{"2":{"1122":1,"1176":1}}],["即使是最顶尖的公司",{"2":{"1059":1}}],["即使是在机器学习的专业人士中",{"2":{"1059":1}}],["即使是在复杂的优化问题上",{"2":{"605":1}}],["即使是高端服务器也很少超过64核",{"2":{"457":1}}],["即使是一部普通的也可能被认为是糟糕的",{"2":{"345":1}}],["即使是业余的涂鸦者也可以根据描述场景布局的草图生成照片级真实图像",{"2":{"300":1}}],["即使是顶级程序员也无法提出完美的解决方案",{"2":{"281":1}}],["即使是网络只有一个隐藏层",{"2":{"233":1}}],["即使是对以前从未遇到过的个体",{"2":{"251":1}}],["即使是对复杂模型的微小调整也需要手工重新计算复杂的导数",{"2":{"161":1}}],["即使是对于无噪声凸问题",{"2":{"86":1}}],["即使y导致x",{"2":{"182":1}}],["即使疾病的相对流行率随着时间的推移而变化",{"2":{"182":1}}],["即使分辨率减小为十万像素",{"2":{"151":1}}],["即使将隐藏层维度降低到1000",{"2":{"151":1}}],["即使经过1000个迭代步骤",{"2":{"114":1}}],["即使经过50次迭代",{"2":{"113":1}}],["即使对于初学者也很容易使用",{"2":{"103":1}}],["即使深度学习中的优化问题通常是非凸的",{"2":{"38":1}}],["即使在没有非常明显区分的组群的情况下也可以",{"2":{"1151":1}}],["即使在单个cpu或gpu上",{"2":{"799":1}}],["即使在一台机器上有多个cpu处理器",{"2":{"795":1}}],["即使在过滤掉不频繁的词元之后",{"2":{"722":1}}],["即使在我们无法得到解析解的情况下",{"2":{"613":1}}],["即使在暂退法和权重衰减的情况下",{"2":{"475":1}}],["即使在经验方差估计值可能消失的情况下也是如此",{"2":{"467":1}}],["即使在包含数百个层的网络中也是如此",{"2":{"430":1}}],["即使在不同的时间步",{"2":{"340":1}}],["即使在不改变输入或输出大小的情况下",{"2":{"231":1}}],["即使在中世纪",{"2":{"299":1}}],["即使在高度或宽度上移动一个元素",{"2":{"146":1}}],["即使在通常使用循环神经网络的一维序列结构任务上",{"2":{"134":1}}],["即使在凸环境下",{"2":{"35":1}}],["即使在无噪声的情况下",{"2":{"27":1}}],["即使只在小批量上",{"2":{"26":1}}],["即",{"2":{"20":2,"126":1,"154":1,"158":1,"191":1,"209":1,"332":1,"513":1,"619":1,"744":1,"785":1,"997":1,"1004":1,"1028":1,"1069":1,"1076":1,"1077":3,"1081":2,"1085":1,"1089":1,"1097":1,"1100":1,"1102":1,"1108":1,"1109":1,"1110":1,"1112":2,"1120":1,"1122":1,"1131":1,"1134":1,"1143":2,"1147":1,"1151":2}}],["与消息订阅与发布",{"2":{"1499":1}}],["与集中式版本控制",{"2":{"1318":1}}],["与集合",{"0":{"1196":1}}],["与监督学习有些相似",{"2":{"1182":1}}],["与随机梯度下降相同",{"2":{"1166":1}}],["与用户是独立的",{"2":{"1158":1}}],["与同一个中心点关联的所有点聚成一类",{"2":{"1151":1}}],["与地标",{"2":{"1146":1}}],["与正态分布无直接关系",{"2":{"1146":1}}],["与逻辑回归和神经网络相比",{"2":{"1143":1}}],["与计算得到的",{"2":{"1122":1}}],["与计算代价的线性增长相比",{"2":{"78":1}}],["与实际值",{"2":{"1121":1}}],["与真实值之间的距离为每个样本",{"2":{"1120":1}}],["与真实环境互动",{"2":{"297":2}}],["与此不同的是",{"2":{"1150":1}}],["与此相反",{"2":{"1093":1}}],["与此同时",{"2":{"300":1}}],["与单变量线性回归类似",{"2":{"1081":1}}],["与单个gpu所能处理的数据相比",{"2":{"832":1}}],["与那些不知道如何使用的人",{"2":{"1059":1}}],["与外部数据源",{"2":{"1040":1}}],["与独立",{"2":{"1034":1}}],["与任何python数组一样",{"2":{"1020":1}}],["与l2范数相比",{"2":{"1000":1}}],["与矩阵类似",{"2":{"993":1}}],["与矩阵变换的联系",{"0":{"970":1}}],["与普通的python数组一样",{"2":{"991":1}}],["与常规卷积不同",{"2":{"969":1}}],["与通过卷积核减少输入元素的常规卷积相反",{"2":{"971":1}}],["与通过卷积核",{"2":{"968":1}}],["与图像分类任务不同",{"2":{"959":1}}],["与图像分类或目标检测不同",{"2":{"948":1}}],["与语义分割不同",{"2":{"944":1}}],["与目标检测相比",{"2":{"943":1}}],["与目标检测不同",{"2":{"943":1}}],["与fast",{"2":{"939":1}}],["与block实例需要使用forward函数不同的是hybridblock实例需要使用hybrid",{"2":{"821":1}}],["与张量核对齐",{"2":{"814":1}}],["与pcie类似",{"2":{"812":1}}],["与ptb数据集相比",{"2":{"723":1}}],["与高效的单处理器实现相比",{"2":{"810":1}}],["与并行计算的区别是通信操作使用的资源",{"2":{"797":1}}],["与跳元模型不同",{"2":{"786":1}}],["与跳元模型的主要区别在于",{"2":{"785":1}}],["与跳元模型相比",{"2":{"756":1}}],["与拟合非对称条件概率pij的word2vec不同",{"2":{"743":1}}],["与transformerencoder不同",{"2":{"734":1}}],["与elmo冻结预训练模型的参数不同",{"2":{"732":1}}],["与原始的transformer编码器不同",{"2":{"734":1}}],["与原始的bert基础模型一样大",{"2":{"686":1}}],["与原始bert模型相同",{"2":{"729":1}}],["与词相似度和类比任务一样",{"2":{"712":1}}],["与没有近似训练的相比",{"2":{"709":1}}],["与输入假设b的软对齐",{"2":{"674":1}}],["与输入前提a的软对齐以及前提",{"2":{"674":1}}],["与输入序列或编码器的时间步t不同",{"2":{"574":1}}],["与假设中的",{"2":{"674":2}}],["与机器翻译中源句和目标句之间的词元对齐类似",{"2":{"673":1}}],["与机器学习文献中成千上万类似模糊的说法相比",{"2":{"475":1}}],["与保留前提和假设中词元的顺序相比",{"2":{"673":1}}],["与情感分析相反",{"2":{"669":1}}],["与线性回归中不同",{"2":{"1109":1}}],["与线性回归中的损失函数类似",{"2":{"922":1}}],["与线性回归一样",{"2":{"630":1,"641":1}}],["与线性模型不同",{"2":{"169":1}}],["与训练类似",{"2":{"577":1}}],["与训练端到端",{"2":{"454":1}}],["与填充词元对应的掩码将被设置为0",{"2":{"575":1}}],["与预测",{"0":{"529":1,"546":1}}],["与预测不同",{"2":{"297":1}}],["与多层感知机一样",{"2":{"527":1}}],["与多层感知机不同的是",{"2":{"340":1}}],["与alexnet相比",{"2":{"511":1}}],["与alexnet",{"2":{"508":1}}],["与芯片设计中工程师从放置晶体管到逻辑元件再到逻辑块的过程类似",{"2":{"506":1}}],["与googlenet一样",{"2":{"502":1}}],["与r",{"2":{"938":1}}],["与ram访问一样",{"2":{"812":1}}],["与resnet类似",{"2":{"482":2}}],["与rmsprop不同",{"2":{"33":1}}],["与编码器的自注意力的情况类似",{"2":{"409":1}}],["与下面的热图所示相似",{"2":{"399":1}}],["与非参数的注意力汇聚模型相比",{"2":{"392":1}}],["与加性注意力演示相同",{"2":{"370":1}}],["与键",{"2":{"356":1}}],["与金钱类似",{"2":{"354":1}}],["与本节中描述的语言模型相关的问题有哪些",{"2":{"344":1}}],["与wxh和whh的拼接的矩阵乘法",{"2":{"340":1}}],["与前几章中略有不同",{"2":{"837":1}}],["与前提中的",{"2":{"674":2}}],["与前向递归一样",{"2":{"519":1}}],["与前一个时间步的隐藏变量一起计算得出",{"2":{"340":1}}],["与前面的部分不同",{"2":{"210":1}}],["与当前第i个子序列样本相邻",{"2":{"335":1}}],["与上一节相比",{"2":{"326":1}}],["与上一层相比",{"2":{"136":1}}],["与猴子使用打字机完全不同的是",{"2":{"315":1}}],["与以前工作的另一个不同之处是接受次优解",{"2":{"302":1}}],["与一个算法自动执行的数百万个选择相比",{"2":{"302":1}}],["与五子棋不同的是",{"2":{"301":1}}],["与神经网络不同的是",{"2":{"299":1}}],["与环境互动",{"0":{"297":1}}],["与文本相比",{"2":{"295":1}}],["与解决回归问题不同",{"2":{"291":1}}],["与传统机器学习方法相比",{"2":{"284":1}}],["与应用程序进行交互",{"2":{"281":1}}],["与特征选择相比",{"2":{"270":1}}],["与梯度向量",{"2":{"241":1}}],["与梯度下降的0",{"2":{"95":1}}],["与我们之前在图像分类或目标检测部分介绍的卷积神经网络不同",{"2":{"861":1}}],["与我们在深度学习程序中看到的操作类似",{"2":{"819":1}}],["与我们在sigmoid函数图像中看到的类似",{"2":{"237":1}}],["与我们将在本书中所讲到的其他大部分模型不同",{"2":{"612":1}}],["与我们前面的例子相比",{"2":{"230":1}}],["与sigmoid函数类似",{"2":{"237":1}}],["与softmax回归的简洁实现",{"2":{"225":1}}],["与sgd算法相比",{"2":{"27":1}}],["与算法伦理应用有关的哲学问题",{"2":{"179":1}}],["与小批量训练相比",{"2":{"167":1}}],["与互相关运算符一样",{"2":{"146":1}}],["与卷积层一样",{"2":{"147":1}}],["与卷积层类似",{"2":{"146":1}}],["与卷积核进行互相关计算得到的",{"2":{"141":1}}],["与全连接层一样",{"2":{"137":1}}],["与大批量一次处理数据的",{"2":{"82":1}}],["与其写所有这些for循环的代码",{"2":{"1093":1}}],["与其自己写代码做矩阵乘法",{"2":{"1093":1}}],["与其拥有最大iou的真实边界框的类别是猫",{"2":{"853":2}}],["与其拥有最大iou的真实边界框的类别是狗",{"2":{"853":1}}],["与其距离不超过采样上下文窗口大小的词为其上下文词",{"2":{"774":1}}],["与其他框架对比",{"0":{"1530":1}}],["与其他类型的",{"2":{"734":1}}],["与其他神经元连接",{"2":{"619":1}}],["与其他一些魔法数",{"2":{"467":1}}],["与其他调度器相比",{"2":{"75":1}}],["与其只使用单独一个注意力汇聚",{"2":{"380":1}}],["与其基于单独调整的组件组装系统",{"2":{"302":1}}],["与其在工业和自然科学中的生产性使用一样",{"2":{"299":1}}],["与其相关的参数才会得到有意义的更新",{"2":{"25":1}}],["与之前一样",{"2":{"27":1,"87":1}}],["与",{"0":{"1203":1,"1311":1,"1372":1,"1394":1,"1395":1,"1447":1,"1453":1,"1459":1,"1510":1,"1514":1,"1517":1},"1":{"1448":1,"1449":1,"1511":1,"1512":1,"1513":1,"1515":1,"1516":1,"1518":1,"1519":1},"2":{"20":1,"28":1,"137":1,"312":1,"325":1,"335":1,"340":1,"355":1,"374":1,"376":1,"389":1,"404":1,"409":1,"463":1,"513":1,"541":2,"545":1,"557":1,"564":1,"566":1,"589":1,"590":1,"658":1,"659":1,"681":1,"698":1,"699":1,"702":1,"703":1,"718":1,"750":1,"826":1,"828":1,"899":1,"904":1,"905":1,"908":1,"1054":1,"1100":1,"1109":1,"1146":1,"1199":1,"1205":1,"1359":1,"1444":1,"1516":1,"1523":1}}],["jcnij2−",{"2":{"1154":1}}],["jcv",{"2":{"1131":1}}],["jtrain",{"2":{"1131":1,"1132":1}}],["jtest",{"2":{"1130":1,"1131":1}}],["jval以及梯度gradient",{"2":{"1111":1}}],["jval=",{"2":{"1111":1}}],["jval",{"2":{"1109":2,"1111":1}}],["j$",{"2":{"1093":1}}],["j取值从",{"2":{"1093":1}}],["j等于0",{"2":{"1092":1,"1093":1}}],["j所表达的值是什么样的",{"2":{"1066":1}}],["jpegimages",{"2":{"945":3}}],["jpg|jpeg|png|gif|ico|css|js",{"2":{"1371":1}}],["jpg",{"2":{"848":3,"857":2,"863":3,"878":2,"912":3,"918":5,"945":3,"964":3}}],["j|+|xi",{"2":{"924":1}}],["j|xi",{"2":{"924":1}}],["j表示坐标",{"2":{"924":1}}],["jit",{"2":{"819":7,"820":4,"821":2}}],["jia",{"2":{"300":1,"486":1}}],["j≠0logp",{"2":{"784":1}}],["j≠0p",{"2":{"708":2,"783":1}}],["just",{"2":{"727":3}}],["jslet",{"2":{"1511":1}}],["jsroutes",{"2":{"1478":1}}],["jsconst",{"2":{"1476":2,"1493":1,"1512":1,"1515":1,"1516":1}}],["jsimport",{"2":{"1471":2,"1474":2,"1481":1,"1482":1,"1485":1,"1491":1,"1518":1}}],["js中操作ref对象时候需要",{"2":{"1455":2}}],["js中操作数据需要",{"2":{"1455":1}}],["js发布版3",{"2":{"1437":1}}],["jsximport",{"2":{"1454":1}}],["jsxsetup",{"2":{"1452":1}}],["jsx",{"2":{"1399":1,"1444":2,"1527":1,"1530":1}}],["js",{"0":{"1526":1},"1":{"1527":1,"1528":1,"1529":1,"1530":1,"1531":1},"2":{"1048":6,"1196":1,"1216":1,"1315":3,"1363":2,"1443":1,"1469":1,"1483":1,"1486":1,"1490":1,"1491":1,"1493":1,"1498":1,"1519":1,"1526":1,"1530":1,"1531":2,"1543":1}}],["json序列化与反序列化",{"2":{"1263":1}}],["jsonrpc",{"2":{"1045":1,"1046":1,"1047":1}}],["json",{"2":{"685":3,"686":7,"821":1,"1044":4,"1045":1,"1046":1,"1047":2,"1196":1,"1197":2,"1199":1,"1211":1,"1263":1,"1371":1,"1494":1,"1495":1}}],["jsexport",{"2":{"7":1}}],["j是指",{"2":{"675":1}}],["jj",{"2":{"659":1}}],["j−xi",{"2":{"924":1}}],["j−xi+1",{"2":{"924":1}}],["j−yj",{"2":{"647":1}}],["j−b",{"2":{"156":2}}],["jwijkxixj",{"2":{"416":1}}],["je",{"2":{"376":2,"409":2,"578":2}}],["jensens",{"2":{"42":1,"115":1}}],["jensen",{"2":{"42":1}}],["javascriptimport",{"2":{"1499":1}}],["javascript",{"2":{"1371":1,"1499":1,"1526":1,"1533":1,"1539":1}}],["java等等",{"2":{"1111":1}}],["java",{"2":{"1088":1,"1093":2}}],["jaccard",{"2":{"849":1,"851":17,"1154":1}}],["jampani",{"2":{"844":1}}],["james",{"2":{"355":1}}],["japan",{"2":{"751":1}}],["janzing",{"2":{"349":2}}],["jaeger",{"2":{"309":1}}],["jr",{"2":{"301":1}}],["jobs",{"2":{"1315":1}}],["job",{"0":{"1310":1},"2":{"1310":2,"1311":1,"1312":2,"1313":1,"1315":2}}],["journal",{"2":{"1198":1,"1202":2}}],["jour是ρ",{"2":{"20":1}}],["jouppi",{"2":{"811":1}}],["joulin",{"2":{"756":1,"759":1}}],["john",{"2":{"659":1}}],["joint",{"2":{"1030":1,"1032":1}}],["jointp",{"2":{"519":2}}],["join",{"2":{"206":3,"333":4,"565":2,"577":4,"578":3,"667":1,"686":6,"692":2,"718":1,"748":1,"757":5,"772":1,"773":2,"864":1,"872":6,"874":4,"890":10,"892":5,"901":1,"902":1,"904":5,"908":9,"932":6,"945":9,"949":3,"1011":2}}],["j重写为",{"2":{"155":1}}],["j的相关信息",{"2":{"155":1}}],["j+1层的激活单元数量为行数",{"2":{"1099":1}}],["j+1$",{"2":{"1099":1}}],["j+1|能够尽可能使邻近的像素值相似",{"2":{"924":1}}],["j+1",{"2":{"709":1}}],["j+b",{"2":{"153":2,"154":2,"155":1,"156":1,"158":1}}],["j+∑a∑b",{"2":{"153":1}}],["j+∑k∑l",{"2":{"153":1}}],["j+64",{"2":{"78":8}}],["j=0",{"2":{"1067":1,"1069":1,"1165":1,"1166":1,"1168":1}}],["j=g",{"2":{"675":1}}],["j=1",{"2":{"674":1,"675":1,"676":1,"1000":1,"1069":1,"1116":2,"1117":1,"1120":1}}],["j=l+s",{"2":{"162":1}}],["j=u+∑a=−δδ∑b=−δδ",{"2":{"155":1}}],["j=u+∑a∑b",{"2":{"154":1}}],["j=",{"2":{"153":1}}],["j=bc",{"2":{"77":1}}],["j分别表示输入图像和隐藏表示中位置",{"2":{"153":1}}],["j和",{"2":{"153":1}}],["j",{"2":{"77":24,"78":12,"126":8,"141":2,"145":2,"146":19,"153":9,"154":5,"155":1,"156":1,"158":2,"164":1,"165":1,"211":4,"320":4,"357":3,"376":2,"409":2,"578":2,"600":3,"650":2,"651":3,"676":2,"709":4,"742":4,"757":2,"849":1,"851":6,"924":1,"968":4,"992":1,"1064":1,"1077":6,"1080":2,"1081":2,"1086":2,"1092":2,"1093":4,"1099":4,"1109":7,"1110":2,"1111":2,"1115":1,"1116":1,"1117":1,"1120":2,"1121":5,"1122":2,"1124":2,"1126":1,"1152":1,"1154":1,"1187":5,"1188":27,"1189":21,"1190":11,"1191":5,"1192":1}}],["j保留在cpu缓存中",{"2":{"77":1}}],["j⊤",{"2":{"77":2}}],["uomg",{"2":{"1495":1}}],["uo⊤vc",{"2":{"708":1,"783":1}}],["ul>",{"2":{"1456":2,"1457":2,"1469":2,"1490":2,"1506":2,"1507":2,"1508":2}}],["u>",{"2":{"1431":2}}],["ubuntu",{"2":{"1312":1,"1315":2,"1343":1}}],["uv",{"0":{"1290":1},"1":{"1291":1,"1292":1,"1293":1},"2":{"1292":1,"1293":2,"1294":3}}],["u^tv的示意图",{"2":{"1145":1}}],["u和v之间的夹角大于90度",{"2":{"1145":1}}],["u和v",{"2":{"1145":1}}],["u和v中的元素",{"2":{"1018":1}}],["u−5",{"2":{"1143":2}}],["uri",{"2":{"1048":3}}],["url带有",{"2":{"1476":1}}],["url更加美观",{"2":{"1476":1}}],["urllist",{"2":{"1471":1}}],["url的站点上",{"2":{"206":1}}],["url",{"2":{"79":4,"206":5,"208":2,"361":1,"565":1,"686":4,"748":4,"772":1,"872":1,"889":1,"901":1,"931":1,"945":1,"1315":2,"1431":4}}],["url>",{"2":{"13":1,"1324":1,"1330":1}}],["u2",{"2":{"984":1,"1145":1}}],["u202f",{"2":{"565":1}}],["ucsd",{"2":{"813":2}}],["uc−∑j∈vp",{"2":{"786":1}}],["uc−∑j∈vexp⁡",{"2":{"786":1}}],["uc⊤v¯o",{"2":{"785":1}}],["uci",{"2":{"456":1}}],["uk",{"2":{"744":3}}],["uk⊤vi",{"2":{"742":1,"744":1}}],["uj∑i∈vexp",{"2":{"786":1}}],["uj∑i∈vexp⁡",{"2":{"784":1}}],["uj=uo−∑j∈vp",{"2":{"784":1}}],["uj⊤v¯o",{"2":{"786":1}}],["uj⊤vc",{"2":{"784":2}}],["uj⊤vi+bi+cj≈logxij",{"2":{"744":1}}],["uj⊤vi+bi+cj−logxij",{"2":{"743":1}}],["uj⊤vi−logxij",{"2":{"743":1}}],["uj⊤vi",{"2":{"742":1,"743":1,"744":2}}],["uj−uk",{"2":{"744":1}}],["uj",{"2":{"744":3,"784":1,"786":1}}],["uhk⊤vit",{"2":{"708":1}}],["ui和vi分别是向量c",{"2":{"1018":1}}],["ui",{"2":{"1018":1,"1056":1,"1527":1,"1528":1}}],["uijlings",{"2":{"937":1}}],["uint8",{"2":{"866":3}}],["ui⊤v¯o",{"2":{"785":1,"786":2}}],["ui⊤vc",{"2":{"783":1,"784":3}}],["uit+j⊤vit",{"2":{"708":2}}],["ui来自目标分布",{"2":{"191":1}}],["utc",{"2":{"1315":1}}],["utv=vtu",{"2":{"1145":1}}],["utv就是",{"2":{"1145":1}}],["utv也叫做向量u和v之间的内积",{"2":{"1145":1}}],["utv的结果",{"2":{"1145":1}}],["utils",{"2":{"581":1,"589":1,"668":1,"669":2,"681":2,"687":3,"722":2,"726":1,"777":2,"827":1,"836":3,"874":2,"882":1,"892":3,"904":3,"932":3,"947":1,"948":1,"949":2,"1499":3}}],["utf",{"2":{"565":1,"692":1}}],["upperschool",{"2":{"1493":2}}],["upperlefts",{"2":{"849":9}}],["upstream",{"2":{"1324":1}}],["upsampling",{"2":{"863":1}}],["up",{"2":{"333":1,"1347":1,"1413":2}}],["upload",{"2":{"213":1,"1315":4}}],["updatemoney",{"2":{"1503":5}}],["updatea",{"2":{"1501":4}}],["updatea=",{"2":{"1501":1}}],["updated",{"2":{"1470":1}}],["updates",{"2":{"634":1,"1432":2}}],["update中的w和x都是向量",{"2":{"613":1}}],["update中的相同符号",{"2":{"270":1}}],["updater是更新模型参数的常用函数",{"2":{"335":1,"635":1}}],["updater",{"2":{"221":7,"335":25,"635":27}}],["update=20",{"2":{"72":2}}],["update",{"2":{"68":2,"70":1,"72":5,"129":2,"206":1,"472":6,"540":1,"613":1,"1109":2,"1432":1,"1500":7}}],["um",{"2":{"191":2,"984":1}}],["u1",{"2":{"191":2,"1145":1}}],["unmount",{"2":{"1524":1}}],["undefined",{"2":{"1404":3,"1432":1,"1434":1,"1454":1}}],["underset",{"2":{"1110":1}}],["understudy",{"2":{"578":1}}],["underflow",{"2":{"624":1}}],["underfitting",{"2":{"258":1}}],["underfit",{"2":{"204":1}}],["unrolling",{"2":{"1123":1}}],["until",{"2":{"1116":1,"1117":1}}],["unlock",{"2":{"813":1}}],["un",{"2":{"709":2}}],["unweighted",{"2":{"575":6}}],["unshift",{"2":{"1495":1}}],["unshared",{"2":{"813":1}}],["unsqueeze",{"2":{"369":4,"375":4,"388":4,"390":4,"391":4,"392":6,"399":4,"577":4,"727":5,"848":2,"852":2,"853":4,"854":10,"863":2,"866":2,"919":2,"932":2,"964":2}}],["unsupervised",{"2":{"296":1,"1061":1,"1150":1}}],["unknown",{"2":{"748":2,"890":1,"908":3,"1046":1,"1399":1,"1404":2}}],["unk>",{"2":{"363":1,"748":1,"773":1}}],["unk",{"2":{"363":3,"567":1,"757":4,"772":2,"773":1}}],["unix",{"2":{"1089":1}}],["uniques",{"2":{"854":4}}],["unique",{"2":{"854":5}}],["union",{"0":{"1407":1},"2":{"849":7}}],["uninstall",{"2":{"445":1}}],["unigram",{"2":{"317":1,"318":1}}],["units=10",{"2":{"423":1,"442":1,"502":1}}],["units=256",{"2":{"423":1,"424":1,"442":1}}],["units=8",{"2":{"414":1}}],["units=64",{"2":{"414":1}}],["units=5",{"2":{"414":1}}],["units=3",{"2":{"414":1}}],["units",{"2":{"414":20,"550":1,"1099":1}}],["units和units",{"2":{"414":1}}],["united",{"2":{"292":1}}],["unit",{"2":{"235":1,"457":2,"538":1,"740":1,"807":2,"1099":3,"1122":1,"1444":1}}],["uniform",{"2":{"136":2,"137":1,"141":2,"172":3,"325":3,"350":1,"368":4,"386":1,"391":1,"413":2,"414":5,"418":2,"422":2,"425":2,"429":2,"435":1,"436":3,"437":1,"442":2,"448":2,"461":2,"480":2,"488":2,"495":2,"501":2,"502":2,"508":2,"547":1,"561":1,"576":2,"702":1,"713":2,"767":1,"773":1,"796":2,"827":1,"848":1,"862":1,"873":1,"883":1,"969":1,"1006":1}}],["unbiased",{"2":{"170":1}}],["u",{"2":{"153":2,"247":1,"388":1,"436":1,"757":2,"763":12,"976":12,"984":1,"1000":11,"1018":1,"1145":3,"1158":2,"1159":1,"1160":1,"1404":1,"1431":2,"1471":2}}],["usr",{"2":{"1364":1}}],["usually",{"2":{"1165":1}}],["usb",{"2":{"1040":2,"1042":2}}],["using",{"2":{"1121":1,"1148":1,"1185":1}}],["usingpaddlein",{"2":{"67":1}}],["usingpytorchin",{"2":{"67":1}}],["usingcustomdefinedscheduler",{"2":{"67":2}}],["usetalkstore",{"2":{"1490":3,"1495":1}}],["usecountstore",{"2":{"1490":1,"1491":2,"1492":2,"1493":1}}],["usesumref",{"2":{"1520":1}}],["usesumstore",{"2":{"1490":2}}],["usesum",{"2":{"1471":4}}],["uses",{"2":{"1311":1,"1315":5}}],["username",{"2":{"1500":10}}],["userouter",{"2":{"1485":2}}],["useroute",{"2":{"1481":2,"1482":2,"1485":2}}],["userwithrequiredemail",{"2":{"1435":1}}],["userwithoptionalcontact",{"2":{"1435":1}}],["userresponse",{"2":{"1431":1}}],["usertraditional",{"2":{"1428":1}}],["user>",{"2":{"1410":2,"1431":1}}],["userid",{"2":{"1207":1}}],["user",{"2":{"1168":1,"1215":1,"1327":1,"1336":2,"1410":1,"1412":1,"1419":2,"1428":1,"1431":3,"1434":3,"1435":3}}],["users",{"2":{"1089":1,"1092":2,"1094":1,"1431":2}}],["use",{"2":{"41":2,"129":2,"263":2,"321":4,"329":1,"335":19,"357":1,"369":6,"382":9,"407":12,"421":1,"445":1,"501":12,"502":4,"581":4,"635":1,"826":3,"831":1,"893":3,"981":4,"1052":1,"1183":1,"1443":1,"1474":1,"1489":1,"1524":1}}],["usedog",{"2":{"1471":4}}],["used",{"2":{"0":1}}],["usedata",{"2":{"0":3}}],["usage",{"2":{"0":1}}],["3自带",{"2":{"1272":1}}],["3306",{"2":{"1427":2}}],["33",{"2":{"1092":1}}],["333",{"2":{"1092":1}}],["3367",{"2":{"748":1}}],["3和2分别表示矩阵的第三行和第二列对应的元素",{"2":{"1089":1}}],["3和p4=0",{"2":{"578":1}}],["3表示第3类",{"2":{"1060":1}}],["3+3",{"2":{"1018":1}}],["3j和",{"2":{"992":1}}],["3−1",{"2":{"957":2}}],["34模型",{"2":{"905":1}}],["3之间",{"2":{"903":3}}],["3有128个通道",{"2":{"812":1}}],["3服务器的cpu在多个芯片上拥有高达256mb的高速缓存",{"2":{"810":1}}],["3gb",{"2":{"805":1}}],["319d85e578af0cdc590547f26231e4e31cdf1e42",{"2":{"772":1}}],["36",{"2":{"744":2}}],["3c914d17d80b1459be871a5039ac23e752a53cbe",{"2":{"718":1}}],["3个例子所示",{"2":{"1184":1}}],["3个标量来表示偏置",{"2":{"641":1}}],["3个输出",{"2":{"231":1}}],["3提供了数据流的图形化演示",{"2":{"556":1}}],["3说明了更新门起作用后的计算流",{"2":{"542":1}}],["3x3最大池化层后接1x1卷积层",{"2":{"487":1}}],["3x3最大汇聚层后接1x1卷积层",{"2":{"487":3}}],["3×2",{"2":{"1089":1,"1090":1}}],["3×18gb",{"2":{"842":1}}],["3×0",{"2":{"513":1}}],["3×0+4×1+6×2+7×3=37",{"2":{"126":1}}],["3×3和5×5的卷积层",{"2":{"487":1}}],["384",{"2":{"461":10,"488":8,"495":6}}],["324",{"2":{"1088":1}}],["322+162+82+42+1",{"2":{"959":1}}],["32=15",{"2":{"862":1}}],["32=10且",{"2":{"862":1}}],["32=2",{"2":{"488":1}}],["320−64+16×2+32",{"2":{"862":1}}],["320",{"2":{"488":8,"862":3,"864":2,"866":3,"948":1}}],["32",{"2":{"324":4,"329":1,"376":2,"398":4,"409":17,"425":6,"433":1,"482":4,"488":25,"523":3,"528":3,"543":4,"557":4,"576":2,"584":1,"862":1,"864":2,"882":3,"890":1,"891":3,"902":1,"932":1,"958":3,"959":3,"961":1,"1089":1,"1133":1}}],["3e",{"2":{"129":4}}],["37×0",{"2":{"959":1}}],["37=0",{"2":{"959":1}}],["378",{"2":{"858":1}}],["37",{"2":{"116":1,"959":2}}],["3d张量",{"2":{"368":4}}],["3d",{"2":{"102":2}}],["350px",{"2":{"811":1}}],["35−1",{"2":{"320":1}}],["35",{"2":{"80":4,"81":4,"320":1,"324":4,"329":1,"523":3,"528":3,"543":4,"557":4}}],["30d",{"2":{"1371":1}}],["30~90",{"2":{"813":1}}],["305",{"2":{"813":1}}],["3072",{"2":{"690":1}}],["300+贡献者",{"2":{"1437":1}}],["30080",{"2":{"1391":1}}],["300d",{"2":{"748":2}}],["300",{"2":{"576":1,"813":1,"927":3,"946":3}}],["300px",{"2":{"292":1,"790":1,"1025":1}}],["300000",{"2":{"889":1}}],["3000",{"2":{"290":1,"1364":1,"1499":1}}],["30",{"2":{"67":4,"71":4,"736":3,"813":4,"938":6,"1102":1,"1299":1,"1398":1,"1433":1}}],["3并训练30次迭代",{"2":{"67":1}}],["3f",{"2":{"67":9,"77":12,"78":4,"80":8,"81":8,"129":4,"137":12,"376":2,"409":2,"576":4,"578":2,"726":6,"750":1,"767":3,"768":3,"883":9,"894":9,"906":6}}],["3",{"0":{"1060":1,"1065":1,"1072":1,"1073":1,"1074":2,"1075":1,"1076":1,"1077":1,"1082":1,"1090":1,"1099":1,"1108":1,"1116":1,"1122":1,"1131":1,"1139":1,"1145":1,"1152":1,"1158":1,"1166":1,"1173":1,"1180":1,"1189":1,"1220":1,"1227":1,"1259":1,"1274":1,"1311":1,"1320":1,"1329":1,"1331":1,"1332":1,"1333":1,"1334":2,"1335":1,"1341":1,"1363":1,"1369":1,"1378":1,"1379":1,"1380":1,"1381":1,"1382":2,"1383":1,"1384":1,"1385":1,"1386":1,"1387":1,"1391":1,"1403":1,"1440":1,"1445":1,"1446":1,"1447":1,"1450":1,"1455":2,"1456":1,"1457":1,"1458":1,"1459":1,"1460":1,"1461":1,"1467":1,"1468":1,"1469":1,"1470":1,"1471":1,"1475":1,"1490":1,"1499":1,"1508":1,"1517":1,"1524":1,"1537":1},"1":{"1275":1,"1276":1,"1277":1,"1332":1,"1333":1,"1334":1,"1335":1,"1342":1,"1343":1,"1344":1,"1345":1,"1380":1,"1381":1,"1382":1,"1383":1,"1384":1,"1385":1,"1386":1,"1387":1,"1404":1,"1405":1,"1447":1,"1448":2,"1449":2,"1450":1,"1451":2,"1452":2,"1453":2,"1454":2,"1455":1,"1456":1,"1457":1,"1458":1,"1459":1,"1460":1,"1461":1,"1462":2,"1463":2,"1464":2,"1465":2,"1466":2,"1467":1,"1468":1,"1469":1,"1470":1,"1471":1,"1518":1,"1519":1},"2":{"12":1,"35":3,"41":4,"57":3,"67":7,"72":4,"73":4,"78":4,"80":1,"101":2,"102":2,"120":4,"122":8,"126":2,"137":3,"141":6,"142":8,"146":3,"147":22,"148":6,"208":2,"262":3,"263":4,"264":1,"278":1,"282":1,"284":1,"290":1,"340":9,"350":2,"351":3,"368":8,"382":14,"396":2,"399":4,"405":4,"406":11,"407":3,"409":8,"413":4,"414":2,"422":2,"437":1,"446":1,"447":4,"448":8,"451":2,"472":6,"473":1,"479":1,"480":8,"487":2,"488":2,"495":6,"501":12,"515":1,"542":1,"556":1,"575":17,"589":1,"595":4,"599":1,"605":1,"616":2,"631":5,"633":4,"635":6,"640":1,"658":1,"667":4,"677":1,"687":3,"688":3,"692":2,"699":6,"702":3,"709":1,"718":1,"720":1,"726":12,"727":2,"733":1,"750":3,"757":1,"762":3,"765":6,"768":3,"773":1,"775":1,"776":6,"802":1,"813":2,"816":1,"817":2,"821":1,"834":11,"842":2,"848":3,"849":3,"853":3,"854":4,"858":3,"862":6,"863":11,"865":4,"866":12,"883":8,"893":2,"894":3,"903":6,"907":1,"927":2,"928":1,"933":3,"938":2,"945":3,"956":6,"957":5,"958":5,"959":3,"963":3,"968":2,"970":16,"981":8,"989":4,"990":4,"992":9,"993":5,"994":4,"999":4,"1000":4,"1004":2,"1017":33,"1018":16,"1019":8,"1020":2,"1022":4,"1027":3,"1028":3,"1048":2,"1060":2,"1061":2,"1065":1,"1072":1,"1073":1,"1074":2,"1075":1,"1076":1,"1077":1,"1080":1,"1082":1,"1083":2,"1086":1,"1088":6,"1089":8,"1090":13,"1092":5,"1093":1,"1099":2,"1100":3,"1103":1,"1107":1,"1108":2,"1112":3,"1116":1,"1121":9,"1122":1,"1131":1,"1138":1,"1139":2,"1140":1,"1145":3,"1146":1,"1148":1,"1150":1,"1151":1,"1152":1,"1154":2,"1158":1,"1166":1,"1173":1,"1180":1,"1184":1,"1189":1,"1191":1,"1193":24,"1216":4,"1218":1,"1219":1,"1221":1,"1225":1,"1226":1,"1239":1,"1240":1,"1255":1,"1306":1,"1314":1,"1390":1,"1398":1,"1402":1,"1413":1,"1414":1,"1426":1,"1433":1,"1437":2,"1443":1,"1483":1,"1501":1,"1527":1,"1528":2,"1531":1}}],["4直至中心点不再变化",{"2":{"1151":1}}],["47",{"2":{"1089":2}}],["4+4",{"2":{"1018":1}}],["4e443f8a2eca6b1dac8a6c57641b67dd40621a49",{"2":{"945":1}}],["4×1",{"2":{"1072":1}}],["4×4的特征图",{"2":{"913":1}}],["4×0",{"2":{"513":2}}],["4×0+5×1+7×2+8×3=43",{"2":{"126":1}}],["4时",{"2":{"912":1}}],["4和4",{"2":{"903":3}}],["4和5",{"2":{"702":1}}],["443",{"2":{"1370":1,"1371":1}}],["447",{"2":{"959":1}}],["447等给出",{"2":{"959":1}}],["4465",{"2":{"891":6}}],["44比特",{"2":{"650":1}}],["4914",{"2":{"891":6}}],["493",{"2":{"858":1}}],["4个维度",{"2":{"883":3}}],["450",{"2":{"927":3}}],["456",{"2":{"872":3,"903":6,"919":3,"947":3}}],["45",{"2":{"853":1,"858":1,"1077":1}}],["4kb",{"2":{"813":6,"1198":1}}],["460232315178",{"2":{"1072":1}}],["46",{"2":{"813":1}}],["4f",{"2":{"765":2,"820":1}}],["4亿个参数",{"2":{"656":1,"726":1,"728":1}}],["4表示卷积层",{"2":{"472":2}}],["4=4倍",{"2":{"457":1}}],["42b",{"2":{"748":2}}],["42",{"2":{"435":7,"436":4,"813":1,"1214":1,"1401":1,"1407":1,"1430":1}}],["4822",{"2":{"891":6}}],["485",{"2":{"872":3,"903":6,"919":3,"947":3}}],["4800+次提交",{"2":{"1437":1}}],["480−64+16×2+32",{"2":{"862":1}}],["480",{"2":{"488":2,"862":3,"864":2,"866":3,"948":1}}],["48",{"2":{"407":7,"408":3,"488":8}}],["4步预测",{"2":{"351":1}}],["4的adagrad算法时",{"2":{"108":1}}],["40+个rfc",{"2":{"1437":1}}],["406",{"2":{"872":3,"903":6,"919":3,"947":3}}],["40gb",{"2":{"810":1,"813":2}}],["400",{"2":{"858":1}}],["4000",{"2":{"796":10}}],["400px",{"2":{"152":1,"157":1,"183":1,"207":2,"213":1,"346":1,"355":2,"455":1,"508":1,"811":1,"899":1}}],["4096",{"2":{"461":12,"508":12,"1371":1}}],["40",{"2":{"89":1,"107":1,"369":4,"813":3,"891":3,"1080":1}}],["4略微提高到0",{"2":{"87":1}}],["4x2",{"2":{"57":1}}],["4",{"0":{"1061":1,"1066":1,"1075":1,"1080":1,"1081":1,"1082":1,"1083":2,"1084":1,"1085":1,"1086":1,"1091":1,"1100":1,"1109":1,"1117":1,"1123":1,"1132":1,"1140":1,"1146":1,"1153":1,"1159":1,"1167":1,"1174":1,"1181":1,"1190":1,"1221":1,"1278":1,"1312":1,"1321":1,"1330":1,"1335":1,"1336":1,"1346":1,"1370":1,"1383":1,"1388":1,"1389":1,"1390":1,"1391":1,"1406":1,"1441":1,"1456":1,"1472":1,"1473":1,"1474":1,"1475":1,"1476":2,"1477":1,"1478":1,"1479":1,"1480":1,"1483":1,"1484":1,"1485":1,"1486":1,"1491":1,"1500":1,"1520":1,"1525":1,"1538":1},"1":{"1279":1,"1280":1,"1281":1,"1389":1,"1390":1,"1391":1,"1407":1,"1408":1,"1409":1,"1410":1,"1473":1,"1474":1,"1475":1,"1476":1,"1477":1,"1478":1,"1479":1,"1480":1,"1481":2,"1482":2,"1483":1,"1484":1,"1485":1,"1486":1},"2":{"7":1,"27":3,"57":1,"80":1,"87":8,"88":1,"95":1,"99":2,"103":3,"108":2,"113":1,"120":3,"126":1,"142":4,"146":5,"147":6,"208":1,"242":4,"243":16,"262":3,"264":3,"290":1,"305":1,"340":15,"350":4,"351":2,"368":12,"369":5,"375":4,"382":2,"390":8,"396":2,"399":4,"405":10,"406":7,"409":8,"413":8,"429":7,"433":11,"435":3,"436":1,"437":6,"441":8,"472":3,"473":4,"480":4,"482":16,"488":1,"501":4,"509":2,"515":1,"573":4,"575":20,"578":1,"583":3,"589":2,"599":3,"616":2,"631":2,"681":3,"687":2,"688":3,"699":5,"702":3,"713":5,"726":3,"733":1,"734":2,"742":1,"757":2,"762":2,"763":3,"765":7,"773":1,"775":1,"813":2,"816":1,"817":2,"821":1,"827":1,"834":3,"836":3,"841":1,"842":2,"848":4,"849":6,"852":6,"853":3,"854":11,"858":1,"863":3,"866":3,"872":1,"874":2,"882":3,"883":3,"895":8,"903":15,"907":5,"912":1,"938":9,"955":3,"959":3,"961":3,"963":3,"970":8,"974":9,"981":4,"990":4,"992":12,"993":4,"994":8,"995":4,"997":4,"999":4,"1000":8,"1004":2,"1007":4,"1011":1,"1017":33,"1018":20,"1026":4,"1027":1,"1028":1,"1061":3,"1066":1,"1075":1,"1080":1,"1081":1,"1082":1,"1083":2,"1084":1,"1085":1,"1086":1,"1089":5,"1090":1,"1091":1,"1094":1,"1099":1,"1100":1,"1103":1,"1109":1,"1112":1,"1117":1,"1121":5,"1123":1,"1132":1,"1139":1,"1140":1,"1146":1,"1153":1,"1154":2,"1159":1,"1161":1,"1167":1,"1174":1,"1181":1,"1187":1,"1190":1,"1191":3,"1193":25,"1221":1,"1235":1,"1314":1,"1364":1,"1398":1,"1402":1,"1414":1,"1426":1,"1437":1,"1501":1}}],["w为一个一行三列的零矩阵",{"2":{"1088":1}}],["w=1",{"2":{"912":1}}],["w=2",{"2":{"912":1}}],["w=4",{"2":{"912":1,"915":1}}],["w=w",{"2":{"232":1}}],["w列中的像素进行采样",{"2":{"912":1}}],["w和fmap",{"2":{"912":1}}],["w和b之前",{"2":{"610":1}}],["w和b为创建的模型参数",{"2":{"601":1}}],["w4",{"2":{"834":6}}],["wc∣wo",{"2":{"785":1,"786":2}}],["wc∣wo1",{"2":{"785":1}}],["wj∣wo",{"2":{"786":1}}],["wj∣wc",{"2":{"784":1}}],["wj∣wi",{"2":{"742":1,"744":1}}],["wj和wk是上下文词",{"2":{"744":1}}],["w∣wc",{"2":{"709":1}}],["w∣x",{"2":{"280":1}}],["wk∣steam",{"2":{"744":1}}],["wk∣ice",{"2":{"744":1}}],["wk=",{"2":{"744":1}}],["wk",{"2":{"708":2}}],["wk∼p",{"2":{"708":4}}],["wk∈rh×k和",{"2":{"369":1}}],["w∗=",{"2":{"612":1}}],["w∗",{"2":{"611":2}}],["w的矩阵乘法和向量化的x给出了一个长度为4的向量",{"2":{"970":1}}],["w的估计误差",{"2":{"595":4,"605":1}}],["w的l2范数",{"2":{"278":4}}],["w的l2范数是",{"2":{"275":4}}],["wxo∈rd×h",{"2":{"553":1}}],["wxf",{"2":{"553":1}}],["wxz∈rd×h",{"2":{"540":1}}],["wxh",{"2":{"521":1,"527":1}}],["wxh∈rd×h",{"2":{"340":1}}],["wx+b",{"2":{"469":1}}],["w是参数",{"2":{"425":1}}],["wv∈rh",{"2":{"369":1}}],["wqq+wkk",{"2":{"369":1}}],["wqh∈rq×h",{"2":{"312":1}}],["wrapper",{"2":{"1244":2}}],["wreck",{"2":{"315":1}}],["write",{"0":{"1200":1},"2":{"206":1,"421":1,"813":3,"908":6,"1011":5}}],["woof",{"2":{"1416":4}}],["wood",{"2":{"316":1}}],["wo1",{"2":{"785":1}}],["wo2m",{"2":{"785":3}}],["wo∣wc",{"2":{"709":1,"783":1,"784":2}}],["woman",{"2":{"658":3,"751":3}}],["wo∈rpo×hpv",{"2":{"381":1}}],["wo",{"2":{"307":3,"381":1,"708":1,"709":5}}],["world",{"2":{"1401":1,"1430":1}}],["worst",{"2":{"751":2}}],["workflows",{"2":{"1309":1}}],["workflow",{"0":{"1309":1,"1315":1},"2":{"1309":1,"1315":1}}],["work",{"2":{"1137":1,"1174":1}}],["working",{"2":{"1094":1,"1319":1}}],["worker",{"0":{"1377":1},"2":{"687":7,"1364":2,"1371":1,"1378":2,"1381":1}}],["workers=d2l",{"2":{"777":1,"882":3,"948":3}}],["workers=0",{"2":{"679":2,"725":1,"864":2}}],["workers=num",{"2":{"669":6,"687":4,"722":3,"777":2,"949":6}}],["workers=get",{"2":{"583":3,"584":6}}],["workers",{"2":{"583":6,"584":6,"669":12,"687":10,"722":9,"777":7,"882":3,"948":3,"949":12}}],["works",{"2":{"0":1,"1425":1}}],["wordpiece的词元化方法是对",{"2":{"722":1}}],["word2vec工具包含跳元模型和连续词袋模型",{"2":{"787":1}}],["word2vec工具包含两个模型",{"2":{"782":1}}],["word2vec工具是为了解决上述问题而提出的",{"2":{"782":1}}],["word2vec的跳元模型和",{"2":{"771":1}}],["word2vec中定义的跳元语法模型",{"2":{"760":1}}],["word2vec中的讨论",{"2":{"707":1}}],["word2vec和glove都没有对词的内部结构进行探讨",{"2":{"755":1}}],["word2vec和glove都将相同的预训练向量分配给同一个词",{"2":{"731":1}}],["word2vec和glove等词嵌入模型与上下文无关",{"2":{"739":1}}],["word2vec",{"0":{"780":1},"1":{"781":1,"782":1,"783":1,"784":1,"785":1,"786":1,"787":1,"788":1},"2":{"718":1,"731":1,"747":1,"754":2,"760":2,"763":1,"765":1,"771":1,"776":1,"780":1}}],["words和类似的特征提取方法占据了主导地位",{"2":{"455":1}}],["words",{"2":{"318":1,"760":6,"777":6}}],["word",{"2":{"282":1,"362":2,"693":1,"695":6,"722":3,"750":1,"754":1,"768":1,"1297":1}}],["word中所示",{"2":{"282":1}}],["wu",{"2":{"301":1,"345":1,"722":1,"757":1}}],["w−η|b|∑i∈bx",{"2":{"270":1}}],["w←w−η|b|∑i∈b∂wl",{"2":{"613":1}}],["w←",{"2":{"270":1}}],["w⊤x",{"2":{"270":2,"611":1,"613":2}}],["wd",{"2":{"210":1,"278":9,"613":1,"865":5,"874":1,"894":5,"895":6,"896":3,"906":5,"907":6,"908":3,"961":1}}],["www",{"2":{"207":1,"887":1,"899":1,"1306":1,"1367":1,"1370":1}}],["wb",{"2":{"206":1}}],["w3∣wc",{"2":{"709":1}}],["w3",{"2":{"173":2,"174":1,"709":4,"834":6}}],["w2",{"2":{"173":2,"174":1,"217":9,"219":4,"221":1,"613":1,"834":6,"938":1}}],["w1",{"2":{"173":2,"174":1,"217":9,"219":4,"221":1,"834":6}}],["what",{"2":{"1059":1,"1070":1,"1129":1,"1135":1,"1137":1,"1174":1,"1183":1}}],["whe",{"2":{"756":1}}],["where",{"2":{"46":1,"48":1,"262":1,"271":1,"519":1,"575":2,"756":2}}],["whos",{"2":{"1089":1}}],["whos命令",{"2":{"1089":1}}],["who",{"2":{"660":1,"1089":2}}],["who∈rh×h是权重参数",{"2":{"553":1}}],["whc∈rh×h是权重参数",{"2":{"554":1}}],["whf",{"2":{"553":1}}],["whz∈rh×h是权重参数",{"2":{"540":1}}],["whq+bq",{"2":{"527":1}}],["whq∈rh×q是权重参数",{"2":{"339":1}}],["whh+bh",{"2":{"541":1}}],["whh",{"2":{"521":2,"527":2}}],["whh⊤",{"2":{"312":1}}],["whh和wqh",{"2":{"312":1}}],["whh∈rh×h和偏置bh∈r1×h",{"2":{"340":1}}],["whh∈rh×h和",{"2":{"312":1}}],["whx",{"2":{"312":1}}],["wh中乘积的第一项和第二项很容易计算",{"2":{"307":1}}],["wh",{"2":{"307":14,"308":1,"309":1,"310":3,"756":1,"852":2,"854":2}}],["while语句重复设置",{"2":{"1092":1}}],["while循环的迭代次数和if语句的结果都取决于输入a的值",{"2":{"977":1}}],["while",{"0":{"1092":1,"1224":1,"1226":1},"1":{"1225":1,"1226":1},"2":{"206":1,"425":4,"687":3,"726":3,"757":1,"775":1,"854":3,"977":4,"1091":1,"1092":6,"1193":1,"1226":1,"1246":1}}],["why",{"2":{"119":1,"121":1,"126":1,"130":1,"131":1,"134":1,"151":1,"158":1,"724":2}}],["wiredtiger",{"0":{"1203":1},"2":{"1198":1,"1201":1,"1203":1,"1205":1,"1211":1}}],["wireframe",{"2":{"102":2}}],["wifi",{"2":{"807":1}}],["wiki来下载并生成wikitext",{"2":{"722":1}}],["wiki函数和",{"2":{"722":1}}],["wiki",{"2":{"718":2,"722":7,"725":4,"748":3,"753":1}}],["wikitextdataset类",{"2":{"722":1}}],["wikitextdataset类为用于预训练bert的wikitext",{"2":{"722":1}}],["wikitextdataset",{"2":{"722":6,"725":1}}],["wikitext",{"2":{"718":4,"722":6,"723":1,"725":2}}],["winnow算法",{"2":{"1141":1}}],["windows",{"2":{"1172":1,"1273":1,"1302":1,"1312":1,"1315":1}}],["window",{"2":{"760":6,"774":6,"777":6,"1402":1}}],["win",{"2":{"583":1}}],["winter",{"2":{"342":1}}],["wi",{"2":{"381":6,"773":4}}],["wij2",{"2":{"247":1}}],["wij2xj2",{"2":{"247":1}}],["wij",{"2":{"247":1}}],["wijxj",{"2":{"247":1}}],["width=bbox",{"2":{"858":1}}],["width",{"2":{"152":1,"157":1,"183":1,"207":2,"213":1,"291":1,"292":1,"295":1,"299":1,"346":1,"355":2,"404":1,"455":1,"494":1,"508":1,"790":1,"811":3,"848":15,"887":1,"899":1,"946":7,"1025":1}}],["wigner",{"2":{"105":1}}],["withdefaults",{"2":{"1469":1}}],["within",{"2":{"813":1}}],["without",{"2":{"339":2,"340":1}}],["with",{"0":{"1062":1,"1079":1,"1251":1},"1":{"1063":1,"1064":1,"1065":1,"1066":1,"1067":1,"1068":1,"1069":1,"1070":1,"1080":1,"1081":1,"1082":1,"1083":1,"1084":1,"1085":1,"1086":1,"1252":1},"2":{"7":1,"21":2,"28":2,"34":2,"35":2,"67":4,"80":3,"81":2,"91":2,"108":2,"129":3,"137":6,"206":2,"210":2,"235":2,"236":1,"237":1,"242":2,"275":2,"278":2,"282":1,"295":1,"326":1,"332":1,"334":1,"335":4,"340":6,"350":2,"361":1,"392":2,"406":1,"448":2,"449":2,"451":1,"541":3,"546":1,"547":1,"560":1,"561":1,"565":1,"576":4,"584":1,"595":2,"604":2,"605":4,"634":2,"635":2,"667":1,"692":1,"718":1,"726":1,"748":1,"765":2,"767":1,"772":1,"790":7,"791":2,"792":1,"796":8,"797":8,"813":1,"820":8,"828":1,"837":3,"883":6,"885":1,"890":1,"906":1,"908":3,"927":1,"936":1,"945":3,"963":1,"974":3,"975":2,"976":1,"977":2,"1011":1,"1047":1,"1164":1,"1193":2,"1252":1,"1315":3,"1417":1,"1425":1,"1443":1}}],["wt",{"0":{"1198":1},"2":{"1198":3}}],["wt−1",{"2":{"86":2}}],["wt=wt−1−ηst+ϵ⋅gt",{"2":{"27":1}}],["want",{"2":{"1443":1}}],["wang",{"2":{"300":1,"467":1,"811":1,"842":1}}],["way",{"2":{"813":1}}],["waston",{"2":{"379":1}}],["waston核回归",{"2":{"379":1}}],["washington",{"2":{"295":1}}],["water",{"2":{"744":1}}],["watson可以得到",{"2":{"388":1}}],["watson核回归中以实现更好地预测结果",{"2":{"394":1}}],["watson核回归的注意力汇聚是对训练数据中输出的加权平均",{"2":{"393":1}}],["watson核回归的带参数版本为",{"2":{"391":1}}],["watson核回归是具有注意力机制的机器学习范例",{"2":{"393":1}}],["watson核回归是一个非参数模型",{"2":{"388":1}}],["watson核回归具有一致性",{"2":{"389":1}}],["watson核回归",{"2":{"388":1}}],["watson核回归模型",{"2":{"385":1,"394":1}}],["watson所描述的估计器被称为",{"2":{"388":1}}],["watson",{"0":{"385":1},"1":{"386":1,"387":1,"388":1,"389":1,"390":1,"391":1,"392":1,"393":1,"394":1},"2":{"367":1,"385":1,"388":8,"389":3,"391":1}}],["watson使用了高斯核来对查询和键之间的关系建模",{"2":{"367":1}}],["watkins",{"2":{"300":1}}],["watch对比watcheffect",{"2":{"1467":1}}],["watcheffect",{"0":{"1467":1},"2":{"1467":3}}],["watch的第三个参数是",{"2":{"1463":1}}],["watch的第二个参数是",{"2":{"1463":1}}],["watch的第一个参数是",{"2":{"1463":1}}],["watching",{"2":{"532":1}}],["watch",{"0":{"1461":1},"1":{"1462":1,"1463":1,"1464":1,"1465":1,"1466":1},"2":{"129":2,"1462":2,"1463":2,"1464":3,"1465":3,"1466":2,"1467":3}}],["wake",{"2":{"282":2}}],["waldo",{"2":{"152":2,"157":2}}],["waitall",{"2":{"726":1,"790":1,"791":3,"792":1,"796":4,"797":3,"820":2,"828":1,"830":1,"837":1}}],["wait=true",{"2":{"635":1}}],["wait",{"2":{"77":3,"791":3,"792":1}}],["warstadt",{"2":{"657":1}}],["ward",{"2":{"578":1}}],["warm",{"2":{"333":1}}],["warmup",{"2":{"66":1,"72":14,"73":2}}],["warnings",{"2":{"21":2,"27":2,"34":2,"38":2,"54":2,"67":2,"77":2,"87":2,"99":2,"107":2,"112":2,"120":2,"126":2,"136":2,"141":2,"146":2,"172":3,"208":3,"216":2,"224":2,"234":2,"242":2,"261":2,"271":2,"318":2,"324":2,"329":2,"340":2,"350":2,"357":2,"367":2,"374":2,"381":2,"385":2,"395":2,"404":2,"413":2,"422":2,"429":2,"441":2,"461":2,"472":2,"480":2,"487":2,"494":2,"501":2,"507":2,"523":2,"528":2,"533":2,"543":2,"557":2,"564":2,"572":2,"581":2,"589":2,"598":2,"615":2,"622":2,"629":2,"666":2,"673":2,"685":2,"691":2,"698":2,"712":2,"718":2,"725":2,"733":2,"747":2,"760":2,"771":2,"789":2,"795":2,"819":2,"825":2,"833":2,"847":2,"857":2,"861":2,"871":2,"877":2,"887":2,"899":2,"912":2,"931":2,"938":2,"945":2,"954":2,"974":2,"989":2,"1006":2,"1013":2,"1017":2,"1026":2}}],["warning",{"2":{"8":6}}],["welcome",{"2":{"1058":1}}],["well的时光机器中加载文本",{"2":{"361":1}}],["wells的其他书作为数据集时效果如何",{"2":{"337":1}}],["wells的时光机器数据集上训练",{"2":{"329":1}}],["welling",{"2":{"75":1}}],["webassembly",{"2":{"1540":1}}],["webpack构建",{"2":{"1444":1}}],["website",{"2":{"1168":1}}],["web",{"2":{"1054":1,"1297":1,"1529":1,"1543":1}}],["weigth",{"2":{"713":1}}],["weight=params",{"2":{"834":6}}],["weight=mask",{"2":{"765":2}}],["weight函数",{"2":{"436":1}}],["weighted",{"2":{"191":3,"192":1,"575":6,"997":1}}],["weights传递",{"2":{"775":1}}],["weights=false",{"2":{"577":4}}],["weights的形状为",{"2":{"391":4}}],["weights的形状",{"2":{"388":4,"575":1}}],["weights",{"2":{"81":4,"129":9,"137":4,"176":2,"225":2,"263":1,"278":1,"350":4,"357":2,"369":9,"370":9,"375":21,"376":4,"388":12,"390":7,"391":6,"392":3,"407":12,"408":28,"409":47,"414":1,"418":3,"430":1,"431":3,"432":3,"433":1,"435":6,"436":5,"442":2,"451":2,"575":16,"576":3,"577":8,"595":2,"623":4,"702":4,"713":5,"722":17,"726":19,"767":4,"775":7,"828":2,"883":4}}],["weight",{"2":{"49":1,"81":2,"127":11,"129":9,"137":2,"168":1,"170":1,"176":5,"204":1,"210":9,"211":2,"212":2,"213":3,"225":4,"263":7,"269":1,"270":1,"278":8,"350":2,"376":3,"388":1,"391":2,"392":1,"409":6,"414":13,"418":1,"425":10,"431":2,"435":18,"436":21,"437":12,"451":3,"472":5,"573":4,"574":6,"576":2,"577":12,"578":2,"592":3,"595":3,"610":1,"623":3,"680":3,"702":2,"703":8,"713":4,"714":5,"762":7,"767":2,"768":3,"827":4,"828":2,"863":13,"865":2,"873":3,"874":7,"876":8,"883":2,"894":2,"906":2,"925":6,"926":9,"961":2,"968":2,"969":4,"1099":1}}],["went",{"2":{"525":2,"732":2,"751":1}}],["we",{"2":{"487":1}}],["werbos",{"2":{"306":1}}],["weston",{"2":{"300":1,"700":1}}],["w",{"2":{"21":16,"27":2,"28":8,"34":16,"78":2,"80":15,"91":6,"108":6,"118":1,"122":3,"126":6,"127":1,"146":8,"153":2,"164":1,"165":1,"232":6,"244":1,"262":5,"270":3,"271":3,"273":10,"274":8,"275":25,"278":1,"280":2,"307":1,"331":24,"332":25,"340":12,"341":1,"369":28,"382":32,"389":3,"391":9,"418":2,"425":1,"544":56,"545":57,"558":72,"559":73,"582":1,"585":1,"589":2,"595":15,"599":8,"601":5,"602":2,"605":24,"611":4,"613":6,"630":6,"632":2,"635":2,"699":6,"708":11,"709":3,"750":12,"751":1,"757":2,"768":15,"775":1,"783":1,"784":1,"785":4,"786":4,"837":6,"848":42,"858":5,"863":5,"876":6,"908":3,"912":18,"933":3,"938":1,"964":12,"968":3,"970":20,"1011":1,"1061":1}}],["oldvalue",{"2":{"1462":2,"1463":4,"1464":4,"1465":4,"1466":2}}],["ollivier",{"2":{"310":1}}],["oop",{"0":{"1253":1},"1":{"1254":1,"1255":1}}],["octet",{"2":{"1364":1}}],["octaveoptions=optimset",{"2":{"1111":1}}],["octavefunction",{"2":{"1109":1,"1111":1}}],["octave程序运行非常快的思想",{"2":{"1092":1}}],["octave还有一个其他许多编程语言都没有的概念",{"2":{"1092":1}}],["octave依然知道会在",{"2":{"1092":1}}],["octave环境里使用那些循环语句",{"2":{"1092":1}}],["octave里也有",{"2":{"1092":1}}],["octave里已经建好了",{"2":{"1061":1}}],["octave也可以让你为图像标号",{"2":{"1091":1}}],["octave也可以保存为很多其他的格式",{"2":{"1091":1}}],["octave将会消除之前的正弦图",{"2":{"1091":1}}],["octave有非常简单的工具用来生成大量不同的图",{"2":{"1091":1}}],["octave窗口",{"2":{"1090":1}}],["octave能够很方便地很快速地帮助我们组合复杂的矩阵以及对数据进行移动",{"2":{"1089":1}}],["octave工作空间中的所有变量",{"2":{"1089":1}}],["octave中使用引号来表示字符串",{"2":{"1089":1}}],["octave的搜索路径",{"2":{"1092":1}}],["octave的安装位置",{"2":{"1089":1}}],["octave的辅导课视频中",{"2":{"1089":1}}],["octave很好",{"2":{"1088":1}}],["octave是一种很好的原始语言",{"2":{"1088":1}}],["octave语言",{"2":{"1088":1}}],["octave教程",{"0":{"1087":1},"1":{"1088":1,"1089":1,"1090":1,"1091":1,"1092":1,"1093":1,"1094":1}}],["octave",{"0":{"1087":1},"1":{"1088":1,"1089":1,"1090":1,"1091":1,"1092":1,"1093":1,"1094":1},"2":{"1061":1,"1077":1,"1085":1,"1088":1,"1089":6,"1092":10,"1093":2,"1094":1,"1109":1,"1111":2,"1117":1,"1124":1,"1159":1,"1184":1,"1193":2}}],["ocr",{"0":{"1170":1},"1":{"1171":1,"1172":1,"1173":1,"1174":1},"2":{"1193":1}}],["oak",{"2":{"918":2}}],["og",{"2":{"863":9}}],["omni",{"2":{"813":1}}],["omit",{"2":{"116":1}}],["over",{"2":{"813":3,"849":1,"1114":1}}],["overflow",{"2":{"624":1,"1300":1,"1303":1,"1314":1}}],["overfitting",{"2":{"251":1,"258":1,"286":1,"1114":1}}],["overfit",{"2":{"204":1}}],["o代入损失",{"2":{"647":1}}],["o3=x1w31+x2w32+x3w33+x4w34+b3",{"2":{"641":1}}],["o2m",{"2":{"785":1}}],["o2=x1w21+x2w22+x3w23+x4w24+b2",{"2":{"641":1}}],["o2和o3取决于",{"2":{"641":1}}],["o2和o3",{"2":{"641":1}}],["o1=x1w11+x2w12+x3w13+x4w14+b1",{"2":{"641":1}}],["o1",{"2":{"641":1}}],["ok−max",{"2":{"624":5}}],["ok",{"2":{"624":19,"643":1,"647":4,"1433":3}}],["ok=true",{"2":{"206":1,"890":1,"1011":1}}],["oj−max",{"2":{"624":6}}],["oj是未规范化的预测o的第j个元素",{"2":{"624":1}}],["oj",{"2":{"624":1,"643":1,"647":2}}],["otherwise当σ非常大时",{"2":{"966":1}}],["ott",{"2":{"757":1}}],["ot∈rn×q",{"2":{"521":1}}],["ot给出的",{"2":{"312":1}}],["ot=σ",{"2":{"553":1}}],["ot=ht",{"2":{"527":1}}],["ot=htwhq+bq",{"2":{"340":1,"521":1}}],["ot=wqhht",{"2":{"312":1}}],["ot=g",{"2":{"307":1}}],["ot中的递归计算",{"2":{"307":1}}],["ot−1",{"2":{"307":1}}],["ot",{"2":{"307":6,"312":5}}],["obj变化了",{"2":{"1464":1}}],["obj",{"2":{"848":7,"1433":2,"1456":3,"1457":3,"1464":4,"1495":2}}],["objectid",{"2":{"1197":1}}],["objectives",{"2":{"1001":1}}],["objectives中讨论的那样",{"2":{"980":1}}],["objective",{"2":{"162":1,"283":1,"286":1,"1143":1,"1152":1}}],["object",{"2":{"209":1,"392":2,"857":2,"886":3,"911":1,"930":1,"952":1,"953":1,"961":1,"1045":1,"1046":1,"1047":1,"1464":1}}],["observation",{"2":{"298":1}}],["oi2",{"2":{"247":1}}],["oi",{"2":{"247":3}}],["oi=∑j=1ninwijxj",{"2":{"247":1}}],["oi的尺度分布",{"2":{"247":1}}],["o=xw+b",{"2":{"644":1}}],["o=∂h",{"2":{"241":1}}],["o=fl∘",{"2":{"241":1}}],["o=",{"2":{"232":1}}],["o=hwhq+bq",{"2":{"339":1}}],["o=hw",{"2":{"232":2}}],["o=w",{"2":{"162":1}}],["o∈rn×q是输出变量",{"2":{"339":1}}],["o∈rn×q",{"2":{"232":1}}],["ops",{"2":{"938":2}}],["opttheta",{"2":{"1109":1,"1111":1}}],["options类型的",{"2":{"1448":1}}],["optionsapi",{"0":{"1447":1},"1":{"1448":1,"1449":1}}],["options",{"0":{"1448":1,"1453":1},"2":{"1109":2,"1111":2,"1530":1}}],["optional",{"2":{"1086":1,"1145":1,"1184":1,"1185":1,"1435":2}}],["option",{"2":{"1047":1}}],["optimset",{"2":{"1109":1}}],["optimal",{"2":{"513":1}}],["optimization中详细介绍",{"2":{"605":1}}],["optimization",{"2":{"47":1,"65":2,"980":1,"1111":1,"1121":1,"1143":1,"1152":1}}],["optimizer=optimizer",{"2":{"67":1,"137":1,"210":1}}],["optimizer",{"2":{"21":1,"29":1,"34":1,"67":3,"68":2,"71":2,"72":1,"73":1,"81":9,"92":1,"109":1,"136":1,"137":8,"175":1,"176":1,"210":9,"221":1,"225":1,"263":1,"278":1,"335":4,"350":1,"392":3,"576":9,"594":1,"625":1,"635":4,"681":1,"688":1,"704":1,"715":1,"726":1,"767":7,"828":1,"865":1,"874":2,"883":1,"894":2,"906":2,"926":1,"927":1,"961":1}}],["optimizers",{"2":{"21":1,"29":1,"34":1,"67":1,"68":1,"81":1,"92":1,"109":1,"137":1,"175":1,"176":1,"210":1,"225":1,"263":1,"278":1,"335":1,"350":1,"392":1,"576":1,"594":1,"625":1,"635":1}}],["optim",{"2":{"21":1,"29":1,"34":1,"67":2,"68":1,"71":1,"72":1,"73":1,"81":1,"92":1,"109":1,"137":1,"175":1,"176":1,"210":1,"221":1,"225":1,"263":1,"278":1,"335":2,"350":1,"392":1,"576":1,"594":1,"625":1,"635":1,"681":1,"688":1,"704":1,"715":1,"726":1,"767":1,"828":1,"865":1,"874":2,"883":1,"894":2,"906":2,"926":1,"927":1,"961":1}}],["optane",{"2":{"813":2}}],["operators",{"2":{"1102":1}}],["operatorname",{"2":{"235":1,"236":1,"237":1}}],["operations",{"2":{"1088":1}}],["operation",{"2":{"368":1,"643":1,"832":1}}],["openshift",{"2":{"1393":1}}],["openpyxl",{"2":{"1297":1}}],["openai",{"2":{"1055":1}}],["open",{"2":{"206":3,"361":1,"565":1,"667":1,"686":3,"692":1,"718":1,"748":1,"772":1,"863":2,"878":1,"890":1,"908":3,"918":3,"945":3,"1011":1,"1252":1}}],["os",{"2":{"206":7,"564":4,"565":1,"666":3,"667":1,"685":3,"686":6,"691":3,"692":3,"718":4,"747":3,"748":1,"771":3,"772":1,"789":3,"864":2,"871":3,"872":6,"874":4,"887":3,"890":13,"892":5,"899":3,"901":1,"902":1,"904":5,"908":6,"931":3,"932":6,"945":12,"949":3,"1011":4,"1263":1,"1297":1,"1315":2,"1346":1}}],["onunmounted",{"2":{"1470":3,"1499":2}}],["onupdated",{"2":{"1470":4}}],["onbeforeunmount",{"2":{"1470":4}}],["onbeforeupdate",{"2":{"1470":3}}],["onbeforemount",{"2":{"1470":3}}],["onmounted",{"2":{"1470":4,"1471":4}}],["onmousedown",{"2":{"1402":1}}],["once",{"2":{"1339":1}}],["on函数的功能是将新的图像绘制在旧的之上",{"2":{"1091":1}}],["online",{"2":{"196":1,"1168":1}}],["on",{"0":{"1200":1},"2":{"137":8,"576":4,"726":3,"767":3,"813":10,"827":1,"883":3,"894":3,"906":3,"963":3,"1090":1,"1091":1,"1094":1,"1109":1,"1111":2,"1137":1,"1174":1,"1315":3,"1364":1,"1371":2,"1441":1,"1499":3,"1525":1}}],["oneline",{"2":{"1328":1}}],["one是否有效",{"2":{"711":1}}],["one",{"0":{"1062":1},"1":{"1063":1,"1064":1,"1065":1,"1066":1,"1067":1,"1068":1,"1069":1,"1070":1},"2":{"325":4,"330":10,"332":4,"351":1,"472":1,"575":3,"633":2,"640":1,"657":2,"658":1,"659":1,"709":1,"813":1,"981":3,"1112":2,"1193":1,"1437":2}}],["onestep",{"2":{"351":3}}],["ones",{"2":{"128":2,"235":2,"236":2,"237":2,"242":2,"271":1,"369":4,"382":4,"390":12,"396":2,"405":4,"406":6,"407":7,"408":3,"448":4,"472":6,"575":16,"615":2,"763":6,"790":6,"835":3,"975":1,"997":4,"999":4,"1000":4,"1007":8,"1017":4,"1020":1,"1026":2,"1088":1,"1090":1}}],["onedevicestrategy",{"2":{"67":1,"137":1,"326":1,"332":1,"546":1,"547":1,"560":1,"561":1}}],["orange",{"2":{"1401":1}}],["orchestration",{"2":{"1355":1}}],["org",{"2":{"1284":1,"1306":1}}],["oriented",{"2":{"1195":1}}],["original",{"2":{"832":1,"1515":2,"1516":2}}],["original描述了这种设计",{"2":{"832":1}}],["origin",{"2":{"773":1,"1324":2,"1330":3,"1335":1,"1337":2}}],["orig",{"2":{"72":3}}],["or与and整体一样",{"2":{"1101":1}}],["ordereddict保证了按照成员添加的顺序遍历它们",{"2":{"424":3}}],["order",{"2":{"348":1}}],["or",{"2":{"137":5,"263":4,"335":4,"363":1,"767":3,"883":3,"890":1,"894":3,"906":3,"981":1,"1028":1,"1101":1,"1102":3,"1220":1}}],["o目标函数",{"2":{"59":1}}],["o",{"2":{"54":2,"57":3,"59":1,"122":3,"162":1,"339":1,"382":8,"386":1,"514":1,"558":8,"559":16,"643":2,"644":1,"647":1,"655":1,"757":2,"1060":1,"1350":1,"1377":1,"1394":1}}],["outlier",{"2":{"1144":1}}],["outcome",{"2":{"1027":2}}],["outs",{"2":{"713":6}}],["outside",{"2":{"342":1}}],["outer",{"2":{"345":1}}],["output3",{"2":{"1430":1}}],["output2",{"2":{"1430":1}}],["output1",{"2":{"1430":1}}],["output由编码器的循环层返回",{"2":{"573":1}}],["outputlayer",{"2":{"423":1}}],["output函数反转了transpose",{"2":{"382":1}}],["output的形状",{"2":{"382":4,"573":2,"574":4}}],["output说明了",{"2":{"367":1}}],["outputs=3",{"2":{"677":2}}],["outputs的形状是",{"2":{"713":3}}],["outputs的形状为",{"2":{"375":12}}],["outputs的开头",{"2":{"408":3}}],["outputs",{"2":{"173":5,"174":9,"217":12,"331":12,"332":11,"333":20,"375":52,"405":9,"408":21,"534":5,"535":8,"544":12,"545":12,"558":12,"559":12,"574":8,"577":8,"630":12,"676":6,"702":6,"713":9,"757":3,"905":6,"906":2,"1012":1,"1013":4,"1315":1}}],["output",{"2":{"7":1,"8":1,"136":4,"174":2,"282":1,"325":8,"367":1,"375":8,"382":28,"442":6,"461":4,"472":2,"488":4,"495":4,"502":4,"508":4,"552":1,"573":17,"574":25,"577":12,"635":1,"688":9,"699":1,"737":7,"757":4,"762":3,"766":2,"821":2,"836":2,"848":6,"854":6,"862":1,"863":3,"873":3,"876":1,"905":11,"906":10,"908":15,"927":3,"938":2,"946":1,"959":9,"964":21,"1099":2}}],["out",{"2":{"5":1,"9":1,"81":8,"121":2,"122":4,"141":2,"165":1,"170":1,"174":4,"263":6,"284":1,"295":1,"350":2,"375":9,"423":9,"442":2,"494":12,"507":6,"508":8,"565":2,"687":14,"765":4,"826":8,"848":9,"854":9,"863":18,"957":8,"966":8}}],["ofcost",{"2":{"1122":1}}],["off",{"2":{"658":2,"1140":1,"1499":1}}],["offset",{"2":{"321":18,"610":1,"848":12,"850":1,"852":32,"854":24}}],["offline",{"2":{"297":1}}],["of",{"2":{"0":2,"5":1,"6":1,"9":1,"99":4,"165":1,"235":4,"236":4,"237":4,"292":1,"409":2,"422":1,"455":1,"475":1,"657":1,"687":6,"980":1,"1026":5,"1109":1,"1114":1,"1151":2,"1154":1,"1160":1,"1173":1,"1174":1,"1191":1,"1425":1,"1443":1}}],["r表示所使用的颜色",{"2":{"1091":1}}],["r的",{"2":{"1088":1}}],["rpa",{"2":{"1051":1}}],["rpc",{"2":{"1044":4,"1047":1}}],["rcparams",{"2":{"981":1}}],["rcnn中讨论的目标检测问题中",{"2":{"943":1}}],["rcnn",{"2":{"886":1,"936":1}}],["rgb值",{"2":{"1097":1}}],["rgb",{"2":{"888":1,"919":15,"945":1,"947":4}}],["rgnet",{"2":{"433":20}}],["r=0",{"2":{"848":1}}],["r=2",{"2":{"848":1}}],["r=1",{"2":{"848":3}}],["r2",{"2":{"848":1}}],["r1",{"2":{"848":4}}],["ryzen9",{"2":{"812":1}}],["rule",{"2":{"981":1,"1032":1,"1033":1}}],["russell",{"2":{"619":1}}],["runs",{"2":{"1315":2}}],["runner",{"0":{"1312":1},"2":{"1310":1}}],["running",{"2":{"1168":1}}],["runoob",{"2":{"1306":1}}],["run",{"2":{"15":1,"16":1,"17":1,"796":20,"797":6,"1311":1,"1315":8,"1339":1,"1340":2,"1343":1,"1443":1}}],["runtimeerror",{"2":{"827":1}}],["runtime",{"0":{"0":1},"1":{"1":1,"2":1,"3":1,"4":1,"5":1},"2":{"0":1,"5":1,"1350":2,"1377":1,"1378":2,"1394":1}}],["root",{"2":{"1364":1,"1367":1,"1370":1}}],["root=",{"2":{"582":2,"584":2,"882":2}}],["robin",{"2":{"1362":1}}],["rossum",{"2":{"1296":1}}],["romance",{"2":{"1191":1}}],["rois",{"2":{"938":6}}],["roi中提到",{"2":{"938":1}}],["roi",{"2":{"938":5}}],["route",{"2":{"1481":2,"1482":2,"1483":2,"1485":3}}],["routes",{"2":{"1474":1,"1479":1}}],["routerview",{"2":{"1474":1,"1479":1}}],["routerview>",{"2":{"1474":2}}],["routerlink>",{"2":{"1474":3,"1479":1,"1481":1,"1482":2,"1484":1}}],["routerlink",{"2":{"1474":4,"1479":1,"1481":1,"1482":2,"1484":1}}],["router的最新版本",{"2":{"1474":1}}],["router",{"2":{"1444":1,"1474":7,"1476":2,"1477":4,"1478":4,"1479":7,"1481":3,"1482":1,"1485":4,"1527":1,"1528":1}}],["round",{"2":{"721":1,"722":3,"813":1,"1362":1}}],["roukos",{"2":{"578":1}}],["rowwise",{"2":{"644":1}}],["row",{"2":{"357":4,"398":4,"399":4,"667":13,"851":6,"964":15}}],["rows=2",{"2":{"878":1}}],["rows",{"2":{"357":3,"582":9,"667":4,"878":2}}],["rtx",{"2":{"812":1}}],["rt⊙ht−1",{"2":{"541":1}}],["rt=σ",{"2":{"540":1}}],["rstrip",{"2":{"748":1,"890":1}}],["rstride",{"2":{"102":2}}],["rsqrt",{"2":{"472":1}}],["rkhs",{"2":{"278":1}}],["ringsync",{"2":{"842":1}}],["ringsync说明了n=4个节点上的步骤顺序",{"2":{"842":1}}],["ring",{"0":{"842":1}}],["right|",{"2":{"1000":1}}],["rightarrow",{"2":{"981":1}}],["right",{"2":{"334":1,"1068":1,"1110":1,"1112":2,"1120":5,"1160":1,"1165":4,"1413":1}}],["ridge",{"2":{"270":1}}],["risk中定义的真实风险中的恒等式进行更正",{"2":{"192":1}}],["risk所述",{"2":{"99":1}}],["risk",{"2":{"99":7,"190":8,"191":3,"192":1}}],["rmi",{"2":{"1342":1}}],["rmse",{"2":{"210":16,"211":3,"212":2,"213":2}}],["rmsprop算法对此有多敏感",{"2":{"111":1}}],["rmsprop算法使用该技术来调整按系数顺序的预处理器",{"2":{"110":1}}],["rmsprop算法与动量法都使用泄漏平均值",{"2":{"110":1}}],["rmsprop算法与adagrad算法非常相似",{"2":{"110":1}}],["rmsprop算法中不会发生这种情况",{"2":{"108":1}}],["rmsprop算法中两项的组合都非常简单",{"2":{"33":1}}],["rmsprop算法",{"0":{"106":1},"1":{"107":1,"108":1,"109":1,"110":1,"111":1}}],["rmsprop",{"2":{"65":1,"106":1,"108":11,"109":4}}],["rmsprop中",{"2":{"32":1}}],["rmsprop的区别在于",{"2":{"20":1}}],["rmsprop类似的以下泄漏更新",{"2":{"20":1}}],["rmsprop和adadelta中用于相同用途的参数",{"2":{"20":1}}],["rm",{"2":{"209":3,"848":2,"1343":1}}],["rl",{"2":{"209":4,"298":2}}],["rb",{"2":{"206":1,"692":1}}],["r∗表示对于x的最低风险",{"2":{"115":1}}],["rx",{"2":{"102":2}}],["radius",{"2":{"1417":7,"1423":1,"1426":5,"1444":1}}],["radford",{"2":{"732":1,"757":1}}],["rag",{"2":{"1053":1,"1056":1}}],["rajpurkar",{"2":{"660":1}}],["rasul",{"2":{"581":1}}],["rawperson",{"2":{"1518":2}}],["raw",{"2":{"565":3,"757":3,"772":2}}],["ratio是验证集中的样本数与原始训练集中的样本数之比",{"2":{"890":1}}],["ratio=0",{"2":{"890":1}}],["ratio=",{"2":{"879":3,"891":3,"903":3}}],["ratios=ratio",{"2":{"959":3}}],["ratios=",{"2":{"848":3,"912":3}}],["ratios",{"2":{"848":15,"912":1,"959":5}}],["ratio",{"2":{"509":4,"847":1,"848":16,"890":6,"902":4,"959":3}}],["rate值",{"2":{"594":3}}],["rate=",{"2":{"263":1,"625":1}}],["rate=learning",{"2":{"210":1,"874":2}}],["rate=lr",{"2":{"67":2,"68":2,"137":2,"175":2,"176":1,"221":1,"225":2,"278":2,"335":1,"350":1,"576":2,"681":1,"688":1,"704":1,"715":1,"767":1,"828":1,"865":1,"883":1,"926":1,"927":1}}],["rate=scheduler",{"2":{"71":1,"894":1,"906":1}}],["rate=0",{"2":{"71":1,"72":1,"73":1,"176":1,"263":1,"392":2,"594":2,"625":1,"726":1,"961":1}}],["rate",{"2":{"21":1,"29":3,"34":3,"55":1,"66":1,"67":1,"68":6,"81":3,"92":3,"109":3,"137":1,"176":1,"210":9,"211":2,"225":1,"263":1,"278":1,"335":1,"350":1,"392":1,"480":1,"482":12,"576":1,"594":1,"613":1,"625":1,"681":1,"688":1,"704":1,"715":1,"726":1,"767":1,"828":1,"865":1,"874":12,"883":1,"894":3,"906":3,"926":1,"927":2,"961":1,"1067":1,"1068":1,"1083":1}}],["rahimi在接受2017年neurips大会的",{"2":{"475":1}}],["rainier",{"2":{"918":3}}],["raining",{"2":{"342":6}}],["raise",{"2":{"375":1,"533":4,"534":8,"1249":1}}],["ram",{"2":{"299":1,"801":1}}],["rancher",{"2":{"1393":1}}],["rank",{"2":{"1191":1}}],["randint",{"2":{"320":1,"321":3,"734":3,"774":1}}],["rand",{"2":{"127":2,"136":2,"141":2,"172":1,"325":2,"368":4,"386":3,"391":1,"413":2,"414":3,"422":2,"425":12,"429":2,"448":2,"488":2,"495":2,"501":2,"502":2,"796":3,"848":2,"862":2,"926":1,"946":6,"947":3,"969":2,"1088":1,"1090":2,"1125":1,"1495":1}}],["randn",{"2":{"77":4,"217":4,"331":2,"414":3,"442":2,"461":2,"480":2,"508":2,"544":2,"558":2,"734":2,"790":6,"819":2,"834":8,"977":2,"1017":2}}],["randomcrop",{"2":{"946":2}}],["randomcolorjitter",{"2":{"880":1,"903":1}}],["randomlighting",{"2":{"903":1}}],["randomly",{"2":{"813":4}}],["randomhue",{"2":{"880":1}}],["randomhorizontalflip",{"2":{"872":2,"879":2,"881":2,"882":2,"891":2,"903":2}}],["randombrightness",{"2":{"880":1}}],["randomverticalflip",{"2":{"879":2}}],["randomfliptopbottom",{"2":{"879":1}}],["randomflipleftright",{"2":{"872":1,"879":1,"881":1,"882":1,"891":1,"903":1}}],["randomresizedcrop",{"2":{"872":3,"879":3,"891":3,"903":3}}],["randomgenerator类缓存k个随机采样结果",{"2":{"779":1}}],["randomgenerator",{"2":{"775":3}}],["randomnormal",{"2":{"592":1,"623":1}}],["randomness",{"2":{"319":1}}],["random",{"2":{"77":2,"80":2,"81":1,"127":1,"136":2,"141":2,"172":3,"173":3,"217":4,"243":4,"262":3,"273":2,"318":4,"319":1,"320":4,"321":8,"325":2,"329":3,"331":1,"335":20,"368":4,"369":1,"370":1,"385":1,"386":1,"391":1,"413":2,"414":6,"418":2,"422":2,"425":2,"429":2,"435":1,"436":2,"437":1,"442":2,"448":2,"461":2,"480":2,"488":2,"495":2,"501":2,"502":2,"508":2,"544":1,"558":2,"598":4,"599":2,"600":2,"601":2,"630":2,"631":1,"718":4,"720":4,"721":6,"734":1,"771":3,"773":1,"774":1,"775":1,"790":5,"796":3,"813":3,"819":2,"821":1,"827":1,"834":4,"848":1,"862":1,"946":1,"969":1,"977":2,"1006":2,"1017":2,"1026":6,"1028":1,"1125":1,"1153":1,"1263":1,"1471":1}}],["range",{"0":{"1225":1},"2":{"54":2,"57":2,"59":1,"67":3,"68":1,"70":1,"71":4,"72":2,"73":2,"77":12,"78":4,"80":4,"81":4,"126":4,"129":4,"137":3,"146":4,"172":1,"210":4,"211":3,"235":1,"242":1,"243":4,"262":1,"263":4,"275":4,"278":4,"320":3,"321":3,"333":4,"335":4,"350":6,"351":9,"362":1,"369":1,"375":1,"390":1,"392":4,"399":1,"407":5,"408":9,"409":4,"418":1,"433":4,"441":1,"446":4,"472":1,"480":4,"502":4,"507":4,"573":1,"574":1,"575":1,"576":4,"577":4,"578":3,"595":4,"600":4,"605":4,"615":3,"633":2,"635":3,"667":1,"699":2,"720":1,"734":3,"757":2,"767":3,"774":4,"775":3,"790":9,"792":2,"796":3,"820":8,"826":3,"828":6,"835":10,"837":13,"851":3,"852":3,"854":3,"863":6,"866":3,"872":2,"878":1,"882":2,"883":3,"893":1,"894":3,"896":3,"906":3,"920":3,"927":3,"946":3,"957":3,"958":2,"959":6,"963":3,"968":2,"974":1,"981":1,"990":1,"992":1,"993":1,"994":2,"995":1,"1017":2,"1018":1,"1019":2,"1026":4,"1207":1,"1225":1,"1242":1,"1243":1,"1247":1,"1262":1,"1296":1}}],["r→r",{"2":{"54":1,"981":1,"1018":2}}],["r",{"0":{"936":1,"937":1,"938":1,"939":1,"940":1},"1":{"937":1,"938":1,"939":1,"940":1,"941":1,"942":1},"2":{"52":2,"80":2,"81":2,"115":10,"206":4,"361":1,"544":8,"545":16,"565":1,"635":1,"667":1,"718":1,"748":1,"757":2,"790":1,"821":1,"848":2,"890":1,"936":4,"937":4,"938":8,"939":9,"940":6,"941":6,"945":3,"981":1,"1018":2,"1090":2,"1091":1,"1154":1,"1187":2,"1188":5,"1189":3,"1190":2,"1252":1,"1255":4,"1269":1}}],["rnn练习中介绍的方法进一步提高模型的分类精度",{"2":{"706":1}}],["rnn相同",{"2":{"703":1}}],["rnn的双向循环神经网络模型相比",{"2":{"702":1}}],["rnn和",{"2":{"663":1}}],["rnn和rnn",{"2":{"549":1}}],["rnn描述了一个具有l个隐藏层的深度循环神经网络",{"2":{"526":1}}],["rnn再次遇到",{"2":{"348":1}}],["rnn展示了循环神经网络在三个相邻时间步的计算逻辑",{"2":{"340":1}}],["rnns",{"2":{"338":1,"520":1}}],["rnn中所示的具体示例",{"2":{"712":1}}],["rnn中用于情感分析的架构和本节中用于情感分析的架构",{"2":{"706":1}}],["rnn中使用带有glove预训练的循环神经网络架构进行情感分析相比",{"2":{"698":1}}],["rnn中描述了l个隐藏层构成",{"2":{"527":1}}],["rnn中的语言建模问题",{"2":{"550":1}}],["rnn中的情感分类应用",{"2":{"523":1}}],["rnn中的描述",{"2":{"329":1}}],["rnn中",{"2":{"522":1,"663":1}}],["rnn中介绍",{"2":{"325":1}}],["rnn返回两个以上的值",{"2":{"325":1}}],["rnnmodelscratch",{"2":{"332":8,"335":3,"546":3,"560":3}}],["rnnmodel",{"2":{"325":8,"326":4,"523":3,"528":3,"547":4,"561":4}}],["rnn",{"2":{"50":1,"305":5,"306":2,"307":1,"309":1,"312":7,"324":3,"325":51,"326":5,"329":1,"332":17,"335":6,"338":1,"339":2,"340":9,"341":4,"343":1,"374":1,"375":10,"395":1,"397":6,"403":2,"517":1,"518":1,"523":2,"526":2,"527":2,"528":2,"531":1,"541":3,"543":2,"545":2,"546":1,"547":2,"550":3,"557":2,"560":1,"561":2,"572":1,"573":12,"574":13,"663":1,"712":3,"713":1,"781":1}}],["rn→r的输入是",{"2":{"983":1}}],["rn→r是凸函数",{"2":{"46":1}}],["rn→r是凸的",{"2":{"46":1}}],["rn→r",{"2":{"46":2}}],["rn→r存在时",{"2":{"46":1}}],["rd→rd",{"2":{"1018":1}}],["rd→r",{"2":{"156":1}}],["rd→r的泰勒展开式",{"2":{"59":1}}],["rd→r将向量映射成标量",{"2":{"57":1}}],["rd",{"2":{"40":1,"1018":1}}],["rho",{"2":{"21":29,"109":2}}],["rebase",{"0":{"1334":1},"2":{"1334":3,"1337":1}}],["release",{"2":{"1309":1,"1315":14,"1325":1,"1437":1}}],["relu和预处理是提升计算机视觉任务性能的其他关键步骤",{"2":{"464":1}}],["relu激活函数在正区间的梯度总是1",{"2":{"460":1}}],["relu激活函数使训练模型更加容易",{"2":{"460":1}}],["relu激活函数的计算更简单",{"2":{"460":1}}],["relu激活函数和平方损失",{"2":{"350":1}}],["relu激活函数缓解了梯度消失问题",{"2":{"249":1}}],["relu提供了一种非常简单的非线性变换",{"2":{"235":1}}],["relu函数有许多变体",{"2":{"235":1}}],["relu函数不可导",{"2":{"235":1}}],["relu函数的导数为1",{"2":{"235":1}}],["relu函数的导数为0",{"2":{"235":1}}],["relu函数通过将相应的活性值设为0",{"2":{"235":1}}],["relu函数被定义为该元素与0的最大值",{"2":{"235":1}}],["relu函数",{"0":{"235":1}}],["relu",{"2":{"67":15,"174":12,"176":8,"218":4,"219":4,"225":4,"235":16,"350":4,"405":10,"414":4,"418":2,"422":4,"423":4,"424":3,"425":16,"429":4,"433":7,"435":3,"436":1,"437":10,"442":4,"461":28,"480":6,"481":6,"482":8,"487":24,"488":12,"494":12,"501":10,"502":5,"507":4,"508":8,"674":6,"702":7,"736":3,"819":8,"821":1,"826":3,"834":9,"893":3,"905":3,"957":3}}],["reorg",{"2":{"890":7,"902":4}}],["refs",{"0":{"1502":1}}],["ref=",{"2":{"1468":5}}],["ref定义的数据",{"2":{"1461":1}}],["ref创建的变量必须使用",{"2":{"1458":1}}],["ref用来定义",{"2":{"1458":1}}],["ref对象的value属性是响应式的",{"2":{"1455":1}}],["ref与reactive",{"2":{"1441":1}}],["reflog",{"2":{"1337":1}}],["ref",{"0":{"1455":1,"1457":1,"1458":1,"1468":1},"2":{"813":4,"1455":6,"1457":4,"1458":1,"1459":1,"1460":3,"1462":4,"1463":4,"1465":1,"1467":3,"1468":9,"1470":2,"1471":2,"1497":5,"1501":5,"1503":2}}],["reference",{"2":{"813":2}}],["remote",{"0":{"1324":1},"2":{"813":3,"1319":1,"1324":2,"1330":2}}],["remove",{"2":{"774":1}}],["react",{"2":{"1530":2,"1538":1,"1543":1}}],["reactive定义的数据",{"2":{"1461":1}}],["reactive定义的响应式数据是",{"2":{"1456":1}}],["reactive都可以",{"2":{"1458":1}}],["reactive重新分配一个新对象",{"2":{"1458":1}}],["reactive用来定义",{"2":{"1458":1}}],["reactive",{"0":{"1456":1,"1458":1},"2":{"1456":5,"1459":2,"1464":5,"1465":3,"1466":2,"1469":2,"1471":2,"1495":2,"1503":2,"1508":2,"1515":1,"1516":1,"1518":3,"1519":1}}],["reached",{"2":{"726":9}}],["real",{"2":{"1368":1}}],["readonlycopy",{"2":{"1515":1}}],["readonlynumbers",{"2":{"1426":2}}],["readonlyarray",{"2":{"1426":3}}],["readonlyuser",{"2":{"1410":1}}],["readonly",{"0":{"1426":1,"1514":1,"1515":1},"1":{"1515":1,"1516":1},"2":{"1410":3,"1419":1,"1426":4,"1428":2,"1515":1,"1516":1}}],["readresource",{"2":{"1048":1}}],["ready",{"2":{"1048":1}}],["read之间的差值",{"2":{"794":1}}],["read障碍器来模拟同步执行",{"2":{"792":1}}],["readthetrainingset",{"2":{"772":1}}],["readlines",{"2":{"361":1,"667":1,"718":1,"890":1}}],["read",{"2":{"77":4,"206":1,"208":2,"318":1,"361":2,"364":1,"421":1,"565":3,"569":1,"667":3,"668":3,"669":6,"679":2,"687":9,"692":3,"695":6,"718":1,"722":4,"725":1,"772":3,"777":3,"791":3,"792":1,"802":1,"810":1,"813":6,"866":3,"890":4,"902":1,"932":13,"945":11,"947":6,"964":1,"1011":1,"1252":1}}],["req",{"2":{"703":1,"714":1,"876":1}}],["required",{"2":{"1435":2}}],["requirements",{"0":{"1266":1},"1":{"1267":1,"1268":1,"1269":1},"2":{"1269":2}}],["requires",{"2":{"80":2,"217":4,"235":1,"242":1,"273":2,"331":1,"334":1,"391":1,"425":1,"544":1,"558":1,"601":2,"630":2,"703":1,"714":1,"835":1,"876":1,"905":1,"906":1,"974":2,"977":1}}],["request",{"2":{"1048":2,"1309":1,"1315":1}}],["requests",{"2":{"206":2,"1273":1,"1281":1,"1285":1,"1289":1,"1293":1,"1297":1}}],["reverse",{"2":{"1430":2}}],["reverse=true",{"2":{"363":1}}],["reviews的数据集加载到数据迭代器中进行情感分析",{"2":{"697":1}}],["review",{"0":{"1071":1},"1":{"1072":1,"1073":1,"1074":1,"1075":1,"1076":1,"1077":1},"2":{"691":1,"692":3,"693":1,"1193":1}}],["revisited",{"2":{"624":1,"1135":1}}],["revisited中",{"2":{"220":1}}],["re",{"2":{"360":4,"361":1,"666":3,"667":3,"756":1,"1263":1}}],["reed",{"2":{"300":1}}],["reward",{"2":{"298":1}}],["render",{"2":{"1417":1}}],["ren",{"2":{"235":1,"422":1,"500":1,"505":2,"826":1,"936":1,"939":1,"1468":4}}],["ret",{"2":{"750":1,"768":1}}],["retain",{"2":{"235":2,"236":2,"237":2}}],["return",{"2":{"7":2,"21":5,"27":2,"28":5,"34":5,"35":1,"54":4,"56":2,"57":5,"59":7,"67":4,"68":1,"70":1,"71":4,"72":3,"79":4,"80":6,"87":8,"88":1,"91":4,"99":2,"108":6,"113":5,"114":2,"120":2,"121":1,"122":1,"126":2,"127":4,"136":1,"137":5,"141":4,"146":2,"172":12,"174":4,"206":3,"210":11,"211":2,"218":4,"219":4,"220":1,"263":3,"273":4,"274":4,"320":1,"321":2,"325":12,"331":8,"332":16,"333":4,"334":1,"335":4,"350":4,"361":1,"362":2,"363":8,"364":1,"368":8,"369":4,"370":4,"375":14,"382":12,"386":4,"391":4,"398":4,"405":4,"406":4,"407":8,"408":16,"413":4,"414":4,"418":1,"423":4,"424":4,"425":8,"433":8,"436":1,"442":4,"446":11,"461":1,"472":9,"473":1,"474":1,"480":8,"481":4,"482":3,"487":4,"488":6,"494":4,"495":1,"501":4,"502":5,"507":4,"508":4,"535":4,"544":12,"545":8,"547":2,"558":12,"559":8,"561":2,"565":3,"566":1,"568":3,"569":1,"573":6,"574":10,"575":8,"577":4,"578":1,"582":4,"583":4,"584":6,"590":5,"599":2,"602":1,"603":1,"615":4,"616":1,"631":2,"632":1,"633":3,"634":6,"635":5,"667":2,"668":9,"669":5,"674":6,"675":3,"676":3,"677":3,"679":3,"681":1,"682":3,"686":3,"687":14,"688":3,"692":1,"695":3,"699":3,"702":3,"713":3,"715":3,"717":1,"718":1,"720":2,"721":2,"722":13,"725":2,"726":3,"727":3,"734":4,"736":3,"737":3,"738":3,"748":3,"750":3,"751":1,"757":3,"763":3,"765":3,"772":1,"773":3,"774":1,"775":2,"776":1,"777":8,"796":3,"797":3,"816":2,"817":5,"819":4,"820":1,"821":1,"826":6,"827":1,"834":3,"835":3,"836":4,"848":4,"849":3,"851":3,"852":4,"854":10,"858":3,"863":3,"864":3,"865":2,"866":6,"882":3,"883":3,"890":2,"893":6,"905":6,"919":6,"920":7,"922":3,"923":4,"924":1,"925":1,"926":6,"927":3,"932":14,"945":9,"946":3,"947":12,"948":1,"949":5,"954":3,"955":3,"956":9,"957":3,"958":3,"959":9,"962":9,"964":3,"966":5,"968":1,"970":2,"977":4,"981":6,"1021":1,"1048":2,"1081":1,"1085":1,"1107":1,"1109":1,"1117":1,"1229":1,"1230":2,"1244":2,"1252":1,"1255":1,"1259":1,"1398":1,"1401":1,"1416":2,"1417":1,"1420":2,"1425":5,"1427":1,"1428":1,"1430":2,"1432":4,"1433":2,"1445":1,"1451":1,"1452":1,"1460":2,"1471":2,"1483":1,"1490":2,"1493":2,"1495":1,"1520":3}}],["replicas",{"2":{"1390":1}}],["replicaset",{"0":{"1382":1}}],["replica",{"0":{"1209":1},"2":{"1209":1,"1210":1}}],["replace是替换当前记录",{"2":{"1484":1}}],["replace属性",{"0":{"1484":1}}],["replace",{"2":{"565":2,"692":1,"721":4,"757":1,"1484":1,"1485":1}}],["repmat",{"2":{"1061":1}}],["rep中讨论的bert的输入表示",{"2":{"727":1}}],["rep",{"2":{"687":1,"734":1}}],["repo",{"2":{"1327":1}}],["report",{"2":{"660":1}}],["repository",{"2":{"13":1,"1309":1,"1319":2}}],["repeat的形状",{"2":{"388":4}}],["repeats=x",{"2":{"574":1}}],["repeats=batch",{"2":{"408":1}}],["repeats=keys",{"2":{"391":1}}],["repeats=n",{"2":{"387":1,"388":1,"392":4}}],["repeats=self",{"2":{"382":3}}],["repeats=shape",{"2":{"368":1}}],["repeats=2",{"2":{"369":1}}],["repeat",{"2":{"368":4,"369":3,"382":4,"387":4,"388":12,"391":3,"392":8,"408":2,"574":2,"736":3,"848":4,"852":1,"1069":1,"1109":2,"1116":1,"1117":1,"1151":1,"1165":1,"1166":1,"1168":1}}],["representation",{"0":{"1096":1},"1":{"1097":1,"1098":1,"1099":1,"1100":1,"1101":1,"1102":1,"1103":1},"2":{"302":1,"380":1,"1063":1,"1099":1,"1100":1,"1107":1,"1161":1,"1193":1}}],["representations",{"2":{"232":1}}],["reinit确保参数会被重新初始化",{"2":{"435":1}}],["reinit=true",{"2":{"67":2,"137":1,"326":1,"335":1,"435":4,"436":1,"576":1,"767":1,"828":1,"926":1}}],["reinforcement",{"2":{"199":1,"298":2}}],["recall",{"2":{"1139":1,"1140":2}}],["rectangle",{"2":{"858":1}}],["rect",{"2":{"848":5,"858":4,"866":9,"946":8}}],["rectified",{"2":{"235":1}}],["recursion",{"2":{"519":2}}],["recur递归计算得到的",{"2":{"312":1}}],["recur中的",{"2":{"310":1}}],["recur中的循环计算",{"2":{"307":1}}],["recur中的梯度计算",{"2":{"307":1}}],["recur",{"2":{"307":1,"312":1}}],["recurrent",{"2":{"305":1,"338":1,"340":3,"538":1,"550":1}}],["recoveryunit",{"2":{"1204":1}}],["recommendations",{"2":{"1188":1}}],["recommender",{"0":{"1186":1},"1":{"1187":1,"1188":1,"1189":1,"1190":1,"1191":1,"1192":1},"2":{"294":2,"1193":1}}],["reconstruction",{"2":{"1161":1}}],["recognition",{"2":{"857":1}}],["recognize",{"2":{"315":1}}],["recordstore",{"2":{"1204":1}}],["record内",{"2":{"974":1}}],["record",{"2":{"67":1,"80":1,"81":1,"129":1,"137":1,"210":1,"235":1,"236":1,"237":1,"242":1,"275":1,"278":1,"335":1,"350":1,"392":1,"406":1,"576":1,"595":1,"605":1,"635":1,"726":1,"767":1,"828":1,"837":1,"883":1,"906":1,"927":1,"963":1,"974":2,"975":1,"976":1,"977":1}}],["receptive",{"2":{"131":1}}],["registry",{"2":{"1340":1}}],["registerresource",{"2":{"1048":1}}],["registertool",{"2":{"1048":1}}],["register",{"2":{"77":1}}],["region",{"2":{"936":1,"939":1}}],["reg中",{"2":{"644":1}}],["regardent",{"2":{"572":2}}],["regordent",{"2":{"532":1}}],["regressive",{"2":{"404":1}}],["regression",{"0":{"1062":1,"1079":1,"1105":1},"1":{"1063":1,"1064":1,"1065":1,"1066":1,"1067":1,"1068":1,"1069":1,"1070":1,"1080":1,"1081":1,"1082":1,"1083":1,"1084":1,"1085":1,"1086":1,"1106":1,"1107":1,"1108":1,"1109":1,"1110":1,"1111":1,"1112":1},"2":{"191":1,"207":1,"270":2,"290":1,"379":1,"388":1,"587":6,"608":2,"609":1,"1084":1,"1100":2,"1106":1,"1112":1,"1116":1,"1117":1,"1193":3}}],["regression中我们介绍了线性回归",{"2":{"639":1}}],["regression中讨论的",{"2":{"604":1}}],["regression中描述的平方损失函数",{"2":{"603":1}}],["regression中的线性回归例子",{"2":{"270":1}}],["regression中",{"2":{"100":1}}],["reg",{"2":{"386":1,"387":4,"388":4,"392":4,"644":1,"650":1,"651":1,"1117":2}}],["regularized",{"2":{"1116":1,"1117":1}}],["regularizer参数将其应用于网络层",{"2":{"278":1}}],["regularizers",{"2":{"210":1,"278":1}}],["regularizer=tf",{"2":{"210":1,"278":1}}],["regularization",{"0":{"1113":1},"1":{"1114":1,"1115":1,"1116":1,"1117":1},"2":{"251":1,"1114":1,"1133":1,"1193":1}}],["rest",{"2":{"1376":1}}],["resource",{"2":{"1048":3}}],["resourcetemplate",{"2":{"1048":2}}],["result",{"2":{"821":1,"1046":1,"1048":2,"1244":2}}],["results",{"0":{"1":1},"1":{"2":1,"3":1,"4":1},"2":{"0":1,"54":20,"57":12,"59":3}}],["respirator",{"2":{"660":2}}],["research",{"2":{"718":1}}],["reset",{"2":{"540":1,"634":1,"865":1,"874":1,"905":1,"927":1,"1333":2,"1337":1}}],["reserved",{"2":{"363":4,"567":1,"569":2,"668":3,"693":1,"722":3}}],["resnet34",{"2":{"905":3}}],["resnet引入了",{"2":{"505":1}}],["resnet18",{"2":{"502":1,"826":3,"827":3,"862":3,"873":6,"874":3,"883":3,"893":4}}],["resnet18描述了完整的resnet",{"2":{"502":1}}],["resnetblock",{"2":{"502":10}}],["resnet则使用4个由残差块组成的模块",{"2":{"502":1}}],["resnet的区别在于",{"2":{"826":1}}],["resnet的前两层跟之前介绍的googlenet中的一样",{"2":{"502":1}}],["resnet的resnet",{"2":{"482":1}}],["resnet模型",{"0":{"502":1}}],["resnet沿用了vgg完整的3×3卷积层设计",{"2":{"501":1}}],["resnet赢得了2015年imagenet大规模视觉识别挑战赛",{"2":{"500":1}}],["resnet",{"0":{"499":1},"1":{"500":1,"501":1,"502":1,"503":1,"504":1,"505":1},"2":{"492":3,"499":1,"500":1,"501":2,"502":11,"504":1,"826":23,"828":1,"862":1,"893":5}}],["resnet通过步幅为2的残差块减小高和宽",{"2":{"482":1}}],["resnet和densenet的关键区别在于",{"2":{"479":1}}],["resnet将介绍",{"2":{"491":1}}],["resnet将f分解为两部分",{"2":{"479":1}}],["resnet将函数展开为",{"2":{"479":1}}],["resnet极大地改变了如何参数化深层网络中函数的观点",{"2":{"478":1}}],["resnet中描述的resnet",{"2":{"893":2}}],["resnet中描述的实现方法略有不同",{"2":{"893":1}}],["resnet中的resnet",{"2":{"883":1}}],["resnet中的练习",{"2":{"480":1}}],["resnet中将介绍的残差块",{"2":{"466":1}}],["resnet中残差网络的启发",{"2":{"404":1}}],["resize",{"2":{"584":16,"872":3,"891":3,"903":3,"919":2}}],["resize=64",{"2":{"584":1}}],["resize=none",{"2":{"584":4}}],["resize=96",{"2":{"483":1,"489":1,"503":1}}],["resize=224",{"2":{"462":1,"496":1,"509":1}}],["residuals",{"2":{"502":8,"826":6,"893":2}}],["residual",{"2":{"404":1,"500":1,"501":20,"502":12,"504":1,"826":6,"893":4}}],["reshape",{"2":{"81":2,"122":3,"129":12,"141":8,"147":3,"172":4,"174":3,"209":1,"213":1,"219":4,"262":1,"263":6,"321":6,"325":4,"330":4,"332":1,"333":8,"335":4,"350":2,"351":7,"357":1,"368":12,"369":5,"370":1,"376":1,"382":16,"388":3,"390":4,"391":7,"392":8,"398":4,"408":1,"409":5,"473":8,"495":1,"545":1,"559":1,"576":4,"577":1,"582":2,"595":4,"599":3,"603":1,"605":1,"632":1,"636":1,"682":6,"715":3,"726":12,"736":12,"750":2,"767":3,"776":1,"834":3,"836":3,"848":9,"851":2,"852":6,"854":14,"863":6,"866":3,"923":1,"938":3,"959":3,"962":6,"968":6,"970":10,"992":4,"993":4,"994":8,"1017":6,"1018":4,"1019":8,"1121":3}}],["res",{"2":{"80":8}}],["redux",{"2":{"1530":1}}],["reduction",{"0":{"1155":1},"1":{"1156":1,"1157":1,"1158":1,"1159":1,"1160":1,"1161":1,"1162":1},"2":{"844":1,"995":1,"996":1,"1193":1}}],["reduction所述",{"2":{"631":1}}],["reduction和",{"2":{"631":1}}],["reduction=",{"2":{"81":2,"175":2,"220":1,"225":2,"263":1,"278":1,"350":2,"392":2,"575":4,"624":1,"681":2,"688":2,"704":2,"715":2,"736":2,"765":2,"834":2,"865":2,"874":2,"883":2,"893":2,"905":2,"962":4}}],["reduce",{"0":{"1240":1},"2":{"80":1,"120":1,"122":1,"126":2,"129":1,"146":2,"210":1,"263":2,"274":1,"334":1,"387":1,"413":2,"425":2,"472":2,"568":1,"575":1,"576":2,"605":1,"631":8,"634":1,"635":1,"974":1,"975":1,"977":1,"995":10,"996":1,"997":1,"1000":1,"1018":1,"1026":1,"1169":1,"1240":3}}],["redirect",{"2":{"1486":1}}],["redmon",{"2":{"942":1}}],["red",{"2":{"858":1,"1413":2}}],["reds",{"2":{"357":1}}],["reddi",{"2":{"32":2,"35":1}}],["=ε作为我们的判定边界",{"2":{"1180":1}}],["=εnormal欺诈检测",{"2":{"1178":1}}],["=用户的第i个活动特征",{"2":{"1178":1}}],["=b",{"2":{"1154":1}}],["=b−η|b|∑i∈b",{"2":{"613":1}}],["=b−12c⊤q−1c",{"2":{"94":1}}],["=tp",{"2":{"1140":2}}],["=tanh⁡",{"2":{"103":1}}],["=a",{"2":{"1077":1,"1121":3}}],["=argmaxy∈yp",{"2":{"513":1}}],["=argminf⁡l",{"2":{"500":1}}],["=argminx",{"2":{"50":1}}],["=θk",{"2":{"1188":2,"1189":1}}],["=θ1f1+θ2f2+⋯+θnfn除了组合原有特征以外",{"2":{"1146":1}}],["=θ1−a1m∑i=1m",{"2":{"1069":1,"1081":1}}],["=θj",{"2":{"1116":1}}],["=θj−a",{"2":{"1116":1,"1117":1}}],["=θj−α1b∑k=ii+b−1",{"2":{"1166":1}}],["=θj−α1m∑i=1m",{"2":{"1109":1,"1110":3}}],["=θj−α",{"2":{"1165":1,"1168":1}}],["=θj−α∂∂θjj",{"2":{"1068":2,"1109":1}}],["=θ",{"2":{"1100":3}}],["=θ2−a1m∑i=1m",{"2":{"1081":1}}],["=θtx=θ0x0+θ1x1+θ2x2+",{"2":{"1081":1,"1086":1,"1110":1}}],["=θtx=θ0+θ1x1+θ2x2+",{"2":{"1081":1}}],["=θtx",{"2":{"1080":1}}],["=θ0",{"2":{"1115":1}}],["=θ0+θ1f1+θ2f2+θ3f3",{"2":{"1146":1}}],["=θ0+θ1",{"2":{"1084":2}}],["=θ0+θ1×frontage+θ2×depth",{"2":{"1084":1}}],["=θ0+θ1x1+θ2x22+θ3x33+θ4x44",{"2":{"1115":1}}],["=θ0+θ1x1+θ2x22+θ3x33",{"2":{"1084":1}}],["=θ0+θ1x1+θ2x22",{"2":{"1084":1}}],["=θ0+θ1x1+θ2x2+",{"2":{"1080":1}}],["=θ0+θ1x",{"2":{"1063":1,"1064":1,"1084":1}}],["=θ0x0+θ1x1+θ2x2+",{"2":{"1080":1}}],["=θ0−a1m∑i=1m",{"2":{"1069":1,"1081":1,"1116":1,"1117":1}}],["=∥x∥2的梯度是什么",{"2":{"986":1}}],["=∥x∥2−1",{"2":{"47":1}}],["=ddxf",{"2":{"981":1}}],["=dxf",{"2":{"981":1}}],["=df",{"2":{"981":1}}],["=dydx=dfdx=ddxf",{"2":{"981":1}}],["=def=",{"2":{"519":1}}],["=def=∑h1",{"2":{"519":1}}],["=defp",{"2":{"519":2}}],["=def",{"2":{"241":1}}],["=def∂w",{"2":{"241":1}}],["=def⋅",{"2":{"241":1}}],["=defx",{"2":{"60":1}}],["=deff",{"2":{"46":2}}],["=y",{"2":{"981":1,"1109":1}}],["=k",{"2":{"977":1}}],["=6",{"2":{"957":1}}],["=6个",{"2":{"320":1}}],["=|α|f",{"2":{"1000":1}}],["=|a∩b||a∪b|",{"2":{"849":1,"1154":1}}],["=|bt|个独立梯度组成",{"2":{"78":1}}],["=uz^",{"2":{"1160":1}}],["=ureducet∗x",{"2":{"1159":1}}],["=u12+u22",{"2":{"1145":1}}],["=uc⊤v¯o−log",{"2":{"786":1}}],["=uo−∑j∈v",{"2":{"784":1}}],["=uo⊤vc−log⁡",{"2":{"784":1}}],["=3x12+5ex2的梯度",{"2":{"986":1}}],["=3x2−4x",{"2":{"981":1}}],["=3ddxx2−4ddxx=6x−4",{"2":{"981":1}}],["=33",{"2":{"956":1}}],["=3",{"2":{"775":1,"1080":1}}],["=2",{"2":{"775":1,"981":1,"1080":1,"1111":4}}],["=−y",{"2":{"1109":1}}],["=−y×log",{"2":{"1109":1,"1110":2}}],["=−1​",{"2":{"1144":1}}],["=−1的区间里函数值为0",{"2":{"1144":1}}],["=−1mtest∑i=1mtestlog⁡hθ",{"2":{"1130":1}}],["=−1m",{"2":{"1120":1}}],["=−1m∑i=1my",{"2":{"1109":3}}],["=−1m∑i=1m",{"2":{"1109":6,"1110":2}}],["=−1",{"2":{"709":1,"1144":1,"1145":1}}],["=−logσ",{"2":{"708":2}}],["=−log⁡p",{"2":{"651":1,"708":1}}],["=−∑j=1qyjlog⁡exp⁡",{"2":{"647":1}}],["=−∑j=1qyjlog⁡y^j",{"2":{"646":1}}],["=∏j=1n12πσjexp",{"2":{"1184":1}}],["=∏j=1np",{"2":{"1180":1,"1184":1}}],["=∏j=1112πσjexp",{"2":{"1180":1}}],["=∏j=1l",{"2":{"709":1}}],["=∏i=1np",{"2":{"616":1,"646":1}}],["=∏t=t1p",{"2":{"349":1}}],["=∏t=1tp",{"2":{"316":1,"347":1,"348":1,"519":1}}],["=ϕl",{"2":{"527":1}}],["=γ⊙x−μ^bσ^b+β",{"2":{"467":1}}],["=>import",{"2":{"1523":1}}],["=>person",{"2":{"1465":1,"1466":1}}],["=>",{"2":{"376":2,"409":2,"578":2,"1048":4,"1398":2,"1402":1,"1404":1,"1405":2,"1412":2,"1420":1,"1430":1,"1432":2,"1452":1,"1460":1,"1462":1,"1463":1,"1464":2,"1465":3,"1466":1,"1467":2,"1469":1,"1470":6,"1471":4,"1493":1,"1494":1,"1495":1,"1499":6,"1503":1,"1520":2}}],["=n",{"2":{"316":4}}],["=ninσ2γ2",{"2":{"247":1}}],["=πt",{"2":{"310":1}}],["=costfunction",{"2":{"1111":1}}],["=cos⁡",{"2":{"979":1}}],["=cddxf",{"2":{"981":1}}],["=c⋅w⊤x的层",{"2":{"425":1}}],["=c",{"2":{"244":1}}],["=c−1μ",{"2":{"192":1}}],["=σ",{"2":{"708":1,"709":1}}],["=σ2",{"2":{"232":1}}],["=σ1",{"2":{"232":1}}],["=μ−μσ=0和e",{"2":{"209":1}}],["=μ",{"2":{"192":2}}],["=∫∫l",{"2":{"190":1}}],["=∫f",{"2":{"156":1}}],["=hθ",{"2":{"1100":1}}],["=ht时",{"2":{"573":1}}],["=h",{"2":{"170":1,"652":1}}],["=w−η|b|∑i∈bx",{"2":{"613":1}}],["=wv⊤tanh",{"2":{"369":1}}],["=whh⊤∂l∂ht+1+wqh⊤∂l∂ot",{"2":{"312":1}}],["=wqh⊤∂l∂ot",{"2":{"312":1}}],["=w⊤x",{"2":{"270":1}}],["=w",{"2":{"164":1}}],["=∂∂zj",{"2":{"1122":1}}],["=∂∂θj",{"2":{"1109":1}}],["=∂∂θj12m∑i=1m",{"2":{"1069":1}}],["=∂ht",{"2":{"310":1}}],["=∂j∂zx⊤+λw",{"2":{"164":1}}],["=∂j∂h⊙ϕ",{"2":{"164":1}}],["=∂j∂oh⊤+λw",{"2":{"164":1}}],["=∂l∂o∈rq",{"2":{"164":1}}],["=8",{"2":{"146":1}}],["=7",{"2":{"146":1,"1090":1}}],["=55和3×",{"2":{"956":1}}],["=5",{"2":{"146":1}}],["=56",{"2":{"120":1}}],["=4",{"2":{"146":1,"709":1,"775":1}}],["=∑xf",{"2":{"1036":1}}],["=∑xxp",{"2":{"1036":1}}],["=∑xtp",{"2":{"348":3}}],["=∑j=0nθjxj",{"2":{"1093":1}}],["=∑j=1qyjlog⁡∑k=1qexp⁡",{"2":{"647":1}}],["=∑j=1nine",{"2":{"247":2}}],["=∑j−p",{"2":{"650":1}}],["=∑htp",{"2":{"519":1}}],["=∑htπt",{"2":{"519":2}}],["=∑h3",{"2":{"519":1}}],["=∑h2",{"2":{"519":1}}],["=∑h1p",{"2":{"519":1}}],["=∑h1",{"2":{"519":5}}],["=∑i=1∞p",{"2":{"1027":1}}],["=∑i=1nl",{"2":{"646":1}}],["=∑i=1n−log⁡p",{"2":{"646":1}}],["=∑i=1n12log⁡",{"2":{"616":1}}],["=∑i=1nα",{"2":{"388":2,"389":1}}],["=∑i=1nk",{"2":{"388":1}}],["=∑i=1mα",{"2":{"367":1}}],["=∑t=1tα",{"2":{"374":1}}],["=∑t=1t∂l∂htht−1⊤",{"2":{"312":1}}],["=∑t=1t∂l∂htxt⊤",{"2":{"312":1}}],["=∑t=1t∂l∂otht⊤",{"2":{"312":1}}],["=∑t=1tηte",{"2":{"115":1}}],["=∑ap",{"2":{"1033":1}}],["=∑a∑bf",{"2":{"156":1}}],["=∑af",{"2":{"156":1}}],["=∑τ=0t−1βτgt−τ",{"2":{"86":1}}],["=e−∥x−l",{"2":{"1146":1}}],["=exp",{"2":{"783":1,"785":1}}],["=exp⁡",{"2":{"44":1,"191":1,"236":1,"367":1,"624":1,"647":1,"743":1,"744":2,"785":1}}],["=e",{"2":{"247":1,"1036":3}}],["=eξ",{"2":{"115":1}}],["=η0⋅",{"2":{"114":1}}],["=η0⋅e−λt指数衰减η",{"2":{"114":1}}],["=ηi",{"2":{"114":1}}],["=ηv^ts^t+ϵ",{"2":{"33":1}}],["=∇f",{"2":{"113":1}}],["=pt",{"2":{"180":1}}],["=prod",{"2":{"164":2}}],["=p",{"2":{"105":2,"191":2,"192":1,"316":1,"317":4,"348":2,"515":4,"519":2,"708":1,"1025":1,"1032":3,"1034":5,"1035":8,"1107":1,"1112":1,"1145":1}}],["=pij",{"2":{"105":1}}],["=paddle",{"2":{"71":1}}],["=r",{"2":{"95":1}}],["=oj−max",{"2":{"624":1}}],["=o",{"2":{"94":1}}],["=q⊤k",{"2":{"370":1}}],["=q",{"2":{"94":1,"191":1}}],["=1这个约束所代替的",{"2":{"1145":1}}],["=1​",{"2":{"1144":1}}],["=1计算输出层的值",{"2":{"1100":1}}],["=1时",{"2":{"1081":1,"1144":1}}],["=1m∑i=1mcost",{"2":{"1109":1}}],["=1m∑i=1m12",{"2":{"1109":1}}],["=1m∑i=1m",{"2":{"1069":2,"1109":2,"1117":1,"1152":1}}],["=1llog⁡p",{"2":{"515":1}}],["=1lα∑t",{"2":{"515":1}}],["=10时",{"2":{"514":2}}],["=10次平方梯度观测值的平均值",{"2":{"108":1}}],["=1t",{"2":{"513":1}}],["=1t∑t=1tl",{"2":{"307":1}}],["=1",{"2":{"310":1,"391":1,"519":1,"646":1,"709":3,"743":1,"744":1,"981":1,"1027":1,"1144":2,"1145":3,"1184":1,"1187":1,"1188":4,"1189":4,"1190":2}}],["=11+e−θtx",{"2":{"1109":1,"1110":1}}],["=11+e−θtx带入到这样定义了的代价函数中时",{"2":{"1109":1}}],["=11+e−z",{"2":{"1107":2}}],["=11+exp⁡",{"2":{"191":1,"708":1}}],["=11−γ",{"2":{"107":1}}],["=1−πt且p",{"2":{"310":1}}],["=1−tanh2",{"2":{"237":1}}],["=1−tanh2⁡",{"2":{"103":1}}],["=1−",{"2":{"116":1}}],["=1−pt",{"2":{"180":1}}],["=1−p",{"2":{"116":1}}],["=1n∑i=1nl",{"2":{"611":1}}],["=1n∑i=1nyi",{"2":{"387":1}}],["=1n∑i=1n12",{"2":{"270":1,"611":1}}],["=1n∑i=1nδxi",{"2":{"116":1}}],["=1n∑i=1n∇fi",{"2":{"113":2}}],["=1n∑i=1nfi",{"2":{"113":1}}],["=1|bt|∑i∈bthi",{"2":{"86":1}}],["=12∑",{"2":{"1189":1,"1190":1}}],["=12∑iλixi2",{"2":{"97":1}}],["=12mtest∑i=1mtest",{"2":{"1131":1}}],["=12mcv∑i=1m",{"2":{"1131":1,"1132":1}}],["=12m∑i=1m",{"2":{"1064":1,"1081":2,"1086":1,"1116":1,"1131":1,"1132":1}}],["=12m",{"2":{"786":1,"1115":1}}],["=12exp⁡",{"2":{"621":1}}],["=12πσexp⁡",{"2":{"1179":1}}],["=12πσ2exp⁡",{"2":{"616":2}}],["=12πexp⁡",{"2":{"388":1}}],["=12z⊤λz+b",{"2":{"94":1}}],["=12",{"2":{"60":1,"94":1,"611":1,"1086":5,"1145":1}}],["=12∥x∥2是凸的",{"2":{"46":1}}],["=12x⊤qx+x⊤c+b的最小值和最小化器",{"2":{"97":1}}],["=12x⊤qx+x⊤c+b",{"2":{"94":1}}],["=12x⊤qx+c⊤x+b这一问题",{"2":{"26":1}}],["=12x2+ϵx+12ϵ2",{"2":{"59":1}}],["=12x2",{"2":{"59":1}}],["=12x¯⊤λx¯+c¯⊤x¯+b",{"2":{"26":1}}],["===",{"2":{"1432":1,"1467":2}}],["==",{"2":{"67":5,"80":4,"81":6,"129":4,"137":11,"146":4,"172":8,"174":4,"176":1,"206":2,"211":2,"225":2,"263":8,"275":4,"278":4,"335":4,"350":2,"357":2,"362":2,"363":1,"368":4,"431":1,"435":8,"436":2,"437":6,"442":3,"472":6,"502":4,"566":1,"575":1,"576":6,"577":4,"623":2,"634":4,"635":1,"682":6,"692":1,"713":2,"715":3,"726":3,"767":8,"775":1,"777":4,"826":3,"836":3,"848":1,"854":7,"858":1,"863":3,"883":6,"893":1,"894":7,"906":7,"927":4,"959":8,"962":3,"969":3,"970":4,"974":4,"976":8,"977":4,"981":1,"992":4,"1018":3,"1021":2,"1024":1,"1219":1,"1240":1,"1315":1,"1432":1}}],["=xk",{"2":{"1189":1}}],["=xij和qij",{"2":{"743":1}}],["=xty|x|⋅|y|=∑i=1nxiyi∑i=1nxi2∑i=1nyi2",{"2":{"1154":1}}],["=xtxθ−xty",{"2":{"1086":1}}],["=xt",{"2":{"527":1}}],["=x+g",{"2":{"479":1}}],["=x+ϵ",{"2":{"170":1}}],["=xw+b",{"2":{"232":1}}],["=xw",{"2":{"232":1}}],["=x3−1x和其在x=1处切线的图像",{"2":{"986":1}}],["=x3",{"2":{"102":1}}],["=x⋅cos",{"2":{"101":1}}],["=x⋅cos⁡",{"2":{"56":1}}],["=x",{"2":{"60":1,"170":1,"241":1,"312":1,"500":1,"1147":3}}],["=xcos⁡",{"2":{"59":1}}],["=x和h=1",{"2":{"59":1}}],["=x12+2x22而言",{"2":{"118":1}}],["=x12+2x22",{"2":{"57":1,"87":1}}],["=x2−y2",{"2":{"102":1}}],["=x2",{"2":{"54":1,"118":1}}],["=leftchild",{"2":{"709":1}}],["=log⁡",{"2":{"624":2,"655":1}}],["=log⁡∑iexp⁡",{"2":{"52":1}}],["=limϵ→0f",{"2":{"46":1}}],["=v⊤x+b",{"2":{"47":1}}],["=g",{"2":{"46":1,"574":1,"981":1,"1099":4,"1100":4,"1101":1,"1107":1,"1108":1,"1109":1,"1117":1,"1122":1}}],["=max",{"2":{"44":1,"235":1,"773":1,"1090":1}}],["=fminunc",{"2":{"1111":1}}],["=fl",{"2":{"241":1}}],["=f",{"2":{"44":1,"46":5,"48":1,"52":1,"54":2,"57":1,"59":1,"60":1,"479":1,"744":1,"981":2}}],["=f¯",{"2":{"26":1}}],["=0就会将负例正确分离",{"2":{"1144":1}}],["=0的点",{"2":{"191":1}}],["=0的x",{"2":{"44":1}}],["=0可以写成",{"2":{"60":1}}],["=0",{"2":{"27":1,"31":2,"87":1,"93":1,"103":1,"105":1,"108":1,"111":1,"247":1,"743":1,"1000":1,"1025":1,"1027":1,"1035":7,"1085":1,"1107":2,"1108":3}}],["=λw",{"2":{"164":2}}],["=λ2x2时会发生什么",{"2":{"95":1}}],["=λf",{"2":{"46":1}}],["=λg",{"2":{"46":1}}],["=λx¯+c¯=λ",{"2":{"26":1}}],["=λ12ux中的一个",{"2":{"26":1}}],["=sin⁡",{"2":{"979":1}}],["=softmax",{"2":{"367":1}}],["=s",{"2":{"25":1}}],["=δxt−1+ϵst+ϵ⊙gt",{"2":{"20":1}}],["=",{"2":{"0":1,"21":32,"27":6,"28":17,"29":3,"34":36,"35":25,"41":10,"44":2,"45":1,"46":1,"52":1,"54":12,"56":1,"57":15,"59":5,"67":57,"68":12,"70":5,"71":13,"72":16,"73":7,"77":29,"78":3,"79":16,"80":38,"81":41,"87":5,"88":4,"89":3,"91":14,"92":3,"94":1,"95":5,"99":2,"101":2,"102":10,"103":2,"107":3,"108":24,"109":3,"113":6,"114":4,"118":1,"120":2,"121":1,"122":11,"126":7,"127":9,"128":5,"129":31,"136":11,"137":66,"141":20,"142":8,"145":1,"146":8,"147":19,"148":8,"170":1,"172":16,"173":10,"174":46,"175":15,"176":9,"206":12,"208":5,"209":10,"210":34,"211":12,"212":2,"213":5,"216":2,"217":28,"218":2,"219":8,"220":2,"221":7,"225":19,"235":11,"236":6,"237":6,"242":9,"243":8,"262":12,"263":41,"271":8,"273":10,"275":21,"276":1,"278":28,"296":1,"318":10,"320":8,"321":30,"324":8,"325":54,"326":14,"329":3,"330":4,"331":32,"332":56,"333":20,"334":17,"335":61,"340":4,"350":38,"351":17,"357":4,"361":3,"362":1,"363":9,"364":6,"368":16,"369":52,"370":24,"375":74,"376":14,"382":80,"386":24,"387":4,"388":12,"390":17,"391":12,"392":49,"396":12,"398":40,"399":4,"400":3,"405":15,"406":23,"407":66,"408":125,"409":57,"413":11,"414":20,"418":5,"422":8,"423":11,"424":10,"425":39,"429":8,"433":9,"435":4,"436":12,"437":11,"441":24,"442":30,"446":5,"447":4,"448":8,"449":5,"451":6,"461":9,"462":2,"463":1,"472":74,"473":9,"474":3,"480":33,"481":11,"482":25,"483":2,"487":44,"488":26,"489":2,"494":1,"495":11,"496":2,"501":52,"502":27,"503":2,"507":6,"508":21,"509":8,"519":1,"523":21,"528":21,"529":1,"535":16,"543":8,"544":33,"545":33,"546":10,"547":14,"557":8,"558":37,"559":40,"560":10,"561":14,"565":7,"566":4,"567":1,"568":5,"569":9,"573":35,"574":48,"575":39,"576":52,"577":45,"578":12,"582":24,"583":10,"584":17,"589":3,"590":8,"591":4,"592":5,"593":4,"594":4,"595":21,"597":1,"599":8,"600":7,"601":10,"604":3,"605":13,"609":1,"615":14,"616":5,"622":2,"623":5,"624":3,"625":4,"626":1,"629":2,"630":16,"631":10,"633":4,"634":11,"635":38,"636":3,"666":6,"667":11,"668":24,"669":25,"674":21,"675":9,"676":14,"677":30,"679":11,"680":12,"681":10,"682":9,"686":25,"687":65,"688":26,"692":6,"693":4,"694":3,"695":30,"698":6,"699":9,"702":42,"703":8,"704":9,"712":6,"713":24,"714":4,"715":15,"717":1,"718":4,"720":6,"721":13,"722":47,"724":1,"725":8,"726":53,"727":23,"734":39,"736":45,"737":17,"738":24,"743":1,"748":15,"750":7,"751":3,"757":20,"760":6,"762":4,"763":9,"765":11,"766":4,"767":23,"768":12,"772":5,"773":6,"774":5,"775":12,"776":8,"777":33,"790":32,"791":4,"792":3,"796":10,"797":12,"816":8,"817":5,"819":21,"820":10,"821":8,"826":6,"827":13,"828":27,"834":63,"835":12,"836":9,"837":26,"848":75,"849":24,"851":46,"852":55,"853":6,"854":99,"857":2,"858":15,"862":11,"863":39,"864":7,"865":7,"866":31,"872":19,"873":9,"874":24,"876":8,"878":3,"879":3,"880":3,"881":3,"882":12,"883":51,"889":4,"890":12,"891":6,"892":14,"893":20,"894":28,"895":6,"896":15,"898":5,"901":4,"902":3,"903":6,"904":14,"905":26,"906":34,"907":6,"908":13,"910":3,"912":15,"918":5,"919":15,"920":21,"923":2,"925":5,"926":13,"927":27,"931":1,"932":27,"933":6,"938":7,"945":38,"946":13,"947":24,"948":9,"949":12,"956":6,"957":5,"958":5,"959":58,"961":8,"962":14,"963":26,"964":37,"966":21,"968":13,"969":19,"970":16,"974":15,"975":4,"976":13,"977":25,"981":12,"983":1,"989":8,"990":4,"992":8,"993":4,"994":16,"995":12,"996":4,"997":5,"999":5,"1000":7,"1011":2,"1012":3,"1013":6,"1017":7,"1018":16,"1019":8,"1020":5,"1021":18,"1022":12,"1026":21,"1047":4,"1048":6,"1061":1,"1067":2,"1076":1,"1077":1,"1080":1,"1081":1,"1085":1,"1088":1,"1089":6,"1090":3,"1092":9,"1093":2,"1094":1,"1109":11,"1117":6,"1120":1,"1121":8,"1122":1,"1124":1,"1125":1,"1151":4,"1154":1,"1159":1,"1160":1,"1165":1,"1167":1,"1214":2,"1216":2,"1218":2,"1219":3,"1220":2,"1221":1,"1223":1,"1226":1,"1233":1,"1236":1,"1239":1,"1240":4,"1242":1,"1243":1,"1244":1,"1246":1,"1247":1,"1252":1,"1255":1,"1261":1,"1398":7,"1399":3,"1401":5,"1402":2,"1404":11,"1405":7,"1407":5,"1408":4,"1409":3,"1410":5,"1412":5,"1413":3,"1414":3,"1416":3,"1417":2,"1419":2,"1420":2,"1421":2,"1422":3,"1425":4,"1426":4,"1427":1,"1428":6,"1430":4,"1431":5,"1432":6,"1433":4,"1434":7,"1435":5,"1445":1,"1451":4,"1454":4,"1455":7,"1456":5,"1457":5,"1459":4,"1460":7,"1462":2,"1463":2,"1464":3,"1465":4,"1466":4,"1467":4,"1468":7,"1469":4,"1470":1,"1471":9,"1474":1,"1476":2,"1479":1,"1481":1,"1482":1,"1485":2,"1489":2,"1490":4,"1491":4,"1492":2,"1493":3,"1495":4,"1497":4,"1498":3,"1499":1,"1500":5,"1501":5,"1503":4,"1508":1,"1511":1,"1512":1,"1515":2,"1516":2,"1518":4,"1519":2,"1520":3,"1522":1,"1523":1}}],["fgvc",{"2":{"1543":1}}],["f≈e0=1",{"2":{"1146":1}}],["f5=x22得到",{"2":{"1146":1}}],["f4=x12",{"2":{"1146":1}}],["f−32",{"2":{"989":1}}],["fba480ffa8aa7e0febbb511d181409f899b9baa5",{"2":{"872":1}}],["f=d2l",{"2":{"827":1,"883":2}}],["fminuc这样的优化算法来求解求出权重矩阵",{"2":{"1121":1}}],["fminuc",{"2":{"1117":1,"1121":1}}],["fminunc",{"2":{"1109":2,"1111":1}}],["fminunc是",{"2":{"1109":1}}],["fmap",{"2":{"912":27,"915":2}}],["fma",{"2":{"813":1}}],["fmt",{"2":{"635":2,"981":3}}],["fmts",{"2":{"635":3,"981":1}}],["fmts=",{"2":{"54":2,"635":1,"981":1}}],["f中交换词索引j和k",{"2":{"744":1}}],["f中定义",{"2":{"709":1}}],["f分别输入ai和bj",{"2":{"674":1}}],["f∈f",{"2":{"500":1}}],["f3≈0",{"2":{"1146":1}}],["f3=x1x2",{"2":{"1146":1}}],["f3",{"2":{"479":1,"1146":3}}],["f2=x2",{"2":{"1146":1}}],["f2",{"2":{"479":2,"1146":4}}],["f1≈1",{"2":{"1146":1}}],["f1=similarity",{"2":{"1146":1}}],["f1=x1",{"2":{"1146":1}}],["f1score",{"2":{"1140":1}}],["f1",{"2":{"479":4,"1140":1,"1146":4}}],["ff",{"2":{"500":1}}],["ff∗",{"2":{"500":1}}],["ffn",{"2":{"405":33,"407":32,"408":32,"409":18,"686":10,"690":1,"726":3,"734":16,"738":10}}],["ff7f0e",{"2":{"57":3}}],["f可以是",{"2":{"381":1}}],["fetch",{"2":{"1330":1}}],["female",{"2":{"751":1}}],["feed",{"2":{"404":1}}],["feng",{"2":{"395":1,"403":1}}],["feline",{"2":{"316":1,"1416":1}}],["fergus",{"2":{"300":1}}],["featurex",{"2":{"1089":1}}],["feature",{"2":{"21":15,"28":11,"34":15,"35":12,"80":10,"91":7,"108":9,"131":1,"158":1,"270":1,"350":1,"494":1,"609":1,"618":1,"681":2,"905":2,"906":2,"946":13,"947":14,"964":2,"1082":1,"1325":1,"1329":3}}],["featuresx文件如这个窗口所示",{"2":{"1089":1}}],["featuresx",{"2":{"1089":7}}],["features函数计算风格层的输出",{"2":{"923":1}}],["features函数计算所得到的内容层的输出",{"2":{"922":1}}],["features函数来抽取合成图像的内容特征和风格特征",{"2":{"920":1}}],["features和output",{"2":{"873":1}}],["features=768",{"2":{"738":6}}],["features=128",{"2":{"726":3}}],["features=256",{"2":{"686":6}}],["features中的每一行都包含一个二维数据样本",{"2":{"599":1}}],["features中的单项式由gamma函数重新缩放",{"2":{"262":1}}],["features",{"2":{"7":1,"91":2,"208":1,"209":18,"210":29,"212":1,"213":6,"262":12,"263":19,"264":2,"265":2,"266":2,"284":1,"350":5,"351":14,"369":16,"472":11,"589":1,"590":1,"595":4,"599":4,"600":7,"605":8,"693":2,"694":3,"695":12,"738":6,"827":2,"828":2,"862":2,"873":3,"874":1,"876":1,"883":8,"894":6,"905":15,"906":11,"908":3,"920":9,"927":3,"932":12,"936":1,"945":15,"946":3,"947":18,"963":6,"1080":1,"1084":1,"1183":1}}],["fcn所示",{"2":{"862":1}}],["fcn",{"2":{"861":2,"862":1,"886":1}}],["fc",{"2":{"231":1,"642":1,"826":2,"873":7,"874":10,"876":2}}],["fruits",{"2":{"1401":1}}],["freeze",{"2":{"1269":1}}],["free",{"2":{"1195":1}}],["freq=10",{"2":{"772":1,"777":3}}],["freq=5",{"2":{"668":3,"693":1,"695":3,"722":3}}],["freq=2",{"2":{"567":1,"569":2}}],["freq=0",{"2":{"363":1}}],["freq参数",{"2":{"366":1}}],["frequency",{"2":{"318":2}}],["freq",{"2":{"318":6,"363":3,"757":14}}],["freqs的键中指定的同一数据集",{"2":{"757":1}}],["freqs的键迭代地执行字节对编码算法",{"2":{"757":1}}],["freqs的键",{"2":{"757":2}}],["freqs将词映射到数据集中的频率",{"2":{"757":1}}],["freqs",{"2":{"318":13,"363":4,"757":18}}],["freitas",{"2":{"300":1,"519":1}}],["fragment",{"2":{"1441":1}}],["fra",{"2":{"376":4,"409":4,"565":4,"578":4}}],["frasconi",{"2":{"397":1}}],["fras",{"2":{"376":4,"409":4,"578":4}}],["francisco",{"2":{"342":1}}],["frac",{"2":{"236":1,"237":1,"262":2,"334":1,"981":1,"1120":2,"1121":3,"1160":1,"1165":1,"1167":1}}],["framework",{"2":{"225":1,"278":2}}],["frobenius范数满足向量范数的所有性质",{"2":{"1000":1}}],["frobenius",{"2":{"1000":1}}],["frontends",{"2":{"790":1}}],["frontends所示",{"2":{"790":3}}],["frontmatter",{"0":{"4":1},"2":{"0":3,"4":1}}],["from",{"2":{"0":1,"21":5,"27":5,"34":5,"38":9,"54":5,"67":12,"77":8,"79":1,"87":5,"99":9,"107":5,"112":5,"120":4,"126":7,"136":7,"137":1,"141":3,"146":6,"172":7,"175":1,"208":8,"216":6,"220":1,"224":7,"225":1,"234":5,"242":5,"261":7,"271":8,"318":4,"324":9,"329":9,"335":1,"340":4,"350":8,"357":4,"360":4,"367":8,"374":7,"381":7,"385":7,"395":7,"404":7,"413":3,"418":1,"422":5,"429":3,"441":5,"446":3,"461":6,"472":6,"480":6,"487":7,"494":6,"501":8,"507":6,"523":6,"528":6,"533":2,"543":7,"557":7,"564":4,"572":8,"575":1,"581":8,"583":1,"584":2,"589":5,"590":1,"591":3,"598":5,"615":5,"622":7,"624":1,"629":8,"666":5,"673":8,"685":6,"691":5,"698":6,"712":6,"718":3,"720":4,"721":1,"722":8,"725":5,"731":1,"733":6,"747":5,"760":6,"771":3,"789":6,"795":3,"813":9,"819":10,"825":6,"833":8,"847":4,"857":5,"861":9,"871":7,"877":7,"887":7,"899":6,"912":4,"918":6,"931":4,"945":4,"954":9,"967":6,"981":10,"1026":6,"1048":5,"1161":1,"1235":1,"1240":1,"1315":1,"1454":2,"1455":1,"1456":1,"1457":1,"1459":1,"1460":1,"1462":1,"1463":1,"1464":1,"1465":1,"1466":1,"1467":1,"1468":4,"1469":5,"1470":1,"1471":6,"1474":6,"1481":1,"1482":1,"1485":1,"1489":3,"1490":5,"1491":1,"1492":2,"1493":1,"1495":4,"1497":3,"1499":4,"1501":3,"1503":3,"1508":1,"1518":1,"1520":1,"1523":1,"1525":2}}],["fp16或int8通常就足够了",{"2":{"811":1}}],["fp",{"2":{"206":3,"1139":2}}],["foundation",{"2":{"1374":1}}],["focal",{"2":{"966":6}}],["fontsize=9",{"2":{"848":1}}],["footprint",{"2":{"832":1}}],["fold",{"2":{"211":6,"212":1}}],["folder",{"2":{"206":2,"692":3,"892":10,"904":10}}],["folder=none",{"2":{"206":1}}],["for=",{"2":{"1456":1,"1457":1,"1469":1,"1471":1,"1479":1,"1490":1,"1506":1,"1507":1,"1508":1}}],["fork≠0",{"2":{"1188":1}}],["fork=0",{"2":{"1188":1}}],["forever",{"2":{"1168":1,"1191":1}}],["formulation",{"2":{"1158":1,"1187":1}}],["form",{"2":{"1151":1}}],["format=json",{"2":{"1495":1}}],["formatting",{"2":{"1444":1}}],["formats",{"2":{"981":1}}],["format",{"2":{"137":1}}],["for循环也是可以的",{"2":{"1110":1}}],["for循环来更新这些参数值",{"2":{"1110":1}}],["for语句",{"2":{"1091":1}}],["forums",{"2":{"634":1}}],["forcing",{"2":{"576":1}}],["force",{"2":{"67":2,"137":1,"326":1,"335":1,"435":4,"436":1,"576":1,"767":1,"828":1,"926":1}}],["forget",{"2":{"552":1}}],["forward中定义的所有打印语句都被忽略了",{"2":{"821":1}}],["forward中的单隐藏层简单网络的参数是",{"2":{"164":1}}],["forward函数中添加控制流",{"2":{"823":1}}],["forward函数的第一行中添加x",{"2":{"823":1}}],["forward函数增加了一个必需的参数f",{"2":{"821":1}}],["forward函数",{"2":{"821":1}}],["forward",{"2":{"127":3,"161":1,"162":2,"163":2,"165":1,"174":2,"325":3,"332":16,"369":3,"370":3,"375":3,"382":3,"391":3,"398":3,"404":1,"405":3,"406":3,"407":6,"408":6,"413":3,"414":3,"422":2,"423":3,"424":3,"425":6,"442":3,"472":3,"480":3,"487":3,"501":3,"519":1,"533":3,"534":3,"535":3,"573":3,"574":3,"575":6,"674":3,"675":3,"676":3,"677":3,"688":3,"702":3,"713":3,"734":3,"736":3,"737":3,"738":3,"765":2,"810":1,"821":1,"893":1,"926":3,"956":9,"957":2,"958":3,"959":9,"1099":1,"1100":1}}],["for",{"0":{"1092":1,"1224":1,"1225":1},"1":{"1225":1,"1226":1},"2":{"0":1,"5":1,"9":1,"21":4,"28":4,"34":4,"35":4,"41":2,"47":1,"54":6,"57":2,"59":1,"67":7,"68":1,"70":1,"71":4,"72":2,"73":2,"77":16,"78":4,"80":12,"81":8,"89":1,"91":4,"95":1,"101":1,"107":1,"108":4,"120":2,"121":1,"126":4,"129":4,"136":4,"137":11,"146":4,"173":1,"206":1,"210":9,"211":2,"217":1,"225":1,"243":4,"262":2,"263":7,"275":8,"278":9,"318":7,"320":4,"321":4,"331":3,"332":4,"333":12,"334":12,"335":11,"342":2,"350":10,"351":12,"357":2,"361":1,"362":3,"363":7,"364":2,"375":5,"376":3,"392":4,"398":4,"399":1,"407":9,"408":12,"409":22,"418":2,"424":8,"432":2,"433":4,"436":2,"446":4,"461":4,"480":9,"482":4,"488":4,"495":4,"502":9,"507":4,"508":8,"509":2,"544":3,"545":4,"558":3,"559":4,"565":1,"566":4,"568":3,"569":1,"573":2,"574":1,"576":13,"577":4,"578":5,"582":4,"583":1,"584":1,"595":8,"600":3,"604":4,"605":7,"615":3,"616":4,"633":1,"634":4,"635":9,"636":2,"667":8,"668":3,"669":1,"681":1,"686":3,"687":19,"692":3,"693":2,"694":3,"695":6,"699":3,"702":7,"713":2,"717":1,"718":1,"720":1,"721":5,"722":19,"726":8,"734":6,"748":4,"750":4,"757":6,"767":9,"768":3,"772":1,"773":7,"774":5,"775":3,"776":3,"777":5,"790":9,"792":2,"796":3,"797":3,"820":8,"826":3,"827":3,"828":12,"835":16,"836":1,"837":26,"848":1,"851":3,"852":3,"854":4,"862":1,"866":3,"872":2,"874":2,"876":2,"878":1,"882":2,"883":13,"890":4,"892":8,"893":1,"894":6,"896":3,"904":8,"905":9,"906":13,"908":9,"920":3,"925":2,"926":3,"927":3,"932":3,"933":3,"945":8,"946":5,"947":6,"948":3,"956":3,"957":3,"958":3,"959":6,"963":6,"964":6,"966":8,"968":2,"981":2,"1026":4,"1048":1,"1081":1,"1092":6,"1093":4,"1110":2,"1116":1,"1117":1,"1122":1,"1128":1,"1139":1,"1141":1,"1151":2,"1162":1,"1165":2,"1166":2,"1168":1,"1193":2,"1230":1,"1242":1,"1243":1,"1247":1,"1296":1,"1444":5,"1525":1}}],["ft=σ",{"2":{"553":1}}],["ftse100",{"2":{"346":1}}],["ftse100所示的股票价格",{"2":{"346":1}}],["ft+1",{"2":{"196":1}}],["ft",{"2":{"196":2}}],["ft⟶data",{"2":{"196":1}}],["f相对于x的梯度维数是多少",{"2":{"167":1}}],["f∗g=g∗f",{"2":{"160":1}}],["f∗g",{"2":{"156":3}}],["f有多少局部最小值",{"2":{"118":1}}],["f在",{"2":{"87":1}}],["fallback>",{"2":{"1523":1}}],["fallback",{"2":{"1523":1}}],["falsesharing",{"2":{"810":1}}],["falsesharing所示的错误共享",{"2":{"810":1}}],["false",{"2":{"67":2,"80":1,"206":1,"217":4,"235":1,"242":1,"273":2,"544":1,"558":1,"582":6,"601":2,"669":3,"679":1,"687":3,"695":3,"703":1,"714":2,"720":1,"726":3,"810":1,"835":1,"864":1,"866":3,"876":1,"883":3,"905":1,"948":1,"949":3,"1088":1,"1139":2,"1216":1,"1219":1,"1220":3,"1409":2,"1432":1,"1522":1}}],["father",{"2":{"1497":2,"1501":2,"1503":2}}],["fatter",{"2":{"757":1}}],["fail",{"2":{"1313":1,"1315":1}}],["fair",{"2":{"1026":19}}],["facebook",{"2":{"1303":1}}],["facecolor=color",{"2":{"848":1}}],["factorization",{"2":{"1191":1}}],["factor=tf",{"2":{"436":1}}],["factor=",{"2":{"436":1}}],["factor=0",{"2":{"70":1,"71":2}}],["factor=1",{"2":{"70":1}}],["factor",{"2":{"70":8,"71":4,"436":2,"863":15}}],["factorscheduler",{"2":{"70":2}}],["fancy",{"2":{"816":2,"817":4}}],["fabric",{"2":{"813":1}}],["faster",{"0":{"939":1},"2":{"757":1,"936":1,"939":5,"941":1}}],["fast",{"0":{"938":1},"2":{"757":5,"936":1,"938":5,"939":1,"941":1,"1313":1,"1315":1}}],["fasttext的词量更大",{"2":{"756":1}}],["fasttext的其余部分与跳元模型相同",{"2":{"756":1}}],["fasttext可以被认为是子词级跳元模型",{"2":{"756":1}}],["fasttext模型提出了一种子词嵌入方法",{"2":{"756":1,"758":1}}],["fasttext模型",{"0":{"756":1}}],["fasttext",{"2":{"748":1,"755":1}}],["fasttext网站",{"2":{"748":1}}],["fashionmnist",{"2":{"582":6,"584":6}}],["fashion",{"2":{"67":4,"137":1,"173":1,"175":4,"216":2,"217":1,"225":1,"321":2,"462":3,"473":2,"483":1,"489":1,"496":1,"497":1,"503":1,"509":1,"581":1,"582":8,"584":8,"585":1,"622":1,"629":2,"636":2,"744":1,"828":3,"837":3,"882":2}}],["fa19780a7b011d9b009e8bff8e99922a8ee2eb90",{"2":{"208":1}}],["fly",{"2":{"1422":3}}],["flyable",{"2":{"1422":3}}],["flying",{"2":{"727":3,"731":1,"1422":1}}],["fletcher",{"2":{"1109":1}}],["flipud",{"2":{"1090":1}}],["flipup",{"2":{"1090":1}}],["flow",{"2":{"1325":2}}],["floor",{"2":{"890":1,"1090":1}}],["floating",{"2":{"813":1}}],["floattensor",{"2":{"413":1}}],["float",{"2":{"54":3,"57":4,"59":1,"72":2,"122":1,"129":1,"172":1,"210":4,"211":2,"212":2,"213":1,"392":8,"575":1,"605":4,"634":3,"635":4,"726":2,"748":1,"750":1,"767":2,"768":3,"827":1,"852":1,"883":1,"905":1,"906":2,"927":9,"932":1,"947":1,"962":6,"964":4,"1022":4,"1216":1,"1232":1}}],["float32",{"2":{"41":1,"54":1,"57":2,"79":4,"99":1,"101":1,"102":1,"103":1,"136":2,"147":3,"172":6,"209":3,"235":2,"242":1,"262":1,"325":2,"331":6,"332":2,"333":1,"334":2,"335":1,"350":2,"369":3,"370":1,"386":1,"390":1,"391":1,"398":6,"406":3,"407":1,"408":1,"409":1,"413":1,"414":2,"430":1,"436":1,"472":6,"544":6,"558":3,"575":6,"722":6,"765":1,"767":2,"852":4,"854":3,"863":1,"866":1,"894":1,"919":1,"926":1,"932":2,"938":2,"947":4,"964":2,"966":2,"968":1,"970":1,"974":2,"994":3,"995":3,"997":3,"999":2,"1000":1,"1007":1,"1017":1,"1018":3,"1020":1,"1026":2}}],["flask",{"2":{"1297":1}}],["flat",{"2":{"576":1,"713":1}}],["flatten=true",{"2":{"676":3}}],["flatten=flatten",{"2":{"674":2}}],["flatten=false",{"2":{"369":4,"375":1,"382":4,"405":2,"408":1,"574":1,"674":3,"675":3,"736":2}}],["flatten",{"2":{"67":3,"136":3,"174":1,"176":3,"225":3,"425":3,"429":1,"433":1,"435":3,"436":1,"437":1,"442":3,"461":3,"473":3,"474":3,"482":3,"488":3,"495":4,"502":2,"508":3,"582":3,"623":4,"674":11,"713":2,"737":2,"826":2,"956":9}}],["flammarion",{"2":{"95":1}}],["fn=batchify",{"2":{"777":3}}],["fname",{"2":{"206":12,"890":6,"932":6,"945":15}}],["fn",{"2":{"67":6,"68":2,"71":2,"72":2,"73":2,"80":8,"81":6,"137":2,"321":3,"332":16,"584":3,"1139":2}}],["f的梯度接近零",{"2":{"103":1}}],["f的值可能会趋于增加",{"2":{"59":1}}],["f的最小值满足∇f=0",{"2":{"59":1}}],["f为凸函数",{"2":{"46":1}}],["fixed",{"2":{"866":2,"946":1}}],["fixedhiddenmlp",{"2":{"425":10}}],["findindex",{"2":{"1432":1}}],["find",{"2":{"1090":4,"1432":1}}],["finetune",{"2":{"870":1,"873":9,"874":2,"876":2,"905":19}}],["finetune所示",{"2":{"870":1}}],["finetuning",{"2":{"656":1,"663":1,"685":1}}],["fine",{"2":{"869":1,"870":1,"874":9,"886":1,"905":2}}],["finally",{"2":{"1236":2}}],["final",{"2":{"72":7,"73":2,"312":2,"862":2}}],["firstname",{"2":{"1460":5}}],["first函数将图像增广应用于每个训练样本的第一个元素",{"2":{"882":1}}],["first",{"2":{"348":1,"502":12,"583":1,"584":2,"826":9,"874":2,"882":1,"892":3,"893":3,"904":3,"1109":2,"1117":2}}],["field",{"2":{"131":1}}],["fitting",{"2":{"1114":1}}],["fit",{"2":{"67":2,"137":1,"611":3}}],["figure",{"2":{"102":2,"981":1}}],["figsize函数来设置图表大小",{"2":{"981":1}}],["figsize",{"2":{"44":1,"54":2,"57":3,"80":1,"89":1,"95":1,"99":2,"107":1,"566":1,"582":3,"599":1,"693":1,"848":1,"857":2,"863":3,"878":2,"912":3,"918":3,"964":3,"966":3,"981":5,"1026":4}}],["figsize=figsize",{"2":{"357":1,"582":3,"635":1}}],["figsize=",{"2":{"41":2,"235":8,"236":8,"237":8,"242":4,"350":2,"351":3,"357":1,"398":4,"399":4,"409":4,"616":2,"635":1,"927":3,"981":2}}],["fig",{"2":{"40":3,"50":2,"120":2,"122":1,"126":2,"130":3,"131":2,"140":1,"146":2,"157":1,"163":1,"164":1,"171":2,"181":2,"183":1,"207":2,"208":1,"213":1,"229":1,"231":1,"259":1,"282":2,"289":1,"291":3,"292":1,"294":1,"295":1,"297":1,"298":1,"299":1,"304":1,"311":1,"312":6,"319":2,"340":1,"341":2,"346":1,"347":1,"355":4,"356":2,"357":2,"367":2,"374":2,"380":1,"385":1,"388":1,"397":4,"404":3,"406":1,"408":1,"422":1,"449":1,"455":1,"458":1,"461":1,"479":2,"487":1,"488":1,"494":1,"500":3,"501":6,"502":1,"505":1,"508":2,"513":13,"515":1,"519":1,"520":1,"526":1,"527":1,"532":1,"540":1,"541":1,"542":1,"572":4,"573":2,"574":2,"576":1,"577":1,"591":1,"611":1,"618":4,"619":1,"635":2,"641":1,"657":1,"658":2,"659":2,"660":1,"663":2,"672":1,"673":1,"674":1,"675":1,"685":1,"687":1,"688":1,"698":2,"699":11,"701":1,"709":4,"712":1,"733":1,"734":1,"754":2,"783":1,"785":3,"790":5,"795":1,"797":1,"800":1,"801":1,"807":1,"808":1,"809":1,"810":2,"811":5,"816":1,"832":2,"833":1,"841":2,"842":3,"843":2,"848":2,"849":1,"851":3,"853":3,"854":4,"858":3,"862":1,"870":1,"887":1,"888":1,"889":1,"899":1,"901":1,"916":1,"917":2,"937":1,"938":2,"939":1,"940":1,"943":1,"944":1,"953":3,"959":2,"964":6,"968":2,"969":3,"980":1,"1025":1}}],["filt",{"2":{"863":6}}],["filtering",{"2":{"1189":1,"1190":1}}],["filter=50",{"2":{"834":1}}],["filter=20",{"2":{"834":1}}],["filters",{"2":{"455":1,"958":10}}],["filters是从alexnet论文",{"2":{"455":1}}],["filters=num",{"2":{"480":1}}],["filters=384",{"2":{"461":2}}],["filters=256",{"2":{"461":2}}],["filters=96",{"2":{"461":1}}],["filters=16",{"2":{"67":1,"136":1,"473":1,"474":1}}],["filters=6",{"2":{"67":1,"136":1,"473":1,"474":1}}],["filter",{"0":{"1240":1},"2":{"155":1,"487":1,"947":9,"1239":1,"1240":2,"1525":1}}],["filterwarnings",{"2":{"21":1,"27":1,"34":1,"38":1,"54":1,"67":1,"77":1,"87":1,"99":1,"107":1,"112":1,"120":1,"126":1,"136":1,"141":1,"146":1,"172":2,"208":2,"216":1,"224":1,"234":1,"242":1,"261":1,"271":1,"318":1,"324":1,"329":1,"340":1,"350":1,"357":1,"367":1,"374":1,"381":1,"385":1,"395":1,"404":1,"413":1,"422":1,"429":1,"441":1,"461":1,"472":1,"480":1,"487":1,"494":1,"501":1,"507":1,"523":1,"528":1,"533":1,"543":1,"557":1,"564":1,"572":1,"581":1,"589":1,"598":1,"615":1,"622":1,"629":1,"666":1,"673":1,"685":1,"691":1,"698":1,"712":1,"718":1,"725":1,"733":1,"747":1,"760":1,"771":1,"789":1,"795":1,"819":1,"825":1,"833":1,"847":1,"857":1,"861":1,"871":1,"877":1,"887":1,"899":1,"912":1,"931":1,"938":1,"945":1,"954":1,"974":1,"989":1,"1006":1,"1013":1,"1017":1,"1026":1}}],["fill=false",{"2":{"858":1}}],["fill",{"2":{"592":1}}],["filled",{"2":{"409":8}}],["fillna",{"2":{"209":1,"409":4,"1012":1}}],["filename",{"2":{"890":2,"1328":1,"1333":2,"1336":1,"1337":1}}],["file",{"2":{"213":1,"441":10,"667":2,"692":2,"718":2,"890":5,"1011":3}}],["files",{"2":{"0":1,"441":6}}],["futurestud",{"2":{"1314":1}}],["fused",{"2":{"809":1}}],["fun∣deep",{"2":{"316":1}}],["fun",{"2":{"316":1}}],["functools",{"2":{"1240":1}}],["functionval",{"2":{"1109":1,"1111":1}}],["function修饰符",{"2":{"1021":1}}],["function脚本化后",{"2":{"820":1}}],["function简单地转换模型",{"2":{"819":1}}],["function更常被用作函数装饰器",{"2":{"819":1}}],["function重新启用这个功能",{"2":{"819":1}}],["function进行访问",{"2":{"818":1}}],["functionclasses",{"2":{"500":1}}],["functionclasses右侧的嵌套函数",{"2":{"500":1}}],["functionclasses的左边",{"2":{"500":1}}],["functionclasses所示",{"2":{"500":1}}],["functional模块中定义",{"2":{"423":2}}],["functional",{"2":{"235":1,"236":1,"242":1,"324":2,"329":2,"368":4,"388":2,"391":2,"413":2,"422":2,"441":2,"487":2,"501":2,"543":1,"557":1,"673":2,"765":2,"833":2,"861":2,"866":2,"908":2,"946":2,"954":2}}],["function",{"2":{"41":1,"162":1,"232":1,"234":1,"236":1,"283":1,"286":3,"367":2,"472":1,"500":3,"504":2,"557":1,"559":3,"611":1,"641":1,"819":2,"820":1,"980":1,"982":1,"1021":1,"1048":1,"1055":1,"1064":1,"1065":1,"1066":1,"1092":1,"1107":2,"1109":1,"1110":1,"1115":2,"1120":1,"1152":1,"1398":1,"1401":1,"1402":1,"1407":1,"1413":1,"1420":1,"1427":1,"1430":1,"1433":2,"1451":3,"1454":3,"1455":3,"1456":3,"1457":3,"1459":3,"1460":1,"1462":1,"1463":3,"1464":4,"1465":5,"1466":5,"1467":2,"1468":2,"1470":1,"1471":3,"1495":1,"1497":1,"1499":1,"1501":1,"1503":1,"1520":1}}],["functions中的",{"2":{"381":1}}],["functions中常用的激活函数及其衍生函数",{"2":{"103":1}}],["functions",{"2":{"39":1,"234":1,"367":1,"379":1,"1092":1,"1121":1}}],["func中的所有语句都执行完毕",{"2":{"816":1}}],["func中被重复调用",{"2":{"816":1}}],["func函数求值时",{"2":{"816":1}}],["func",{"2":{"41":6,"816":2,"817":4,"1244":2}}],["fullname",{"2":{"1460":4}}],["full可以简化为",{"2":{"785":1}}],["fully",{"2":{"591":1,"618":1,"861":1}}],["full所示",{"2":{"488":1}}],["full",{"2":{"5":1,"9":1,"77":4,"488":1,"785":1,"851":9}}],["f",{"2":{"26":1,"27":6,"41":6,"42":1,"44":10,"45":3,"46":8,"52":2,"54":32,"55":4,"56":4,"57":25,"59":12,"60":4,"67":6,"68":4,"77":8,"78":4,"80":4,"81":4,"87":10,"88":2,"93":1,"99":4,"101":5,"102":2,"103":3,"108":2,"113":9,"114":4,"115":6,"129":4,"137":16,"190":3,"191":3,"192":2,"206":6,"211":4,"212":4,"213":2,"270":1,"324":2,"325":2,"329":2,"330":4,"332":2,"335":4,"350":12,"351":1,"361":3,"367":1,"376":4,"386":12,"387":1,"388":3,"389":1,"392":4,"399":1,"409":4,"413":2,"414":2,"422":2,"423":2,"425":3,"433":2,"441":2,"442":2,"446":5,"479":2,"487":14,"500":2,"501":6,"521":6,"543":1,"545":2,"558":8,"559":16,"565":2,"576":8,"578":4,"583":1,"595":10,"605":10,"615":4,"616":2,"667":2,"673":2,"674":31,"692":2,"708":1,"718":2,"726":12,"734":2,"744":4,"748":2,"750":1,"757":3,"762":4,"765":2,"767":6,"768":3,"772":4,"773":3,"774":1,"796":1,"816":3,"817":2,"820":1,"821":4,"827":1,"828":6,"833":2,"834":14,"837":8,"861":2,"865":2,"883":15,"890":2,"893":3,"894":15,"906":12,"908":9,"932":9,"945":12,"954":2,"959":18,"963":9,"964":2,"966":1,"977":8,"981":21,"1000":3,"1011":6,"1018":1,"1036":5,"1088":1,"1146":3,"1147":1,"1244":1,"1252":2,"1277":1,"1336":1,"1392":2}}],["v3",{"2":{"1315":3,"1437":1}}],["v是一个类似这样的向量",{"2":{"1145":1}}],["v是一个行向量",{"2":{"1088":1}}],["v是另一个向量",{"2":{"1145":1}}],["v+1",{"2":{"1090":1}}],["v都是正数",{"2":{"1090":1}}],["v中",{"2":{"1089":1}}],["v中缩放的",{"2":{"397":1}}],["v=",{"2":{"1089":1,"1154":1}}],["vw=∑g∈gwzg",{"2":{"756":1}}],["vb=∑j=1nvb",{"2":{"676":1}}],["vb",{"2":{"659":1,"676":1}}],["void",{"2":{"1404":1,"1405":1,"1412":1,"1416":4,"1417":3,"1422":5,"1432":1}}],["voc函数来下载并读取pascal",{"2":{"949":1}}],["voctrainval",{"2":{"945":1}}],["vocsegdataset",{"2":{"864":2,"947":3,"948":2,"949":6}}],["vocdevkit",{"2":{"864":1,"866":3,"945":3,"949":3}}],["voc2012语义分割数据集",{"2":{"949":1}}],["voc2012数据集中的类别索引",{"2":{"945":1}}],["voc2012数据集的类数",{"2":{"862":1}}],["voc2012之后",{"2":{"945":1}}],["voc2012",{"0":{"945":1},"1":{"946":1,"947":1,"948":1,"949":1},"2":{"864":2,"866":6,"945":5,"949":6,"950":1}}],["voc",{"2":{"864":6,"866":11,"945":37,"946":6,"947":18,"948":7,"949":12}}],["vocab=none",{"2":{"668":3,"687":3}}],["vocabulary",{"2":{"363":1}}],["vocab",{"2":{"318":12,"321":2,"324":4,"325":28,"326":15,"329":2,"330":6,"331":8,"332":24,"333":18,"335":16,"363":5,"364":6,"375":24,"376":9,"407":8,"408":12,"409":24,"523":17,"528":13,"529":1,"543":4,"544":8,"546":12,"547":11,"557":4,"558":8,"560":12,"561":11,"567":3,"568":7,"569":10,"573":13,"574":20,"575":4,"576":13,"577":32,"578":4,"668":21,"669":8,"677":6,"679":4,"680":6,"682":10,"686":27,"687":18,"693":4,"695":21,"698":3,"702":12,"703":3,"704":2,"712":3,"713":7,"714":1,"715":8,"720":1,"721":6,"722":26,"725":3,"726":16,"727":3,"734":12,"736":12,"738":9,"760":3,"766":4,"768":6,"772":4,"773":5,"775":4,"777":19}}],["volume",{"0":{"1386":1},"2":{"1345":1}}],["volatile",{"2":{"813":2}}],["volta",{"2":{"802":1,"812":1,"814":1}}],["vollgraf",{"2":{"581":1}}],["vo1+",{"2":{"785":3}}],["vgg中所介绍的",{"2":{"920":1}}],["vgg中所示",{"2":{"508":1}}],["vgg19",{"2":{"920":3}}],["vgg的计算要慢得多",{"2":{"511":1}}],["vgg的几个vgg块",{"2":{"508":1}}],["vgg神经网络连接",{"2":{"508":1}}],["vgg网络使用了5个卷积块",{"2":{"920":1}}],["vgg网络可以分为两部分",{"2":{"508":1}}],["vgg网络",{"0":{"508":1}}],["vgg块",{"0":{"507":1}}],["vgg时相似",{"2":{"496":1}}],["vgg",{"0":{"506":1},"1":{"507":1,"508":1,"509":1,"510":1,"511":1},"2":{"492":2,"506":1,"507":4,"508":13,"509":2,"510":1,"957":1}}],["vgg和nin的模型参数大小与googlenet进行比较",{"2":{"491":1}}],["v∈rn×v",{"2":{"370":1}}],["v仅有一个输出",{"2":{"369":4}}],["vm",{"2":{"367":2,"1346":1,"1353":1}}],["vscode",{"2":{"1304":1}}],["vs",{"2":{"259":2,"1112":2,"1132":1,"1182":1,"1191":1}}],["v被称为卷积核",{"2":{"155":1}}],["v被称为动量",{"2":{"86":1}}],["v和u实际上不依赖于",{"2":{"154":1}}],["venv",{"0":{"1270":1},"1":{"1271":1,"1272":1,"1273":1},"2":{"1264":1,"1272":1,"1273":4,"1294":2}}],["vehicle",{"2":{"1127":1}}],["vecs",{"2":{"748":2,"751":4}}],["vec",{"2":{"748":9,"750":1,"751":1,"990":1,"998":1}}],["vectors",{"2":{"731":1,"1072":1}}],["vectorization",{"2":{"644":1,"1093":1,"1191":1}}],["vectorization中",{"2":{"232":1}}],["vector",{"2":{"135":1,"454":1,"807":1,"998":1,"1017":1,"1074":1,"1080":1,"1142":1,"1143":1,"1158":1,"1193":1}}],["version",{"2":{"1047":2,"1048":2,"1315":1,"1443":2}}],["very",{"2":{"518":1}}],["verify=true",{"2":{"206":1}}],["vert",{"2":{"136":1}}],["vert一致",{"2":{"136":1}}],["verbose=0",{"2":{"67":2,"137":2}}],["vit",{"2":{"1543":1}}],["vitest",{"2":{"1444":1}}],["vite构建对比图如下",{"2":{"1444":1}}],["vite的优势如下",{"2":{"1444":1}}],["vitejs",{"2":{"1444":1}}],["vite",{"0":{"1444":1},"2":{"1443":1,"1444":3,"1454":4,"1527":1,"1528":1,"1530":2}}],["vitepress",{"2":{"0":2,"6":1,"7":1,"12":1,"1529":1,"1531":1}}],["view",{"2":{"1479":1}}],["views文件夹",{"2":{"1475":1}}],["virtualenv",{"0":{"1270":1},"1":{"1271":1,"1272":1,"1273":1},"2":{"1272":2}}],["virus",{"2":{"660":2}}],["vi",{"2":{"744":3,"1018":1}}],["vinyals",{"2":{"572":2}}],["vincent",{"2":{"341":1}}],["visin",{"2":{"967":1}}],["visible",{"2":{"582":6}}],["vision",{"2":{"581":1,"582":4,"583":1,"584":3,"861":1,"862":1,"871":1,"872":12,"873":2,"874":3,"877":1,"879":3,"880":3,"881":3,"882":7,"887":1,"891":9,"892":1,"899":1,"903":12,"904":1,"905":1,"918":1,"920":1,"931":1,"932":1,"938":1,"945":3,"946":3,"947":1,"954":1}}],["visualization",{"2":{"1157":1}}],["visual",{"2":{"455":1,"506":1}}],["visa和万事达卡",{"2":{"301":1}}],["vi∈rv",{"2":{"367":2}}],["vial",{"2":{"115":1}}],["v0",{"2":{"95":2}}],["v2",{"2":{"88":5,"862":1,"873":2,"874":1,"905":1}}],["v2有条目vi2",{"2":{"27":1}}],["v100",{"2":{"812":1}}],["v100系列加速卡",{"2":{"802":1}}],["v1",{"2":{"88":5,"367":2,"660":2,"692":1,"718":1,"1315":4,"1335":3,"1389":1,"1390":1,"1391":1}}],["vtxt",{"2":{"95":2}}],["vt+1xt+1",{"2":{"95":1}}],["vt←βvt−1+gt",{"2":{"88":1}}],["vt←β1vt−1+",{"2":{"33":1}}],["vt=βvt−1+λzt−1zt=zt−1−η",{"2":{"94":1}}],["vt=βvt−1+gt",{"2":{"86":1}}],["vt=β2vt−2+βgt−1",{"2":{"86":1}}],["va=",{"2":{"848":1}}],["va=∑i=1mva",{"2":{"676":1}}],["vaswani",{"2":{"380":1,"395":1,"398":1,"403":1}}],["va",{"2":{"376":2,"409":2,"578":2,"675":2,"676":1}}],["vapnik和chervonenkis",{"2":{"253":1}}],["varepsilon",{"2":{"1124":3}}],["var=variance",{"2":{"472":1}}],["var",{"2":{"247":1,"472":47,"1020":7,"1036":2,"1367":1,"1370":1,"1371":1}}],["variation",{"2":{"924":1}}],["variance",{"2":{"169":1,"472":13,"1132":2,"1133":1}}],["variables是tensorflow中的可变容器",{"2":{"1021":1}}],["variables=false",{"2":{"129":1}}],["variables",{"0":{"1079":1},"1":{"1080":1,"1081":1,"1082":1,"1083":1,"1084":1,"1085":1,"1086":1},"2":{"81":1,"210":1,"278":3,"332":2,"335":1,"350":1,"392":2,"576":2,"595":2,"635":1,"1081":1,"1193":1}}],["variable",{"0":{"1062":1},"1":{"1063":1,"1064":1,"1065":1,"1066":1,"1067":1,"1068":1,"1069":1,"1070":1},"2":{"21":4,"28":2,"34":4,"77":3,"80":2,"91":2,"108":2,"126":1,"128":1,"146":1,"217":4,"232":2,"235":1,"242":1,"273":2,"331":5,"338":1,"350":1,"351":2,"391":1,"472":3,"544":5,"558":3,"601":2,"615":1,"630":2,"974":1,"977":1,"989":1,"1020":2,"1021":1,"1028":1,"1106":1,"1193":1}}],["val=max",{"2":{"1090":1}}],["val",{"2":{"436":3,"932":12,"945":3,"1090":1,"1252":1,"1460":4}}],["value事件",{"2":{"1500":1}}],["value作为props传给detail组件",{"2":{"1483":2}}],["value是响应式的",{"2":{"1455":2}}],["valueerror",{"2":{"1250":1}}],["value的形状",{"2":{"392":4}}],["value=0",{"2":{"575":3}}],["value=tf",{"2":{"391":1}}],["value=",{"2":{"368":4,"575":4,"1500":4}}],["value",{"2":{"210":1,"334":1,"356":1,"382":5,"407":12,"408":15,"409":9,"431":1,"435":1,"436":2,"472":2,"575":4,"604":1,"680":1,"686":2,"703":2,"714":1,"726":1,"734":4,"738":4,"821":1,"844":3,"863":2,"926":1,"1047":1,"1091":1,"1159":1,"1407":2,"1432":2,"1455":8,"1457":3,"1458":2,"1459":3,"1460":7,"1462":1,"1463":3,"1467":8,"1468":5,"1470":1,"1471":2,"1491":5,"1494":1,"1497":3,"1499":7,"1500":5,"1501":3,"1503":3,"1520":2}}],["values=none",{"2":{"848":1}}],["values的小批量",{"2":{"369":3}}],["values的小批量数据集中",{"2":{"369":1}}],["values的形状为",{"2":{"391":4}}],["values的形状",{"2":{"369":4,"370":4,"382":4,"392":4}}],["values",{"2":{"137":1,"209":3,"334":1,"369":16,"370":12,"382":20,"390":8,"391":8,"392":16,"408":20,"409":4,"424":3,"773":1,"827":1,"848":1,"890":2,"1013":2}}],["valid和reorg",{"2":{"890":1}}],["valid中的验证集",{"2":{"890":1}}],["valid函数来",{"2":{"890":1}}],["validation",{"2":{"256":2,"613":1,"932":3,"1131":3,"1132":1}}],["valid",{"2":{"142":1,"147":2,"148":1,"211":12,"212":2,"368":36,"369":16,"370":16,"375":20,"382":28,"396":4,"407":26,"408":39,"495":1,"568":2,"569":8,"575":20,"576":20,"577":12,"687":30,"688":6,"722":20,"726":16,"727":6,"734":6,"738":6,"890":19,"892":29,"894":30,"895":3,"896":6,"901":1,"902":5,"904":29,"906":30,"907":3,"908":9}}],["vanhoucke",{"2":{"491":3}}],["van",{"2":{"454":1,"455":1,"478":1,"485":1,"538":1,"572":2,"937":1,"1296":1}}],["vanishing",{"2":{"103":2,"241":1}}],["vandenberghe",{"2":{"62":1}}],["v",{"0":{"1500":1},"2":{"34":40,"35":24,"91":28,"153":3,"154":6,"155":2,"158":4,"241":1,"369":8,"370":1,"381":3,"382":8,"675":14,"676":24,"677":12,"680":1,"721":4,"757":2,"763":12,"1018":1,"1061":1,"1089":6,"1090":9,"1092":6,"1154":1,"1159":1,"1160":1,"1324":1,"1330":1,"1404":1,"1441":1,"1456":1,"1457":1,"1460":2,"1469":1,"1471":2,"1479":1,"1490":1,"1500":7,"1501":2,"1506":1,"1507":2,"1508":3,"1522":1,"1523":2,"1525":9}}],["v^t=vt1−β1t",{"2":{"33":1}}],["vuex",{"2":{"1530":1}}],["vuex换成了pinia",{"2":{"1496":1}}],["vueuse",{"2":{"1527":1,"1528":1}}],["vue父组件中",{"2":{"1506":1,"1507":1,"1508":1}}],["vue代码如下",{"2":{"1474":1}}],["vue组件实例在创建时要经历一系列的初始化步骤",{"2":{"1470":1}}],["vue中代码",{"2":{"1469":2}}],["vue中要使用defineexpose暴露内容",{"2":{"1468":1}}],["vuesetupextend",{"2":{"1454":2}}],["vue2的生命周期",{"2":{"1470":1}}],["vue2的api设计是options",{"2":{"1447":1}}],["vue2",{"2":{"1453":1}}],["vue3新组件",{"0":{"1521":1},"1":{"1522":1,"1523":1,"1524":1,"1525":1}}],["vue3组件通信和vue2的区别",{"2":{"1496":1}}],["vue3中要使用vue",{"2":{"1474":1}}],["vue3中的watch只能监视以下四种数据",{"2":{"1461":1}}],["vue3写法",{"2":{"1470":1}}],["vue3的生命周期",{"2":{"1470":1}}],["vue3的api设计是composition",{"2":{"1447":1}}],["vue3核心语法",{"0":{"1446":1},"1":{"1447":1,"1448":1,"1449":1,"1450":1,"1451":1,"1452":1,"1453":1,"1454":1,"1455":1,"1456":1,"1457":1,"1458":1,"1459":1,"1460":1,"1461":1,"1462":1,"1463":1,"1464":1,"1465":1,"1466":1,"1467":1,"1468":1,"1469":1,"1470":1,"1471":1}}],["vue3向下兼容vue2语法",{"2":{"1445":1}}],["vue3",{"2":{"1444":2}}],["vue3可以更好的支持typescript",{"2":{"1440":1}}],["vue3简介",{"0":{"1437":1},"1":{"1438":1,"1439":1,"1440":1,"1441":1}}],["vuejs",{"2":{"1437":1}}],["vue",{"0":{"1443":1,"1526":1,"1528":1},"1":{"1527":1,"1528":1,"1529":1,"1530":1,"1531":1},"2":{"0":1,"12":1,"1437":1,"1443":9,"1444":3,"1445":1,"1451":1,"1454":3,"1455":2,"1456":2,"1457":2,"1459":2,"1460":2,"1462":2,"1463":2,"1464":2,"1465":2,"1466":2,"1467":2,"1468":7,"1469":5,"1470":2,"1471":4,"1474":6,"1477":1,"1478":1,"1479":3,"1481":2,"1482":2,"1484":1,"1485":1,"1489":2,"1490":2,"1492":1,"1495":1,"1497":5,"1499":1,"1500":6,"1501":6,"1503":5,"1508":1,"1518":2,"1520":1,"1523":3,"1526":3,"1527":4,"1528":5,"1530":2,"1531":7,"1538":1,"1543":1}}],["m`",{"2":{"1422":1}}],["mj代表用户",{"2":{"1187":1}}],["m还是1",{"2":{"1179":1}}],["m−1",{"2":{"1179":2}}],["m为训练样本数",{"2":{"1148":1}}],["m为样本个数",{"2":{"1086":1}}],["m这个版本的公式",{"2":{"1179":1}}],["m这个文件",{"2":{"1094":1}}],["m这一项",{"2":{"1143":2}}],["m项",{"2":{"1143":1}}],["m∗",{"2":{"1080":1}}],["m×m",{"2":{"1077":1}}],["m×n",{"2":{"1077":1}}],["m×n矩阵乘以n×o矩阵",{"2":{"1075":1}}],["m×n的矩阵乘以n×1的向量",{"2":{"1074":1}}],["m=47",{"2":{"1064":1}}],["m代表了训练样本的数量",{"2":{"1064":1}}],["mkv",{"2":{"1058":1,"1059":1,"1060":1,"1061":1,"1063":1,"1064":1,"1065":1,"1066":1,"1067":1,"1068":1,"1069":1,"1070":1,"1072":1,"1073":1,"1074":1,"1075":1,"1076":1,"1077":1,"1080":1,"1081":1,"1082":1,"1083":1,"1084":1,"1085":1,"1086":1,"1088":1,"1089":1,"1090":1,"1091":1,"1092":1,"1093":1,"1094":1,"1097":1,"1098":1,"1099":1,"1100":1,"1101":1,"1102":1,"1103":1,"1106":1,"1107":1,"1108":1,"1109":1,"1110":1,"1111":1,"1112":1,"1114":1,"1115":1,"1116":1,"1117":1,"1120":1,"1121":1,"1122":1,"1123":1,"1124":1,"1125":1,"1126":1,"1127":1,"1129":1,"1130":1,"1131":1,"1132":1,"1133":1,"1134":1,"1135":1,"1137":1,"1138":1,"1139":1,"1140":1,"1141":1,"1143":1,"1144":1,"1145":1,"1146":1,"1147":1,"1148":1,"1150":1,"1151":1,"1152":1,"1153":1,"1154":1,"1156":1,"1157":1,"1158":1,"1159":1,"1160":1,"1161":1,"1162":1,"1164":1,"1165":1,"1166":1,"1167":1,"1168":1,"1169":1,"1171":1,"1172":1,"1173":1,"1174":1,"1176":1,"1178":1,"1179":1,"1180":1,"1181":1,"1182":1,"1183":1,"1184":1,"1185":1,"1187":1,"1188":1,"1189":1,"1190":1,"1191":1,"1192":1}}],["mkx将有较高概率与m的特征向量v1在一条直线上",{"2":{"314":1}}],["m的重数分别为2",{"2":{"742":1}}],["mp",{"2":{"687":7}}],["mplot3d",{"2":{"38":4,"99":4}}],["mpl",{"2":{"38":4,"99":4}}],["mutate",{"2":{"1494":2}}],["mutually",{"2":{"1027":1}}],["mutex",{"2":{"813":1}}],["mu",{"2":{"616":10,"1184":1}}],["mult设置为零",{"2":{"278":1}}],["mult",{"2":{"278":2,"813":1,"873":1}}],["multinomial",{"2":{"1006":1,"1026":22}}],["multivariate",{"2":{"982":1,"1184":1,"1185":1}}],["multiscale",{"2":{"886":1,"911":1,"912":1,"913":2,"915":1,"953":1}}],["multistep",{"2":{"351":14}}],["multistepdecay",{"2":{"71":1}}],["multisteplr",{"2":{"71":1}}],["multibox",{"2":{"848":6,"852":3,"853":3,"854":6,"912":3,"959":3,"963":3,"964":3}}],["multimachine",{"2":{"843":1}}],["multimachine说明了分布式并行训练是如何发生的",{"2":{"843":1}}],["multips",{"2":{"843":2}}],["multiprocessing",{"2":{"685":3,"687":3}}],["multiplication",{"2":{"999":1,"1032":1,"1073":1,"1074":1,"1075":1,"1076":1}}],["multipliers",{"2":{"48":1}}],["multiple",{"0":{"1079":1},"1":{"1080":1,"1081":1,"1082":1,"1083":1,"1084":1,"1085":1,"1086":1},"2":{"809":1,"824":2,"1080":1,"1081":1,"1193":1}}],["multiply",{"2":{"129":1,"809":1,"1109":2,"1117":2,"1401":1}}],["multiheadattention",{"2":{"382":11,"396":4,"407":4,"408":8}}],["multihead",{"2":{"379":1,"380":2,"404":1}}],["multiclass",{"2":{"291":1,"1103":1,"1112":1}}],["multilayer",{"2":{"231":1}}],["multifactorscheduler",{"2":{"71":3}}],["multi",{"2":{"57":1,"120":6,"121":3,"122":4,"292":1,"298":1,"379":1,"380":2,"404":1,"681":4,"688":1,"699":3,"825":2,"826":1,"827":1,"828":1,"831":2,"841":1,"883":1,"1371":1}}],["mt",{"2":{"534":1,"568":1}}],["mcpserver",{"2":{"1048":2}}],["mcp",{"0":{"1039":1,"1040":1,"1041":1},"1":{"1040":1,"1041":2,"1042":2,"1043":1,"1044":1,"1045":1,"1046":1,"1047":1,"1048":1},"2":{"1040":5,"1041":2,"1042":9,"1043":2,"1044":3,"1047":2,"1048":4}}],["mccann",{"2":{"731":1}}],["mcculloch",{"2":{"300":1}}],["mceliece",{"2":{"519":1}}],["m个",{"2":{"367":1}}],["myobj",{"2":{"1512":1}}],["myomit",{"2":{"1434":2}}],["myvar",{"2":{"1511":1}}],["myarray",{"2":{"1421":1}}],["myapp",{"2":{"1389":1,"1390":2,"1391":1}}],["myenv",{"2":{"1277":2}}],["myerror",{"2":{"1249":2}}],["mycontext",{"2":{"1252":2}}],["mysearch2",{"2":{"1420":1}}],["mysearch",{"2":{"1420":1}}],["mysequential的用法与之前为sequential类编写的代码相同",{"2":{"424":1}}],["mysequential",{"2":{"424":8}}],["mysql",{"0":{"1205":1},"2":{"1194":1,"1196":2,"1199":1,"1205":5,"1211":2}}],["mypick",{"2":{"1434":2}}],["mypy",{"2":{"1259":1}}],["myplot",{"2":{"1091":2}}],["mypress是一个使用vue和vitepress构建的简单博客应用程序",{"2":{"10":1}}],["mypress",{"0":{"10":1},"1":{"11":1,"12":1,"13":1,"14":1,"15":1,"16":1,"17":1,"18":1},"2":{"13":1}}],["mydict2",{"2":{"441":8}}],["mydict",{"2":{"441":15,"1421":1}}],["mydense",{"2":{"414":8}}],["myinit",{"2":{"436":3}}],["mylinear",{"2":{"414":7}}],["my",{"2":{"320":2,"321":1,"436":4,"821":9,"1257":3,"1371":1,"1389":2,"1390":1,"1391":1,"1392":3}}],["mnih",{"2":{"356":1}}],["mnist那样的小数据集",{"2":{"930":1}}],["mnist训练数据集上训练模型",{"2":{"869":1}}],["mnist是一个服装分类数据集",{"2":{"585":1}}],["mnist函数的图像大小调整功能",{"2":{"584":1}}],["mnist函数",{"2":{"584":1}}],["mnist函数中的resize参数执行此调整",{"2":{"462":1}}],["mnist由10个类别的图像组成",{"2":{"582":1}}],["mnist来训练模型",{"2":{"496":1}}],["mnist图像的分辨率",{"2":{"462":1}}],["mnist图像分类数据集",{"2":{"216":1}}],["mnist的输出为10",{"2":{"497":1}}],["mnist的一个问题是",{"2":{"462":1}}],["mnist的深度网络",{"2":{"31":1}}],["mnist中包含的10个类别",{"2":{"582":1}}],["mnist中定义的",{"2":{"321":1}}],["mnist中的每个图像由",{"2":{"217":1}}],["mnist中引入的fashion",{"2":{"173":1,"629":1}}],["mnist上的训练短小精悍",{"2":{"488":1}}],["mnist上的训练",{"2":{"111":1}}],["mnist",{"2":{"67":4,"137":1,"175":4,"216":2,"225":1,"321":1,"461":4,"462":1,"473":2,"483":1,"489":1,"496":1,"503":1,"509":1,"581":1,"582":23,"583":4,"584":21,"622":1,"629":1,"636":2,"828":3,"837":3,"882":2}}],["mnist数据集中对象的位置和大小已被规范化",{"2":{"882":1}}],["mnist数据集中的服装图片",{"2":{"135":1}}],["mnist数据集的文本标签",{"2":{"582":1}}],["mnist数据集下载并读取到内存中",{"2":{"582":1}}],["mnist数据集图像的高度和宽度从224改为96",{"2":{"511":1}}],["mnist数据集来训练我们的模型",{"2":{"489":1}}],["mnist数据集来说可能太复杂了",{"2":{"465":1}}],["mnist数据集上会发生什么",{"2":{"837":1}}],["mnist数据集上训练resnet",{"2":{"503":1}}],["mnist数据集上训练网络",{"2":{"473":1}}],["mnist数据集上的表现",{"2":{"137":1}}],["mnist数据集上的训练有何影响",{"2":{"68":1}}],["mnist数据集做实验时已经观察到了这种过拟合现象",{"2":{"251":1}}],["mnist数据集",{"2":{"67":1,"173":1,"178":1,"462":1,"509":1,"581":2,"584":6,"622":1,"629":1,"869":1,"882":1}}],["mn+ϵ1",{"2":{"316":1}}],["mb",{"2":{"300":2,"1346":1}}],["mf",{"2":{"300":2}}],["mlm的前向推断返回encoded",{"2":{"736":1}}],["mlm中描述的可能的词元替换之后",{"2":{"721":1}}],["mlm中定义遮蔽语言模型任务之后",{"2":{"721":1}}],["mlm",{"2":{"686":2,"721":23,"722":62,"725":1,"726":75,"736":39,"738":19}}],["ml",{"2":{"281":1,"282":2,"304":1,"1094":2}}],["mlp所述",{"2":{"332":1}}],["mlp提到过",{"2":{"242":1}}],["mlp中介绍的",{"2":{"540":1}}],["mlp中介绍的多层感知机模型",{"2":{"338":1}}],["mlp中描述了多层感知机",{"2":{"216":1}}],["mlp中带有1个隐藏层和5个隐藏单元的多层感知机",{"2":{"171":1}}],["mlp",{"2":{"135":1,"204":3,"216":2,"224":1,"228":1,"231":2,"369":1,"405":1,"422":1,"423":7,"424":1,"442":22,"674":6,"675":3,"676":3,"736":10,"821":9}}],["mm",{"2":{"77":2,"78":2,"243":2,"332":6,"425":2,"790":6,"796":1,"834":4,"999":2}}],["mvcc",{"2":{"1200":1}}],["mvapich2",{"2":{"813":1}}],["mvb",{"2":{"675":1}}],["mv",{"2":{"77":2,"750":2,"768":2,"998":3}}],["mime",{"2":{"1364":1,"1365":1}}],["mitt",{"0":{"1499":1},"2":{"1499":4}}],["mitchell的机器学习的定义",{"2":{"1059":1}}],["mitchell提出",{"2":{"1059":1}}],["mitliagkas",{"2":{"795":1}}],["mispredict",{"2":{"813":1}}],["mikolov",{"2":{"773":1,"775":1,"782":2,"788":1}}],["mirhoseini",{"2":{"832":1}}],["mirroredstrategy的范围",{"2":{"502":1}}],["mirroredstrategy",{"2":{"451":1}}],["mirrors",{"2":{"445":1}}],["mirza",{"2":{"300":1}}],["milestones=",{"2":{"71":2}}],["minx",{"2":{"1189":1}}],["minθ",{"2":{"1188":2,"1190":1}}],["minθc∑i=1m",{"2":{"1144":1,"1147":1}}],["minθ12m",{"2":{"1115":1}}],["min=0",{"2":{"849":3}}],["min会是什么样子",{"2":{"655":1}}],["min中的加权经验风险最小化中",{"2":{"192":1}}],["min中的这一项为经验风险",{"2":{"190":1}}],["min中最小化经验风险",{"2":{"190":1}}],["minval=0",{"2":{"172":1}}],["min",{"2":{"54":2,"99":4,"190":1,"191":3,"263":4,"334":1,"363":2,"567":1,"569":2,"578":2,"600":2,"668":3,"693":1,"695":3,"722":3,"772":1,"774":1,"777":3,"849":1,"854":12,"1058":1,"1059":1,"1060":1,"1061":1,"1063":1,"1064":1,"1065":1,"1066":1,"1067":1,"1068":1,"1069":1,"1070":1,"1072":1,"1073":1,"1074":1,"1075":1,"1076":1,"1077":1,"1080":1,"1081":1,"1082":1,"1083":1,"1084":1,"1085":1,"1086":1,"1088":1,"1089":1,"1090":1,"1091":1,"1092":1,"1093":1,"1094":1,"1097":1,"1098":1,"1099":1,"1100":1,"1101":1,"1102":1,"1103":1,"1106":1,"1107":1,"1108":1,"1109":1,"1110":2,"1111":1,"1112":1,"1114":1,"1115":1,"1116":1,"1117":1,"1120":1,"1121":1,"1122":1,"1123":1,"1124":1,"1125":1,"1126":1,"1127":1,"1129":1,"1130":1,"1131":1,"1132":1,"1133":1,"1134":1,"1135":1,"1137":1,"1138":1,"1139":1,"1140":1,"1141":1,"1143":1,"1144":1,"1145":1,"1146":1,"1147":1,"1148":1,"1150":1,"1151":1,"1152":1,"1153":1,"1154":1,"1156":1,"1157":1,"1158":1,"1159":1,"1160":1,"1161":1,"1162":1,"1164":1,"1165":1,"1166":1,"1167":1,"1168":1,"1169":1,"1171":1,"1172":1,"1173":1,"1174":1,"1176":1,"1178":1,"1179":1,"1180":1,"1181":1,"1182":1,"1183":1,"1184":1,"1185":1,"1187":1,"1188":1,"1189":1,"1190":1,"1191":1,"1192":1,"1371":1}}],["minikube",{"2":{"1393":1}}],["mini",{"2":{"1166":1}}],["minimum",{"2":{"101":4,"849":2,"1067":2}}],["minimizef⁡1n∑i=1nβil",{"2":{"191":1}}],["minimizef⁡1n∑i=1nl",{"2":{"190":1}}],["minimize",{"2":{"47":1,"48":1}}],["mini2",{"2":{"80":2}}],["mini1",{"2":{"80":2}}],["minibatches",{"2":{"78":1}}],["minibatch",{"2":{"28":1,"32":1,"65":1,"66":1,"76":2,"613":1,"644":2,"763":1,"765":1,"776":1,"831":1}}],["ms",{"2":{"813":4}}],["mszoning",{"2":{"209":7}}],["mseloss计算平方误差时不带系数1",{"2":{"81":2,"350":2}}],["mseloss",{"2":{"81":2,"210":1,"263":2,"278":2,"350":2,"392":2,"593":2}}],["mse",{"2":{"68":1,"611":1}}],["msg",{"2":{"7":2,"1520":2}}],["meow",{"2":{"1416":1}}],["meows",{"2":{"1416":1}}],["medium",{"2":{"1407":1}}],["medicine",{"2":{"292":1}}],["me",{"2":{"1056":1}}],["message",{"2":{"1046":1,"1401":1,"1431":1,"1434":1,"1471":2}}],["mesh是一个大约有28000个标签的集合",{"2":{"292":1}}],["meshgrid",{"2":{"57":3,"102":2,"848":3}}],["merges",{"2":{"757":2}}],["merge",{"2":{"757":2,"1329":1}}],["merity",{"2":{"718":1}}],["merrienboer",{"2":{"538":1,"572":2}}],["measure",{"2":{"1154":1}}],["measures",{"2":{"894":9,"906":9}}],["meat",{"2":{"658":1}}],["means",{"2":{"1151":1}}],["meansquarederror计算平方误差时不带系数1",{"2":{"81":1,"350":1}}],["meansquarederror",{"2":{"81":1,"210":1,"263":1,"278":1,"350":1,"392":1,"593":1}}],["mean或average",{"2":{"995":1}}],["mean和moving",{"2":{"472":5}}],["mean=",{"2":{"947":2}}],["mean=rgb",{"2":{"919":2}}],["mean=mean",{"2":{"472":1}}],["mean=1",{"2":{"273":1}}],["mean=0",{"2":{"80":3,"217":2,"225":1,"278":2,"331":1,"435":3,"544":1,"558":1,"601":1,"623":1,"630":1,"828":1}}],["mean",{"2":{"79":4,"80":4,"81":2,"146":2,"209":1,"210":2,"278":1,"335":3,"387":4,"413":8,"472":78,"575":3,"595":1,"605":4,"616":3,"635":2,"726":5,"765":2,"865":4,"919":9,"922":3,"923":3,"924":2,"947":2,"962":4,"963":2,"995":8,"1012":1,"1151":1,"1192":1}}],["mechanical",{"2":{"456":1}}],["mechanism",{"2":{"379":1,"1019":1}}],["methos",{"2":{"1453":2}}],["methods",{"2":{"1445":1,"1448":2,"1490":1}}],["method",{"2":{"299":1,"980":1,"1045":1,"1047":1}}],["metadata",{"2":{"1389":1,"1390":2,"1391":1}}],["metamind",{"2":{"718":1}}],["metrics",{"2":{"137":5,"635":3,"1139":1}}],["metrics=",{"2":{"67":1,"137":1}}],["metric",{"2":{"67":18,"137":33,"263":12,"335":20,"576":28,"634":12,"635":24,"726":33,"767":21,"827":4,"883":33,"894":33,"906":21,"963":18}}],["memory",{"2":{"165":1,"538":1,"550":1,"551":1,"552":1,"554":1,"813":6,"832":1,"1052":1}}],["m",{"2":{"31":2,"81":6,"137":8,"176":3,"225":3,"241":2,"243":19,"300":1,"316":1,"341":2,"350":6,"376":2,"409":2,"435":25,"436":14,"576":6,"578":2,"623":6,"635":1,"674":1,"676":1,"702":3,"713":6,"717":1,"742":2,"757":2,"767":6,"828":3,"843":2,"848":1,"883":6,"932":1,"981":1,"992":1,"1063":1,"1077":1,"1092":1,"1110":1,"1120":2,"1121":2,"1134":1,"1143":3,"1147":5,"1150":1,"1151":2,"1152":2,"1153":1,"1154":2,"1165":1,"1166":1,"1178":2,"1180":1,"1184":2,"1185":1,"1273":1,"1328":1,"1335":1,"1336":1,"1422":1}}],["moldevalue",{"2":{"1500":1}}],["mosueenter等等",{"2":{"1498":1}}],["most",{"2":{"890":1}}],["mount",{"2":{"1474":1,"1489":1,"1524":1}}],["mounted",{"2":{"1470":1}}],["mousemove",{"2":{"1414":1}}],["mouseevent",{"2":{"1402":4}}],["move",{"2":{"1413":1,"1416":2}}],["movie",{"2":{"691":1,"704":2,"715":2,"736":7,"1191":1}}],["moving`",{"2":{"1416":1}}],["moving",{"2":{"472":75,"1089":1,"1416":1}}],["motivation",{"2":{"1156":1,"1157":1,"1178":1}}],["motorbike",{"2":{"945":1}}],["mobo",{"2":{"801":2}}],["mongos",{"2":{"1208":3,"1210":1}}],["mongodb",{"0":{"1194":1,"1205":1,"1210":1},"1":{"1195":1,"1196":1,"1197":1,"1198":1,"1199":1,"1200":1,"1201":1,"1202":1,"1203":1,"1204":1,"1205":1,"1206":1,"1207":1,"1208":1,"1209":1,"1210":1,"1211":1},"2":{"1194":2,"1195":1,"1196":2,"1197":1,"1198":1,"1199":1,"1201":1,"1202":1,"1203":1,"1205":5,"1206":1,"1207":1,"1210":2,"1211":2,"1543":1}}],["monitor",{"2":{"945":1}}],["moneycontext",{"2":{"1503":2}}],["money",{"2":{"754":1,"1503":8}}],["monomials",{"2":{"269":1}}],["moi",{"2":{"376":2,"409":2,"578":2}}],["mooij",{"2":{"349":1}}],["modal",{"2":{"1522":1}}],["modified",{"2":{"813":1}}],["modern",{"2":{"492":1,"550":1,"619":1,"663":1,"886":1}}],["mode",{"2":{"146":4,"945":2}}],["mode=",{"2":{"146":2,"582":2,"584":2,"882":2}}],["modelvalue",{"2":{"1500":2}}],["modelvalue=",{"2":{"1500":1}}],["modelvalue事件",{"2":{"1500":1}}],["model指令",{"2":{"1500":2}}],["model里面了",{"2":{"1496":1}}],["model=",{"2":{"1460":2,"1500":2}}],["modelcontextprotocol",{"2":{"1048":4}}],["model为例",{"2":{"917":1}}],["model用简单的例子阐述了基于卷积神经网络的风格迁移方法",{"2":{"917":1}}],["model的本质是下面这行代码",{"2":{"1500":1}}],["model的本质",{"2":{"1500":3}}],["model的运行情况",{"2":{"821":1}}],["model的语言模型",{"2":{"754":1}}],["modeling",{"0":{"736":1},"2":{"1064":1}}],["model函数中的参数设置",{"2":{"690":1}}],["model函数来",{"2":{"686":1}}],["model所示",{"2":{"347":1,"736":1}}],["model中语言模型的训练",{"2":{"572":1}}],["model中的",{"2":{"568":1}}],["model中的字符级词元化不同",{"2":{"566":1}}],["model中的语料库",{"2":{"564":1}}],["model中的语言模型",{"2":{"341":1}}],["model中",{"2":{"338":1}}],["model中介绍过的一样",{"2":{"329":1}}],["model中描述了仿射变换",{"2":{"229":1}}],["models",{"2":{"67":1,"68":1,"136":1,"176":1,"210":1,"225":1,"278":1,"296":1,"299":1,"305":1,"347":2,"414":1,"418":1,"422":2,"429":1,"435":3,"436":1,"437":1,"451":1,"461":1,"473":1,"474":1,"488":2,"494":1,"495":1,"502":1,"507":1,"508":2,"623":1,"686":2,"731":1,"862":2,"873":4,"874":2,"905":2,"920":2}}],["model",{"0":{"1039":1,"1500":1},"1":{"1040":1,"1041":1,"1042":1,"1043":1,"1044":1,"1045":1,"1046":1,"1047":1,"1048":1},"2":{"67":4,"68":3,"99":1,"170":1,"174":1,"196":1,"211":1,"251":1,"269":1,"282":1,"283":1,"315":2,"341":1,"347":1,"348":1,"408":1,"413":2,"414":1,"421":1,"422":2,"423":1,"424":1,"425":2,"439":1,"442":1,"487":1,"501":1,"519":1,"523":8,"528":5,"529":1,"535":1,"546":6,"547":10,"560":6,"561":10,"610":2,"643":2,"686":11,"731":1,"821":2,"862":1,"873":2,"874":1,"905":1,"917":1,"920":1,"1040":1,"1042":1,"1043":1,"1063":1,"1099":1,"1100":1,"1131":1,"1500":8,"1525":1}}],["module2",{"2":{"1258":1}}],["module1",{"2":{"1258":1}}],["modulelist",{"2":{"702":1}}],["modules字典中查找需要初始化参数的子块",{"2":{"424":1}}],["modules的主要优点是",{"2":{"424":1}}],["modules属性",{"2":{"424":1}}],["modules",{"2":{"424":5}}],["modules中",{"2":{"424":2}}],["module的类型是ordereddict",{"2":{"424":1}}],["module是module子类的一个实例",{"2":{"424":1}}],["module",{"2":{"67":2,"127":1,"137":1,"174":1,"325":1,"334":1,"335":2,"369":1,"370":1,"382":1,"391":1,"398":1,"405":1,"406":1,"407":2,"408":2,"413":1,"414":1,"423":1,"424":6,"425":2,"433":1,"442":1,"472":1,"480":1,"487":1,"501":1,"533":1,"534":1,"535":1,"634":1,"635":1,"674":1,"675":1,"676":1,"677":1,"688":1,"702":1,"713":1,"734":2,"736":1,"737":1,"738":1,"765":1,"821":1,"826":6,"862":2,"926":1,"959":1,"1257":3,"1444":1}}],["momentum=0",{"2":{"472":3,"474":4,"894":2,"906":2}}],["momentum小节一样",{"2":{"107":1}}],["momentum",{"2":{"65":1,"66":1,"84":1,"86":2,"88":4,"91":20,"92":5,"472":18,"894":2,"906":2}}],["momentum中我们添加了一种机制",{"2":{"32":1}}],["momentum中那样",{"2":{"26":1}}],["more",{"0":{"5":1,"9":1}}],["mxnet能够根据用户需要",{"2":{"822":1}}],["mxnet通过直接调用c++后端替代python解释器",{"2":{"821":1}}],["mxnet通过初始化权重参数的方法是",{"2":{"434":1}}],["mxnet阻止程序返回python",{"2":{"791":1}}],["mxnet程序的执行主要发生在c++实现的后端",{"2":{"790":1}}],["mxnet有一个用于与用户直接交互的前端",{"2":{"790":1}}],["mxnet和tensorflow之类则采用了一种异步编程",{"2":{"789":1}}],["mxnet命令",{"2":{"445":1}}],["mxnet的initializer模块提供了各种模型参数初始化方法",{"2":{"596":1}}],["mxnet的init模块提供了多种预置初始化方法",{"2":{"434":1}}],["mxnet的gluon",{"2":{"300":1}}],["mxnet使用特殊值",{"2":{"418":1}}],["mxnet所取代",{"2":{"300":1}}],["mxnet",{"2":{"21":2,"23":1,"27":2,"31":1,"34":2,"37":1,"38":2,"41":1,"52":1,"54":4,"57":2,"64":1,"67":3,"75":1,"77":3,"83":1,"87":2,"91":1,"97":1,"99":3,"101":1,"102":2,"103":1,"105":1,"107":2,"108":1,"111":1,"112":2,"113":1,"118":1,"120":3,"122":1,"124":1,"126":4,"128":1,"133":1,"136":3,"137":1,"139":1,"141":2,"144":1,"146":4,"147":2,"148":1,"150":1,"172":3,"178":1,"208":3,"215":1,"216":2,"223":1,"224":3,"227":1,"234":2,"239":1,"242":2,"250":1,"261":3,"263":1,"268":1,"271":3,"278":1,"280":1,"318":2,"321":1,"323":1,"324":3,"325":2,"328":1,"329":2,"332":1,"333":1,"335":2,"337":1,"340":3,"344":1,"350":5,"351":2,"353":1,"357":2,"359":1,"360":1,"366":1,"367":3,"372":1,"374":3,"376":1,"378":1,"381":3,"382":1,"384":1,"385":3,"394":1,"395":3,"396":1,"402":1,"404":3,"409":2,"411":1,"413":2,"414":1,"416":1,"418":4,"420":1,"422":3,"423":1,"424":1,"426":1,"428":1,"429":2,"431":1,"434":1,"436":2,"437":1,"439":1,"441":2,"444":1,"445":2,"446":3,"449":1,"453":1,"461":3,"465":1,"472":3,"473":1,"477":1,"480":3,"485":1,"487":3,"491":1,"494":3,"498":1,"501":3,"505":1,"507":4,"509":1,"511":1,"523":3,"525":1,"528":3,"531":1,"533":1,"537":1,"543":3,"546":1,"549":1,"557":3,"560":1,"563":1,"564":2,"571":1,"572":3,"578":1,"580":1,"581":2,"582":2,"586":1,"589":2,"591":2,"592":3,"593":1,"594":2,"596":1,"597":1,"598":2,"599":1,"600":1,"607":1,"615":3,"616":1,"621":1,"622":3,"628":1,"629":2,"631":3,"633":2,"634":1,"635":1,"638":1,"666":2,"671":1,"673":3,"679":1,"684":1,"685":3,"686":1,"690":1,"691":2,"697":1,"698":3,"699":1,"706":1,"712":3,"717":1,"718":2,"724":1,"725":3,"726":1,"729":1,"733":3,"740":1,"747":2,"753":1,"757":1,"759":1,"760":3,"765":1,"770":1,"771":2,"779":1,"789":3,"790":4,"791":2,"792":1,"793":1,"794":2,"795":3,"796":2,"797":1,"799":1,"818":1,"819":5,"820":2,"821":7,"822":1,"823":2,"825":3,"827":4,"829":1,"830":2,"833":2,"837":1,"839":1,"847":2,"848":1,"854":1,"856":1,"857":2,"860":1,"861":3,"864":1,"868":1,"871":3,"873":1,"876":1,"877":3,"882":1,"885":1,"887":3,"893":3,"897":1,"898":1,"899":3,"910":1,"912":2,"915":1,"918":3,"929":1,"931":2,"935":1,"938":1,"942":1,"945":2,"951":1,"954":3,"966":1,"967":3,"970":4,"972":1,"974":1,"979":1,"981":2,"986":1,"989":1,"998":1,"1004":1,"1005":1,"1006":1,"1009":1,"1013":1,"1015":1,"1017":4,"1018":1,"1020":3,"1021":3,"1022":1,"1024":1,"1026":2,"1038":1}}],["mastery",{"2":{"1531":1}}],["master",{"2":{"1375":1,"1381":1}}],["mask=none",{"2":{"765":2}}],["mask>",{"2":{"721":3,"722":3}}],["masklm和nextsentencepred来定义bertmodel类",{"2":{"738":1}}],["masklm和nextsentencepred中采用的多层感知机的参数不会更新",{"2":{"688":1}}],["masklm",{"2":{"736":9,"738":3}}],["masklm类和nextsentencepred类在其使用的多层感知机中都有一些参数",{"2":{"688":1}}],["masks令负类锚框和填充锚框不参与损失的计算",{"2":{"962":1}}],["masks",{"2":{"660":2,"776":4,"962":15,"963":9}}],["mask函数",{"2":{"575":1}}],["maskedsoftmaxceloss",{"2":{"575":11,"576":4}}],["masked",{"0":{"736":1},"2":{"368":11,"369":4,"370":4,"404":1,"721":5,"736":12}}],["mask",{"0":{"940":1},"2":{"157":1,"172":8,"368":4,"575":20,"633":2,"660":3,"722":1,"736":4,"765":8,"767":12,"852":24,"853":1,"936":1,"940":4,"941":1}}],["mask中所示",{"2":{"157":1}}],["macos",{"2":{"1273":1,"1302":1,"1312":1,"1315":1}}],["machine函数中",{"2":{"364":1}}],["machine",{"0":{"1136":1},"1":{"1137":1,"1138":1,"1139":1,"1140":1,"1141":1},"2":{"281":1,"318":1,"319":1,"321":3,"324":4,"329":2,"341":1,"361":4,"364":3,"368":1,"523":3,"528":3,"532":1,"543":4,"550":1,"557":4,"564":4,"572":2,"575":1,"693":1,"754":1,"1059":1,"1128":1,"1141":1,"1143":1,"1163":1,"1193":3}}],["machines",{"2":{"135":1,"454":1,"1142":1,"1193":1}}],["magnitude",{"2":{"1114":1}}],["magic",{"2":{"1090":3,"1091":1}}],["mae",{"2":{"963":15}}],["may",{"2":{"945":1}}],["male",{"2":{"751":1}}],["maas",{"2":{"712":1}}],["maaten",{"2":{"478":1,"485":1}}],["management",{"2":{"1444":1}}],["manager",{"2":{"1376":1,"1378":1,"1425":1}}],["manipulations",{"2":{"848":6}}],["manning",{"2":{"743":1,"744":1,"746":1}}],["man",{"2":{"658":1,"751":3,"757":2,"783":4,"785":3}}],["major=true",{"2":{"325":2,"375":1,"523":1,"528":1,"547":2,"561":2,"573":2,"574":1,"713":1}}],["maddison",{"2":{"300":1,"301":1}}],["makesound",{"2":{"1416":4}}],["makers",{"2":{"660":2}}],["make",{"2":{"213":1,"848":3}}],["makedirs",{"2":{"206":1,"890":1,"1011":1}}],["margin",{"2":{"1144":2,"1145":1}}],["marginal",{"2":{"1033":2}}],["marginalization",{"2":{"1033":1}}],["markraw",{"0":{"1517":1,"1519":1},"1":{"1518":1,"1519":1},"2":{"1518":3,"1519":3}}],["marketplace",{"2":{"1311":1}}],["markov",{"2":{"298":1,"348":2,"519":1}}],["markdown",{"0":{"6":1},"1":{"7":1,"8":1,"9":1},"2":{"6":1,"9":1}}],["martens",{"2":{"86":1}}],["maps",{"2":{"158":1}}],["map",{"0":{"1240":1},"2":{"80":1,"131":1,"584":2,"663":3,"672":2,"685":2,"687":3,"698":3,"712":2,"754":3,"851":12,"852":12,"1169":1,"1239":1,"1240":2,"1402":1}}],["maxiter",{"2":{"1109":1,"1111":1}}],["maximum",{"2":{"146":1,"218":3,"849":2,"854":1}}],["maximize",{"2":{"48":1}}],["maxlen",{"2":{"575":5}}],["maxval=5",{"2":{"386":1}}],["maxval=1",{"2":{"172":1}}],["maxpool2d",{"2":{"67":6,"147":12,"148":4,"461":12,"473":2,"474":2,"482":4,"487":4,"488":16,"495":12,"502":5,"507":4,"957":3}}],["maxdepth",{"2":{"65":1,"134":1,"204":1,"305":1,"379":1,"421":1,"492":1,"550":1,"587":1,"663":1,"754":1,"824":1,"886":1,"987":1}}],["max",{"2":{"54":4,"70":1,"72":9,"146":10,"218":1,"235":1,"262":4,"321":4,"351":20,"364":3,"398":12,"624":2,"655":2,"686":8,"687":31,"720":2,"721":1,"722":41,"725":6,"734":6,"738":6,"757":11,"760":6,"763":2,"774":3,"776":6,"777":6,"849":1,"851":21,"854":3,"890":1,"920":2,"1090":4,"1112":1,"1154":1,"1313":1}}],["matchlabels",{"2":{"1390":1}}],["matches",{"2":{"578":3}}],["matlab和octave",{"2":{"1109":1}}],["matlab文件",{"2":{"1089":1}}],["matlab的标识",{"2":{"1089":1}}],["matlabv=1",{"2":{"1088":1}}],["matlab功能要比octave强大的多",{"2":{"1088":1}}],["matlab",{"2":{"1077":1,"1088":1,"1089":1,"1093":1,"1111":1}}],["matvec",{"2":{"998":2}}],["mat",{"2":{"970":1,"972":1,"1089":5}}],["matrix",{"0":{"1313":1},"2":{"357":2,"992":5,"994":1,"998":2,"999":2,"1017":1,"1074":1,"1075":2,"1076":1,"1109":3,"1117":3,"1159":1,"1191":1,"1313":1,"1315":3}}],["matrices",{"2":{"357":6,"1072":1}}],["matmul",{"2":{"122":1,"219":2,"243":1,"332":3,"340":5,"369":1,"370":2,"388":4,"390":2,"391":1,"414":3,"425":1,"545":7,"559":9,"599":2,"602":1,"632":1,"796":1,"923":1,"970":4,"999":1}}],["mathematics",{"2":{"1145":1}}],["mathop",{"2":{"1112":1}}],["mathbf",{"2":{"334":3,"1000":3}}],["mathcal",{"2":{"262":1,"271":1}}],["math",{"2":{"21":3,"27":6,"28":2,"34":2,"35":4,"67":3,"72":2,"80":1,"107":4,"108":4,"112":4,"114":1,"210":2,"218":1,"261":4,"262":1,"329":4,"334":2,"335":4,"367":3,"370":4,"381":3,"395":3,"404":3,"407":4,"408":4,"425":1,"472":2,"572":4,"578":3,"615":4,"616":2,"633":1,"760":3,"765":2,"771":3,"773":1,"887":3,"890":1,"1235":2,"1417":1}}],["matplotlib",{"2":{"21":4,"27":4,"34":4,"38":4,"54":4,"67":4,"77":4,"87":4,"99":4,"107":1,"112":4,"208":4,"234":4,"242":4,"271":4,"329":4,"350":4,"581":4,"598":4,"615":4,"833":3,"847":3,"857":4,"861":3,"871":3,"877":3,"912":3,"918":3,"931":3,"945":3,"954":3,"981":10,"1026":4,"1297":1}}],["main",{"2":{"0":1,"1048":2,"1315":4,"1322":1,"1325":3,"1330":2,"1334":2,"1337":2,"1474":2,"1489":1}}],["mdiag−12",{"2":{"31":1}}],["md```js",{"2":{"7":1}}],["md",{"2":{"0":2,"8":1}}],["igor",{"2":{"1359":1}}],["ignore",{"2":{"21":1,"27":1,"34":1,"38":1,"54":1,"67":1,"77":1,"87":1,"99":1,"107":1,"112":1,"120":1,"126":1,"136":1,"141":1,"146":1,"172":2,"208":2,"216":1,"224":1,"234":1,"242":1,"261":1,"271":1,"318":1,"324":1,"329":1,"340":1,"350":1,"357":1,"367":1,"374":1,"381":1,"385":1,"395":1,"404":1,"413":1,"422":1,"429":1,"441":1,"461":1,"472":1,"480":1,"487":1,"494":1,"501":1,"507":1,"523":1,"528":1,"533":1,"543":1,"557":1,"564":1,"572":1,"581":1,"589":1,"598":1,"615":1,"622":1,"629":1,"666":1,"673":1,"685":1,"691":1,"698":1,"712":1,"718":1,"725":1,"733":1,"747":1,"760":1,"771":1,"789":1,"795":1,"819":1,"825":1,"833":1,"847":1,"857":1,"861":1,"871":1,"877":1,"883":1,"887":1,"899":1,"912":1,"931":1,"938":1,"945":1,"954":1,"974":1,"989":1,"1006":1,"1013":1,"1017":1,"1026":1}}],["i个训练样本在参数向量θ上的投影",{"2":{"1145":1}}],["i^2",{"2":{"1000":1}}],["i行j列的元素xij即向量xi和xj的内积",{"2":{"923":1}}],["ip",{"2":{"1362":2,"1368":1,"1384":2}}],["ip连接之间的差异",{"2":{"815":1}}],["ipython",{"2":{"629":4}}],["i9",{"2":{"812":1}}],["ice",{"2":{"744":5}}],["ichi",{"2":{"455":1}}],["iyyer",{"2":{"731":1}}],["i是指",{"2":{"675":1}}],["i≤j",{"2":{"660":1}}],["iou超过阈值",{"2":{"853":1}}],["ious",{"2":{"851":9}}],["iou函数将在这两个列表中计算它们成对的交并比",{"2":{"849":1}}],["iou所示",{"2":{"849":1}}],["iou",{"0":{"849":1},"2":{"849":5,"851":10,"854":15,"855":1}}],["io",{"2":{"582":1,"583":1,"584":2,"590":2,"668":1,"669":2,"679":2,"687":3,"718":1,"722":2,"725":1,"777":2,"864":2,"874":2,"882":1,"892":3,"904":3,"932":4,"945":3,"947":1,"948":1,"949":2,"964":1,"1306":1,"1314":1}}],["ioffe",{"2":{"78":1,"466":1,"491":4}}],["i=ithoutputj",{"2":{"1120":1}}],["i=",{"2":{"1112":1}}],["i=get",{"2":{"959":3}}],["i=g",{"2":{"675":1}}],["i=0⇔f",{"2":{"1000":1}}],["i=0",{"2":{"446":4}}],["i=1",{"2":{"48":1,"314":1,"381":1,"674":1,"675":1,"676":1,"786":1,"841":1,"1110":3,"1120":1,"1160":2,"1165":1,"1166":1}}],["i从0开始",{"2":{"446":2}}],["iωj",{"2":{"400":4}}],["i100002j",{"2":{"398":2}}],["ils",{"2":{"532":1,"572":2}}],["ilyas",{"2":{"475":1}}],["ilya",{"2":{"455":1}}],["il",{"2":{"376":2,"409":2,"578":2}}],["iloc",{"2":{"208":3,"1012":2}}],["ih",{"2":{"375":1,"573":3,"574":3}}],["i>=tau",{"2":{"351":3}}],["id=",{"2":{"1467":1}}],["id>",{"2":{"1342":1,"1343":2,"1344":2}}],["ide",{"2":{"1042":1,"1436":1}}],["identification",{"2":{"899":1,"901":5}}],["identity",{"2":{"500":1,"504":1,"1430":4}}],["identically",{"2":{"284":1,"305":1}}],["ids=devices",{"2":{"726":1,"828":1,"883":1,"894":1,"906":1}}],["ids",{"2":{"687":36,"722":42,"727":6,"896":9,"908":6}}],["id",{"2":{"213":1,"854":30,"896":3,"908":3,"1021":20,"1045":1,"1046":1,"1315":1,"1333":1,"1337":1,"1410":1,"1412":3,"1419":4,"1428":5,"1431":1,"1432":4,"1434":3,"1435":1,"1456":4,"1457":4,"1469":6,"1479":1,"1481":2,"1482":2,"1483":1,"1490":4,"1495":1,"1506":1,"1507":1,"1508":5,"1518":4,"1519":4}}],["idx是np",{"2":{"736":3}}],["idx",{"2":{"211":3,"333":4,"363":14,"424":4,"634":2,"668":12,"680":3,"686":15,"687":15,"703":3,"714":1,"721":1,"722":24,"736":12,"748":22,"750":2,"751":2,"774":2,"851":27,"852":9,"854":18,"932":9,"945":6,"947":9,"959":6,"964":6}}],["i+δ",{"2":{"400":2}}],["i+t",{"2":{"351":6}}],["i+a",{"2":{"153":2,"154":2,"155":1,"156":1,"158":1}}],["i+1",{"2":{"129":4,"351":2,"757":1,"836":1,"958":2,"1092":1}}],["immediate等等",{"2":{"1463":1}}],["imresize",{"2":{"919":1,"964":1}}],["imread",{"2":{"848":3,"857":2,"863":1,"878":1,"912":3,"918":2,"932":1,"945":2,"964":1}}],["imdb函数中",{"2":{"695":1}}],["imdb",{"2":{"692":2,"695":9,"698":3,"712":3}}],["image函数",{"2":{"947":1}}],["imagereadmode",{"2":{"945":1}}],["imagefolder",{"2":{"872":2,"874":2,"892":2,"904":2}}],["imagefolderdataset",{"2":{"872":2,"892":1,"904":1}}],["imagesc",{"2":{"1091":1}}],["images函数定义为",{"2":{"945":1}}],["imagesets",{"2":{"945":4}}],["images",{"2":{"582":7,"636":1,"866":12,"872":1,"878":1,"882":8,"932":12,"933":3,"945":15,"946":3,"947":3,"1342":1,"1471":1}}],["imagenet",{"0":{"899":1},"1":{"900":1,"901":1,"902":1,"903":1,"904":1,"905":1,"906":1,"907":1,"908":1,"909":1,"910":1}}],["imagenet竞赛自2010年以来",{"2":{"492":1}}],["imagenet数据集中的图像比cifar",{"2":{"909":1}}],["imagenet数据集中的图像更高更宽",{"2":{"899":1}}],["imagenet数据集中有一个",{"2":{"876":1}}],["imagenet数据集由斯坦福教授李飞飞小组的研究人员开发",{"2":{"456":1}}],["imagenet数据集发布",{"2":{"456":1}}],["image",{"2":{"456":1,"461":1,"584":1,"587":1,"726":1,"847":1,"848":1,"857":2,"861":1,"863":9,"866":5,"877":2,"878":2,"883":2,"886":1,"887":1,"912":2,"918":6,"919":7,"920":12,"927":9,"931":1,"932":4,"944":1,"945":10,"946":2,"947":6,"951":1,"954":1,"964":5,"1342":1,"1389":1,"1390":1}}],["imshow",{"2":{"357":1,"582":5,"848":1,"853":1,"854":2,"857":2,"858":1,"863":6,"878":2,"912":3,"918":5,"927":3,"964":3}}],["implemented",{"2":{"1431":2}}],["implements",{"2":{"1422":2}}],["implementational",{"2":{"1192":1}}],["implementation",{"2":{"220":1,"624":1,"1123":1}}],["imperative",{"2":{"816":1}}],["import",{"2":{"0":1,"21":9,"27":13,"34":9,"38":16,"54":12,"67":18,"77":15,"87":9,"99":16,"107":13,"112":13,"120":9,"126":12,"136":12,"141":8,"146":11,"172":13,"206":5,"208":19,"216":11,"224":12,"234":9,"242":9,"261":19,"271":12,"318":13,"324":14,"329":17,"340":9,"350":12,"357":9,"360":11,"367":14,"374":12,"381":15,"385":12,"395":16,"404":20,"413":10,"418":3,"422":10,"429":8,"441":11,"446":7,"461":12,"472":12,"480":12,"487":14,"494":12,"501":14,"507":12,"523":10,"528":10,"533":5,"543":13,"557":13,"564":13,"572":19,"581":15,"589":13,"591":3,"592":1,"594":1,"598":13,"615":20,"622":12,"629":13,"666":15,"673":12,"685":19,"691":12,"698":10,"712":10,"717":1,"718":13,"725":9,"733":10,"747":12,"757":2,"760":13,"771":16,"789":13,"795":8,"819":15,"825":10,"833":11,"847":8,"857":9,"861":14,"864":1,"871":15,"877":12,"887":26,"899":15,"912":7,"918":11,"931":15,"938":6,"945":12,"954":14,"967":9,"974":5,"981":13,"989":5,"1006":5,"1011":2,"1013":5,"1017":5,"1026":15,"1048":4,"1235":1,"1240":1,"1454":1,"1455":1,"1456":1,"1457":1,"1459":1,"1460":1,"1462":1,"1463":1,"1464":1,"1465":1,"1466":1,"1467":1,"1468":4,"1469":5,"1470":1,"1471":4,"1474":4,"1489":2,"1490":5,"1492":2,"1493":1,"1495":3,"1497":3,"1499":2,"1501":3,"1503":3,"1508":1}}],["img=feature",{"2":{"946":1}}],["imgs",{"2":{"582":6,"866":15,"872":8,"874":2,"933":5,"945":10,"946":15,"947":6}}],["img",{"2":{"136":2,"141":1,"142":1,"152":1,"582":10,"848":9,"853":1,"854":2,"857":6,"858":1,"863":23,"866":6,"878":8,"879":9,"880":9,"881":3,"912":12,"918":15,"919":26,"920":6,"926":16,"932":9,"945":4,"946":4,"947":18,"964":18,"1471":1}}],["i−a",{"2":{"156":3}}],["i−ηλ",{"2":{"94":1}}],["i−λ",{"2":{"94":1}}],["ij是锚框i和真实边界框j的iou",{"2":{"851":3}}],["ij中最小化损失函数将使预测的条件分布接近全局语料库统计中的条件分布",{"2":{"742":1}}],["ij中",{"2":{"742":1}}],["ij可以重写为",{"2":{"742":1}}],["ij=exp⁡",{"2":{"631":1}}],["ij",{"2":{"57":1,"742":2,"848":1,"992":2,"1000":1,"1121":6}}],["ifp",{"2":{"1178":1}}],["ifj=0",{"2":{"1121":1}}],["ifj≠0",{"2":{"1121":1}}],["if语句",{"0":{"1092":1},"2":{"1092":1}}],["if",{"0":{"1223":1},"2":{"57":2,"67":8,"71":1,"72":2,"80":4,"81":6,"114":1,"129":4,"137":13,"146":2,"172":8,"174":8,"176":1,"206":5,"210":4,"211":2,"225":2,"263":4,"275":4,"278":4,"321":1,"325":4,"334":10,"335":15,"350":2,"357":3,"362":1,"363":7,"364":1,"368":8,"382":4,"408":8,"424":1,"435":8,"436":2,"446":8,"472":12,"482":4,"501":8,"502":4,"565":1,"566":2,"568":1,"575":1,"576":7,"577":8,"578":1,"582":5,"583":1,"584":4,"590":1,"597":1,"623":2,"634":5,"635":15,"667":4,"668":3,"674":4,"682":6,"687":3,"692":2,"702":2,"713":7,"715":3,"718":1,"720":2,"721":4,"726":3,"734":1,"738":3,"748":1,"757":2,"767":5,"773":2,"774":1,"775":2,"826":3,"828":2,"848":3,"854":4,"863":3,"874":4,"883":7,"889":1,"890":2,"893":3,"894":13,"901":1,"902":1,"906":15,"920":2,"927":4,"932":9,"945":3,"947":3,"959":3,"964":6,"966":3,"977":4,"981":7,"1092":5,"1193":1,"1215":1,"1223":2,"1315":1,"1432":1,"1462":1,"1467":3,"1491":2,"1525":1}}],["ii",{"2":{"52":1,"652":1,"1066":1,"1083":1,"1100":1,"1102":1,"1147":1,"1157":1,"1160":2,"1193":3}}],["i∈",{"2":{"47":1}}],["izmailov",{"2":{"38":1,"66":1}}],["i",{"2":{"25":5,"52":1,"54":2,"57":4,"59":1,"67":9,"77":20,"116":2,"122":3,"126":8,"129":8,"137":12,"141":2,"145":2,"146":19,"153":14,"154":6,"155":4,"156":2,"158":2,"211":6,"243":4,"253":2,"262":3,"268":1,"270":7,"271":2,"284":2,"305":2,"320":3,"321":15,"333":8,"334":2,"350":9,"351":53,"357":2,"362":2,"363":3,"376":4,"399":3,"407":14,"408":54,"409":12,"418":2,"433":6,"446":22,"480":4,"482":8,"502":8,"525":2,"558":8,"559":16,"565":3,"566":4,"578":12,"582":8,"595":1,"600":6,"604":4,"605":2,"609":4,"610":2,"611":10,"613":8,"615":12,"616":4,"633":2,"635":3,"646":8,"652":1,"657":2,"667":2,"676":2,"687":2,"699":8,"702":3,"720":3,"721":2,"722":6,"732":2,"734":4,"750":8,"757":6,"767":12,"768":9,"774":4,"775":7,"797":3,"820":8,"826":6,"828":9,"835":25,"836":2,"837":17,"848":4,"851":6,"852":6,"854":23,"866":9,"872":4,"882":4,"883":12,"893":2,"894":12,"906":12,"908":6,"920":8,"924":1,"945":9,"958":4,"959":66,"964":6,"966":8,"968":4,"981":1,"992":1,"1000":1,"1026":12,"1063":2,"1064":2,"1065":1,"1069":12,"1076":2,"1077":6,"1080":5,"1081":13,"1082":1,"1086":2,"1092":18,"1093":1,"1099":2,"1101":1,"1109":78,"1110":18,"1112":7,"1115":4,"1116":11,"1117":10,"1120":8,"1121":3,"1122":1,"1130":3,"1131":6,"1132":4,"1144":7,"1145":22,"1146":1,"1147":4,"1151":3,"1152":5,"1154":9,"1156":1,"1159":7,"1160":6,"1161":2,"1165":7,"1166":1,"1176":3,"1178":1,"1179":2,"1180":2,"1184":3,"1185":3,"1187":4,"1188":20,"1189":24,"1190":8,"1191":6,"1192":1,"1193":3,"1225":2,"1296":2,"1334":1,"1454":1,"1499":1}}],["isshow",{"2":{"1522":2}}],["isstring",{"2":{"1409":3}}],["isstudent",{"2":{"1398":1}}],["isreactive",{"2":{"1518":5}}],["isloading",{"2":{"1471":1}}],["istrue",{"2":{"1414":1}}],["isactive",{"2":{"1401":1}}],["iso",{"2":{"1029":1}}],["isola",{"2":{"300":1}}],["is∣deep",{"2":{"316":1}}],["isinstance",{"2":{"137":4,"325":2,"334":4,"335":9,"363":3,"424":1,"634":2,"635":8,"713":3,"848":1,"883":2,"981":1}}],["is",{"2":{"8":10,"67":1,"68":4,"79":4,"174":6,"210":4,"211":1,"263":4,"271":1,"316":2,"335":4,"342":6,"350":1,"363":2,"368":4,"382":4,"408":5,"449":3,"472":7,"501":1,"582":2,"590":5,"635":3,"658":6,"659":1,"660":1,"667":4,"668":3,"682":2,"692":3,"695":3,"704":2,"715":2,"720":5,"722":12,"724":2,"727":3,"731":1,"734":1,"736":7,"738":3,"813":2,"848":1,"882":3,"894":9,"906":9,"932":24,"945":6,"947":6,"981":2,"1056":1,"1059":1,"1168":1,"1399":1,"1416":2}}],["inject",{"0":{"1503":1},"2":{"1503":3}}],["inpt",{"2":{"1468":1}}],["input表明bert输入序列的嵌入是词元嵌入",{"2":{"734":1}}],["input=",{"2":{"1500":3}}],["input=h2",{"2":{"834":1}}],["input=h1",{"2":{"834":2}}],["input=x",{"2":{"834":1}}],["input=128",{"2":{"726":1}}],["input=256",{"2":{"686":2}}],["inputschema",{"2":{"1048":1}}],["inputspec用于描述模型输入的签名信息",{"2":{"820":1}}],["inputspec",{"2":{"819":1,"820":1}}],["inputs=768",{"2":{"736":2}}],["inputs来将特殊的",{"2":{"722":1}}],["inputs函数以小批量接受多个输入",{"2":{"681":1}}],["inputs的形状是",{"2":{"713":3}}],["inputs的形状",{"2":{"332":4}}],["inputs的向量",{"2":{"219":1}}],["inputs",{"2":{"127":2,"173":3,"174":15,"217":8,"219":4,"271":2,"273":4,"278":3,"325":8,"331":8,"332":8,"356":1,"388":8,"392":8,"413":3,"425":4,"442":2,"472":5,"523":4,"528":4,"544":8,"545":8,"547":4,"558":8,"559":8,"561":4,"630":8,"674":8,"675":4,"676":4,"677":12,"681":2,"688":7,"702":9,"713":6,"722":6,"736":2,"737":4,"765":3,"865":4,"954":4,"955":4,"1012":8,"1013":4}}],["input",{"2":{"7":1,"8":1,"174":2,"263":5,"278":1,"282":1,"333":12,"405":4,"407":8,"408":8,"409":6,"472":3,"473":1,"474":1,"480":10,"481":6,"501":6,"502":4,"552":1,"576":8,"623":1,"687":1,"713":1,"721":5,"727":1,"734":8,"738":4,"762":2,"766":2,"819":1,"820":1,"836":2,"863":3,"1099":3,"1232":1,"1233":1,"1460":2,"1468":1,"1500":4}}],["ingress",{"2":{"1372":1}}],["innodb",{"2":{"1199":1,"1205":1}}],["innertext",{"2":{"1467":1,"1468":3}}],["inner",{"2":{"1081":2}}],["instructs",{"2":{"813":1}}],["instruction",{"2":{"809":1}}],["instantaneous",{"2":{"981":1}}],["instance",{"2":{"284":1,"609":1,"944":1}}],["install",{"2":{"13":1,"208":4,"445":2,"717":1,"724":1,"1011":1,"1235":1,"1269":1,"1272":1,"1273":1,"1277":1,"1280":1,"1281":2,"1284":2,"1285":1,"1288":1,"1289":1,"1292":1,"1293":1,"1294":2,"1315":1,"1443":1,"1489":1}}],["insist",{"2":{"660":1}}],["insert",{"2":{"584":3}}],["incrementodd",{"2":{"1491":1}}],["increment",{"2":{"1471":5,"1491":1,"1493":1}}],["increase",{"2":{"72":2}}],["includes",{"2":{"1420":1}}],["include",{"2":{"1313":1,"1364":1}}],["inconclusive",{"2":{"660":1}}],["inception中的inception块与残差块之间的主要区别是什么",{"2":{"505":1}}],["inception所示",{"2":{"487":1}}],["inception",{"2":{"487":10,"488":38}}],["inception块相当于一个有4条路径的子网络",{"2":{"490":1}}],["inception块的组合从vgg继承",{"2":{"488":1}}],["inception块之间的最大汇聚层可降低维度",{"2":{"488":1}}],["inception块由四条并行路径组成",{"2":{"487":1}}],["inception块",{"0":{"487":1}}],["invalid",{"2":{"1433":1}}],["invariance",{"2":{"152":2}}],["inverse",{"2":{"854":4,"1077":1}}],["inverse函数",{"2":{"854":1}}],["inv",{"2":{"472":4,"1085":1,"1086":1}}],["ind=2",{"2":{"1090":1}}],["ind",{"2":{"1090":1}}],["inds",{"2":{"854":6}}],["indices函数将rgb值映射到在pascal",{"2":{"945":1}}],["indices包含子序列的随机起始索引",{"2":{"320":1}}],["indices",{"2":{"320":6,"363":4,"600":9,"748":2,"750":1,"768":1,"774":3,"851":6,"852":12,"945":4,"947":3,"1092":2}}],["independent",{"2":{"1034":1}}],["independently",{"2":{"284":1,"305":1}}],["independence",{"2":{"1034":1}}],["index=0",{"2":{"796":1}}],["index=false",{"2":{"213":1,"896":3}}],["indexedslices",{"2":{"334":1}}],["index",{"2":{"209":1,"363":2,"777":8,"796":1,"932":3,"1048":1,"1151":1,"1198":1,"1319":1,"1364":3,"1367":2,"1370":2,"1421":1,"1432":4,"1444":1,"1471":2,"1474":1}}],["indexing=",{"2":{"57":1,"848":1}}],["inf或nan",{"2":{"624":1}}],["inference",{"2":{"614":1,"663":3,"664":1,"665":1,"666":1,"672":2,"679":2,"685":3}}],["inf",{"2":{"210":4,"236":2,"624":1}}],["information",{"2":{"649":1}}],["info",{"2":{"8":4,"342":1,"649":1,"854":6,"1230":1,"1254":1,"1392":1}}],["in中的值相对应的输入张量x和核张量k",{"2":{"120":1}}],["in中",{"2":{"120":1}}],["intuitions",{"2":{"1101":1,"1102":1}}],["intuition",{"2":{"1065":1,"1066":1,"1068":1,"1122":1,"1144":1}}],["int8和int4操作",{"2":{"814":1}}],["into",{"2":{"665":1,"836":2}}],["int32",{"2":{"568":1,"569":2,"575":1,"577":3,"584":1,"687":2,"722":4,"768":3,"851":3,"852":3,"854":2,"866":2,"896":2,"938":1,"945":3}}],["intra",{"2":{"395":1}}],["introduction",{"2":{"281":1,"1057":1,"1150":1,"1193":1}}],["intro",{"2":{"65":1,"300":2,"445":1}}],["int64",{"2":{"375":1,"407":1,"573":1,"575":1,"577":2,"687":2,"722":5,"763":2,"851":3,"852":1,"854":2,"945":1,"964":1}}],["int",{"2":{"333":4,"578":1,"582":1,"750":4,"751":1,"757":1,"854":1,"896":1,"1022":4,"1216":1,"1232":1,"1259":3}}],["integral",{"2":{"980":1}}],["interface",{"2":{"1350":1,"1394":1,"1421":1,"1422":1,"1423":3,"1431":2,"1433":1,"1469":1}}],["inters",{"2":{"849":9}}],["inters的形状",{"2":{"849":3}}],["intersection",{"0":{"1408":1},"2":{"849":1,"1148":1}}],["intersect",{"2":{"40":2}}],["interpreted",{"2":{"816":1}}],["interpolation",{"2":{"345":1,"863":1,"940":1}}],["intercept",{"2":{"610":1}}],["internal",{"2":{"475":1}}],["inter",{"2":{"409":9,"849":30}}],["interleave",{"2":{"368":2,"382":2,"387":2,"388":2,"391":1,"736":2,"848":1}}],["intel的xeon每个芯片有48个通道",{"2":{"812":1}}],["intel的openvino就是使用这些处理器来获得可观的吞吐量",{"2":{"809":1}}],["intelligence",{"2":{"619":1}}],["intel",{"2":{"300":4,"773":1,"813":3}}],["inequality中i=t",{"2":{"115":1}}],["inequality",{"2":{"42":2}}],["initvalue",{"2":{"1520":3}}],["inits",{"2":{"926":3,"927":3}}],["inits函数",{"2":{"926":1}}],["init函数来应用到net",{"2":{"436":2}}],["init模块提供了多种预置初始化方法",{"2":{"434":1}}],["initialvalue",{"2":{"1511":1}}],["initialtheta=zeros",{"2":{"1111":1}}],["initialtheta",{"2":{"1109":2,"1111":1}}],["initialization",{"2":{"417":1,"1125":1,"1153":1}}],["initialized",{"2":{"827":1}}],["initialize函数允许我们在所选设备上初始化参数",{"2":{"827":1}}],["initializers",{"2":{"435":3,"436":1,"472":4,"592":1,"623":1}}],["initializers模块中提供了各种初始化方法",{"2":{"434":1}}],["initializer模块提供了多种预置初始化方法",{"2":{"434":1}}],["initializer=weight",{"2":{"623":1}}],["initializer=none",{"2":{"592":1}}],["initializer=nn",{"2":{"472":2,"573":2,"574":3}}],["initializer=myinit",{"2":{"436":1}}],["initializer=",{"2":{"325":1,"547":1,"561":1,"592":1}}],["initializer=paddle",{"2":{"176":1,"225":1,"278":2,"734":1,"968":1}}],["initializer=initializer",{"2":{"127":2,"592":1}}],["initializer=tf",{"2":{"81":1,"414":2,"435":6,"472":4}}],["initializer",{"2":{"81":2,"127":2,"137":1,"176":1,"225":1,"278":2,"350":1,"414":2,"435":7,"436":3,"472":2,"573":2,"574":3,"592":4,"623":3,"702":1,"713":2,"734":1,"767":1,"828":1,"873":1,"883":1,"968":1}}],["initialize",{"2":{"67":2,"81":1,"129":1,"136":1,"137":1,"141":1,"176":1,"210":1,"225":1,"263":1,"278":1,"325":1,"326":1,"335":1,"350":1,"369":1,"370":1,"375":2,"382":1,"392":1,"396":1,"398":1,"405":1,"406":3,"407":2,"408":1,"413":1,"414":2,"418":1,"422":1,"423":1,"424":1,"425":2,"429":1,"433":1,"435":4,"436":1,"437":1,"442":1,"451":1,"461":1,"480":1,"481":1,"488":1,"495":1,"501":2,"502":1,"508":1,"573":1,"574":1,"576":1,"592":1,"623":1,"680":1,"688":1,"702":1,"713":1,"726":1,"734":1,"736":1,"737":1,"762":1,"767":1,"819":1,"821":1,"827":1,"828":1,"863":3,"873":1,"874":1,"883":1,"893":1,"905":1,"926":1,"956":1,"959":1,"961":1,"968":1,"969":4}}],["initial",{"2":{"320":7,"325":2,"391":1}}],["init=init",{"2":{"67":2,"137":1,"335":1,"435":4,"472":2,"827":1,"828":1,"863":1,"874":1,"883":1,"893":1,"961":1}}],["init",{"0":{"1258":1},"2":{"21":5,"28":5,"34":5,"35":4,"67":1,"68":1,"70":1,"71":1,"72":1,"77":1,"81":6,"91":4,"108":4,"127":9,"136":1,"137":6,"172":1,"174":6,"176":4,"204":1,"208":1,"224":1,"225":4,"271":1,"273":4,"275":4,"278":1,"321":1,"325":8,"332":28,"335":3,"350":7,"363":1,"369":8,"370":8,"375":18,"382":8,"391":8,"398":8,"405":8,"406":8,"407":16,"408":20,"413":8,"414":8,"417":1,"421":1,"423":12,"424":8,"425":16,"429":1,"435":20,"436":11,"442":8,"472":9,"480":10,"481":2,"487":8,"501":8,"502":2,"533":8,"534":12,"535":12,"545":5,"546":3,"559":4,"560":3,"572":1,"573":8,"574":16,"575":2,"576":5,"577":4,"592":2,"615":1,"622":1,"623":6,"634":1,"635":2,"668":3,"673":1,"674":6,"675":6,"676":6,"677":6,"680":1,"687":3,"688":6,"698":1,"702":14,"712":1,"713":13,"722":3,"725":1,"726":1,"734":6,"736":6,"737":6,"738":6,"748":1,"765":4,"767":5,"775":1,"777":2,"820":1,"821":2,"825":1,"828":5,"861":1,"863":2,"871":1,"873":2,"877":1,"883":5,"887":1,"893":2,"899":1,"905":1,"918":1,"926":7,"932":3,"947":3,"954":1,"959":6,"967":1,"968":1,"969":2,"1255":1,"1258":1,"1285":1,"1289":1,"1293":1,"1294":3,"1327":1}}],["inline",{"2":{"21":4,"27":4,"34":4,"38":4,"54":4,"67":4,"77":4,"87":4,"99":4,"107":1,"112":4,"208":4,"234":4,"242":4,"271":4,"329":4,"350":4,"581":4,"598":4,"615":4,"833":3,"847":3,"857":4,"861":3,"871":3,"877":3,"912":3,"918":3,"931":3,"945":3,"954":3,"981":13,"1026":4}}],["in",{"2":{"0":1,"6":1,"21":7,"28":4,"34":4,"35":4,"41":2,"54":6,"57":2,"59":1,"67":9,"68":1,"70":1,"71":5,"72":2,"73":2,"77":20,"78":8,"80":12,"81":8,"89":1,"91":4,"95":1,"107":1,"108":4,"120":6,"121":4,"122":4,"126":4,"129":4,"136":4,"137":15,"141":2,"146":4,"173":1,"206":3,"210":10,"211":2,"217":1,"225":1,"243":4,"262":2,"263":7,"275":8,"278":9,"284":1,"295":1,"318":7,"320":4,"321":4,"331":3,"332":5,"333":12,"334":12,"335":13,"342":2,"350":10,"351":12,"357":2,"361":1,"362":3,"363":8,"364":2,"375":5,"376":3,"392":4,"398":5,"399":1,"407":9,"408":12,"409":22,"414":10,"418":2,"424":8,"432":2,"433":4,"436":2,"446":4,"449":3,"461":4,"472":3,"480":9,"482":16,"487":10,"488":4,"494":4,"495":4,"502":9,"507":10,"508":14,"509":2,"544":3,"545":4,"558":3,"559":4,"565":2,"566":4,"568":3,"569":1,"573":2,"574":1,"576":15,"577":4,"578":5,"582":4,"583":1,"584":1,"595":8,"600":3,"604":4,"605":8,"615":3,"616":4,"633":1,"634":4,"635":9,"636":2,"667":11,"668":3,"669":1,"679":1,"681":1,"686":9,"687":19,"692":3,"693":2,"694":3,"695":6,"699":5,"702":9,"713":4,"717":1,"718":1,"720":1,"721":6,"722":19,"725":1,"726":11,"734":6,"738":12,"748":4,"750":4,"757":7,"767":10,"768":3,"772":1,"773":8,"774":5,"775":4,"776":3,"777":5,"790":9,"792":2,"796":3,"797":3,"813":2,"820":8,"826":11,"827":3,"828":14,"835":16,"836":1,"837":26,"848":31,"851":3,"852":3,"854":4,"862":1,"863":9,"864":1,"866":4,"872":2,"873":1,"874":5,"876":2,"878":1,"882":2,"883":17,"890":5,"892":8,"893":1,"894":6,"896":4,"904":8,"905":9,"906":13,"908":10,"919":1,"920":5,"925":2,"926":3,"927":3,"932":3,"933":3,"945":10,"946":5,"947":7,"948":3,"956":3,"957":10,"958":3,"959":12,"963":8,"964":7,"966":8,"968":2,"981":2,"1026":4,"1082":1,"1083":1,"1122":1,"1127":1,"1221":2,"1225":1,"1230":1,"1242":1,"1243":1,"1247":1,"1296":1,"1393":1,"1410":2,"1425":2,"1434":2,"1435":4,"1456":1,"1457":1,"1469":1,"1471":1,"1479":1,"1490":1,"1506":1,"1507":1,"1508":1}}],["ith个样本包括中心词及其ni个上下文词和mi个噪声词",{"2":{"776":1}}],["it=σ",{"2":{"553":1}}],["items",{"2":{"363":2,"757":3,"1430":2,"1432":7}}],["item",{"2":{"113":2,"129":1,"210":2,"275":2,"278":2,"577":3,"791":2,"854":4,"1022":4,"1432":5,"1469":4,"1506":1,"1507":1}}],["iterationnumber",{"2":{"1167":1}}],["iterrows",{"2":{"932":3}}],["iter访问到的测试数据集对模型进行评估",{"2":{"635":1}}],["iter访问到的训练数据集上训练一个模型net",{"2":{"635":1}}],["iter可访问的数据集",{"2":{"634":1}}],["iter函数的行为会有什么变化",{"2":{"607":1}}],["iter函数的方式相同",{"2":{"590":1}}],["iter函数遍历整个数据集",{"2":{"605":1}}],["iter函数",{"2":{"600":1}}],["iter的方式与我们在",{"2":{"590":1}}],["iter中",{"2":{"330":1}}],["iter=true",{"2":{"329":1,"335":3}}],["iter=false",{"2":{"321":1,"335":4}}],["iter",{"2":{"21":6,"28":2,"29":4,"34":6,"35":8,"67":37,"68":8,"71":8,"72":8,"73":8,"79":8,"80":18,"81":24,"91":2,"92":4,"108":2,"109":4,"137":42,"175":16,"176":8,"210":8,"216":2,"221":9,"225":4,"263":26,"271":2,"275":12,"278":12,"320":2,"321":16,"324":4,"326":4,"329":3,"335":34,"350":17,"376":2,"409":8,"462":2,"463":2,"473":8,"474":2,"483":4,"489":4,"496":4,"503":4,"509":4,"523":6,"528":3,"529":1,"543":4,"546":3,"547":4,"557":4,"560":3,"561":4,"569":4,"576":10,"582":2,"583":5,"584":3,"590":3,"595":4,"600":3,"605":4,"622":2,"626":2,"629":2,"634":7,"635":14,"636":3,"669":15,"679":8,"681":6,"687":6,"688":8,"694":9,"695":12,"698":6,"704":6,"712":6,"715":6,"722":8,"725":4,"726":9,"760":3,"767":10,"777":8,"827":2,"828":12,"837":12,"864":8,"865":6,"866":3,"874":12,"883":27,"892":12,"894":24,"895":6,"896":6,"904":12,"905":6,"906":24,"907":6,"908":6,"932":15,"948":6,"949":12,"961":1,"963":6}}],["it",{"2":{"0":1,"342":6,"1126":1,"1343":1,"1344":1,"1392":1}}],["c非常大",{"2":{"1144":1}}],["c×a+b",{"2":{"1143":1}}],["c++数值线性代数库",{"2":{"1093":1}}],["c++",{"2":{"1093":1,"1111":1}}],["c矩阵",{"2":{"1089":1}}],["c等于3大于等于1",{"2":{"1088":1}}],["cf",{"2":{"981":1}}],["cv2",{"2":{"932":1,"945":2,"964":1}}],["cv",{"2":{"886":1}}],["cy",{"2":{"858":5}}],["cycles",{"2":{"813":10}}],["c语言有一个register关键字",{"2":{"810":1}}],["c语言和任何其他现代编程语言一样",{"2":{"233":1}}],["cc",{"2":{"748":1}}],["c=",{"2":{"1501":1}}],["c=1λ",{"2":{"1147":1}}],["c=1",{"2":{"1144":1}}],["c=100",{"2":{"743":1}}],["c=3",{"2":{"1091":1}}],["c=3然后按enter键",{"2":{"1091":1}}],["c=ab=",{"2":{"999":1}}],["c=q",{"2":{"573":1}}],["cbow所示",{"2":{"785":1}}],["cbow",{"0":{"785":1},"1":{"786":1},"2":{"707":1,"782":1,"785":4,"786":1}}],["c72329e68a732bef0452e4b96a1c341c8910f81f",{"2":{"686":1}}],["cm",{"2":{"1336":1}}],["cmp",{"2":{"634":5}}],["cmap=cmap",{"2":{"357":1}}],["cmap=",{"2":{"357":1,"399":4}}],["c~t=tanh",{"2":{"554":1}}],["c~t∈rn×h",{"2":{"554":1}}],["c∣c",{"2":{"515":1}}],["c4",{"2":{"487":8}}],["c4是每条路径的输出通道数",{"2":{"487":4}}],["c3",{"2":{"487":14}}],["c2",{"2":{"487":14,"1465":4,"1466":4}}],["c2050",{"2":{"300":1}}],["c1816da3821ae9f43899be655002f6c723e91b88",{"2":{"748":1}}],["c1",{"2":{"487":12,"1465":4,"1466":4}}],["c是一个常数",{"2":{"981":2}}],["c是某个在优化过程中没有更新的指定常量",{"2":{"425":1}}],["c是常数",{"2":{"318":1}}],["ceo",{"2":{"1471":1}}],["ceiling",{"2":{"1174":1}}],["ceil",{"2":{"1090":1}}],["certificate",{"2":{"1370":2}}],["cer",{"2":{"658":1}}],["centroid",{"2":{"1151":1}}],["centroids",{"2":{"1151":1}}],["central",{"2":{"457":1,"807":1}}],["centercrop",{"2":{"872":3,"903":3}}],["center和box",{"2":{"860":1}}],["center从两角表示法转换为中心宽度表示法",{"2":{"858":1}}],["centers",{"2":{"774":8,"776":4,"777":21}}],["center",{"2":{"763":6,"767":6,"774":2,"776":2,"848":14,"852":2,"854":2,"858":5,"860":1,"863":12,"1426":4}}],["centeredlayer",{"2":{"413":11}}],["ce",{"2":{"342":2}}],["cell",{"2":{"325":4,"547":2,"552":2,"554":1,"561":2}}],["cncf",{"2":{"1374":1}}],["cn2",{"2":{"1154":1}}],["cn212",{"2":{"1154":1}}],["cn",{"2":{"445":1,"1306":1,"1444":1}}],["cntk",{"2":{"300":1}}],["cnn特征图y",{"2":{"959":1}}],["cnn在faster",{"2":{"941":1}}],["cnn在现实世界中难以被广泛应用",{"2":{"937":1}}],["cnn将fast",{"2":{"941":1}}],["cnn将兴趣区域汇聚层替换为了",{"2":{"940":1}}],["cnn对r",{"2":{"941":1}}],["cnn对图像选取若干提议区域",{"2":{"941":1}}],["cnn修改而来的",{"2":{"940":1}}],["cnn是基于faster",{"2":{"940":1}}],["cnn所示",{"2":{"940":1}}],["cnn的基础上引入了一个全卷积网络",{"2":{"941":1}}],["cnn的一个主要改进",{"2":{"941":1}}],["cnn的目标函数不仅包括目标检测中的类别和边界框预测",{"2":{"939":1}}],["cnn的主要改进之一",{"2":{"938":1}}],["cnn的主要性能瓶颈在于",{"2":{"938":1}}],["cnn只将生成提议区域的方法从选择性搜索改为了区域提议网络",{"2":{"939":1}}],["cnn描述了faster",{"2":{"939":1}}],["cnn引入了兴趣区域汇聚层",{"2":{"938":1}}],["cnn用来提取特征的卷积神经网络的输入是整个图像",{"2":{"938":1}}],["cnn相比",{"2":{"938":1,"939":1}}],["cnn包括以下四个步骤",{"2":{"937":1}}],["cnn模型的一部分",{"2":{"939":1}}],["cnn模型通常需要在选择性搜索中生成大量的提议区域",{"2":{"939":1}}],["cnn模型通过预训练的卷积神经网络有效地抽取了图像特征",{"2":{"937":1}}],["cnn模型",{"2":{"937":1,"938":1,"939":1}}],["cnn展示了r",{"2":{"937":1}}],["cnn首先从输入图像中选取若干",{"2":{"937":1}}],["cnn及其一系列改进方法",{"2":{"936":1}}],["cnn或regions",{"2":{"936":1}}],["cnn和",{"2":{"886":1}}],["cnn中使用的选择性搜索替换为参与训练的区域提议网络",{"2":{"941":1}}],["cnn中提出的兴趣区域汇聚层与",{"2":{"938":1}}],["cnn中描述了fast",{"2":{"938":1}}],["cnn中唯一的区别在于架构的选择",{"2":{"698":1}}],["cnn中",{"2":{"698":1,"886":1}}],["cnn",{"0":{"936":1,"937":1,"938":1,"939":1,"940":1},"1":{"937":1,"938":1,"939":1,"940":1,"941":1,"942":1},"2":{"134":2,"138":1,"151":1,"159":1,"395":1,"397":6,"403":2,"492":1,"663":1,"698":2,"936":8,"937":1,"938":2,"939":2,"940":2}}],["cnn进行复习",{"2":{"67":1}}],["cra",{"2":{"1530":1}}],["crane",{"2":{"727":12,"731":3}}],["crt",{"2":{"1370":1}}],["cri",{"2":{"1350":2,"1377":1,"1394":2}}],["cron",{"2":{"1315":1}}],["crop",{"2":{"864":7,"866":15,"946":12,"947":21,"948":3,"949":9}}],["crossentropy",{"2":{"220":1}}],["crossentropyloss",{"2":{"67":2,"137":2,"175":2,"220":1,"225":2,"335":2,"575":2,"624":1,"681":2,"688":2,"704":2,"715":2,"726":1,"736":2,"828":2,"834":2,"874":2,"883":2,"893":2,"905":2,"962":2}}],["cross",{"2":{"126":1,"156":1,"291":1,"633":6,"635":1,"646":3,"647":1,"648":2,"765":2,"865":2,"1131":1,"1132":1}}],["crewai",{"2":{"1051":1,"1055":1}}],["createpinia",{"2":{"1489":2}}],["createwebhashhistory",{"2":{"1476":1}}],["createwebhistory",{"2":{"1474":2,"1476":1,"1479":1}}],["createrouter",{"2":{"1474":2,"1476":2,"1479":1}}],["createresponse",{"2":{"1431":1}}],["createapp",{"2":{"1444":1,"1489":2}}],["createuser",{"2":{"1434":1}}],["createuserrequest>",{"2":{"1431":1}}],["createuserrequest",{"2":{"1431":1}}],["createconnection",{"2":{"1427":1}}],["created",{"2":{"1470":1}}],["createdat",{"2":{"1412":1,"1428":5}}],["createdearlier",{"2":{"502":1}}],["create",{"2":{"391":1,"414":2,"472":2,"734":1,"926":1,"968":1,"1277":2,"1294":1,"1315":5,"1443":1,"1444":1}}],["credit",{"2":{"298":1}}],["ct=ft⊙ct−1+it⊙c~t",{"2":{"555":1}}],["ct=∂f",{"2":{"307":1}}],["ct",{"2":{"289":1,"307":1,"374":1,"556":1}}],["ctx方法",{"2":{"449":1}}],["ctx=row",{"2":{"964":1}}],["ctx=boxes",{"2":{"854":1}}],["ctx=ctx",{"2":{"828":1}}],["ctx=d2l",{"2":{"682":2,"715":1,"835":1}}],["ctx=devices",{"2":{"680":1,"686":1,"688":1,"702":1,"713":1,"726":1,"727":3,"796":2,"827":1,"866":1,"883":1,"893":1,"905":1}}],["ctx=device",{"2":{"67":2,"137":1,"326":1,"331":3,"332":1,"333":2,"335":2,"544":3,"545":1,"558":3,"559":2,"576":2,"577":3,"767":1,"848":4,"851":1,"852":2,"854":1,"926":1,"961":1}}],["ctx=try",{"2":{"448":2,"451":1}}],["ctx=x",{"2":{"408":1,"414":2,"573":1,"734":1}}],["ctx",{"2":{"67":2,"137":5,"332":2,"335":2,"398":2,"408":1,"414":2,"447":1,"449":2,"451":1,"472":4,"573":1,"576":1,"734":1,"767":1,"827":1,"828":3,"835":1,"848":1,"852":1,"854":2,"865":1,"866":1,"874":1,"896":1,"905":1,"908":1,"919":2,"927":1,"963":2,"964":2}}],["css开始",{"2":{"1541":1}}],["css",{"2":{"1363":1,"1371":1,"1444":1,"1533":1,"1539":1}}],["csdn",{"2":{"1121":1}}],["csv函数",{"2":{"1011":1}}],["csv中",{"2":{"1011":1}}],["csv包含训练图像的标签",{"2":{"901":1}}],["csv文件",{"2":{"896":1,"908":1}}],["csv是提交文件的范例",{"2":{"889":1}}],["csv含有训练图像的标签",{"2":{"889":1}}],["csv的文件",{"2":{"213":1}}],["csv",{"2":{"208":4,"213":2,"889":2,"890":6,"896":6,"901":2,"902":2,"908":3,"932":24,"1011":2,"1297":1}}],["cstride",{"2":{"102":2}}],["cpu在16x",{"2":{"841":1}}],["cpu上甚至没有这些参数",{"2":{"827":1}}],["cpu特别适用于int8操作",{"2":{"814":1}}],["cpu有24个通道",{"2":{"841":1}}],["cpu有2到4个内存通道",{"2":{"802":1}}],["cpu有几十个寄存器",{"2":{"810":1}}],["cpu需要在一个时钟周期内执行许多操作",{"2":{"809":1}}],["cpu的负载",{"2":{"1178":1}}],["cpu的速度以及gpu的速度和数量",{"2":{"821":1}}],["cpu的内存通常为ddr4类型",{"2":{"802":1}}],["cpu的每个核心都拥有高时钟频率的运行能力",{"2":{"457":1}}],["cpu或gpu",{"2":{"801":1}}],["cpu和gpu之间的总线",{"2":{"797":1}}],["cpu和gpu可以用paddle",{"2":{"446":1}}],["cpu和gpu可以用torch",{"2":{"446":1}}],["cpu和gpu可以用cpu",{"2":{"446":1}}],["cpuplace",{"2":{"446":2,"797":1}}],["cpu设备意味着所有物理cpu和内存",{"2":{"446":2}}],["cpu",{"0":{"807":1},"1":{"808":1,"809":1,"810":1},"2":{"376":1,"409":1,"446":17,"450":1,"457":1,"619":1,"768":1,"797":17,"807":1,"813":7,"827":1,"866":1,"896":1,"905":1,"906":1,"908":1,"964":2}}],["cpu每秒可处理高达2⋅109⋅16⋅32=1012个字节",{"2":{"77":1}}],["cp",{"2":{"192":1}}],["c为",{"2":{"1183":1}}],["c为常量",{"2":{"191":1,"244":1}}],["c为某些常数",{"2":{"59":1}}],["clean",{"2":{"1336":1}}],["cleartimeout",{"2":{"1520":1}}],["clear",{"2":{"67":1,"81":1,"129":1,"137":1,"210":1,"236":1,"237":1,"278":1,"335":1,"350":1,"392":1,"576":1,"595":1,"604":1,"635":2,"726":1,"767":1,"828":1,"883":1,"906":1,"927":1,"963":1,"974":1,"975":1,"976":2,"1089":2,"1499":1}}],["clusterip",{"2":{"1384":1}}],["clustering",{"2":{"296":1,"1149":1,"1193":1}}],["clusters",{"2":{"1154":1,"1352":1}}],["cluster",{"0":{"1381":1},"2":{"1151":3,"1392":1}}],["clf",{"2":{"1091":1}}],["cli版本在4",{"2":{"1443":1}}],["cli版本",{"2":{"1443":1}}],["cli已处于维护模式",{"2":{"1443":1}}],["cli",{"0":{"1443":1},"2":{"1443":2,"1530":1}}],["click=",{"2":{"1445":3,"1451":3,"1454":3,"1455":3,"1456":3,"1457":3,"1459":3,"1460":1,"1462":1,"1463":3,"1464":4,"1465":5,"1466":5,"1467":2,"1468":2,"1470":1,"1471":3,"1497":1,"1498":1,"1501":1,"1503":3,"1522":1}}],["click",{"2":{"1414":1,"1498":1}}],["client",{"2":{"1047":5,"1048":12,"1340":2}}],["clients",{"2":{"1042":1,"1043":1}}],["clipping",{"2":{"334":4,"335":6,"576":4}}],["clipped",{"2":{"210":8}}],["clip",{"2":{"210":3,"849":2,"919":2}}],["cls>",{"2":{"687":3,"720":1,"721":1,"722":3,"727":2,"734":1,"738":3}}],["cls",{"2":{"657":2,"688":1,"727":6,"734":2,"735":1,"737":2,"854":30,"954":3,"956":6,"959":51,"962":45,"963":35,"964":12,"1254":2}}],["closest",{"2":{"1151":1}}],["close",{"2":{"1048":1}}],["cloud",{"2":{"445":1,"1374":1}}],["clone",{"2":{"13":1,"442":18,"994":2,"1327":1}}],["claude",{"2":{"1042":1}}],["cla",{"2":{"635":1,"981":1}}],["clamp",{"2":{"210":1,"849":1,"919":1}}],["class=",{"2":{"1444":1,"1445":1,"1451":1,"1454":1,"1455":1,"1456":1,"1457":1,"1459":1,"1460":1,"1462":1,"1463":1,"1464":1,"1465":1,"1466":1,"1467":1,"1468":1,"1469":1,"1470":1,"1474":7,"1477":2,"1479":3,"1492":1,"1497":2,"1500":2,"1501":3,"1503":2,"1506":1,"1507":1,"1508":1,"1522":1,"1523":1}}],["classmethod",{"2":{"1254":1}}],["classes=1",{"2":{"959":3,"961":3}}],["classes=2",{"2":{"873":1,"874":1}}],["classes分别指定了a和q",{"2":{"954":1}}],["classes",{"2":{"826":6,"854":3,"862":11,"863":6,"893":8,"896":2,"908":2,"945":2,"954":6,"959":15,"962":4,"1139":2}}],["classification",{"2":{"209":1,"291":4,"292":1,"330":1,"587":1,"640":1,"1103":1,"1106":1,"1112":1,"1145":1,"1171":1}}],["class",{"2":{"68":1,"70":1,"71":1,"72":1,"127":3,"136":3,"137":1,"174":3,"291":1,"321":1,"325":4,"332":3,"363":1,"369":4,"370":4,"375":4,"382":4,"391":3,"398":4,"405":4,"406":4,"407":8,"408":6,"413":4,"414":3,"422":1,"423":3,"424":3,"425":6,"436":1,"442":3,"461":3,"472":3,"480":4,"481":1,"487":4,"488":3,"495":3,"501":4,"502":4,"508":3,"533":4,"534":4,"535":4,"573":4,"574":3,"575":4,"615":1,"634":1,"635":2,"668":3,"674":2,"675":2,"676":2,"677":2,"687":2,"688":2,"702":2,"713":2,"722":3,"734":3,"736":3,"737":3,"738":3,"748":1,"765":2,"775":1,"777":2,"820":1,"850":1,"852":26,"854":18,"926":2,"932":3,"947":3,"959":5,"963":6,"1094":2,"1106":2,"1215":1,"1416":3,"1417":2,"1422":2,"1425":1,"1426":1,"1427":1,"1428":2}}],["ca",{"2":{"813":2}}],["cach",{"2":{"807":1}}],["cache",{"0":{"1201":1},"2":{"206":3,"813":7,"1371":6}}],["came",{"2":{"727":3,"731":1}}],["campbell",{"2":{"301":1}}],["car=",{"2":{"1497":1}}],["car变化了",{"2":{"1465":1,"1466":1}}],["carol",{"2":{"1187":1,"1191":1}}],["car",{"2":{"659":1,"945":1,"1191":1,"1456":4,"1457":5,"1465":7,"1466":7,"1497":5,"1503":8}}],["cardinality",{"2":{"80":1,"81":1,"137":1}}],["case",{"2":{"1413":2}}],["cash",{"2":{"525":1,"732":1}}],["cast",{"2":{"172":1,"332":1,"334":1,"370":1,"392":2,"407":1,"408":1,"436":1,"472":1,"575":1,"584":1,"851":2}}],["caffe",{"2":{"300":1}}],["causality",{"2":{"296":1}}],["capabilities",{"2":{"1047":2}}],["capacity",{"2":{"259":2}}],["cap中的蘑菇实际上是一个死帽蕈",{"2":{"291":1}}],["cap",{"2":{"291":3}}],["catch",{"2":{"1048":1,"1471":1}}],["cat1",{"2":{"878":2}}],["cat=",{"2":{"854":1}}],["cat=0",{"2":{"854":1}}],["catdog",{"2":{"848":3,"857":2,"863":3,"912":3}}],["cats",{"2":{"755":1}}],["category>",{"2":{"1506":1,"1507":1}}],["category",{"2":{"291":1,"1506":1,"1507":1,"1508":2}}],["category=deprecationwarning",{"2":{"172":1,"208":1}}],["categoricalcrossentropy",{"2":{"575":1}}],["categorical",{"2":{"220":1}}],["cat",{"2":{"181":4,"316":1,"332":1,"375":2,"408":1,"480":1,"487":1,"545":1,"559":1,"576":1,"675":2,"676":1,"702":2,"713":1,"755":1,"848":2,"853":1,"854":3,"858":3,"945":1,"956":1,"959":1,"1018":2,"1025":2,"1416":1}}],["calculatebonus",{"2":{"1425":1}}],["calculatearea",{"2":{"1417":3}}],["calculator",{"2":{"1405":1}}],["calculus",{"2":{"980":3,"983":1,"987":1}}],["calculus中所说",{"2":{"973":1}}],["calculus中的微积分规则",{"2":{"59":1}}],["calc",{"2":{"962":3,"963":3}}],["calibration",{"2":{"643":1}}],["calme",{"2":{"376":2,"409":2,"578":2}}],["calm",{"2":{"376":2,"409":2,"578":2}}],["calling",{"2":{"1055":1}}],["calltool",{"2":{"1048":1}}],["call",{"2":{"68":1,"70":1,"71":1,"72":1,"127":1,"174":1,"325":1,"332":4,"369":1,"370":1,"375":1,"382":1,"391":1,"398":1,"405":1,"406":1,"407":2,"408":2,"413":1,"414":1,"422":6,"423":1,"424":1,"425":2,"436":2,"442":1,"472":1,"480":2,"481":1,"487":1,"501":1,"502":1,"533":1,"534":1,"535":1,"573":1,"574":1,"575":1,"635":1}}],["callback=learningratescheduler",{"2":{"68":1,"71":1,"72":1,"73":1}}],["callback",{"2":{"67":6,"137":3}}],["callbacks=",{"2":{"67":2,"137":1}}],["callbacks",{"2":{"67":1,"137":1}}],["canine",{"2":{"1416":1}}],["candidates",{"2":{"775":4}}],["candidate",{"2":{"541":1,"554":1,"721":7}}],["canny",{"2":{"302":1}}],["canny边缘检测器",{"2":{"302":1}}],["can",{"2":{"0":1,"660":2}}],["c",{"2":{"56":5,"59":15,"77":17,"78":4,"122":6,"158":4,"191":1,"207":1,"291":1,"293":2,"341":2,"390":2,"513":11,"515":14,"558":8,"559":36,"574":3,"578":3,"615":6,"702":6,"731":1,"743":2,"750":2,"751":4,"757":2,"776":2,"816":4,"817":2,"837":6,"848":1,"852":7,"887":1,"899":1,"977":12,"1021":2,"1038":1,"1040":2,"1042":2,"1089":4,"1090":1,"1092":1,"1093":1,"1103":2,"1144":2,"1147":3,"1151":3,"1152":5,"1183":1,"1340":1,"1349":1,"1456":3,"1457":3,"1464":4,"1483":1,"1501":4}}],["cx",{"2":{"56":1,"59":1,"858":5}}],["citys",{"2":{"1518":2,"1519":2}}],["citys2",{"2":{"1518":2,"1519":1}}],["citysd",{"2":{"1518":1}}],["city",{"2":{"1421":1,"1433":1}}],["cite",{"2":{"19":1,"25":1,"26":1,"32":3,"35":1,"38":1,"62":1,"66":1,"72":1,"73":1,"75":1,"78":1,"86":4,"95":2,"105":1,"106":1,"115":1,"135":1,"170":2,"198":1,"205":1,"231":1,"235":1,"247":1,"248":1,"250":1,"299":2,"300":17,"301":6,"302":2,"306":1,"309":1,"310":1,"316":1,"341":1,"345":2,"349":2,"355":1,"356":1,"373":2,"380":1,"388":2,"395":2,"397":1,"398":1,"403":2,"404":1,"411":2,"422":1,"454":2,"455":5,"466":1,"467":2,"475":2,"478":1,"485":1,"486":1,"491":4,"493":1,"500":1,"505":2,"507":1,"511":1,"519":2,"521":2,"538":3,"551":1,"564":1,"572":3,"578":1,"581":2,"619":1,"642":1,"657":1,"658":1,"660":1,"666":1,"672":1,"698":1,"700":1,"712":1,"718":1,"722":1,"726":1,"731":3,"732":1,"733":1,"737":1,"740":1,"743":1,"744":1,"746":1,"756":1,"757":3,"759":1,"773":1,"775":1,"782":2,"788":1,"795":1,"800":1,"811":3,"826":1,"832":4,"840":3,"841":1,"842":1,"843":1,"844":1,"856":1,"861":1,"868":1,"916":1,"920":1,"929":1,"936":4,"937":2,"938":1,"939":1,"940":1,"942":2,"952":1,"953":1,"966":2,"967":1,"1002":1}}],["circle",{"2":{"980":2,"1255":1,"1417":2,"1423":2,"1426":1}}],["cifar10相同",{"2":{"904":1}}],["cifar10一样",{"2":{"904":1}}],["cifar10的cifar",{"2":{"901":1}}],["cifar10的左上角显示了数据集中飞机",{"2":{"888":1}}],["cifar10中的最后一步类似",{"2":{"908":1}}],["cifar10中所做的那样整理数据集",{"2":{"902":1}}],["cifar10中cifar",{"2":{"899":1,"903":1}}],["cifar10中显示的cifar",{"2":{"889":1}}],["cifar10显示了竞赛网站页面上的信息",{"2":{"887":1}}],["cifar10",{"2":{"882":9,"883":6,"886":1,"887":2,"889":3,"890":2}}],["cifar",{"0":{"887":1},"1":{"888":1,"889":1,"890":1,"891":1,"892":1,"893":1,"894":1,"895":1,"896":1,"897":1,"898":1},"2":{"882":1,"887":2,"889":5}}],["ci是约束函数",{"2":{"47":1}}],["ci",{"0":{"1315":1},"2":{"47":1,"1315":3,"1346":1,"1354":1,"1372":1,"1544":1,"1546":1}}],["coordinate",{"2":{"1405":1}}],["co",{"2":{"1336":1}}],["code",{"2":{"1046":1,"1056":1,"1109":2,"1444":2}}],["cow",{"2":{"945":1}}],["copyfile",{"2":{"890":5}}],["copy",{"0":{"1200":1},"2":{"680":1,"703":2,"714":1,"797":9,"863":2,"890":1,"926":1,"994":1}}],["copyto",{"2":{"449":3,"472":2,"797":1,"835":3,"920":2}}],["copyto所示",{"2":{"449":1}}],["coat",{"2":{"582":2}}],["countdown",{"2":{"1246":1}}],["countstore",{"2":{"1491":2,"1492":2,"1493":2}}],["counts=true",{"2":{"854":3}}],["counts",{"2":{"773":3,"854":6,"1026":28}}],["count",{"2":{"363":2,"446":6,"566":1,"667":1,"693":1,"773":4,"890":5,"1226":3,"1401":1,"1490":4,"1491":1,"1492":3,"1493":1}}],["counter",{"2":{"363":3,"773":5,"775":3,"777":6,"890":1}}],["coffee中由于突出性导致的选择不同",{"2":{"355":1}}],["coffee所示",{"2":{"355":1}}],["coffee",{"2":{"355":2}}],["covariance",{"2":{"1159":1}}],["covariates",{"2":{"284":1}}],["covariate",{"2":{"181":1,"191":1,"192":1,"475":2,"609":1}}],["cove",{"2":{"731":1}}],["coverage",{"2":{"319":1}}],["corner的输入参数的最内层维度总是4",{"2":{"860":1}}],["corner反之亦然",{"2":{"858":1}}],["corner",{"2":{"852":2,"854":2,"858":5,"860":1}}],["cortexa77",{"2":{"808":1}}],["cortexa77的arm",{"2":{"808":1}}],["cortex",{"2":{"808":1}}],["corpus",{"2":{"318":7,"320":5,"321":15,"363":3,"364":9,"657":1,"773":3,"774":3,"777":6}}],["cores",{"2":{"807":1,"811":1}}],["core",{"2":{"300":1,"811":1,"812":1,"813":2,"1437":1}}],["corrado",{"2":{"782":1}}],["corr1d",{"2":{"699":6}}],["corresponding",{"2":{"1168":1}}],["correction中相同符号",{"2":{"192":1}}],["correction",{"2":{"191":1}}],["correlation为例来解释感受野",{"2":{"131":1}}],["correlation的输入张量x和卷积核张量k",{"2":{"126":1}}],["correlation中输出的卷积层有时被称为特征映射",{"2":{"131":1}}],["correlation中相同的输出",{"2":{"130":1}}],["correlation中的输入和k",{"2":{"130":1}}],["correlation中的卷积核",{"2":{"130":1}}],["correlation中",{"2":{"126":1,"140":1}}],["correlation",{"2":{"126":2,"156":1}}],["corr2d",{"2":{"120":5,"121":3,"122":3,"126":3,"127":4,"128":2,"970":2}}],["corr",{"2":{"34":16,"35":16}}],["com去看看",{"2":{"1061":1}}],["commit",{"0":{"1321":1},"2":{"1319":2,"1320":2,"1321":3,"1322":1,"1323":1,"1325":1,"1328":1,"1333":2,"1336":1,"1337":2}}],["command",{"2":{"1047":1,"1048":1}}],["common",{"2":{"890":1}}],["commutative",{"2":{"844":1}}],["combined",{"2":{"854":6}}],["com",{"2":{"206":1,"207":1,"686":2,"718":1,"887":1,"899":1,"1306":1,"1327":1,"1336":1,"1364":1,"1367":1,"1370":1,"1419":1,"1431":1,"1495":1}}],["compressed",{"2":{"1161":1}}],["compression",{"2":{"1156":1}}],["compress",{"2":{"813":1}}],["compare=200",{"2":{"677":2}}],["compare",{"2":{"675":6,"677":11,"773":3}}],["compositionapi",{"0":{"1447":1},"1":{"1448":1,"1449":1}}],["composition",{"0":{"1449":1},"2":{"1441":1,"1451":1,"1528":1,"1530":1}}],["composite",{"2":{"984":1}}],["compose",{"0":{"1347":1,"1349":1},"2":{"584":3,"872":6,"881":3,"882":6,"891":6,"903":6,"919":2,"1347":3,"1349":3,"1355":1}}],["components",{"2":{"1160":1,"1468":1,"1469":1}}],["component",{"2":{"296":1,"355":1,"990":1,"1158":1,"1159":1,"1474":2,"1478":3,"1479":4,"1483":1,"1524":1}}],["computing",{"2":{"1090":1,"1374":1}}],["computecost",{"2":{"1081":1}}],["compute",{"2":{"816":2,"925":1,"927":3,"1109":2}}],["computed中的",{"2":{"1448":1}}],["computed与watch",{"2":{"1441":1}}],["computed",{"0":{"1460":1},"2":{"289":1,"1448":1,"1460":3,"1490":1}}],["computational",{"2":{"973":1}}],["computation",{"2":{"421":1,"824":1,"1021":2}}],["comp",{"2":{"141":12,"142":8}}],["compile",{"2":{"67":1,"68":1,"137":1,"210":1,"817":1,"819":1}}],["cocke",{"2":{"564":2}}],["cock",{"2":{"205":1}}],["cock于2011年收集",{"2":{"205":1}}],["collaborative",{"2":{"1189":1,"1190":1}}],["collate",{"2":{"777":2}}],["collobert",{"2":{"700":1}}],["collections",{"2":{"360":4,"363":1,"572":4,"578":1,"757":3,"887":3,"890":1}}],["collection",{"0":{"1196":1},"2":{"297":2,"1196":1,"1198":1}}],["collect",{"2":{"67":1,"68":1,"71":1,"72":1,"73":1,"81":1,"137":2,"176":1,"210":1,"225":1,"263":1,"278":2,"334":1,"335":1,"350":1,"392":1,"418":4,"432":3,"433":2,"576":1,"594":2,"625":1,"681":1,"688":1,"703":1,"704":1,"714":1,"715":1,"726":1,"767":1,"827":1,"828":1,"865":2,"873":1,"874":2,"876":1,"883":1,"894":1,"905":1,"906":1,"926":1,"927":1,"961":1}}],["cola",{"2":{"657":1}}],["col",{"2":{"398":4,"851":6}}],["cols=4",{"2":{"878":1}}],["cols",{"2":{"357":2,"582":9,"878":2}}],["column",{"2":{"77":4,"399":4}}],["coloredcircle",{"2":{"1423":1}}],["colorjitter",{"2":{"880":6,"903":2}}],["colormap2label",{"2":{"945":19,"947":9}}],["colormap2label函数来构建从上述rgb颜色值到类别索引的映射",{"2":{"945":1}}],["colormap",{"2":{"866":9,"945":34,"1091":3}}],["color",{"2":{"848":5,"858":1,"880":5,"881":3,"1413":1,"1417":7,"1423":1,"1444":1}}],["colors",{"2":{"848":4}}],["colors=none",{"2":{"848":1}}],["colors=",{"2":{"57":3,"933":3}}],["colorbar",{"2":{"357":1,"1091":4}}],["color=text",{"2":{"848":1}}],["color=",{"2":{"57":3,"1026":4}}],["cosine",{"2":{"768":3,"1154":1}}],["cosine相似度=",{"2":{"750":1}}],["cosinescheduler",{"2":{"72":3,"73":2}}],["cos⁡",{"2":{"400":6}}],["cost1",{"2":{"1144":1}}],["costreg",{"2":{"1117":1}}],["costfunction",{"2":{"1109":2,"1111":2}}],["costfunctionj",{"2":{"1092":1}}],["cost",{"2":{"231":1,"642":1,"1064":1,"1065":1,"1066":1,"1109":5,"1110":3,"1115":1,"1120":1,"1122":1,"1144":1}}],["cosh",{"2":{"59":2}}],["cos",{"2":{"41":2,"56":2,"59":3,"72":1,"99":2,"398":4,"750":11,"751":1,"768":9,"1091":1,"1154":1}}],["conda",{"0":{"1274":1},"1":{"1275":1,"1276":1,"1277":1},"2":{"1277":5,"1294":3}}],["conditionally",{"2":{"1034":1}}],["conditional",{"2":{"708":2,"1031":1,"1032":1,"1035":2}}],["condition",{"2":{"26":1,"348":1}}],["conjugate",{"2":{"1109":1}}],["conf",{"2":{"854":24,"1364":1}}],["confidence",{"2":{"854":1}}],["configmap",{"0":{"1385":1},"2":{"1385":1}}],["config",{"2":{"446":3,"635":2,"1208":2,"1210":1,"1336":6,"1427":9,"1454":1,"1524":1}}],["conflicts",{"2":{"813":1}}],["connect",{"2":{"1047":2,"1048":2}}],["connected",{"2":{"591":1,"618":1,"1048":2}}],["connections",{"2":{"1362":1,"1364":1,"1371":1}}],["connection",{"2":{"404":1,"970":1,"972":1}}],["console",{"2":{"1048":8,"1402":1,"1413":2,"1416":3,"1417":3,"1422":3,"1433":1,"1451":2,"1454":2,"1455":2,"1457":1,"1460":1,"1462":1,"1463":1,"1464":2,"1465":2,"1466":1,"1467":4,"1468":8,"1469":1,"1470":7,"1471":1,"1481":1,"1482":1,"1485":4,"1494":1,"1499":3,"1518":4}}],["consistency",{"2":{"389":1}}],["const2",{"2":{"1167":1}}],["const1",{"2":{"1167":1}}],["constructor",{"2":{"1416":1,"1417":2,"1425":2,"1426":1,"1427":1,"1428":2}}],["construction",{"2":{"421":1,"422":1,"439":1}}],["construction对块的介绍",{"2":{"413":1}}],["constrained",{"2":{"47":1}}],["constraints",{"2":{"47":1}}],["constant函数创建的随机权重参数在训练期间不会更新",{"2":{"425":2}}],["constant",{"2":{"113":2,"114":1,"147":4,"148":2,"330":1,"334":1,"368":2,"369":1,"396":1,"406":1,"407":1,"413":1,"425":3,"435":12,"447":1,"575":4,"576":1,"577":2,"582":2,"600":1,"633":2,"702":6,"703":6,"863":2,"926":1,"968":1,"969":2,"989":2,"992":1,"1000":1,"1013":2,"1017":1,"1018":3,"1022":2}}],["const",{"2":{"0":1,"1047":4,"1048":6,"1398":1,"1402":1,"1416":2,"1419":1,"1420":2,"1421":2,"1430":1,"1431":3,"1432":3,"1433":4,"1462":1,"1467":2,"1468":1,"1469":1,"1471":3,"1474":1,"1481":1,"1482":1,"1485":2,"1489":2,"1490":4,"1491":2,"1492":2,"1493":1,"1495":2,"1497":3,"1499":1,"1500":2,"1515":1,"1516":1,"1523":1}}],["conclusion",{"0":{"1175":1},"1":{"1176":1},"2":{"1193":1}}],["concept",{"2":{"183":1}}],["concat的形状",{"2":{"382":4}}],["concatenate",{"2":{"332":1,"375":2,"408":1,"480":2,"487":2,"545":1,"559":1,"574":1,"576":1,"675":2,"676":1,"702":2,"713":1,"848":2,"956":1,"959":1,"1018":3}}],["concat",{"2":{"148":2,"208":1,"211":2,"213":1,"332":2,"340":2,"375":4,"376":1,"382":8,"408":2,"409":1,"480":1,"487":1,"545":2,"559":2,"574":4,"576":2,"675":2,"676":1,"702":2,"713":1,"848":2,"852":1,"854":7,"956":5,"959":7,"1018":4}}],["concise中对多gpu训练的介绍",{"2":{"883":1}}],["concise中我们使用深度学习框架的高级api简洁实现线性回归",{"2":{"639":1}}],["concise中训练的模型",{"2":{"347":1}}],["concise中",{"2":{"246":1,"622":1}}],["concise",{"2":{"21":4,"29":4,"34":4,"81":8,"92":4,"109":4,"204":1,"224":1,"225":1,"228":1,"278":6,"305":1,"324":1,"350":1,"422":1,"424":1,"573":1,"587":2,"588":1,"622":1,"824":1,"825":1,"831":1}}],["conv来构建输入张量x和卷积核张量k从而",{"2":{"968":1}}],["conv解释了如何为2×2的输入张量计算卷积核为2×2的转置卷积",{"2":{"968":1}}],["convtranspose2d",{"2":{"862":1,"863":1,"968":1,"969":3}}],["conv3",{"2":{"501":16,"893":4}}],["conv2",{"2":{"501":8,"893":2}}],["conv2dtranspose",{"2":{"862":2,"863":2,"968":2,"969":6}}],["conv2d",{"2":{"67":8,"127":4,"129":31,"136":8,"137":2,"141":44,"142":30,"461":20,"473":8,"474":8,"480":4,"481":4,"482":4,"487":24,"488":12,"494":12,"501":12,"502":5,"507":4,"826":3,"828":2,"834":4,"862":3,"883":2,"893":4,"954":3,"955":3,"957":3,"969":3}}],["conv1d和",{"2":{"699":1}}],["conv1d构造输入张量x和核张量k来验证上述一维互相关实现的输出",{"2":{"699":1}}],["conv1d中的0×1+1×2=2",{"2":{"699":1}}],["conv1d中的0和1",{"2":{"699":1}}],["conv1d中的1和2",{"2":{"699":1}}],["conv1d中所示",{"2":{"699":1}}],["conv1d",{"2":{"699":8,"701":2,"702":5}}],["conv1",{"2":{"501":8,"893":2}}],["convs和输出通道的数量num",{"2":{"507":1}}],["convs",{"2":{"480":8,"482":24,"507":9,"508":8,"702":9}}],["convblock",{"2":{"480":3}}],["convnet几年来它一直是行业标准",{"2":{"457":1}}],["convergence",{"2":{"1116":1,"1117":1,"1167":1}}],["conversion",{"2":{"791":2}}],["convert",{"2":{"334":1,"409":1,"431":1}}],["convexfunction",{"2":{"1109":1}}],["convex",{"2":{"39":2,"40":4,"41":1}}],["convexity",{"2":{"38":2,"65":1}}],["convolution",{"2":{"154":1,"155":1,"834":2,"861":1,"967":1}}],["convolutional",{"2":{"134":1,"151":1,"155":1,"861":1}}],["conv中相同输入和卷积核张量",{"2":{"969":1}}],["conv中通过转置卷积层将特征图的高和宽变换为输入图像的尺寸",{"2":{"862":1}}],["conv中引入的转置卷积",{"2":{"861":1}}],["conv中观察到的互相关和卷积运算之间的对应关系",{"2":{"130":1}}],["conv中的描述",{"2":{"126":1}}],["conv",{"2":{"119":1,"120":3,"121":1,"122":2,"125":1,"130":1,"131":1,"134":2,"140":1,"141":2,"142":2,"145":1,"146":1,"151":1,"155":2,"156":5,"158":3,"160":2,"480":8,"481":2,"508":19,"509":6,"702":6,"834":12,"862":4,"863":10,"886":1,"912":1,"913":1,"967":2,"968":5,"969":10,"970":2}}],["containerport",{"2":{"1389":1,"1390":1}}],["containerization",{"2":{"1352":1}}],["containerd",{"2":{"1350":1,"1377":1,"1394":2}}],["container",{"2":{"1343":2,"1344":2,"1350":1,"1353":1,"1377":1,"1378":2,"1389":1,"1394":1}}],["containers",{"0":{"8":1},"2":{"1389":1,"1390":1}}],["controller",{"2":{"1372":1,"1376":1,"1378":1}}],["control",{"0":{"1376":1},"2":{"1092":1,"1371":1,"1378":1,"1381":1}}],["contrast",{"2":{"880":1}}],["contrast=0",{"2":{"880":7,"903":3}}],["contradiction",{"2":{"665":1,"667":1,"682":3}}],["continue",{"2":{"583":1,"720":1,"721":1,"774":1,"854":1,"964":3,"1092":2,"1227":1}}],["continuous",{"2":{"334":1,"1028":1}}],["contexts函数从corpus中提取所有中心词及其上下文词",{"2":{"774":1}}],["contexts",{"2":{"763":6,"774":10,"775":6,"776":4,"777":22}}],["context的形状",{"2":{"574":1}}],["context的形状为",{"2":{"375":4}}],["context",{"0":{"1039":1},"1":{"1040":1,"1041":1,"1042":1,"1043":1,"1044":1,"1045":1,"1046":1,"1047":1,"1048":1},"2":{"332":1,"375":8,"445":3,"574":20,"731":1,"767":6,"774":2,"776":5,"1040":1,"1042":1,"1043":1}}],["contextual",{"2":{"298":1}}],["content=欢迎你",{"2":{"1481":1}}],["contents函数对内容图像抽取内容特征",{"2":{"920":1}}],["contents",{"2":{"920":12,"925":7,"927":27,"1048":2}}],["content",{"2":{"206":1,"918":6,"920":23,"922":3,"925":3,"927":12,"1048":2,"1188":1,"1315":1,"1474":1,"1481":2,"1482":1,"1483":1,"1490":4,"1495":1}}],["contour",{"2":{"57":3}}],["ch13函数",{"2":{"883":1}}],["ch13函数那样指定训练的轮数",{"2":{"726":1}}],["ch13中被设置",{"2":{"688":1}}],["ch13",{"2":{"681":3,"688":3,"704":3,"715":3,"865":3,"874":3,"883":12,"894":3}}],["ch11",{"2":{"21":6,"28":2,"29":4,"34":6,"35":8,"79":4,"80":6,"81":12,"91":2,"92":4,"108":2,"109":4}}],["chung",{"2":{"538":1}}],["chi",{"2":{"1148":1}}],["chishti关于dram的讲座",{"2":{"802":1}}],["child",{"2":{"757":1,"1497":5,"1498":1,"1501":6,"1503":4,"1523":3}}],["children字典中查找需要初始化参数的子块",{"2":{"424":1}}],["children的主要优点是",{"2":{"424":1}}],["children属性",{"2":{"424":1}}],["children添加一个块",{"2":{"424":1}}],["children",{"2":{"424":3,"862":3,"1479":1}}],["children中",{"2":{"424":1}}],["china",{"2":{"751":2}}],["chip",{"2":{"750":2,"768":3,"773":1}}],["chimera",{"2":{"425":13}}],["cheap",{"2":{"1056":1}}],["chellappa",{"2":{"856":1}}],["chen",{"2":{"493":1,"722":1,"773":1,"775":1,"782":2,"788":1,"1542":1}}],["cheng",{"2":{"395":1,"403":1}}],["chez",{"2":{"376":2,"409":2,"578":2}}],["checkout",{"2":{"1315":2,"1323":2,"1329":2,"1333":1,"1336":1}}],["checkpoint",{"2":{"1198":1,"1202":2}}],["checking",{"2":{"1124":2}}],["check",{"2":{"5":1,"9":1,"295":1,"1134":1}}],["ch8函数",{"2":{"333":1}}],["ch8",{"2":{"326":9,"333":6,"335":21,"523":3,"529":1,"546":3,"547":4,"560":3,"561":4}}],["choosing",{"2":{"1154":1,"1160":1,"1183":1}}],["choose",{"2":{"116":1,"1443":1}}],["choices",{"2":{"775":1}}],["choice",{"2":{"643":1,"720":2,"721":1}}],["cho",{"2":{"300":1,"373":1,"538":2,"572":2}}],["ch3函数相同",{"2":{"335":1}}],["ch3函数",{"2":{"221":1}}],["ch3",{"2":{"137":2,"175":4,"176":4,"221":5,"225":1,"263":4,"626":1,"635":7,"636":2}}],["ch3不同",{"2":{"137":1}}],["ch6",{"2":{"137":5,"463":1,"473":3,"474":1,"483":1,"488":1,"489":1,"496":1,"503":1,"509":2}}],["ch6也类似于",{"2":{"137":1}}],["ch6定义在卷积神经网络一章lenet一节中的相同",{"2":{"67":4}}],["chases",{"2":{"1191":1}}],["chair",{"2":{"945":1}}],["chainer和pytorch采取了命令式编程",{"2":{"818":1}}],["changage",{"2":{"1454":2}}],["changname",{"2":{"1454":2}}],["changeprice",{"2":{"1467":2}}],["changeperson",{"2":{"1463":2,"1464":2}}],["changecar",{"2":{"1465":2,"1466":2}}],["changecarprice",{"2":{"1456":2,"1457":2}}],["changec2",{"2":{"1465":2,"1466":2}}],["changec1",{"2":{"1465":2,"1466":2}}],["changesum",{"2":{"1462":2,"1467":2,"1470":2}}],["changefullname",{"2":{"1460":2}}],["changefirstgame",{"2":{"1456":2,"1457":2}}],["changegender",{"2":{"1459":2}}],["changeage",{"2":{"1445":2,"1451":3,"1455":2,"1459":2,"1463":2,"1464":2,"1465":2,"1466":2}}],["changename",{"2":{"1445":2,"1451":3,"1455":2,"1459":2,"1463":2,"1464":2,"1465":2,"1466":2}}],["changeradius",{"2":{"1426":1}}],["chang",{"2":{"726":1,"733":1}}],["channel中的输出都只有一个通道",{"2":{"699":1}}],["channel中的多输入通道一维互相关的等价形式是",{"2":{"699":1}}],["channel中验证结果",{"2":{"699":1}}],["channel演示了具有3个输入通道的一维互相关操作",{"2":{"699":1}}],["channel",{"2":{"119":1,"134":1,"158":1,"445":1,"699":1,"993":1}}],["channels为当前的通道数",{"2":{"482":4}}],["channels可以定义具有多个通道的卷积层",{"2":{"158":1}}],["channels中描述的具有多个输出通道的二维卷积相同",{"2":{"699":1}}],["channels中描述了构成每个图像的多个通道和多层卷积层",{"2":{"119":1}}],["channels中所述",{"2":{"131":1,"494":1}}],["channels中所讨论的",{"2":{"121":1}}],["channels",{"2":{"119":1,"134":1,"147":1,"148":1,"158":2,"480":28,"481":14,"482":26,"487":10,"494":24,"501":28,"502":18,"507":19,"508":18,"702":14,"826":17,"863":18,"893":7,"923":3,"957":17,"959":6}}],["channels=num",{"2":{"957":1}}],["channels=1",{"2":{"141":4,"826":2}}],["channels=16",{"2":{"67":1,"136":1}}],["channels=6",{"2":{"67":1,"136":1}}],["charlie",{"2":{"1398":1,"1421":1}}],["char",{"2":{"362":1,"364":1,"565":8}}],["character",{"2":{"341":1,"1171":2}}],["chap",{"2":{"67":1,"228":1,"275":1,"338":1,"550":1,"564":1,"605":1,"663":4,"698":1,"727":1,"733":1,"747":1,"754":1,"886":2}}],["cd命令设置到你函数所在的目录下",{"2":{"1092":1}}],["cd命令",{"2":{"1089":1}}],["cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a",{"2":{"748":1}}],["cd",{"2":{"13":1,"1346":1,"1354":1,"1372":1,"1443":1,"1546":1}}],["cute",{"2":{"1191":1}}],["cum",{"2":{"1026":14}}],["cumsum",{"2":{"80":4,"615":2,"996":4,"1026":4}}],["curves",{"2":{"1134":1}}],["cur",{"2":{"757":4,"776":4}}],["current",{"2":{"0":1,"1168":1}}],["cudaplace",{"2":{"446":4}}],["cuda",{"2":{"446":13,"449":3,"790":2,"796":12,"797":6,"813":1,"836":2,"837":2}}],["cudatoolkit=10",{"2":{"445":1}}],["cu100安装支持cuda10",{"2":{"445":1}}],["cues",{"2":{"354":1,"379":2}}],["customref",{"0":{"1520":1},"2":{"1520":2}}],["custom",{"0":{"8":1},"2":{"67":3,"68":1,"71":1,"72":1,"73":1,"421":1}}],["ddd",{"2":{"1444":1}}],["ddx",{"2":{"981":8}}],["ddxtanh",{"2":{"237":1}}],["ddxsigmoid",{"2":{"236":1}}],["dvcs",{"2":{"1318":1}}],["django",{"2":{"1297":1}}],["d中仅有一个为1",{"2":{"1103":1}}],["dpng",{"2":{"1091":1}}],["dna序列和等等",{"2":{"1058":1}}],["d1",{"2":{"1035":1}}],["d1=1",{"2":{"1035":13}}],["d1=1∣h=1",{"2":{"1035":3}}],["d1=1∣h=0",{"2":{"1035":2}}],["d1=1∣h",{"2":{"1035":1}}],["d1=0∣h",{"2":{"1035":1}}],["d1∣h",{"2":{"1035":1}}],["d1中列出了这样的条件概率",{"2":{"1035":1}}],["dxtaxdx=2ax",{"2":{"1086":1}}],["dxn=nxn−1",{"2":{"981":1}}],["dx的图像",{"2":{"979":1}}],["dxdy=∫∫l",{"2":{"191":1,"192":1}}],["dxdy",{"2":{"190":1,"191":1,"192":1}}],["df",{"2":{"896":12}}],["ds",{"2":{"892":24,"896":6,"904":24,"908":3}}],["dc=0",{"2":{"981":1}}],["dc",{"2":{"813":6}}],["dgl",{"2":{"811":1}}],["dgx",{"2":{"300":1,"842":1}}],["d=",{"2":{"1501":1}}],["d=0∣w",{"2":{"708":2}}],["d=1∣w",{"2":{"708":3}}],["d=1∣wc",{"2":{"708":1}}],["d=∑a=−δδ∑b=−δδ∑c",{"2":{"158":1}}],["dqn",{"2":{"642":1}}],["dq",{"2":{"642":1}}],["draskychen",{"2":{"1550":1}}],["drasky",{"2":{"1542":1}}],["draw",{"2":{"775":3,"1417":3}}],["driving",{"2":{"1127":1}}],["drives",{"2":{"805":1}}],["drive",{"2":{"804":1}}],["driver",{"2":{"727":3,"731":1}}],["drink",{"2":{"736":1}}],["dress",{"2":{"582":2}}],["dropbox",{"2":{"1303":1}}],["drop",{"2":{"170":1,"864":2,"892":6,"904":6,"948":2,"949":4,"1332":1}}],["dropout可以用来减少过拟合",{"2":{"701":1}}],["dropout=dropout",{"2":{"375":4,"573":4,"574":4}}],["dropout=0",{"2":{"369":4,"370":4,"375":4,"573":4,"574":4,"686":4,"726":2}}],["dropout层仅传递数据",{"2":{"176":1}}],["dropout层将根据指定的暂退概率随机丢弃上一层的输出",{"2":{"176":1}}],["dropout1",{"2":{"174":7,"176":4}}],["dropout2",{"2":{"171":1,"174":8,"176":4}}],["dropout2中",{"2":{"171":1}}],["dropout",{"0":{"168":1},"1":{"169":1,"170":1,"171":1,"172":1,"173":1,"174":1,"175":1,"176":1,"177":1,"178":1},"2":{"168":1,"170":1,"172":42,"174":8,"176":8,"204":1,"369":20,"370":20,"375":4,"376":3,"382":8,"398":20,"406":20,"407":28,"408":36,"409":12,"461":9,"464":1,"495":4,"508":8,"576":3,"674":6,"686":4,"702":9,"734":10,"738":6}}],["dydx=dydududx",{"2":{"984":1}}],["dynamic",{"2":{"519":1,"1048":1}}],["dy=p",{"2":{"42":1}}],["d∣c",{"2":{"515":2}}],["d×d权重矩阵和d维隐状态的乘法计算复杂度为o",{"2":{"397":1}}],["dln⁡",{"2":{"981":1}}],["dl",{"2":{"281":1}}],["dtype和name",{"2":{"820":1}}],["dtypes",{"2":{"209":2}}],["dtype",{"2":{"172":2,"472":1,"575":2,"584":2,"634":5,"699":1,"734":1,"762":2,"962":3,"997":1,"1020":1}}],["dtype=float",{"2":{"1013":6}}],["dtype=str",{"2":{"734":1}}],["dtype=x",{"2":{"699":1}}],["dtype=dtype",{"2":{"436":1}}],["dtype=d2l",{"2":{"147":2,"209":3,"350":2}}],["dtype=none",{"2":{"436":1}}],["dtype=np",{"2":{"79":4,"398":2,"851":1,"852":2,"854":2}}],["dtype=paddle",{"2":{"369":1,"398":2,"406":1,"407":1,"573":1,"575":2,"577":2,"722":7,"851":1,"852":2,"945":1,"966":2,"994":1,"995":1}}],["dtype=tf",{"2":{"172":2,"235":1,"325":1,"331":6,"333":1,"334":1,"335":1,"369":1,"370":1,"392":2,"406":1,"407":1,"408":1,"544":6,"558":3,"575":3,"974":1,"994":1,"995":1,"997":1,"1018":1}}],["dtype=torch",{"2":{"136":1,"369":1,"375":1,"398":2,"406":1,"407":1,"573":1,"575":2,"577":2,"687":2,"722":7,"763":2,"851":1,"852":2,"854":1,"945":1,"994":1,"995":1,"1018":1}}],["dtype=",{"2":{"41":1,"54":1,"57":2,"99":1,"101":1,"102":1,"103":1,"147":1,"235":1,"242":1,"262":1,"375":1,"386":1,"390":1,"391":1,"413":1,"414":2,"472":6,"584":1,"687":4,"722":6,"762":2,"763":2,"765":1,"767":2,"851":2,"852":1,"854":4,"866":2,"926":1,"932":1,"938":1,"947":2,"968":1,"970":1,"974":1,"997":1,"999":1,"1000":1,"1007":1,"1018":1}}],["dz",{"2":{"156":1}}],["d",{"2":{"105":1,"158":2,"253":1,"269":1,"284":1,"293":2,"305":1,"370":17,"396":1,"398":14,"400":1,"409":4,"515":3,"527":1,"578":3,"615":1,"751":1,"757":2,"816":4,"817":2,"837":6,"959":3,"977":15,"1103":1,"1121":2,"1132":4,"1329":1,"1454":1,"1456":3,"1457":3,"1501":4}}],["db",{"2":{"80":2,"605":2}}],["dw",{"2":{"80":2,"605":2}}],["double",{"2":{"1089":1}}],["doucet",{"2":{"519":1}}],["dollar",{"2":{"936":1,"940":1}}],["donahue",{"2":{"936":1,"937":1}}],["done",{"2":{"820":1}}],["dong",{"2":{"395":1,"403":1}}],["do",{"2":{"751":2,"1135":1,"1261":1}}],["down",{"2":{"525":1,"732":1,"754":1,"957":6,"958":3,"959":5,"1347":1,"1413":2}}],["download=true",{"2":{"582":2,"584":2,"882":4}}],["download",{"2":{"79":4,"206":5,"208":2,"361":1,"565":1,"666":3,"669":3,"679":1,"686":3,"687":3,"692":1,"695":3,"717":1,"722":3,"724":1,"725":1,"748":1,"772":1,"864":1,"866":3,"872":1,"889":2,"901":1,"932":3,"945":1,"949":3}}],["dosovitskiy",{"2":{"411":1}}],["doglist",{"2":{"1471":6}}],["dog所示",{"2":{"1025":1}}],["dog中显示的竞争网页上的",{"2":{"901":1}}],["dog显示了鉴定比赛网页上的信息",{"2":{"899":1}}],["dog=",{"2":{"854":1}}],["dog=0",{"2":{"854":3}}],["dogs",{"0":{"899":1},"1":{"900":1,"901":1,"902":1,"903":1,"904":1,"905":1,"906":1,"907":1,"908":1,"909":1,"910":1},"2":{"755":1}}],["dog",{"2":{"181":4,"755":1,"853":1,"858":3,"886":1,"899":2,"901":8,"902":3,"945":1,"1025":1,"1416":5,"1471":1}}],["dot操作符也将使用所有cpu上的所有核心",{"2":{"795":1}}],["dot中描述",{"2":{"763":1}}],["dotproductattention",{"2":{"370":11,"382":4}}],["dot",{"0":{"997":1},"2":{"77":5,"78":1,"174":3,"219":2,"243":1,"262":1,"332":3,"369":1,"370":3,"390":3,"391":1,"414":1,"425":1,"545":7,"559":9,"674":3,"750":1,"763":1,"768":1,"790":5,"791":4,"796":1,"834":2,"974":3,"997":4,"998":2,"999":1,"1085":1}}],["docker",{"0":{"1338":1,"1339":1,"1340":1,"1341":1,"1346":1,"1347":1,"1348":1,"1349":2,"1350":1,"1351":1,"1394":1,"1395":1},"1":{"1339":1,"1340":1,"1341":1,"1342":2,"1343":2,"1344":2,"1345":2,"1346":1,"1347":1,"1348":1,"1349":1,"1350":1,"1351":1},"2":{"1339":1,"1340":10,"1342":2,"1343":4,"1344":1,"1345":1,"1346":1,"1347":3,"1348":3,"1349":4,"1350":2,"1351":1,"1353":1,"1355":3,"1372":1,"1374":1,"1377":1,"1393":2,"1394":4,"1395":2,"1543":1,"1546":1}}],["docx",{"2":{"1297":1}}],["document",{"0":{"1196":1},"2":{"1195":1,"1196":1,"1467":1,"1468":1}}],["documentation",{"2":{"5":1,"9":1}}],["docs",{"2":{"15":1,"16":1,"17":1,"1306":1,"1309":1,"1313":1}}],["duck",{"2":{"1422":1}}],["ducharme",{"2":{"341":1}}],["duchi",{"2":{"25":1,"26":1}}],["dumoulin",{"2":{"967":1}}],["dummies",{"2":{"209":1,"1012":1}}],["dummy",{"2":{"68":3,"209":2,"1012":1}}],["d2=1",{"2":{"1035":5}}],["d2=1∣h=1",{"2":{"1035":4}}],["d2=1∣h=0",{"2":{"1035":3}}],["d2=1∣h",{"2":{"1035":1}}],["d2=0∣h",{"2":{"1035":1}}],["d2∣h",{"2":{"1035":1}}],["d2所示",{"2":{"1035":1}}],["d2",{"2":{"26":1,"59":1,"397":1,"1035":1}}],["d2l",{"2":{"21":29,"27":12,"28":10,"29":3,"34":29,"35":8,"38":8,"41":14,"44":2,"54":14,"56":4,"57":24,"59":10,"67":28,"68":2,"70":2,"71":7,"72":4,"73":3,"77":18,"79":17,"80":27,"81":12,"87":18,"88":4,"89":6,"91":8,"92":3,"95":6,"99":18,"101":4,"102":20,"103":6,"107":13,"108":10,"109":3,"112":8,"113":6,"114":4,"120":12,"121":2,"122":10,"126":12,"128":3,"129":3,"136":8,"137":26,"146":8,"147":4,"148":1,"172":8,"175":9,"176":4,"206":1,"208":8,"209":3,"210":4,"211":3,"213":2,"216":9,"219":3,"221":7,"224":8,"225":2,"234":8,"235":8,"236":8,"237":8,"242":12,"261":8,"262":2,"263":24,"271":13,"275":24,"278":12,"318":15,"320":2,"321":12,"324":12,"326":12,"329":10,"330":6,"331":9,"332":11,"333":9,"335":29,"340":23,"350":25,"351":22,"357":13,"360":8,"361":3,"367":8,"368":6,"369":8,"370":4,"374":8,"375":11,"376":14,"381":8,"382":8,"385":8,"386":14,"388":9,"390":10,"391":2,"392":15,"395":8,"396":6,"398":13,"399":4,"404":8,"405":2,"406":7,"407":18,"408":17,"409":31,"461":8,"462":1,"463":2,"472":8,"473":6,"474":2,"480":8,"483":3,"487":8,"488":1,"489":3,"494":8,"496":3,"501":8,"503":3,"507":8,"509":4,"523":18,"528":15,"529":1,"543":12,"544":5,"545":1,"546":9,"547":9,"557":12,"558":4,"560":9,"561":9,"564":8,"565":3,"566":5,"567":1,"568":4,"569":7,"572":8,"573":7,"574":7,"575":9,"576":19,"577":4,"581":12,"582":4,"583":1,"589":10,"595":3,"598":8,"599":12,"600":1,"601":2,"602":1,"603":1,"605":1,"615":13,"616":2,"622":9,"626":1,"629":9,"631":12,"632":2,"633":3,"634":7,"635":5,"636":5,"666":12,"668":12,"669":6,"673":6,"679":6,"680":6,"681":3,"685":6,"686":20,"687":18,"688":4,"691":6,"692":2,"693":8,"694":4,"695":28,"698":9,"699":6,"702":3,"703":3,"704":5,"712":9,"713":1,"714":1,"715":3,"718":7,"720":1,"722":12,"725":10,"726":13,"727":3,"733":6,"734":3,"747":6,"748":11,"760":9,"762":1,"765":6,"767":9,"771":6,"772":4,"773":2,"776":5,"777":5,"789":7,"790":10,"791":4,"792":2,"795":6,"796":12,"797":9,"819":8,"820":1,"825":6,"826":6,"827":5,"828":15,"833":6,"835":2,"837":18,"847":6,"848":15,"852":9,"853":3,"854":21,"857":12,"858":5,"861":6,"863":10,"864":4,"865":6,"866":12,"871":6,"872":4,"874":6,"877":6,"878":5,"882":2,"883":21,"887":6,"889":3,"893":2,"894":17,"895":3,"899":6,"901":3,"902":3,"905":1,"906":10,"907":3,"912":21,"918":17,"923":3,"924":2,"927":6,"931":8,"932":3,"933":6,"945":12,"946":3,"949":6,"954":6,"959":3,"961":4,"963":12,"964":12,"966":15,"967":6,"968":3,"970":18,"981":11,"1026":32}}],["div>",{"2":{"1444":1,"1445":1,"1451":1,"1454":1,"1455":1,"1456":1,"1457":1,"1459":1,"1460":1,"1462":1,"1463":1,"1464":1,"1465":1,"1466":1,"1467":1,"1468":1,"1469":1,"1470":1,"1474":3,"1479":2,"1492":1,"1497":2,"1500":2,"1501":3,"1503":2,"1506":1,"1507":1,"1508":1,"1522":1,"1523":1}}],["div",{"2":{"1444":1,"1445":1,"1451":1,"1454":1,"1455":1,"1456":1,"1457":1,"1459":1,"1460":1,"1462":1,"1463":1,"1464":1,"1465":1,"1466":1,"1467":1,"1468":1,"1469":1,"1470":1,"1474":3,"1479":2,"1492":1,"1497":2,"1500":2,"1501":3,"1503":2,"1506":1,"1507":1,"1508":1,"1522":1,"1523":1}}],["divvala",{"2":{"942":1}}],["diagnosing",{"2":{"1132":1}}],["diab",{"2":{"658":1}}],["dij",{"2":{"1124":2}}],["die=",{"2":{"1026":4}}],["dieses",{"2":{"295":1}}],["diningtable",{"2":{"945":1}}],["dinner",{"2":{"295":1}}],["did",{"2":{"295":2,"751":2}}],["diceroll",{"2":{"1414":1}}],["dickstein",{"2":{"248":1}}],["dict=true",{"2":{"137":1}}],["dict",{"2":{"71":1,"206":1,"430":1,"432":2,"433":1,"435":2,"442":4,"686":2,"757":1,"873":2,"874":1,"890":1,"1216":1}}],["directive",{"2":{"1524":1}}],["direction",{"2":{"1158":1,"1413":6}}],["direction=",{"2":{"523":2,"713":1}}],["directions==1",{"2":{"325":1}}],["directions",{"2":{"325":10,"573":1}}],["directions应该是2",{"2":{"325":2}}],["directory",{"2":{"1319":1}}],["dirname",{"2":{"206":1}}],["dir",{"2":{"206":7,"565":2,"666":3,"667":4,"669":9,"679":3,"686":9,"687":9,"692":4,"695":9,"718":2,"722":6,"725":2,"748":2,"772":2,"864":3,"866":6,"872":7,"874":4,"889":2,"890":19,"892":5,"901":2,"902":5,"904":5,"908":3,"932":9,"945":16,"947":6,"948":2,"949":9,"1006":4}}],["dir=os",{"2":{"206":1}}],["differentiable",{"2":{"981":1}}],["differential",{"2":{"980":1}}],["differentiation",{"2":{"973":1}}],["difference",{"2":{"472":1}}],["diff取期望",{"2":{"115":1}}],["diff",{"2":{"115":1}}],["dispatch",{"2":{"1309":2}}],["disp",{"2":{"1092":1}}],["display函数指定matplotlib软件包输出svg图表以获得更清晰的图像",{"2":{"981":1}}],["display",{"2":{"41":2,"357":1,"581":4,"629":4,"635":4,"912":7,"964":6,"981":3}}],["disk",{"2":{"804":1,"813":2,"1386":1}}],["discounting处理成同一个词",{"2":{"1138":1}}],["discounted",{"2":{"1138":1}}],["discounts",{"2":{"1138":1}}],["discard",{"2":{"851":12,"892":2,"904":2,"948":1,"949":2}}],["discrete中",{"2":{"160":1}}],["discrete中定义的严格卷积运算",{"2":{"130":1}}],["discrete之间的符号",{"2":{"156":1}}],["discrete",{"2":{"156":1,"1028":1}}],["discussions",{"2":{"23":4,"31":4,"37":4,"52":4,"64":4,"75":4,"83":4,"97":4,"105":4,"111":4,"118":4,"124":4,"133":4,"139":4,"144":4,"150":4,"160":1,"167":1,"178":4,"203":1,"215":4,"223":4,"227":4,"239":4,"250":4,"268":4,"280":4,"304":1,"314":1,"323":4,"328":4,"337":4,"344":4,"353":4,"359":4,"366":4,"372":3,"378":3,"384":3,"394":3,"402":3,"411":3,"416":4,"420":4,"428":4,"439":4,"444":4,"453":4,"465":4,"477":4,"485":4,"491":4,"498":4,"505":4,"511":4,"517":1,"525":3,"531":3,"537":3,"549":3,"563":3,"571":3,"580":3,"586":4,"597":4,"607":4,"621":4,"628":4,"638":4,"655":1,"662":1,"671":3,"684":3,"690":3,"697":3,"706":3,"711":1,"717":3,"724":3,"729":3,"740":3,"746":1,"753":3,"759":3,"770":3,"779":3,"788":1,"794":3,"799":3,"815":1,"823":4,"830":3,"839":3,"846":1,"856":3,"860":3,"868":3,"876":3,"885":3,"898":3,"910":3,"915":3,"929":3,"935":3,"951":3,"966":3,"972":3,"979":4,"986":4,"1004":4,"1009":4,"1015":4,"1024":4,"1038":4}}],["distortion",{"2":{"1152":1}}],["dist",{"2":{"1048":1,"1154":1}}],["distributions",{"2":{"1006":1,"1026":5}}],["distribution",{"2":{"187":1,"297":1,"616":3,"645":1,"962":1,"1006":1,"1026":6,"1028":1,"1032":2,"1033":1,"1179":1,"1184":1,"1185":1}}],["distributed描述了交换参数的不同策略",{"2":{"841":1}}],["distributed",{"2":{"284":1,"305":1,"841":1,"1352":1}}],["distribute",{"2":{"67":1,"137":1,"326":1,"332":1,"451":1,"502":1,"546":1,"547":1,"560":1,"561":1}}],["distill",{"2":{"86":1}}],["dimension",{"2":{"399":4,"991":2}}],["dimensionality",{"0":{"1155":1},"1":{"1156":1,"1157":1,"1158":1,"1159":1,"1160":1,"1161":1,"1162":1},"2":{"284":1,"618":1,"1193":1}}],["dims=2",{"2":{"473":6}}],["dims=4",{"2":{"472":1,"473":6}}],["dims",{"2":{"369":4,"375":4,"388":7,"390":4,"391":5,"392":8,"399":4,"472":7,"574":1,"575":2,"577":4,"584":1,"727":3,"848":1,"852":1,"853":2,"854":5,"863":1,"866":1,"919":1,"932":1,"964":1}}],["dim=embed",{"2":{"766":4}}],["dim=len",{"2":{"766":2}}],["dim=4",{"2":{"762":3}}],["dim=20",{"2":{"762":1}}],["dim=2",{"2":{"577":1,"675":2,"702":1,"964":1}}],["dim=",{"2":{"368":2,"375":1,"472":2,"674":2,"702":1,"854":1,"962":1}}],["dim=1",{"2":{"333":1,"375":2,"388":1,"391":1,"480":1,"487":1,"575":1,"674":2,"676":3,"682":1,"702":1,"713":1,"715":1,"737":1,"765":1,"768":1,"848":1,"851":1,"854":1,"866":1,"896":1,"908":1,"956":2,"959":1,"962":2,"1018":1,"1026":1}}],["dim=0",{"2":{"332":1,"375":1,"382":1,"472":2,"545":1,"559":1,"577":3,"848":1,"853":2,"854":3,"876":1,"1018":1,"1026":1}}],["dim",{"2":{"21":15,"28":11,"34":15,"35":12,"80":10,"91":9,"108":9,"368":2,"398":12,"762":3}}],["dark",{"2":{"1407":1}}],["darrell",{"2":{"861":1,"868":1,"936":1,"937":1}}],["daemon",{"2":{"1340":4}}],["dave",{"2":{"1187":1,"1191":1}}],["davidson",{"2":{"811":1}}],["dabdb=at",{"2":{"1086":1}}],["daughter",{"2":{"751":2}}],["daly",{"2":{"712":1}}],["dalal",{"2":{"455":1}}],["dancing",{"2":{"658":1}}],["dangerous",{"2":{"8":2}}],["danger",{"2":{"8":2}}],["dashed",{"2":{"1026":4}}],["das",{"2":{"395":1,"672":1}}],["dayan",{"2":{"300":1}}],["dahl",{"2":{"86":1}}],["datetime",{"2":{"1235":3,"1263":1}}],["date",{"2":{"1197":1,"1412":1,"1428":5}}],["dat",{"2":{"79":4,"1089":5}}],["databaseconnection",{"2":{"1427":3}}],["data函数读取训练数据标签",{"2":{"902":1}}],["data=h2",{"2":{"834":1}}],["data=h1",{"2":{"834":2}}],["data=x",{"2":{"834":1}}],["data=tf",{"2":{"436":1}}],["datacenter",{"2":{"813":1}}],["data中解压下载的文件后",{"2":{"901":1}}],["data中解压下载的文件并在其中解压缩train",{"2":{"889":1}}],["data中进行了描述",{"2":{"760":1}}],["data中用于预训练word2vec的ptb数据集相比",{"2":{"718":1}}],["dataparallel",{"2":{"726":1,"828":2,"883":2,"894":2,"906":2}}],["data`",{"2":{"725":1}}],["data模块提供了数据处理工具",{"2":{"596":3}}],["data方法访问参数",{"2":{"592":1}}],["data和bias",{"2":{"592":1}}],["dataloader",{"2":{"582":2,"583":9,"584":12,"590":3,"669":9,"679":2,"687":9,"722":6,"725":1,"777":6,"864":2,"874":6,"882":10,"892":9,"904":9,"932":6,"948":6,"949":9}}],["dataframe",{"2":{"409":4,"896":3}}],["data前缀的函数",{"2":{"321":1}}],["datasetfolder",{"2":{"872":2,"874":2,"892":2,"904":2}}],["dataset=train",{"2":{"722":1,"725":1}}],["dataset=mnist",{"2":{"583":1,"584":2}}],["dataset和",{"2":{"686":1}}],["dataset`",{"2":{"679":1}}],["dataset中描述的",{"2":{"961":1}}],["dataset中",{"2":{"952":1}}],["dataset中从wikitext",{"2":{"725":1}}],["dataset中定义的函数下载并读取snli数据集",{"2":{"679":1}}],["dataset中介绍了自然语言推断任务和snli数据集",{"2":{"672":1}}],["datasets",{"2":{"582":5,"584":5,"872":4,"874":4,"882":4,"892":4,"904":4,"1164":1}}],["dataset",{"2":{"256":1,"282":1,"286":2,"305":1,"550":1,"582":2,"583":1,"584":8,"587":1,"590":13,"613":1,"660":1,"663":2,"664":1,"668":15,"685":1,"687":12,"691":1,"718":1,"722":3,"754":2,"774":3,"777":8,"866":3,"882":4,"886":2,"892":6,"904":6,"930":1,"932":3,"947":3,"963":3}}],["data",{"0":{"2":1,"3":1},"2":{"0":3,"7":2,"21":8,"28":4,"29":4,"34":8,"35":13,"67":4,"79":52,"80":22,"81":28,"91":4,"92":4,"108":4,"109":4,"127":2,"129":4,"137":8,"175":4,"206":14,"207":1,"208":12,"209":2,"211":4,"213":5,"216":1,"225":1,"236":1,"237":1,"263":8,"271":6,"278":2,"282":1,"283":1,"284":2,"297":2,"320":5,"321":15,"324":4,"329":2,"334":1,"351":2,"361":2,"376":1,"391":1,"409":4,"414":4,"418":1,"425":1,"431":2,"432":2,"433":2,"435":10,"436":19,"437":10,"451":2,"462":2,"472":4,"473":4,"483":1,"489":1,"496":1,"503":1,"509":1,"523":3,"528":3,"534":1,"543":4,"557":4,"565":6,"568":1,"569":8,"571":1,"576":9,"581":1,"582":6,"583":4,"584":17,"589":2,"590":15,"592":2,"595":9,"599":3,"600":3,"605":4,"607":1,"609":3,"622":1,"629":1,"634":12,"666":7,"667":13,"668":2,"669":30,"679":10,"680":2,"686":19,"687":15,"692":14,"693":1,"694":3,"695":31,"698":3,"703":4,"712":3,"714":2,"718":3,"720":4,"721":2,"722":23,"725":5,"734":2,"748":10,"760":7,"767":16,"768":2,"771":1,"772":4,"776":5,"777":19,"796":3,"809":1,"827":5,"828":3,"833":2,"835":41,"836":8,"837":3,"848":9,"863":2,"864":3,"872":20,"874":8,"876":2,"879":3,"880":3,"881":2,"882":11,"883":5,"885":1,"889":10,"890":18,"891":9,"892":12,"901":9,"902":7,"903":12,"904":12,"905":6,"908":9,"926":3,"931":2,"932":40,"945":4,"947":2,"948":2,"949":8,"961":1,"966":4,"968":1,"969":2,"1011":8,"1012":2,"1046":1,"1089":1,"1090":1,"1091":1,"1141":1,"1156":1,"1169":1,"1173":2,"1252":1,"1431":3,"1434":1,"1441":1,"1445":1,"1448":2,"1453":2,"1471":2,"1490":1,"1495":1}}],["dean",{"2":{"1127":1}}],["death",{"2":{"291":4}}],["destroyed",{"2":{"1470":1}}],["design",{"0":{"1136":1},"1":{"1137":1,"1138":1,"1139":1,"1140":1,"1141":1},"2":{"1193":1}}],["desktop目录下寻找函数",{"2":{"1092":1}}],["desktop",{"2":{"1042":1,"1089":1,"1092":1,"1094":1}}],["describe",{"2":{"1392":1}}],["description",{"2":{"820":3,"1048":2,"1171":1}}],["description=",{"2":{"820":1}}],["descending=true",{"2":{"854":2}}],["descent",{"2":{"53":1,"76":1,"112":1,"287":1,"613":2,"1067":2,"1068":1,"1081":1,"1082":1,"1083":1,"1110":2,"1165":1,"1166":1,"1167":1}}],["dex=ex",{"2":{"981":1}}],["demo",{"2":{"889":2,"890":1,"901":2,"902":1,"1048":2,"1467":2,"1548":1}}],["demonstrates",{"2":{"0":1,"6":1}}],["det",{"2":{"1184":1}}],["detection函数",{"2":{"964":1}}],["detection函数来执行非极大值抑制",{"2":{"854":1}}],["detection函数来",{"2":{"854":1}}],["detection中",{"2":{"953":1}}],["detection",{"2":{"854":6,"857":1,"886":3,"911":1,"930":1,"931":2,"932":3,"944":1,"952":1,"961":1,"964":3,"1171":1,"1177":1,"1178":1,"1181":1,"1182":1,"1185":1,"1193":1}}],["detail",{"2":{"1192":1,"1478":1,"1479":7,"1481":2,"1482":1,"1483":2}}],["details所示",{"2":{"574":1}}],["details中基于bahdanau注意力实现的序列到序列的学习相比",{"2":{"404":1}}],["details中的循环神经网络编码器",{"2":{"374":1}}],["details描述了bahdanau注意力的架构",{"2":{"374":1}}],["details",{"2":{"8":4,"374":1,"574":1,"1121":1}}],["detached",{"2":{"1323":1}}],["detach",{"2":{"235":6,"236":6,"237":6,"242":4,"335":3,"392":2,"863":2,"906":2,"908":2,"922":2,"923":2,"976":3}}],["dendrite",{"2":{"1099":1}}],["dendrites",{"2":{"619":1}}],["density",{"2":{"1028":1}}],["denseblock",{"2":{"480":12,"482":4}}],["densenet一个诟病的问题是内存或显存消耗过多",{"2":{"485":1}}],["densenet的优点之一是其模型参数比resnet小",{"2":{"485":1}}],["densenet的主要构建模块是稠密块和过渡层",{"2":{"484":1}}],["densenet则使用过渡层来减半高和宽",{"2":{"482":1}}],["densenet使用的是4个稠密块",{"2":{"482":1}}],["densenet使用了resnet改良版的",{"2":{"480":1}}],["densenet首先使用同resnet一样的单卷积层和最大汇聚层",{"2":{"482":1}}],["densenet模型",{"0":{"482":1}}],["densenet所示",{"2":{"479":1}}],["densenet这个名字由变量之间的",{"2":{"479":1}}],["densenet输出是连接",{"2":{"479":1}}],["densenet",{"0":{"478":1},"1":{"479":1,"480":1,"481":1,"482":1,"483":1,"484":1,"485":1},"2":{"478":1,"479":3,"484":1,"492":2}}],["dense类本身就是block的子类",{"2":{"422":1}}],["dense2",{"2":{"405":8}}],["dense1",{"2":{"405":8,"432":1}}],["dense",{"2":{"67":6,"68":1,"81":2,"136":7,"174":3,"176":6,"210":2,"225":4,"263":2,"278":2,"325":6,"350":4,"369":6,"375":10,"382":8,"405":4,"408":10,"413":2,"414":6,"418":4,"422":4,"423":4,"424":4,"425":19,"429":4,"433":5,"435":6,"436":2,"437":6,"442":4,"451":2,"461":6,"473":6,"474":6,"479":1,"482":14,"488":2,"502":2,"508":6,"574":10,"591":2,"592":1,"618":1,"623":2,"674":2,"676":1,"688":1,"702":1,"713":1,"736":2,"737":1,"738":1,"819":7,"821":2,"826":1,"893":1,"905":2}}],["denoising",{"2":{"924":1}}],["department",{"2":{"1425":8}}],["depth`",{"2":{"1422":1}}],["depth",{"2":{"1422":4}}],["depth=y",{"2":{"633":2}}],["depth=pred",{"2":{"575":1}}],["deployment",{"0":{"1383":1,"1390":1},"2":{"1390":2,"1392":2}}],["deploy",{"2":{"1349":1}}],["dependencies",{"2":{"1315":1}}],["dependence",{"2":{"1034":1}}],["dependent",{"2":{"1106":1}}],["deposit",{"2":{"525":1,"732":1,"754":1}}],["derivative中",{"2":{"981":1}}],["derivative中的导数f",{"2":{"981":1}}],["derivative",{"2":{"981":1,"982":1,"1109":1}}],["derivatives",{"2":{"647":1}}],["der",{"2":{"478":1,"485":1}}],["dehghani",{"2":{"411":1}}],["decrement",{"2":{"1471":4,"1491":1,"1493":1}}],["decimal128",{"2":{"1197":1}}],["deciding",{"2":{"1129":1,"1135":1}}],["decision",{"2":{"298":1,"299":1,"1108":2}}],["decorator",{"0":{"1244":1},"2":{"1244":2}}],["decomposition",{"2":{"1159":1}}],["decomposableattention",{"2":{"677":6,"680":3}}],["decode",{"2":{"692":1}}],["decoder中",{"2":{"572":1}}],["decoderblock",{"2":{"408":14}}],["decoder",{"2":{"375":16,"376":2,"404":1,"408":7,"409":8,"532":5,"534":8,"535":20,"550":1,"574":19,"576":2,"577":12,"702":6,"713":7}}],["dec",{"2":{"376":3,"408":16,"409":47,"535":16,"576":8,"577":28}}],["decandia",{"2":{"844":1}}],["decade中",{"2":{"445":1}}],["decade",{"2":{"300":2}}],["decay分别设置为2和0",{"2":{"907":1}}],["decay分别设置为4和0",{"2":{"895":1}}],["decay=5e",{"2":{"961":2}}],["decay=0",{"2":{"874":4}}],["decay=wd",{"2":{"278":1,"865":2,"894":2,"906":2}}],["decay=weight",{"2":{"210":1}}],["decay指定weight",{"2":{"278":1}}],["decay超参数",{"2":{"278":2}}],["decay",{"2":{"49":1,"114":2,"168":1,"170":1,"204":1,"210":9,"211":2,"212":2,"213":3,"269":1,"270":1,"278":2,"894":6,"895":6,"896":3,"898":1,"906":6,"907":6,"908":3,"910":1,"927":4}}],["deeper",{"2":{"487":1}}],["deeplearning",{"2":{"294":2}}],["deep",{"2":{"281":1,"285":1,"298":1,"316":8,"325":1,"526":3,"527":3,"550":1,"665":1,"1463":2,"1465":1,"1466":1}}],["degree",{"2":{"262":4}}],["de",{"2":{"205":2,"300":1,"519":1,"937":1}}],["delay",{"2":{"1520":2}}],["delete",{"2":{"1392":1}}],["del",{"2":{"841":1}}],["della",{"2":{"564":2}}],["delimiter=",{"2":{"79":4}}],["delta^",{"2":{"1121":2}}],["delta",{"2":{"21":32,"472":2,"1121":3}}],["defineasynccomponent",{"2":{"1523":2}}],["defineemits",{"2":{"1500":2}}],["defineexpose",{"2":{"1468":2}}],["definestore",{"2":{"1490":4,"1491":2,"1493":2,"1495":2}}],["definecomponent",{"2":{"1471":2}}],["defineconfig",{"2":{"1454":2}}],["defineprops",{"2":{"1469":4,"1497":1,"1500":2,"1501":1}}],["defined",{"2":{"679":1,"725":1,"864":1,"883":2,"945":2,"947":1}}],["def和",{"2":{"998":1}}],["def中定义的矩阵a∈rm×n和向量x∈rn",{"2":{"998":1}}],["def中定义",{"2":{"994":1}}],["def中的转置是一个形状为n×m的矩阵",{"2":{"992":1}}],["def中的任何一对",{"2":{"400":1}}],["def那样",{"2":{"992":1}}],["defers",{"2":{"417":1}}],["deferred",{"2":{"417":1,"421":1,"592":2}}],["def",{"2":{"21":8,"27":2,"28":7,"34":8,"35":3,"54":6,"56":2,"57":8,"59":7,"67":7,"68":2,"70":2,"71":4,"72":3,"79":4,"80":8,"81":6,"87":8,"88":1,"91":7,"99":4,"108":8,"113":5,"114":2,"120":2,"121":1,"122":1,"126":2,"127":9,"136":1,"137":11,"141":4,"146":2,"172":4,"174":7,"176":1,"206":3,"210":9,"211":2,"213":1,"218":3,"219":3,"220":1,"225":1,"263":6,"273":3,"274":3,"275":3,"278":3,"320":2,"321":6,"325":12,"331":7,"332":18,"333":3,"334":3,"335":7,"350":9,"357":1,"361":1,"362":1,"363":7,"364":1,"368":4,"369":8,"370":8,"375":18,"382":16,"386":4,"391":8,"398":9,"405":8,"406":8,"407":16,"408":24,"413":8,"414":9,"418":1,"423":8,"424":8,"425":16,"433":7,"435":8,"436":4,"442":8,"446":7,"461":1,"472":14,"473":1,"474":1,"480":13,"481":4,"482":3,"487":8,"488":6,"494":4,"495":1,"501":8,"502":5,"507":4,"508":3,"533":8,"534":12,"535":8,"544":11,"545":6,"558":11,"559":6,"565":3,"566":2,"568":2,"569":1,"573":8,"574":12,"575":8,"576":5,"577":4,"578":1,"582":4,"583":3,"584":3,"590":3,"599":2,"600":2,"602":1,"603":1,"604":3,"615":6,"616":1,"623":2,"631":2,"632":1,"633":3,"634":9,"635":9,"636":1,"667":2,"668":12,"669":3,"674":8,"675":6,"676":6,"677":6,"679":1,"681":1,"682":3,"686":2,"687":18,"688":6,"692":1,"695":3,"699":3,"702":8,"713":8,"715":3,"718":1,"720":2,"721":2,"722":15,"725":1,"726":5,"727":2,"734":7,"736":6,"737":6,"738":6,"748":4,"750":3,"751":1,"757":3,"763":2,"765":5,"767":4,"768":2,"772":1,"773":3,"774":1,"775":3,"776":1,"777":9,"796":3,"797":2,"816":2,"817":5,"819":4,"820":3,"821":2,"826":6,"827":1,"828":3,"834":3,"835":4,"836":4,"837":4,"848":5,"849":3,"851":3,"852":4,"854":7,"858":3,"863":2,"864":1,"865":2,"866":4,"874":2,"878":1,"882":2,"883":11,"890":5,"893":5,"894":2,"902":1,"905":5,"906":2,"912":2,"919":6,"920":6,"922":2,"923":3,"924":1,"925":1,"926":8,"927":2,"932":15,"945":9,"946":3,"947":15,"949":3,"954":3,"955":2,"956":7,"957":2,"958":2,"959":10,"962":8,"964":4,"966":4,"968":1,"970":2,"977":3,"981":10,"990":1,"992":1,"1021":1,"1085":1,"1107":1,"1109":1,"1117":1,"1215":1,"1244":2,"1252":2,"1254":2,"1255":2}}],["default>",{"2":{"1523":1}}],["default=",{"2":{"1508":2}}],["defaultdict",{"2":{"578":1,"757":1}}],["default",{"2":{"7":2,"472":2,"734":1,"848":2,"968":1,"1364":1,"1444":1,"1445":1,"1451":1,"1454":2,"1471":3,"1474":1,"1479":1,"1499":1,"1520":1}}],["devtools",{"2":{"1527":1,"1530":2}}],["devops",{"0":{"1372":1},"2":{"1354":1,"1372":1,"1543":1}}],["development",{"2":{"1444":1}}],["develop",{"2":{"1325":1}}],["developing",{"2":{"1181":1}}],["devlin",{"2":{"726":1,"733":1}}],["deviation",{"2":{"616":1,"1036":1}}],["devices=d2l",{"2":{"883":3}}],["devices=devices",{"2":{"686":2}}],["devices",{"2":{"446":15,"680":3,"681":6,"686":5,"688":3,"702":3,"704":3,"713":1,"715":3,"726":19,"796":10,"827":8,"828":6,"835":1,"836":20,"837":24,"865":7,"866":2,"874":7,"883":20,"893":1,"894":10,"895":6,"896":6,"905":11,"906":13,"907":8,"908":8}}],["device=row",{"2":{"964":1}}],["device=boxes",{"2":{"854":1}}],["device=try",{"2":{"448":2,"451":1}}],["device=x",{"2":{"408":1,"575":1}}],["device=devices",{"2":{"727":3,"796":2,"866":1}}],["device=device",{"2":{"325":3,"331":3,"332":1,"333":2,"335":1,"544":3,"545":1,"558":3,"559":2,"576":1,"577":3,"790":5,"848":4,"851":1,"852":2,"854":1}}],["device=d2l",{"2":{"67":1,"682":2,"715":1,"767":3,"835":1}}],["device=none",{"2":{"137":3}}],["device",{"2":{"67":19,"68":3,"71":3,"72":3,"73":3,"137":38,"325":1,"326":12,"331":2,"332":11,"333":3,"335":22,"376":3,"398":1,"408":1,"409":9,"445":2,"446":34,"447":2,"451":3,"472":4,"523":7,"528":4,"529":1,"544":2,"545":2,"546":8,"547":7,"558":2,"559":2,"560":8,"561":7,"575":1,"576":13,"577":3,"578":1,"726":1,"767":6,"790":3,"796":9,"797":3,"828":1,"835":8,"836":3,"837":34,"848":3,"851":2,"852":5,"854":4,"883":1,"894":1,"906":1,"919":1,"920":8,"926":3,"927":14,"961":2,"963":8,"964":3}}],["dev",{"2":{"15":1,"1053":1,"1323":2,"1329":3}}],["s定理",{"2":{"1148":1}}],["sz",{"2":{"1089":5}}],["szegedy",{"2":{"466":1,"486":1,"491":4}}],["svn",{"2":{"1318":2}}],["svm一起使用这些方法来提高学习算法",{"2":{"1148":1}}],["svm仍然被广泛认为是一种最强大的学习算法",{"2":{"1148":1}}],["svm具有的优化问题",{"2":{"1148":1}}],["svm",{"2":{"1148":1}}],["svd",{"2":{"1061":1,"1159":1,"1160":2}}],["svg",{"2":{"41":2,"357":1,"581":4,"635":1,"981":5}}],["sdk",{"0":{"1048":1},"2":{"1048":5}}],["ssl",{"0":{"1370":1},"2":{"1284":1,"1370":5,"1371":1}}],["sse",{"2":{"1047":1}}],["ssd顶部的多尺度特征图较小",{"2":{"953":1}}],["ssd描述了单发多框检测模型的设计",{"2":{"953":1}}],["ssd中",{"2":{"959":1}}],["ssd中的多尺度特征块",{"2":{"959":1}}],["ssd中不同块的实施细节",{"2":{"953":1}}],["ssd中描述的单发多框检测之外",{"2":{"936":1}}],["ssd中实现",{"2":{"913":1}}],["ssd中设计一个基于锚框的目标检测模型",{"2":{"847":1}}],["ssd控制器和usb这些外围设备要么是芯片组的一部分",{"2":{"807":1}}],["ssd",{"0":{"952":1},"1":{"953":1,"954":1,"955":1,"956":1,"957":1,"958":1,"959":1,"960":1,"961":1,"962":1,"963":1,"964":1,"965":1,"966":1},"2":{"805":1,"813":12,"886":1,"913":1,"952":2,"953":1}}],["s=",{"2":{"912":3}}],["s=0",{"2":{"848":5}}],["s=λ2",{"2":{"162":1}}],["s进行双向传输",{"2":{"842":1}}],["s到1gb",{"2":{"841":1}}],["s到100gb",{"2":{"801":1,"802":1}}],["skills",{"2":{"1196":1}}],["skipgram",{"2":{"742":6,"744":1}}],["skip",{"0":{"783":1},"1":{"784":1},"2":{"707":4,"709":1,"741":1,"763":5,"767":3,"782":1,"783":4,"784":4}}],["skewed",{"2":{"1139":2}}],["skylake所示",{"2":{"810":1}}],["skylake消费级四核cpu",{"2":{"807":1}}],["skylake描述了intel",{"2":{"807":1}}],["skylake",{"2":{"807":1}}],["s之间",{"2":{"802":1}}],["s的速度运行",{"2":{"842":1}}],["s的带宽",{"2":{"802":1,"840":3}}],["s的数据传输速率",{"2":{"812":1}}],["s的数据传输",{"2":{"810":1}}],["s的数据",{"2":{"801":1}}],["s不等",{"2":{"801":1}}],["slot=",{"2":{"1508":1}}],["slot>",{"2":{"1506":2,"1507":2,"1508":1}}],["slot",{"0":{"1505":1},"1":{"1506":1,"1507":1,"1508":1},"2":{"1507":3,"1508":2,"1523":2}}],["sliding",{"2":{"1172":1}}],["slices",{"2":{"583":1,"584":2,"590":1}}],["slice",{"2":{"211":1}}],["sl层",{"2":{"1120":1}}],["sl=4",{"2":{"1121":1}}],["sl=k",{"2":{"1120":1}}],["sl=0",{"2":{"1120":1}}],["sl代表最后一层中处理单元的个数",{"2":{"1120":1}}],["sl表示输出层神经元个数",{"2":{"1120":1}}],["sleep",{"2":{"675":1}}],["sn是标准差",{"2":{"1082":1}}],["sn",{"2":{"848":1}}],["sn和许多宽高比",{"2":{"848":1}}],["snappy",{"2":{"813":1}}],["snlibertdataset",{"2":{"687":9}}],["snli函数来获取数据迭代器和词表",{"2":{"669":1}}],["snli函数和snlidataset类来下载snli数据集",{"2":{"669":1}}],["snlidataset",{"2":{"668":3,"669":6,"679":2}}],["snli以仅提取数据集的一部分",{"2":{"667":1}}],["snli",{"0":{"666":1},"1":{"667":1,"668":1,"669":1},"2":{"666":14,"667":5,"669":13,"670":1,"679":6,"682":4,"687":9}}],["sneaker",{"2":{"582":2}}],["smtplib",{"2":{"1297":1}}],["smooth",{"2":{"966":5}}],["smoothing",{"2":{"316":1,"491":1}}],["smola",{"2":{"840":1}}],["small",{"2":{"509":4,"686":10,"690":1,"1407":1}}],["smith",{"2":{"467":1,"659":1}}],["smi命令列出计算机上所有可用的gpu",{"2":{"831":1}}],["smi命令查看显存使用情况",{"2":{"448":1}}],["smi命令来",{"2":{"445":1}}],["smi",{"2":{"445":1}}],["src=",{"2":{"1444":1,"1471":1}}],["src",{"2":{"376":4,"409":10,"567":2,"568":2,"569":8,"576":2,"577":44,"578":2,"1490":2,"1499":1}}],["srivastava",{"2":{"170":1,"300":1}}],["sym",{"2":{"1404":1}}],["symmetric",{"2":{"992":1}}],["symbol模块不能支持某些函数",{"2":{"821":1}}],["symbolic",{"2":{"817":1}}],["symbol所示",{"2":{"801":1}}],["symbol",{"2":{"801":1,"821":1,"1404":2}}],["symbols函数来合并最频繁的连续符号对以产生新符号",{"2":{"757":1}}],["symbols",{"2":{"757":15}}],["sync",{"2":{"1525":1}}],["sync优化到了v",{"2":{"1496":1}}],["synchronization",{"0":{"842":1}}],["synchronize",{"2":{"790":2,"796":12,"797":6,"837":2,"843":1}}],["synchronous",{"2":{"792":1}}],["synsets",{"2":{"896":1,"908":1}}],["synonyms",{"2":{"747":1}}],["synonyms中的实验",{"2":{"731":1}}],["synapse",{"2":{"619":1}}],["synthesizedimage",{"2":{"926":9}}],["synthetic",{"2":{"271":2,"589":1,"599":3}}],["syntax",{"0":{"7":1},"2":{"7":1}}],["sysoev",{"2":{"1359":1}}],["sys",{"2":{"581":2,"583":1,"1263":1}}],["system",{"0":{"1136":1},"1":{"1137":1,"1138":1,"1139":1,"1140":1,"1141":1},"2":{"294":1,"1181":1,"1193":1}}],["systems",{"0":{"1186":1},"1":{"1187":1,"1188":1,"1189":1,"1190":1,"1191":1,"1192":1},"2":{"294":1,"813":2,"1193":1}}],["species",{"2":{"1416":3}}],["spec=",{"2":{"820":1}}],["spec",{"2":{"820":2,"1389":1,"1390":2,"1391":1}}],["speed",{"2":{"335":8}}],["speech",{"2":{"295":2,"315":1}}],["splitting中比较了多个gpu上不同的并行方式",{"2":{"832":1}}],["splitting",{"2":{"832":1}}],["split=false",{"2":{"681":2,"726":1}}],["splitext",{"2":{"206":1}}],["split",{"2":{"206":1,"362":1,"376":3,"409":1,"566":4,"577":4,"578":2,"667":1,"681":4,"688":1,"715":3,"718":2,"726":1,"748":1,"757":1,"772":2,"827":4,"828":1,"836":12,"837":3,"876":3,"883":7,"890":2,"894":2,"905":1,"906":1,"908":3,"945":3,"1460":2}}],["spa",{"2":{"1526":1}}],["span",{"2":{"1471":1}}],["span>",{"2":{"1460":2,"1471":1}}],["spacy",{"2":{"717":6}}],["space",{"2":{"565":3,"989":1,"1027":2}}],["space和troll2就因为这个原因而臭名昭著的",{"2":{"345":1}}],["sparse",{"2":{"220":1}}],["sparsecategoricalcrossentropy",{"2":{"67":1,"137":1,"175":1,"225":1,"335":1,"624":1}}],["spatial",{"2":{"152":1,"938":3}}],["s3510",{"2":{"813":3}}],["s3",{"2":{"206":1,"718":1,"848":1}}],["s取决于模型参数w",{"2":{"165":1}}],["swimming",{"2":{"1422":1}}],["swimmable",{"2":{"1422":2}}],["swim",{"2":{"1422":2}}],["switch",{"2":{"1329":1,"1413":1}}],["swarm",{"0":{"1348":1,"1349":1,"1351":1,"1395":1},"2":{"1348":1,"1349":1,"1351":1,"1355":1,"1395":1}}],["swapaxes",{"2":{"375":4,"573":1,"574":2,"763":1}}],["swords",{"2":{"1191":1}}],["sw",{"2":{"124":1,"142":4,"150":1}}],["s累加了过去的1",{"2":{"108":1}}],["suspense>",{"2":{"1523":2}}],["suspense",{"0":{"1523":1},"2":{"1441":1,"1523":1}}],["success",{"2":{"1412":1}}],["such",{"2":{"660":1}}],["surf",{"2":{"455":1}}],["suis",{"2":{"376":2,"409":2,"578":2}}],["sukhbaatar",{"2":{"300":1}}],["sun",{"2":{"198":1,"301":1}}],["suppression",{"2":{"854":1}}],["support",{"2":{"135":1,"454":1,"1142":1,"1143":1,"1193":1,"1444":1}}],["supervised",{"2":{"289":3,"754":1,"1060":1,"1182":1}}],["super",{"2":{"127":4,"174":3,"325":4,"369":4,"370":4,"375":5,"382":4,"391":4,"398":4,"405":4,"406":4,"407":8,"408":8,"413":4,"414":4,"423":4,"424":3,"425":8,"442":4,"472":5,"480":5,"481":1,"487":4,"501":4,"502":1,"533":4,"534":4,"535":4,"573":4,"574":4,"575":4,"674":3,"675":3,"676":3,"677":3,"688":3,"702":3,"713":3,"734":3,"736":3,"737":3,"738":3,"765":2,"821":1,"893":1,"926":3,"959":3,"1417":1,"1425":1}}],["sutskever实现了可以在gpu硬件上运行的深度卷积神经网络时",{"2":{"457":1}}],["sutskever和geoff",{"2":{"455":1}}],["sutskever",{"2":{"86":1,"455":2,"572":2,"773":1,"775":1,"782":1,"788":1,"832":1}}],["sumstore",{"2":{"1490":2}}],["sum变化了",{"2":{"1462":1}}],["sum^m",{"2":{"1000":1}}],["sum^n",{"2":{"1000":2}}],["summary",{"2":{"433":1,"1176":1}}],["sum",{"2":{"67":1,"120":2,"122":1,"126":2,"129":6,"137":4,"211":6,"263":3,"271":1,"274":4,"275":2,"334":8,"350":2,"392":8,"425":8,"568":1,"576":9,"605":2,"615":3,"631":8,"634":2,"635":8,"676":6,"699":3,"702":2,"709":1,"711":1,"726":11,"750":6,"765":2,"767":8,"768":6,"773":3,"774":1,"791":1,"827":1,"837":2,"883":22,"894":3,"905":14,"906":8,"925":1,"927":6,"962":6,"974":4,"975":3,"976":4,"977":4,"995":55,"996":15,"997":4,"1000":5,"1004":1,"1018":2,"1026":4,"1033":1,"1061":1,"1081":1,"1090":3,"1109":1,"1117":2,"1120":2,"1262":1,"1462":4,"1470":3,"1471":6,"1490":3,"1491":6,"1492":2,"1493":3}}],["subprocess",{"2":{"789":3,"1297":1}}],["subplot命令",{"2":{"1091":1}}],["subplot",{"2":{"102":2}}],["subplots",{"2":{"41":2,"357":1,"582":3,"635":1}}],["subword",{"2":{"754":1}}],["sublayers",{"2":{"702":1,"828":1}}],["sublayer方法会将layer添加到self",{"2":{"424":1}}],["sublayer",{"2":{"407":1,"408":1,"424":2,"433":1,"734":1,"826":6,"862":2}}],["substring",{"2":{"1420":5}}],["subsampled",{"2":{"773":5,"777":6}}],["subsample",{"2":{"773":2,"777":3}}],["subs",{"2":{"578":4}}],["subspaces",{"2":{"380":1}}],["subseq",{"2":{"631":2}}],["subseqs",{"2":{"320":3}}],["subsec",{"2":{"58":1,"99":1,"103":1,"119":1,"121":1,"131":1,"137":1,"192":1,"209":1,"220":1,"229":1,"231":1,"232":1,"270":1,"280":1,"307":1,"312":2,"330":1,"335":1,"339":1,"341":1,"342":1,"403":1,"404":1,"534":1,"540":1,"602":1,"610":1,"645":1,"662":1,"687":1,"699":1,"718":1,"720":1,"721":2,"722":1,"727":1,"741":1,"744":1,"750":1,"763":2,"765":2,"856":2,"893":1,"913":2,"915":1,"957":1,"962":1,"972":1,"980":1,"1038":1}}],["submitting",{"2":{"1094":1}}],["submit2",{"2":{"213":1}}],["submit2中所示",{"2":{"213":1}}],["submit",{"2":{"213":1}}],["submission",{"2":{"213":6,"889":1,"896":4,"901":1,"908":3}}],["sub",{"2":{"80":2,"361":1,"424":6,"604":1,"667":3}}],["subject",{"2":{"47":1,"500":1}}],["sofa",{"2":{"945":1}}],["soft",{"2":{"655":1}}],["softmax中加粗的路径",{"2":{"709":1}}],["softmax中给定词wc生成词w3的条件概率",{"2":{"709":1}}],["softmax中的条件概率近似为",{"2":{"709":1}}],["softmax中的l",{"2":{"709":1}}],["softmax中说明的数据结构",{"2":{"709":1}}],["softmax中引入的交叉熵损失函数",{"2":{"633":1}}],["softmax是对上面介绍的映射的误称",{"2":{"655":1}}],["softmax及其导数",{"0":{"647":1}}],["softmax运算获取一个向量并将其映射为概率",{"2":{"654":1}}],["softmax运算不会改变未规范化的预测o之间的大小次序",{"2":{"643":1}}],["softmax运算",{"0":{"643":1}}],["softmaxreg",{"2":{"641":1}}],["softmaxreg来描述这个计算过程",{"2":{"641":1}}],["softmaxreg中所示的softmax回归的模型架构",{"2":{"229":1}}],["softmax回归适用于分类问题",{"2":{"654":1}}],["softmax回归是一个线性模型",{"2":{"643":1}}],["softmax回归也是一个单层神经网络",{"2":{"641":1}}],["softmax回归",{"0":{"639":1},"1":{"640":1,"641":1,"642":1,"643":1,"644":1,"645":1,"646":1,"647":1,"648":1,"649":1,"650":1,"651":1,"652":1,"653":1,"654":1,"655":1}}],["softmax回归的矢量计算表达式为",{"2":{"644":1}}],["softmax回归的训练",{"2":{"635":1}}],["softmax回归的从零开始实现",{"0":{"629":1},"1":{"630":1,"631":1,"632":1,"633":1,"634":1,"635":1,"636":1,"637":1,"638":1}}],["softmax回归的输出层是一个全连接层",{"2":{"623":1}}],["softmax回归的简洁实现",{"0":{"622":1},"1":{"623":1,"624":1,"625":1,"626":1,"627":1,"628":1}}],["softmax所述",{"2":{"623":1}}],["softmaxceloss",{"2":{"575":1,"726":1}}],["softmaxcrossentropyloss",{"2":{"67":1,"137":1,"175":1,"220":1,"225":1,"335":1,"624":1,"681":1,"688":1,"704":1,"715":1,"736":1,"828":1,"834":1,"865":1,"874":1,"883":1,"893":1,"905":1,"962":1}}],["softmax函数给出了一个向量y^",{"2":{"646":1}}],["softmax函数能够将未规范化的预测变换为非负数并且总和为1",{"2":{"643":1}}],["softmax函数y^j=exp⁡",{"2":{"624":1}}],["softmax函数",{"2":{"368":1}}],["softmax操作用于输出一个概率分布作为注意力权重",{"2":{"368":1}}],["softmax操作前",{"2":{"232":1}}],["softmax",{"2":{"135":1,"137":3,"191":1,"216":1,"220":2,"221":1,"225":1,"228":3,"232":1,"291":1,"335":2,"368":21,"369":4,"370":6,"388":4,"391":4,"397":1,"587":3,"622":3,"624":2,"626":1,"629":1,"631":5,"632":1,"639":1,"643":2,"644":3,"647":2,"650":1,"651":1,"674":6,"707":1,"709":3,"711":1,"783":1,"784":1,"908":3,"964":3}}],["son",{"2":{"751":3,"783":4,"785":3}}],["song",{"2":{"300":1}}],["solid",{"2":{"744":1,"805":1}}],["solution",{"2":{"612":1,"1444":1}}],["so",{"2":{"704":2,"715":2}}],["socket",{"2":{"813":1}}],["social",{"2":{"634":1}}],["socher",{"2":{"395":1,"403":1,"743":1,"744":1,"746":1}}],["source和target",{"2":{"566":1}}],["source",{"2":{"565":1,"566":8,"567":1,"568":1,"569":3,"1273":1,"1420":5}}],["sorter",{"2":{"392":1}}],["sorteddatainterface",{"2":{"1204":1}}],["sorted",{"2":{"363":1,"388":8,"392":7,"721":1,"854":12,"896":9,"908":3}}],["sort",{"2":{"386":4,"896":3}}],["sohl",{"2":{"248":1}}],["somevalue",{"2":{"1399":2}}],["something",{"2":{"658":1,"1261":1}}],["some",{"2":{"0":1,"6":1,"660":1,"754":1}}],["saturation",{"2":{"880":1}}],["saturation=0",{"2":{"880":7,"903":3}}],["sata",{"2":{"813":6}}],["sa",{"2":{"698":3,"712":2}}],["say",{"2":{"660":1,"1244":2,"1254":1}}],["sanity",{"2":{"1134":1}}],["sande",{"2":{"937":1}}],["sandal",{"2":{"582":2}}],["sandholm",{"2":{"301":1}}],["santurkar",{"2":{"475":1}}],["santos",{"2":{"395":1,"403":1}}],["san",{"2":{"342":1,"1445":1,"1451":1,"1455":1,"1460":1}}],["salary",{"2":{"1425":9}}],["salimans",{"2":{"732":1}}],["sally",{"2":{"295":1}}],["saleprice",{"2":{"209":1,"213":2}}],["samuel的定义可以回溯到50年代",{"2":{"1059":1}}],["samuel",{"2":{"1059":1}}],["sampling中负采样损失函数的定义",{"2":{"765":1}}],["sampling",{"2":{"319":1,"662":1,"708":1,"775":7,"1026":1}}],["samplesubmission",{"2":{"889":1}}],["sample",{"2":{"284":1,"609":1,"708":6,"889":1,"901":1,"957":7,"958":3,"959":5,"1026":12,"1027":1}}],["same",{"2":{"67":1,"136":1,"141":2,"142":1,"461":4,"480":1,"482":2,"487":3,"488":6,"495":3,"501":2,"502":4,"507":1,"813":1}}],["saddle",{"2":{"102":3}}],["saddlepoint",{"2":{"48":1}}],["save命令做了什么",{"2":{"1089":1}}],["save是一个特殊的标记",{"2":{"981":1}}],["save的实际功能",{"2":{"821":1}}],["saved",{"2":{"821":2}}],["save和load函数可用于张量对象的文件读写",{"2":{"443":1}}],["save要求将要保存的变量作为输入",{"2":{"441":1}}],["save",{"2":{"57":5,"79":8,"80":4,"81":4,"99":2,"126":2,"137":8,"206":4,"208":2,"263":3,"320":1,"321":5,"325":4,"332":4,"333":4,"334":4,"335":8,"357":1,"361":2,"362":1,"363":2,"364":1,"368":4,"369":4,"370":4,"375":1,"382":12,"398":4,"405":4,"406":4,"407":8,"441":12,"442":4,"446":8,"501":4,"533":4,"534":4,"535":4,"565":3,"566":2,"568":2,"569":1,"573":4,"575":7,"576":4,"577":12,"578":1,"582":4,"583":3,"584":4,"590":4,"599":2,"602":1,"603":1,"604":4,"615":1,"634":6,"635":7,"636":1,"666":3,"667":1,"668":3,"669":3,"681":1,"682":3,"692":2,"695":3,"715":3,"718":2,"720":2,"721":2,"722":9,"726":3,"734":4,"736":3,"737":3,"738":3,"748":5,"772":2,"773":1,"774":1,"775":3,"776":1,"777":3,"820":1,"821":3,"826":3,"827":1,"836":3,"848":4,"849":3,"851":3,"852":4,"854":7,"858":3,"872":1,"883":6,"889":1,"890":4,"901":1,"931":1,"932":9,"945":12,"946":3,"947":3,"949":3,"981":4,"1089":2}}],["sachan",{"2":{"32":1,"35":1}}],["sb",{"2":{"45":1}}],["s^t=st1−β2t",{"2":{"33":1}}],["sgd函数",{"2":{"335":1,"635":1}}],["sgd一节中",{"2":{"84":1}}],["sgd一节中的实验相比",{"2":{"28":1}}],["sgd比较详细地讨论了这一点",{"2":{"66":1}}],["sgd",{"2":{"65":3,"67":4,"68":4,"71":3,"72":3,"73":3,"76":1,"80":13,"81":4,"91":5,"92":3,"112":1,"113":4,"114":2,"115":10,"137":4,"175":4,"176":4,"221":3,"225":4,"263":4,"275":4,"278":4,"335":7,"392":4,"594":5,"604":4,"605":4,"625":4,"635":2,"828":3,"831":1,"837":3,"865":3,"874":5,"894":2,"906":2,"961":3}}],["sgd中一次处理一个训练样本来取得进展",{"2":{"76":1}}],["sgd中我们则分析了性能保证",{"2":{"66":1}}],["sgd中",{"2":{"32":2}}],["s2>",{"2":{"1507":1}}],["s2s",{"2":{"374":2,"404":1,"513":15}}],["s2",{"2":{"27":4,"57":11,"87":4,"108":5,"113":2,"848":1,"1507":1}}],["s1>",{"2":{"1507":1}}],["s1和s2是稍后将使用的内部状态变量",{"2":{"57":2}}],["s1",{"2":{"27":4,"57":11,"87":4,"108":5,"113":2,"848":3,"1507":1}}],["scikit",{"2":{"1297":1}}],["scaling",{"2":{"1082":1}}],["scala和perl",{"2":{"821":1}}],["scala和c++",{"2":{"790":1}}],["scalar=s",{"2":{"966":3}}],["scalar",{"2":{"791":1,"966":8,"989":1,"1073":1,"1120":1}}],["scale乘以0",{"2":{"938":1}}],["scale",{"2":{"467":1,"470":1,"582":6,"834":11,"848":4,"853":2,"854":2,"912":6,"1163":1,"1193":1}}],["scaleddotproductattention",{"2":{"370":1}}],["scaled",{"2":{"370":1}}],["scale=",{"2":{"879":3,"891":3,"903":3}}],["scale=2",{"2":{"866":3,"933":3}}],["scale=scale",{"2":{"834":4,"878":1}}],["scale=1",{"2":{"273":1,"582":3,"872":1,"878":1}}],["scale=0",{"2":{"80":1,"173":3,"217":2,"262":1,"331":1,"544":1,"558":1,"882":3,"938":3}}],["scatter",{"2":{"599":1,"836":3}}],["schedule",{"2":{"1309":1,"1315":1}}],["scheduler=none",{"2":{"67":2}}],["scheduler",{"2":{"65":1,"66":2,"67":13,"68":7,"70":2,"71":20,"72":9,"73":9,"894":5,"906":5,"927":6,"1376":1,"1378":1}}],["schema",{"2":{"1048":1,"1195":1,"1205":2}}],["schuster",{"2":{"521":1,"722":1}}],["school",{"2":{"1491":1,"1493":3}}],["scholkopf",{"2":{"349":1}}],["schon",{"2":{"295":1}}],["schmidhuber",{"2":{"300":1,"455":1,"521":1,"538":1,"551":1}}],["score",{"2":{"515":2,"578":3,"964":9,"1140":1,"1215":1,"1223":2}}],["scores",{"2":{"369":8,"370":8,"854":6,"1401":1}}],["scores的形状",{"2":{"369":4}}],["scoring",{"2":{"367":4,"374":1,"379":1,"381":1}}],["scope",{"2":{"67":1,"137":1,"326":1,"332":1,"335":2,"451":1,"473":1,"488":1,"509":1,"546":1,"547":1,"560":1,"561":1}}],["sconvergingatlr=5",{"2":{"21":1}}],["scroll",{"2":{"1414":1}}],["scratch的例子中",{"2":{"624":1}}],["scratch不同",{"2":{"590":1}}],["scratch完全相同",{"2":{"546":1}}],["scratch模型的方式有三个不同之处",{"2":{"335":1}}],["scratch类似",{"2":{"325":1}}],["scratch中我们从头实现线性回归",{"2":{"639":1}}],["scratch中一样",{"2":{"622":1}}],["scratch中实现线性回归时",{"2":{"591":1}}],["scratch中使用data",{"2":{"590":1}}],["scratch中使用的时间机器数据集",{"2":{"543":1}}],["scratch中类似",{"2":{"589":1}}],["scratch中定义的",{"2":{"635":1}}],["scratch中定义的init",{"2":{"545":1}}],["scratch中定义的train",{"2":{"137":2}}],["scratch中讨论的单层实现",{"2":{"531":1}}],["scratch中的线性回归实现",{"2":{"635":1}}],["scratch中的实验相同",{"2":{"557":1}}],["scratch中的",{"2":{"335":1,"588":1}}],["scratch中分离梯度时",{"2":{"309":1}}],["scratch中",{"2":{"306":1,"326":1,"517":1,"560":1,"588":1,"626":1,"781":1}}],["scratch中描述的",{"2":{"137":1}}],["scratch中处理梯度截断时",{"2":{"50":1}}],["scratch",{"2":{"135":2,"204":1,"216":2,"220":1,"221":1,"228":1,"305":1,"306":1,"324":1,"329":1,"587":2,"598":1,"629":1,"874":9}}],["scratch一节中已经实现过小批量随机梯度下降算法",{"2":{"80":1}}],["scripts",{"2":{"1273":1}}],["script脚本化后",{"2":{"820":1}}],["script简单地转换模型",{"2":{"819":1}}],["script函数来转换模型",{"2":{"819":1}}],["script>",{"2":{"0":1,"1444":1,"1445":1,"1451":1,"1454":2,"1455":1,"1456":1,"1457":1,"1459":1,"1460":1,"1462":1,"1463":1,"1464":1,"1465":1,"1466":1,"1467":1,"1468":3,"1469":2,"1470":1,"1471":2,"1474":1,"1490":2,"1492":1,"1497":2,"1500":2,"1501":3,"1503":2,"1508":1}}],["script",{"2":{"0":1,"819":1,"820":1,"1444":2,"1445":1,"1451":1,"1454":3,"1455":1,"1456":1,"1457":1,"1459":1,"1460":1,"1462":1,"1463":1,"1464":1,"1465":1,"1466":1,"1467":1,"1468":3,"1469":2,"1470":1,"1471":2,"1474":1,"1490":2,"1492":1,"1497":2,"1500":2,"1501":3,"1503":2,"1508":1}}],["side",{"2":{"1549":1}}],["sidelength",{"2":{"1423":1}}],["si",{"2":{"1460":2}}],["si表示每层的neuron个数",{"2":{"1120":1}}],["sit",{"2":{"525":1,"732":1,"754":1}}],["site",{"2":{"0":1}}],["sift",{"2":{"455":1}}],["silver",{"2":{"300":1,"301":1}}],["sich",{"2":{"295":1}}],["sie",{"2":{"295":1}}],["siri",{"2":{"282":5}}],["simplified",{"2":{"1110":1}}],["simplernn",{"2":{"325":1}}],["simplernncell",{"2":{"325":1}}],["simultaneously",{"2":{"1109":2}}],["simultaneous",{"2":{"944":1}}],["simd",{"2":{"809":1}}],["sim=",{"2":{"768":3}}],["similar",{"2":{"750":4,"768":6}}],["similarity",{"2":{"658":1,"754":1,"1154":1}}],["simonyan和ziserman尝试了各种架构",{"2":{"510":1}}],["simonyan",{"2":{"507":1,"511":1}}],["sim",{"2":{"262":1,"271":1}}],["sigmd",{"2":{"765":7}}],["sigma^",{"2":{"1160":2}}],["sigmas",{"2":{"966":5}}],["sigma",{"2":{"616":11,"708":1,"709":1,"1159":1,"1160":1,"1184":1}}],["sigma=",{"2":{"966":3}}],["sigma=1m∑i=1n",{"2":{"1159":1}}],["sigma=1",{"2":{"278":1}}],["sigma=0",{"2":{"81":1,"176":1,"225":1,"435":1,"592":2,"623":1,"827":1,"828":1}}],["sigmoidbceloss",{"2":{"765":5}}],["sigmoid在隐藏层中已经较少使用",{"2":{"236":1}}],["sigmoid可以视为softmax的特例",{"2":{"236":1}}],["sigmoid仍然被广泛用作输出单元上的激活函数",{"2":{"236":1}}],["sigmoid通常称为挤压函数",{"2":{"236":1}}],["sigmoid函数可能在正区间内得到几乎为0的梯度",{"2":{"460":1}}],["sigmoid函数和tanh函数",{"2":{"238":1}}],["sigmoid函数的导数达到最大值0",{"2":{"236":1}}],["sigmoid函数的导数图像如下所示",{"2":{"236":1}}],["sigmoid函数的导数为下面的公式",{"2":{"236":1}}],["sigmoid函数接近线性变换",{"2":{"236":1}}],["sigmoid函数是一个自然的选择",{"2":{"236":1}}],["sigmoid函数将输入变换为区间",{"2":{"236":1}}],["sigmoid函数",{"0":{"236":1}}],["sigmoid",{"2":{"67":1,"136":16,"236":14,"242":8,"473":16,"474":16,"545":8,"559":12,"1107":2,"1109":2,"1117":2}}],["sign",{"2":{"35":4}}],["size设置为更大的整数",{"2":{"890":1}}],["size之间的整数作为上下文窗口",{"2":{"774":1}}],["size被设置为100",{"2":{"766":1}}],["size一致",{"2":{"714":1}}],["sizes=size",{"2":{"959":3}}],["sizes=s",{"2":{"912":3}}],["sizes=",{"2":{"848":3}}],["sizes",{"2":{"702":12,"848":21,"959":5}}],["size相等",{"2":{"600":1}}],["size的小批量",{"2":{"600":1}}],["size的向量",{"2":{"275":3}}],["size个可能的输出词元的预测值",{"2":{"408":1}}],["size+num",{"2":{"375":3}}],["size指定了每个小批量中子序列样本的数目",{"2":{"320":1}}],["size`的向量",{"2":{"275":1}}],["size",{"2":{"67":8,"79":4,"80":2,"127":8,"137":7,"146":4,"175":10,"210":9,"211":5,"212":2,"213":3,"216":2,"221":2,"225":5,"263":15,"271":3,"275":4,"278":1,"320":5,"321":21,"324":8,"325":38,"329":3,"331":8,"332":36,"335":16,"350":3,"369":26,"370":20,"375":69,"376":5,"382":62,"396":4,"407":44,"408":73,"409":35,"462":2,"473":4,"483":2,"489":2,"494":8,"496":2,"503":2,"509":2,"515":1,"523":11,"528":12,"543":8,"544":8,"545":8,"546":3,"547":2,"557":8,"558":8,"559":12,"560":3,"561":2,"569":2,"573":35,"574":43,"575":18,"576":5,"583":9,"584":12,"586":1,"590":11,"595":1,"600":8,"604":9,"605":10,"613":1,"622":2,"629":2,"634":3,"635":7,"669":9,"674":9,"677":6,"679":7,"680":6,"687":12,"695":9,"698":6,"702":26,"712":6,"713":17,"722":8,"725":6,"726":12,"734":19,"736":21,"738":15,"760":12,"766":6,"767":2,"772":1,"774":5,"777":12,"827":1,"828":7,"837":6,"848":9,"852":6,"854":9,"863":21,"864":14,"874":6,"882":6,"883":10,"890":1,"892":9,"898":1,"902":1,"904":9,"905":1,"906":1,"910":1,"923":1,"927":2,"932":12,"933":3,"947":18,"948":9,"949":18,"959":3,"961":2,"962":4,"963":3,"995":2,"1000":1,"1017":3,"1061":1,"1084":3,"1089":9,"1407":1}}],["size=step",{"2":{"927":1}}],["size=shape",{"2":{"331":2,"544":2,"558":2}}],["size=4",{"2":{"863":3}}],["size=64",{"2":{"862":3}}],["size=value",{"2":{"738":2}}],["size=query",{"2":{"738":2}}],["size=key",{"2":{"738":2}}],["size=embed",{"2":{"713":1}}],["size=768",{"2":{"734":6,"738":6}}],["size=7",{"2":{"482":4,"488":3,"502":5}}],["size=8",{"2":{"375":8,"573":4,"574":4}}],["size=x",{"2":{"335":4,"573":1}}],["size=len",{"2":{"326":3,"547":1,"561":1}}],["size=labels",{"2":{"262":1}}],["size=128",{"2":{"726":3,"874":3}}],["size=18",{"2":{"582":2}}],["size=11",{"2":{"461":4,"495":4}}],["size=1",{"2":{"325":2,"333":4,"335":3,"481":4,"487":12,"488":3,"494":8,"501":4,"862":3,"893":1}}],["size=1000",{"2":{"590":1}}],["size=100",{"2":{"80":1}}],["size=10",{"2":{"21":1,"28":1,"34":1,"35":4,"79":4,"80":1,"91":1,"108":1,"375":8,"573":4,"574":4}}],["size=3",{"2":{"141":4,"142":4,"461":24,"480":3,"482":4,"487":6,"488":19,"495":14,"501":8,"502":5,"507":4,"826":3,"893":3,"954":3,"955":3,"957":3}}],["size=",{"2":{"80":2,"129":3,"136":2,"141":6,"142":4,"147":3,"148":1,"173":3,"217":2,"243":4,"262":1,"273":2,"325":2,"368":2,"413":1,"414":2,"418":1,"422":1,"425":1,"429":2,"437":1,"442":2,"448":1,"461":1,"480":2,"488":2,"495":2,"501":1,"502":2,"508":2,"601":1,"630":1,"790":8,"796":4,"819":2,"821":1,"827":1,"834":12,"848":2,"862":2,"938":3,"946":1,"969":2,"977":1,"1017":1}}],["size=batch",{"2":{"67":4,"137":1,"325":2,"583":1,"584":2,"590":1,"669":2,"679":2,"687":2,"722":1,"725":1,"777":1,"864":2,"874":4,"882":3,"892":3,"904":3,"932":2,"948":1,"949":2}}],["size=256",{"2":{"686":6,"828":2,"837":2}}],["size=20",{"2":{"369":3}}],["size=2",{"2":{"67":8,"136":8,"320":1,"321":1,"369":3,"473":8,"474":8,"481":4,"507":4,"569":1,"736":3,"968":3,"969":6}}],["size=500",{"2":{"1026":1}}],["size=512",{"2":{"828":2}}],["size=5",{"2":{"67":8,"136":8,"461":4,"473":8,"474":8,"487":3,"495":4,"969":6}}],["singular",{"2":{"1159":1}}],["singh",{"2":{"657":1,"856":1}}],["single",{"2":{"591":1,"618":5,"809":1,"1444":1}}],["singer",{"2":{"25":1,"26":1}}],["sin⁡",{"2":{"400":4}}],["sinh",{"2":{"59":1}}],["sin",{"2":{"56":1,"59":2,"350":2,"386":4,"398":4,"1091":1}}],["shellnpm",{"2":{"1499":1}}],["shell",{"2":{"1047":1,"1281":1,"1285":1,"1293":1,"1294":3,"1311":1}}],["shelhamer",{"2":{"861":1,"868":1}}],["sheep",{"2":{"945":1}}],["shen",{"2":{"301":1}}],["should",{"2":{"657":2}}],["short",{"2":{"538":1,"550":1,"551":1}}],["show=",{"2":{"1471":1,"1522":1}}],["showlog",{"2":{"1468":2}}],["showtel",{"2":{"1445":2,"1451":3,"1454":2,"1455":2}}],["show",{"2":{"27":2,"54":4,"55":2,"56":1,"57":4,"59":3,"87":5,"88":2,"108":1,"113":1,"114":2,"357":2,"369":1,"370":1,"376":3,"388":4,"392":4,"399":4,"409":4,"566":2,"582":7,"636":1,"773":1,"848":2,"853":2,"854":2,"866":3,"872":1,"878":1,"882":3,"912":3,"933":6,"945":3,"946":3,"964":3,"1056":1}}],["shutil",{"2":{"887":3,"890":1}}],["shun",{"2":{"455":1}}],["shuffle=is",{"2":{"590":3,"882":3}}],["shuffle=false",{"2":{"584":2,"669":3,"679":1,"892":6,"904":6}}],["shuffle=true",{"2":{"583":3,"584":4,"669":3,"679":1,"687":3,"722":3,"725":1,"777":3,"864":1,"874":3,"892":3,"904":3,"932":3,"948":3,"949":3}}],["shuffle",{"2":{"262":1,"320":1,"583":1,"584":1,"590":1,"600":2,"718":1,"721":1}}],["shrink=0",{"2":{"357":1}}],["shallowreadonlycopy",{"2":{"1516":1}}],["shallowreadonly",{"0":{"1514":1,"1516":1},"1":{"1515":1,"1516":1},"2":{"1516":1}}],["shallowreactive",{"0":{"1510":1,"1512":1},"1":{"1511":1,"1512":1,"1513":1},"2":{"1512":1,"1513":1}}],["shallowref",{"0":{"1510":1,"1511":1},"1":{"1511":1,"1512":1,"1513":1},"2":{"1511":1,"1513":1}}],["shadow",{"2":{"1444":1}}],["shaking",{"2":{"1439":1}}],["sha",{"2":{"1321":1}}],["shann",{"2":{"1109":1}}],["sharing",{"2":{"810":1}}],["sharding",{"0":{"1206":1},"1":{"1207":1},"2":{"1195":1,"1207":3,"1210":1}}],["shard",{"2":{"726":15,"827":6,"828":4,"837":14,"883":10,"905":4,"906":4,"1207":1,"1208":1}}],["shards",{"2":{"726":28,"827":9,"828":4,"837":12,"883":8,"905":4,"906":4}}],["share",{"2":{"1364":1}}],["shared",{"2":{"437":11,"813":2}}],["sharey=true",{"2":{"357":1}}],["sharex=true",{"2":{"357":1}}],["shazeer",{"2":{"380":1,"395":1,"398":1,"403":1}}],["sha1",{"2":{"206":6}}],["shao",{"2":{"198":1,"467":1}}],["shape`",{"2":{"1417":1}}],["shape属性访问向量的长度",{"2":{"991":1}}],["shape",{"2":{"67":6,"79":4,"80":8,"81":11,"121":1,"122":2,"126":10,"128":1,"136":8,"137":7,"141":16,"142":8,"146":8,"172":4,"208":2,"209":2,"210":1,"211":1,"262":1,"263":14,"321":3,"325":16,"330":4,"331":4,"332":13,"335":4,"357":2,"368":19,"370":4,"375":12,"382":34,"390":5,"391":8,"396":2,"398":8,"406":9,"407":25,"408":25,"409":18,"414":2,"418":1,"432":2,"436":6,"461":8,"472":27,"480":4,"481":3,"488":8,"495":8,"501":8,"502":8,"508":8,"544":4,"545":1,"558":4,"559":1,"573":8,"574":14,"575":4,"576":4,"577":1,"582":2,"584":2,"595":4,"599":4,"603":1,"605":1,"632":1,"633":2,"634":6,"635":4,"669":3,"693":1,"694":6,"699":6,"714":1,"722":7,"726":3,"727":4,"734":13,"736":12,"737":8,"738":4,"762":2,"763":3,"765":2,"767":6,"777":2,"819":1,"834":3,"836":7,"837":3,"848":10,"851":6,"852":6,"854":9,"862":3,"863":12,"866":6,"873":1,"874":1,"876":3,"879":5,"881":3,"883":4,"894":3,"906":3,"912":3,"919":6,"920":12,"923":2,"926":9,"927":9,"932":2,"947":6,"948":6,"956":7,"957":3,"958":3,"959":12,"962":4,"964":3,"968":6,"969":6,"991":5,"994":4,"995":16,"998":8,"1017":1,"1020":1,"1117":1,"1417":2,"1423":4}}],["shape=k",{"2":{"968":1}}],["shape=kernel",{"2":{"127":2}}],["shape=img",{"2":{"926":2}}],["shape=y",{"2":{"599":1}}],["shape=x",{"2":{"599":1,"734":1}}],["shape=weight",{"2":{"472":4}}],["shape=shape",{"2":{"331":2,"368":1,"472":8,"544":2,"558":2}}],["shape=tf",{"2":{"172":1}}],["shape=",{"2":{"21":4,"28":1,"80":2,"127":2,"141":1,"217":2,"243":2,"273":4,"278":1,"325":5,"331":2,"332":1,"333":1,"335":1,"368":4,"369":2,"370":1,"382":4,"386":1,"391":2,"392":2,"408":1,"409":1,"414":6,"442":1,"448":1,"461":1,"473":1,"474":1,"488":2,"495":1,"502":2,"508":1,"545":1,"559":2,"576":1,"601":3,"623":1,"630":3,"686":2,"726":1,"734":1,"790":3,"820":1,"834":8,"835":1,"848":1,"862":1,"912":1,"969":1,"977":2,"997":1,"999":2,"1000":1,"1017":1}}],["shirt",{"2":{"582":4}}],["shift",{"2":{"181":1,"182":1,"183":1,"191":1,"192":1,"297":1,"467":1,"470":1,"475":2,"848":30}}],["shiki",{"2":{"7":1}}],["sh",{"2":{"124":1,"142":4,"150":1}}],["sql",{"2":{"1205":1}}],["squeeze",{"2":{"369":4,"391":1,"472":2,"576":2,"577":4,"582":1,"633":1,"634":1,"688":1,"702":3,"837":1,"852":3,"854":3,"964":2,"1026":1}}],["squeeze=false",{"2":{"357":1}}],["squad",{"2":{"660":2}}],["squashing",{"2":{"236":1}}],["squareandcubethisnumber",{"2":{"1092":2}}],["squarethisnumber",{"2":{"1092":3}}],["squares",{"2":{"1090":1,"1240":1}}],["square的加权平方误差的度量",{"2":{"744":1}}],["squared",{"2":{"80":4,"275":5,"286":1,"472":1,"603":1,"605":1,"616":1,"645":1,"962":1}}],["squarerootscheduler",{"2":{"68":2}}],["square",{"2":{"21":4,"28":4,"34":4,"35":8,"108":4,"744":1,"922":3,"923":3,"992":1,"1148":1,"1423":1}}],["sqrt",{"2":{"21":8,"27":2,"28":4,"34":4,"35":4,"108":6,"210":4,"334":4,"370":4,"407":4,"408":4,"472":4,"616":1,"750":6,"768":3,"773":1,"848":12,"1000":2,"1235":1}}],["s",{"2":{"21":32,"28":29,"34":40,"35":28,"42":1,"77":1,"108":28,"162":1,"318":1,"335":6,"374":1,"376":2,"409":2,"574":1,"578":2,"659":1,"660":1,"667":9,"687":6,"757":2,"801":1,"804":1,"805":2,"812":3,"813":7,"841":3,"842":2,"912":3,"966":6,"1027":1,"1061":1,"1070":1,"1108":1,"1121":1,"1154":5,"1159":1,"1160":3,"1340":1}}],["style>",{"2":{"1444":2}}],["styles函数对风格图像抽取风格特征",{"2":{"920":1}}],["styles",{"2":{"920":12,"925":7,"926":12,"927":33}}],["style",{"2":{"886":2,"916":3,"917":3,"918":3,"920":23,"923":3,"925":3,"927":6}}],["studying",{"2":{"657":1}}],["study",{"2":{"657":1}}],["steam",{"2":{"744":5}}],["steinhardt",{"2":{"475":1}}],["stepdecay",{"2":{"894":1,"906":1,"927":1}}],["steplr",{"2":{"894":1,"906":1,"927":1}}],["step和",{"2":{"312":1}}],["step=0",{"2":{"242":1}}],["step=",{"2":{"71":2}}],["step",{"0":{"1311":1},"2":{"67":5,"71":8,"81":3,"137":3,"210":3,"278":3,"312":1,"335":3,"346":1,"350":3,"351":5,"376":2,"392":3,"409":8,"576":3,"595":3,"635":3,"726":21,"767":3,"828":3,"883":3,"894":2,"906":5,"927":7,"963":3,"1311":1}}],["steps指定了训练的迭代步数",{"2":{"726":1}}],["steps指定文本序列的长度",{"2":{"668":1}}],["steps个标记之后的标记被截断",{"2":{"668":1}}],["steps时",{"2":{"568":1}}],["steps或",{"2":{"409":1}}],["steps或查询的数目",{"2":{"409":1}}],["steps+1",{"2":{"351":6}}],["steps的序列",{"2":{"320":1}}],["steps的子序列的起始索引",{"2":{"320":1}}],["steps是每个子序列中预定义的时间步数",{"2":{"320":1}}],["steps=8",{"2":{"569":1}}],["steps=1000",{"2":{"114":1}}],["steps=500",{"2":{"695":3}}],["steps=50",{"2":{"113":1,"114":1,"669":3,"679":1}}],["steps=5",{"2":{"73":2,"320":1,"321":1}}],["steps=0",{"2":{"72":1}}],["steps=20",{"2":{"57":2}}],["steps",{"2":{"57":2,"72":8,"320":7,"321":27,"324":8,"325":4,"329":3,"351":18,"375":20,"376":5,"398":12,"408":21,"409":15,"523":6,"528":6,"543":8,"557":8,"568":10,"569":3,"573":9,"574":12,"575":9,"576":2,"577":12,"578":2,"668":13,"669":6,"679":6,"693":2,"695":6,"726":21,"848":12,"1310":1,"1315":3}}],["st",{"2":{"374":1,"574":3,"1336":1}}],["store组合式写法",{"0":{"1495":1}}],["storetorefs",{"0":{"1492":1},"2":{"1492":2,"1493":1}}],["store是一个保存",{"2":{"1490":1}}],["store",{"2":{"844":1,"1490":4,"1492":1,"1494":1}}],["stochastic",{"2":{"112":1,"613":1,"1165":1,"1167":1}}],["stopwtach",{"2":{"1467":2}}],["stopwatch",{"2":{"1462":2}}],["stopping",{"2":{"254":1}}],["stop",{"2":{"70":5,"77":12,"78":4,"80":7,"81":4,"137":4,"217":4,"235":1,"242":1,"273":2,"318":1,"331":1,"334":1,"335":6,"472":1,"544":1,"558":1,"576":4,"583":1,"601":3,"615":5,"630":2,"703":1,"714":1,"726":3,"767":3,"820":1,"828":3,"835":1,"837":3,"876":1,"883":3,"894":3,"905":1,"906":4,"963":3,"974":1,"976":1,"977":1,"1343":1}}],["st持续增长",{"2":{"106":1}}],["stdout",{"2":{"1047":1}}],["stdin",{"2":{"1047":1}}],["stdioclienttransport",{"2":{"1047":1,"1048":2}}],["stdioservertransport",{"2":{"1047":1,"1048":2}}],["stdio",{"2":{"1047":3,"1048":2}}],["std=",{"2":{"947":2}}],["std=rgb",{"2":{"919":2}}],["std=1",{"2":{"278":2}}],["std=0",{"2":{"80":2,"81":2,"176":2,"225":2,"435":2,"623":2,"828":2}}],["stddev=0",{"2":{"80":1,"81":1,"217":2,"331":1,"435":1,"544":1,"558":1,"592":1,"599":1,"601":1,"623":1,"630":1}}],["std",{"2":{"79":4,"209":1,"616":2,"919":11,"947":2}}],["strlength2",{"2":{"1399":1}}],["strlength",{"2":{"1399":1}}],["stream",{"2":{"1364":1}}],["streamable",{"2":{"1047":1}}],["stream=true",{"2":{"206":1}}],["strang",{"2":{"1002":1}}],["strategy",{"2":{"67":2,"137":2,"326":3,"332":2,"335":5,"451":2,"488":1,"546":3,"547":3,"560":3,"561":3,"1313":1,"1315":1}}],["stringify",{"2":{"1494":1}}],["stringdictionary",{"2":{"1421":2}}],["stringornumber",{"2":{"1407":2}}],["stringarray",{"2":{"1405":1,"1421":2}}],["string>somevalue",{"2":{"1399":1}}],["string>",{"2":{"1398":1,"1409":1,"1430":1}}],["string",{"2":{"362":1,"1045":2,"1046":2,"1047":1,"1048":1,"1148":1,"1398":4,"1399":2,"1401":2,"1404":1,"1405":2,"1407":1,"1408":1,"1409":1,"1410":2,"1412":2,"1416":5,"1417":3,"1419":2,"1420":2,"1421":3,"1423":2,"1425":9,"1427":2,"1428":7,"1431":8,"1432":1,"1433":1,"1434":4,"1435":3,"1469":2,"1471":2,"1493":1,"1495":1,"1497":1,"1520":1}}],["strip",{"2":{"361":1,"667":1,"718":1}}],["stripe",{"2":{"301":1}}],["stride2",{"2":{"969":1}}],["stride2中步幅为2的转置卷积的输出",{"2":{"969":1}}],["stride2中",{"2":{"969":1}}],["stride=strides",{"2":{"501":4}}],["stride=1",{"2":{"487":2,"826":2}}],["stride=4",{"2":{"461":2}}],["stride=32",{"2":{"862":2}}],["stride=3",{"2":{"147":1,"969":4}}],["stride=",{"2":{"142":2,"147":2,"834":6}}],["stride=2",{"2":{"67":4,"136":4,"142":2,"147":2,"148":2,"461":6,"473":4,"474":4,"481":2,"482":4,"488":10,"495":6,"502":4,"507":2,"863":2,"969":2}}],["stride是垂直步幅为3",{"2":{"142":1}}],["strides=3",{"2":{"969":2}}],["strides=32",{"2":{"862":1}}],["strides=strides",{"2":{"494":1,"501":4,"893":2}}],["strides=1",{"2":{"487":1,"495":12,"501":4,"826":1,"893":2}}],["strides=4",{"2":{"461":2,"495":4}}],["strides=",{"2":{"142":2,"147":2}}],["strides=2",{"2":{"67":4,"136":4,"142":2,"147":2,"148":2,"461":6,"473":4,"474":4,"481":2,"482":4,"488":10,"495":6,"501":4,"502":10,"507":2,"826":3,"863":1,"893":1,"969":1}}],["strides",{"2":{"134":1,"494":7}}],["stride",{"2":{"134":1,"140":1,"142":2}}],["str",{"2":{"137":5,"335":4,"407":1,"408":1,"424":2,"576":4,"668":3,"687":3,"726":3,"767":3,"828":3,"837":3,"854":1,"883":3,"894":3,"896":3,"906":3,"908":3,"932":3,"947":3,"963":3,"1026":4,"1216":1,"1232":1,"1404":1}}],["stash",{"2":{"1332":8}}],["staging",{"2":{"1319":1}}],["stale",{"2":{"688":1,"883":1}}],["staled",{"2":{"688":1}}],["stanford",{"2":{"660":1,"666":4,"692":1,"748":1}}],["standard",{"2":{"616":1,"1036":1}}],["status",{"2":{"1328":1,"1336":1,"1412":3,"1431":1}}],["staticmethod",{"2":{"1254":1}}],["static脚本化后",{"2":{"820":1}}],["static简单地转换模型",{"2":{"819":1}}],["static函数来转换模型",{"2":{"819":1}}],["static",{"2":{"819":3,"820":1,"1367":2}}],["statistical",{"2":{"564":1}}],["stationary",{"2":{"347":1}}],["statements",{"2":{"1092":2}}],["statemachine",{"2":{"1052":1}}],["state是一个包含num",{"2":{"574":1}}],["state函数一样",{"2":{"545":1}}],["state函数",{"2":{"534":1}}],["state函数在初始化时返回隐状态",{"2":{"332":1}}],["state的形状",{"2":{"573":2,"574":2}}],["state的形状为",{"2":{"375":4}}],["state的计算是循环的",{"2":{"340":1}}],["state定义的隐状态的循环神经网络是非常常见的一种",{"2":{"340":1}}],["state计算的层",{"2":{"340":1}}],["state多添加了一项",{"2":{"340":1}}],["state相比",{"2":{"340":1,"541":1}}],["state中还将包含记忆单元信息",{"2":{"573":1}}],["state中的普通的循环神经网络",{"2":{"541":1}}],["state中",{"2":{"339":1}}],["state对于nn",{"2":{"335":4}}],["state即可",{"2":{"325":1}}],["state=true",{"2":{"325":1,"375":1,"547":1,"561":1,"573":1,"574":1}}],["state",{"2":{"71":1,"325":49,"332":68,"333":24,"335":34,"338":1,"339":1,"340":3,"375":76,"408":54,"430":1,"432":2,"433":1,"435":2,"442":4,"534":8,"535":12,"541":2,"545":13,"546":3,"559":12,"560":3,"573":21,"574":45,"577":16,"686":2,"805":1,"873":2,"874":1,"1444":1,"1490":3,"1493":3,"1494":3}}],["states中的讨论相同",{"2":{"341":1}}],["states中的讨论",{"2":{"307":1}}],["states",{"2":{"21":13,"28":13,"34":13,"35":12,"80":12,"91":12,"108":12,"292":1,"340":1}}],["stackedrnncells",{"2":{"375":1,"573":1,"574":1}}],["stackedanimals",{"2":{"292":1}}],["stackedanimals所示的这张",{"2":{"292":1}}],["stack",{"2":{"121":2,"848":6,"852":9,"854":3,"858":2,"1300":1,"1303":1,"1314":1,"1349":1}}],["starting",{"2":{"1048":1}}],["startswith",{"2":{"583":1}}],["start=0",{"2":{"575":1}}],["start=",{"2":{"242":1}}],["start",{"2":{"77":12,"78":4,"80":4,"81":4,"137":4,"615":3,"674":4,"726":3,"737":2,"757":7,"813":1,"828":3,"837":3,"883":3,"894":3,"906":3,"956":2,"963":3,"1261":2,"1443":1}}],["stability复习初始化方法",{"2":{"827":2}}],["stability中讨论了良好初始化的必要性",{"2":{"434":1}}],["stability所述",{"2":{"334":1}}],["stability",{"2":{"66":1,"204":1,"240":1}}],["st可能会太快地",{"2":{"35":1}}],["st←γst−1+",{"2":{"107":1}}],["st←st−1+",{"2":{"35":2}}],["st←β2st−1+",{"2":{"33":1}}],["st=",{"2":{"107":1}}],["st=st−1+gt2",{"2":{"27":1}}],["st=ρst−1+",{"2":{"20":1}}],["st用于存储梯度二阶导数的泄露平均值",{"2":{"20":1}}],["seek+rotation",{"2":{"813":1}}],["seed=1322",{"2":{"385":1}}],["seed",{"2":{"385":1}}],["serve",{"2":{"1443":1}}],["serverless",{"2":{"1357":1}}],["servers",{"2":{"1042":1,"1043":1}}],["server",{"0":{"1203":1},"2":{"813":1,"1047":8,"1048":12,"1203":1,"1205":1,"1208":2,"1210":1,"1364":2,"1365":2,"1367":1,"1369":4,"1370":1,"1376":1,"1377":1,"1378":1,"1392":1}}],["service",{"0":{"1384":1,"1391":1},"2":{"1391":3,"1530":1}}],["sergeev",{"2":{"841":1}}],["series",{"2":{"213":1}}],["semantic",{"2":{"658":1,"861":1,"864":2,"886":2,"943":2,"945":2,"947":1}}],["sep>",{"2":{"687":6,"720":1,"721":1,"722":3,"727":3,"734":2}}],["sep",{"2":{"657":1,"727":1,"734":3}}],["sendtoy",{"2":{"1499":1}}],["sendfile",{"2":{"1364":1}}],["send",{"2":{"813":3,"1498":2,"1499":4}}],["sennrich",{"2":{"757":1}}],["sent",{"2":{"724":1,"1047":1}}],["sentence函数从输入paragraph生成用于下一句预测的训练样本",{"2":{"720":1}}],["sentence函数生成二分类任务的训练样本",{"2":{"720":1}}],["sentences数",{"2":{"772":1}}],["sentences",{"2":{"687":6,"722":6,"724":1,"772":3,"773":8,"777":9}}],["sentence",{"0":{"737":1},"2":{"577":8,"720":7,"722":6,"726":3,"773":1}}],["sentiment中的imdb评论数据集不是很大",{"2":{"712":1}}],["sentiment中",{"2":{"664":1}}],["sentiment",{"2":{"522":1,"523":1,"663":3,"691":2,"692":1,"698":1,"702":1,"703":1,"704":2,"706":2,"712":1,"715":5}}],["sensory",{"2":{"356":1}}],["seaborn",{"2":{"1297":1}}],["searchfunc",{"2":{"1420":3}}],["search中介绍不同的序列生成策略",{"2":{"577":1}}],["search演示了束搜索的过程",{"2":{"515":1}}],["search",{"2":{"456":1,"512":4,"514":1,"515":4,"550":1,"1092":1,"1111":1,"1420":1}}],["seasonality",{"2":{"345":1}}],["seq相比",{"2":{"659":1}}],["seq中的单文本分类相比",{"2":{"658":1}}],["seqs所示",{"2":{"687":1,"688":1}}],["seqs中的文本对分类的bert微调在输入表示上有所不同",{"2":{"658":1}}],["seqs",{"2":{"658":1}}],["seq所示",{"2":{"657":1}}],["seq2seqdecoder",{"2":{"574":11,"576":1}}],["seq2seq所示",{"2":{"572":1,"573":1,"576":1}}],["seq2seq演示了",{"2":{"572":1}}],["seq2seq的设计",{"2":{"572":1}}],["seq2seq的机器翻译问题中应用束搜索",{"2":{"517":1}}],["seq2seq的序列预测",{"2":{"513":1}}],["seq2seqencoder",{"2":{"375":4,"376":1,"573":11,"576":1}}],["seq2seqattentiondecoder",{"2":{"375":11,"376":1}}],["seq2seq中所述",{"2":{"762":1}}],["seq2seq中一样",{"2":{"573":1}}],["seq2seq中",{"2":{"512":2,"572":1}}],["seq2seq中的模型相同",{"2":{"374":1}}],["seq2seq中的相同符号表达",{"2":{"374":1}}],["seq2seq中探讨了机器翻译问题",{"2":{"373":1}}],["seq2seq",{"0":{"572":1},"1":{"573":1,"574":1,"575":1,"576":1,"577":1,"578":1,"579":1,"580":1},"2":{"373":1,"374":2,"376":5,"409":7,"550":1,"572":3,"574":5,"576":6,"577":6,"578":2}}],["seqdataloader",{"2":{"321":2}}],["seq",{"2":{"320":4,"321":7,"376":3,"409":6,"577":24,"578":6,"657":1,"735":1}}],["sequencetoken",{"2":{"409":1}}],["sequence的自回归模型",{"2":{"328":1}}],["sequences=true",{"2":{"325":1,"375":1,"547":1,"561":1,"573":1,"574":1}}],["sequence中",{"2":{"360":1}}],["sequence中解决的回归问题",{"2":{"339":1}}],["sequence中我们以一种相当特别的方式做到了这一点",{"2":{"319":1}}],["sequence中对马尔可夫模型的讨论",{"2":{"317":1}}],["sequence中对序列模型的分析",{"2":{"316":1}}],["sequence",{"2":{"305":1,"345":1,"347":2,"368":4,"408":2,"409":1,"513":1,"564":1,"566":1,"572":2,"575":15,"715":12,"731":1}}],["sequential的实例被函数paddle",{"2":{"820":1}}],["sequential的实例被函数tf",{"2":{"820":1}}],["sequential的实例被函数torch",{"2":{"820":1}}],["sequential的混合式编程",{"0":{"819":1},"1":{"820":1,"821":1}}],["sequentially",{"2":{"813":3}}],["sequential实例将数据传入到第一层",{"2":{"591":1}}],["sequential类将多个层串联在一起",{"2":{"591":1}}],["sequential类使模型构造变得简单",{"2":{"425":1}}],["sequential定义了一种特殊的layer",{"2":{"422":1}}],["sequential定义了一种特殊的keras",{"2":{"422":1}}],["sequential定义了一种特殊的module",{"2":{"422":1}}],["sequential定义了一种特殊类型的block",{"2":{"422":1}}],["sequential来构建我们的模型",{"2":{"422":4}}],["sequential",{"2":{"67":3,"68":1,"77":1,"81":4,"136":4,"176":4,"210":3,"225":4,"263":4,"278":4,"319":1,"321":5,"350":4,"407":3,"408":3,"413":3,"414":4,"418":2,"422":4,"425":8,"429":4,"433":12,"435":3,"436":1,"437":4,"451":4,"461":4,"473":4,"474":4,"480":6,"481":3,"482":6,"488":24,"494":4,"495":4,"502":12,"507":4,"508":5,"591":4,"592":2,"623":4,"674":3,"702":1,"734":3,"736":3,"738":2,"766":2,"819":3,"826":8,"862":1,"905":4,"920":2,"957":3,"958":3}}],["selector",{"2":{"1390":1,"1391":1}}],["selection",{"2":{"170":1,"211":1,"251":1,"269":1,"270":1,"1131":1}}],["selection中",{"2":{"99":1}}],["selenium",{"2":{"1297":1}}],["self",{"2":{"68":4,"70":10,"71":11,"72":25,"79":4,"127":29,"137":20,"174":44,"321":12,"325":82,"332":52,"363":22,"369":55,"370":27,"375":70,"379":2,"382":72,"391":25,"395":2,"397":6,"398":35,"403":2,"404":1,"405":33,"406":27,"407":101,"408":175,"409":9,"413":8,"414":32,"423":24,"424":19,"425":58,"436":2,"442":27,"472":73,"480":32,"481":11,"487":67,"501":58,"502":7,"533":12,"534":16,"535":32,"573":28,"574":39,"575":12,"615":16,"634":10,"635":30,"668":60,"674":18,"675":18,"676":20,"677":36,"687":79,"688":27,"702":52,"713":32,"722":66,"734":37,"736":19,"737":16,"738":33,"748":14,"754":1,"765":4,"775":15,"777":20,"820":8,"821":7,"893":15,"926":16,"932":27,"947":68,"959":36,"1252":3,"1255":4}}],["segmentationclass",{"2":{"945":3}}],["segmentation路径包含用于训练和测试样本的文本文件",{"2":{"945":1}}],["segmentation展示了语义分割中图像有关狗",{"2":{"943":1}}],["segmentation",{"2":{"886":2,"943":3,"944":3,"945":3,"1171":1}}],["segmentation`",{"2":{"864":1,"945":2,"947":1}}],["segmentation中的图像作为输入",{"2":{"944":1}}],["segmentation中介绍的语义分割读取数据集",{"2":{"864":1}}],["segmentation中所介绍的那样",{"2":{"861":1}}],["segments将一个句子或两个句子作为输入",{"2":{"734":1}}],["segments",{"2":{"687":42,"688":6,"720":3,"722":32,"726":16,"727":15,"734":16,"738":6}}],["segment",{"2":{"41":6,"44":2,"734":6,"757":2}}],["settimeout",{"2":{"1499":1,"1520":1}}],["settheme",{"2":{"1407":1}}],["setinterval",{"2":{"1499":1}}],["setitem",{"2":{"1494":1}}],["setup中的属性",{"2":{"1453":1}}],["setup中访问this是undefined",{"2":{"1451":1}}],["setup函数有一个语法糖",{"2":{"1454":1}}],["setup函数会在beforecreate之前调用",{"2":{"1451":1}}],["setup函数返回的对象中的内容",{"2":{"1451":1}}],["setup是vue3中一个新的配置项",{"2":{"1451":1}}],["setup",{"0":{"1450":1,"1451":1,"1452":1,"1453":1,"1454":1},"1":{"1451":1,"1452":1,"1453":1,"1454":1},"2":{"1315":2,"1441":1,"1451":1,"1454":4,"1455":1,"1456":1,"1457":1,"1459":1,"1460":1,"1462":1,"1463":1,"1464":1,"1465":1,"1466":1,"1467":1,"1468":3,"1469":2,"1470":3,"1471":1,"1474":1,"1490":2,"1492":1,"1497":2,"1500":2,"1501":3,"1503":2,"1508":1}}],["setup>",{"2":{"0":1}}],["setattr",{"2":{"278":1,"703":1,"714":1,"873":1,"876":1,"959":9}}],["sets",{"2":{"39":1,"45":1,"1131":1}}],["set",{"0":{"1209":1},"2":{"21":1,"27":1,"34":1,"38":1,"40":1,"44":1,"54":3,"57":3,"67":2,"68":2,"77":1,"80":2,"87":1,"89":1,"95":1,"99":3,"102":2,"107":2,"112":1,"120":1,"126":1,"129":1,"136":1,"137":1,"141":1,"146":1,"172":1,"208":1,"216":1,"224":1,"234":1,"242":1,"256":1,"261":1,"271":1,"286":2,"318":1,"324":1,"329":1,"334":1,"340":1,"350":1,"357":4,"367":1,"374":1,"381":1,"385":2,"395":1,"404":1,"413":1,"418":1,"422":1,"429":1,"436":2,"441":1,"442":1,"446":4,"461":1,"472":1,"480":1,"487":1,"494":1,"501":1,"507":1,"523":1,"528":1,"543":1,"557":1,"564":1,"565":1,"566":2,"572":1,"582":9,"589":1,"598":1,"599":1,"604":1,"609":2,"622":1,"629":1,"635":1,"666":1,"667":5,"669":18,"673":1,"679":6,"680":2,"685":1,"686":1,"687":12,"691":1,"693":1,"698":1,"703":4,"712":1,"714":2,"718":1,"722":9,"725":4,"733":1,"747":1,"760":1,"789":1,"795":1,"796":1,"819":1,"825":1,"833":1,"835":1,"837":2,"847":4,"848":1,"857":3,"861":1,"863":5,"871":1,"877":1,"878":2,"887":1,"890":1,"894":1,"899":1,"906":1,"912":4,"918":4,"926":1,"927":1,"931":1,"932":4,"938":1,"945":1,"954":1,"964":3,"966":3,"967":1,"974":1,"981":12,"989":1,"1017":1,"1026":13,"1063":1,"1209":1,"1210":1,"1216":1,"1368":2,"1460":1,"1520":1}}],["secret",{"0":{"1385":1},"2":{"1385":1}}],["secrets",{"2":{"1315":1}}],["secondary",{"2":{"1209":2}}],["second",{"2":{"1109":2,"1117":2}}],["sec",{"2":{"19":1,"20":2,"26":1,"28":1,"30":1,"31":1,"32":5,"49":1,"50":1,"59":1,"66":4,"76":2,"78":1,"80":6,"81":4,"84":1,"87":1,"99":1,"100":1,"106":1,"107":1,"108":1,"112":1,"113":1,"126":1,"130":1,"135":2,"137":7,"140":1,"145":1,"146":1,"168":1,"170":2,"173":1,"191":1,"208":1,"211":1,"216":3,"220":1,"221":1,"225":1,"228":3,"242":1,"246":1,"269":1,"270":1,"291":1,"306":3,"309":1,"312":2,"315":1,"316":1,"317":1,"318":1,"319":1,"321":1,"324":1,"325":2,"326":1,"328":1,"329":2,"332":1,"334":1,"335":2,"338":2,"339":1,"341":1,"347":1,"348":1,"350":1,"360":1,"367":1,"368":1,"373":1,"374":2,"376":2,"381":1,"404":2,"406":1,"409":1,"413":1,"422":2,"424":1,"426":1,"434":1,"439":1,"461":2,"463":1,"466":1,"467":1,"473":2,"480":1,"482":1,"485":1,"491":2,"494":1,"509":1,"512":2,"513":1,"517":2,"522":2,"523":1,"528":2,"531":1,"532":1,"538":2,"540":1,"543":1,"545":1,"546":1,"551":1,"557":1,"560":2,"564":1,"566":1,"568":1,"572":4,"573":1,"575":1,"576":4,"577":1,"583":1,"588":2,"589":1,"590":2,"591":1,"601":1,"603":1,"604":1,"615":4,"622":2,"623":1,"624":1,"626":1,"629":1,"633":1,"635":2,"639":3,"643":1,"656":2,"657":1,"663":1,"664":1,"672":1,"679":1,"681":1,"685":3,"686":3,"688":1,"693":1,"702":1,"703":1,"706":2,"707":1,"712":1,"718":2,"725":2,"726":4,"731":2,"734":1,"736":1,"742":1,"747":1,"754":2,"760":2,"762":1,"767":3,"771":2,"781":1,"795":1,"820":1,"825":1,"826":2,"827":4,"828":1,"831":4,"833":1,"834":1,"841":3,"847":1,"857":2,"861":2,"862":2,"863":1,"864":1,"877":1,"879":1,"882":2,"883":5,"887":1,"893":3,"894":3,"896":1,"899":1,"901":1,"902":1,"903":1,"904":2,"905":2,"906":3,"908":2,"911":1,"912":1,"913":3,"915":1,"920":1,"936":1,"938":1,"943":2,"946":2,"951":1,"952":2,"953":1,"954":1,"959":1,"961":1,"963":3,"967":2,"968":1,"973":1,"992":1,"1013":1,"1018":1}}],["a>",{"2":{"1507":1}}],["azure",{"2":{"1393":1}}],["azizpour",{"2":{"467":1}}],["aks",{"2":{"1393":1}}],["aj",{"2":{"1122":4}}],["aji",{"2":{"519":1}}],["a就等于25",{"2":{"1092":1}}],["a逐点乘以这个单位矩阵",{"2":{"1090":1}}],["a设为一个9行9列的魔方阵",{"2":{"1090":1}}],["a向量中的最大值",{"2":{"1090":1}}],["a是一个矩阵的话",{"2":{"1090":1}}],["a中的每一个元素与矩阵",{"2":{"1090":1}}],["a中的所有元素放入一个单独的列向量",{"2":{"1089":1}}],["a矩阵的逆矩阵",{"2":{"1090":1}}],["a矩阵的第一个维度的尺寸",{"2":{"1089":1}}],["a矩阵设置为原来的",{"2":{"1089":1}}],["a±b",{"2":{"1077":1}}],["aa−1=a−1a=i我们一般在",{"2":{"1077":1}}],["aa−1=a−1a=i",{"2":{"1076":1}}],["a×c",{"2":{"1090":1}}],["a×b",{"2":{"1076":1}}],["a×b≠b×a",{"2":{"1076":1}}],["a×",{"2":{"1076":1}}],["a∩b",{"2":{"1038":1}}],["a∪b",{"2":{"1038":1}}],["a∣b",{"2":{"1032":3,"1034":2}}],["a∣c",{"2":{"515":1,"1034":1}}],["a⊤",{"2":{"1004":1}}],["a⊤=",{"2":{"992":1}}],["a的列维数",{"2":{"998":3}}],["a的形状是",{"2":{"992":1}}],["a在对每行进行求和后仍保持两个轴",{"2":{"996":1}}],["a⊙b=",{"2":{"994":1}}],["a等于其转置",{"2":{"992":1}}],["a验证梯度是否正确",{"2":{"977":1}}],["aeroplane",{"2":{"945":1}}],["a和b之间的随机数指的是在区间",{"2":{"879":1}}],["a和tokens",{"2":{"727":1}}],["a0",{"2":{"853":2,"1099":1,"1100":4}}],["a8",{"2":{"851":1}}],["a6",{"2":{"851":1}}],["a4的类别被标记为猫",{"2":{"853":1}}],["a4",{"2":{"851":1,"853":1}}],["a4e718a47137ccd1809c9107ab4f5edd317bae2c",{"2":{"686":1}}],["a3是中间单元",{"2":{"1099":1}}],["a3",{"2":{"851":1,"1099":2,"1100":3}}],["a2nb2n⋮⋮⋱⋮am1bm1am2bm2",{"2":{"994":1}}],["a2和a3",{"2":{"853":1}}],["a2",{"2":{"851":1,"1027":1,"1099":3,"1100":3,"1154":1}}],["a77核心可以同时执行多达8个操作",{"2":{"808":1}}],["a1⊤b1a1⊤b2⋯a1⊤bma2⊤b1a2⊤b2⋯a2⊤bm⋮⋮⋱⋮an⊤b1an⊤b2⋯an⊤bm",{"2":{"999":1}}],["a1⊤a2⊤⋮an⊤",{"2":{"999":2}}],["a1⊤a2⊤⋮am⊤",{"2":{"998":2}}],["a1⊤xa2⊤x⋮am⊤x",{"2":{"998":1}}],["a1nb1na21b21a22b22",{"2":{"994":1}}],["a11b11a12b12",{"2":{"994":1}}],["a11a12⋯a1ka21a22⋯a2k⋮⋮⋱⋮an1an2⋯ank",{"2":{"999":1}}],["a11a12⋯a1na21a22⋯a2n⋮⋮⋱⋮am1am2⋯amn",{"2":{"992":1}}],["a11a21",{"2":{"992":1}}],["a1的类别被标记为狗",{"2":{"853":1}}],["a1",{"2":{"674":1,"1099":3,"1100":4,"1154":1}}],["ageable",{"2":{"1408":2}}],["age",{"2":{"1196":1,"1398":3,"1405":1,"1408":3,"1419":2,"1433":3,"1445":3,"1451":6,"1454":5,"1455":4,"1459":5,"1463":4,"1464":4,"1465":3,"1466":3,"1468":3,"1469":6,"1518":1}}],["agentops",{"2":{"1052":1}}],["agents",{"2":{"1041":1}}],["agent",{"0":{"1049":1,"1050":1,"1051":1,"1052":1,"1053":1},"1":{"1050":1,"1051":1,"1052":1,"1053":1,"1054":1,"1055":1,"1056":1},"2":{"298":1,"1025":1,"1049":1,"1050":2,"1051":3,"1052":1,"1053":1,"1054":8,"1056":4,"1543":1,"1547":1}}],["aggarwal",{"2":{"929":1}}],["agg",{"2":{"677":2}}],["agg=400",{"2":{"677":2}}],["aggregate",{"2":{"676":6,"677":9}}],["against",{"2":{"660":2}}],["agirre",{"2":{"658":1}}],["affine",{"2":{"610":1,"641":1}}],["await",{"2":{"1047":2,"1048":5,"1471":1,"1495":1}}],["award",{"2":{"475":1}}],["aws",{"2":{"292":2,"832":1,"842":1,"1393":1}}],["autumn",{"2":{"918":2}}],["automated",{"2":{"1315":1}}],["automatic",{"2":{"973":1}}],["autopep8",{"2":{"1264":1}}],["autonomous",{"2":{"1127":2}}],["autogpt",{"2":{"1052":1}}],["autograd包会自动计算微分",{"2":{"987":1}}],["autograd中引入的自动微分来计算梯度",{"2":{"601":1}}],["autograd",{"2":{"67":2,"77":1,"80":1,"81":1,"126":1,"129":1,"136":1,"137":1,"172":1,"174":2,"208":1,"210":1,"234":1,"235":1,"236":1,"237":1,"242":2,"271":1,"275":1,"278":1,"329":1,"335":1,"350":2,"381":1,"385":1,"392":1,"395":1,"404":1,"406":1,"408":1,"422":1,"472":2,"572":1,"576":1,"589":1,"595":1,"598":1,"605":1,"629":1,"635":1,"725":1,"726":1,"760":1,"767":1,"789":1,"825":1,"828":1,"833":1,"837":1,"877":1,"883":1,"899":1,"906":1,"918":1,"927":1,"954":1,"963":1,"973":1,"974":3,"975":1,"976":1,"977":1,"987":1}}],["auto",{"2":{"404":1,"795":1,"824":1,"831":1,"1051":1,"1055":1,"1371":1,"1407":1}}],["autoregressive",{"2":{"347":2}}],["aug函数",{"2":{"883":1}}],["aug",{"2":{"878":2,"879":6,"880":6,"881":6,"883":4,"885":3}}],["augs",{"2":{"872":6,"874":6,"881":5,"882":10,"883":14}}],["augmented",{"2":{"731":1}}],["augmentation中对数据增强的描述",{"2":{"951":1}}],["augmentation中对cifar",{"2":{"887":1}}],["augmentation中更详细地讨论数据扩增",{"2":{"461":1}}],["augmentation`",{"2":{"883":2}}],["augmentation",{"2":{"726":1,"877":1,"886":1}}],["ahsgdyfa03",{"2":{"1456":1,"1457":1}}],["ahsgdyfa02",{"2":{"1456":1,"1457":1}}],["ahsgdyfa01",{"2":{"1456":1,"1457":1}}],["ahead",{"2":{"351":2}}],["ahmed",{"2":{"345":1,"840":1}}],["abc=",{"2":{"1500":4}}],["abc事件被触发",{"2":{"1499":1}}],["abc",{"2":{"1499":2,"1500":4}}],["abcdef",{"2":{"1077":1}}],["about",{"2":{"1474":5,"1478":2,"1479":2,"1486":1}}],["ab中的函数g的输出维度被设置为200",{"2":{"680":1}}],["ab中",{"2":{"675":1}}],["ab",{"2":{"675":1,"1077":1}}],["abadie",{"2":{"300":1}}],["abstract",{"2":{"1416":2,"1417":2}}],["abs来对",{"2":{"1090":1}}],["abs",{"2":{"54":4,"122":1,"129":1,"425":4,"436":4,"863":6,"924":2,"962":3,"966":4,"1000":4}}],["aij指第i行",{"2":{"1072":1}}],["air",{"2":{"658":1}}],["airfoil",{"2":{"79":12}}],["aila",{"2":{"300":1}}],["ai",{"0":{"1049":1,"1050":1,"1051":1,"1052":1},"1":{"1050":1,"1051":1,"1052":1,"1053":1,"1054":1,"1055":1,"1056":1},"2":{"298":1,"376":2,"409":2,"578":2,"674":2,"675":1,"692":1,"1027":1,"1040":3,"1042":3,"1049":1,"1050":3,"1051":1,"1054":1,"1056":2,"1099":1,"1303":1,"1542":1,"1543":1,"1546":1,"1547":1,"1548":1}}],["amend",{"2":{"1337":1}}],["amnbmn",{"2":{"994":1}}],["amn",{"2":{"992":1}}],["am2⋮⋮⋱⋮a1na2n",{"2":{"992":1}}],["am1a12a22",{"2":{"992":1}}],["amd的epyc",{"2":{"810":1,"812":1}}],["amd的threadripper3有64个pcie4",{"2":{"801":1}}],["ammar",{"2":{"731":1}}],["am",{"2":{"674":1}}],["amari和juergen",{"2":{"455":1}}],["amazon",{"2":{"294":2,"456":1}}],["amazonaws",{"2":{"206":1,"718":1}}],["amp",{"0":{"1385":1},"2":{"135":1,"406":1,"1088":5}}],["atguiguinput组件中",{"2":{"1500":2}}],["atguiguinput",{"2":{"1500":7}}],["atguigu",{"2":{"1491":1,"1493":1}}],["ati",{"2":{"457":1}}],["at=b直观来看",{"2":{"1077":1}}],["at=bt+∑i=1t−1",{"2":{"307":1}}],["at=∂ht∂wh",{"2":{"307":1}}],["at",{"2":{"295":1,"307":3,"1077":1,"1191":1,"1422":3}}],["attend=100",{"2":{"677":2}}],["attend",{"2":{"674":6,"677":11}}],["attending",{"0":{"674":1},"2":{"675":1}}],["attention对词元以硬的方式对齐",{"2":{"675":1}}],["attention以",{"2":{"674":1}}],["attention描述了使用注意力机制的自然语言推断方法",{"2":{"673":1}}],["attention的重点",{"2":{"564":1}}],["attention2",{"2":{"408":12}}],["attention1",{"2":{"408":12}}],["attention和位置编码",{"2":{"404":1}}],["attention中所述",{"2":{"672":1}}],["attention中所讲",{"2":{"397":1}}],["attention中",{"2":{"663":1}}],["attention中比较了卷积神经网络",{"2":{"403":1}}],["attention中卷积核大小为3的双层卷积神经网络的感受野内",{"2":{"397":1}}],["attention所示",{"2":{"397":1}}],["attentiondecoder",{"2":{"375":6,"408":4}}],["attention",{"2":{"354":1,"356":1,"357":2,"367":4,"369":23,"370":22,"373":1,"374":2,"375":33,"376":7,"379":10,"380":4,"381":1,"382":17,"388":19,"391":8,"392":4,"395":3,"396":9,"397":3,"403":1,"404":3,"407":28,"408":36,"409":53,"577":24,"578":2,"663":1,"672":2,"673":1,"685":1}}],["attn所示",{"2":{"369":1}}],["attn",{"2":{"367":2,"369":1,"374":1,"388":4,"396":1,"409":8}}],["attr=none",{"2":{"472":2}}],["attr=true",{"2":{"375":1}}],["attr=bias",{"2":{"278":1,"382":4,"592":1}}],["attr=false",{"2":{"263":1,"369":3,"863":1,"968":1,"969":2}}],["attr=weight",{"2":{"176":3,"278":1,"573":2,"574":3,"592":1}}],["attr",{"2":{"176":4,"225":3,"278":4,"573":4,"574":6,"592":4}}],["attach",{"2":{"80":2,"173":1,"217":1,"235":1,"242":1,"273":2,"331":1,"544":1,"558":1,"601":2,"630":2,"835":1,"974":1,"977":1}}],["atm",{"2":{"135":1}}],["alert",{"2":{"1445":1,"1451":1,"1454":1,"1455":1}}],["alex",{"2":{"455":1}}],["alexnet中的讨论",{"2":{"915":1}}],["alexnet中的alexnet类似",{"2":{"509":1}}],["alexnet中的alexnet架构相匹配",{"2":{"461":1}}],["alexnet提到过大型数据集是成功应用深度神经网络的先决条件",{"2":{"877":1}}],["alexnet和vgg对lenet的改进主要在于如何扩大和加深这两个模块",{"2":{"493":1}}],["alexnet和vgg都有一个共同的设计模式",{"2":{"493":1}}],["alexnet和lenet的设计理念非常相似",{"2":{"458":1}}],["alexnet和lenet的架构非常相似",{"2":{"458":1}}],["alexnet对fashion",{"2":{"465":1}}],["alexnet已经被更有效的架构所超越",{"2":{"464":1}}],["alexnet在训练时增加了大量的图像增强数据",{"2":{"461":1}}],["alexnet通过暂退法",{"2":{"461":1}}],["alexnet将sigmoid激活函数改为更简单的relu激活函数",{"2":{"460":1}}],["alexnet的架构与lenet相似",{"2":{"464":1}}],["alexnet的卷积通道数目是lenet的10倍",{"2":{"459":1}}],["alexnet的更高层建立在这些底层表示的基础上",{"2":{"455":1}}],["alexnet使用relu而不是sigmoid作为其激活函数",{"2":{"458":1}}],["alexnet使用了8层卷积神经网络",{"2":{"458":1}}],["alexnet由八层组成",{"2":{"458":1}}],["alexnet比相对较小的lenet5要深得多",{"2":{"458":1}}],["alexnet所示",{"2":{"458":1}}],["alexnet横空出世",{"2":{"458":1}}],["alexnet以alex",{"2":{"455":1}}],["alexnet",{"0":{"454":1,"458":1},"1":{"455":1,"456":1,"457":1,"458":1,"459":2,"460":2,"461":2,"462":1,"463":1,"464":1,"465":1},"2":{"454":1,"458":1,"492":2,"832":2,"857":1,"946":1}}],["alexa",{"2":{"282":5}}],["altitude",{"2":{"1422":8}}],["alvinn会训练得到一个与人类驾驶员操纵方向基本相近的结果",{"2":{"1127":1}}],["alvinn每两秒将前方的路况图生成一张数字化图片",{"2":{"1127":1}}],["alvinn能够控制navlab",{"2":{"1127":1}}],["alvinn",{"2":{"1127":1}}],["aly",{"2":{"840":1}}],["aliases",{"0":{"1412":1}}],["alias",{"2":{"1336":4}}],["alice",{"2":{"1048":2,"1191":1,"1196":1,"1214":1,"1244":1,"1398":1,"1421":1}}],["ali",{"2":{"475":1}}],["already",{"2":{"295":2}}],["alg",{"2":{"631":2,"995":1,"996":1}}],["algorithm",{"2":{"282":1,"283":1,"1121":1,"1151":1,"1159":1,"1180":1,"1190":1}}],["algebra中解释线性代数的重点内容",{"2":{"1018":1}}],["algebra",{"0":{"1071":1},"1":{"1072":1,"1073":1,"1074":1,"1075":1,"1076":1,"1077":1},"2":{"270":1,"280":1,"987":1,"988":1,"1000":1,"1193":1}}],["alpha的第1个维度",{"2":{"674":3}}],["alpha的形状",{"2":{"674":1}}],["alpha=0",{"2":{"386":1}}],["alphago在2015年达到了相当于人类的棋力",{"2":{"301":1}}],["alphago",{"2":{"298":1}}],["alpha",{"2":{"109":1,"367":1,"374":1,"674":7,"675":6,"677":6,"1167":1}}],["alley",{"2":{"1011":2,"1012":7}}],["alleva",{"2":{"301":1}}],["allreduce之后",{"2":{"835":3}}],["allreduce之前",{"2":{"835":3}}],["allreduce",{"2":{"835":6,"837":3}}],["allreduce函数将所有向量相加",{"2":{"835":1}}],["allow",{"2":{"441":3}}],["all",{"2":{"21":1,"27":2,"28":1,"34":1,"44":1,"47":1,"54":1,"55":2,"56":1,"57":1,"59":3,"68":2,"70":1,"80":5,"87":1,"88":2,"89":1,"91":3,"95":1,"99":1,"107":1,"108":2,"113":2,"114":2,"120":1,"121":3,"122":2,"126":1,"128":3,"137":2,"146":2,"206":4,"208":6,"209":14,"211":2,"212":1,"213":2,"216":1,"221":1,"225":1,"262":2,"264":1,"265":1,"266":1,"271":1,"276":1,"277":1,"278":2,"318":5,"320":2,"321":3,"329":1,"340":1,"350":1,"351":4,"357":2,"361":1,"362":1,"363":3,"364":1,"369":1,"370":1,"375":1,"376":2,"386":1,"399":1,"409":3,"445":1,"446":8,"449":1,"451":1,"462":1,"463":1,"474":1,"483":1,"489":1,"496":1,"503":1,"508":1,"509":1,"529":1,"565":2,"566":2,"567":1,"568":2,"569":2,"576":1,"578":1,"582":2,"583":1,"584":1,"589":1,"590":2,"599":3,"600":1,"602":1,"603":1,"605":2,"615":3,"616":1,"622":1,"626":1,"629":1,"632":1,"634":4,"635":3,"636":1,"667":3,"668":18,"669":2,"680":3,"682":1,"686":2,"687":43,"692":2,"693":3,"699":2,"702":3,"704":2,"713":2,"714":2,"715":2,"718":1,"720":2,"721":2,"722":80,"726":2,"727":2,"734":1,"748":5,"750":4,"751":5,"757":10,"762":1,"765":1,"767":1,"772":2,"773":5,"774":6,"775":10,"776":2,"777":22,"796":3,"816":1,"817":1,"820":1,"827":3,"835":1,"837":1,"848":2,"852":1,"853":4,"854":21,"858":5,"865":3,"872":2,"874":3,"878":1,"882":5,"883":7,"889":2,"890":5,"895":3,"901":1,"902":1,"907":3,"912":3,"920":2,"923":1,"924":1,"925":1,"931":1,"932":1,"945":3,"948":1,"956":1,"959":1,"961":1,"968":2,"981":6,"1011":2,"1012":2,"1017":1,"1018":1,"1019":1,"1020":1,"1021":1,"1109":2,"1112":2,"1328":1,"1499":1}}],["average",{"2":{"86":1,"146":1,"472":3,"495":1,"997":1,"1036":1,"1151":1}}],["avg",{"2":{"80":4,"81":4,"137":1,"146":3,"342":2,"387":1,"388":1,"481":2,"615":1,"826":2,"828":3,"834":6,"837":3}}],["avgpool2d",{"2":{"67":2,"136":8,"473":6,"474":6,"481":4}}],["ar",{"2":{"1154":1}}],["ari=∑i",{"2":{"1154":1}}],["ari",{"2":{"1154":1}}],["article",{"2":{"1121":1}}],["artificial",{"2":{"619":1,"1173":1}}],["around",{"2":{"1089":1}}],["area所示",{"2":{"980":1}}],["areas",{"2":{"849":15}}],["areas的形状",{"2":{"849":3}}],["areasandunion",{"2":{"849":3}}],["areas2",{"2":{"849":9}}],["areas2的形状",{"2":{"849":3}}],["areas1",{"2":{"849":12}}],["area是输入特征的一个",{"2":{"610":1}}],["area中的warea和wage",{"2":{"610":1}}],["area",{"2":{"610":1,"849":9,"980":1,"1255":1,"1319":1}}],["are",{"2":{"532":1}}],["arch上执行for循环来简单实现",{"2":{"508":1}}],["arch",{"2":{"508":14,"509":6}}],["archambeau",{"2":{"316":1}}],["arm和其他芯片供应商之间的细节稍有不同",{"2":{"457":1}}],["armed",{"2":{"298":1}}],["arg",{"2":{"1430":2,"1433":3}}],["argmax需要指定最后一维",{"2":{"962":3}}],["argmaxjy^j=argmaxjoj",{"2":{"643":1}}],["argmax",{"2":{"333":4,"577":4,"634":2,"636":1,"682":3,"715":3,"851":5,"854":2,"866":3,"896":3,"962":3}}],["argsort",{"2":{"854":3}}],["args",{"2":{"325":4,"332":1,"375":4,"407":3,"408":4,"424":4,"533":4,"534":4,"535":12,"573":4,"574":4,"634":2,"820":1,"1047":1,"1048":1,"1230":3,"1244":2}}],["arrow",{"2":{"1443":1}}],["arrowstyle=",{"2":{"99":2}}],["arrowprops=dict",{"2":{"99":2}}],["arraydataset",{"2":{"590":1,"777":1}}],["arrays",{"2":{"569":2,"590":8}}],["array",{"2":{"79":4,"210":4,"262":1,"263":8,"271":2,"330":1,"350":1,"413":1,"447":1,"568":4,"569":7,"575":4,"576":1,"577":3,"590":5,"615":1,"668":2,"682":2,"687":4,"694":3,"695":8,"715":1,"722":7,"727":3,"734":1,"736":5,"737":1,"854":1,"863":1,"866":1,"912":1,"919":2,"932":1,"938":1,"947":2,"964":1,"989":2,"992":1,"1000":1,"1013":2,"1017":1,"1018":3,"1022":2,"1398":1,"1405":1,"1469":1}}],["arange",{"2":{"41":2,"54":2,"57":6,"68":1,"70":1,"71":4,"72":2,"73":2,"89":1,"95":1,"99":2,"101":2,"102":2,"103":2,"107":1,"147":3,"172":3,"213":1,"235":3,"242":3,"262":1,"330":4,"350":2,"369":3,"386":4,"390":3,"398":16,"408":3,"441":3,"575":2,"616":2,"736":3,"836":3,"848":6,"854":3,"863":6,"938":3,"966":6,"970":2,"974":4,"981":1,"990":3,"992":3,"993":3,"994":6,"995":3,"1017":5,"1018":3,"1019":6}}],["across",{"2":{"1315":1}}],["acebdf",{"2":{"1077":1}}],["aclimdb",{"2":{"692":4,"695":6}}],["aclimdb中的imdb评论数据集",{"2":{"692":1}}],["active",{"2":{"1474":6,"1477":4}}],["activate",{"2":{"1273":2,"1277":1,"1294":1}}],["activations",{"2":{"232":1,"501":2}}],["activation",{"2":{"103":1,"232":1,"234":2,"473":8,"474":8,"480":1,"481":1,"482":2,"502":3,"819":3,"826":1,"834":12,"893":1,"957":1,"1099":1}}],["activation=tf",{"2":{"176":2,"418":1,"422":1,"423":1,"424":1,"425":4,"429":1,"433":1,"435":3,"436":1,"437":1,"442":1}}],["activation=",{"2":{"67":8,"136":8,"174":2,"176":2,"225":2,"350":2,"405":1,"418":1,"422":1,"423":1,"424":1,"425":4,"429":1,"433":2,"437":3,"442":1,"461":14,"487":12,"488":6,"494":6,"507":2,"508":4,"674":2,"702":1,"736":1,"738":1,"819":2,"905":1}}],["action中可以编写一些业务逻辑",{"2":{"1491":1}}],["actions",{"0":{"1307":1},"1":{"1308":1,"1309":1,"1310":1,"1311":1,"1312":1,"1313":1,"1314":1,"1315":1},"2":{"1314":1,"1315":6,"1490":2,"1491":1,"1493":1,"1543":1}}],["action",{"0":{"1311":1},"2":{"298":1,"813":2,"1311":2,"1490":1}}],["action=",{"2":{"141":1,"172":1,"208":1,"413":1,"422":1,"429":1,"441":1,"974":1,"989":1,"1006":1,"1013":1,"1017":1}}],["accept",{"2":{"1371":1}}],["acceptability",{"2":{"657":1}}],["accelerate",{"2":{"206":1}}],["accessed",{"2":{"129":1}}],["access",{"2":{"0":1,"77":1,"813":3}}],["accuracy函数中",{"2":{"634":1}}],["accuracy函数进行轻微的修改",{"2":{"137":1}}],["accuracy",{"2":{"67":7,"137":15,"634":10,"635":5,"653":1,"827":3,"828":3,"837":3,"883":6,"894":3}}],["accumulator实例中创建了2个变量",{"2":{"634":1}}],["accumulator",{"2":{"67":3,"137":6,"263":3,"335":4,"576":4,"634":4,"635":4,"726":3,"767":3,"827":1,"883":3,"894":3,"906":3,"963":3}}],["acc",{"2":{"67":33,"137":36,"635":11,"828":3,"837":3,"883":33,"894":27}}],["a+a⊤总是对称的吗",{"2":{"1004":1}}],["a+a⊤",{"2":{"983":1}}],["a+b",{"2":{"64":2,"1004":1}}],["a+λb",{"2":{"46":2}}],["a+λb且λ∈",{"2":{"46":1}}],["axioserror>error",{"2":{"1471":1}}],["axioserror",{"2":{"1471":1}}],["axios",{"2":{"1471":3,"1490":2,"1495":3}}],["axis1",{"2":{"995":12}}],["axis0",{"2":{"995":12}}],["axis",{"2":{"391":1,"981":3,"1091":1}}],["axis=3",{"2":{"584":1}}],["axis=2",{"2":{"369":2,"574":1,"577":3,"675":4,"702":2,"964":1}}],["axis=",{"2":{"368":4,"369":2,"375":3,"390":1,"391":1,"472":4,"480":1,"575":2,"582":1,"674":2,"702":2,"852":1,"854":1,"858":2,"962":2,"995":4}}],["axis=1",{"2":{"213":1,"333":3,"368":1,"369":2,"375":7,"388":4,"390":1,"391":4,"408":4,"472":3,"480":2,"487":2,"574":2,"575":5,"634":2,"636":1,"674":2,"676":6,"682":2,"702":2,"713":2,"715":2,"737":1,"750":3,"765":3,"767":3,"768":2,"848":2,"851":4,"852":1,"854":5,"865":1,"866":2,"896":2,"956":3,"959":2,"962":2,"995":4,"996":4,"1004":1,"1018":3,"1026":4}}],["axis=0",{"2":{"79":8,"120":1,"332":3,"369":2,"375":2,"382":3,"388":4,"392":10,"399":2,"408":1,"472":2,"545":3,"559":3,"577":9,"727":3,"848":2,"853":4,"854":7,"863":1,"866":1,"876":2,"908":1,"919":1,"964":1,"995":12,"996":4,"1018":3,"1026":3}}],["axhline",{"2":{"1026":4}}],["ax=",{"2":{"998":1}}],["ax=axes",{"2":{"357":1}}],["axon",{"2":{"619":2,"1099":1}}],["ax+",{"2":{"46":2}}],["ax",{"2":{"41":2,"102":8,"357":5,"582":17,"933":6}}],["axes函数用于设置由matplotlib生成图表的轴的属性",{"2":{"981":1}}],["axes=none",{"2":{"981":1}}],["axes=1",{"2":{"77":3,"78":1,"974":1,"997":1}}],["axes=ax",{"2":{"41":2}}],["axes",{"2":{"41":4,"357":4,"472":5,"582":21,"635":9,"848":4,"853":2,"854":2,"858":2,"912":3,"927":3,"933":6,"964":3,"981":18}}],["a=1",{"2":{"1481":1}}],["a=a和b=b同时发生的可能性不大于a=a或是b=b单独发生的可能性",{"2":{"1030":1}}],["a=a和b=b同时满足的概率是多少",{"2":{"1030":1}}],["a=a就必须发生",{"2":{"1030":1}}],["a=a",{"2":{"1030":3,"1031":2}}],["a=a⊤",{"2":{"992":1}}],["a=",{"2":{"35":1,"992":1,"998":1,"999":2,"1072":1,"1077":1,"1090":1,"1154":1,"1501":1,"1508":1}}],["apache",{"2":{"1359":1}}],["apps",{"2":{"1390":1}}],["apple",{"2":{"1401":1}}],["application",{"0":{"1170":1},"1":{"1171":1,"1172":1,"1173":1,"1174":1},"2":{"1193":1,"1315":1,"1364":1,"1371":2,"1444":1}}],["applying",{"2":{"1128":1,"1162":1,"1193":1}}],["apply",{"2":{"81":3,"137":2,"176":1,"209":1,"210":1,"225":1,"278":1,"335":1,"350":3,"392":1,"435":8,"436":2,"576":2,"595":1,"623":2,"635":1,"702":1,"713":2,"750":1,"767":2,"768":1,"828":1,"878":1,"879":7,"880":7,"881":3,"883":2,"896":3,"1392":1}}],["approx",{"2":{"707":1,"742":1,"754":1,"771":1,"1160":1}}],["approach",{"2":{"619":1}}],["app中介绍它们",{"2":{"754":1}}],["app中讨论",{"2":{"747":1}}],["app中解释自然语言处理应用时",{"2":{"733":1}}],["app中",{"2":{"663":1,"727":1,"1038":1}}],["app所述",{"2":{"663":1}}],["app",{"2":{"663":2,"1035":1,"1389":1,"1390":2,"1391":1,"1444":3,"1445":1,"1460":1,"1468":1,"1469":2,"1471":1,"1474":6,"1489":7,"1523":1,"1524":6}}],["append",{"2":{"21":1,"28":1,"34":1,"35":1,"54":2,"57":2,"59":1,"80":1,"91":1,"108":1,"210":8,"332":4,"333":8,"334":2,"363":1,"375":8,"424":1,"480":3,"482":4,"502":6,"507":6,"508":2,"545":4,"559":4,"566":2,"577":8,"615":1,"635":2,"674":16,"687":1,"692":2,"702":2,"720":1,"721":2,"722":21,"726":3,"748":2,"757":4,"774":1,"775":2,"826":4,"852":9,"854":6,"894":3,"906":3,"920":2,"932":6,"945":6,"957":8,"958":2,"966":4}}],["api进行了封装",{"2":{"1471":1}}],["apiresponse",{"2":{"1434":1}}],["apiclient",{"2":{"1431":5}}],["api的指导",{"2":{"1005":3}}],["api文档",{"2":{"1005":3}}],["api和jax都采纳了",{"2":{"300":1}}],["apis",{"2":{"0":1,"5":1,"1042":1}}],["api",{"0":{"0":1,"1448":1,"1449":1,"1453":1,"1509":1},"1":{"1":1,"2":1,"3":1,"4":1,"5":1,"1510":1,"1511":1,"1512":1,"1513":1,"1514":1,"1515":1,"1516":1,"1517":1,"1518":1,"1519":1,"1520":1},"2":{"0":1,"987":1,"1050":1,"1052":1,"1053":1,"1203":1,"1364":1,"1368":1,"1371":1,"1376":2,"1377":1,"1378":1,"1381":1,"1392":1,"1441":1,"1448":1,"1451":1,"1471":1,"1495":2,"1513":1,"1528":1,"1530":1}}],["asdda04",{"2":{"1518":1,"1519":1}}],["asdda03",{"2":{"1518":1,"1519":1}}],["asdda02",{"2":{"1518":1,"1519":1}}],["asdda01",{"2":{"1518":1,"1519":1}}],["asdasg01",{"2":{"1469":1}}],["asgdytsa04",{"2":{"1508":1}}],["asgdytsa03",{"2":{"1508":1}}],["asgdytsa02",{"2":{"1508":1}}],["asgdytsa01",{"2":{"1508":1}}],["ast",{"2":{"1121":1}}],["astype",{"2":{"172":2,"392":4,"409":1,"568":1,"569":2,"575":2,"577":2,"634":5,"768":3,"851":2,"852":2,"854":1,"863":1,"866":4,"894":1,"896":2,"919":1,"932":1,"938":2,"945":3,"947":2,"962":2,"964":3,"1026":2}}],["ascii",{"2":{"1089":2}}],["aspect",{"2":{"847":1,"848":1}}],["asanovic",{"2":{"800":1}}],["asarray",{"2":{"409":1}}],["asyncfunction",{"2":{"1412":1}}],["async中的",{"2":{"795":1}}],["asyncgraph独立初始化两个变量",{"2":{"795":1}}],["asyncgraph中进行了说明",{"2":{"790":1}}],["asyncgraph",{"2":{"790":1}}],["asynchronous",{"2":{"789":1,"792":1}}],["async",{"2":{"789":1,"824":1,"1048":3,"1431":2,"1471":1,"1495":1}}],["asset",{"2":{"1315":5}}],["assert",{"2":{"122":1,"172":4,"206":2,"211":1,"472":3,"635":3,"777":2,"836":3}}],["assumption",{"2":{"253":1}}],["assign去整体替换",{"2":{"1458":1}}],["assigned",{"2":{"852":16,"1151":1}}],["assignment",{"2":{"298":1}}],["assign",{"2":{"21":3,"28":2,"34":3,"35":3,"77":3,"78":1,"80":1,"91":2,"108":2,"126":1,"128":1,"146":2,"350":1,"351":4,"436":2,"472":6,"604":1,"615":1,"734":1,"851":3,"852":3,"968":1,"1020":2,"1021":1,"1464":1}}],["asnumpy和item等函数也具有这个效果",{"2":{"793":1}}],["asnumpy",{"2":{"102":3,"263":1,"595":1,"616":2,"768":1,"791":2,"823":1,"848":1,"857":1,"863":2,"878":1,"896":1,"908":1,"912":1,"918":2,"927":1,"964":1,"966":4,"1022":1,"1026":1}}],["as",{"2":{"21":5,"27":5,"34":5,"38":8,"54":8,"67":8,"77":8,"80":1,"81":1,"87":5,"99":8,"107":5,"112":5,"120":5,"126":5,"129":1,"136":5,"137":4,"141":1,"146":4,"172":5,"206":2,"208":12,"210":1,"216":5,"224":5,"234":5,"235":1,"236":1,"237":1,"242":6,"261":8,"271":5,"275":1,"278":1,"318":5,"324":7,"329":7,"332":1,"335":3,"340":5,"350":6,"357":5,"360":4,"361":1,"367":5,"374":5,"381":5,"385":5,"392":1,"395":6,"398":1,"404":10,"413":3,"418":1,"422":3,"429":1,"441":4,"446":1,"449":1,"461":6,"472":6,"480":6,"487":8,"494":6,"501":8,"507":6,"523":3,"528":3,"533":1,"543":6,"557":6,"564":5,"565":1,"572":5,"576":2,"581":5,"589":8,"595":1,"598":5,"605":1,"615":8,"622":5,"629":5,"635":1,"660":1,"666":3,"667":1,"673":5,"685":3,"691":3,"692":1,"698":3,"712":3,"718":4,"725":3,"733":3,"747":3,"748":1,"760":3,"767":1,"771":3,"772":1,"789":3,"795":4,"819":5,"825":3,"833":5,"847":4,"857":5,"861":6,"866":1,"871":4,"877":4,"887":7,"890":1,"896":1,"899":4,"908":4,"912":3,"918":5,"919":1,"931":7,"938":1,"945":7,"954":6,"963":2,"964":1,"967":3,"974":3,"975":1,"976":1,"977":1,"981":8,"989":1,"1006":1,"1011":2,"1013":1,"1017":1,"1026":8,"1085":1,"1107":1,"1109":1,"1117":1,"1168":2,"1250":1,"1252":1,"1399":2,"1468":1,"1471":1,"1495":1}}],["advice",{"2":{"1128":1,"1162":1,"1193":1}}],["adversarial",{"2":{"296":1}}],["advanced",{"2":{"207":1,"1111":1}}],["addr",{"2":{"1368":1}}],["address",{"2":{"802":1}}],["add函数向有序字典",{"2":{"424":1}}],["add函数方便将每个连续的block添加到列表中",{"2":{"422":1}}],["addnorm3",{"2":{"408":8}}],["addnorm2",{"2":{"407":8,"408":8}}],["addnorm1",{"2":{"407":8,"408":8}}],["addnorm",{"2":{"406":10,"407":8,"408":12}}],["addition",{"2":{"1048":1,"1073":1}}],["additional",{"2":{"7":1}}],["additiveattention",{"2":{"369":12,"375":4}}],["additive",{"2":{"369":4}}],["add",{"2":{"67":10,"80":4,"81":6,"102":2,"127":2,"136":1,"137":13,"176":1,"210":2,"225":1,"263":9,"275":4,"278":6,"335":8,"350":1,"392":4,"406":8,"407":3,"408":3,"413":1,"414":3,"418":2,"422":2,"424":6,"425":7,"429":2,"433":10,"437":1,"451":1,"461":1,"472":6,"473":1,"474":1,"480":2,"481":1,"482":11,"488":6,"494":1,"495":1,"502":5,"507":4,"508":4,"576":8,"591":2,"592":1,"623":3,"634":4,"635":6,"674":4,"676":1,"702":1,"726":6,"734":3,"736":3,"766":1,"767":6,"809":1,"813":2,"816":9,"817":6,"819":4,"826":17,"827":1,"828":3,"837":3,"848":1,"858":2,"862":6,"883":9,"893":5,"894":9,"905":2,"906":9,"920":1,"927":3,"957":2,"958":1,"963":6,"1048":5,"1230":2,"1239":1,"1259":1,"1285":1,"1289":1,"1294":2,"1319":2,"1324":1,"1328":2,"1330":1,"1337":1,"1371":1,"1398":1,"1432":3,"1444":8}}],["adaptiveavgpool1d",{"2":{"702":2}}],["adaptiveavgpool2d",{"2":{"482":1,"488":2,"495":2,"502":2,"826":2}}],["adaptivemaxpool2d",{"2":{"482":1,"959":2}}],["adaption",{"2":{"345":1}}],["adam优化器的主要吸引力在于它对初始学习率不那么敏感",{"2":{"210":1}}],["adam",{"2":{"32":1,"34":14,"35":4,"65":2,"210":4,"350":4,"576":4,"681":3,"688":3,"704":3,"715":3,"726":3,"767":3,"883":3,"926":3}}],["adam算法使用偏差校正来调整缓慢的启动速度",{"2":{"36":1}}],["adam算法在rmsprop算法基础上创建的",{"2":{"36":1}}],["adam算法将许多优化算法的功能结合到了相当强大的更新规则中",{"2":{"36":1}}],["adam算法也存在一些问题",{"2":{"35":1}}],["adam算法的关键组成部分之一是",{"2":{"33":1}}],["adam算法",{"0":{"32":1},"1":{"33":1,"34":1,"35":1,"36":1,"37":1},"2":{"32":1}}],["adam一节讨论缓解这种情况的策略",{"2":{"30":1}}],["adagrad一节中",{"2":{"108":1}}],["adagrad中的关键问题之一",{"2":{"106":1}}],["adagrad中",{"2":{"32":1}}],["adagrad算法将梯度gt的平方累加成状态矢量st=st−1+gt2",{"2":{"106":1}}],["adagrad算法按坐标顺序的适应性是非常可取的",{"2":{"106":1}}],["adagrad算法有时在降低学习率方面可能过于剧烈",{"2":{"30":1}}],["adagrad算法对于稀疏特征特别有效",{"2":{"30":1}}],["adagrad算法可以帮助缓解扭曲",{"2":{"30":1}}],["adagrad算法利用梯度的大小作为调整进度速率的手段",{"2":{"30":1}}],["adagrad算法会在单个坐标层面动态降低学习率",{"2":{"30":1}}],["adagrad算法需要对每个自变量维护同它一样形状的状态变量",{"2":{"28":1}}],["adagrad算法巧妙的思路是",{"2":{"26":1}}],["adagrad算法",{"0":{"24":1},"1":{"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1},"2":{"25":1}}],["adagrad",{"2":{"19":1,"20":1,"24":1,"27":3,"28":10,"29":4,"65":1}}],["adadelta真的是学习率为0吗",{"2":{"23":1}}],["adadelta使用泄漏的平均值来保持对适当统计数据的运行估计",{"2":{"22":1}}],["adadelta使用两个状态变量",{"2":{"20":1}}],["adadelta需要两个状态变量来存储梯度的二阶导数和参数的变化",{"2":{"22":1}}],["adadelta需要为每个变量维护两个状态变量",{"2":{"21":1}}],["adadelta没有学习率参数",{"2":{"22":1}}],["adadeltaisnotconvergingatdefaultlearningrate",{"2":{"21":1}}],["adadelta算法",{"0":{"20":1}}],["adadelta算法是在",{"2":{"19":1}}],["adadelta是adagrad的另一种变体",{"2":{"19":1}}],["adadelta",{"0":{"19":1},"1":{"20":1,"21":1,"22":1,"23":1},"2":{"19":1,"21":14,"65":1}}],["a",{"2":{"8":8,"21":3,"28":3,"34":3,"35":2,"40":1,"46":6,"64":2,"77":19,"78":4,"80":3,"91":3,"108":3,"153":3,"154":6,"155":2,"156":3,"158":4,"218":4,"247":1,"291":1,"293":2,"315":1,"341":2,"367":3,"369":1,"370":1,"390":2,"513":9,"515":9,"615":5,"619":1,"634":2,"635":3,"655":6,"658":5,"660":1,"674":21,"675":12,"676":12,"677":15,"720":3,"727":16,"731":2,"734":3,"751":3,"757":5,"773":2,"790":33,"791":8,"813":2,"816":6,"817":4,"821":2,"849":1,"879":1,"977":25,"981":1,"986":3,"992":13,"994":29,"995":63,"996":23,"998":10,"999":4,"1004":1,"1019":8,"1021":2,"1022":30,"1027":2,"1028":1,"1032":5,"1033":1,"1034":6,"1038":2,"1048":5,"1077":8,"1088":1,"1089":31,"1090":31,"1091":2,"1092":1,"1099":1,"1100":3,"1103":1,"1111":1,"1121":1,"1127":1,"1130":1,"1154":2,"1216":2,"1218":7,"1219":3,"1230":4,"1335":1,"1343":1,"1392":1,"1398":3,"1399":1,"1401":2,"1405":1,"1417":2,"1443":1,"1456":3,"1457":3,"1464":4,"1483":1,"1501":5,"1507":1}}],["animal",{"2":{"1416":5}}],["animator",{"2":{"67":12,"80":20,"81":16,"137":15,"263":12,"275":12,"278":12,"335":12,"392":12,"576":12,"635":5,"726":9,"767":9,"828":12,"837":12,"883":12,"894":12,"906":12,"927":12,"963":9}}],["any",{"2":{"1404":1}}],["anything",{"2":{"1404":1}}],["anywhere",{"2":{"1165":1,"1339":1}}],["anomaly",{"2":{"1177":1,"1178":1,"1181":1,"1182":1,"1185":1,"1193":1}}],["another",{"2":{"813":3}}],["anthropic",{"2":{"1040":1}}],["angular",{"2":{"1530":2,"1538":1}}],["anguelov",{"2":{"952":1,"953":1,"966":1}}],["ang",{"2":{"1089":1,"1092":2,"1094":1}}],["angeli",{"2":{"666":1}}],["angeschaut",{"2":{"295":1}}],["anc",{"2":{"851":15,"852":4,"854":4}}],["anchor中",{"2":{"911":1}}],["anchors和num",{"2":{"954":1}}],["anchors函数定义如下",{"2":{"912":1}}],["anchors参数",{"2":{"852":1}}],["anchors",{"2":{"851":30,"852":44,"853":5,"854":28,"912":15,"954":6,"955":6,"959":37,"963":7,"964":6}}],["anchor",{"2":{"847":2,"848":6,"850":1,"851":8,"852":3,"856":1,"886":1,"912":1,"913":2,"915":1,"959":1}}],["anchoring",{"2":{"345":1}}],["answering",{"2":{"660":1}}],["ankle",{"2":{"582":1}}],["ana",{"2":{"851":1}}],["analogy",{"2":{"751":5,"754":1}}],["analytical",{"2":{"612":1}}],["analysis中所述",{"2":{"312":1}}],["analysis中的分析不同",{"2":{"312":1}}],["analysis",{"2":{"296":1,"307":1,"663":3,"691":1,"1138":2,"1158":1,"1159":1,"1174":1}}],["anaconda",{"2":{"445":1}}],["annotate",{"2":{"99":8,"101":4,"102":2,"103":2}}],["an",{"2":{"8":2,"658":1,"1148":1,"1181":1,"1444":1}}],["andew",{"2":{"1176":1}}],["andersen",{"2":{"832":1,"840":1,"843":1}}],["andb5thatwe",{"2":{"502":1}}],["andrew",{"2":{"455":1}}],["and∂s∂w",{"2":{"164":1}}],["and",{"2":{"0":2,"33":1,"42":1,"45":1,"52":1,"59":1,"99":1,"134":1,"190":1,"191":1,"204":1,"213":2,"284":1,"305":2,"335":2,"379":1,"395":1,"424":1,"502":4,"550":1,"565":2,"566":1,"574":8,"616":2,"634":2,"635":3,"643":1,"645":1,"647":2,"663":2,"664":1,"672":1,"679":2,"681":2,"685":1,"687":3,"720":1,"721":9,"726":4,"727":3,"734":2,"757":1,"763":7,"774":4,"777":3,"826":3,"827":2,"836":3,"837":1,"848":1,"886":1,"893":1,"894":1,"906":1,"944":1,"947":3,"962":1,"980":1,"981":2,"1001":1,"1048":1,"1072":1,"1073":1,"1077":1,"1084":1,"1094":1,"1098":1,"1101":3,"1102":6,"1110":1,"1131":1,"1133":1,"1140":1,"1169":1,"1171":1,"1173":1,"1176":1,"1181":1,"1220":1,"1315":1}}],["t1",{"2":{"1468":3}}],["t1+t2+t3",{"2":{"792":1}}],["tsximport",{"2":{"1523":1}}],["tstalkstore",{"2":{"1494":1}}],["tscountstore",{"2":{"1491":2}}],["tsconst",{"2":{"1479":1}}],["ts代码如下",{"2":{"1474":1}}],["ts中内容如下",{"2":{"1471":2}}],["ts",{"2":{"1444":1,"1445":1,"1451":1,"1454":4,"1455":1,"1456":1,"1457":1,"1459":1,"1460":1,"1462":1,"1463":1,"1464":1,"1465":1,"1466":1,"1467":1,"1468":3,"1469":2,"1470":1,"1471":2,"1474":1,"1489":1,"1490":5,"1492":1,"1497":2,"1499":1,"1500":2,"1501":3,"1503":2,"1508":1,"1520":1}}],["tsimport",{"2":{"1489":1,"1495":1}}],["tsipras",{"2":{"475":1}}],["tsinghua",{"2":{"445":1}}],["t>>",{"2":{"1431":4}}],["t>",{"2":{"1409":1,"1410":2,"1412":3,"1430":2,"1431":3,"1432":3,"1433":1,"1434":4,"1435":2}}],["tb",{"2":{"1252":1}}],["tbit",{"2":{"815":1}}],["tbit增加到每平方英寸5",{"2":{"815":1}}],["tς−1",{"2":{"1184":1}}],["tn",{"2":{"1139":2}}],["tp+fn",{"2":{"1139":1,"1140":1}}],["tp+fp",{"2":{"1139":1,"1140":1}}],["tp",{"2":{"1139":2}}],["tpu添加了用于快速矩阵乘法的脉动阵列",{"2":{"811":1}}],["tδ",{"2":{"1121":2}}],["t=1m",{"2":{"1184":1}}],["t=katmatlab",{"2":{"1077":1}}],["t=a",{"2":{"1077":1}}],["t=at±bt",{"2":{"1077":1}}],["t=btat",{"2":{"1077":1}}],["t=",{"2":{"1077":1}}],["tconv",{"2":{"968":9,"969":23}}],["tv",{"2":{"924":1,"925":6,"927":9,"945":1}}],["t4gpu的性能数字",{"2":{"815":1}}],["t4",{"2":{"811":1}}],["t3",{"2":{"792":1}}],["t2",{"2":{"792":1}}],["t时",{"2":{"773":1}}],["t时都可以递归地计算为",{"2":{"312":1}}],["typ=",{"2":{"750":1,"768":1}}],["types",{"0":{"1407":1,"1408":1},"2":{"1364":1,"1371":1,"1469":2}}],["typescriptclass",{"2":{"1425":1,"1432":1}}],["typescriptinterface",{"2":{"1419":1,"1420":1,"1421":1,"1422":1,"1423":1,"1426":1,"1427":1}}],["typescriptimport",{"2":{"1048":1,"1499":1,"1520":1}}],["typescriptabstract",{"2":{"1416":1,"1417":1}}],["typescripttype",{"2":{"1408":1,"1409":1,"1410":1}}],["typescript",{"0":{"1396":1},"1":{"1397":1,"1398":1,"1399":1,"1400":1,"1401":1,"1402":1,"1403":1,"1404":1,"1405":1,"1406":1,"1407":1,"1408":1,"1409":1,"1410":1,"1411":1,"1412":1,"1413":1,"1414":1,"1415":1,"1416":1,"1417":1,"1418":1,"1419":1,"1420":1,"1421":1,"1422":1,"1423":1,"1424":1,"1425":1,"1426":1,"1427":1,"1428":1,"1429":1,"1430":1,"1431":1,"1432":1,"1433":1,"1434":1,"1435":1,"1436":1},"2":{"1047":2,"1048":2,"1397":1,"1398":1,"1399":1,"1400":1,"1401":2,"1402":1,"1403":1,"1404":1,"1405":1,"1407":1,"1412":1,"1413":1,"1414":1,"1418":1,"1424":1,"1428":2,"1430":1,"1431":1,"1433":1,"1434":1,"1435":1,"1436":4,"1444":2,"1527":1,"1528":1,"1530":1,"1544":1}}],["type=",{"2":{"834":2,"1444":1,"1460":2,"1468":1,"1500":4}}],["type",{"0":{"1412":1},"2":{"81":2,"137":4,"176":1,"225":2,"332":1,"350":2,"392":2,"431":4,"435":8,"436":2,"576":2,"577":1,"623":2,"702":2,"713":2,"767":2,"828":2,"883":2,"896":1,"962":1,"1022":8,"1048":1,"1090":1,"1232":1,"1252":1,"1315":1,"1364":1,"1391":1,"1405":7,"1407":3,"1408":2,"1409":2,"1410":4,"1412":5,"1414":3,"1431":2,"1432":1,"1434":7,"1435":5,"1469":3}}],["t+m",{"2":{"785":1,"786":1}}],["t+j",{"2":{"708":6,"783":1,"784":1}}],["t+1",{"2":{"25":1,"68":1,"785":1,"786":1}}],["t恤",{"2":{"582":1}}],["tgt",{"2":{"376":5,"409":14,"569":8,"576":11,"577":16,"578":2}}],["t中的上下文变量c",{"2":{"374":1}}],["tx",{"2":{"1188":5,"1189":5,"1190":2,"1192":1}}],["txt安装依赖",{"2":{"1269":1}}],["txt文件",{"2":{"1089":1}}],["txt",{"0":{"1266":1},"1":{"1267":1,"1268":1,"1269":1},"2":{"361":1,"565":1,"667":2,"748":1,"772":1,"945":12,"1089":1,"1252":1,"1269":3}}],["tx0",{"2":{"95":1}}],["twoloop",{"2":{"842":1}}],["twoloop描述了网络可以分解为一个具有双nvlink带宽的环",{"2":{"842":1}}],["twogpu",{"2":{"797":1}}],["twogpu所示",{"2":{"797":1}}],["two",{"2":{"355":1,"658":2,"687":1,"688":1,"1048":1,"1141":3}}],["t对于本文中的序列通常是离散的",{"2":{"346":1}}],["t∈z+时",{"2":{"346":1}}],["t来说都变得更加棘手",{"2":{"312":1}}],["t⋅∂ot∈rq",{"2":{"312":1}}],["tuning中的实验不同",{"2":{"905":1}}],["tuning中讨论的方法在完整imagenet数据集上选择预训练的模型",{"2":{"905":1}}],["tuning",{"2":{"613":1,"869":1,"870":1,"874":9,"886":1}}],["tuna",{"2":{"445":1}}],["turk",{"2":{"456":1}}],["turing擅长fp16",{"2":{"814":1}}],["turing有相关的细节",{"2":{"811":1}}],["turing",{"2":{"299":1,"811":3}}],["tuytelaars",{"2":{"454":1,"455":1}}],["tuple",{"2":{"335":2,"363":2,"424":1,"848":1,"1216":1}}],["tutorial",{"0":{"1087":1},"1":{"1088":1,"1089":1,"1090":1,"1091":1,"1092":1,"1093":1,"1094":1},"2":{"295":2,"1193":1,"1306":1}}],["t贝尔实验室的研究员yann",{"2":{"135":1}}],["t−0",{"2":{"1086":1}}],["t−m",{"2":{"785":1,"786":1}}],["t−iwqh⊤∂l∂ot+t−i",{"2":{"312":1}}],["t−τ−1",{"2":{"86":1,"89":1}}],["t−2+gt",{"2":{"86":1}}],["t−1替换为gt",{"2":{"88":1}}],["t−1=",{"2":{"86":1}}],["t−1=∂wf",{"2":{"86":1}}],["t−1=∂w1|bt|∑i∈btf",{"2":{"86":1}}],["t−1其中β∈",{"2":{"86":1}}],["t−1",{"2":{"86":1,"88":1,"785":1,"786":1}}],["t−12",{"2":{"25":1,"27":1,"66":1,"106":1}}],["tiobe",{"2":{"1303":1}}],["tinyssd",{"2":{"959":9,"961":3}}],["tinyssd了",{"2":{"959":1}}],["tinymembench",{"2":{"813":4}}],["tiny",{"2":{"774":3,"889":3,"901":4,"1011":2}}],["tired",{"2":{"675":1}}],["tik",{"2":{"615":2}}],["tilda",{"2":{"545":8,"559":8}}],["tilde",{"2":{"541":2}}],["tile的形状",{"2":{"392":8}}],["tile",{"2":{"369":1,"391":1,"392":24,"408":2,"574":1,"848":3,"852":2}}],["title=",{"2":{"1506":1,"1507":1}}],["title3",{"2":{"1468":3}}],["title2",{"2":{"1468":3}}],["title1",{"2":{"1468":4}}],["title",{"2":{"357":1,"582":3,"1048":2,"1474":1,"1481":3,"1482":5,"1483":1,"1495":2,"1506":1,"1507":1}}],["titles=titles",{"2":{"636":1}}],["titles=get",{"2":{"582":4}}],["titles=",{"2":{"409":4}}],["titles=none",{"2":{"357":1,"582":3}}],["titles",{"2":{"357":2,"582":6,"636":1}}],["ti≤t≤ti+1分段常数η",{"2":{"114":1}}],["tieleman",{"2":{"106":1}}],["ticks",{"2":{"102":8}}],["timeout",{"2":{"1364":1,"1427":3}}],["timeit",{"0":{"1262":1},"2":{"1262":3}}],["timemachine",{"2":{"319":3,"361":1}}],["time",{"2":{"80":1,"89":1,"95":1,"107":1,"306":1,"318":2,"319":1,"321":3,"324":4,"325":2,"326":4,"329":2,"333":2,"335":7,"346":1,"350":8,"351":9,"361":4,"364":4,"375":1,"475":1,"523":4,"528":4,"543":4,"546":1,"547":2,"557":4,"561":2,"573":2,"574":1,"615":8,"713":1,"796":4,"813":2,"1091":1,"1261":5}}],["times=",{"2":{"848":1}}],["times",{"2":{"77":4,"78":4,"615":7}}],["timer",{"2":{"77":36,"78":11,"80":24,"81":20,"137":20,"335":12,"576":12,"583":3,"615":12,"726":15,"767":9,"820":3,"828":15,"837":15,"883":15,"894":15,"906":15,"963":12,"1520":3}}],["tip",{"2":{"8":4}}],["tel就是一个普通的字符串",{"2":{"1455":1}}],["tel都不是响应式数据",{"2":{"1454":1}}],["tel数据都不是响应式数据",{"2":{"1451":1}}],["tel",{"2":{"1445":2,"1451":3,"1454":2,"1455":2}}],["teleport>",{"2":{"1522":1}}],["teleport",{"0":{"1522":1},"2":{"1441":1,"1522":2}}],["team",{"2":{"1425":1}}],["teamsize",{"2":{"1425":5}}],["teacher",{"2":{"576":1}}],["template>",{"2":{"1444":2,"1445":2,"1451":2,"1454":2,"1455":2,"1456":2,"1457":2,"1459":2,"1460":2,"1462":2,"1463":2,"1464":2,"1465":2,"1466":2,"1467":2,"1468":4,"1469":4,"1470":2,"1471":2,"1474":2,"1479":2,"1490":4,"1492":2,"1497":4,"1500":4,"1501":6,"1503":4,"1506":2,"1507":4,"1508":2,"1523":4}}],["template",{"2":{"1390":1,"1507":2,"1523":2}}],["temperature",{"2":{"1299":1}}],["temp",{"2":{"1090":1,"1467":7}}],["tempout",{"2":{"687":2}}],["terminal",{"2":{"619":1}}],["term",{"2":{"538":1,"550":1,"551":1}}],["teye",{"2":{"467":1}}],["tesla中的小结来自eliot",{"2":{"813":1}}],["tesla",{"2":{"301":1,"813":2}}],["test2",{"2":{"1409":1}}],["test1",{"2":{"1409":1}}],["tests",{"2":{"1315":2}}],["test函数用来",{"2":{"890":1}}],["testing",{"2":{"388":4,"392":4,"1444":2}}],["test中的图像进行分类",{"2":{"181":1}}],["test",{"2":{"67":31,"68":4,"71":4,"72":4,"73":4,"137":33,"175":8,"176":4,"181":1,"208":6,"209":1,"210":32,"213":8,"216":1,"221":5,"225":2,"262":3,"263":28,"271":5,"275":8,"278":8,"286":2,"386":21,"387":4,"388":11,"392":20,"462":1,"463":1,"473":4,"474":1,"475":1,"483":2,"489":2,"496":2,"503":2,"509":2,"582":8,"584":10,"622":1,"626":1,"629":1,"634":1,"635":9,"636":3,"667":3,"669":19,"679":8,"681":3,"687":9,"688":4,"692":1,"695":27,"698":3,"704":3,"712":3,"715":3,"828":9,"837":9,"864":4,"865":3,"866":15,"872":10,"874":10,"882":3,"883":34,"889":1,"890":14,"891":3,"892":21,"896":6,"901":2,"902":1,"903":3,"904":21,"908":9,"948":1,"949":6,"1131":3,"1252":1,"1315":4,"1433":1,"1443":2,"1444":1,"1456":2,"1457":2,"1464":2,"1468":2}}],["techniques",{"2":{"207":1}}],["textmy",{"2":{"1258":1}}],["textcnn通过一个具体的例子说明了textcnn的模型架构",{"2":{"701":1}}],["textcnn",{"2":{"701":1,"702":9}}],["textcnn模型使用一维卷积层和最大时间汇聚层将单个词元表示转换为下游应用输出",{"2":{"705":1}}],["textcnn模型将输入转换为输出",{"2":{"701":1}}],["textcnn模型将单个预训练的词元表示作为输入",{"2":{"701":1}}],["textcnn模型",{"0":{"701":1},"1":{"702":1,"703":1,"704":1}}],["textcnn中使用的最大时间汇聚层的工作原理类似于一维全局汇聚",{"2":{"700":1}}],["textual",{"2":{"658":1}}],["text德语",{"2":{"295":1}}],["texttom",{"2":{"295":1}}],["text",{"2":{"99":4,"262":1,"271":1,"305":1,"315":1,"318":1,"360":1,"565":10,"566":3,"569":2,"582":2,"659":1,"667":3,"717":3,"727":9,"772":2,"848":2,"1048":5,"1171":1,"1371":2,"1460":2,"1468":1,"1500":4}}],["teh",{"2":{"75":1}}],["tensorcore",{"2":{"811":1}}],["tensorcore给出了优化的概述",{"2":{"811":1}}],["tensordataset",{"2":{"590":2}}],["tensordot",{"2":{"77":3,"78":1,"974":1,"997":1}}],["tensor",{"2":{"41":2,"56":1,"59":2,"79":1,"80":2,"120":2,"126":2,"128":1,"137":5,"146":1,"172":1,"209":3,"262":1,"320":2,"321":6,"330":2,"333":4,"334":1,"335":2,"368":6,"369":3,"382":2,"396":1,"398":1,"406":3,"407":2,"409":5,"413":1,"425":1,"431":1,"436":2,"447":2,"448":2,"568":1,"575":8,"576":3,"577":6,"582":2,"583":1,"584":2,"589":1,"590":1,"599":1,"600":1,"631":2,"633":2,"668":4,"682":4,"687":8,"693":1,"694":2,"695":8,"699":4,"713":1,"715":2,"722":14,"727":6,"734":2,"736":4,"737":2,"748":2,"762":1,"765":6,"767":3,"776":4,"796":2,"797":1,"811":2,"828":2,"835":4,"836":1,"848":31,"852":5,"853":2,"854":13,"858":1,"866":3,"883":3,"912":2,"919":4,"932":3,"938":3,"947":2,"964":3,"966":2,"968":2,"970":2,"974":1,"977":1,"989":4,"992":2,"1000":2,"1013":4,"1016":1,"1017":2,"1018":6,"1022":4,"1026":4}}],["tensorflow提供了tf",{"2":{"1021":1}}],["tensorflow中的梯度不会通过variable反向传播",{"2":{"1020":1}}],["tensorflow中的variables是支持赋值的可变容器",{"2":{"1020":1}}],["tensorflow中的tensors是不可变的",{"2":{"1020":1}}],["tensorflow中的initializers模块提供了多种模型参数初始化方法",{"2":{"592":1}}],["tensorflow中构建的所有函数都是作为计算图构建的",{"2":{"819":1}}],["tensorflow2",{"2":{"818":1}}],["tensorflow的initializers模块提供了多种模型参数初始化方法",{"2":{"596":1}}],["tensorflow在根模块和keras",{"2":{"434":1}}],["tensorflow采用",{"2":{"147":1}}],["tensorflow",{"2":{"21":4,"23":1,"27":3,"28":1,"29":1,"31":1,"34":4,"35":1,"37":1,"38":3,"41":1,"52":1,"54":5,"57":2,"64":1,"67":5,"68":2,"71":2,"72":2,"73":2,"75":1,"77":6,"78":1,"79":1,"80":2,"81":2,"83":1,"87":3,"91":2,"92":1,"97":1,"99":4,"101":1,"102":2,"103":1,"105":1,"107":3,"108":2,"109":1,"111":1,"112":3,"113":1,"118":1,"120":3,"122":1,"124":1,"126":3,"127":1,"128":1,"129":2,"133":1,"136":4,"137":1,"139":1,"141":3,"142":2,"144":1,"146":2,"147":6,"148":4,"150":1,"172":4,"173":1,"174":1,"175":1,"176":2,"178":1,"208":3,"210":3,"215":1,"216":3,"217":1,"218":1,"219":1,"220":1,"221":1,"223":1,"224":3,"225":2,"227":1,"234":3,"235":2,"236":2,"237":2,"239":1,"242":3,"243":1,"250":1,"261":3,"262":1,"263":2,"268":1,"271":3,"273":1,"274":1,"275":1,"278":2,"280":1,"318":3,"321":1,"323":1,"324":3,"325":4,"326":2,"328":1,"329":4,"330":2,"331":1,"332":4,"333":2,"334":1,"335":4,"337":1,"340":4,"344":1,"350":7,"351":2,"353":1,"357":3,"359":1,"360":2,"366":1,"367":3,"368":3,"369":2,"370":2,"374":3,"375":2,"376":2,"381":3,"382":4,"385":3,"386":2,"387":1,"388":2,"390":2,"391":1,"392":4,"395":3,"396":2,"398":2,"399":1,"404":3,"405":2,"406":3,"407":4,"408":3,"409":4,"413":5,"414":5,"416":1,"418":5,"420":1,"422":3,"423":3,"424":2,"425":3,"426":1,"428":1,"429":2,"430":1,"431":1,"432":2,"433":3,"434":1,"435":3,"436":3,"437":1,"439":1,"441":5,"442":4,"444":1,"446":4,"447":1,"448":2,"449":3,"451":2,"453":1,"461":4,"465":1,"472":4,"473":3,"474":1,"477":1,"480":5,"481":2,"482":3,"485":1,"487":3,"488":6,"491":1,"494":3,"495":2,"498":1,"501":5,"502":5,"505":1,"507":4,"508":2,"509":1,"511":1,"533":2,"534":1,"535":1,"543":3,"544":1,"545":2,"546":1,"547":1,"557":3,"558":1,"559":2,"560":1,"561":1,"564":3,"572":3,"573":3,"574":2,"575":4,"576":1,"577":1,"578":1,"581":3,"582":4,"583":1,"584":1,"586":1,"589":3,"590":1,"591":2,"592":3,"593":2,"594":2,"595":2,"596":1,"597":1,"598":3,"599":1,"600":1,"601":1,"604":1,"605":1,"607":1,"615":4,"616":1,"621":1,"622":3,"623":1,"624":1,"625":1,"628":1,"629":3,"630":1,"631":3,"633":2,"634":1,"635":2,"638":1,"818":2,"819":7,"820":3,"821":2,"823":2,"857":4,"974":7,"975":1,"976":2,"977":3,"979":1,"981":2,"986":1,"989":2,"990":2,"991":2,"992":4,"993":1,"994":3,"995":7,"996":3,"997":2,"998":2,"999":1,"1000":3,"1004":1,"1005":1,"1006":2,"1007":2,"1009":1,"1013":2,"1015":1,"1017":11,"1018":4,"1019":1,"1020":3,"1021":4,"1022":3,"1024":1,"1026":8,"1038":1,"1297":1}}],["trouser",{"2":{"582":2}}],["trip",{"2":{"813":1}}],["triple",{"2":{"318":2}}],["trigger",{"2":{"1520":2}}],["triggs",{"2":{"455":1}}],["trigram",{"2":{"317":1,"318":8}}],["truncate",{"2":{"568":3,"577":4,"668":3,"687":6,"693":1,"695":6}}],["truncated",{"2":{"311":2}}],["truncation",{"2":{"568":1}}],["truth",{"2":{"386":7,"387":1,"847":1,"851":9,"853":5}}],["true标志允许使用过时的梯度",{"2":{"883":1}}],["true标志添加到tf",{"2":{"819":1}}],["trues",{"2":{"636":2}}],["true",{"2":{"174":6,"190":2,"192":1,"206":1,"210":2,"262":5,"271":6,"331":1,"368":1,"376":2,"409":2,"544":1,"558":1,"575":3,"589":4,"595":12,"599":4,"605":3,"636":2,"669":3,"679":1,"687":3,"695":3,"703":1,"720":1,"726":3,"734":3,"797":1,"852":12,"864":1,"876":1,"883":3,"889":1,"901":1,"905":1,"945":3,"948":1,"949":3,"974":1,"1139":2,"1216":1,"1219":2,"1220":2,"1221":2,"1315":2,"1398":1,"1401":1,"1404":1,"1409":2,"1414":1,"1432":1,"1463":1,"1465":1,"1466":1,"1483":1}}],["tree",{"2":{"299":1,"342":1,"772":1,"1320":2}}],["tr",{"2":{"81":2}}],["try",{"2":{"67":4,"137":1,"326":4,"332":7,"333":1,"335":5,"376":1,"409":4,"446":20,"448":2,"449":4,"451":1,"463":1,"473":2,"474":1,"483":1,"489":1,"496":1,"503":1,"509":1,"523":3,"528":3,"546":3,"547":1,"560":3,"561":1,"576":1,"680":3,"682":6,"686":2,"702":3,"713":1,"715":3,"726":2,"767":3,"789":1,"790":1,"796":3,"827":4,"828":3,"835":4,"837":3,"865":3,"874":3,"883":6,"895":3,"907":3,"927":3,"961":3,"1129":1,"1236":1,"1471":1}}],["track",{"2":{"1520":2}}],["trace",{"2":{"27":2,"54":4,"55":2,"56":1,"57":4,"59":3,"87":5,"88":2,"108":1,"113":1,"114":2}}],["trading",{"2":{"1140":1}}],["tradeoff",{"2":{"169":1}}],["traveler",{"2":{"546":2}}],["traveller",{"2":{"326":4,"333":3,"335":11}}],["transport",{"2":{"1047":4,"1048":5}}],["transposition中",{"2":{"972":1}}],["transposition",{"2":{"970":1}}],["transposed",{"2":{"861":2,"862":1,"886":1,"967":2}}],["transpose",{"2":{"128":1,"325":1,"330":1,"332":1,"335":1,"370":4,"375":5,"382":31,"409":3,"573":1,"574":2,"674":4,"702":2,"763":1,"862":2,"863":7,"865":1,"866":3,"919":3,"932":2,"933":2,"945":4,"946":2,"947":1,"956":2,"964":5,"992":5,"1077":1}}],["transfer中的内容图像为本书作者在西雅图郊区的雷尼尔山国家公园拍摄的风景照",{"2":{"916":1}}],["transfer",{"2":{"813":4,"869":1,"886":1,"916":2,"917":3}}],["transform=augs",{"2":{"882":2}}],["transform=test",{"2":{"874":2}}],["transform=train",{"2":{"874":2}}],["transform=transform",{"2":{"892":4,"904":4}}],["transform=trans",{"2":{"582":4,"584":4}}],["transformation",{"2":{"610":2}}],["transform",{"2":{"583":1,"584":2,"874":2,"882":1,"891":4,"892":6,"903":4,"904":6,"947":4}}],["transforms",{"2":{"581":2,"582":2,"583":1,"584":9,"863":2,"866":4,"872":27,"879":9,"880":9,"881":6,"882":15,"891":27,"903":34,"919":13,"946":6,"947":2}}],["transformer会面临什么挑战",{"2":{"411":1}}],["transformer模型中基于位置的前馈网络使用同一个多层感知机",{"2":{"410":1}}],["transformer模型完全基于注意力机制",{"2":{"403":1}}],["transformer是编码器",{"2":{"410":1}}],["transformer是由编码器和解码器组成的",{"2":{"404":1}}],["transformerdecoder",{"2":{"408":7,"409":4}}],["transformer解码器",{"2":{"408":1}}],["transformer解码器也是由多个相同的层组成",{"2":{"408":1}}],["transformer解码器也是由多个相同的层叠加而成的",{"2":{"404":1}}],["transformer所示",{"2":{"408":1}}],["transformerencoder",{"2":{"407":11,"409":4}}],["transformer编码器或transformer解码器通常被单独用于不同的深度学习任务中",{"2":{"409":1}}],["transformer编码器输出的形状是",{"2":{"407":1}}],["transformer编码器",{"2":{"407":5}}],["transformer编码器中的任何层都不会改变其输入的形状",{"2":{"407":1}}],["transformer编码器块",{"2":{"407":4,"726":1}}],["transformer编码器都将输出一个d维表示向量",{"2":{"404":1}}],["transformer的编码器是由多个相同的层叠加而成的",{"2":{"404":1}}],["transformer的编码器和解码器是基于自注意力的模块叠加而成的",{"2":{"404":1}}],["transformer中实现的transformerencoder类",{"2":{"734":1}}],["transformer中的残差连接和层规范化是训练非常深度模型的重要工具",{"2":{"410":1}}],["transformer中的加法和规范化",{"2":{"406":1}}],["transformer中概述了transformer的架构",{"2":{"404":1}}],["transformer中展示",{"2":{"404":1}}],["transformer作为编码器",{"2":{"404":1}}],["transformer",{"0":{"403":1},"1":{"404":1,"405":1,"406":1,"407":1,"408":1,"409":1,"410":1,"411":1},"2":{"379":1,"403":1,"404":1,"411":1,"583":2}}],["transformer一直都普遍存在于现代的深度学习应用中",{"2":{"379":1}}],["trans",{"2":{"582":2,"584":14,"863":9,"968":6,"969":4,"970":2}}],["transduction",{"2":{"564":1}}],["transitionblock",{"2":{"481":3,"482":1}}],["transition",{"2":{"479":1,"481":5,"482":3}}],["translation的机器翻译模型",{"2":{"754":1}}],["translation中对机器翻译数据集的预处理步骤",{"2":{"693":1}}],["translation中",{"2":{"572":1,"575":1}}],["translation中看到的",{"2":{"572":1}}],["translation中所讨论的",{"2":{"532":1}}],["translation中高效处理小批量数据集",{"2":{"368":1}}],["translation",{"2":{"152":1,"376":6,"409":7,"550":1,"564":4,"578":6,"610":1}}],["train路径中将有45000张图像用于训练",{"2":{"890":1}}],["train和test文件夹分别包含训练和测试图像",{"2":{"889":1}}],["train和hotdog",{"2":{"872":1}}],["trainlabels",{"2":{"889":2,"890":2}}],["train的负采样为例",{"2":{"771":1}}],["train中提到的",{"2":{"742":1}}],["train中的第3个时间步的输出o3",{"2":{"341":1}}],["train中的图像",{"2":{"181":1}}],["train表示是否希望数据迭代器对象在每个迭代周期内打乱数据",{"2":{"590":1}}],["train包含着键",{"2":{"388":4}}],["train个样本用于训练",{"2":{"350":1}}],["train演示了",{"2":{"341":1}}],["train=is",{"2":{"882":2,"947":3}}],["train=false",{"2":{"263":4,"271":1,"582":2,"584":2,"667":1,"695":3,"932":3}}],["train=true",{"2":{"79":4,"350":1,"582":2,"584":2,"590":4,"667":1,"692":1,"882":2,"932":6,"945":3}}],["train+n",{"2":{"262":1}}],["training慢得多",{"2":{"376":1}}],["training类似",{"2":{"376":1,"409":1}}],["training=self",{"2":{"472":1}}],["training=true",{"2":{"406":1,"472":1,"576":1,"595":1}}],["training=false",{"2":{"369":1,"370":1,"375":2,"382":1,"396":1,"398":1,"406":1,"407":2,"408":1,"573":1,"574":1,"577":2}}],["training=none",{"2":{"174":1}}],["training",{"2":{"137":2,"174":14,"252":1,"286":2,"388":4,"392":4,"408":4,"472":5,"576":1,"609":2,"732":1,"754":1,"932":3,"1063":1,"1131":1,"1132":1}}],["trainable=false",{"2":{"472":2}}],["trainable=true",{"2":{"80":2,"472":2,"601":2}}],["trainable",{"2":{"81":1,"210":1,"278":3,"332":2,"335":1,"350":1,"392":2,"576":2,"595":2,"635":1}}],["traincallback",{"2":{"67":1,"137":2}}],["trainer",{"2":{"21":6,"29":6,"34":6,"57":6,"67":17,"68":11,"71":13,"72":6,"73":6,"80":8,"81":15,"92":6,"109":6,"137":3,"175":6,"176":8,"210":3,"225":6,"263":9,"278":11,"335":3,"350":11,"392":9,"576":3,"594":5,"595":6,"625":4,"626":1,"635":1,"681":7,"688":7,"704":7,"715":7,"726":9,"767":3,"828":9,"865":7,"874":9,"883":21,"894":10,"906":12,"926":7,"927":11,"961":4,"963":5}}],["train",{"2":{"21":5,"27":2,"28":1,"29":4,"34":5,"35":4,"57":3,"67":71,"68":8,"71":8,"72":8,"73":8,"80":10,"81":8,"87":5,"88":2,"91":5,"92":4,"108":2,"109":4,"113":1,"114":2,"137":57,"175":12,"176":8,"181":1,"208":7,"209":7,"210":49,"211":24,"212":4,"213":12,"216":1,"221":8,"225":3,"262":2,"263":47,"264":5,"265":5,"266":5,"271":5,"275":16,"276":1,"277":1,"278":18,"282":1,"324":4,"326":8,"329":2,"335":43,"341":1,"350":28,"351":12,"376":3,"386":26,"387":4,"388":28,"391":2,"392":89,"409":12,"462":1,"463":2,"473":7,"474":2,"483":3,"488":1,"489":3,"496":3,"503":3,"509":4,"523":9,"528":3,"529":2,"543":4,"546":6,"547":8,"557":4,"560":6,"561":8,"569":2,"576":9,"582":14,"583":10,"584":12,"590":4,"595":1,"605":8,"622":1,"626":2,"629":1,"635":32,"667":8,"669":26,"679":10,"681":6,"687":9,"688":8,"692":7,"693":7,"694":14,"695":30,"698":3,"704":6,"707":1,"712":3,"715":6,"718":1,"722":16,"725":6,"726":14,"767":4,"772":1,"828":13,"837":17,"864":4,"865":6,"872":10,"874":20,"882":12,"883":61,"885":1,"889":1,"890":15,"891":3,"892":30,"894":29,"895":6,"896":9,"901":2,"902":1,"903":3,"904":30,"906":18,"907":6,"908":12,"927":6,"932":29,"945":20,"946":6,"947":6,"948":10,"949":6,"961":1,"963":8,"1131":2}}],["tag",{"0":{"1335":1},"2":{"1315":2,"1335":2}}],["tagger",{"2":{"731":1}}],["tagging中说明了文本标记应用的bert微调",{"2":{"659":1}}],["tagging",{"2":{"659":2}}],["tangent",{"2":{"981":1}}],["tanh函数的平均值为0",{"2":{"332":1}}],["tanh函数的导数接近最大值1",{"2":{"237":1}}],["tanh函数的导数图像如下所示",{"2":{"237":1}}],["tanh函数的导数是",{"2":{"237":1}}],["tanh函数的公式如下",{"2":{"237":1}}],["tanh函数接近线性变换",{"2":{"237":1}}],["tanh函数",{"0":{"237":1}}],["tanh",{"2":{"103":2,"237":15,"332":4,"369":4,"545":4,"559":8,"738":3}}],["ta",{"2":{"757":2}}],["tasks",{"2":{"718":1,"735":1}}],["talkstore",{"2":{"1490":2}}],["talklist就是state",{"2":{"1495":1}}],["talklist",{"2":{"1490":2,"1494":1,"1495":4}}],["talk",{"2":{"1490":6,"1494":1,"1495":1}}],["talking",{"2":{"658":1}}],["tal",{"2":{"757":1}}],["tallest",{"2":{"757":1}}],["taller",{"2":{"757":1}}],["tallec",{"2":{"310":1}}],["tall",{"2":{"757":5}}],["taking",{"2":{"658":2}}],["tackstrom",{"2":{"395":1,"672":1}}],["tau+1",{"2":{"351":3}}],["tau",{"2":{"350":12,"351":49}}],["tay",{"2":{"231":1,"411":1,"642":1}}],["taylor的导数",{"2":{"59":1}}],["taylor中的o",{"2":{"55":1}}],["taylor",{"2":{"54":2,"57":1,"59":1,"479":1}}],["tape",{"2":{"210":2,"275":2,"278":2,"576":2,"595":2,"635":3}}],["targetport",{"2":{"1391":1}}],["targets",{"2":{"865":4,"932":9}}],["target函数",{"2":{"852":1,"853":1}}],["target",{"2":{"284":1,"565":1,"566":8,"569":3,"609":1,"765":3,"852":3,"853":3,"890":3,"932":6,"963":9,"1498":1,"1500":3}}],["tar",{"2":{"206":1,"692":1,"945":1}}],["tar文件可以被解压缩",{"2":{"206":1}}],["tar文件",{"2":{"206":1}}],["tarfile",{"2":{"206":2}}],["table",{"2":{"813":2}}],["tab",{"2":{"21":7,"23":8,"27":5,"28":4,"29":3,"31":8,"34":7,"35":3,"37":8,"38":3,"41":2,"44":1,"52":8,"54":8,"55":2,"56":1,"57":5,"59":3,"64":8,"67":6,"68":8,"70":1,"71":6,"72":4,"73":4,"75":8,"77":12,"78":3,"79":3,"80":11,"81":6,"83":8,"87":4,"88":2,"89":1,"91":9,"92":3,"95":1,"97":8,"99":6,"101":2,"102":4,"103":2,"105":8,"107":4,"108":8,"109":3,"111":8,"112":3,"113":4,"114":2,"118":8,"120":5,"121":3,"122":4,"124":8,"126":5,"127":3,"128":5,"129":6,"133":8,"136":6,"137":9,"139":8,"141":6,"142":6,"144":8,"146":6,"147":22,"148":9,"150":8,"172":6,"173":2,"174":3,"175":3,"176":6,"178":8,"206":3,"208":8,"209":3,"210":8,"211":2,"212":1,"213":2,"215":8,"216":4,"217":3,"218":3,"219":3,"220":2,"221":4,"223":8,"224":3,"225":7,"227":8,"234":3,"235":6,"236":6,"237":6,"239":8,"242":3,"243":3,"250":8,"261":3,"262":3,"263":6,"264":1,"265":1,"266":1,"268":8,"271":4,"273":3,"274":3,"275":3,"276":1,"277":1,"278":11,"280":8,"300":1,"318":8,"320":2,"321":6,"323":8,"324":3,"325":18,"326":6,"328":8,"329":5,"330":6,"331":3,"332":13,"333":5,"334":3,"335":11,"337":8,"340":6,"344":8,"350":14,"351":10,"353":8,"357":5,"359":8,"360":3,"361":1,"362":1,"363":3,"364":1,"366":8,"367":3,"368":9,"369":7,"370":7,"372":6,"374":3,"375":7,"376":6,"378":6,"381":3,"382":11,"384":6,"385":3,"386":7,"387":3,"388":6,"390":6,"391":3,"392":12,"394":6,"395":3,"396":5,"398":6,"399":4,"402":6,"404":3,"405":6,"406":8,"407":11,"408":8,"409":13,"411":6,"413":11,"414":17,"416":8,"418":9,"420":8,"422":11,"423":9,"424":11,"425":7,"426":8,"428":8,"429":3,"430":2,"431":6,"432":5,"433":8,"434":8,"435":9,"436":16,"437":7,"439":8,"441":12,"442":11,"444":8,"445":8,"446":15,"447":3,"448":6,"449":11,"451":7,"453":8,"461":6,"462":1,"463":1,"465":8,"472":6,"473":8,"474":4,"477":8,"480":9,"481":5,"482":9,"483":1,"485":8,"487":3,"488":18,"489":1,"491":8,"494":3,"495":6,"496":1,"498":8,"501":9,"502":14,"503":1,"505":8,"507":7,"508":7,"509":3,"511":8,"523":2,"525":6,"528":4,"529":1,"531":6,"533":3,"534":3,"535":3,"537":6,"543":3,"544":3,"545":6,"546":3,"547":3,"549":6,"557":3,"558":3,"559":6,"560":3,"561":3,"563":6,"564":3,"565":2,"566":2,"567":1,"568":2,"569":2,"571":6,"572":3,"573":8,"574":6,"575":12,"576":4,"577":3,"578":3,"580":6,"581":3,"582":13,"583":4,"584":4,"586":8,"589":4,"590":5,"591":11,"592":17,"593":11,"594":11,"595":6,"596":6,"597":8,"598":3,"599":5,"600":3,"601":3,"602":1,"603":1,"604":3,"605":5,"607":8,"615":9,"616":3,"621":8,"622":4,"623":3,"624":2,"625":3,"626":1,"628":8,"629":4,"630":3,"631":6,"632":1,"633":5,"634":8,"635":8,"636":1,"638":8,"666":2,"667":3,"668":2,"669":4,"671":6,"673":2,"674":4,"675":2,"676":2,"677":2,"679":2,"680":2,"681":2,"682":3,"684":6,"685":2,"686":6,"687":4,"688":5,"690":6,"691":2,"692":2,"693":3,"694":2,"695":2,"697":6,"698":2,"699":4,"702":4,"703":2,"704":4,"706":6,"712":2,"713":5,"714":4,"715":6,"717":6,"718":3,"720":2,"721":2,"722":8,"724":6,"725":4,"726":7,"727":4,"729":6,"733":2,"734":6,"736":6,"737":6,"738":2,"740":6,"744":2,"747":2,"748":5,"750":6,"751":5,"753":6,"757":10,"759":6,"760":2,"762":3,"763":4,"765":5,"766":1,"767":3,"768":2,"770":6,"771":2,"772":2,"773":5,"774":3,"775":3,"776":2,"777":3,"779":6,"789":2,"790":24,"791":4,"792":2,"793":2,"794":12,"795":2,"796":18,"797":10,"799":6,"816":1,"817":1,"818":8,"819":22,"820":20,"821":23,"822":2,"823":12,"825":2,"826":2,"827":12,"828":4,"829":4,"830":10,"833":2,"834":2,"835":7,"836":4,"837":6,"839":6,"847":2,"848":8,"849":2,"851":2,"852":3,"853":6,"854":11,"856":6,"857":4,"858":5,"860":6,"861":2,"862":7,"863":10,"864":2,"865":2,"866":6,"868":6,"871":2,"872":6,"873":11,"874":5,"876":10,"877":2,"878":2,"879":6,"880":6,"881":2,"882":10,"883":7,"885":6,"887":2,"889":1,"890":5,"891":4,"892":4,"893":12,"894":2,"895":2,"896":2,"897":6,"898":6,"899":2,"901":1,"902":1,"903":4,"904":4,"905":4,"906":2,"907":2,"908":2,"910":6,"912":7,"915":6,"918":3,"919":2,"920":7,"922":2,"923":3,"924":1,"925":1,"926":4,"927":4,"929":6,"931":3,"932":7,"933":2,"935":6,"938":6,"942":6,"945":11,"946":4,"947":2,"948":3,"949":2,"951":6,"954":2,"955":2,"956":5,"957":4,"958":2,"959":9,"961":3,"962":4,"963":2,"964":6,"966":10,"967":2,"968":4,"969":6,"970":8,"972":6,"974":18,"975":3,"976":6,"977":9,"979":8,"981":9,"986":8,"989":3,"990":6,"991":6,"992":12,"993":3,"994":9,"995":21,"996":9,"997":6,"998":9,"999":3,"1000":9,"1004":8,"1005":6,"1006":3,"1007":6,"1009":8,"1011":2,"1012":2,"1013":3,"1015":8,"1017":37,"1018":12,"1019":4,"1020":9,"1021":14,"1022":10,"1024":8,"1026":15,"1038":8}}],["t",{"2":{"25":4,"34":12,"35":16,"68":2,"70":2,"71":6,"72":7,"73":4,"79":4,"95":4,"106":1,"113":6,"114":12,"115":3,"136":4,"235":2,"236":2,"237":2,"242":2,"263":1,"300":1,"325":3,"330":3,"332":3,"334":1,"335":3,"350":10,"351":13,"392":2,"398":4,"461":4,"488":4,"495":4,"502":4,"508":4,"549":1,"566":1,"574":1,"582":1,"667":1,"708":10,"713":3,"757":3,"783":2,"784":1,"785":2,"786":1,"848":3,"876":1,"923":1,"970":2,"974":4,"975":2,"976":3,"977":2,"992":4,"1081":1,"1085":4,"1086":1,"1088":1,"1091":8,"1103":1,"1109":2,"1117":2,"1121":1,"1154":1,"1159":2,"1184":1,"1185":1,"1409":1,"1410":4,"1412":1,"1430":4,"1431":3,"1432":6,"1433":6,"1434":10,"1435":8}}],["tfp",{"2":{"1026":5}}],["tflops",{"2":{"457":1}}],["tflops的浮点性能",{"2":{"457":1}}],["tf",{"2":{"21":9,"27":1,"28":4,"29":1,"34":8,"35":4,"38":1,"54":1,"67":13,"68":3,"77":7,"78":1,"80":7,"81":6,"87":1,"91":2,"92":1,"99":1,"107":1,"108":4,"109":1,"112":1,"120":2,"126":4,"127":2,"128":3,"129":6,"136":11,"137":5,"141":6,"142":2,"146":5,"147":7,"148":4,"172":6,"174":5,"175":2,"176":8,"208":1,"210":10,"216":1,"217":8,"218":1,"219":2,"220":1,"224":1,"225":6,"234":1,"235":5,"236":3,"237":3,"242":5,"243":3,"261":1,"263":4,"271":1,"273":4,"274":2,"275":2,"278":7,"300":1,"318":1,"324":1,"325":8,"326":1,"329":1,"330":4,"331":5,"332":10,"334":8,"335":4,"340":1,"350":8,"351":2,"357":1,"367":1,"368":10,"369":16,"370":7,"374":1,"375":11,"381":1,"382":14,"385":2,"386":2,"387":2,"388":8,"390":9,"391":9,"392":19,"395":1,"396":2,"398":3,"399":2,"404":1,"405":5,"406":8,"407":7,"408":10,"409":3,"413":8,"414":7,"418":5,"422":5,"423":3,"424":3,"425":17,"429":6,"431":1,"433":6,"435":12,"436":7,"437":5,"441":3,"442":5,"446":11,"447":1,"448":2,"451":3,"461":17,"472":11,"473":15,"474":17,"480":8,"481":5,"482":10,"487":10,"488":17,"494":5,"495":9,"501":10,"502":14,"507":4,"508":9,"533":2,"534":1,"535":1,"543":1,"544":5,"545":12,"546":1,"547":3,"557":1,"558":6,"559":17,"560":1,"561":3,"564":1,"572":1,"573":5,"574":8,"575":18,"576":7,"577":7,"581":1,"582":3,"583":1,"584":6,"589":1,"590":1,"591":2,"592":3,"593":1,"594":1,"595":1,"598":1,"599":3,"600":3,"601":4,"605":2,"615":2,"622":1,"623":4,"624":1,"625":1,"629":1,"630":4,"631":2,"633":7,"635":7,"819":5,"820":1,"821":1,"857":1,"974":7,"975":1,"976":2,"977":5,"989":3,"990":1,"992":5,"993":2,"994":4,"995":11,"996":2,"997":3,"998":1,"999":3,"1000":6,"1006":2,"1007":2,"1013":3,"1017":8,"1018":9,"1019":4,"1020":4,"1021":4,"1022":2,"1026":4}}],["tony",{"2":{"1518":1}}],["toy事件被触发",{"2":{"1499":1}}],["toy=",{"2":{"1498":1}}],["toy",{"2":{"1497":6,"1498":3,"1499":4}}],["touppercase",{"2":{"1493":1}}],["to的对象写法配合name属性",{"2":{"1478":1}}],["to的对象写法",{"2":{"1477":1,"1481":1,"1482":1}}],["to的字符串写法",{"2":{"1477":1,"1478":1,"1481":1,"1482":1}}],["to的两种写法",{"0":{"1477":1}}],["to=",{"2":{"1474":3,"1477":2,"1478":2,"1479":3,"1481":2,"1482":2,"1522":1}}],["toraw",{"0":{"1517":1,"1518":1},"1":{"1518":1,"1519":1},"2":{"1518":5}}],["toref",{"0":{"1459":1},"2":{"1459":2}}],["torefs与toref功能一致",{"2":{"1459":1}}],["torefs",{"0":{"1459":1},"2":{"1459":2}}],["torch张量和numpy数组将共享它们的底层内存",{"2":{"1022":1}}],["torchscript允许用户使用纯命令式编程进行开发和调试",{"2":{"818":1}}],["torchvision",{"2":{"581":2,"582":2,"584":2,"861":1,"862":1,"863":1,"866":2,"871":1,"872":11,"873":2,"874":3,"877":1,"879":3,"880":3,"881":2,"882":7,"887":1,"891":9,"892":2,"899":1,"903":11,"904":2,"905":1,"918":1,"919":5,"920":1,"931":1,"932":1,"938":2,"945":4,"946":3,"947":1,"954":1,"964":1}}],["torch和theano",{"2":{"300":1}}],["torch",{"2":{"21":7,"27":2,"28":3,"29":1,"34":6,"35":5,"38":2,"54":2,"67":6,"68":1,"71":1,"72":1,"73":1,"77":9,"78":1,"79":1,"80":2,"81":2,"87":2,"91":1,"92":1,"99":2,"107":2,"108":3,"109":1,"112":2,"120":2,"126":3,"127":2,"136":4,"137":3,"141":3,"146":3,"172":7,"175":1,"176":1,"208":3,"210":5,"216":3,"217":4,"218":2,"221":1,"224":3,"225":1,"234":2,"235":3,"236":2,"237":2,"242":5,"243":3,"261":3,"263":1,"271":3,"273":2,"274":1,"275":1,"278":1,"318":2,"324":4,"325":6,"329":4,"330":1,"331":1,"332":6,"334":2,"335":2,"340":2,"350":4,"357":2,"360":1,"367":3,"368":4,"369":3,"370":2,"374":3,"375":4,"381":3,"382":1,"385":3,"386":1,"387":1,"390":2,"391":2,"392":3,"395":3,"398":4,"404":3,"408":2,"413":5,"414":5,"422":4,"425":2,"429":3,"441":11,"442":3,"446":12,"447":1,"448":2,"461":4,"472":10,"480":5,"487":5,"488":1,"494":3,"495":1,"501":5,"502":1,"507":3,"508":1,"523":3,"528":3,"533":1,"543":3,"544":1,"545":5,"557":3,"558":1,"559":8,"564":2,"572":3,"575":6,"576":4,"577":6,"581":3,"582":1,"589":3,"591":1,"594":1,"598":2,"601":2,"604":1,"605":1,"615":2,"622":3,"625":1,"629":2,"630":2,"634":2,"635":2,"666":3,"668":3,"669":2,"673":4,"674":3,"675":2,"676":1,"681":1,"682":3,"685":3,"686":3,"687":7,"688":1,"691":3,"694":1,"695":4,"698":3,"702":3,"704":1,"712":3,"713":1,"715":3,"718":2,"722":9,"725":3,"726":1,"727":3,"733":3,"734":3,"736":4,"737":2,"747":3,"750":5,"760":3,"763":3,"767":1,"768":5,"771":2,"777":2,"789":3,"790":10,"795":2,"796":8,"797":3,"819":5,"820":1,"825":3,"828":1,"833":4,"834":10,"835":1,"836":3,"837":2,"847":3,"848":12,"849":2,"851":6,"852":6,"854":7,"857":2,"861":4,"862":1,"863":5,"865":1,"866":1,"871":3,"874":4,"876":1,"877":3,"882":1,"883":1,"887":3,"892":3,"894":2,"896":1,"899":3,"904":3,"906":2,"908":1,"912":2,"918":3,"919":3,"922":1,"923":1,"926":2,"927":1,"931":2,"932":4,"938":3,"945":3,"947":1,"948":1,"949":2,"954":4,"956":4,"957":1,"958":1,"959":2,"961":1,"962":1,"964":1,"966":4,"967":3,"969":1,"974":3,"975":1,"977":1,"981":1,"989":3,"990":1,"992":2,"993":1,"994":2,"995":1,"997":4,"998":1,"999":2,"1000":5,"1006":2,"1007":2,"1013":3,"1017":6,"1018":7,"1019":2,"1021":1,"1022":2,"1026":4}}],["too",{"2":{"1141":2}}],["tool",{"2":{"1048":1,"1052":1}}],["toolkits",{"2":{"38":4,"99":4}}],["together",{"2":{"1126":1}}],["toml",{"2":{"1285":1}}],["tom定义的机器学习是",{"2":{"1059":1}}],["tomography",{"2":{"289":1}}],["total",{"2":{"924":1,"1215":1,"1240":1}}],["totensor",{"2":{"582":2,"583":1,"584":3,"863":2,"872":6,"882":6,"891":6,"903":6,"919":2}}],["topilimage",{"2":{"919":1}}],["topk",{"2":{"750":14,"751":2,"768":9}}],["tokyo",{"2":{"751":2}}],["tok",{"2":{"717":2}}],["tokenembedding",{"2":{"680":3,"703":3,"714":1,"748":2}}],["token=",{"2":{"362":1,"693":1,"695":6,"722":3}}],["token",{"2":{"318":13,"333":4,"362":4,"363":26,"364":2,"568":2,"680":3,"686":15,"687":36,"703":3,"714":1,"721":10,"722":30,"727":6,"734":6,"748":16,"750":3,"751":7,"757":37,"768":6,"773":12,"1315":3}}],["tokenize函数进行词元化",{"2":{"722":1}}],["tokenizer",{"2":{"717":2}}],["tokenize",{"2":{"318":1,"362":2,"364":1,"566":2,"569":1,"668":6,"687":3,"693":1,"695":6,"722":3,"724":2}}],["tokens的输出",{"2":{"722":1}}],["tokens是一个字符串列表",{"2":{"721":1}}],["tokens是表示bert输入序列的词元的列表",{"2":{"721":1}}],["tokens函数",{"2":{"721":2}}],["tokens=",{"2":{"364":1,"567":1,"569":2,"668":3,"693":1,"722":3}}],["tokens=none",{"2":{"363":2}}],["tokens=10000",{"2":{"321":1}}],["tokens",{"2":{"318":6,"321":12,"362":2,"363":20,"364":5,"566":1,"576":13,"577":24,"578":7,"668":18,"687":94,"688":6,"693":5,"695":15,"718":1,"720":9,"721":17,"722":11,"726":18,"727":30,"734":23,"738":6,"748":2,"750":4,"757":4,"767":3,"768":9,"773":3,"775":1,"890":2}}],["tolist",{"2":{"409":3,"577":1,"615":1}}],["toc",{"2":{"65":1,"134":1,"204":1,"305":1,"379":1,"421":1,"492":1,"550":1,"587":1,"663":1,"754":1,"824":1,"886":1,"987":1,"1057":1,"1078":1,"1095":1,"1104":1,"1118":1,"1128":1,"1142":1,"1149":1,"1163":1,"1177":1}}],["to",{"2":{"0":1,"47":1,"67":3,"77":3,"137":12,"172":1,"213":1,"315":2,"325":1,"326":1,"330":1,"332":1,"333":4,"334":1,"335":4,"363":13,"368":2,"369":1,"398":2,"408":1,"409":2,"413":1,"431":1,"436":2,"447":1,"448":2,"451":2,"472":2,"487":1,"500":1,"523":1,"525":4,"528":1,"547":1,"561":1,"572":1,"574":1,"575":4,"576":4,"577":7,"668":2,"680":3,"682":2,"686":9,"687":4,"703":3,"714":1,"715":1,"721":1,"722":7,"726":8,"727":3,"732":4,"734":1,"736":2,"737":1,"748":18,"750":2,"751":2,"754":4,"767":5,"768":3,"775":1,"791":3,"792":2,"794":1,"796":2,"797":12,"813":8,"819":4,"820":2,"828":4,"835":7,"836":1,"848":3,"851":4,"852":10,"854":7,"858":10,"860":2,"866":3,"883":7,"894":1,"896":4,"905":4,"906":3,"908":1,"912":1,"919":3,"920":2,"926":1,"927":1,"932":2,"938":2,"947":2,"959":6,"963":3,"964":3,"966":1,"970":1,"972":1,"974":1,"977":1,"989":2,"992":1,"1000":1,"1013":8,"1017":1,"1018":3,"1022":2,"1026":4,"1048":1,"1109":2,"1110":2,"1129":1,"1135":1,"1137":1,"1141":3,"1151":5,"1168":1,"1174":1,"1183":1,"1443":1,"1444":1}}],["thank",{"2":{"1176":1}}],["that",{"2":{"660":3,"1443":1}}],["throw",{"2":{"1404":1,"1431":2}}],["through",{"2":{"306":1}}],["threshold是一个用于非背景预测的阈值",{"2":{"854":3}}],["threshold",{"2":{"851":4,"854":12,"964":6}}],["threshold=0",{"2":{"851":3,"854":9,"964":3}}],["threadripper有8个插槽",{"2":{"802":1}}],["threading",{"2":{"790":1}}],["threading演示了前端和后端如何交互",{"2":{"790":1}}],["three",{"2":{"544":16,"558":20}}],["theano",{"2":{"818":1}}],["their",{"2":{"660":1}}],["they",{"2":{"532":1}}],["thefollowinglayersarethesameasb2",{"2":{"502":1}}],["thefollowinglayersarethesameasb1thatwecreatedearlier",{"2":{"502":1}}],["theory",{"2":{"342":1,"649":2}}],["theorem",{"2":{"253":1,"1032":1}}],["thetavec",{"2":{"1121":4}}],["theta3",{"2":{"1121":2}}],["theta2",{"2":{"1121":3}}],["theta1",{"2":{"1121":4,"1125":1}}],["theta^",{"2":{"1112":1,"1121":1}}],["theta",{"2":{"334":15,"1068":2,"1081":2,"1085":3,"1092":1,"1093":3,"1101":1,"1109":8,"1110":14,"1111":6,"1115":6,"1116":1,"1117":7,"1120":4,"1121":3,"1124":2,"1145":2,"1165":2}}],["theme",{"0":{"2":1},"2":{"0":4,"2":1,"1407":3}}],["the",{"2":{"0":3,"5":2,"6":1,"9":2,"292":1,"318":1,"319":1,"525":2,"660":2,"732":2,"754":2,"773":3,"783":4,"785":3,"1056":1,"1098":1,"1114":1,"1154":1,"1160":1,"1168":2,"1174":1,"1185":1,"1443":1}}],["this",{"2":{"0":1,"6":1,"8":10,"295":2,"704":2,"715":2,"724":2,"736":7,"1399":1,"1416":4,"1417":7,"1422":6,"1425":11,"1426":3,"1427":1,"1428":5,"1432":6,"1445":3,"1454":1,"1491":4,"1493":1,"1498":1}}],["b+",{"0":{"1199":1},"2":{"1199":1}}],["b个训练实例",{"2":{"1166":1}}],["bson",{"0":{"1197":1},"2":{"1196":1,"1197":1}}],["bs",{"2":{"1154":1}}],["bgfs",{"2":{"1111":1}}],["b在下面",{"2":{"1089":1}}],["b为",{"2":{"1089":1}}],["b×c",{"2":{"1076":1}}],["b∣a",{"2":{"1032":2}}],["b∣c",{"2":{"515":2,"1034":2}}],["b是一个4行3列的矩阵",{"2":{"999":1}}],["b是r中的三个点",{"2":{"46":1}}],["bb",{"2":{"852":25,"854":15}}],["bbox中打印出的原图看上去没什么两样",{"2":{"863":1}}],["bbox是边界框的英文缩写",{"2":{"858":1}}],["bbox函数中实现",{"2":{"851":1}}],["bbox=dict",{"2":{"848":1}}],["bbox",{"2":{"848":5,"851":15,"852":36,"853":2,"854":10,"857":1,"858":14,"912":6,"943":1,"952":1,"955":3,"959":45,"962":54,"963":50,"964":12}}],["bboxes",{"2":{"848":4,"853":2,"854":2,"912":3,"933":3,"964":3}}],["bboxes函数来在图像上绘制多个边界框",{"2":{"848":1}}],["bw",{"2":{"841":1}}],["b等操作必须重写为a",{"2":{"821":1}}],["b和a",{"2":{"821":1}}],["b和c",{"2":{"751":1,"1038":1}}],["b中所有词元的bert",{"2":{"727":1}}],["bcebos",{"2":{"686":2}}],["bc∈r1×h是偏置参数",{"2":{"554":1}}],["bj",{"2":{"674":2,"675":1,"686":2}}],["bj∈rd",{"2":{"674":1}}],["b^",{"2":{"613":1}}],["b←b−η|b|∑i∈b∂bl",{"2":{"613":1}}],["b∗=argminw",{"2":{"611":1}}],["b∗",{"2":{"611":1}}],["b称为偏置",{"2":{"610":1}}],["b的词元数",{"2":{"674":6}}],["b的形状",{"2":{"674":6}}],["b的估计误差",{"2":{"595":4,"605":1}}],["b的系数比",{"2":{"154":1}}],["bfgs或者等高线梯度的实现上",{"2":{"1111":1}}],["bfgs这些算法",{"2":{"1111":1}}],["bfgs的细节",{"2":{"1111":1}}],["bfgs",{"2":{"1109":1,"1111":3}}],["bf",{"2":{"553":1}}],["bz∈r1×h是偏置参数",{"2":{"540":1}}],["bhagavatula",{"2":{"731":1}}],["bh∈r1×h是偏置项",{"2":{"541":1}}],["bh",{"2":{"521":1}}],["b5116e234e9eb9076672cfeabf5469f3eec904fa",{"2":{"748":1}}],["b5",{"2":{"488":8,"502":5}}],["b4",{"2":{"488":8,"502":6,"834":6}}],["bnb",{"2":{"851":1}}],["bn2",{"2":{"501":8,"893":2}}],["bn1",{"2":{"501":8,"893":2}}],["bn",{"2":{"406":9,"467":1,"469":1,"480":2,"674":1}}],["blame",{"2":{"1336":1}}],["black",{"2":{"1026":4,"1264":1}}],["blob",{"2":{"1320":2}}],["blog",{"2":{"1121":1}}],["block4",{"2":{"826":2}}],["block3",{"2":{"826":2}}],["block给出了基本处理块的概述",{"2":{"811":1}}],["blocking参数",{"2":{"797":1}}],["blocking",{"2":{"797":1}}],["blocking=true以模拟这个场景",{"2":{"797":1}}],["blocking=non",{"2":{"797":1}}],["blocking=false",{"2":{"797":1}}],["block函数中定义",{"2":{"508":1}}],["block的函数来实现一个vgg块",{"2":{"507":1}}],["block的类型是ordereddict",{"2":{"424":1}}],["block=true",{"2":{"502":4,"826":3,"893":1}}],["block=false",{"2":{"502":4,"826":3,"893":1}}],["block右图是resnet的基础架构",{"2":{"501":1}}],["block中右图虚线框内上方的加权运算",{"2":{"501":1}}],["block左图虚线框中的部分需要直接拟合出该映射f",{"2":{"501":1}}],["block上方激活函数的输入",{"2":{"501":1}}],["block所示",{"2":{"479":1,"501":2}}],["block2",{"2":{"433":8,"826":2}}],["block1",{"2":{"433":8,"826":2}}],["block是tf",{"2":{"424":1}}],["block是block子类的一个实例",{"2":{"424":1}}],["blocks中的vgg模块设计",{"2":{"957":1}}],["blocks",{"2":{"422":1,"482":12,"500":1,"504":1,"819":2}}],["blocks所示",{"2":{"422":1}}],["block",{"2":{"8":2,"78":4,"127":1,"325":1,"334":1,"335":1,"369":1,"370":1,"382":1,"391":1,"398":1,"405":1,"406":1,"407":2,"408":2,"413":1,"414":1,"421":1,"422":1,"423":1,"424":11,"425":2,"433":4,"442":1,"472":1,"479":2,"480":7,"481":5,"482":7,"487":2,"494":4,"495":16,"501":4,"502":15,"507":4,"508":4,"533":1,"534":1,"535":1,"674":1,"675":1,"676":1,"677":1,"688":1,"702":1,"713":1,"734":1,"736":1,"737":1,"738":1,"811":1,"826":18,"893":6,"926":1,"956":7,"959":1}}],["blue",{"2":{"858":1,"1413":2}}],["blues",{"2":{"399":4}}],["blks",{"2":{"407":15,"408":15,"482":8,"508":6,"734":9}}],["blk",{"2":{"407":20,"408":27,"409":8,"480":17,"481":9,"494":3,"501":16,"502":12,"507":8,"508":12,"734":6,"826":12,"893":4,"957":23,"958":12,"959":55}}],["bleu是一种常用的评估方法",{"2":{"579":1}}],["bleu的代码实现",{"2":{"578":1}}],["bleu的评估都是这个n元语法是否出现在标签序列中",{"2":{"578":1}}],["bleu中乘法项之前的系数用于惩罚较短的预测序列",{"2":{"578":1}}],["bleu中bleu的定义",{"2":{"578":1}}],["bleu为1",{"2":{"578":1}}],["bleu",{"2":{"376":4,"409":4,"578":6}}],["bmm",{"2":{"369":2,"370":4,"390":4,"391":2,"674":6,"763":2}}],["bq∈r1×q是输出层的偏置参数",{"2":{"339":1}}],["bt=∂f",{"2":{"307":1}}],["bt和ct",{"2":{"307":1}}],["bt",{"2":{"307":1}}],["br>",{"2":{"1460":3,"1468":2,"1471":1}}],["brill进行了一项有趣的研究",{"2":{"1141":1}}],["brightness",{"2":{"880":1}}],["brightness=0",{"2":{"880":7,"903":3}}],["breed",{"2":{"899":1,"901":5,"1471":1}}],["breaking",{"2":{"565":1}}],["break",{"2":{"206":1,"363":1,"566":1,"569":1,"577":4,"584":1,"600":1,"636":1,"669":1,"694":3,"721":1,"722":1,"726":3,"777":1,"854":3,"948":3,"1092":3,"1227":1,"1413":2}}],["brand",{"2":{"1456":2,"1457":2,"1503":1}}],["branches",{"2":{"1315":2}}],["branch",{"0":{"1322":1},"2":{"813":1,"1329":3,"1336":1}}],["brain",{"2":{"1098":1}}],["bradbury",{"2":{"718":1,"731":1}}],["br",{"2":{"540":1,"1336":1}}],["broyden",{"2":{"1109":1}}],["broadwell",{"2":{"813":4}}],["broadcast",{"2":{"574":1}}],["broadcasting中有详细介绍",{"2":{"610":1}}],["broadcasting中描述的广播机制",{"2":{"602":1}}],["broadcasting",{"2":{"339":1,"540":1,"1019":2}}],["brown",{"2":{"301":1,"564":2}}],["b3",{"2":{"173":2,"174":1,"488":8,"502":6,"834":6}}],["b2",{"2":{"173":2,"174":1,"217":9,"219":4,"221":1,"488":8,"502":5,"834":6,"851":1,"1154":1}}],["b1b2⋯bm",{"2":{"999":2}}],["b11b12⋯b1mb21b22⋯b2m⋮⋮⋱⋮bk1bk2⋯bkm",{"2":{"999":1}}],["b1",{"2":{"173":2,"174":1,"217":9,"219":4,"221":1,"482":4,"488":8,"502":5,"674":1,"834":6,"835":2,"1154":1}}],["bicycle",{"2":{"945":1}}],["bilinear",{"2":{"863":10,"940":1}}],["bilingual",{"2":{"578":1}}],["bird",{"2":{"945":1,"1422":1}}],["birch",{"2":{"757":1}}],["birnn",{"2":{"520":1,"713":7}}],["birnn描述了具有单个隐藏层的双向循环神经网络的架构",{"2":{"520":1}}],["bigsum",{"2":{"1493":2}}],["bigint",{"2":{"1404":1}}],["biggest",{"2":{"751":1}}],["big",{"2":{"751":2,"1404":1}}],["bigram",{"2":{"317":1,"318":8}}],["bind",{"2":{"1525":1}}],["bind=",{"2":{"1501":2}}],["bin",{"2":{"1273":1,"1392":1}}],["binary",{"2":{"765":2,"1102":1,"1197":1}}],["bins=range",{"2":{"693":1}}],["binomial",{"2":{"291":1}}],["bit=128",{"2":{"810":1}}],["bit",{"2":{"650":1}}],["bidirect",{"2":{"523":2,"713":2}}],["bidirective=true",{"2":{"523":2}}],["bidirectional=true",{"2":{"523":2,"713":2}}],["bidirectional",{"2":{"325":1,"520":1,"713":1}}],["bi",{"2":{"307":1,"348":1,"518":1,"550":1,"553":1}}],["bioasq组织已经举办比赛来完成这项工作",{"2":{"292":1}}],["bishop",{"2":{"170":1,"300":1}}],["bias=params",{"2":{"834":6}}],["bias=bias",{"2":{"382":8}}],["bias=use",{"2":{"382":4}}],["bias=false",{"2":{"129":3,"263":3,"369":9,"382":4,"407":8,"472":2,"863":1,"968":1,"969":2}}],["bias",{"2":{"34":16,"35":16,"127":9,"169":1,"263":1,"278":5,"369":3,"375":1,"382":8,"407":8,"414":10,"431":9,"432":3,"433":3,"435":10,"592":3,"595":3,"610":1,"863":1,"874":2,"968":1,"969":2,"1099":1,"1132":2,"1133":1}}],["b少很多",{"2":{"154":1}}],["b对位置",{"2":{"154":1}}],["b=10",{"2":{"1230":1}}],["b=2",{"2":{"1091":2,"1481":1}}],["b=b上进行求值",{"2":{"1032":1}}],["b=b∣a=a",{"2":{"1031":1}}],["b=b也必须发生",{"2":{"1030":1}}],["b=b",{"2":{"1030":2,"1031":1}}],["b=none",{"2":{"727":3,"734":1}}],["b=4",{"2":{"599":1}}],["b=true",{"2":{"370":2,"674":1}}],["b=true为了交换keys的最后两个维度",{"2":{"370":3}}],["b=0",{"2":{"155":1}}],["b=",{"2":{"153":1,"154":1,"999":2,"1154":1,"1501":1}}],["bpe函数尝试将单词从输入参数symbols分成可能最长的子词",{"2":{"757":1}}],["bpe",{"2":{"757":3}}],["bptt中",{"2":{"538":1}}],["bptt中的依赖关系",{"2":{"312":1}}],["bptt中的模型参数是",{"2":{"312":1}}],["bptt表明",{"2":{"312":1}}],["bptt所示",{"2":{"312":2}}],["bptt说明了",{"2":{"311":1}}],["bptt",{"2":{"305":1,"306":2,"307":11,"308":1,"309":1,"310":1,"311":1,"312":12}}],["bp",{"2":{"52":1}}],["bx+",{"2":{"46":2}}],["b≤1",{"2":{"46":1}}],["b−x",{"2":{"46":1}}],["b∈x∩y",{"2":{"40":1}}],["b∈x",{"2":{"40":3}}],["buddy",{"2":{"1416":3}}],["button>",{"2":{"1445":3,"1451":3,"1454":3,"1455":3,"1456":3,"1457":3,"1459":3,"1460":1,"1462":1,"1463":3,"1464":4,"1465":5,"1466":5,"1467":2,"1468":2,"1470":1,"1471":3,"1497":1,"1498":1,"1501":1,"1503":3,"1522":1}}],["button",{"2":{"1402":1,"1445":3,"1451":3,"1454":3,"1455":3,"1456":3,"1457":3,"1459":3,"1460":1,"1462":1,"1463":3,"1464":4,"1465":5,"1466":5,"1467":2,"1468":2,"1470":1,"1471":3,"1497":1,"1498":1,"1501":1,"1503":3,"1522":1}}],["butit",{"2":{"21":1}}],["bus",{"2":{"807":1,"945":1}}],["buffer",{"2":{"590":1}}],["burst",{"2":{"77":1,"802":1}}],["build",{"2":{"16":1,"127":1,"278":1,"414":1,"472":2,"568":1,"569":2,"1315":4,"1339":1,"1340":1}}],["builtscheduler",{"2":{"67":2}}],["built",{"2":{"6":1}}],["barks",{"2":{"1416":2}}],["barrier",{"2":{"832":1}}],["balso",{"2":{"841":1}}],["baby",{"2":{"750":2}}],["bad",{"2":{"682":1,"704":1,"715":1,"751":2}}],["bag",{"2":{"582":2}}],["bags",{"2":{"455":1}}],["bayes",{"2":{"1032":1}}],["bayes定理",{"2":{"1032":1,"1037":1}}],["bay",{"2":{"454":1,"455":1}}],["bandwidth",{"2":{"803":1}}],["bandit",{"2":{"298":2}}],["bandits",{"2":{"197":1}}],["banko",{"2":{"1141":1}}],["bank",{"2":{"525":3,"732":4,"754":3,"772":1,"802":1,"813":1}}],["bananasdataset",{"2":{"932":9}}],["bananas",{"2":{"932":22,"961":1}}],["bananas函数读取图像和标签",{"2":{"932":1}}],["bananas函数",{"2":{"932":2}}],["banana",{"2":{"342":1,"931":2,"932":3,"964":3,"1401":1}}],["bahdanau注意力是深度学习中的具有突破性价值的注意力模型",{"2":{"379":1}}],["bahdanau注意力将上一时间步的解码器隐状态视为查询",{"2":{"377":1}}],["bahdanau等人提出了一个没有严格单向对齐限制的",{"2":{"373":1}}],["bahdanau",{"0":{"373":1},"1":{"374":1,"375":1,"376":1,"377":1,"378":1},"2":{"300":1,"373":1,"379":1,"538":1}}],["bahri",{"2":{"248":1,"411":1}}],["backend=",{"2":{"945":2,"964":1}}],["backend",{"2":{"932":1,"981":5,"1369":2}}],["background",{"2":{"852":1,"945":1,"1444":1}}],["backpropagate",{"2":{"973":1}}],["backpropagation",{"2":{"299":1,"306":1,"1121":1,"1122":1}}],["backprop中所解释的那样",{"2":{"312":1}}],["backprop中",{"2":{"312":1}}],["backprop中描述了多层感知机中的",{"2":{"306":1}}],["backprop",{"2":{"161":1,"164":1,"165":1,"204":1}}],["backward",{"2":{"67":3,"80":3,"81":3,"129":3,"137":3,"164":1,"210":3,"235":3,"236":3,"237":3,"242":3,"275":3,"278":3,"335":5,"350":3,"392":3,"519":1,"576":3,"595":3,"605":3,"635":5,"726":3,"767":3,"828":3,"837":3,"883":3,"906":3,"927":3,"963":3,"974":6,"975":4,"976":6,"977":3}}],["bach",{"2":{"95":1}}],["basic",{"2":{"1088":1}}],["basics",{"2":{"342":1,"649":1}}],["based",{"2":{"936":1,"1188":1}}],["baseline",{"2":{"210":1}}],["base",{"2":{"70":7,"71":9,"72":9,"73":2,"206":3,"686":8,"690":1,"958":6,"959":3}}],["bashdocker",{"2":{"1342":1,"1343":1,"1344":1,"1345":1}}],["bashcurl",{"2":{"1284":1}}],["bash",{"2":{"1269":1,"1273":1,"1277":1,"1281":1,"1285":1,"1289":1,"1293":1,"1336":1,"1337":1,"1343":1,"1344":1,"1392":2}}],["bashpip",{"2":{"1235":1,"1280":1,"1288":1,"1292":1}}],["bashnpm",{"2":{"13":1,"15":1,"16":1,"17":1}}],["bashgit",{"2":{"13":1,"1324":1,"1327":1,"1328":1,"1329":1,"1330":1,"1332":1,"1333":1,"1334":1,"1335":1}}],["ba",{"2":{"32":1,"404":1}}],["batch=",{"2":{"892":3,"904":3,"948":1,"949":2}}],["batch函数来处理多个gpu",{"2":{"837":1}}],["batch函数",{"2":{"836":1}}],["batch函数不同",{"2":{"681":1}}],["batchify",{"2":{"776":2,"777":1}}],["batchsize",{"2":{"737":5}}],["batchnorm2d",{"2":{"474":4,"480":2,"481":2,"482":4,"501":4,"502":2,"826":2,"957":2}}],["batchnorm中的μ^b和σ^b",{"2":{"467":1}}],["batchnorm中",{"2":{"467":1}}],["batchnormalization",{"2":{"406":1,"474":4,"480":1,"481":1,"482":2,"501":2,"502":2}}],["batchnorm1d",{"2":{"406":2,"474":4}}],["batchnorm",{"2":{"406":1,"467":1,"472":7,"473":16,"474":4,"480":1,"481":1,"482":2,"501":2,"502":1,"826":1,"893":3,"957":1}}],["batches",{"2":{"137":12,"320":2,"321":6,"767":12,"883":12,"894":12,"906":12}}],["batch",{"2":{"21":1,"28":1,"34":1,"35":4,"67":8,"78":1,"79":8,"80":4,"91":1,"108":1,"137":4,"175":10,"195":1,"210":9,"211":2,"212":2,"213":3,"216":2,"221":2,"225":4,"263":13,"270":1,"271":3,"275":4,"278":1,"320":9,"321":22,"324":8,"325":16,"329":3,"332":16,"333":4,"335":15,"350":3,"369":17,"370":22,"375":39,"376":2,"382":47,"390":3,"391":1,"396":4,"406":1,"408":15,"409":8,"462":2,"466":2,"472":19,"473":4,"481":2,"483":2,"489":2,"491":2,"492":2,"496":2,"503":2,"509":2,"523":6,"528":6,"543":8,"545":8,"557":8,"559":12,"569":3,"573":12,"574":13,"575":13,"576":10,"582":2,"583":8,"584":14,"590":11,"595":1,"600":11,"604":9,"605":10,"613":3,"622":2,"629":2,"635":4,"669":9,"674":3,"679":7,"681":3,"687":12,"688":2,"695":9,"698":6,"712":6,"722":8,"725":6,"726":10,"736":21,"760":6,"763":2,"767":7,"776":2,"777":8,"827":1,"828":12,"833":1,"836":3,"837":17,"852":33,"854":6,"864":7,"874":9,"882":6,"883":16,"890":1,"892":9,"894":5,"902":1,"904":9,"905":1,"906":2,"932":14,"933":6,"948":5,"949":9,"956":1,"961":2,"962":4,"963":1,"1067":1,"1166":1}}],["b",{"2":{"21":16,"28":8,"34":16,"46":9,"64":2,"77":16,"78":4,"80":15,"91":6,"108":6,"127":1,"153":2,"154":2,"155":1,"156":2,"158":4,"270":3,"271":3,"273":10,"275":13,"278":1,"291":1,"293":2,"331":16,"332":16,"390":2,"513":9,"515":6,"521":6,"544":32,"545":32,"558":40,"559":40,"578":5,"589":2,"595":12,"599":6,"601":6,"602":2,"605":23,"611":5,"613":6,"615":5,"630":6,"632":1,"634":2,"635":5,"655":6,"674":15,"675":12,"676":12,"677":15,"720":3,"727":5,"734":3,"751":4,"757":2,"790":11,"791":7,"816":6,"817":4,"821":1,"848":1,"849":1,"854":21,"879":1,"977":28,"986":3,"992":14,"994":12,"999":7,"1019":9,"1021":2,"1022":8,"1032":6,"1033":2,"1034":4,"1038":2,"1048":5,"1077":2,"1089":7,"1090":3,"1092":2,"1103":2,"1154":2,"1166":1,"1216":1,"1218":8,"1219":4,"1230":3,"1329":1,"1398":3,"1401":2,"1405":1,"1456":3,"1457":3,"1464":4,"1483":1,"1501":4}}],["border",{"2":{"1444":1}}],["bordercolor",{"2":{"1423":1}}],["body",{"2":{"1315":1,"1522":1}}],["bodla",{"2":{"856":1}}],["bob",{"2":{"1191":1,"1398":1,"1421":1}}],["boundary",{"2":{"1108":2}}],["bounding",{"2":{"847":1,"854":1,"856":1,"858":1,"886":1}}],["boat",{"2":{"945":1}}],["bojanowski",{"2":{"756":1,"759":1}}],["boyfriend",{"2":{"755":1}}],["boy",{"2":{"755":1}}],["boyd",{"2":{"62":1}}],["bowman",{"2":{"657":1,"666":1}}],["bo∈r1×h是偏置参数",{"2":{"553":1}}],["boot",{"2":{"582":2}}],["boolean",{"2":{"633":2,"1398":1,"1401":1,"1404":1,"1420":1,"1432":2}}],["bool",{"2":{"392":8,"1216":1,"1404":1}}],["book",{"2":{"355":1}}],["book中描述那样",{"2":{"355":1}}],["bos>",{"2":{"567":1,"569":2,"576":4,"577":4}}],["bos",{"2":{"363":1,"409":1,"567":1,"572":2,"576":9,"577":1}}],["bottle",{"2":{"945":1}}],["bottleneck",{"2":{"505":1}}],["bottou在上世纪90年代写的代码呢",{"2":{"135":1}}],["bottou",{"2":{"135":1,"300":1,"581":1,"700":1,"832":1}}],["both",{"2":{"0":1}}],["boxes中的实验里的第一个尺度",{"2":{"915":1}}],["boxes中的方法",{"2":{"913":1}}],["boxes实验的第一个尺度上",{"2":{"913":1}}],["boxes和",{"2":{"856":1}}],["boxes2的数量",{"2":{"849":12}}],["boxes2",{"2":{"849":18}}],["boxes1的数量",{"2":{"849":12}}],["boxes1",{"2":{"849":18}}],["boxes",{"2":{"848":20,"849":15,"850":1,"851":15,"852":5,"854":10,"856":1,"858":17,"912":1,"938":2}}],["box",{"2":{"8":2,"847":2,"849":12,"851":18,"852":2,"854":5,"858":6,"886":1,"1444":1,"1500":2}}],["behind",{"2":{"1145":1}}],["beforedestroy",{"2":{"1470":1}}],["beforeupdate",{"2":{"1470":1}}],["beforemount",{"2":{"1470":1}}],["beforecreate",{"2":{"1470":1}}],["before",{"2":{"1021":4}}],["between1",{"2":{"1165":1}}],["bethge",{"2":{"916":1,"920":1}}],["beta的第1个维度",{"2":{"674":3}}],["beta的形状",{"2":{"674":5}}],["beta=self",{"2":{"472":1}}],["betas",{"2":{"89":2}}],["beta",{"2":{"88":4,"89":4,"472":18,"473":4,"674":7,"675":6,"677":6}}],["beta2",{"2":{"34":16,"35":12}}],["beta1",{"2":{"34":16,"35":16}}],["beijing",{"2":{"751":2}}],["benchmark",{"2":{"658":1,"790":9,"791":4,"792":2,"796":9,"797":9,"820":9}}],["bengio等人首先提出使用神经网络进行语言建模",{"2":{"341":1}}],["bengio",{"2":{"135":1,"247":1,"300":2,"341":1,"373":1,"397":1,"455":1,"581":1,"832":1}}],["bert结合了这两个方面的优点",{"2":{"739":1}}],["bert模型",{"2":{"738":3}}],["bert模型成为下游应用模型的一部分",{"2":{"689":1}}],["bert的下一句预测任务",{"2":{"737":3}}],["bert的掩蔽语言模型任务",{"2":{"736":3}}],["bert在预训练中考虑了一个二元分类任务",{"2":{"737":1}}],["bert在两个方面与gpt相似",{"2":{"733":1}}],["bert随机掩蔽词元并使用来自双向上下文的词元以自监督的方式预测掩蔽词元",{"2":{"736":1}}],["bert编码器",{"2":{"734":3}}],["bertencoder中的位置前馈网络",{"2":{"740":1}}],["bertencoder的编码结果和用于预测的词元位置",{"2":{"736":1}}],["bertencoder的前向推断给出了输入文本的每个词元和插入的特殊标记",{"2":{"735":1}}],["bertencoder",{"2":{"734":8,"738":3}}],["bertencoder使用片段嵌入和可学习的位置嵌入",{"2":{"734":1}}],["bert使用可学习的位置嵌入",{"2":{"734":1}}],["bert选择transformer编码器作为其双向架构",{"2":{"734":1}}],["bert进一步改进了11种自然语言处理任务的技术水平",{"2":{"733":1}}],["bert表示将被输入到一个添加的输出层中",{"2":{"733":1}}],["bert能够基于其双向上下文表示任何词元",{"2":{"733":1}}],["bert函数定义了在wikitext",{"2":{"726":1}}],["bert预训练的最终损失是遮蔽语言模型损失和下一句预测损失的和",{"2":{"726":1}}],["bertlarge",{"2":{"726":1}}],["bertbase",{"2":{"726":1}}],["bert输入序列",{"2":{"734":1}}],["bert输入序列是",{"2":{"734":1}}],["bert输入序列是特殊类别词元",{"2":{"734":1}}],["bert输入序列的嵌入是词元嵌入",{"2":{"739":1}}],["bert输入序列的长度为6",{"2":{"727":1}}],["bert输入序列的最大长度是64",{"2":{"725":1}}],["bert输入序列明确地表示单个文本和文本对",{"2":{"657":1,"734":1}}],["bertclassifier",{"2":{"688":8}}],["bertmodel",{"2":{"686":3,"726":2,"738":6}}],["bert只需要最少的架构更改",{"2":{"663":1}}],["bert只需要最小的架构改变",{"2":{"661":1}}],["bert描述了bert的输入表示",{"2":{"657":1}}],["bert改进了各种自然语言处理任务的技术水平",{"2":{"656":1}}],["bert中实现的bert模型和",{"2":{"725":1}}],["bert中实现的bert模型",{"2":{"718":1}}],["bert中所示",{"2":{"685":1}}],["bert中讨论的那样",{"2":{"685":1}}],["bert中介绍的那样",{"2":{"663":1}}],["bert中",{"2":{"656":1,"688":1}}],["bert",{"0":{"730":1,"733":1},"1":{"731":1,"732":1,"733":1,"734":1,"735":1,"736":1,"737":1,"738":1,"739":1,"740":1},"2":{"656":2,"657":2,"658":3,"659":3,"660":2,"663":2,"685":2,"686":32,"687":2,"688":12,"690":2,"718":2,"722":7,"725":2,"726":12,"727":6,"730":1,"733":3,"734":3,"735":1,"754":3}}],["bert和",{"2":{"522":1}}],["bert微调所需的",{"2":{"137":2}}],["beautifulsoup",{"2":{"1297":1}}],["beautiful",{"2":{"748":1,"750":2}}],["beam",{"2":{"512":2,"515":6,"550":1,"577":1}}],["beach",{"2":{"315":1}}],["beyer",{"2":{"411":1}}],["beutel",{"2":{"345":1}}],["below",{"2":{"45":1,"854":12}}],["beginning",{"2":{"409":1}}],["begin",{"2":{"23":4,"31":4,"37":4,"52":4,"64":4,"72":5,"75":4,"83":4,"97":4,"105":4,"111":4,"118":4,"124":4,"133":4,"137":2,"139":4,"144":4,"147":5,"148":2,"150":4,"178":4,"215":4,"223":4,"227":4,"239":4,"250":4,"268":4,"278":3,"280":4,"323":4,"325":9,"328":4,"332":8,"333":4,"335":4,"337":4,"344":4,"353":4,"359":4,"366":4,"372":3,"378":3,"384":3,"394":3,"402":3,"411":3,"414":3,"416":4,"418":3,"420":4,"422":4,"423":2,"424":3,"426":4,"428":4,"431":1,"434":4,"436":5,"437":2,"439":4,"444":4,"445":3,"446":3,"449":3,"453":4,"465":4,"477":4,"485":4,"491":4,"498":4,"505":4,"507":2,"511":4,"525":3,"531":3,"537":3,"549":3,"563":3,"571":3,"573":1,"580":3,"586":4,"591":4,"592":7,"593":4,"594":4,"596":3,"597":4,"607":4,"621":4,"628":4,"638":4,"671":3,"684":3,"690":3,"697":3,"706":3,"717":3,"724":3,"729":3,"740":3,"753":3,"759":3,"770":3,"779":3,"790":9,"791":2,"792":1,"793":1,"794":6,"796":6,"797":3,"799":3,"818":4,"819":8,"820":8,"821":10,"822":1,"823":6,"827":5,"829":2,"830":5,"839":3,"856":3,"860":3,"868":3,"873":3,"876":3,"882":2,"885":3,"893":5,"897":3,"898":3,"910":3,"915":3,"929":3,"935":3,"942":3,"951":3,"966":3,"972":3,"979":4,"986":4,"998":3,"1004":4,"1005":3,"1009":4,"1015":4,"1017":6,"1020":2,"1021":4,"1022":2,"1024":4,"1038":4}}],["be",{"2":{"0":1}}],["bytes的数据",{"2":{"810":1}}],["byte",{"0":{"757":1},"2":{"722":1,"757":2}}],["by",{"2":{"0":1,"6":1,"7":1,"210":1}}],["p>",{"2":{"1522":1}}],["p>我是弹窗中的一些内容",{"2":{"1522":1}}],["p=2",{"2":{"1154":1}}],["p=0",{"2":{"461":4}}],["p事实上是有符号的",{"2":{"1145":1}}],["p也是一个实数",{"2":{"1145":1}}],["p是v投影到向量u上的长度",{"2":{"1145":1}}],["pycharm",{"2":{"1304":1}}],["pygame",{"2":{"1297":1}}],["py",{"0":{"1258":1},"2":{"1257":1,"1258":3,"1302":1}}],["pyplot",{"2":{"981":1}}],["pytorch会累积梯度",{"2":{"974":1}}],["pytorch会根据一个范围均匀地初始化权重和偏置矩阵",{"2":{"434":1}}],["pytorch数据集提供的transform参数应用图像增广来转化图像",{"2":{"882":1}}],["pytorch是基于命令式编程并且使用动态计算图",{"2":{"818":1}}],["pytorch程序的执行主要发生在c++实现的后端",{"2":{"790":1}}],["pytorch有一个用于与用户直接交互的前端",{"2":{"790":1}}],["pytorch的tensor是在gpu上定义的",{"2":{"790":1}}],["pytorch的nn",{"2":{"434":1}}],["pytorch不会隐式地调整输入的形状",{"2":{"623":1}}],["pytorch在optim模块中实现了该算法的许多变种",{"2":{"594":1}}],["pytorch同时衰减权重和偏移",{"2":{"278":1}}],["pytorch",{"2":{"21":2,"23":1,"27":1,"28":1,"29":1,"31":1,"34":2,"35":1,"37":1,"38":1,"41":1,"52":1,"54":3,"57":2,"64":1,"67":2,"68":2,"71":2,"72":2,"73":2,"75":1,"77":4,"78":1,"79":1,"80":2,"81":2,"83":1,"87":1,"91":2,"92":1,"97":1,"99":2,"101":1,"102":2,"103":1,"105":1,"107":1,"108":2,"109":1,"111":1,"112":1,"113":1,"118":1,"120":2,"122":1,"124":1,"126":2,"127":1,"128":1,"129":2,"133":1,"136":2,"137":3,"139":1,"141":2,"142":2,"144":1,"146":2,"147":5,"148":2,"150":1,"172":2,"173":1,"174":1,"175":1,"176":2,"178":1,"208":1,"210":3,"215":1,"216":1,"217":1,"218":1,"219":1,"220":1,"221":1,"223":1,"224":1,"225":2,"227":1,"234":1,"235":2,"236":2,"237":2,"239":1,"242":1,"243":1,"250":1,"261":1,"262":1,"263":2,"268":1,"271":1,"273":1,"274":1,"275":1,"278":2,"280":1,"318":1,"321":1,"323":1,"324":1,"325":5,"326":2,"328":1,"329":1,"330":2,"331":1,"332":4,"333":2,"334":1,"335":4,"337":1,"340":2,"344":1,"350":5,"351":2,"353":1,"357":1,"359":1,"360":1,"366":1,"367":1,"368":3,"369":2,"370":2,"372":1,"374":1,"375":2,"376":2,"378":1,"381":1,"382":4,"384":1,"385":1,"386":2,"387":1,"388":2,"390":2,"391":1,"392":4,"394":1,"395":1,"396":2,"398":2,"399":1,"402":1,"404":1,"405":2,"406":3,"407":4,"408":3,"409":4,"411":1,"413":4,"414":5,"416":1,"420":1,"422":2,"423":3,"424":3,"425":3,"426":1,"428":1,"429":1,"430":1,"431":3,"432":2,"433":3,"434":1,"435":3,"436":3,"437":2,"439":1,"441":4,"442":4,"444":1,"445":1,"446":4,"447":1,"448":2,"449":3,"451":2,"453":1,"461":2,"465":1,"472":2,"473":3,"474":1,"477":1,"480":3,"481":2,"482":3,"485":1,"487":1,"488":6,"491":1,"494":1,"495":2,"498":1,"501":3,"502":5,"505":1,"507":2,"508":2,"509":1,"511":1,"523":1,"525":1,"528":2,"531":1,"533":1,"534":1,"535":1,"537":1,"543":1,"544":1,"545":2,"546":1,"547":1,"549":1,"557":1,"558":1,"559":2,"560":1,"561":1,"563":1,"564":1,"571":1,"572":1,"573":3,"574":2,"575":4,"576":1,"577":1,"578":1,"580":1,"581":1,"582":4,"583":1,"584":1,"586":1,"589":1,"590":1,"591":2,"592":3,"593":2,"594":2,"595":2,"596":1,"597":1,"598":1,"599":1,"600":1,"601":1,"604":1,"605":1,"607":1,"615":2,"616":1,"621":1,"622":1,"623":1,"624":1,"625":1,"628":1,"629":1,"630":1,"631":3,"633":2,"634":1,"635":2,"638":1,"666":1,"668":1,"669":1,"671":1,"673":1,"674":2,"675":1,"676":1,"677":1,"679":1,"680":1,"681":1,"682":1,"684":1,"685":1,"686":3,"687":2,"688":3,"690":1,"691":1,"694":1,"695":1,"697":1,"698":1,"699":1,"702":2,"703":1,"704":1,"706":1,"712":1,"713":2,"714":1,"715":2,"717":1,"718":1,"722":3,"724":1,"725":2,"726":4,"727":1,"729":1,"733":1,"734":3,"736":3,"737":3,"738":1,"740":1,"747":1,"750":1,"753":1,"757":1,"759":1,"760":1,"762":1,"763":2,"765":2,"766":1,"767":1,"768":1,"770":1,"771":1,"777":1,"779":1,"789":1,"790":6,"794":2,"795":1,"796":5,"797":3,"799":1,"818":1,"819":4,"820":3,"821":2,"823":2,"825":1,"826":1,"827":2,"828":3,"829":1,"830":2,"833":1,"834":1,"835":3,"836":2,"837":3,"839":1,"847":1,"848":3,"849":1,"851":1,"852":1,"853":1,"854":4,"856":1,"857":2,"860":1,"861":1,"862":4,"863":5,"864":1,"865":1,"866":3,"868":1,"871":1,"872":2,"873":4,"874":3,"876":3,"877":1,"878":1,"879":3,"880":3,"881":1,"882":4,"883":3,"885":1,"887":1,"891":2,"892":2,"893":2,"894":1,"895":1,"896":1,"897":1,"898":1,"899":1,"903":2,"904":2,"905":2,"906":1,"907":1,"908":1,"910":1,"912":2,"915":1,"918":2,"919":1,"920":3,"922":1,"923":1,"926":2,"927":2,"929":1,"931":1,"932":3,"933":1,"935":1,"938":3,"942":1,"945":4,"946":2,"947":1,"948":1,"949":1,"951":1,"954":1,"955":1,"956":2,"957":2,"958":1,"959":4,"961":1,"962":2,"963":1,"964":3,"966":3,"967":1,"968":1,"969":3,"970":4,"972":1,"974":6,"975":1,"976":2,"977":3,"979":1,"981":1,"986":1,"989":1,"990":2,"991":2,"992":4,"993":1,"994":3,"995":7,"996":3,"997":2,"998":2,"999":1,"1000":3,"1004":1,"1005":1,"1006":1,"1007":2,"1009":1,"1013":1,"1015":1,"1017":10,"1018":4,"1019":1,"1020":3,"1021":4,"1022":3,"1024":1,"1026":5,"1038":1,"1297":1}}],["python123",{"2":{"1306":1}}],["python中文社区",{"2":{"1306":1}}],["python中的",{"2":{"423":1}}],["pythonif",{"2":{"1299":1}}],["pythonimgs",{"2":{"933":1,"946":1}}],["pythonimg",{"2":{"848":1,"863":1,"964":1}}],["pythonimport",{"2":{"360":1,"367":1,"572":1,"887":1,"1085":1,"1107":1,"1109":1,"1117":1,"1235":1,"1257":1,"1261":1,"1262":1}}],["python语言介绍",{"0":{"1295":1},"1":{"1296":1,"1297":1,"1298":1,"1299":1,"1300":1,"1301":1,"1302":1,"1303":1,"1304":1,"1305":1,"1306":1}}],["python3",{"2":{"1284":1,"1306":2}}],["python=3",{"2":{"1277":1}}],["python官方的虚拟环境创建工具",{"2":{"1271":1}}],["python自带",{"2":{"1268":1}}],["python自带的包管理工具",{"2":{"1267":1}}],["python项目管理工具全景总结",{"0":{"1265":1},"1":{"1266":1,"1267":1,"1268":1,"1269":1,"1270":1,"1271":1,"1272":1,"1273":1,"1274":1,"1275":1,"1276":1,"1277":1,"1278":1,"1279":1,"1280":1,"1281":1,"1282":1,"1283":1,"1284":1,"1285":1,"1286":1,"1287":1,"1288":1,"1289":1,"1290":1,"1291":1,"1292":1,"1293":1,"1294":1}}],["python进阶语法与编程技巧",{"0":{"1237":1},"1":{"1238":1,"1239":1,"1240":1,"1241":1,"1242":1,"1243":1,"1244":1,"1245":1,"1246":1,"1247":1,"1248":1,"1249":1,"1250":1,"1251":1,"1252":1,"1253":1,"1254":1,"1255":1,"1256":1,"1257":1,"1258":1,"1259":1,"1260":1,"1261":1,"1262":1,"1263":1,"1264":1}}],["python基础语法学习笔记",{"0":{"1212":1},"1":{"1213":1,"1214":1,"1215":1,"1216":1,"1217":1,"1218":1,"1219":1,"1220":1,"1221":1,"1222":1,"1223":1,"1224":1,"1225":1,"1226":1,"1227":1,"1228":1,"1229":1,"1230":1,"1231":1,"1232":1,"1233":1,"1234":1,"1235":1,"1236":1}}],["python代码",{"2":{"1117":1}}],["python代码实现",{"2":{"1107":1,"1109":1}}],["pythonhelp",{"2":{"1007":1}}],["pythonu",{"2":{"1000":1}}],["python控制流的梯度计算",{"0":{"977":1}}],["pythona",{"2":{"977":2,"992":2,"994":3,"995":6,"996":2,"998":1,"1019":1,"1022":2,"1218":1,"1219":1}}],["pythonaugs",{"2":{"881":1}}],["pythonapply",{"2":{"879":2,"880":2}}],["pythonadd",{"2":{"406":1,"1239":1}}],["pythonvoc",{"2":{"866":1}}],["pythonvocab",{"2":{"528":1,"734":1}}],["pythonoutput",{"2":{"854":1}}],["python将很难让所有的gpu都保持忙碌",{"2":{"819":1}}],["python会单独执行这三个函数的调用",{"2":{"816":1}}],["python是一种解释型语言",{"2":{"816":1}}],["python是单线程的",{"2":{"789":1}}],["pythonrois",{"2":{"938":1}}],["pythonrgb",{"2":{"919":1}}],["pythonrgnet",{"2":{"433":1}}],["pythonrun",{"2":{"796":1}}],["python前端线程和c++后端线程之间的简化交互可以概括如下",{"2":{"792":1}}],["python前端线程将等待c++后端线程完成变量z的结果计算",{"2":{"790":1}}],["python并不善于编写并行和异步代码",{"2":{"789":1}}],["pythongen",{"2":{"1247":1}}],["pythonglove",{"2":{"703":1}}],["pythongru",{"2":{"547":1}}],["pythonembed",{"2":{"680":1,"702":1,"762":1,"766":1}}],["pythonencoding",{"2":{"398":1}}],["pythonencoder",{"2":{"375":1,"407":1,"573":1}}],["pythonb",{"2":{"992":2,"999":1}}],["pythonb5",{"2":{"488":1}}],["pythonb4",{"2":{"488":1}}],["pythonb3",{"2":{"488":1}}],["pythonb2",{"2":{"488":1}}],["pythonb1",{"2":{"488":1}}],["pythonblk",{"2":{"480":1,"481":1,"501":2}}],["pythonbatch",{"2":{"225":1,"583":1,"883":1,"948":1}}],["pythonz",{"2":{"449":2,"1021":1}}],["python解释器需要执行所有层的代码来生成一条指令",{"2":{"819":1}}],["python解释器在第一次调用块时执行它",{"2":{"426":1}}],["python解释器都会向深度学习框架发送一个命令",{"2":{"77":1}}],["python的问题全局解释器锁",{"2":{"426":4}}],["pythonfair",{"2":{"1026":1}}],["pythonfinetune",{"2":{"873":1,"876":1}}],["pythonforward",{"2":{"957":1}}],["pythonfor",{"2":{"605":1,"1225":1}}],["pythonffn",{"2":{"405":1}}],["pythonfrom",{"2":{"120":1,"126":1,"136":1,"141":1,"146":1,"172":1,"216":1,"224":1,"261":1,"318":1,"324":1,"340":1,"357":1,"374":1,"381":1,"385":1,"395":1,"404":1,"413":1,"418":1,"422":1,"429":1,"441":1,"446":1,"461":1,"472":1,"480":1,"487":1,"494":1,"501":1,"507":1,"523":1,"528":1,"533":1,"543":1,"557":1,"564":1,"589":1,"592":1,"594":1,"622":1,"629":1,"666":1,"673":1,"685":1,"691":1,"698":1,"712":1,"718":1,"725":1,"733":1,"747":1,"760":1,"771":1,"789":1,"795":1,"819":1,"825":1,"899":1,"938":1,"967":1,"974":1,"989":1,"1006":1,"1013":1,"1017":1}}],["pythonpretrained",{"2":{"862":1,"873":2,"920":1}}],["pythonprint",{"2":{"418":1,"430":1,"431":1,"432":1,"433":1}}],["pythonp",{"2":{"399":1}}],["pythonpool2d",{"2":{"147":3,"148":1}}],["pythonweight",{"2":{"827":1,"876":1}}],["pythonweights",{"2":{"390":1}}],["pythonw",{"2":{"595":1,"601":1,"863":1}}],["pythonwith",{"2":{"236":1,"237":1,"790":2,"791":2,"792":1,"796":1,"797":1,"974":1,"976":1,"1252":1}}],["pythonqueries",{"2":{"369":1,"370":1}}],["pythonsquares",{"2":{"1242":1}}],["pythonsum",{"2":{"996":1}}],["pythonsigmas",{"2":{"966":1}}],["pythonstyle",{"2":{"918":1}}],["pythonstate",{"2":{"325":1}}],["pythonshape",{"2":{"879":1}}],["pythonscore",{"2":{"1223":1}}],["pythonscratch",{"2":{"874":1}}],["pythonscheduler",{"2":{"71":1,"72":1,"73":1}}],["pythonskip",{"2":{"763":1}}],["pythonmlm",{"2":{"736":2}}],["pythonmnist",{"2":{"582":1}}],["pythonmydict",{"2":{"441":1}}],["pythonmasked",{"2":{"368":2}}],["pythonm",{"2":{"243":1}}],["pythony",{"2":{"235":1,"236":1,"237":1,"387":1,"413":1,"441":1,"442":1,"448":1,"974":1,"976":1,"997":1}}],["pythonlabels",{"2":{"853":1}}],["pythonlayer",{"2":{"413":1}}],["pythonlen",{"2":{"573":1,"991":1}}],["pythonlstm",{"2":{"561":1}}],["pythonln",{"2":{"406":1}}],["pythonloss",{"2":{"210":1,"220":1,"575":1,"593":1,"624":1,"765":1,"905":1}}],["pythonlr",{"2":{"67":1,"681":1,"688":1,"704":1,"715":1}}],["pythonname",{"2":{"1233":1}}],["pythonnp",{"2":{"997":1,"1000":2,"1007":1,"1017":4,"1018":1,"1026":1}}],["pythonnpx",{"2":{"330":1,"446":1,"938":1}}],["pythonnsp",{"2":{"737":2}}],["pythonn",{"2":{"386":1,"945":1}}],["pythonnet",{"2":{"176":1,"225":1,"392":1,"413":1,"414":1,"418":1,"423":1,"424":1,"425":1,"431":1,"432":1,"435":2,"436":1,"437":1,"442":1,"451":2,"473":2,"474":1,"482":2,"495":1,"502":3,"508":1,"623":1,"688":1,"713":1,"714":1,"726":1,"819":1,"820":1,"821":4,"827":1,"862":1,"896":1,"908":1,"920":1,"959":1}}],["pythonnums",{"2":{"1221":1}}],["pythonnum",{"2":{"173":1,"175":1,"217":1,"221":1,"325":1,"326":1,"382":1,"396":1,"409":1,"595":1,"630":1,"862":1,"865":1,"963":1}}],["pythoncount",{"2":{"1226":1}}],["pythoncounts",{"2":{"1026":2}}],["pythoncolor",{"2":{"880":1}}],["pythonconv",{"2":{"863":1}}],["pythonconv2d",{"2":{"141":1,"142":2}}],["pythoncls",{"2":{"962":1}}],["pythonclone",{"2":{"442":1}}],["pythonclass",{"2":{"127":1,"332":1,"375":1,"391":1,"408":2,"414":1,"423":1,"424":1,"425":2,"436":1,"442":1,"472":1,"480":1,"574":1,"674":1,"675":1,"676":1,"677":1,"687":1,"688":1,"702":1,"713":1,"821":1,"893":1,"926":1,"959":1,"1249":1,"1252":1,"1254":1,"1255":1}}],["pythonx2",{"2":{"441":1}}],["pythonx",{"2":{"136":1,"172":1,"235":1,"325":1,"330":1,"390":1,"407":1,"418":1,"447":1,"448":1,"461":1,"488":1,"495":1,"502":1,"575":2,"582":1,"790":1,"827":1,"862":1,"968":1,"969":1,"974":1,"990":2,"991":1,"993":1,"995":1,"1017":2,"1018":2,"1214":1,"1220":1}}],["pythontry",{"2":{"1236":1,"1250":1}}],["pythontransform",{"2":{"891":2,"903":2}}],["pythontrain",{"2":{"694":1,"828":2,"872":1,"874":1,"882":1,"892":2,"904":2}}],["pythontrainer",{"2":{"68":2,"71":1,"72":1,"73":1,"176":1,"625":1}}],["pythontconv",{"2":{"969":2}}],["pythontokens",{"2":{"734":1}}],["pythontimer",{"2":{"78":1}}],["python和深度学习框架本身带来的额外开销也是相当大的",{"2":{"77":1}}],["pythond",{"2":{"1243":1}}],["pythondense",{"2":{"414":2}}],["pythondec",{"2":{"409":1}}],["pythondecoder",{"2":{"408":1,"574":1}}],["pythondevices",{"2":{"796":1,"895":1,"907":1}}],["pythondevice",{"2":{"326":1,"927":1,"961":1}}],["pythondef",{"2":{"28":1,"35":1,"80":1,"91":1,"108":1,"137":1,"210":2,"218":1,"219":1,"263":1,"273":1,"274":1,"275":1,"278":1,"331":1,"332":2,"333":1,"334":1,"335":1,"350":1,"386":1,"433":1,"446":1,"481":1,"502":1,"508":1,"544":1,"545":2,"558":1,"559":2,"584":1,"590":1,"604":1,"635":1,"674":1,"686":1,"726":1,"727":1,"750":1,"763":1,"767":1,"768":1,"797":1,"828":1,"835":2,"837":2,"863":1,"866":2,"874":1,"882":1,"893":2,"894":1,"905":1,"906":1,"912":1,"920":1,"922":1,"923":1,"926":1,"927":1,"955":1,"956":2,"957":1,"958":1,"959":2,"962":1,"964":2,"966":1,"977":1,"1081":1,"1229":1,"1230":4,"1244":1,"1246":1,"1257":1,"1259":1}}],["pythondropout1",{"2":{"174":1}}],["pythondata",{"2":{"81":1,"835":1,"836":1}}],["pythond2l",{"2":{"21":1,"29":1,"34":1,"92":1,"109":1,"129":1,"388":1,"392":1,"686":1,"857":1,"863":1,"878":1,"882":1}}],["python",{"0":{"1259":1,"1296":1,"1297":1,"1298":1,"1302":1,"1303":1,"1304":1,"1305":1},"1":{"1299":1,"1300":1,"1301":1},"2":{"21":8,"27":6,"28":4,"29":3,"34":8,"35":3,"38":4,"41":2,"44":1,"54":9,"55":2,"56":1,"57":5,"59":3,"67":7,"68":8,"70":1,"71":6,"72":4,"73":4,"77":16,"78":3,"79":4,"80":12,"81":7,"87":5,"88":2,"89":1,"91":9,"92":3,"95":1,"99":7,"101":2,"102":4,"103":2,"107":5,"108":8,"109":3,"112":4,"113":4,"114":2,"120":5,"121":3,"122":4,"126":5,"127":3,"128":5,"129":7,"136":6,"137":8,"141":6,"142":6,"146":6,"147":12,"148":5,"172":6,"173":2,"174":3,"175":3,"176":6,"206":3,"208":9,"209":3,"210":8,"211":2,"212":1,"213":2,"216":4,"217":3,"218":3,"219":3,"220":2,"221":4,"224":3,"225":7,"234":4,"235":6,"236":6,"237":6,"242":4,"243":3,"261":3,"262":3,"263":6,"264":1,"265":1,"266":1,"271":5,"273":3,"274":3,"275":3,"276":1,"277":1,"278":5,"318":8,"320":2,"321":6,"324":3,"325":13,"326":6,"329":6,"330":6,"331":3,"332":13,"333":5,"334":3,"335":12,"340":6,"350":16,"351":10,"357":5,"360":3,"361":1,"362":1,"363":3,"364":1,"367":3,"368":10,"369":8,"370":8,"374":3,"375":7,"376":7,"381":3,"382":13,"385":3,"386":7,"387":3,"388":7,"390":6,"391":3,"392":14,"395":3,"396":5,"398":7,"399":4,"404":3,"405":7,"406":9,"407":13,"408":8,"409":13,"413":11,"414":11,"418":3,"422":3,"423":5,"424":5,"425":7,"429":3,"430":2,"431":4,"432":5,"433":8,"435":10,"436":6,"437":3,"441":12,"442":11,"445":1,"446":9,"447":3,"448":6,"449":5,"451":7,"461":6,"462":1,"463":1,"472":6,"473":8,"474":4,"480":9,"481":5,"482":10,"483":1,"487":3,"488":18,"489":1,"494":3,"495":6,"496":1,"501":9,"502":14,"503":1,"507":3,"508":7,"509":3,"523":2,"528":4,"529":1,"533":3,"534":4,"535":4,"543":3,"544":3,"545":6,"546":3,"547":3,"557":3,"558":3,"559":6,"560":3,"561":3,"564":3,"565":2,"566":2,"567":1,"568":2,"569":2,"572":3,"573":9,"574":6,"575":13,"576":5,"577":4,"578":3,"581":4,"582":13,"583":4,"584":4,"589":4,"590":5,"591":4,"592":3,"593":3,"594":3,"595":6,"598":4,"599":5,"600":3,"601":3,"602":1,"603":1,"604":3,"605":5,"615":10,"616":3,"622":4,"623":3,"624":2,"625":3,"626":1,"629":4,"630":3,"631":6,"632":1,"633":5,"634":8,"635":8,"636":1,"666":2,"667":3,"668":3,"669":5,"673":2,"674":4,"675":2,"676":2,"677":2,"679":2,"680":2,"681":3,"682":4,"685":2,"686":6,"687":5,"688":5,"691":2,"692":2,"693":3,"694":2,"695":3,"698":2,"699":4,"702":4,"703":2,"704":4,"712":2,"713":5,"714":4,"715":7,"717":1,"718":3,"720":2,"721":2,"722":11,"725":4,"726":8,"727":4,"733":2,"734":7,"736":7,"737":7,"738":3,"747":2,"748":5,"750":6,"751":5,"757":10,"760":2,"762":3,"763":4,"765":5,"766":1,"767":3,"768":2,"771":2,"772":2,"773":5,"774":3,"775":3,"776":2,"777":4,"789":2,"790":6,"795":2,"796":6,"797":4,"816":1,"817":1,"819":6,"820":4,"821":4,"825":2,"826":3,"827":3,"828":4,"833":3,"834":3,"835":7,"836":5,"837":6,"847":3,"848":9,"849":3,"851":3,"852":4,"853":6,"854":13,"857":5,"858":5,"861":3,"862":7,"863":10,"864":2,"865":2,"866":6,"871":3,"872":7,"873":5,"874":5,"876":4,"877":3,"878":2,"879":6,"880":6,"881":2,"882":6,"883":9,"887":2,"889":1,"890":5,"891":4,"892":4,"893":2,"894":2,"895":2,"896":2,"899":2,"901":1,"902":1,"903":4,"904":4,"905":4,"906":2,"907":2,"908":2,"912":8,"918":4,"919":2,"920":7,"922":2,"923":3,"924":1,"925":1,"926":4,"927":4,"931":4,"932":10,"933":2,"938":6,"945":14,"946":5,"947":3,"948":3,"949":3,"954":3,"955":2,"956":5,"957":4,"958":2,"959":9,"961":3,"962":4,"963":2,"964":6,"966":4,"967":2,"968":4,"969":6,"970":8,"974":20,"975":4,"976":6,"977":9,"981":10,"989":3,"990":6,"991":6,"992":12,"993":3,"994":9,"995":21,"996":9,"997":6,"998":3,"999":3,"1000":9,"1006":3,"1007":6,"1011":2,"1012":2,"1013":3,"1017":25,"1018":12,"1019":4,"1020":5,"1021":6,"1022":6,"1026":16,"1081":1,"1088":3,"1214":1,"1215":1,"1217":1,"1234":1,"1237":2,"1240":1,"1272":1,"1273":1,"1284":1,"1295":4,"1296":2,"1297":2,"1299":1,"1301":1,"1303":2,"1304":1,"1305":3,"1306":1,"1363":1}}],["png是一个图像文件格式",{"2":{"1091":1}}],["png",{"2":{"889":2,"945":3,"1091":1}}],["pn1",{"2":{"578":1}}],["pca算法",{"2":{"1161":1}}],["pca技术的一个很大的优点是",{"2":{"1158":1}}],["pca技术的一大好处是对数据进行降维的处理",{"2":{"1158":1}}],["pca将n个特征降维到k个",{"2":{"1158":1}}],["pca",{"2":{"1158":1,"1159":1,"1162":1}}],["pci",{"2":{"813":3}}],["pcie链接非常宝贵",{"2":{"812":1}}],["pcie",{"2":{"801":1,"812":1,"813":1}}],["pcm",{"2":{"357":2}}],["ptbdataset",{"2":{"777":4}}],["ptb函数",{"2":{"777":1}}],["ptb函数来获得该数据集的数据迭代器和词表",{"2":{"760":1}}],["ptb",{"2":{"760":3,"772":7,"777":7}}],["p4",{"2":{"487":24}}],["p3dn",{"2":{"819":1}}],["p3608",{"2":{"813":3}}],["p3=1",{"2":{"578":1}}],["p3",{"2":{"487":24,"832":1,"842":1}}],["p2实例就是将大量gpu连接到主机处理器",{"2":{"812":1}}],["p2=p",{"2":{"744":1}}],["p2=3",{"2":{"578":1}}],["p2",{"2":{"487":24,"744":1,"830":2,"832":1}}],["p1=p",{"2":{"744":1}}],["p1",{"2":{"487":16,"744":1}}],["puppies",{"2":{"1191":1}}],["putting",{"2":{"1126":1}}],["pull",{"2":{"844":1,"1309":1,"1315":1,"1330":1,"1337":1,"1342":1}}],["pullover",{"2":{"582":2}}],["push是追加历史记录",{"2":{"1484":1}}],["push",{"2":{"844":2,"1309":1,"1315":3,"1319":2,"1325":1,"1330":1,"1335":1,"1337":1,"1426":2,"1432":1,"1471":1,"1485":1}}],["punkt",{"2":{"724":1}}],["purpose",{"2":{"457":1}}],["pubsub",{"2":{"1499":1}}],["publicuser",{"2":{"1434":1}}],["public",{"2":{"1371":1,"1417":1,"1425":4,"1428":5}}],["pub",{"2":{"86":1}}],["p∈rn×d输出x+p",{"2":{"398":1}}],["pqh=pkh=pvh=po",{"2":{"382":1}}],["ppl",{"2":{"335":12}}],["p^",{"2":{"316":5}}],["pf",{"2":{"300":1}}],["pembroke",{"2":{"1471":1}}],["pep8",{"0":{"1215":1},"2":{"1264":1}}],["pearson相关系数即将x",{"2":{"1154":1}}],["pearson皮尔逊相关系数",{"2":{"1154":1}}],["pedersen",{"2":{"1002":1}}],["pending",{"2":{"1412":1}}],["pennington",{"2":{"743":1,"744":1,"746":1}}],["penalty",{"2":{"274":4,"275":8}}],["petersen",{"2":{"1002":1}}],["peters",{"2":{"349":1,"731":2}}],["persistent",{"2":{"1386":1}}],["persistent=true",{"2":{"335":1,"976":1}}],["persons>",{"2":{"1469":1}}],["persons",{"2":{"1469":6}}],["personinter>",{"2":{"1469":1}}],["personinter",{"2":{"1469":2}}],["person变化了",{"2":{"1463":1,"1464":1}}],["person",{"2":{"945":1,"1254":1,"1398":1,"1405":1,"1408":3,"1419":2,"1433":4,"1445":1,"1451":2,"1454":3,"1455":2,"1456":2,"1457":2,"1459":8,"1460":1,"1462":2,"1463":9,"1464":9,"1465":15,"1466":14,"1467":2,"1468":6,"1469":6,"1470":2,"1518":3}}],["period和lr",{"2":{"895":1,"907":1}}],["period",{"2":{"894":6,"895":6,"896":3,"898":1,"906":6,"907":6,"908":3,"910":1}}],["perdu",{"2":{"376":2,"409":2,"578":2}}],["perm=",{"2":{"375":1,"382":2,"409":1,"763":1,"992":2}}],["permute",{"2":{"375":4,"382":2,"409":1,"573":1,"574":2,"575":1,"674":2,"702":1,"763":1,"863":3,"866":2,"919":2,"933":1,"945":2,"946":1,"956":1,"964":2}}],["perplexity",{"0":{"342":1},"2":{"335":4,"342":2}}],["perplexity所述",{"2":{"335":1}}],["per",{"2":{"320":3,"566":1,"693":1,"773":1,"813":1,"848":15,"890":3}}],["perceptron",{"2":{"231":1,"1141":1}}],["perceptrons中",{"2":{"338":1}}],["perceptrons",{"2":{"204":1}}],["performance",{"2":{"77":4,"78":4,"824":1}}],["pdm",{"0":{"1286":1},"1":{"1287":1,"1288":1,"1289":1},"2":{"1288":1,"1289":3,"1294":3}}],["pdparams",{"2":{"442":2,"686":1}}],["pd",{"2":{"208":7,"209":1,"213":2,"404":4,"409":4,"887":3,"896":3,"931":3,"932":3,"1011":2,"1012":1}}],["ps",{"2":{"180":2,"841":2,"843":4,"1343":2}}],["pwa",{"2":{"1529":1,"1540":1}}],["pwd",{"2":{"1089":1}}],["pwepoiut下雨了",{"2":{"342":1}}],["pwepoiut",{"2":{"342":1}}],["pw",{"2":{"124":1,"142":1,"150":1}}],["phone",{"2":{"1435":3}}],["photo",{"0":{"1170":1},"1":{"1171":1,"1172":1,"1173":1,"1174":1},"2":{"1193":1}}],["pham",{"2":{"712":1,"832":1}}],["physical",{"2":{"446":3}}],["ph1−p",{"2":{"170":1}}],["ph",{"2":{"124":1,"141":2,"142":1,"150":1}}],["plus",{"2":{"1528":1}}],["plusonetoincludethebeginning",{"2":{"409":1}}],["plugins",{"2":{"1454":1}}],["plugin",{"2":{"1454":2}}],["plain",{"2":{"1371":1}}],["planner",{"2":{"1052":1}}],["plant",{"2":{"945":1}}],["plane",{"0":{"1376":1},"2":{"658":2,"1378":1,"1381":1}}],["plan9from",{"2":{"345":1}}],["platform",{"2":{"583":1}}],["place=boxes",{"2":{"854":1}}],["place=place",{"2":{"848":2}}],["place=paddle",{"2":{"797":1}}],["place=data",{"2":{"835":2}}],["place=d2l",{"2":{"682":2,"715":1}}],["place=devices",{"2":{"796":2,"828":2,"835":1,"883":3}}],["place=device",{"2":{"137":5,"333":1,"335":2,"576":1,"577":3,"767":1,"835":1,"836":1}}],["place=try",{"2":{"448":2}}],["place",{"2":{"137":1,"447":1,"451":1,"835":2,"848":2,"851":1,"852":3,"854":1}}],["placeupdatesvia",{"2":{"21":3}}],["plotting",{"2":{"1091":1}}],["plot",{"2":{"41":2,"44":1,"54":2,"57":3,"68":1,"70":1,"71":4,"72":2,"73":2,"80":1,"89":1,"95":1,"99":2,"101":2,"102":6,"103":2,"107":1,"211":1,"213":1,"235":8,"236":8,"237":8,"242":4,"318":2,"350":2,"351":3,"386":3,"387":4,"388":4,"392":4,"398":4,"616":2,"635":1,"966":6,"981":4,"1026":4,"1091":6}}],["plt已标记为保存到d2l包中",{"2":{"981":1}}],["plt",{"2":{"41":2,"57":12,"80":1,"89":3,"95":3,"99":2,"102":10,"107":2,"357":1,"386":1,"566":4,"582":3,"599":1,"635":1,"693":3,"848":3,"853":1,"854":2,"857":3,"858":2,"863":6,"878":2,"912":5,"918":5,"964":3,"966":12,"981":3,"1026":20}}],["pinia提供的storetorefs只会将数据做转换",{"2":{"1492":1}}],["pinia",{"0":{"1487":1,"1489":1,"1504":1},"1":{"1488":1,"1489":1,"1490":1,"1491":1,"1492":1,"1493":1,"1494":1,"1495":1},"2":{"1444":1,"1489":4,"1490":2,"1491":1,"1492":1,"1493":1,"1495":1,"1527":1,"1528":1,"1530":1}}],["pinv",{"2":{"1085":1,"1090":1}}],["ping",{"2":{"813":1}}],["pixel",{"2":{"848":15}}],["pik的比值",{"2":{"744":1}}],["pil图片",{"2":{"582":2}}],["piece",{"2":{"1437":2}}],["piecewise",{"2":{"114":1}}],["pietra",{"2":{"564":2}}],["pickle=true",{"2":{"441":3}}],["pi+δ",{"2":{"400":3}}],["piouw",{"2":{"342":2}}],["pitts",{"2":{"300":1}}],["pipenv",{"0":{"1278":1},"1":{"1279":1,"1280":1,"1281":1},"2":{"1280":1,"1281":4,"1294":3}}],["pipeline",{"2":{"1171":1,"1174":1}}],["pip",{"0":{"1266":1},"1":{"1267":1,"1268":1,"1269":1},"2":{"208":4,"717":1,"724":1,"1011":1,"1235":1,"1269":2,"1272":1,"1273":1,"1284":1,"1293":1,"1294":2}}],["pid",{"2":{"198":1}}],["pi",{"2":{"41":2,"56":1,"59":1,"72":1,"99":2,"398":2,"400":3,"616":1,"1417":1}}],["ports",{"2":{"1389":1,"1390":1,"1391":1}}],["port",{"2":{"1384":1,"1391":1,"1427":6}}],["pods",{"2":{"1392":1}}],["pod",{"0":{"1380":1,"1389":1},"2":{"1376":1,"1382":2,"1384":1,"1389":2,"1391":1,"1392":6}}],["podoprikhin",{"2":{"38":1,"66":1}}],["poetry",{"0":{"1282":1},"1":{"1283":1,"1284":1,"1285":1},"2":{"1264":1,"1284":2,"1285":4,"1294":4}}],["pot项目收集大量的数据吧",{"2":{"1137":1}}],["potted",{"2":{"945":1}}],["potts",{"2":{"666":1}}],["pomerleau那里拿到的",{"2":{"1127":1}}],["population",{"2":{"775":2}}],["pop",{"2":{"687":6,"1332":1}}],["popvssoda",{"2":{"183":2}}],["po是通过参数num",{"2":{"382":1}}],["post",{"2":{"1047":1,"1431":3}}],["postprocess",{"2":{"919":3,"927":3}}],["pos中的联合概率",{"2":{"708":1}}],["pos中的联合概率才最大化为1",{"2":{"708":1}}],["pos只考虑那些正样本的事件",{"2":{"708":1}}],["positive",{"2":{"715":3,"1106":1,"1139":4}}],["positionwiseffn",{"2":{"405":11,"407":4,"408":4}}],["positionwise",{"2":{"404":1,"405":1}}],["position",{"2":{"398":4,"399":4,"721":5}}],["positionalencoding",{"2":{"398":11,"407":4,"408":4}}],["positional",{"2":{"379":1,"395":1,"398":3,"400":1,"404":2}}],["positions=none",{"2":{"738":3}}],["positions=3",{"2":{"736":3}}],["positions处的预测结果mlm",{"2":{"736":1}}],["positions定义为在encoded",{"2":{"736":1}}],["positions是不包括特殊词元的bert输入序列的词元索引的列表",{"2":{"721":1}}],["positions",{"2":{"376":4,"409":8,"721":17,"722":29,"726":16,"736":30,"738":6}}],["posistions",{"2":{"376":2}}],["pos",{"2":{"320":3,"398":15,"407":8,"408":8,"659":1,"692":2,"708":1,"734":7,"854":9}}],["pouget",{"2":{"300":1}}],["policy",{"2":{"298":1}}],["poly",{"2":{"262":6,"264":2,"265":2,"266":2}}],["polynomial",{"2":{"114":3,"1084":1,"1148":1}}],["polyak",{"2":{"86":1}}],["points",{"2":{"1151":1}}],["point",{"2":{"102":3,"284":1,"609":1,"813":1,"1426":3}}],["powershell",{"2":{"1443":1,"1444":1}}],["power",{"2":{"262":1,"398":2,"981":1,"1081":1,"1117":1}}],["powered",{"2":{"7":1}}],["pow",{"2":{"68":1,"274":3,"398":2,"578":2}}],["pooled",{"2":{"938":1}}],["pool2d",{"2":{"146":4,"147":21,"148":7,"834":4}}],["pooling中介绍的汇聚层有所不同",{"2":{"938":1}}],["pooling中",{"2":{"879":1}}],["pooling中定义的注意力汇聚函数f",{"2":{"396":1}}],["pooling中的输入张量x",{"2":{"146":1}}],["pooling中的输出张量的高度为2",{"2":{"146":1}}],["pooling所示",{"2":{"388":1}}],["pooling和",{"2":{"388":2}}],["pooling",{"2":{"134":2,"145":2,"146":3,"356":1,"367":1,"387":1,"388":4,"495":1,"834":2,"938":2,"967":1}}],["pool",{"2":{"67":4,"136":4,"146":4,"147":3,"148":1,"461":6,"473":4,"474":4,"481":4,"482":2,"487":1,"488":8,"495":6,"502":3,"507":2,"687":9,"702":6,"826":2,"834":2,"938":2}}],["p",{"2":{"21":18,"28":18,"34":18,"35":21,"42":4,"80":15,"81":2,"91":15,"108":18,"116":1,"146":16,"183":1,"190":1,"191":9,"192":3,"280":1,"315":1,"316":5,"317":12,"334":14,"338":1,"347":2,"348":8,"349":1,"398":28,"399":11,"513":1,"515":9,"519":25,"574":1,"616":7,"621":1,"646":1,"650":2,"652":5,"687":27,"708":2,"709":2,"713":2,"742":3,"757":2,"773":1,"775":1,"783":3,"785":3,"835":12,"956":6,"1000":1,"1025":1,"1026":4,"1028":2,"1030":2,"1031":1,"1032":6,"1033":1,"1034":3,"1035":21,"1036":1,"1110":1,"1145":12,"1154":1,"1168":1,"1178":1,"1179":1,"1180":2,"1184":4,"1410":4,"1434":4,"1435":8}}],["pave",{"2":{"1011":1,"1012":5}}],["pascal",{"0":{"945":1},"1":{"946":1,"947":1,"948":1,"949":1}}],["password",{"2":{"1434":1,"1500":1}}],["pass",{"2":{"162":1,"1227":1,"1249":1,"1364":1,"1368":1,"1369":1,"1371":1}}],["package",{"2":{"1258":1}}],["packet",{"2":{"813":1}}],["pacman",{"2":{"40":1}}],["pacman里的例子",{"2":{"40":1}}],["pan",{"2":{"811":1}}],["pandas软件包是python中常用的数据分析工具中",{"2":{"1014":1}}],["pandas软件包会自动为我们实现这一点",{"2":{"209":1}}],["pandas可以自动将此列转换为两列",{"2":{"1012":1}}],["pandas可以与张量兼容",{"2":{"1010":1,"1014":1}}],["pandas的人",{"2":{"992":1}}],["pandas",{"2":{"208":8,"404":4,"887":3,"931":3,"987":1,"1010":1,"1011":2,"1235":1,"1277":1,"1297":1}}],["pandas中引入的",{"2":{"208":1}}],["papineni",{"2":{"578":1}}],["paliwal",{"2":{"521":1}}],["paulus",{"2":{"395":1,"403":1}}],["pair函数",{"2":{"757":1}}],["pairs",{"2":{"616":1,"726":3,"757":5}}],["pair",{"0":{"757":1},"2":{"318":2,"509":6,"566":2,"687":6,"722":1,"727":9,"757":11,"773":1}}],["patil",{"2":{"811":1}}],["patterson",{"2":{"800":1}}],["pattern",{"2":{"251":1}}],["patch",{"2":{"566":2,"848":1,"858":2}}],["patches",{"2":{"566":3}}],["path",{"2":{"206":6,"565":1,"667":1,"686":6,"692":2,"718":1,"748":1,"772":1,"813":1,"864":1,"872":6,"874":4,"890":10,"892":5,"901":1,"902":1,"904":5,"908":3,"932":6,"945":9,"949":3,"1011":2,"1092":1,"1315":1,"1371":1,"1474":2,"1477":1,"1478":3,"1479":6,"1481":1,"1483":1,"1486":1}}],["parent",{"0":{"1502":1}}],["parse",{"2":{"1495":1}}],["parmas",{"2":{"1485":1}}],["parmar",{"2":{"380":1,"395":1,"398":1,"403":1}}],["parikh等人提出用注意力机制解决自然语言推断问题",{"2":{"672":1}}],["parikh",{"2":{"395":1,"672":1}}],["parallel",{"2":{"833":1,"836":3,"1313":1}}],["parallel演示了在k=2时基于数据并行方法训练模型",{"2":{"833":1}}],["parallelism",{"2":{"824":1,"1169":1}}],["para中展示了深度学习框架如何在cpu和gpu之间自动地并行化计算和通信",{"2":{"831":1}}],["para中的",{"2":{"391":1}}],["paragraph和",{"2":{"722":1}}],["paragraph",{"2":{"720":8,"722":21}}],["paragraphs是三重列表的嵌套",{"2":{"720":1}}],["paragraphs",{"2":{"718":3,"720":4,"722":24,"725":2}}],["para来学习注意力汇聚的参数",{"2":{"389":1}}],["para",{"2":{"389":1,"795":1}}],["paramiko",{"2":{"1297":1}}],["paramattr",{"2":{"127":2,"176":1,"225":1,"278":2,"573":2,"574":3,"592":2}}],["parameterized",{"2":{"235":1}}],["parameterization",{"2":{"231":1,"642":1}}],["parameter",{"2":{"127":2,"217":4,"282":1,"391":2,"414":4,"425":1,"472":4,"734":2,"762":2,"926":2,"968":1}}],["parameterserver描述了在",{"2":{"841":1}}],["parameterserver",{"2":{"824":1,"840":1,"841":1}}],["parameters=",{"2":{"874":1,"906":1}}],["parameters=params",{"2":{"221":1}}],["parameters=net",{"2":{"67":1,"68":1,"71":1,"72":1,"73":1,"81":1,"137":1,"175":1,"176":1,"210":1,"225":1,"263":1,"278":1,"335":1,"350":1,"392":1,"576":1,"594":1,"625":1,"681":1,"688":1,"704":1,"715":1,"726":1,"767":1,"828":1,"865":1,"874":1,"883":1,"894":1,"961":1}}],["parameters",{"2":{"67":2,"68":2,"71":2,"72":2,"73":2,"81":2,"137":4,"175":2,"176":2,"210":2,"225":2,"263":2,"278":2,"334":2,"335":2,"350":2,"392":2,"421":1,"422":1,"432":2,"436":2,"442":2,"473":1,"576":3,"594":3,"610":1,"625":2,"681":2,"686":1,"688":2,"704":2,"713":4,"715":2,"726":2,"767":2,"828":2,"865":2,"874":6,"876":2,"883":2,"894":2,"905":2,"906":2,"926":3,"961":2,"1064":1,"1123":1}}],["param",{"2":{"67":3,"68":2,"80":2,"173":2,"217":2,"278":2,"331":6,"334":7,"432":4,"436":4,"473":3,"544":6,"558":6,"576":3,"604":13,"713":3,"837":6,"874":10,"876":4,"905":4,"906":6,"946":1}}],["params参数",{"0":{"1482":1}}],["params=shared",{"2":{"437":1}}],["params",{"2":{"21":8,"28":8,"34":8,"35":8,"67":1,"68":1,"71":1,"72":1,"73":1,"80":8,"81":4,"91":8,"108":8,"127":2,"137":2,"173":2,"175":1,"176":1,"210":4,"217":5,"221":2,"225":1,"263":1,"273":4,"275":4,"278":4,"331":15,"332":26,"334":16,"335":10,"350":4,"391":1,"392":1,"414":3,"418":4,"425":1,"430":1,"432":3,"433":2,"437":1,"442":7,"472":2,"544":15,"545":8,"546":3,"558":15,"559":8,"560":3,"576":1,"594":2,"604":11,"616":6,"625":1,"635":8,"681":1,"686":3,"688":1,"703":1,"704":1,"714":1,"715":1,"726":1,"734":1,"767":1,"827":2,"828":1,"834":18,"835":24,"837":31,"865":2,"873":1,"874":10,"876":1,"883":1,"894":1,"905":1,"906":1,"926":2,"927":1,"946":1,"961":1,"1045":1,"1047":1,"1482":2,"1508":4}}],["park",{"2":{"300":2,"832":1,"840":1,"843":1}}],["parts",{"2":{"566":4}}],["partition",{"2":{"631":4}}],["partitioning",{"2":{"319":1}}],["partialuser",{"2":{"1410":1}}],["partial",{"2":{"307":6,"308":1,"309":1,"310":1,"312":8,"982":1,"1121":2,"1410":2,"1432":1}}],["part",{"2":{"211":8,"1174":1}}],["pad函数将",{"2":{"568":1}}],["pad>",{"2":{"567":1,"568":3,"569":2,"577":4,"668":6,"687":3,"693":2,"695":6,"722":9}}],["pad",{"2":{"141":1,"147":2,"148":1,"363":1,"567":1,"568":4,"577":4,"584":1,"668":13,"693":1,"695":6,"722":7}}],["pad中",{"2":{"141":1}}],["padded",{"2":{"147":4,"148":2}}],["padding中卷积层输出形状的计算方法",{"2":{"862":1}}],["paddings",{"2":{"147":4,"148":2}}],["padding",{"2":{"134":2,"140":2,"141":1,"494":7,"568":3,"1444":1}}],["padding=0",{"2":{"495":3}}],["padding=padding",{"2":{"494":1}}],["padding=3",{"2":{"482":3,"488":3,"502":3}}],["padding=16",{"2":{"862":3}}],["padding=1",{"2":{"141":3,"142":3,"147":3,"148":3,"461":11,"480":3,"482":3,"487":6,"488":15,"495":6,"501":6,"502":3,"507":3,"826":3,"863":3,"893":3,"954":3,"955":3,"957":3,"969":3}}],["padding=",{"2":{"67":1,"136":1,"141":5,"142":5,"147":5,"148":1,"461":4,"480":1,"482":2,"487":3,"488":6,"495":4,"501":2,"502":4,"507":1}}],["padding=2",{"2":{"67":3,"136":3,"461":3,"487":3,"495":3,"969":6}}],["paddlevision",{"2":{"861":1,"862":1,"863":1,"866":2,"871":1,"872":10,"873":2,"874":1,"877":1,"879":3,"880":3,"881":1,"882":7,"887":1,"891":9,"892":2,"899":1,"903":11,"904":2,"905":1,"918":1,"919":4,"920":1,"931":1,"932":1,"938":2,"945":1,"954":1,"964":1}}],["paddlescatter",{"2":{"836":4}}],["paddlenlp",{"2":{"686":2}}],["paddlepaddle会累积梯度",{"2":{"974":1}}],["paddlepaddle会使用xavier初始化权重矩阵",{"2":{"434":1}}],["paddlepaddle在optimizer模块中实现了该算法的许多变种",{"2":{"594":1}}],["paddlepaddle的gru层output的形状",{"2":{"573":1}}],["paddlepaddle的nn",{"2":{"434":1}}],["paddlepaddle",{"2":{"445":1}}],["paddle",{"2":{"21":9,"23":1,"27":3,"28":4,"29":2,"31":1,"34":8,"35":6,"37":1,"38":3,"41":1,"52":1,"54":5,"57":1,"64":1,"67":8,"68":3,"71":4,"72":3,"73":3,"75":1,"77":10,"78":2,"79":1,"80":3,"81":4,"83":1,"87":3,"91":3,"92":2,"97":1,"99":4,"101":1,"102":2,"103":1,"105":1,"107":3,"108":5,"109":2,"111":1,"112":3,"113":1,"118":1,"120":4,"122":1,"124":1,"126":5,"127":5,"128":1,"129":3,"133":1,"136":6,"137":11,"139":1,"141":6,"142":2,"144":1,"146":5,"147":6,"148":3,"150":1,"172":10,"173":1,"174":1,"175":2,"176":4,"178":1,"208":4,"210":8,"215":1,"216":4,"217":5,"218":3,"219":1,"220":1,"221":2,"223":1,"224":4,"225":4,"227":1,"234":3,"235":5,"236":4,"237":4,"239":1,"242":6,"243":4,"250":1,"261":4,"262":1,"263":3,"268":1,"271":4,"273":3,"274":2,"275":2,"278":4,"280":1,"318":3,"321":1,"323":1,"324":5,"325":9,"326":2,"328":1,"329":5,"330":4,"331":2,"332":10,"333":4,"334":4,"335":9,"337":1,"340":4,"344":1,"350":9,"351":2,"353":1,"357":3,"359":1,"360":2,"366":1,"367":4,"368":8,"369":8,"370":5,"372":1,"374":4,"375":7,"376":2,"378":1,"381":4,"382":5,"384":1,"385":4,"386":6,"387":2,"388":2,"390":8,"391":3,"392":9,"394":1,"395":4,"396":2,"398":12,"399":1,"402":1,"404":4,"405":2,"406":3,"407":4,"408":5,"409":5,"411":1,"413":9,"414":10,"416":1,"420":1,"422":6,"423":3,"424":3,"425":5,"426":1,"428":1,"429":4,"430":1,"431":3,"432":2,"433":3,"434":1,"435":9,"436":7,"437":1,"439":1,"441":15,"442":7,"444":1,"445":2,"446":16,"447":2,"448":6,"449":2,"451":2,"453":1,"461":6,"465":1,"472":13,"473":3,"474":1,"477":1,"480":8,"481":2,"482":3,"485":1,"487":6,"488":7,"491":1,"494":4,"495":3,"498":1,"501":8,"502":6,"505":1,"507":4,"508":3,"509":1,"511":1,"523":4,"525":1,"528":5,"531":1,"533":2,"534":1,"535":1,"537":1,"543":5,"544":4,"545":5,"546":1,"547":1,"549":1,"557":5,"558":2,"559":7,"560":1,"561":1,"563":1,"564":3,"571":1,"572":4,"573":5,"574":5,"575":11,"576":6,"577":7,"578":1,"580":1,"581":4,"582":8,"583":2,"584":5,"586":1,"589":3,"590":3,"591":3,"592":5,"593":2,"594":3,"595":2,"597":1,"598":3,"599":1,"600":1,"601":1,"604":2,"605":2,"607":1,"615":4,"616":1,"621":1,"622":4,"623":1,"624":1,"625":2,"628":1,"629":3,"630":3,"631":3,"633":3,"634":4,"635":4,"638":1,"666":4,"668":4,"669":3,"671":1,"673":5,"674":5,"675":3,"676":2,"677":1,"679":3,"680":1,"681":2,"682":4,"684":1,"685":4,"686":6,"687":9,"688":4,"690":1,"691":4,"694":1,"695":1,"697":1,"698":4,"699":1,"702":5,"703":1,"704":2,"706":1,"712":4,"713":4,"714":1,"715":5,"717":1,"718":3,"722":12,"724":1,"725":6,"726":5,"727":4,"729":1,"733":4,"734":7,"736":7,"737":5,"738":1,"740":1,"747":4,"750":6,"753":1,"757":1,"759":1,"760":4,"762":1,"763":5,"765":2,"766":1,"767":5,"768":6,"770":1,"771":3,"777":3,"779":1,"789":4,"790":16,"794":2,"795":3,"796":14,"797":7,"799":1,"818":1,"819":11,"820":4,"821":3,"823":1,"825":4,"826":1,"827":1,"828":6,"829":1,"830":2,"833":5,"834":11,"835":9,"836":4,"837":7,"839":1,"847":4,"848":19,"849":3,"851":10,"852":13,"853":1,"854":18,"856":1,"857":4,"860":1,"861":6,"862":5,"863":10,"864":3,"865":2,"866":6,"868":1,"871":5,"872":3,"873":4,"874":9,"876":4,"877":5,"878":1,"879":3,"880":3,"881":2,"882":4,"883":8,"885":1,"887":5,"891":2,"892":5,"893":2,"894":4,"895":1,"896":2,"897":1,"898":1,"899":5,"903":2,"904":5,"905":2,"906":4,"907":1,"908":2,"910":1,"912":6,"915":1,"918":6,"919":4,"920":3,"922":2,"923":2,"926":4,"927":3,"929":1,"931":4,"932":9,"933":1,"935":1,"938":9,"942":1,"945":10,"946":5,"947":5,"948":2,"949":3,"951":1,"954":6,"955":1,"956":6,"957":3,"958":2,"959":6,"961":2,"962":3,"963":1,"964":7,"966":7,"967":4,"968":2,"969":4,"970":4,"972":1,"974":11,"975":2,"976":4,"977":7,"979":1,"981":2,"986":1,"989":4,"990":3,"991":2,"992":9,"993":3,"994":7,"995":8,"996":4,"997":5,"998":2,"999":3,"1000":8,"1004":1,"1006":3,"1007":4,"1009":1,"1013":4,"1015":1,"1017":15,"1018":11,"1019":5,"1020":2,"1021":3,"1022":4,"1024":1,"1026":15,"1038":1}}],["pagey",{"2":{"1498":1}}],["pagex",{"2":{"1498":1}}],["pages",{"2":{"1474":3}}],["pagerank",{"2":{"293":1}}],["page",{"0":{"3":1,"4":1},"2":{"0":7,"3":1,"6":1,"293":1,"1198":1,"1444":1}}],["pr",{"2":{"1315":2,"1325":1}}],["practice",{"2":{"1082":1,"1083":1}}],["private",{"2":{"1417":1,"1425":3,"1427":1,"1428":2,"1432":1}}],["prioritizing",{"2":{"1137":1}}],["prior函数",{"2":{"959":1}}],["prior函数中更改sizes和ratios的值",{"2":{"856":1}}],["prior函数中实现",{"2":{"848":1}}],["prior",{"2":{"848":6,"912":3,"959":3}}],["primary",{"2":{"634":1,"1209":4}}],["principal",{"2":{"296":1,"1158":1,"1159":1,"1160":1}}],["printoptions",{"2":{"847":3}}],["print",{"2":{"54":2,"57":2,"59":1,"67":3,"68":4,"77":4,"78":4,"80":4,"81":4,"129":4,"136":4,"137":10,"172":15,"206":1,"208":3,"211":1,"212":1,"213":1,"243":8,"263":5,"275":4,"278":4,"320":1,"321":1,"335":15,"350":4,"361":3,"362":2,"363":3,"376":2,"392":4,"399":1,"406":4,"409":3,"418":1,"430":2,"431":11,"432":5,"433":4,"435":8,"436":4,"437":6,"449":6,"461":4,"473":2,"488":4,"495":4,"502":4,"508":4,"565":2,"569":4,"576":4,"578":2,"582":1,"584":1,"595":12,"599":1,"600":1,"605":6,"667":4,"668":3,"669":3,"687":3,"692":2,"693":1,"694":6,"722":1,"726":6,"750":1,"757":4,"762":2,"765":2,"767":3,"768":3,"774":2,"776":1,"777":1,"793":1,"816":1,"817":2,"820":1,"821":3,"827":1,"828":3,"835":8,"836":9,"837":3,"848":3,"863":6,"882":1,"883":6,"890":2,"894":3,"906":3,"932":3,"947":3,"948":6,"959":9,"963":6,"981":1,"1006":4,"1011":1,"1012":2,"1021":8,"1218":7,"1219":3,"1220":3,"1221":2,"1223":3,"1225":1,"1226":1,"1230":4,"1232":1,"1233":1,"1235":2,"1236":2,"1239":1,"1244":3,"1250":1,"1252":3,"1254":2,"1257":1,"1261":1,"1262":1,"1296":1,"1299":1}}],["pricing",{"2":{"207":2,"208":1}}],["pricey",{"2":{"1089":2}}],["pricey这个文件就是训练集中的价格数据",{"2":{"1089":1}}],["price=warea⋅area+wage⋅age+b",{"2":{"610":1}}],["prices",{"2":{"207":1}}],["price",{"2":{"204":1,"610":3,"1011":2,"1432":3,"1456":3,"1457":3,"1503":2}}],["protected",{"2":{"1416":1,"1417":1,"1425":4,"1428":2}}],["prototyping",{"2":{"1088":1}}],["protocol",{"0":{"1039":1},"1":{"1040":1,"1041":1,"1042":1,"1043":1,"1044":1,"1045":1,"1046":1,"1047":1,"1048":1},"2":{"1040":1,"1042":1,"1043":1}}],["promise",{"2":{"1412":1,"1431":4}}],["proxy",{"2":{"1364":1,"1368":3,"1369":1,"1371":2,"1377":1,"1378":2,"1527":1}}],["prod",{"2":{"1090":2}}],["product>",{"2":{"1432":1}}],["productrepo",{"2":{"1432":4}}],["products",{"2":{"660":1}}],["product",{"0":{"997":1},"2":{"370":1,"994":1,"997":1,"998":1,"1432":1}}],["prog",{"2":{"817":3}}],["programming",{"2":{"282":1,"519":1,"789":1,"816":1,"817":1,"1094":1}}],["props是使用频率最高的一种通信方式",{"2":{"1497":1}}],["props的函数写法",{"2":{"1483":1}}],["props的布尔值写法",{"2":{"1483":1}}],["props的对象写法",{"2":{"1483":1}}],["props",{"0":{"1469":1,"1497":1},"2":{"1469":3,"1483":3,"1501":1}}],["propert",{"2":{"1525":1}}],["properties",{"2":{"1076":1}}],["property",{"2":{"363":2,"375":5,"408":4,"1255":1}}],["proposal",{"2":{"939":1}}],["propagation或backpropagation",{"2":{"164":1}}],["propagation或forward",{"2":{"162":1}}],["propagation",{"2":{"161":1,"1099":1,"1100":1}}],["processes",{"2":{"1364":1,"1371":1}}],["processor",{"2":{"807":1}}],["processing",{"2":{"457":2,"807":2,"811":2,"1099":1}}],["process",{"2":{"298":1,"584":3}}],["probablity",{"2":{"1107":1}}],["probability",{"2":{"987":1,"1026":5,"1027":1,"1030":1,"1031":1,"1033":1,"1035":1,"1038":1}}],["probabilistic",{"2":{"296":1}}],["probs",{"2":{"854":22,"964":6,"1026":20}}],["prob中关于条件概率的对数损失为",{"2":{"708":1}}],["prob中所说的概率基本公理",{"2":{"643":1}}],["prob",{"2":{"631":6,"708":1,"854":8,"1025":1,"1035":4}}],["prob2中改变",{"2":{"513":1}}],["prob2中的输出序列",{"2":{"513":1}}],["prob2中的时间步4生成",{"2":{"513":1}}],["prob2中的",{"2":{"513":1}}],["prob2中的词元",{"2":{"513":1}}],["prob2中的另一个例子阐述了这个问题",{"2":{"513":1}}],["prob2",{"2":{"513":1}}],["prob1不同",{"2":{"513":1}}],["prob1中的贪心搜索的条件概率",{"2":{"513":1}}],["prob1中的条件概率",{"2":{"513":1}}],["prob1中的",{"2":{"513":2}}],["prob1中",{"2":{"513":2}}],["prob1",{"2":{"513":1}}],["problem中介绍过",{"2":{"330":1}}],["problem",{"2":{"209":1,"298":2,"640":1,"1114":1,"1158":1,"1171":1,"1178":1,"1187":1}}],["project",{"2":{"1315":1,"1443":1,"1444":1,"1549":1}}],["projected",{"2":{"1158":1}}],["projects",{"2":{"666":3,"748":1}}],["projection=",{"2":{"102":2}}],["projection",{"2":{"50":1}}],["projections中菱形例子的一个广义版本",{"2":{"50":1}}],["projections",{"2":{"50":3,"380":1}}],["projx",{"2":{"50":1}}],["provide",{"0":{"1503":1},"2":{"1503":3}}],["provides",{"2":{"7":1}}],["provided",{"2":{"0":1,"6":1}}],["prettier",{"2":{"1444":1}}],["pretrain显示了",{"2":{"754":1}}],["pretrain中所强调的那样",{"2":{"754":1}}],["pretrain中训练了词元的表示",{"2":{"663":1}}],["pretrain",{"2":{"754":2}}],["pretrained=true",{"2":{"862":3,"873":5,"905":3,"920":3}}],["pretrained",{"2":{"686":16,"690":1,"862":8,"873":6,"874":1,"876":3,"920":4}}],["pretraining和",{"2":{"731":1}}],["pretraining",{"2":{"718":1,"725":1,"735":1,"754":2,"760":1}}],["pretraining中",{"2":{"747":1}}],["pretraining中所讨论的",{"2":{"686":1}}],["pretraining中指出的那样",{"2":{"656":1}}],["pretrainingwikitext",{"2":{"686":1}}],["precision",{"2":{"1139":1,"1140":2}}],["preconditioning",{"2":{"53":1}}],["preliminaries",{"2":{"987":1}}],["prelu",{"2":{"235":2}}],["pre",{"2":{"732":1}}],["prepare",{"2":{"721":1,"725":1}}],["preprocess",{"2":{"565":2,"569":1,"687":6,"919":3,"920":6}}],["preprocessing中介绍的时光机器数据集构建词表",{"2":{"318":1}}],["preprocessing中",{"2":{"315":1}}],["preprocessing",{"2":{"305":1,"360":1}}],["premises",{"2":{"667":2,"668":12,"677":6}}],["premise",{"2":{"665":1,"668":9,"682":12,"687":19}}],["prev",{"2":{"565":2}}],["preview",{"2":{"17":1}}],["prefix=",{"2":{"905":1}}],["prefix",{"2":{"333":12,"335":8}}],["predicate",{"2":{"1432":2}}],["predictor",{"2":{"954":3,"955":3,"956":6,"959":18}}],["predicted",{"2":{"854":17}}],["predicting",{"2":{"854":1,"856":1}}],["prediction",{"0":{"737":1},"2":{"351":2,"608":1,"614":1,"634":1,"1093":1}}],["predictions",{"2":{"213":1}}],["predict所示",{"2":{"577":1}}],["predict",{"2":{"221":1,"326":4,"333":6,"335":19,"376":2,"409":2,"577":5,"578":2,"636":2,"682":4,"704":2,"715":5,"866":6,"964":6}}],["pred的形状",{"2":{"575":4}}],["preds指示预测的数量",{"2":{"721":1}}],["preds步",{"2":{"333":4}}],["preds",{"2":{"210":8,"213":2,"333":8,"351":20,"636":2,"721":4,"722":12,"854":14,"896":9,"908":9,"956":10,"959":75,"962":28,"963":20,"964":12}}],["pred",{"2":{"208":2,"210":2,"213":2,"386":2,"387":1,"575":8,"577":12,"578":10,"636":2,"721":25,"722":41,"726":16,"736":27,"738":9,"763":6,"765":4,"767":6,"827":4,"854":18,"866":24,"883":13,"956":12}}],["pre>",{"2":{"0":6}}]],"serializationVersion":2}';export{e as default};
