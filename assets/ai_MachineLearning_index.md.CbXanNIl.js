import{_ as i,c as e,o as a,ag as t}from"./chunks/framework.C2Gjomh7.js";const c=JSON.parse('{"title":"斯坦福大学 2014 机器学习教程中文笔记目录","description":"","frontmatter":{},"headers":[],"relativePath":"ai/MachineLearning/index.md","filePath":"ai/MachineLearning/index.md","lastUpdated":1756829839000}'),r={name:"ai/MachineLearning/index.md"};function n(h,l,p,u,o,s){return a(),e("div",null,[...l[0]||(l[0]=[t('<h1 id="斯坦福大学-2014-机器学习教程中文笔记目录" tabindex="-1">斯坦福大学 2014 机器学习教程中文笔记目录 <a class="header-anchor" href="#斯坦福大学-2014-机器学习教程中文笔记目录" aria-label="Permalink to &quot;斯坦福大学 2014 机器学习教程中文笔记目录&quot;">​</a></h1><ul><li><p><a href="./1.引言、单变量线性回归、线性代数.html">一、引言 (Introduction)</a></p><ul><li>1.1 欢迎</li><li>1.2 机器学习是什么？</li><li>1.3 监督学习</li><li>1.4 无监督学习</li></ul></li><li><p><a href="./1.引言、单变量线性回归、线性代数.html">二、单变量线性回归 (Linear Regression with One Variable)</a></p><ul><li>2.1 模型表示</li><li>2.2 代价函数</li><li>2.3 代价函数的直观理解 I</li><li>2.4 代价函数的直观理解 II</li><li>2.5 梯度下降</li><li>2.6 梯度下降的直观理解</li><li>2.7 梯度下降的线性回归</li><li>2.8 接下来的内容</li></ul></li><li><p><a href="./1.引言、单变量线性回归、线性代数.html">三、线性代数回顾 (Linear Algebra Review)</a></p><ul><li>3.1 矩阵和向量</li><li>3.2 加法和标量乘法</li><li>3.3 矩阵向量乘法</li><li>3.4 矩阵乘法</li><li>3.5 矩阵乘法的性质</li><li>3.6 逆、转置</li></ul></li><li><p><a href="./2.多变量线性回归.html">四、多变量线性回归 (Linear Regression with Multiple Variables)</a></p><ul><li>4.1 多维特征</li><li>4.2 多变量梯度下降</li><li>4.3 梯度下降法实践1——特征缩放</li><li>4.4 梯度下降法实践2——学习率</li><li>4.5 特征和多项式回归</li><li>4.6 正规方程</li><li>4.7 正规方程及不可逆性（选修）</li></ul></li><li><p><a href="./2.多变量线性回归.html">五、Octave 教程 (Octave Tutorial)</a></p><ul><li>5.1 基本操作</li><li>5.2 移动数据</li><li>5.3 计算数据</li><li>5.4 绘图数据</li><li>5.5 控制语句：for，while，if</li><li>5.6 向量化</li><li>5.7 工作与提交的编程练习</li></ul></li><li><p><a href="./3.逻辑回归、正则化.html">六、逻辑回归 (Logistic Regression)</a></p><ul><li>6.1 分类问题</li><li>6.2 假说表示</li><li>6.3 判定边界</li><li>6.4 代价函数</li><li>6.5 简化的成本函数和梯度下降</li><li>6.6 高级优化</li><li>6.7 多类别分类：一对多</li></ul></li><li><p><a href="./3.逻辑回归、正则化.html">七、正则化 (Regularization)</a></p><ul><li>7.1 过拟合的问题</li><li>7.2 代价函数</li><li>7.3 正则化线性回归</li><li>7.4 正则化的逻辑回归模型</li></ul></li><li><p><a href="./4.神经网络、表述.html">八、神经网络：表述 (Neural Networks: Representation)</a></p><ul><li>8.1 非线性假设</li><li>8.2 神经元和大脑</li><li>8.3 模型表示 I</li><li>8.4 模型表示 II</li><li>8.5 样本和直观理解 I</li><li>8.6 样本和直观理解 II</li><li>8.7 多类分类</li></ul></li><li><p><a href="./5.神经网络的学习.html">九、神经网络的学习 (Neural Networks: Learning)</a></p><ul><li>9.1 代价函数</li><li>9.2 反向传播算法</li><li>9.3 反向传播算法的直观理解</li><li>9.4 实现注意：展开参数</li><li>9.5 梯度检验</li><li>9.6 随机初始化</li><li>9.7 综合起来</li><li>9.8 自动驾驶</li></ul></li><li><p><a href="./6.学习建议、系统设计.html">十、应用机器学习的建议 (Advice for Applying Machine Learning)</a></p><ul><li>10.1 决定下一步做什么</li><li>10.2 评估一个假设</li><li>10.3 模型选择和交叉验证集</li><li>10.4 诊断偏差和方差</li><li>10.5 正则化和偏差/方差</li><li>10.6 学习曲线</li><li>10.7 决定下一步做什么</li></ul></li><li><p><a href="./6.学习建议、系统设计.html">十一、机器学习系统的设计 (Machine Learning System Design)</a></p><ul><li>11.1 首先要做什么</li><li>11.2 误差分析</li><li>11.3 类偏斜的误差度量</li><li>11.4 查准率和查全率之间的权衡</li><li>11.5 机器学习的数据</li></ul></li><li><p><a href="./7.支持向量机.html">十二、支持向量机 (Support Vector Machines)</a></p><ul><li>12.1 优化目标</li><li>12.2 大边界的直观理解</li><li>12.3 数学背后的大边界分类（选修）</li><li>12.4 核函数 1</li><li>12.5 核函数 2</li><li>12.6 使用支持向量机</li></ul></li><li><p><a href="./8.聚类、降维.html">十三、聚类 (Clustering)</a></p><ul><li>13.1 无监督学习：简介</li><li>13.2 K-均值算法</li><li>13.3 优化目标</li><li>13.4 随机初始化</li><li>13.5 选择聚类数</li></ul></li><li><p><a href="./8.聚类、降维.html">十四、降维 (Dimensionality Reduction)</a></p><ul><li>14.1 动机一：数据压缩</li><li>14.2 动机二：数据可视化</li><li>14.3 主成分分析问题</li><li>14.4 主成分分析算法</li><li>14.5 选择主成分的数量</li><li>14.6 重建的压缩表示</li><li>14.7 主成分分析法的应用建议</li></ul></li><li><p><a href="./9.异常检测、推荐系统.html">十五、异常检测 (Anomaly Detection)</a></p><ul><li>15.1 问题的动机</li><li>15.2 高斯分布</li><li>15.3 算法</li><li>15.4 开发和评价一个异常检测系统</li><li>15.5 异常检测与监督学习对比</li><li>15.6 选择特征</li><li>15.7 多元高斯分布（选修）</li><li>15.8 使用多元高斯分布进行异常检测（选修）</li></ul></li><li><p><a href="./9.异常检测、推荐系统.html">十六、推荐系统 (Recommender Systems)</a></p><ul><li>16.1 问题形式化</li><li>16.2 基于内容的推荐系统</li><li>16.3 协同过滤</li><li>16.4 协同过滤算法</li><li>16.5 向量化：低秩矩阵分解</li><li>16.6 推行工作上的细节：均值归一化</li></ul></li><li><p><a href="./X.大规模机器学习、Photo OCR、总结.html">十七、大规模机器学习 (Large Scale Machine Learning)</a></p><ul><li>17.1 大型数据集的学习</li><li>17.2 随机梯度下降法</li><li>17.3 小批量梯度下降</li><li>17.4 随机梯度下降收敛</li><li>17.5 在线学习</li><li>17.6 映射化简和数据并行</li></ul></li><li><p><a href="./X.大规模机器学习、Photo OCR、总结.html">十八、应用实例：图片文字识别 (Application Example: Photo OCR)</a></p><ul><li>18.1 问题描述和流程图</li><li>18.2 滑动窗口</li><li>18.3 获取大量数据和人工数据</li><li>18.4 上限分析</li></ul></li><li><p><a href="./X.大规模机器学习、Photo OCR、总结.html">十九、总结 (Conclusion)</a></p><ul><li>19.1 总结和致谢</li></ul></li></ul>',2)])])}const f=i(r,[["render",n]]);export{c as __pageData,f as default};
