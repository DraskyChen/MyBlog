<!DOCTYPE html>
<html lang="zh-CN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>层和块 | Drasky's Blog</title>
    <meta name="description" content="A VitePress Site">
    <meta name="generator" content="VitePress v1.6.4">
    <link rel="preload stylesheet" href="/MyBlog/assets/style.yzDaPA9-.css" as="style">
    <link rel="preload stylesheet" href="/MyBlog/vp-icons.css" as="style">
    
    <script type="module" src="/MyBlog/assets/app.D4-0N0H9.js"></script>
    <link rel="preload" href="/MyBlog/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/MyBlog/assets/chunks/theme.CapJMVUD.js">
    <link rel="modulepreload" href="/MyBlog/assets/chunks/framework.C2Gjomh7.js">
    <link rel="modulepreload" href="/MyBlog/assets/ai_DeepLearning_深度学习计算_model-construction.md.BzbvW5S1.lean.js">
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-5R3J1LLHED"></script>
    <script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-5R3J1LLHED");</script>
    <link rel="icon" href="./IronMan.svg">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-d8b57b2d><!--[--><!--]--><!--[--><span tabindex="-1" data-v-fcbfc0e0></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-fcbfc0e0>Skip to content</a><!--]--><!----><header class="VPNav" data-v-d8b57b2d data-v-7ad780c2><div class="VPNavBar" data-v-7ad780c2 data-v-9fd4d1dd><div class="wrapper" data-v-9fd4d1dd><div class="container" data-v-9fd4d1dd><div class="title" data-v-9fd4d1dd><div class="VPNavBarTitle has-sidebar" data-v-9fd4d1dd data-v-9f43907a><a class="title" href="/MyBlog/" data-v-9f43907a><!--[--><!--]--><!--[--><img class="VPImage logo" src="/MyBlog/IronMan.svg" alt data-v-ab19afbb><!--]--><span data-v-9f43907a>Drasky&#39;s Blog</span><!--[--><!--]--></a></div></div><div class="content" data-v-9fd4d1dd><div class="content-body" data-v-9fd4d1dd><!--[--><!--]--><div class="VPNavBarSearch search" data-v-9fd4d1dd><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-9fd4d1dd data-v-afb2845e><span id="main-nav-aria-label" class="visually-hidden" data-v-afb2845e> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/MyBlog/" tabindex="0" data-v-afb2845e data-v-815115f5><!--[--><span data-v-815115f5>主页</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-afb2845e data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-bfe7971f><span class="text" data-v-bfe7971f><!----><span data-v-bfe7971f>前端</span><span class="vpi-chevron-down text-icon" data-v-bfe7971f></span></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><div class="items" data-v-20ed86d6><!--[--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>基础知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/frontend/HTML/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>HTML</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/frontend/CSS/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>CSS</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/frontend/JavaScript/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>JavaScript</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>进阶知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/frontend/TypeScript/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>TypeScript</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>框架技术</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/frontend/Vue/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Vue</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/frontend/React/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>React</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>前端工程化</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/frontend/Webpack/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Webpack</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/frontend/Vite/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Vite</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuLink" data-v-20ed86d6 data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/frontend/awesome.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Awesome</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-afb2845e data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-bfe7971f><span class="text" data-v-bfe7971f><!----><span data-v-bfe7971f>后端</span><span class="vpi-chevron-down text-icon" data-v-bfe7971f></span></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><div class="items" data-v-20ed86d6><!--[--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>基础知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/backend/Java/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Java</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/backend/Python/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Python</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>数据库</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/backend/RDBMS/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>关系型数据库 (RDBMS)</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/backend/NoSQL/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>非关系型数据库 (NoSQL)</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>框架技术</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/backend/SpringBoot/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>SpringBoot</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/backend/Django/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Django</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuLink" data-v-20ed86d6 data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/backend/awesome.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Awesome</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-afb2845e data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-bfe7971f><span class="text" data-v-bfe7971f><!----><span data-v-bfe7971f>AI</span><span class="vpi-chevron-down text-icon" data-v-bfe7971f></span></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><div class="items" data-v-20ed86d6><!--[--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>基础知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/ai/MachineLearning/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>机器学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/ai/DeepLearning/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>深度学习</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>框架技术</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/ai/TensorFlow/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>TensorFlow</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/ai/PyTorch/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>PyTorch</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>进阶知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/ai/NLP/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>NLP</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/ai/CV/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>CV</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>LLM</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/ai/LLM/Agent/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Agent</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuLink" data-v-20ed86d6 data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/ai/awesome.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Awesome</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-afb2845e data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-bfe7971f><span class="text" data-v-bfe7971f><!----><span data-v-bfe7971f>DevOps</span><span class="vpi-chevron-down text-icon" data-v-bfe7971f></span></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><div class="items" data-v-20ed86d6><!--[--><!--[--><div class="VPMenuLink" data-v-20ed86d6 data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/devops/devtools/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>开发工具</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-20ed86d6 data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/devops/Git/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Git</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-20ed86d6 data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/devops/CI_CD/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>CI/CD</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-20ed86d6 data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/devops/container/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>容器化</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-20ed86d6 data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/devops/mon&amp;log/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>监控与日志</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-20ed86d6 data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/devops/server/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Web 服务器/反向代理</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><div class="VPFlyout VPNavBarTranslations translations" data-v-9fd4d1dd data-v-acee064b data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="Change language" data-v-bfe7971f><span class="text" data-v-bfe7971f><span class="vpi-languages option-icon" data-v-bfe7971f></span><!----><span class="vpi-chevron-down text-icon" data-v-bfe7971f></span></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><!----><!--[--><!--[--><div class="items" data-v-acee064b><p class="title" data-v-acee064b>简体中文</p><!--[--><div class="VPMenuLink" data-v-acee064b data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/en-US/ai/DeepLearning/深度学习计算/model-construction.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>English</span><!--]--></a></div><!--]--></div><!--]--><!--]--></div></div></div><div class="VPNavBarAppearance appearance" data-v-9fd4d1dd data-v-3f90c1a5><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-3f90c1a5 data-v-be9742d9 data-v-b4ccac88><span class="check" data-v-b4ccac88><span class="icon" data-v-b4ccac88><!--[--><span class="vpi-sun sun" data-v-be9742d9></span><span class="vpi-moon moon" data-v-be9742d9></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-9fd4d1dd data-v-ef6192dc data-v-e71e869c><!--[--><a class="VPSocialLink no-icon" href="https://github.com/DraskyChen" aria-label="github" target="_blank" rel="noopener" data-v-e71e869c data-v-60a9a2d3><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-9fd4d1dd data-v-f953d92f data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-bfe7971f><span class="vpi-more-horizontal icon" data-v-bfe7971f></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><!----><!--[--><!--[--><div class="group translations" data-v-f953d92f><p class="trans-title" data-v-f953d92f>简体中文</p><!--[--><div class="VPMenuLink" data-v-f953d92f data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/en-US/ai/DeepLearning/深度学习计算/model-construction.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>English</span><!--]--></a></div><!--]--></div><div class="group" data-v-f953d92f><div class="item appearance" data-v-f953d92f><p class="label" data-v-f953d92f>Appearance</p><div class="appearance-action" data-v-f953d92f><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-f953d92f data-v-be9742d9 data-v-b4ccac88><span class="check" data-v-b4ccac88><span class="icon" data-v-b4ccac88><!--[--><span class="vpi-sun sun" data-v-be9742d9></span><span class="vpi-moon moon" data-v-be9742d9></span><!--]--></span></span></button></div></div></div><div class="group" data-v-f953d92f><div class="item social-links" data-v-f953d92f><div class="VPSocialLinks social-links-list" data-v-f953d92f data-v-e71e869c><!--[--><a class="VPSocialLink no-icon" href="https://github.com/DraskyChen" aria-label="github" target="_blank" rel="noopener" data-v-e71e869c data-v-60a9a2d3><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-9fd4d1dd data-v-6bee1efd><span class="container" data-v-6bee1efd><span class="top" data-v-6bee1efd></span><span class="middle" data-v-6bee1efd></span><span class="bottom" data-v-6bee1efd></span></span></button></div></div></div></div><div class="divider" data-v-9fd4d1dd><div class="divider-line" data-v-9fd4d1dd></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-d8b57b2d data-v-2488c25a><div class="container" data-v-2488c25a><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-2488c25a><span class="vpi-align-left menu-icon" data-v-2488c25a></span><span class="menu-text" data-v-2488c25a>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-2488c25a data-v-6b867909><button data-v-6b867909>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-d8b57b2d data-v-42c4c606><div class="curtain" data-v-42c4c606></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-42c4c606><span class="visually-hidden" id="sidebar-aria-label" data-v-42c4c606> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>优化算法</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/adadelta.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>adadelta</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/adagrad.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>adagrad</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/adam.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>adam</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/convexity.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>convexity</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/gd.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>gd</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/lr-scheduler.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>lr-scheduler</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/minibatch-sgd.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>minibatch-sgd</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/momentum.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>momentum</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/optimization-intro.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>optimization-intro</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/rmsprop.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>rmsprop</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/sgd.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>sgd</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>卷积神经网络</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/channels.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>channels</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/conv-layer.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>conv-layer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/lenet.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>lenet</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/padding-and-strides.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>padding-and-strides</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/pooling.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>pooling</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/why-conv.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>why-conv</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>多层感知机</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/backprop.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>backprop</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/dropout.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>dropout</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/environment.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>environment</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/kaggle-house-price.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>kaggle-house-price</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/mlp-concise.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>mlp-concise</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/mlp-scratch.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>mlp-scratch</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/mlp.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>mlp</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/numerical-stability-and-init.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>numerical-stability-and-init</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/underfit-overfit.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>underfit-overfit</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/weight-decay.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>weight-decay</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><!----><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%BC%95%E8%A8%80.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>引言</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>循环神经网络</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/bptt.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>bptt</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/language-models-and-dataset.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>language-models-and-dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/rnn-concise.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>rnn-concise</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/rnn-scratch.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>rnn-scratch</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/rnn.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>rnn</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/sequence.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>sequence</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/text-preprocessing.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>text-preprocessing</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>注意力机制</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/attention-cues.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>attention-cues</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/attention-scoring-functions.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>attention-scoring-functions</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/bahdanau-attention.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>bahdanau-attention</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/multihead-attention.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>multihead-attention</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/nadaraya-waston.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>nadaraya-waston</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/self-attention-and-positional-encoding.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>self-attention-and-positional-encoding</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/transformer.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>transformer</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0 has-active" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>深度学习计算</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/custom-layer.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>custom-layer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/deferred-init.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>deferred-init</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/model-construction.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>model-construction</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/parameters.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>parameters</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/read-write.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>read-write</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/use-gpu.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>use-gpu</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>现代卷积神经网络</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/alexnet.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>alexnet</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/batch-norm.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>batch-norm</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/densenet.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>densenet</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/googlenet.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>googlenet</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/nin.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>nin</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/resnet.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>resnet</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/vgg.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>vgg</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>现代循环神经网络</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/beam-search.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>beam-search</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/bi-rnn.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>bi-rnn</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/deep-rnn.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>deep-rnn</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/encoder-decoder.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>encoder-decoder</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/gru.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>gru</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/lstm.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>lstm</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/machine-translation-and-dataset.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>machine-translation-and-dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/seq2seq.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>seq2seq</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>线性神经网络</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-classification-dataset.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>image-classification-dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/linear-regression-concise.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>linear-regression-concise</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/linear-regression-scratch.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>linear-regression-scratch</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/linear-regression.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>linear-regression</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/softmax-regression-concise.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>softmax-regression-concise</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/softmax-regression-scratch.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>softmax-regression-scratch</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/softmax-regression.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>softmax-regression</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>自然语言处理：应用</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E5%BA%94%E7%94%A8/finetuning-bert.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>finetuning-bert</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E5%BA%94%E7%94%A8/natural-language-inference-and-dataset.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>natural-language-inference-and-dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E5%BA%94%E7%94%A8/natural-language-inference-attention.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>natural-language-inference-attention</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E5%BA%94%E7%94%A8/natural-language-inference-bert.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>natural-language-inference-bert</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E5%BA%94%E7%94%A8/sentiment-analysis-and-dataset.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>sentiment-analysis-and-dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E5%BA%94%E7%94%A8/sentiment-analysis-cnn.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>sentiment-analysis-cnn</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E5%BA%94%E7%94%A8/sentiment-analysis-rnn.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>sentiment-analysis-rnn</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>自然语言处理：预训练</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/approx-training.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>approx-training</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/bert-dataset.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>bert-dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/bert-pretraining.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>bert-pretraining</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/bert.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>bert</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/glove.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>glove</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/similarity-analogy.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>similarity-analogy</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/subword-embedding.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>subword-embedding</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/word-embedding-dataset.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>word-embedding-dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/word2vec-pretraining.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>word2vec-pretraining</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/word2vec.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>word2vec</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>计算性能</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%80%A7%E8%83%BD/async-computation.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>async-computation</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%80%A7%E8%83%BD/auto-parallelism.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>auto-parallelism</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%80%A7%E8%83%BD/hardware.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>hardware</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%80%A7%E8%83%BD/hybridize.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>hybridize</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%80%A7%E8%83%BD/multiple-gpus-concise.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>multiple-gpus-concise</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%80%A7%E8%83%BD/multiple-gpus.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>multiple-gpus</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%80%A7%E8%83%BD/parameterserver.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>parameterserver</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>计算机视觉</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/anchor.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>anchor</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/bounding-box.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>bounding-box</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/fcn.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>fcn</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/fine-tuning.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>fine-tuning</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/image-augmentation.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>image-augmentation</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/kaggle-cifar10.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>kaggle-cifar10</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/kaggle-dog.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>kaggle-dog</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/multiscale-object-detection.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>multiscale-object-detection</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/neural-style.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>neural-style</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/object-detection-dataset.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>object-detection-dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/rcnn.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>rcnn</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/semantic-segmentation-and-dataset.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>semantic-segmentation-and-dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/ssd.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>ssd</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/transposed-conv.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>transposed-conv</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>预备知识</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/autograd.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>autograd</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/calculus.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>calculus</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/linear-algebra.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>linear-algebra</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/lookup-api.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>lookup-api</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/ndarray.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>ndarray</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/pandas.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>pandas</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/probability.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>probability</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-d8b57b2d data-v-9a6c75ad><div class="VPDoc has-sidebar has-aside" data-v-9a6c75ad data-v-e6f2a212><!--[--><!--]--><div class="container" data-v-e6f2a212><div class="aside" data-v-e6f2a212><div class="aside-curtain" data-v-e6f2a212></div><div class="aside-container" data-v-e6f2a212><div class="aside-content" data-v-e6f2a212><div class="VPDocAside" data-v-e6f2a212 data-v-cb998dce><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-cb998dce data-v-f610f197><div class="content" data-v-f610f197><div class="outline-marker" data-v-f610f197></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-f610f197>On this page</div><ul class="VPDocOutlineItem root" data-v-f610f197 data-v-53c99d69><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-cb998dce></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-e6f2a212><div class="content-container" data-v-e6f2a212><!--[--><!--]--><main class="main" data-v-e6f2a212><div style="position:relative;" class="vp-doc _MyBlog_ai_DeepLearning_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97_model-construction" data-v-e6f2a212><div><h1 id="层和块" tabindex="-1">层和块 <a class="header-anchor" href="#层和块" aria-label="Permalink to &quot;层和块&quot;">​</a></h1><p>🏷️<code>sec_model_construction</code></p><p>之前首次介绍神经网络时，我们关注的是具有单一输出的线性模型。 在这里，整个模型只有一个输出。 注意，单个神经网络 （1）接受一些输入； （2）生成相应的标量输出； （3）具有一组相关 <em>参数</em>（parameters），更新这些参数可以优化某目标函数。</p><p>然后，当考虑具有多个输出的网络时， 我们利用矢量化算法来描述整层神经元。 像单个神经元一样，层（1）接受一组输入， （2）生成相应的输出， （3）由一组可调整参数描述。 当我们使用softmax回归时，一个单层本身就是模型。 然而，即使我们随后引入了多层感知机，我们仍然可以认为该模型保留了上面所说的基本架构。</p><p>对于多层感知机而言，整个模型及其组成层都是这种架构。 整个模型接受原始输入（特征），生成输出（预测）， 并包含一些参数（所有组成层的参数集合）。 同样，每个单独的层接收输入（由前一层提供）， 生成输出（到下一层的输入），并且具有一组可调参数， 这些参数根据从下一层反向传播的信号进行更新。</p><p>事实证明，研究讨论“比单个层大”但“比整个模型小”的组件更有价值。 例如，在计算机视觉中广泛流行的ResNet-152架构就有数百层， 这些层是由<em>层组</em>（groups of layers）的重复模式组成。 这个ResNet架构赢得了2015年ImageNet和COCO计算机视觉比赛 的识别和检测任务 :cite:<code>He.Zhang.Ren.ea.2016</code>。 目前ResNet架构仍然是许多视觉任务的首选架构。 在其他的领域，如自然语言处理和语音， 层组以各种重复模式排列的类似架构现在也是普遍存在。</p><p>为了实现这些复杂的网络，我们引入了神经网络<em>块</em>的概念。 <em>块</em>（block）可以描述单个层、由多个层组成的组件或整个模型本身。 使用块进行抽象的一个好处是可以将一些块组合成更大的组件， 这一过程通常是递归的，如 :numref:<code>fig_blocks</code>所示。 通过定义代码来按需生成任意复杂度的块， 我们可以通过简洁的代码实现复杂的神经网络。</p><p><img src="/MyBlog/assets/blocks.C0rtU3ZL.svg" alt="多个层被组合成块，形成更大的模型"> 🏷️<code>fig_blocks</code></p><p>从编程的角度来看，块由<em>类</em>（class）表示。 它的任何子类都必须定义一个将其输入转换为输出的前向传播函数， 并且必须存储任何必需的参数。 注意，有些块不需要任何参数。 最后，为了计算梯度，块必须具有反向传播函数。 在定义我们自己的块时，由于自动微分（在 :numref:<code>sec_autograd</code> 中引入） 提供了一些后端实现，我们只需要考虑前向传播函数和必需的参数。</p><p>在构造自定义块之前，(<strong>我们先回顾一下多层感知机</strong>) （ :numref:<code>sec_mlp_concise</code> ）的代码。 下面的代码生成一个网络，其中包含一个具有256个单元和ReLU激活函数的全连接隐藏层， 然后是一个具有10个隐藏单元且不带激活函数的全连接输出层。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> mxnet </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np, npx</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> mxnet.gluon </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">npx.set_np()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net.add(nn.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net.add(nn.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net.initialize()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.random.uniform(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net(X)</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab pytorch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> functional </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> F</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential(nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU(), nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.rand(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net(X)</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab tensorflow</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorflow </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tf</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tf.keras.models.Sequential([</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    tf.keras.layers.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tf.nn.relu),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    tf.keras.layers.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tf.random.uniform((</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net(X)</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab paddle</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> warnings</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">warnings.filterwarnings(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">action</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;ignore&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> paddle</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> paddle </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> paddle.nn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> functional </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> F</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential(nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU(), nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> paddle.rand([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net(X)</span></span></code></pre></div><p>:begin_tab:<code>mxnet</code> 在这个例子中，我们通过实例化<code>nn.Sequential</code>来构建我们的模型， 返回的对象赋给<code>net</code>变量。 接下来，我们反复调用<code>net</code>变量的<code>add</code>函数，按照想要执行的顺序添加层。 简而言之，<code>nn.Sequential</code>定义了一种特殊类型的<code>Block</code>， 即在Gluon中表示块的类，它维护<code>Block</code>的有序列表。 <code>add</code>函数方便将每个连续的<code>Block</code>添加到列表中。 请注意，每层都是<code>Dense</code>类的一个实例，<code>Dense</code>类本身就是<code>Block</code>的子类。 到目前为止，我们一直在通过<code>net(X)</code>调用我们的模型来获得模型的输出。 这实际上是<code>net.forward(X)</code>的简写， 这是通过<code>Block</code>类的<code>__call__</code>函数实现的一个Python技巧。 前向传播（<code>forward</code>）函数非常简单：它将列表中的每个<code>Block</code>连接在一起， 将每个<code>Block</code>的输出作为输入传递给下一层。</p><p>:end_tab:</p><p>:begin_tab:<code>pytorch</code> 在这个例子中，我们通过实例化<code>nn.Sequential</code>来构建我们的模型， 层的执行顺序是作为参数传递的。 简而言之，(<strong><code>nn.Sequential</code>定义了一种特殊的<code>Module</code></strong>)， 即在PyTorch中表示一个块的类， 它维护了一个由<code>Module</code>组成的有序列表。 注意，两个全连接层都是<code>Linear</code>类的实例， <code>Linear</code>类本身就是<code>Module</code>的子类。 另外，到目前为止，我们一直在通过<code>net(X)</code>调用我们的模型来获得模型的输出。 这实际上是<code>net.__call__(X)</code>的简写。 这个前向传播函数非常简单： 它将列表中的每个块连接在一起，将每个块的输出作为下一个块的输入。</p><p>:end_tab:</p><p>:begin_tab:<code>tensorflow</code> 在这个例子中，我们通过实例化<code>keras.models.Sequential</code>来构建我们的模型， 层的执行顺序是作为参数传递的。 简而言之，<code>Sequential</code>定义了一种特殊的<code>keras.Model</code>， 即在Keras中表示一个块的类。 它维护了一个由<code>Model</code>组成的有序列表， 注意两个全连接层都是<code>Model</code>类的实例， 这个类本身就是<code>Model</code>的子类。 前向传播（<code>call</code>）函数也非常简单： 它将列表中的每个块连接在一起，将每个块的输出作为下一个块的输入。 注意，到目前为止，我们一直在通过<code>net(X)</code>调用我们的模型来获得模型的输出。 这实际上是<code>net.call(X)</code>的简写， 这是通过Block类的<code>__call__</code>函数实现的一个Python技巧。 :end_tab:</p><p>:begin_tab:<code>paddle</code> 在这个例子中，我们通过实例化<code>nn.Sequential</code>来构建我们的模型， 层的执行顺序是作为参数传递的。 简而言之，(<strong><code>nn.Sequential</code>定义了一种特殊的<code>Layer</code></strong>)， 即在PaddlePaddle中表示一个块的类， 它维护了一个由<code>Layer</code>组成的有序列表。 注意，两个全连接层都是<code>Linear</code>类的实例， <code>Linear</code>类本身就是<code>Layer</code>的子类。 另外，到目前为止，我们一直在通过<code>net(X)</code>调用我们的模型来获得模型的输出。 这实际上是<code>net.__call__(X)</code>的简写。 这个前向传播函数非常简单： 它将列表中的每个块连接在一起，将每个块的输出作为下一个块的输入。 :end_tab:</p><h2 id="自定义块" tabindex="-1">[<strong>自定义块</strong>] <a class="header-anchor" href="#自定义块" aria-label="Permalink to &quot;[**自定义块**]&quot;">​</a></h2><p>要想直观地了解块是如何工作的，最简单的方法就是自己实现一个。 在实现我们自定义块之前，我们简要总结一下每个块必须提供的基本功能。</p><p>:begin_tab:<code>mxnet, tensorflow</code></p><ol><li>将输入数据作为其前向传播函数的参数。</li><li>通过前向传播函数来生成输出。请注意，输出的形状可能与输入的形状不同。例如，我们上面模型中的第一个全连接的层接收任意维的输入，但是返回一个维度256的输出。</li><li>计算其输出关于输入的梯度，可通过其反向传播函数进行访问。通常这是自动发生的。</li><li>存储和访问前向传播计算所需的参数。</li><li>根据需要初始化模型参数。 :end_tab:</li></ol><p>:begin_tab:<code>pytorch, paddle</code></p><ol><li>将输入数据作为其前向传播函数的参数。</li><li>通过前向传播函数来生成输出。请注意，输出的形状可能与输入的形状不同。例如，我们上面模型中的第一个全连接的层接收一个20维的输入，但是返回一个维度为256的输出。</li><li>计算其输出关于输入的梯度，可通过其反向传播函数进行访问。通常这是自动发生的。</li><li>存储和访问前向传播计算所需的参数。</li><li>根据需要初始化模型参数。 :end_tab:</li></ol><p>在下面的代码片段中，我们从零开始编写一个块。 它包含一个多层感知机，其具有256个隐藏单元的隐藏层和一个10维输出层。 注意，下面的<code>MLP</code>类继承了表示块的类。 我们的实现只需要提供我们自己的构造函数（Python中的<code>__init__</code>函数）和前向传播函数。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> MLP</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Block</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 用模型参数声明层。这里，我们声明两个全连接的层</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kwargs):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 调用MLP的父类Block的构造函数来执行必要的初始化。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍）</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kwargs)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.hidden </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 隐藏层</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.out </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 输出层</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 定义模型的前向传播，即如何根据输入X返回所需的模型输出</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, X):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.out(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.hidden(X))</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab pytorch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> MLP</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 用模型参数声明层。这里，我们声明两个全连接的层</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 调用MLP的父类Module的构造函数来执行必要的初始化。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍）</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.hidden </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 隐藏层</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.out </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 输出层</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 定义模型的前向传播，即如何根据输入X返回所需的模型输出</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, X):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.out(F.relu(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.hidden(X)))</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab tensorflow</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> MLP</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">tf</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">keras</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Model</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 用模型参数声明层。这里，我们声明两个全连接的层</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 调用MLP的父类Model的构造函数来执行必要的初始化。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍）</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # Hiddenlayer</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.hidden </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tf.keras.layers.Dense(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">units</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tf.nn.relu)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.out </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tf.keras.layers.Dense(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">units</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Outputlayer</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 定义模型的前向传播，即如何根据输入X返回所需的模型输出</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> call</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, X):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.out(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.hidden((X)))</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab paddle</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> MLP</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Layer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 用模型参数声明层。这里，我们声明两个全连接的层</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 调用`MLP`的父类Layer的构造函数来执行必要的初始化。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数`params`（稍后将介绍）</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.hidden </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 隐藏层</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.out </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 输出层</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 定义模型的正向传播，即如何根据输入`X`返回所需的模型输出</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, X):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.out(F.relu(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.hidden(X)))</span></span></code></pre></div><p>我们首先看一下前向传播函数，它以<code>X</code>作为输入， 计算带有激活函数的隐藏表示，并输出其未规范化的输出值。 在这个<code>MLP</code>实现中，两个层都是实例变量。 要了解这为什么是合理的，可以想象实例化两个多层感知机（<code>net1</code>和<code>net2</code>）， 并根据不同的数据对它们进行训练。 当然，我们希望它们学到两种不同的模型。</p><p>接着我们[<strong>实例化多层感知机的层，然后在每次调用前向传播函数时调用这些层</strong>]。 注意一些关键细节： 首先，我们定制的<code>__init__</code>函数通过<code>super().__init__()</code> 调用父类的<code>__init__</code>函数， 省去了重复编写模版代码的痛苦。 然后，我们实例化两个全连接层， 分别为<code>self.hidden</code>和<code>self.out</code>。 注意，除非我们实现一个新的运算符， 否则我们不必担心反向传播函数或参数初始化， 系统将自动生成这些。</p><p>我们来试一下这个函数：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MLP()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net.initialize()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net(X)</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab pytorch, paddle</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MLP()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net(X)</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab tensorflow</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MLP()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net(X)</span></span></code></pre></div><p>块的一个主要优点是它的多功能性。 我们可以子类化块以创建层（如全连接层的类）、 整个模型（如上面的<code>MLP</code>类）或具有中等复杂度的各种组件。 我们在接下来的章节中充分利用了这种多功能性， 比如在处理卷积神经网络时。</p><h2 id="顺序块" tabindex="-1">[<strong>顺序块</strong>] <a class="header-anchor" href="#顺序块" aria-label="Permalink to &quot;[**顺序块**]&quot;">​</a></h2><p>现在我们可以更仔细地看看<code>Sequential</code>类是如何工作的， 回想一下<code>Sequential</code>的设计是为了把其他模块串起来。 为了构建我们自己的简化的<code>MySequential</code>， 我们只需要定义两个关键函数：</p><ol><li>一种将块逐个追加到列表中的函数；</li><li>一种前向传播函数，用于将输入按追加块的顺序传递给块组成的“链条”。</li></ol><p>下面的<code>MySequential</code>类提供了与默认<code>Sequential</code>类相同的功能。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> MySequential</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Block</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> add</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, block):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 这里，block是Block子类的一个实例，我们假设它有一个唯一的名称。我们把它</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 保存在&#39;Block&#39;类的成员变量_children中。block的类型是OrderedDict。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 当MySequential实例调用initialize函数时，系统会自动初始化_children</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 的所有成员</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">._children[block.name] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> block</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, X):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # OrderedDict保证了按照成员添加的顺序遍历它们</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> block </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">._children.values():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> block(X)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> X</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab pytorch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> MySequential</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">args):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> idx, module </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> enumerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(args):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">            # 这里，module是Module子类的一个实例。我们把它保存在&#39;Module&#39;类的成员</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">            # 变量_modules中。_module的类型是OrderedDict</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">._modules[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(idx)] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> module</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, X):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # OrderedDict保证了按照成员添加的顺序遍历它们</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> block </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">._modules.values():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> block(X)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> X</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab tensorflow</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> MySequential</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">tf</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">keras</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Model</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">args):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.modules </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> []</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> block </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> args:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">            # 这里，block是tf.keras.layers.Layer子类的一个实例</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.modules.append(block)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> call</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, X):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> module </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.modules:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> module(X)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> X</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab paddle</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> MySequential</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Layer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">layers):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(MySequential, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 如果传入的是一个tuple</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(layers) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> and</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> isinstance</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(layers[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">tuple</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">): </span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">            for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name, layer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> layers:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">                # add_sublayer方法会将layer添加到self._sub_layers(一个tuple)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">                self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.add_sublayer(name, layer)  </span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        else</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">            for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> idx, layer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> enumerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(layers):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">                self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.add_sublayer(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(idx), layer)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, X):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # OrderedDict保证了按照成员添加的顺序遍历它们</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> layer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">._sub_layers.values():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> layer(X)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> X</span></span></code></pre></div><p>:begin_tab:<code>mxnet</code><code>add</code>函数向有序字典<code>_children</code>添加一个块。 读者可能会好奇为什么每个Gluon中的<code>Block</code>都有一个<code>_children</code>属性？ 以及为什么我们使用它而不是自己定义一个Python列表？ 简而言之，<code>_children</code>的主要优点是： 在块的参数初始化过程中， Gluon知道在<code>_children</code>字典中查找需要初始化参数的子块。 :end_tab:</p><p>:begin_tab:<code>pytorch</code><code>__init__</code>函数将每个模块逐个添加到有序字典<code>_modules</code>中。 读者可能会好奇为什么每个<code>Module</code>都有一个<code>_modules</code>属性？ 以及为什么我们使用它而不是自己定义一个Python列表？ 简而言之，<code>_modules</code>的主要优点是： 在模块的参数初始化过程中， 系统知道在<code>_modules</code>字典中查找需要初始化参数的子块。 :end_tab:</p><p>:begin_tab:<code>paddle</code><code>__init__</code>函数将每个模块逐个添加到有序字典<code>_sub_layers</code>中。 你可能会好奇为什么每个<code>Layer</code>都有一个<code>_sub_layers</code>属性？ 以及为什么我们使用它而不是自己定义一个Python列表？ 简而言之，<code>_sub_layers</code>的主要优点是： 在模块的参数初始化过程中， 系统知道在<code>_sub_layers</code>字典中查找需要初始化参数的子块。 :end_tab:</p><p>当<code>MySequential</code>的前向传播函数被调用时， 每个添加的块都按照它们被添加的顺序执行。 现在可以使用我们的<code>MySequential</code>类重新实现多层感知机。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MySequential()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net.add(nn.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net.add(nn.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net.initialize()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net(X)</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab pytorch, paddle</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MySequential(nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU(), nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net(X)</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab tensorflow</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MySequential(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    tf.keras.layers.Dense(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">units</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tf.nn.relu),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    tf.keras.layers.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net(X)</span></span></code></pre></div><p>请注意，<code>MySequential</code>的用法与之前为<code>Sequential</code>类编写的代码相同 （如 :numref:<code>sec_mlp_concise</code> 中所述）。</p><h2 id="在前向传播函数中执行代码" tabindex="-1">[<strong>在前向传播函数中执行代码</strong>] <a class="header-anchor" href="#在前向传播函数中执行代码" aria-label="Permalink to &quot;[**在前向传播函数中执行代码**]&quot;">​</a></h2><p><code>Sequential</code>类使模型构造变得简单， 允许我们组合新的架构，而不必定义自己的类。 然而，并不是所有的架构都是简单的顺序架构。 当需要更强的灵活性时，我们需要定义自己的块。 例如，我们可能希望在前向传播函数中执行Python的控制流。 此外，我们可能希望执行任意的数学运算， 而不是简单地依赖预定义的神经网络层。</p><p>到目前为止， 我们网络中的所有操作都对网络的激活值及网络的参数起作用。 然而，有时我们可能希望合并既不是上一层的结果也不是可更新参数的项， 我们称之为<em>常数参数</em>（constant parameter）。 例如，我们需要一个计算函数 <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.566ex;" xmlns="http://www.w3.org/2000/svg" width="17.581ex" height="2.456ex" role="img" focusable="false" viewBox="0 -835.3 7770.8 1085.3" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(550,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(939,0)"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(1546,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(1990.7,0)"><g data-mml-node="mi"><path data-c="1D430" d="M624 444Q636 441 722 441Q797 441 800 444H805V382H741L593 11Q592 10 590 8T586 4T584 2T581 0T579 -2T575 -3T571 -3T567 -4T561 -4T553 -4H542Q525 -4 518 6T490 70Q474 110 463 137L415 257L367 137Q357 111 341 72Q320 17 313 7T289 -4H277Q259 -4 253 -2T238 11L90 382H25V444H32Q47 441 140 441Q243 441 261 444H270V382H222L310 164L382 342L366 382H303V444H310Q322 441 407 441Q508 441 523 444H531V382H506Q481 382 481 380Q482 376 529 259T577 142L674 382H617V444H624Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(2821.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3488.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(4544.2,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(5199.4,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msup" transform="translate(5699.7,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D430" d="M624 444Q636 441 722 441Q797 441 800 444H805V382H741L593 11Q592 10 590 8T586 4T584 2T581 0T579 -2T575 -3T571 -3T567 -4T561 -4T553 -4H542Q525 -4 518 6T490 70Q474 110 463 137L415 257L367 137Q357 111 341 72Q320 17 313 7T289 -4H277Q259 -4 253 -2T238 11L90 382H25V444H32Q47 441 140 441Q243 441 261 444H270V382H222L310 164L382 342L366 382H303V444H310Q322 441 407 441Q508 441 523 444H531V382H506Q481 382 481 380Q482 376 529 259T577 142L674 382H617V444H624Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mi" transform="translate(864,363) scale(0.707)"><path data-c="22A4" d="M55 642T55 648T59 659T66 666T71 668H708Q723 660 723 648T708 628H409V15Q402 2 391 0Q387 0 384 1T379 3T375 6T373 9T371 13T369 16V628H71Q70 628 67 630T59 637Z" style="stroke-width:3;"></path></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(7163.8,0)"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z" style="stroke-width:3;"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mo stretchy="false">(</mo><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow><mo>,</mo><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">w</mi></mrow><mo stretchy="false">)</mo><mo>=</mo><mi>c</mi><mo>⋅</mo><msup><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">w</mi></mrow><mi mathvariant="normal">⊤</mi></msup><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow></math></mjx-assistive-mml></mjx-container>的层， 其中<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:0;" xmlns="http://www.w3.org/2000/svg" width="1.373ex" height="1.005ex" role="img" focusable="false" viewBox="0 -444 607 444" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D431" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z" style="stroke-width:3;"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">x</mi></mrow></math></mjx-assistive-mml></mjx-container>是输入， <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:0;" xmlns="http://www.w3.org/2000/svg" width="1.88ex" height="1.005ex" role="img" focusable="false" viewBox="0 -444 831 444" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D430" d="M624 444Q636 441 722 441Q797 441 800 444H805V382H741L593 11Q592 10 590 8T586 4T584 2T581 0T579 -2T575 -3T571 -3T567 -4T561 -4T553 -4H542Q525 -4 518 6T490 70Q474 110 463 137L415 257L367 137Q357 111 341 72Q320 17 313 7T289 -4H277Q259 -4 253 -2T238 11L90 382H25V444H32Q47 441 140 441Q243 441 261 444H270V382H222L310 164L382 342L366 382H303V444H310Q322 441 407 441Q508 441 523 444H531V382H506Q481 382 481 380Q482 376 529 259T577 142L674 382H617V444H624Z" style="stroke-width:3;"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">w</mi></mrow></math></mjx-assistive-mml></mjx-container>是参数， <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.98ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 433 453" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>c</mi></math></mjx-assistive-mml></mjx-container>是某个在优化过程中没有更新的指定常量。 因此我们实现了一个<code>FixedHiddenMLP</code>类，如下所示：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> FixedHiddenMLP</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Block</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kwargs):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kwargs)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 使用get_constant函数创建的随机权重参数在训练期间不会更新（即为常量参数）</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.rand_weight </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.params.get_constant(</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &#39;rand_weight&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, np.random.uniform(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)))</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.dense </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, X):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.dense(X)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 使用创建的常量参数以及relu和dot函数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> npx.relu(np.dot(X, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.rand_weight.data()) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 复用全连接层。这相当于两个全连接层共享参数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.dense(X)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 控制流</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        while</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.abs(X).sum() </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> X.sum()</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab pytorch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> FixedHiddenMLP</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 不计算梯度的随机权重参数。因此其在训练期间保持不变</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.rand_weight </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.rand((</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">requires_grad</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, X):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear(X)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 使用创建的常量参数以及relu和mm函数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> F.relu(torch.mm(X, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.rand_weight) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 复用全连接层。这相当于两个全连接层共享参数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear(X)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 控制流</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        while</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> X.abs().sum() </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> X.sum()</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab tensorflow</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> FixedHiddenMLP</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">tf</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">keras</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Model</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.flatten </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tf.keras.layers.Flatten()</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 使用tf.constant函数创建的随机权重参数在训练期间不会更新（即为常量参数）</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.rand_weight </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tf.constant(tf.random.uniform((</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)))</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.dense </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tf.keras.layers.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tf.nn.relu)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> call</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, inputs):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.flatten(inputs)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 使用创建的常量参数以及relu和matmul函数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tf.nn.relu(tf.matmul(X, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.rand_weight) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 复用全连接层。这相当于两个全连接层共享参数。</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.dense(X)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 控制流</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        while</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tf.reduce_sum(tf.math.abs(X)) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tf.reduce_sum(X)</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab paddle</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> FixedHiddenMLP</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Layer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 不计算梯度的随机权重参数。因此其在训练期间保持不变。</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.rand_weight </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> paddle.rand([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, X):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear(X)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 使用创建的常量参数以及relu和mm函数。</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> F.relu(paddle.tensor.mm(X, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.rand_weight) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 复用全连接层。这相当于两个全连接层共享参数。</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear(X)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 控制流</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        while</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> X.abs().sum() </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> X.sum()</span></span></code></pre></div><p>在这个<code>FixedHiddenMLP</code>模型中，我们实现了一个隐藏层， 其权重（<code>self.rand_weight</code>）在实例化时被随机初始化，之后为常量。 这个权重不是一个模型参数，因此它永远不会被反向传播更新。 然后，神经网络将这个固定层的输出通过一个全连接层。</p><p>注意，在返回输出之前，模型做了一些不寻常的事情： 它运行了一个while循环，在<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.528ex" height="1.885ex" role="img" focusable="false" viewBox="0 -683 1117.6 833" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(714,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>L</mi><mn>1</mn></msub></math></mjx-assistive-mml></mjx-container>范数大于<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:0;" xmlns="http://www.w3.org/2000/svg" width="1.131ex" height="1.507ex" role="img" focusable="false" viewBox="0 -666 500 666" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn></math></mjx-assistive-mml></mjx-container>的条件下， 将输出向量除以<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:0;" xmlns="http://www.w3.org/2000/svg" width="1.131ex" height="1.507ex" role="img" focusable="false" viewBox="0 -666 500 666" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>2</mn></math></mjx-assistive-mml></mjx-container>，直到它满足条件为止。 最后，模型返回了<code>X</code>中所有项的和。 注意，此操作可能不会常用于在任何实际任务中， 我们只展示如何将任意代码集成到神经网络计算的流程中。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> FixedHiddenMLP()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net.initialize()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net(X)</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab pytorch, tensorflow, paddle</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> FixedHiddenMLP()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net(X)</span></span></code></pre></div><p>我们可以[<strong>混合搭配各种组合块的方法</strong>]。 在下面的例子中，我们以一些想到的方法嵌套块。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> NestMLP</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Block</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kwargs):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kwargs)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.net.add(nn.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">64</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                     nn.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">32</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.dense </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">16</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, X):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.net(X))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">chimera </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">chimera.add(NestMLP(), nn.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), FixedHiddenMLP())</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">chimera.initialize()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">chimera(X)</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab pytorch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> NestMLP</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential(nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">64</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                                 nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">64</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">32</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU())</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">32</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">16</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, X):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.net(X))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">chimera </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential(NestMLP(), nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">16</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), FixedHiddenMLP())</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">chimera(X)</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab tensorflow</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> NestMLP</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">tf</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">keras</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Model</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tf.keras.Sequential()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.net.add(tf.keras.layers.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">64</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tf.nn.relu))</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.net.add(tf.keras.layers.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">32</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tf.nn.relu))</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.dense </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tf.keras.layers.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">16</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tf.nn.relu)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> call</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, inputs):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.net(inputs))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">chimera </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tf.keras.Sequential()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">chimera.add(NestMLP())</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">chimera.add(tf.keras.layers.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">chimera.add(FixedHiddenMLP())</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">chimera(X)</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab paddle</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> NestMLP</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Layer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential(nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">64</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                                 nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">64</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">32</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU())</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">32</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">16</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, X):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.net(X))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">chimera </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential(NestMLP(), nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">16</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), FixedHiddenMLP())</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">chimera(X)</span></span></code></pre></div><h2 id="效率" tabindex="-1">效率 <a class="header-anchor" href="#效率" aria-label="Permalink to &quot;效率&quot;">​</a></h2><p>:begin_tab:<code>mxnet</code> 读者可能会开始担心操作效率的问题。 毕竟，我们在一个高性能的深度学习库中进行了大量的字典查找、 代码执行和许多其他的Python代码。 Python的问题<a href="https://wiki.python.org/moin/GlobalInterpreterLock" target="_blank" rel="noreferrer">全局解释器锁</a> 是众所周知的。 在深度学习环境中，我们担心速度极快的GPU可能要等到CPU运行Python代码后才能运行另一个作业。</p><p>提高Python速度的最好方法是完全避免使用Python。 Gluon这样做的一个方法是允许<em>混合式编程</em>（hybridization），这将在后面描述。 Python解释器在第一次调用块时执行它。 Gluon运行时记录正在发生的事情，以及下一次它将对Python调用加速。 在某些情况下，这可以大大加快运行速度， 但当控制流（如上所述）在不同的网络通路上引导不同的分支时，需要格外小心。 我们建议感兴趣的读者在读完本章后，阅读混合式编程部分（ :numref:<code>sec_hybridize</code> ）来了解编译。 :end_tab:</p><p>:begin_tab:<code>pytorch</code> 读者可能会开始担心操作效率的问题。 毕竟，我们在一个高性能的深度学习库中进行了大量的字典查找、 代码执行和许多其他的Python代码。 Python的问题<a href="https://wiki.python.org/moin/GlobalInterpreterLock" target="_blank" rel="noreferrer">全局解释器锁</a> 是众所周知的。 在深度学习环境中，我们担心速度极快的GPU可能要等到CPU运行Python代码后才能运行另一个作业。 :end_tab:</p><p>:begin_tab:<code>tensorflow</code> 读者可能会开始担心操作效率的问题。 毕竟，我们在一个高性能的深度学习库中进行了大量的字典查找、 代码执行和许多其他的Python代码。 Python的问题<a href="https://wiki.python.org/moin/GlobalInterpreterLock" target="_blank" rel="noreferrer">全局解释器锁</a> 是众所周知的。 在深度学习环境中，我们担心速度极快的GPU可能要等到CPU运行Python代码后才能运行另一个作业。 :end_tab:</p><p>:begin_tab:<code>paddle</code> 你可能会开始担心操作效率的问题。 毕竟，我们在一个高性能的深度学习库中进行了大量的字典查找、 代码执行和许多其他的Python代码。 Python的问题<a href="https://wiki.python.org/moin/GlobalInterpreterLock" target="_blank" rel="noreferrer">全局解释器锁</a> 是众所周知的。 在深度学习环境中，我们担心速度极快的GPU可能要等到CPU运行Python代码后才能运行另一个作业。 :end_tab:</p><h2 id="小结" tabindex="-1">小结 <a class="header-anchor" href="#小结" aria-label="Permalink to &quot;小结&quot;">​</a></h2><ul><li>一个块可以由许多层组成；一个块可以由许多块组成。</li><li>块可以包含代码。</li><li>块负责大量的内部处理，包括参数初始化和反向传播。</li><li>层和块的顺序连接由<code>Sequential</code>块处理。</li></ul><h2 id="练习" tabindex="-1">练习 <a class="header-anchor" href="#练习" aria-label="Permalink to &quot;练习&quot;">​</a></h2><ol><li>如果将<code>MySequential</code>中存储块的方式更改为Python列表，会出现什么样的问题？</li><li>实现一个块，它以两个块为参数，例如<code>net1</code>和<code>net2</code>，并返回前向传播中两个网络的串联输出。这也被称为平行块。</li><li>假设我们想要连接同一网络的多个实例。实现一个函数，该函数生成同一个块的多个实例，并在此基础上构建更大的网络。</li></ol><p>:begin_tab:<code>mxnet</code><a href="https://discuss.d2l.ai/t/1828" target="_blank" rel="noreferrer">Discussions</a> :end_tab:</p><p>:begin_tab:<code>pytorch</code><a href="https://discuss.d2l.ai/t/1827" target="_blank" rel="noreferrer">Discussions</a> :end_tab:</p><p>:begin_tab:<code>tensorflow</code><a href="https://discuss.d2l.ai/t/1826" target="_blank" rel="noreferrer">Discussions</a> :end_tab:</p><p>:begin_tab:<code>paddle</code><a href="https://discuss.d2l.ai/t/11777" target="_blank" rel="noreferrer">Discussions</a> :end_tab:</p></div></div></main><footer class="VPDocFooter" data-v-e6f2a212 data-v-1bcd8184><!--[--><!--]--><div class="edit-info" data-v-1bcd8184><!----><div class="last-updated" data-v-1bcd8184><p class="VPLastUpdated" data-v-1bcd8184 data-v-1bb0c8a8>Last updated: <time datetime="2025-09-02T16:17:19.000Z" data-v-1bb0c8a8></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-1bcd8184><span class="visually-hidden" id="doc-footer-aria-label" data-v-1bcd8184>Pager</span><div class="pager" data-v-1bcd8184><a class="VPLink link pager-link prev" href="/MyBlog/ai/DeepLearning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/deferred-init.html" data-v-1bcd8184><!--[--><span class="desc" data-v-1bcd8184>Previous page</span><span class="title" data-v-1bcd8184>deferred-init</span><!--]--></a></div><div class="pager" data-v-1bcd8184><a class="VPLink link pager-link next" href="/MyBlog/ai/DeepLearning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/parameters.html" data-v-1bcd8184><!--[--><span class="desc" data-v-1bcd8184>Next page</span><span class="title" data-v-1bcd8184>parameters</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-d8b57b2d data-v-566314d4><div class="container" data-v-566314d4><!----><p class="copyright" data-v-566314d4>Copyright © 2025-present Drasky Chen</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"ai_cv_index.md\":\"B5kmByve\",\"ai_deeplearning_index.md\":\"yaBeF44B\",\"ai_deeplearning_优化算法_adadelta.md\":\"CbsNYMlD\",\"ai_deeplearning_优化算法_adagrad.md\":\"HncdhpQY\",\"ai_deeplearning_优化算法_adam.md\":\"BQhf6b3Z\",\"ai_deeplearning_优化算法_convexity.md\":\"BxENDO19\",\"ai_deeplearning_优化算法_gd.md\":\"BfiWzdGe\",\"ai_deeplearning_优化算法_index.md\":\"Ct782-u-\",\"ai_deeplearning_优化算法_lr-scheduler.md\":\"crBETzCo\",\"ai_deeplearning_优化算法_minibatch-sgd.md\":\"Be8IF8pr\",\"ai_deeplearning_优化算法_momentum.md\":\"DfGrRY9_\",\"ai_deeplearning_优化算法_optimization-intro.md\":\"DHBFzF6f\",\"ai_deeplearning_优化算法_rmsprop.md\":\"9myt26Du\",\"ai_deeplearning_优化算法_sgd.md\":\"C_-Otv3a\",\"ai_deeplearning_卷积神经网络_channels.md\":\"sccO21aY\",\"ai_deeplearning_卷积神经网络_conv-layer.md\":\"BtfzPDIj\",\"ai_deeplearning_卷积神经网络_index.md\":\"BytDAWCk\",\"ai_deeplearning_卷积神经网络_lenet.md\":\"Du7sXM4q\",\"ai_deeplearning_卷积神经网络_padding-and-strides.md\":\"CMPv2iwf\",\"ai_deeplearning_卷积神经网络_pooling.md\":\"Cn_o7JXH\",\"ai_deeplearning_卷积神经网络_why-conv.md\":\"3hbkuABH\",\"ai_deeplearning_多层感知机_backprop.md\":\"CXlm1R8s\",\"ai_deeplearning_多层感知机_dropout.md\":\"dnOwu9Ju\",\"ai_deeplearning_多层感知机_environment.md\":\"wuKUW1Zk\",\"ai_deeplearning_多层感知机_index.md\":\"CN1cCF8f\",\"ai_deeplearning_多层感知机_kaggle-house-price.md\":\"JCWbqUwj\",\"ai_deeplearning_多层感知机_mlp-concise.md\":\"e3XJ9_CI\",\"ai_deeplearning_多层感知机_mlp-scratch.md\":\"C6ZKftuZ\",\"ai_deeplearning_多层感知机_mlp.md\":\"CwYXs5Al\",\"ai_deeplearning_多层感知机_numerical-stability-and-init.md\":\"DGnppwzp\",\"ai_deeplearning_多层感知机_underfit-overfit.md\":\"D1AbILg9\",\"ai_deeplearning_多层感知机_weight-decay.md\":\"ht8TZVrx\",\"ai_deeplearning_引言.md\":\"usPXbFzx\",\"ai_deeplearning_循环神经网络_bptt.md\":\"Bu3BN7Yf\",\"ai_deeplearning_循环神经网络_index.md\":\"C998TH-6\",\"ai_deeplearning_循环神经网络_language-models-and-dataset.md\":\"D_mJ98jY\",\"ai_deeplearning_循环神经网络_rnn-concise.md\":\"BIeiN_Ba\",\"ai_deeplearning_循环神经网络_rnn-scratch.md\":\"hPTLcL3O\",\"ai_deeplearning_循环神经网络_rnn.md\":\"CGrMGGhk\",\"ai_deeplearning_循环神经网络_sequence.md\":\"sukp9-p_\",\"ai_deeplearning_循环神经网络_text-preprocessing.md\":\"laZT2Xl9\",\"ai_deeplearning_注意力机制_attention-cues.md\":\"8S-Nx-sj\",\"ai_deeplearning_注意力机制_attention-scoring-functions.md\":\"B3qf_UDL\",\"ai_deeplearning_注意力机制_bahdanau-attention.md\":\"Bq1F_oj0\",\"ai_deeplearning_注意力机制_index.md\":\"0gQV7od4\",\"ai_deeplearning_注意力机制_multihead-attention.md\":\"n_JSfyMs\",\"ai_deeplearning_注意力机制_nadaraya-waston.md\":\"LD7i-SbO\",\"ai_deeplearning_注意力机制_self-attention-and-positional-encoding.md\":\"CmN18lZW\",\"ai_deeplearning_注意力机制_transformer.md\":\"DbliP0fO\",\"ai_deeplearning_深度学习计算_custom-layer.md\":\"CA6tw5Ls\",\"ai_deeplearning_深度学习计算_deferred-init.md\":\"Dl7C3t-i\",\"ai_deeplearning_深度学习计算_index.md\":\"BSuTY6RB\",\"ai_deeplearning_深度学习计算_model-construction.md\":\"BzbvW5S1\",\"ai_deeplearning_深度学习计算_parameters.md\":\"CBX128fL\",\"ai_deeplearning_深度学习计算_read-write.md\":\"DcJ2U7KI\",\"ai_deeplearning_深度学习计算_use-gpu.md\":\"3bFcYhD5\",\"ai_deeplearning_现代卷积神经网络_alexnet.md\":\"BhHdW3Hf\",\"ai_deeplearning_现代卷积神经网络_batch-norm.md\":\"BC4OMaUf\",\"ai_deeplearning_现代卷积神经网络_densenet.md\":\"D8Mu-U0l\",\"ai_deeplearning_现代卷积神经网络_googlenet.md\":\"Dph7FuxX\",\"ai_deeplearning_现代卷积神经网络_index.md\":\"BfJIioHo\",\"ai_deeplearning_现代卷积神经网络_nin.md\":\"DDLrYIj5\",\"ai_deeplearning_现代卷积神经网络_resnet.md\":\"CfXXTcjo\",\"ai_deeplearning_现代卷积神经网络_vgg.md\":\"Bwiuxj1x\",\"ai_deeplearning_现代循环神经网络_beam-search.md\":\"nZPMVrew\",\"ai_deeplearning_现代循环神经网络_bi-rnn.md\":\"nH9SmpHA\",\"ai_deeplearning_现代循环神经网络_deep-rnn.md\":\"BgRLgkzF\",\"ai_deeplearning_现代循环神经网络_encoder-decoder.md\":\"BJflHZRx\",\"ai_deeplearning_现代循环神经网络_gru.md\":\"DRDvH_fj\",\"ai_deeplearning_现代循环神经网络_index.md\":\"Bzi7fvgO\",\"ai_deeplearning_现代循环神经网络_lstm.md\":\"dPkTGdN1\",\"ai_deeplearning_现代循环神经网络_machine-translation-and-dataset.md\":\"DyDx2QQD\",\"ai_deeplearning_现代循环神经网络_seq2seq.md\":\"IiQTlrXZ\",\"ai_deeplearning_线性神经网络_image-classification-dataset.md\":\"D9cdqgOJ\",\"ai_deeplearning_线性神经网络_index.md\":\"D81VgZ5h\",\"ai_deeplearning_线性神经网络_linear-regression-concise.md\":\"P2NwDNmW\",\"ai_deeplearning_线性神经网络_linear-regression-scratch.md\":\"DItnjE_L\",\"ai_deeplearning_线性神经网络_linear-regression.md\":\"B6QKBOIw\",\"ai_deeplearning_线性神经网络_softmax-regression-concise.md\":\"BY5796Ed\",\"ai_deeplearning_线性神经网络_softmax-regression-scratch.md\":\"CnYkb5xz\",\"ai_deeplearning_线性神经网络_softmax-regression.md\":\"CRDoPLnR\",\"ai_deeplearning_自然语言处理：应用_finetuning-bert.md\":\"BPjTEB0f\",\"ai_deeplearning_自然语言处理：应用_index.md\":\"H_4diCQ3\",\"ai_deeplearning_自然语言处理：应用_natural-language-inference-and-dataset.md\":\"BNMJlp3P\",\"ai_deeplearning_自然语言处理：应用_natural-language-inference-attention.md\":\"B21VIoEy\",\"ai_deeplearning_自然语言处理：应用_natural-language-inference-bert.md\":\"Dwc18Hwy\",\"ai_deeplearning_自然语言处理：应用_sentiment-analysis-and-dataset.md\":\"BI04hczh\",\"ai_deeplearning_自然语言处理：应用_sentiment-analysis-cnn.md\":\"Du6679S2\",\"ai_deeplearning_自然语言处理：应用_sentiment-analysis-rnn.md\":\"BoQxvAjw\",\"ai_deeplearning_自然语言处理：预训练_approx-training.md\":\"BHthSzzE\",\"ai_deeplearning_自然语言处理：预训练_bert-dataset.md\":\"Cl_Uf126\",\"ai_deeplearning_自然语言处理：预训练_bert-pretraining.md\":\"DXjRvByL\",\"ai_deeplearning_自然语言处理：预训练_bert.md\":\"CdaZ5dUA\",\"ai_deeplearning_自然语言处理：预训练_glove.md\":\"CAAAE6ZQ\",\"ai_deeplearning_自然语言处理：预训练_index.md\":\"251eI_CT\",\"ai_deeplearning_自然语言处理：预训练_similarity-analogy.md\":\"DMsB5Z0H\",\"ai_deeplearning_自然语言处理：预训练_subword-embedding.md\":\"B-jG7TmX\",\"ai_deeplearning_自然语言处理：预训练_word-embedding-dataset.md\":\"CPmmFSn9\",\"ai_deeplearning_自然语言处理：预训练_word2vec-pretraining.md\":\"ciBYGLi-\",\"ai_deeplearning_自然语言处理：预训练_word2vec.md\":\"DA-95Hlf\",\"ai_deeplearning_计算性能_async-computation.md\":\"B3l9WmWp\",\"ai_deeplearning_计算性能_auto-parallelism.md\":\"wvCqWZ_1\",\"ai_deeplearning_计算性能_hardware.md\":\"BfSMQAjL\",\"ai_deeplearning_计算性能_hybridize.md\":\"2vHepORo\",\"ai_deeplearning_计算性能_index.md\":\"B1On18kr\",\"ai_deeplearning_计算性能_multiple-gpus-concise.md\":\"Z9tBFWyg\",\"ai_deeplearning_计算性能_multiple-gpus.md\":\"BKreGSJJ\",\"ai_deeplearning_计算性能_parameterserver.md\":\"eP9ScBHQ\",\"ai_deeplearning_计算机视觉_anchor.md\":\"DRXVVYC0\",\"ai_deeplearning_计算机视觉_bounding-box.md\":\"CllPeWsr\",\"ai_deeplearning_计算机视觉_fcn.md\":\"CScTRqMq\",\"ai_deeplearning_计算机视觉_fine-tuning.md\":\"DsvClRJP\",\"ai_deeplearning_计算机视觉_image-augmentation.md\":\"ByLswgpj\",\"ai_deeplearning_计算机视觉_index.md\":\"D8y7gs0r\",\"ai_deeplearning_计算机视觉_kaggle-cifar10.md\":\"CiFrksp-\",\"ai_deeplearning_计算机视觉_kaggle-dog.md\":\"CpEoAg0I\",\"ai_deeplearning_计算机视觉_multiscale-object-detection.md\":\"uc10-Avf\",\"ai_deeplearning_计算机视觉_neural-style.md\":\"C2MYor7Y\",\"ai_deeplearning_计算机视觉_object-detection-dataset.md\":\"ThCHA8zN\",\"ai_deeplearning_计算机视觉_rcnn.md\":\"DX8Dz5N1\",\"ai_deeplearning_计算机视觉_semantic-segmentation-and-dataset.md\":\"OB4PCxLD\",\"ai_deeplearning_计算机视觉_ssd.md\":\"DASu9AZu\",\"ai_deeplearning_计算机视觉_transposed-conv.md\":\"C6fgyeir\",\"ai_deeplearning_预备知识_autograd.md\":\"DpX39Wgm\",\"ai_deeplearning_预备知识_calculus.md\":\"v2AaC9i7\",\"ai_deeplearning_预备知识_index.md\":\"_Px1u1i3\",\"ai_deeplearning_预备知识_linear-algebra.md\":\"DC1OJtqY\",\"ai_deeplearning_预备知识_lookup-api.md\":\"BRkY9gmG\",\"ai_deeplearning_预备知识_ndarray.md\":\"DHq3nQlq\",\"ai_deeplearning_预备知识_pandas.md\":\"DOVe31Bf\",\"ai_deeplearning_预备知识_probability.md\":\"YTIOv30Y\",\"ai_index.md\":\"DOPGjfjG\",\"ai_llm_agent_1.agent.md\":\"CrlDhfo9\",\"ai_llm_agent_2.langchain笔记.md\":\"D2A4O2f0\",\"ai_llm_agent_3.mcp通信协议.md\":\"Dz4yRpL2\",\"ai_llm_agent_index.md\":\"fWuxlY9H\",\"ai_machinelearning_1.引言、单变量线性回归、线性代数.md\":\"DDpp5nIJ\",\"ai_machinelearning_2.多变量线性回归.md\":\"uzezgaI7\",\"ai_machinelearning_3.逻辑回归、正则化.md\":\"D2kpoxOm\",\"ai_machinelearning_4.神经网络、表述.md\":\"X21Smzeq\",\"ai_machinelearning_5.神经网络的学习.md\":\"Btumg1kO\",\"ai_machinelearning_6.学习建议、系统设计.md\":\"BAYUeReB\",\"ai_machinelearning_7.支持向量机.md\":\"D1R1EwXE\",\"ai_machinelearning_8.聚类、降维.md\":\"DCr9bmQy\",\"ai_machinelearning_9.异常检测、推荐系统.md\":\"67xR7oSY\",\"ai_machinelearning_index.md\":\"CbXanNIl\",\"ai_machinelearning_x.大规模机器学习、photo ocr、总结.md\":\"CRUaYBxX\",\"ai_nlp_index.md\":\"DtDDdvcr\",\"ai_pytorch_index.md\":\"6-4QCIFF\",\"ai_tensorflow_index.md\":\"HOKilSya\",\"backend_index.md\":\"CEctC5L4\",\"backend_java_index.md\":\"CazKlGDo\",\"backend_java_java基础.md\":\"DMa6xugx\",\"backend_java_java进阶.md\":\"CDSfqUNm\",\"backend_java_springai.md\":\"5a-2bP2F\",\"backend_java_springboot.md\":\"DZHVzcrG\",\"backend_java_ssm.md\":\"DM1zDzaz\",\"backend_mq_index.md\":\"qgA3hTF7\",\"backend_mq_kafka从入门到放弃.md\":\"Bze7obHo\",\"backend_nosql_index.md\":\"BmRYMDqX\",\"backend_nosql_mongodb技术解析.md\":\"ynish4Yb\",\"backend_python_1.python基础语法.md\":\"D9PhWN-G\",\"backend_python_2.python进阶.md\":\"BIApkA_M\",\"backend_python_3.python项目管理.md\":\"CX9Z4t-A\",\"backend_python_fastapi.md\":\"BV5eThXg\",\"backend_python_flask.md\":\"DDK_C5dz\",\"backend_python_index.md\":\"BIJUeAJF\",\"backend_rdbms_index.md\":\"BmA3K-07\",\"backend_rdbms_mysql从入门到放弃.md\":\"CKUnRvWm\",\"backend_rdbms_postgresql从入门到放弃.md\":\"CsMzOOis\",\"devops_ci_cd_github action详解.md\":\"BrEhPNJ2\",\"devops_ci_cd_index.md\":\"D6guWRwM\",\"devops_container_docker基础.md\":\"DjODkd9X\",\"devops_container_index.md\":\"DoeLMiHG\",\"devops_container_k8s简介.md\":\"BzSNVVRs\",\"devops_git_git学习笔记.md\":\"CXTQGvw-\",\"devops_git_index.md\":\"8itI03Kg\",\"devops_server_index.md\":\"DFcoTuBw\",\"devops_server_nginx详解.md\":\"CgEbSze3\",\"examples_api-examples.md\":\"SCsZDAR3\",\"examples_markdown-examples.md\":\"BKK865AB\",\"frontend_css_index.md\":\"DnhtbnvW\",\"frontend_html_1.快速入门.md\":\"BUdSd5xU\",\"frontend_html_2.常用标签.md\":\"DfeIE1mJ\",\"frontend_html_3.盒子布局.md\":\"d0p2bCXf\",\"frontend_html_index.md\":\"Cm5sPgto\",\"frontend_index.md\":\"BHJbtHMQ\",\"frontend_javascript_1.基础语法.md\":\"CIMT0wEE\",\"frontend_javascript_2.进阶.md\":\"B5yiqZzH\",\"frontend_javascript_es6_.md\":\"CwOYB3Or\",\"frontend_javascript_index.md\":\"SDaf0onj\",\"frontend_react_index.md\":\"B0y-AW4Q\",\"frontend_typescript_index.md\":\"BCbUtQZw\",\"frontend_typescript_typescript学习笔记.md\":\"B22rnB3c\",\"frontend_vue_1.vue3简介.md\":\"BTlTyQ2p\",\"frontend_vue_2.创建vue3工程.md\":\"BEH2WCIe\",\"frontend_vue_3.vue3核心语法.md\":\"DozYtE5M\",\"frontend_vue_4.路由.md\":\"B2NaEGKJ\",\"frontend_vue_5.pinia.md\":\"ALyHDZqk\",\"frontend_vue_6.组件通信.md\":\"dUG9ZDJb\",\"frontend_vue_7.其他api.md\":\"CH0YMuXq\",\"frontend_vue_8.vue3新组件.md\":\"CVdac4bT\",\"frontend_vue_index.md\":\"DEVXRaGz\",\"index.md\":\"D-_hIl13\",\"readme.md\":\"Cas71F-D\",\"self-intro.md\":\"C3cE-YH8\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"Drasky's Blog\",\"description\":\"A VitePress Site\",\"base\":\"/MyBlog/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"logo\":\"/IronMan.svg\",\"search\":{\"provider\":\"local\"},\"nav\":[{\"text\":\"主页\",\"link\":\"/\"},{\"text\":\"前端\",\"items\":[{\"text\":\"基础知识\",\"items\":[{\"text\":\"HTML\",\"link\":\"/frontend/HTML/index\"},{\"text\":\"CSS\",\"link\":\"/frontend/CSS/index\"},{\"text\":\"JavaScript\",\"link\":\"/frontend/JavaScript/index\"}]},{\"text\":\"进阶知识\",\"items\":[{\"text\":\"TypeScript\",\"link\":\"/frontend/TypeScript/index\"}]},{\"text\":\"框架技术\",\"items\":[{\"text\":\"Vue\",\"link\":\"/frontend/Vue/index\"},{\"text\":\"React\",\"link\":\"/frontend/React/index\"}]},{\"text\":\"前端工程化\",\"items\":[{\"text\":\"Webpack\",\"link\":\"/frontend/Webpack/index\"},{\"text\":\"Vite\",\"link\":\"/frontend/Vite/index\"}]},{\"text\":\"Awesome\",\"link\":\"/frontend/awesome\"}]},{\"text\":\"后端\",\"items\":[{\"text\":\"基础知识\",\"items\":[{\"text\":\"Java\",\"link\":\"/backend/Java/index\"},{\"text\":\"Python\",\"link\":\"/backend/Python/index\"}]},{\"text\":\"数据库\",\"items\":[{\"text\":\"关系型数据库 (RDBMS)\",\"link\":\"/backend/RDBMS/index\"},{\"text\":\"非关系型数据库 (NoSQL)\",\"link\":\"/backend/NoSQL/index\"}]},{\"text\":\"框架技术\",\"items\":[{\"text\":\"SpringBoot\",\"link\":\"/backend/SpringBoot/index\"},{\"text\":\"Django\",\"link\":\"/backend/Django/index\"}]},{\"text\":\"Awesome\",\"link\":\"/backend/awesome\"}]},{\"text\":\"AI\",\"items\":[{\"text\":\"基础知识\",\"items\":[{\"text\":\"机器学习\",\"link\":\"/ai/MachineLearning/index\"},{\"text\":\"深度学习\",\"link\":\"/ai/DeepLearning/index\"}]},{\"text\":\"框架技术\",\"items\":[{\"text\":\"TensorFlow\",\"link\":\"/ai/TensorFlow/index\"},{\"text\":\"PyTorch\",\"link\":\"/ai/PyTorch/index\"}]},{\"text\":\"进阶知识\",\"items\":[{\"text\":\"NLP\",\"link\":\"/ai/NLP/index\"},{\"text\":\"CV\",\"link\":\"/ai/CV/index\"}]},{\"text\":\"LLM\",\"items\":[{\"text\":\"Agent\",\"link\":\"/ai/LLM/Agent/index\"}]},{\"text\":\"Awesome\",\"link\":\"/ai/awesome\"}]},{\"text\":\"DevOps\",\"items\":[{\"text\":\"开发工具\",\"link\":\"/devops/devtools/index\"},{\"text\":\"Git\",\"link\":\"/devops/Git/index\"},{\"text\":\"CI/CD\",\"link\":\"/devops/CI_CD/index\"},{\"text\":\"容器化\",\"link\":\"/devops/container/index\"},{\"text\":\"监控与日志\",\"link\":\"/devops/mon&log/index\"},{\"text\":\"Web 服务器/反向代理\",\"link\":\"/devops/server/index\"}]}],\"sidebar\":{\"/backend/Python/\":{\"base\":\"/backend/Python/\",\"items\":[{\"text\":\"1.Python基础语法\",\"link\":\"1.Python基础语法\"},{\"text\":\"2.python进阶\",\"link\":\"2.python进阶\"},{\"text\":\"3.Python项目管理\",\"link\":\"3.Python项目管理\"},{\"text\":\"FastAPI\",\"link\":\"FastAPI\"},{\"text\":\"Flask\",\"link\":\"Flask\"}]},\"/backend/Java/\":{\"base\":\"/backend/Java/\",\"items\":[{\"text\":\"Java基础\",\"link\":\"Java基础\"},{\"text\":\"Java进阶\",\"link\":\"Java进阶\"},{\"text\":\"SpringAI\",\"link\":\"SpringAI\"},{\"text\":\"SpringBoot\",\"link\":\"SpringBoot\"},{\"text\":\"ssm\",\"link\":\"ssm\"}]},\"/backend/NoSQL/\":{\"base\":\"/backend/NoSQL/\",\"items\":[{\"text\":\"MongoDB技术解析\",\"link\":\"MongoDB技术解析\"}]},\"/frontend/HTML/\":{\"base\":\"/frontend/HTML/\",\"items\":[{\"text\":\"1.快速入门\",\"link\":\"1.快速入门\"},{\"text\":\"2.常用标签\",\"link\":\"2.常用标签\"},{\"text\":\"3.盒子布局\",\"link\":\"3.盒子布局\"}]},\"/frontend/CSS/\":{\"base\":\"/frontend/CSS/\",\"items\":[]},\"/frontend/JavaScript/\":{\"base\":\"/frontend/JavaScript/\",\"items\":[{\"text\":\"1.基础语法\",\"link\":\"1.基础语法\"},{\"text\":\"2.进阶\",\"link\":\"2.进阶\"},{\"text\":\"ES6+\",\"link\":\"ES6+\"}]},\"/frontend/TypeScript/\":{\"base\":\"/frontend/TypeScript/\",\"items\":[{\"text\":\"TypeScript学习笔记\",\"link\":\"TypeScript学习笔记\"}]},\"/frontend/Vue/\":{\"base\":\"/frontend/Vue/\",\"items\":[{\"text\":\"1.Vue3简介\",\"link\":\"1.Vue3简介\"},{\"text\":\"2.创建Vue3工程\",\"link\":\"2.创建Vue3工程\"},{\"text\":\"3.Vue3核心语法\",\"link\":\"3.Vue3核心语法\"},{\"text\":\"4.路由\",\"link\":\"4.路由\"},{\"text\":\"5.pinia\",\"link\":\"5.pinia\"},{\"text\":\"6.组件通信\",\"link\":\"6.组件通信\"},{\"text\":\"7.其他API\",\"link\":\"7.其他API\"},{\"text\":\"8.Vue3新组件\",\"link\":\"8.Vue3新组件\"}]},\"/ai/MachineLearning/\":{\"base\":\"/ai/MachineLearning/\",\"items\":[{\"text\":\"1.引言、单变量线性回归、线性代数\",\"link\":\"1.引言、单变量线性回归、线性代数\"},{\"text\":\"2.多变量线性回归\",\"link\":\"2.多变量线性回归\"},{\"text\":\"3.逻辑回归、正则化\",\"link\":\"3.逻辑回归、正则化\"},{\"text\":\"4.神经网络、表述\",\"link\":\"4.神经网络、表述\"},{\"text\":\"5.神经网络的学习\",\"link\":\"5.神经网络的学习\"},{\"text\":\"6.学习建议、系统设计\",\"link\":\"6.学习建议、系统设计\"},{\"text\":\"7.支持向量机\",\"link\":\"7.支持向量机\"},{\"text\":\"8.聚类、降维\",\"link\":\"8.聚类、降维\"},{\"text\":\"9.异常检测、推荐系统\",\"link\":\"9.异常检测、推荐系统\"},{\"text\":\"X.大规模机器学习、Photo OCR、总结\",\"link\":\"X.大规模机器学习、Photo OCR、总结\"}]},\"/ai/DeepLearning/\":{\"base\":\"/ai/DeepLearning/\",\"items\":[{\"text\":\"优化算法\",\"items\":[{\"text\":\"adadelta\",\"link\":\"优化算法/adadelta\"},{\"text\":\"adagrad\",\"link\":\"优化算法/adagrad\"},{\"text\":\"adam\",\"link\":\"优化算法/adam\"},{\"text\":\"convexity\",\"link\":\"优化算法/convexity\"},{\"text\":\"gd\",\"link\":\"优化算法/gd\"},{\"text\":\"lr-scheduler\",\"link\":\"优化算法/lr-scheduler\"},{\"text\":\"minibatch-sgd\",\"link\":\"优化算法/minibatch-sgd\"},{\"text\":\"momentum\",\"link\":\"优化算法/momentum\"},{\"text\":\"optimization-intro\",\"link\":\"优化算法/optimization-intro\"},{\"text\":\"rmsprop\",\"link\":\"优化算法/rmsprop\"},{\"text\":\"sgd\",\"link\":\"优化算法/sgd\"}]},{\"text\":\"卷积神经网络\",\"items\":[{\"text\":\"channels\",\"link\":\"卷积神经网络/channels\"},{\"text\":\"conv-layer\",\"link\":\"卷积神经网络/conv-layer\"},{\"text\":\"lenet\",\"link\":\"卷积神经网络/lenet\"},{\"text\":\"padding-and-strides\",\"link\":\"卷积神经网络/padding-and-strides\"},{\"text\":\"pooling\",\"link\":\"卷积神经网络/pooling\"},{\"text\":\"why-conv\",\"link\":\"卷积神经网络/why-conv\"}]},{\"text\":\"多层感知机\",\"items\":[{\"text\":\"backprop\",\"link\":\"多层感知机/backprop\"},{\"text\":\"dropout\",\"link\":\"多层感知机/dropout\"},{\"text\":\"environment\",\"link\":\"多层感知机/environment\"},{\"text\":\"kaggle-house-price\",\"link\":\"多层感知机/kaggle-house-price\"},{\"text\":\"mlp-concise\",\"link\":\"多层感知机/mlp-concise\"},{\"text\":\"mlp-scratch\",\"link\":\"多层感知机/mlp-scratch\"},{\"text\":\"mlp\",\"link\":\"多层感知机/mlp\"},{\"text\":\"numerical-stability-and-init\",\"link\":\"多层感知机/numerical-stability-and-init\"},{\"text\":\"underfit-overfit\",\"link\":\"多层感知机/underfit-overfit\"},{\"text\":\"weight-decay\",\"link\":\"多层感知机/weight-decay\"}]},{\"text\":\"引言\",\"link\":\"引言\"},{\"text\":\"循环神经网络\",\"items\":[{\"text\":\"bptt\",\"link\":\"循环神经网络/bptt\"},{\"text\":\"language-models-and-dataset\",\"link\":\"循环神经网络/language-models-and-dataset\"},{\"text\":\"rnn-concise\",\"link\":\"循环神经网络/rnn-concise\"},{\"text\":\"rnn-scratch\",\"link\":\"循环神经网络/rnn-scratch\"},{\"text\":\"rnn\",\"link\":\"循环神经网络/rnn\"},{\"text\":\"sequence\",\"link\":\"循环神经网络/sequence\"},{\"text\":\"text-preprocessing\",\"link\":\"循环神经网络/text-preprocessing\"}]},{\"text\":\"注意力机制\",\"items\":[{\"text\":\"attention-cues\",\"link\":\"注意力机制/attention-cues\"},{\"text\":\"attention-scoring-functions\",\"link\":\"注意力机制/attention-scoring-functions\"},{\"text\":\"bahdanau-attention\",\"link\":\"注意力机制/bahdanau-attention\"},{\"text\":\"multihead-attention\",\"link\":\"注意力机制/multihead-attention\"},{\"text\":\"nadaraya-waston\",\"link\":\"注意力机制/nadaraya-waston\"},{\"text\":\"self-attention-and-positional-encoding\",\"link\":\"注意力机制/self-attention-and-positional-encoding\"},{\"text\":\"transformer\",\"link\":\"注意力机制/transformer\"}]},{\"text\":\"深度学习计算\",\"items\":[{\"text\":\"custom-layer\",\"link\":\"深度学习计算/custom-layer\"},{\"text\":\"deferred-init\",\"link\":\"深度学习计算/deferred-init\"},{\"text\":\"model-construction\",\"link\":\"深度学习计算/model-construction\"},{\"text\":\"parameters\",\"link\":\"深度学习计算/parameters\"},{\"text\":\"read-write\",\"link\":\"深度学习计算/read-write\"},{\"text\":\"use-gpu\",\"link\":\"深度学习计算/use-gpu\"}]},{\"text\":\"现代卷积神经网络\",\"items\":[{\"text\":\"alexnet\",\"link\":\"现代卷积神经网络/alexnet\"},{\"text\":\"batch-norm\",\"link\":\"现代卷积神经网络/batch-norm\"},{\"text\":\"densenet\",\"link\":\"现代卷积神经网络/densenet\"},{\"text\":\"googlenet\",\"link\":\"现代卷积神经网络/googlenet\"},{\"text\":\"nin\",\"link\":\"现代卷积神经网络/nin\"},{\"text\":\"resnet\",\"link\":\"现代卷积神经网络/resnet\"},{\"text\":\"vgg\",\"link\":\"现代卷积神经网络/vgg\"}]},{\"text\":\"现代循环神经网络\",\"items\":[{\"text\":\"beam-search\",\"link\":\"现代循环神经网络/beam-search\"},{\"text\":\"bi-rnn\",\"link\":\"现代循环神经网络/bi-rnn\"},{\"text\":\"deep-rnn\",\"link\":\"现代循环神经网络/deep-rnn\"},{\"text\":\"encoder-decoder\",\"link\":\"现代循环神经网络/encoder-decoder\"},{\"text\":\"gru\",\"link\":\"现代循环神经网络/gru\"},{\"text\":\"lstm\",\"link\":\"现代循环神经网络/lstm\"},{\"text\":\"machine-translation-and-dataset\",\"link\":\"现代循环神经网络/machine-translation-and-dataset\"},{\"text\":\"seq2seq\",\"link\":\"现代循环神经网络/seq2seq\"}]},{\"text\":\"线性神经网络\",\"items\":[{\"text\":\"image-classification-dataset\",\"link\":\"线性神经网络/image-classification-dataset\"},{\"text\":\"linear-regression-concise\",\"link\":\"线性神经网络/linear-regression-concise\"},{\"text\":\"linear-regression-scratch\",\"link\":\"线性神经网络/linear-regression-scratch\"},{\"text\":\"linear-regression\",\"link\":\"线性神经网络/linear-regression\"},{\"text\":\"softmax-regression-concise\",\"link\":\"线性神经网络/softmax-regression-concise\"},{\"text\":\"softmax-regression-scratch\",\"link\":\"线性神经网络/softmax-regression-scratch\"},{\"text\":\"softmax-regression\",\"link\":\"线性神经网络/softmax-regression\"}]},{\"text\":\"自然语言处理：应用\",\"items\":[{\"text\":\"finetuning-bert\",\"link\":\"自然语言处理：应用/finetuning-bert\"},{\"text\":\"natural-language-inference-and-dataset\",\"link\":\"自然语言处理：应用/natural-language-inference-and-dataset\"},{\"text\":\"natural-language-inference-attention\",\"link\":\"自然语言处理：应用/natural-language-inference-attention\"},{\"text\":\"natural-language-inference-bert\",\"link\":\"自然语言处理：应用/natural-language-inference-bert\"},{\"text\":\"sentiment-analysis-and-dataset\",\"link\":\"自然语言处理：应用/sentiment-analysis-and-dataset\"},{\"text\":\"sentiment-analysis-cnn\",\"link\":\"自然语言处理：应用/sentiment-analysis-cnn\"},{\"text\":\"sentiment-analysis-rnn\",\"link\":\"自然语言处理：应用/sentiment-analysis-rnn\"}]},{\"text\":\"自然语言处理：预训练\",\"items\":[{\"text\":\"approx-training\",\"link\":\"自然语言处理：预训练/approx-training\"},{\"text\":\"bert-dataset\",\"link\":\"自然语言处理：预训练/bert-dataset\"},{\"text\":\"bert-pretraining\",\"link\":\"自然语言处理：预训练/bert-pretraining\"},{\"text\":\"bert\",\"link\":\"自然语言处理：预训练/bert\"},{\"text\":\"glove\",\"link\":\"自然语言处理：预训练/glove\"},{\"text\":\"similarity-analogy\",\"link\":\"自然语言处理：预训练/similarity-analogy\"},{\"text\":\"subword-embedding\",\"link\":\"自然语言处理：预训练/subword-embedding\"},{\"text\":\"word-embedding-dataset\",\"link\":\"自然语言处理：预训练/word-embedding-dataset\"},{\"text\":\"word2vec-pretraining\",\"link\":\"自然语言处理：预训练/word2vec-pretraining\"},{\"text\":\"word2vec\",\"link\":\"自然语言处理：预训练/word2vec\"}]},{\"text\":\"计算性能\",\"items\":[{\"text\":\"async-computation\",\"link\":\"计算性能/async-computation\"},{\"text\":\"auto-parallelism\",\"link\":\"计算性能/auto-parallelism\"},{\"text\":\"hardware\",\"link\":\"计算性能/hardware\"},{\"text\":\"hybridize\",\"link\":\"计算性能/hybridize\"},{\"text\":\"multiple-gpus-concise\",\"link\":\"计算性能/multiple-gpus-concise\"},{\"text\":\"multiple-gpus\",\"link\":\"计算性能/multiple-gpus\"},{\"text\":\"parameterserver\",\"link\":\"计算性能/parameterserver\"}]},{\"text\":\"计算机视觉\",\"items\":[{\"text\":\"anchor\",\"link\":\"计算机视觉/anchor\"},{\"text\":\"bounding-box\",\"link\":\"计算机视觉/bounding-box\"},{\"text\":\"fcn\",\"link\":\"计算机视觉/fcn\"},{\"text\":\"fine-tuning\",\"link\":\"计算机视觉/fine-tuning\"},{\"text\":\"image-augmentation\",\"link\":\"计算机视觉/image-augmentation\"},{\"text\":\"kaggle-cifar10\",\"link\":\"计算机视觉/kaggle-cifar10\"},{\"text\":\"kaggle-dog\",\"link\":\"计算机视觉/kaggle-dog\"},{\"text\":\"multiscale-object-detection\",\"link\":\"计算机视觉/multiscale-object-detection\"},{\"text\":\"neural-style\",\"link\":\"计算机视觉/neural-style\"},{\"text\":\"object-detection-dataset\",\"link\":\"计算机视觉/object-detection-dataset\"},{\"text\":\"rcnn\",\"link\":\"计算机视觉/rcnn\"},{\"text\":\"semantic-segmentation-and-dataset\",\"link\":\"计算机视觉/semantic-segmentation-and-dataset\"},{\"text\":\"ssd\",\"link\":\"计算机视觉/ssd\"},{\"text\":\"transposed-conv\",\"link\":\"计算机视觉/transposed-conv\"}]},{\"text\":\"预备知识\",\"items\":[{\"text\":\"autograd\",\"link\":\"预备知识/autograd\"},{\"text\":\"calculus\",\"link\":\"预备知识/calculus\"},{\"text\":\"linear-algebra\",\"link\":\"预备知识/linear-algebra\"},{\"text\":\"lookup-api\",\"link\":\"预备知识/lookup-api\"},{\"text\":\"ndarray\",\"link\":\"预备知识/ndarray\"},{\"text\":\"pandas\",\"link\":\"预备知识/pandas\"},{\"text\":\"probability\",\"link\":\"预备知识/probability\"}]}]},\"/ai/LLM/Agent/\":{\"base\":\"/ai/LLM/Agent/\",\"items\":[{\"text\":\"1.agent\",\"link\":\"1.agent\"},{\"text\":\"2.langchain笔记\",\"link\":\"2.langchain笔记\"},{\"text\":\"3.MCP通信协议\",\"link\":\"3.MCP通信协议\"}]},\"/devops/Git/\":{\"base\":\"/devops/Git/\",\"items\":[{\"text\":\"Git学习笔记\",\"link\":\"Git学习笔记\"}]},\"/devops/CI_CD/\":{\"base\":\"/devops/CI_CD/\",\"items\":[{\"text\":\"GitHub Action详解\",\"link\":\"GitHub Action详解\"}]},\"/devops/server/\":{\"base\":\"/devops/server/\",\"items\":[{\"text\":\"Nginx详解\",\"link\":\"Nginx详解\"}]},\"/devops/container/\":{\"base\":\"/devops/container/\",\"items\":[{\"text\":\"docker基础\",\"link\":\"docker基础\"},{\"text\":\"k8s简介\",\"link\":\"k8s简介\"}]},\"/Examples/\":{\"base\":\"/Examples/\",\"items\":[{\"text\":\"api-examples\",\"link\":\"api-examples\"},{\"text\":\"markdown-examples\",\"link\":\"markdown-examples\"}]}},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/DraskyChen\"}],\"footer\":{\"copyright\":\"Copyright © 2025-present Drasky Chen\"}},\"locales\":{\"root\":{\"label\":\"简体中文\",\"lang\":\"zh-CN\"},\"en-US\":{\"label\":\"English\",\"lang\":\"en-US\"}},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>