<!DOCTYPE html>
<html lang="zh-CN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>深度卷积神经网络（AlexNet） | Drasky's Blog</title>
    <meta name="description" content="A VitePress Site">
    <meta name="generator" content="VitePress v1.6.4">
    <link rel="preload stylesheet" href="/MyBlog/assets/style.yzDaPA9-.css" as="style">
    <link rel="preload stylesheet" href="/MyBlog/vp-icons.css" as="style">
    
    <script type="module" src="/MyBlog/assets/app.D4-0N0H9.js"></script>
    <link rel="preload" href="/MyBlog/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/MyBlog/assets/chunks/theme.CapJMVUD.js">
    <link rel="modulepreload" href="/MyBlog/assets/chunks/framework.C2Gjomh7.js">
    <link rel="modulepreload" href="/MyBlog/assets/ai_DeepLearning_现代卷积神经网络_alexnet.md.BhHdW3Hf.lean.js">
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-5R3J1LLHED"></script>
    <script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-5R3J1LLHED");</script>
    <link rel="icon" href="./IronMan.svg">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-d8b57b2d><!--[--><!--]--><!--[--><span tabindex="-1" data-v-fcbfc0e0></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-fcbfc0e0>Skip to content</a><!--]--><!----><header class="VPNav" data-v-d8b57b2d data-v-7ad780c2><div class="VPNavBar" data-v-7ad780c2 data-v-9fd4d1dd><div class="wrapper" data-v-9fd4d1dd><div class="container" data-v-9fd4d1dd><div class="title" data-v-9fd4d1dd><div class="VPNavBarTitle has-sidebar" data-v-9fd4d1dd data-v-9f43907a><a class="title" href="/MyBlog/" data-v-9f43907a><!--[--><!--]--><!--[--><img class="VPImage logo" src="/MyBlog/IronMan.svg" alt data-v-ab19afbb><!--]--><span data-v-9f43907a>Drasky&#39;s Blog</span><!--[--><!--]--></a></div></div><div class="content" data-v-9fd4d1dd><div class="content-body" data-v-9fd4d1dd><!--[--><!--]--><div class="VPNavBarSearch search" data-v-9fd4d1dd><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-9fd4d1dd data-v-afb2845e><span id="main-nav-aria-label" class="visually-hidden" data-v-afb2845e> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/MyBlog/" tabindex="0" data-v-afb2845e data-v-815115f5><!--[--><span data-v-815115f5>主页</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-afb2845e data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-bfe7971f><span class="text" data-v-bfe7971f><!----><span data-v-bfe7971f>前端</span><span class="vpi-chevron-down text-icon" data-v-bfe7971f></span></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><div class="items" data-v-20ed86d6><!--[--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>基础知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/frontend/HTML/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>HTML</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/frontend/CSS/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>CSS</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/frontend/JavaScript/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>JavaScript</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>进阶知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/frontend/TypeScript/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>TypeScript</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>框架技术</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/frontend/Vue/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Vue</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/frontend/React/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>React</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>前端工程化</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/frontend/Webpack/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Webpack</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/frontend/Vite/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Vite</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuLink" data-v-20ed86d6 data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/frontend/awesome.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Awesome</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-afb2845e data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-bfe7971f><span class="text" data-v-bfe7971f><!----><span data-v-bfe7971f>后端</span><span class="vpi-chevron-down text-icon" data-v-bfe7971f></span></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><div class="items" data-v-20ed86d6><!--[--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>基础知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/backend/Java/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Java</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/backend/Python/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Python</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>数据库</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/backend/RDBMS/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>关系型数据库 (RDBMS)</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/backend/NoSQL/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>非关系型数据库 (NoSQL)</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>框架技术</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/backend/SpringBoot/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>SpringBoot</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/backend/Django/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Django</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuLink" data-v-20ed86d6 data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/backend/awesome.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Awesome</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-afb2845e data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-bfe7971f><span class="text" data-v-bfe7971f><!----><span data-v-bfe7971f>AI</span><span class="vpi-chevron-down text-icon" data-v-bfe7971f></span></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><div class="items" data-v-20ed86d6><!--[--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>基础知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/ai/MachineLearning/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>机器学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/ai/DeepLearning/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>深度学习</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>框架技术</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/ai/TensorFlow/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>TensorFlow</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/ai/PyTorch/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>PyTorch</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>进阶知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/ai/NLP/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>NLP</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/ai/CV/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>CV</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-20ed86d6 data-v-a6b0397c><p class="title" data-v-a6b0397c>LLM</p><!--[--><!--[--><div class="VPMenuLink" data-v-a6b0397c data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/ai/LLM/Agent/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Agent</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuLink" data-v-20ed86d6 data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/ai/awesome.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Awesome</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-afb2845e data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-bfe7971f><span class="text" data-v-bfe7971f><!----><span data-v-bfe7971f>DevOps</span><span class="vpi-chevron-down text-icon" data-v-bfe7971f></span></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><div class="items" data-v-20ed86d6><!--[--><!--[--><div class="VPMenuLink" data-v-20ed86d6 data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/devops/devtools/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>开发工具</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-20ed86d6 data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/devops/Git/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Git</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-20ed86d6 data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/devops/CI_CD/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>CI/CD</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-20ed86d6 data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/devops/container/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>容器化</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-20ed86d6 data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/devops/mon&amp;log/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>监控与日志</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-20ed86d6 data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/devops/server/index.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>Web 服务器/反向代理</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><div class="VPFlyout VPNavBarTranslations translations" data-v-9fd4d1dd data-v-acee064b data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="Change language" data-v-bfe7971f><span class="text" data-v-bfe7971f><span class="vpi-languages option-icon" data-v-bfe7971f></span><!----><span class="vpi-chevron-down text-icon" data-v-bfe7971f></span></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><!----><!--[--><!--[--><div class="items" data-v-acee064b><p class="title" data-v-acee064b>简体中文</p><!--[--><div class="VPMenuLink" data-v-acee064b data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/en-US/ai/DeepLearning/现代卷积神经网络/alexnet.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>English</span><!--]--></a></div><!--]--></div><!--]--><!--]--></div></div></div><div class="VPNavBarAppearance appearance" data-v-9fd4d1dd data-v-3f90c1a5><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-3f90c1a5 data-v-be9742d9 data-v-b4ccac88><span class="check" data-v-b4ccac88><span class="icon" data-v-b4ccac88><!--[--><span class="vpi-sun sun" data-v-be9742d9></span><span class="vpi-moon moon" data-v-be9742d9></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-9fd4d1dd data-v-ef6192dc data-v-e71e869c><!--[--><a class="VPSocialLink no-icon" href="https://github.com/DraskyChen" aria-label="github" target="_blank" rel="noopener" data-v-e71e869c data-v-60a9a2d3><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-9fd4d1dd data-v-f953d92f data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-bfe7971f><span class="vpi-more-horizontal icon" data-v-bfe7971f></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><!----><!--[--><!--[--><div class="group translations" data-v-f953d92f><p class="trans-title" data-v-f953d92f>简体中文</p><!--[--><div class="VPMenuLink" data-v-f953d92f data-v-7eeeb2dc><a class="VPLink link" href="/MyBlog/en-US/ai/DeepLearning/现代卷积神经网络/alexnet.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>English</span><!--]--></a></div><!--]--></div><div class="group" data-v-f953d92f><div class="item appearance" data-v-f953d92f><p class="label" data-v-f953d92f>Appearance</p><div class="appearance-action" data-v-f953d92f><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-f953d92f data-v-be9742d9 data-v-b4ccac88><span class="check" data-v-b4ccac88><span class="icon" data-v-b4ccac88><!--[--><span class="vpi-sun sun" data-v-be9742d9></span><span class="vpi-moon moon" data-v-be9742d9></span><!--]--></span></span></button></div></div></div><div class="group" data-v-f953d92f><div class="item social-links" data-v-f953d92f><div class="VPSocialLinks social-links-list" data-v-f953d92f data-v-e71e869c><!--[--><a class="VPSocialLink no-icon" href="https://github.com/DraskyChen" aria-label="github" target="_blank" rel="noopener" data-v-e71e869c data-v-60a9a2d3><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-9fd4d1dd data-v-6bee1efd><span class="container" data-v-6bee1efd><span class="top" data-v-6bee1efd></span><span class="middle" data-v-6bee1efd></span><span class="bottom" data-v-6bee1efd></span></span></button></div></div></div></div><div class="divider" data-v-9fd4d1dd><div class="divider-line" data-v-9fd4d1dd></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-d8b57b2d data-v-2488c25a><div class="container" data-v-2488c25a><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-2488c25a><span class="vpi-align-left menu-icon" data-v-2488c25a></span><span class="menu-text" data-v-2488c25a>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-2488c25a data-v-6b867909><button data-v-6b867909>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-d8b57b2d data-v-42c4c606><div class="curtain" data-v-42c4c606></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-42c4c606><span class="visually-hidden" id="sidebar-aria-label" data-v-42c4c606> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>优化算法</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/adadelta.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>adadelta</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/adagrad.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>adagrad</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/adam.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>adam</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/convexity.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>convexity</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/gd.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>gd</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/lr-scheduler.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>lr-scheduler</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/minibatch-sgd.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>minibatch-sgd</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/momentum.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>momentum</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/optimization-intro.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>optimization-intro</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/rmsprop.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>rmsprop</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/sgd.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>sgd</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>卷积神经网络</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/channels.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>channels</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/conv-layer.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>conv-layer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/lenet.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>lenet</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/padding-and-strides.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>padding-and-strides</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/pooling.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>pooling</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/why-conv.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>why-conv</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>多层感知机</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/backprop.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>backprop</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/dropout.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>dropout</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/environment.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>environment</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/kaggle-house-price.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>kaggle-house-price</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/mlp-concise.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>mlp-concise</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/mlp-scratch.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>mlp-scratch</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/mlp.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>mlp</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/numerical-stability-and-init.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>numerical-stability-and-init</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/underfit-overfit.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>underfit-overfit</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/weight-decay.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>weight-decay</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><!----><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%BC%95%E8%A8%80.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>引言</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>循环神经网络</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/bptt.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>bptt</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/language-models-and-dataset.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>language-models-and-dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/rnn-concise.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>rnn-concise</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/rnn-scratch.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>rnn-scratch</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/rnn.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>rnn</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/sequence.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>sequence</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/text-preprocessing.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>text-preprocessing</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>注意力机制</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/attention-cues.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>attention-cues</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/attention-scoring-functions.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>attention-scoring-functions</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/bahdanau-attention.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>bahdanau-attention</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/multihead-attention.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>multihead-attention</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/nadaraya-waston.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>nadaraya-waston</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/self-attention-and-positional-encoding.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>self-attention-and-positional-encoding</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/transformer.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>transformer</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>深度学习计算</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/custom-layer.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>custom-layer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/deferred-init.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>deferred-init</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/model-construction.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>model-construction</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/parameters.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>parameters</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/read-write.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>read-write</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/use-gpu.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>use-gpu</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0 has-active" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>现代卷积神经网络</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/alexnet.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>alexnet</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/batch-norm.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>batch-norm</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/densenet.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>densenet</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/googlenet.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>googlenet</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/nin.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>nin</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/resnet.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>resnet</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/vgg.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>vgg</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>现代循环神经网络</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/beam-search.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>beam-search</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/bi-rnn.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>bi-rnn</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/deep-rnn.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>deep-rnn</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/encoder-decoder.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>encoder-decoder</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/gru.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>gru</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/lstm.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>lstm</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/machine-translation-and-dataset.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>machine-translation-and-dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/seq2seq.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>seq2seq</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>线性神经网络</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-classification-dataset.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>image-classification-dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/linear-regression-concise.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>linear-regression-concise</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/linear-regression-scratch.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>linear-regression-scratch</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/linear-regression.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>linear-regression</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/softmax-regression-concise.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>softmax-regression-concise</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/softmax-regression-scratch.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>softmax-regression-scratch</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/softmax-regression.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>softmax-regression</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>自然语言处理：应用</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E5%BA%94%E7%94%A8/finetuning-bert.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>finetuning-bert</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E5%BA%94%E7%94%A8/natural-language-inference-and-dataset.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>natural-language-inference-and-dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E5%BA%94%E7%94%A8/natural-language-inference-attention.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>natural-language-inference-attention</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E5%BA%94%E7%94%A8/natural-language-inference-bert.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>natural-language-inference-bert</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E5%BA%94%E7%94%A8/sentiment-analysis-and-dataset.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>sentiment-analysis-and-dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E5%BA%94%E7%94%A8/sentiment-analysis-cnn.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>sentiment-analysis-cnn</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E5%BA%94%E7%94%A8/sentiment-analysis-rnn.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>sentiment-analysis-rnn</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>自然语言处理：预训练</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/approx-training.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>approx-training</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/bert-dataset.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>bert-dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/bert-pretraining.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>bert-pretraining</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/bert.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>bert</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/glove.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>glove</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/similarity-analogy.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>similarity-analogy</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/subword-embedding.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>subword-embedding</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/word-embedding-dataset.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>word-embedding-dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/word2vec-pretraining.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>word2vec-pretraining</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E8%AE%AD%E7%BB%83/word2vec.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>word2vec</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>计算性能</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%80%A7%E8%83%BD/async-computation.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>async-computation</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%80%A7%E8%83%BD/auto-parallelism.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>auto-parallelism</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%80%A7%E8%83%BD/hardware.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>hardware</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%80%A7%E8%83%BD/hybridize.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>hybridize</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%80%A7%E8%83%BD/multiple-gpus-concise.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>multiple-gpus-concise</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%80%A7%E8%83%BD/multiple-gpus.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>multiple-gpus</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%80%A7%E8%83%BD/parameterserver.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>parameterserver</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>计算机视觉</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/anchor.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>anchor</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/bounding-box.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>bounding-box</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/fcn.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>fcn</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/fine-tuning.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>fine-tuning</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/image-augmentation.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>image-augmentation</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/kaggle-cifar10.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>kaggle-cifar10</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/kaggle-dog.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>kaggle-dog</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/multiscale-object-detection.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>multiscale-object-detection</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/neural-style.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>neural-style</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/object-detection-dataset.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>object-detection-dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/rcnn.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>rcnn</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/semantic-segmentation-and-dataset.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>semantic-segmentation-and-dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/ssd.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>ssd</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/transposed-conv.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>transposed-conv</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>预备知识</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/autograd.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>autograd</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/calculus.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>calculus</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/linear-algebra.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>linear-algebra</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/lookup-api.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>lookup-api</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/ndarray.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>ndarray</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/pandas.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>pandas</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/MyBlog/ai/DeepLearning/%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/probability.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>probability</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-d8b57b2d data-v-9a6c75ad><div class="VPDoc has-sidebar has-aside" data-v-9a6c75ad data-v-e6f2a212><!--[--><!--]--><div class="container" data-v-e6f2a212><div class="aside" data-v-e6f2a212><div class="aside-curtain" data-v-e6f2a212></div><div class="aside-container" data-v-e6f2a212><div class="aside-content" data-v-e6f2a212><div class="VPDocAside" data-v-e6f2a212 data-v-cb998dce><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-cb998dce data-v-f610f197><div class="content" data-v-f610f197><div class="outline-marker" data-v-f610f197></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-f610f197>On this page</div><ul class="VPDocOutlineItem root" data-v-f610f197 data-v-53c99d69><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-cb998dce></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-e6f2a212><div class="content-container" data-v-e6f2a212><!--[--><!--]--><main class="main" data-v-e6f2a212><div style="position:relative;" class="vp-doc _MyBlog_ai_DeepLearning_%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C_alexnet" data-v-e6f2a212><div><h1 id="深度卷积神经网络-alexnet" tabindex="-1">深度卷积神经网络（AlexNet） <a class="header-anchor" href="#深度卷积神经网络-alexnet" aria-label="Permalink to &quot;深度卷积神经网络（AlexNet）&quot;">​</a></h1><p>🏷️<code>sec_alexnet</code></p><p>在LeNet提出后，卷积神经网络在计算机视觉和机器学习领域中很有名气。但卷积神经网络并没有主导这些领域。这是因为虽然LeNet在小数据集上取得了很好的效果，但是在更大、更真实的数据集上训练卷积神经网络的性能和可行性还有待研究。事实上，在上世纪90年代初到2012年之间的大部分时间里，神经网络往往被其他机器学习方法超越，如支持向量机（support vector machines）。</p><p>在计算机视觉中，直接将神经网络与其他机器学习方法进行比较也许不公平。这是因为，卷积神经网络的输入是由原始像素值或是经过简单预处理（例如居中、缩放）的像素值组成的。但在使用传统机器学习方法时，从业者永远不会将原始像素作为输入。在传统机器学习方法中，计算机视觉流水线是由经过人的手工精心设计的特征流水线组成的。对于这些传统方法，大部分的进展都来自于对特征有了更聪明的想法，并且学习到的算法往往归于事后的解释。</p><p>虽然上世纪90年代就有了一些神经网络加速卡，但仅靠它们还不足以开发出有大量参数的深层多通道多层卷积神经网络。此外，当时的数据集仍然相对较小。除了这些障碍，训练神经网络的一些关键技巧仍然缺失，包括启发式参数初始化、随机梯度下降的变体、非挤压激活函数和有效的正则化技术。</p><p>因此，与训练<em>端到端</em>（从像素到分类结果）系统不同，经典机器学习的流水线看起来更像下面这样：</p><ol><li>获取一个有趣的数据集。在早期，收集这些数据集需要昂贵的传感器（在当时最先进的图像也就100万像素）。</li><li>根据光学、几何学、其他知识以及偶然的发现，手工对特征数据集进行预处理。</li><li>通过标准的特征提取算法，如SIFT（尺度不变特征变换） :cite:<code>Lowe.2004</code>和SURF（加速鲁棒特征） :cite:<code>Bay.Tuytelaars.Van-Gool.2006</code>或其他手动调整的流水线来输入数据。</li><li>将提取的特征送入最喜欢的分类器中（例如线性模型或其它核方法），以训练分类器。</li></ol><p>当人们和机器学习研究人员交谈时，会发现机器学习研究人员相信机器学习既重要又美丽：优雅的理论去证明各种模型的性质。机器学习是一个正在蓬勃发展、严谨且非常有用的领域。然而，当人们和计算机视觉研究人员交谈，会听到一个完全不同的故事。计算机视觉研究人员会告诉一个诡异事实————推动领域进步的是数据特征，而不是学习算法。计算机视觉研究人员相信，从对最终模型精度的影响来说，更大或更干净的数据集、或是稍微改进的特征提取，比任何学习算法带来的进步要大得多。</p><h2 id="学习表征" tabindex="-1">学习表征 <a class="header-anchor" href="#学习表征" aria-label="Permalink to &quot;学习表征&quot;">​</a></h2><p>另一种预测这个领域发展的方法————观察图像特征的提取方法。在2012年前，图像特征都是机械地计算出来的。事实上，设计一套新的特征函数、改进结果，并撰写论文是盛极一时的潮流。SIFT :cite:<code>Lowe.2004</code>、SURF :cite:<code>Bay.Tuytelaars.Van-Gool.2006</code>、HOG（定向梯度直方图） :cite:<code>Dalal.Triggs.2005</code>、<a href="https://en.wikipedia.org/wiki/Bag-of-words_model_in_computer_vision" target="_blank" rel="noreferrer">bags of visual words</a>和类似的特征提取方法占据了主导地位。</p><p>另一组研究人员，包括Yann LeCun、Geoff Hinton、Yoshua Bengio、Andrew Ng、Shun ichi Amari和Juergen Schmidhuber，想法则与众不同：他们认为特征本身应该被学习。此外，他们还认为，在合理地复杂性前提下，特征应该由多个共同学习的神经网络层组成，每个层都有可学习的参数。在机器视觉中，最底层可能检测边缘、颜色和纹理。事实上，Alex Krizhevsky、Ilya Sutskever和Geoff Hinton提出了一种新的卷积神经网络变体<em>AlexNet</em>。在2012年ImageNet挑战赛中取得了轰动一时的成绩。AlexNet以Alex Krizhevsky的名字命名，他是论文 :cite:<code>Krizhevsky.Sutskever.Hinton.2012</code>的第一作者。</p><p>有趣的是，在网络的最底层，模型学习到了一些类似于传统滤波器的特征抽取器。 :numref:<code>fig_filters</code>是从AlexNet论文 :cite:<code>Krizhevsky.Sutskever.Hinton.2012</code>复制的，描述了底层图像特征。</p><p><img src="/MyBlog/assets/filters.DLjnf6TJ.png" alt="AlexNet第一层学习到的特征抽取器。"> :width:<code>400px</code> 🏷️<code>fig_filters</code></p><p>AlexNet的更高层建立在这些底层表示的基础上，以表示更大的特征，如眼睛、鼻子、草叶等等。而更高的层可以检测整个物体，如人、飞机、狗或飞盘。最终的隐藏神经元可以学习图像的综合表示，从而使属于不同类别的数据易于区分。尽管一直有一群执着的研究者不断钻研，试图学习视觉数据的逐级表征，然而很长一段时间里这些尝试都未有突破。深度卷积神经网络的突破出现在2012年。突破可归因于两个关键因素。</p><h3 id="缺少的成分-数据" tabindex="-1">缺少的成分：数据 <a class="header-anchor" href="#缺少的成分-数据" aria-label="Permalink to &quot;缺少的成分：数据&quot;">​</a></h3><p>包含许多特征的深度模型需要大量的有标签数据，才能显著优于基于凸优化的传统方法（如线性方法和核方法）。 然而，限于早期计算机有限的存储和90年代有限的研究预算，大部分研究只基于小的公开数据集。例如，不少研究论文基于加州大学欧文分校（UCI）提供的若干个公开数据集，其中许多数据集只有几百至几千张在非自然环境下以低分辨率拍摄的图像。这一状况在2010年前后兴起的大数据浪潮中得到改善。2009年，ImageNet数据集发布，并发起ImageNet挑战赛：要求研究人员从100万个样本中训练模型，以区分1000个不同类别的对象。ImageNet数据集由斯坦福教授李飞飞小组的研究人员开发，利用谷歌图像搜索（Google Image Search）对每一类图像进行预筛选，并利用亚马逊众包（Amazon Mechanical Turk）来标注每张图片的相关类别。这种规模是前所未有的。这项被称为ImageNet的挑战赛推动了计算机视觉和机器学习研究的发展，挑战研究人员确定哪些模型能够在更大的数据规模下表现最好。</p><h3 id="缺少的成分-硬件" tabindex="-1">缺少的成分：硬件 <a class="header-anchor" href="#缺少的成分-硬件" aria-label="Permalink to &quot;缺少的成分：硬件&quot;">​</a></h3><p>深度学习对计算资源要求很高，训练可能需要数百个迭代轮数，每次迭代都需要通过代价高昂的许多线性代数层传递数据。这也是为什么在20世纪90年代至21世纪初，优化凸目标的简单算法是研究人员的首选。然而，用GPU训练神经网络改变了这一格局。<em>图形处理器</em>（Graphics Processing Unit，GPU）早年用来加速图形处理，使电脑游戏玩家受益。GPU可优化高吞吐量的<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:0;" xmlns="http://www.w3.org/2000/svg" width="5.028ex" height="1.532ex" role="img" focusable="false" viewBox="0 -677 2222.4 677" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1722.4,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>4</mn><mo>×</mo><mn>4</mn></math></mjx-assistive-mml></mjx-container>矩阵和向量乘法，从而服务于基本的图形任务。幸运的是，这些数学运算与卷积层的计算惊人地相似。由此，英伟达（NVIDIA）和ATI已经开始为通用计算操作优化gpu，甚至把它们作为<em>通用GPU</em>（general-purpose GPUs，GPGPU）来销售。</p><p>那么GPU比CPU强在哪里呢？</p><p>首先，我们深度理解一下中央处理器（Central Processing Unit，CPU）的<em>核心</em>。 CPU的每个核心都拥有高时钟频率的运行能力，和高达数MB的三级缓存（L3Cache）。 它们非常适合执行各种指令，具有分支预测器、深层流水线和其他使CPU能够运行各种程序的功能。 然而，这种明显的优势也是它的致命弱点：通用核心的制造成本非常高。 它们需要大量的芯片面积、复杂的支持结构（内存接口、内核之间的缓存逻辑、高速互连等等），而且它们在任何单个任务上的性能都相对较差。 现代笔记本电脑最多有4核，即使是高端服务器也很少超过64核，因为它们的性价比不高。</p><p>相比于CPU，GPU由<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.05ex;" xmlns="http://www.w3.org/2000/svg" width="10.936ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 4833.6 688" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1777.8,0)"><path data-c="223C" d="M55 166Q55 241 101 304T222 367Q260 367 296 349T362 304T421 252T484 208T554 189Q616 189 655 236T694 338Q694 350 698 358T708 367Q722 367 722 334Q722 260 677 197T562 134H554Q517 134 481 152T414 196T355 248T292 293T223 311Q179 311 145 286Q109 257 96 218T80 156T69 133Q55 133 55 166Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(2833.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)" style="stroke-width:3;"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>100</mn><mo>∼</mo><mn>1000</mn></math></mjx-assistive-mml></mjx-container>个小的处理单元组成（NVIDIA、ATI、ARM和其他芯片供应商之间的细节稍有不同），通常被分成更大的组（NVIDIA称之为warps）。 虽然每个GPU核心都相对较弱，有时甚至以低于1GHz的时钟频率运行，但庞大的核心数量使GPU比CPU快几个数量级。 例如，NVIDIA最近一代的Ampere GPU架构为每个芯片提供了高达312 TFlops的浮点性能，而CPU的浮点性能到目前为止还没有超过1 TFlops。 之所以有如此大的差距，原因其实很简单：首先，功耗往往会随时钟频率呈二次方增长。 对于一个CPU核心，假设它的运行速度比GPU快4倍，但可以使用16个GPU核代替，那么GPU的综合性能就是CPU的<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.566ex;" xmlns="http://www.w3.org/2000/svg" width="12.57ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 5556 1000" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(500,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1222.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(2222.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(2722.4,0)"><g data-mml-node="mo"><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mn" transform="translate(3222.4,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(4000.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(5056,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>16</mn><mo>×</mo><mn>1</mn><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mn>4</mn><mo>=</mo><mn>4</mn></math></mjx-assistive-mml></mjx-container>倍。 其次，GPU内核要简单得多，这使得它们更节能。 此外，深度学习中的许多操作需要相对较高的内存带宽，而GPU拥有10倍于CPU的带宽。</p><p>回到2012年的重大突破，当Alex Krizhevsky和Ilya Sutskever实现了可以在GPU硬件上运行的深度卷积神经网络时，一个重大突破出现了。他们意识到卷积神经网络中的计算瓶颈：卷积和矩阵乘法，都是可以在硬件上并行化的操作。 于是，他们使用两个显存为3GB的NVIDIA GTX580 GPU实现了快速卷积运算。他们的创新<a href="https://code.google.com/archive/p/cuda-convnet/" target="_blank" rel="noreferrer">cuda-convnet</a>几年来它一直是行业标准，并推动了深度学习热潮。</p><h2 id="alexnet" tabindex="-1">AlexNet <a class="header-anchor" href="#alexnet" aria-label="Permalink to &quot;AlexNet&quot;">​</a></h2><p>2012年，AlexNet横空出世。它首次证明了学习到的特征可以超越手工设计的特征。它一举打破了计算机视觉研究的现状。 AlexNet使用了8层卷积神经网络，并以很大的优势赢得了2012年ImageNet图像识别挑战赛。</p><p>AlexNet和LeNet的架构非常相似，如 :numref:<code>fig_alexnet</code>所示。 注意，本书在这里提供的是一个稍微精简版本的AlexNet，去除了当年需要两个小型GPU同时运算的设计特点。</p><p><img src="/MyBlog/assets/alexnet.CFllqKeE.svg" alt="从LeNet（左）到AlexNet（右）"> 🏷️<code>fig_alexnet</code></p><p>AlexNet和LeNet的设计理念非常相似，但也存在显著差异。</p><ol><li>AlexNet比相对较小的LeNet5要深得多。AlexNet由八层组成：五个卷积层、两个全连接隐藏层和一个全连接输出层。</li><li>AlexNet使用ReLU而不是sigmoid作为其激活函数。</li></ol><p>下面的内容将深入研究AlexNet的细节。</p><h3 id="模型设计" tabindex="-1">模型设计 <a class="header-anchor" href="#模型设计" aria-label="Permalink to &quot;模型设计&quot;">​</a></h3><p>在AlexNet的第一层，卷积窗口的形状是<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:0;" xmlns="http://www.w3.org/2000/svg" width="7.291ex" height="1.507ex" role="img" focusable="false" viewBox="0 -666 3222.4 666" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1222.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(2222.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>11</mn><mo>×</mo><mn>11</mn></math></mjx-assistive-mml></mjx-container>。 由于ImageNet中大多数图像的宽和高比MNIST图像的多10倍以上，因此，需要一个更大的卷积窗口来捕获目标。 第二层中的卷积窗口形状被缩减为<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.05ex;" xmlns="http://www.w3.org/2000/svg" width="5.028ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 2222.4 688" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1722.4,0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>5</mn><mo>×</mo><mn>5</mn></math></mjx-assistive-mml></mjx-container>，然后是<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.05ex;" xmlns="http://www.w3.org/2000/svg" width="5.028ex" height="1.554ex" role="img" focusable="false" viewBox="0 -665 2222.4 687" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1722.4,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>3</mn><mo>×</mo><mn>3</mn></math></mjx-assistive-mml></mjx-container>。 此外，在第一层、第二层和第五层卷积层之后，加入窗口形状为<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.05ex;" xmlns="http://www.w3.org/2000/svg" width="5.028ex" height="1.554ex" role="img" focusable="false" viewBox="0 -665 2222.4 687" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1722.4,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>3</mn><mo>×</mo><mn>3</mn></math></mjx-assistive-mml></mjx-container>、步幅为2的最大汇聚层。 而且，AlexNet的卷积通道数目是LeNet的10倍。</p><p>在最后一个卷积层后有两个全连接层，分别有4096个输出。 这两个巨大的全连接层拥有将近1GB的模型参数。 由于早期GPU显存有限，原版的AlexNet采用了双数据流设计，使得每个GPU只负责存储和计算模型的一半参数。 幸运的是，现在GPU显存相对充裕，所以现在很少需要跨GPU分解模型（因此，本书的AlexNet模型在这方面与原始论文稍有不同）。</p><h3 id="激活函数" tabindex="-1">激活函数 <a class="header-anchor" href="#激活函数" aria-label="Permalink to &quot;激活函数&quot;">​</a></h3><p>此外，AlexNet将sigmoid激活函数改为更简单的ReLU激活函数。 一方面，ReLU激活函数的计算更简单，它不需要如sigmoid激活函数那般复杂的求幂运算。 另一方面，当使用不同的参数初始化方法时，ReLU激活函数使训练模型更加容易。 当sigmoid激活函数的输出非常接近于0或1时，这些区域的梯度几乎为0，因此反向传播无法继续更新一些模型参数。 相反，ReLU激活函数在正区间的梯度总是1。 因此，如果模型参数没有正确初始化，sigmoid函数可能在正区间内得到几乎为0的梯度，从而使模型无法得到有效的训练。</p><h3 id="容量控制和预处理" tabindex="-1">容量控制和预处理 <a class="header-anchor" href="#容量控制和预处理" aria-label="Permalink to &quot;容量控制和预处理&quot;">​</a></h3><p>AlexNet通过暂退法（ :numref:<code>sec_dropout</code>）控制全连接层的模型复杂度，而LeNet只使用了权重衰减。 为了进一步扩充数据，AlexNet在训练时增加了大量的图像增强数据，如翻转、裁切和变色。 这使得模型更健壮，更大的样本量有效地减少了过拟合。 在 :numref:<code>sec_image_augmentation</code>中更详细地讨论数据扩增。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d2l </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> mxnet </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d2l</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> mxnet </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np, npx</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> mxnet.gluon </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">npx.set_np()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net.add(</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 这里使用一个11*11的更大窗口来捕捉对象。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 同时，步幅为4，以减少输出的高度和宽度。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 另外，输出通道的数目远大于LeNet</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Conv2D(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">96</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">11</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">strides</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.MaxPool2D(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">pool_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">strides</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Conv2D(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.MaxPool2D(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">pool_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">strides</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 使用三个连续的卷积层和一个较小的卷积窗口。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 除了最后的卷积层，输出通道的数量进一步增加。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 前两个卷积层后不使用汇聚层来减小输入的高和宽</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Conv2D(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">384</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Conv2D(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">384</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Conv2D(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.MaxPool2D(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">pool_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">strides</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4096</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.Dropout(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4096</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.Dropout(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab pytorch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d2l </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d2l</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential(</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 这里使用一个11*11的更大窗口来捕捉对象。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 同时，步幅为4，以减少输出的高度和宽度。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 另外，输出通道的数目远大于LeNet</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Conv2d(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">96</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">11</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">stride</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.MaxPool2d(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">stride</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Conv2d(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">96</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.MaxPool2d(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">stride</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 使用三个连续的卷积层和较小的卷积窗口。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 除了最后的卷积层，输出通道的数量进一步增加。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Conv2d(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">384</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Conv2d(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">384</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">384</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Conv2d(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">384</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.MaxPool2d(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">stride</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Flatten(),</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">6400</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4096</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Dropout(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">p</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4096</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4096</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Dropout(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">p</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4096</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab tensorflow</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d2l </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorflow </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d2l</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tensorflow </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tf</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> net</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">():</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tf.keras.models.Sequential([</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 这里使用一个11*11的更大窗口来捕捉对象。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 同时，步幅为4，以减少输出的高度和宽度。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 另外，输出通道的数目远大于LeNet</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        tf.keras.layers.Conv2D(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">filters</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">96</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">11</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">strides</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">                               activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        tf.keras.layers.MaxPool2D(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">pool_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">strides</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        tf.keras.layers.Conv2D(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">filters</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;same&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">                               activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        tf.keras.layers.MaxPool2D(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">pool_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">strides</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 使用三个连续的卷积层和较小的卷积窗口。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 除了最后的卷积层，输出通道的数量进一步增加。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        tf.keras.layers.Conv2D(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">filters</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">384</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;same&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">                               activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        tf.keras.layers.Conv2D(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">filters</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">384</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;same&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">                               activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        tf.keras.layers.Conv2D(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">filters</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;same&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">                               activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        tf.keras.layers.MaxPool2D(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">pool_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">strides</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        tf.keras.layers.Flatten(),</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        tf.keras.layers.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4096</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        tf.keras.layers.Dropout(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        tf.keras.layers.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4096</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">activation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;relu&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        tf.keras.layers.Dropout(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        tf.keras.layers.Dense(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ])</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab paddle</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d2l </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> paddle </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d2l</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> warnings</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">warnings.filterwarnings(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;ignore&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> paddle</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> paddle.nn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential(</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 这里，我们使用一个11*11的更大窗口来捕捉对象。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 同时，步幅为4，以减少输出的高度和宽度。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 另外，输出通道的数目远大于LeNet</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Conv2D(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">96</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">11</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">stride</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.MaxPool2D(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">stride</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Conv2D(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">96</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.MaxPool2D(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">stride</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 使用三个连续的卷积层和较小的卷积窗口。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 除了最后的卷积层，输出通道的数量进一步增加。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 在前两个卷积层之后，池化层不用于减少输入的高度和宽度</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Conv2D(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">384</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Conv2D(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">384</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">384</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Conv2D(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">384</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">padding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.MaxPool2D(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">stride</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.Flatten(),</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过度拟合</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">6400</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4096</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU(), nn.Dropout(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">p</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4096</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4096</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), nn.ReLU(), nn.Dropout(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">p</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4096</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>[<strong>我们构造一个</strong>]高度和宽度都为224的(<strong>单通道数据，来观察每一层输出的形状</strong>)。 它与 :numref:<code>fig_alexnet</code>中的AlexNet架构相匹配。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.random.uniform(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">224</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">224</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">net.initialize()</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> layer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> net:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> layer(X)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(layer.name, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;output shape:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\t</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, X.shape)</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab pytorch</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.randn(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">224</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">224</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> layer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> net:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    X</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">layer(X)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(layer.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__class__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__name__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;output shape:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\t</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,X.shape)</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab tensorflow</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tf.random.uniform((</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">224</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">224</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> layer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> net().layers:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> layer(X)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(layer.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__class__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__name__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;output shape:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\t</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, X.shape)</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab paddle</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> paddle.randn(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">shape</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">224</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">224</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> layer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> net:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    X</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">layer(X)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(layer.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__class__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__name__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;output shape:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\t</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,X.shape)</span></span></code></pre></div><h2 id="读取数据集" tabindex="-1">读取数据集 <a class="header-anchor" href="#读取数据集" aria-label="Permalink to &quot;读取数据集&quot;">​</a></h2><p>尽管原文中AlexNet是在ImageNet上进行训练的，但本书在这里使用的是Fashion-MNIST数据集。因为即使在现代GPU上，训练ImageNet模型，同时使其收敛可能需要数小时或数天的时间。 将AlexNet直接应用于Fashion-MNIST的一个问题是，[<strong>Fashion-MNIST图像的分辨率</strong>]（<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.05ex;" xmlns="http://www.w3.org/2000/svg" width="7.291ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 3222.4 688" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(500,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1222.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(2222.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(500,0)" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>28</mn><mo>×</mo><mn>28</mn></math></mjx-assistive-mml></mjx-container>像素）(<strong>低于ImageNet图像。</strong>) 为了解决这个问题，(<strong>我们将它们增加到<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:0;" xmlns="http://www.w3.org/2000/svg" width="9.553ex" height="1.532ex" role="img" focusable="false" viewBox="0 -677 4222.4 677" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(1000,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(2722.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(1000,0)" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>224</mn><mo>×</mo><mn>224</mn></math></mjx-assistive-mml></mjx-container></strong>)（通常来讲这不是一个明智的做法，但在这里这样做是为了有效使用AlexNet架构）。 这里需要使用<code>d2l.load_data_fashion_mnist</code>函数中的<code>resize</code>参数执行此调整。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab all</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">batch_size </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 128</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">train_iter, test_iter </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d2l.load_data_fashion_mnist(batch_size, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">resize</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">224</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><h2 id="训练alexnet" tabindex="-1">[<strong>训练AlexNet</strong>] <a class="header-anchor" href="#训练alexnet" aria-label="Permalink to &quot;[**训练AlexNet**]&quot;">​</a></h2><p>现在AlexNet可以开始被训练了。与 :numref:<code>sec_lenet</code>中的LeNet相比，这里的主要变化是使用更小的学习速率训练，这是因为网络更深更广、图像分辨率更高，训练卷积神经网络就更昂贵。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#@tab all</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">lr, num_epochs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.01</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())</span></span></code></pre></div><h2 id="小结" tabindex="-1">小结 <a class="header-anchor" href="#小结" aria-label="Permalink to &quot;小结&quot;">​</a></h2><ul><li>AlexNet的架构与LeNet相似，但使用了更多的卷积层和更多的参数来拟合大规模的ImageNet数据集。</li><li>今天，AlexNet已经被更有效的架构所超越，但它是从浅层网络到深层网络的关键一步。</li><li>尽管AlexNet的代码只比LeNet多出几行，但学术界花了很多年才接受深度学习这一概念，并应用其出色的实验结果。这也是由于缺乏有效的计算工具。</li><li>Dropout、ReLU和预处理是提升计算机视觉任务性能的其他关键步骤。</li></ul><h2 id="练习" tabindex="-1">练习 <a class="header-anchor" href="#练习" aria-label="Permalink to &quot;练习&quot;">​</a></h2><ol><li>试着增加迭代轮数。对比LeNet的结果有什么不同？为什么？</li><li>AlexNet对Fashion-MNIST数据集来说可能太复杂了。 <ol><li>尝试简化模型以加快训练速度，同时确保准确性不会显著下降。</li><li>设计一个更好的模型，可以直接在<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.05ex;" xmlns="http://www.w3.org/2000/svg" width="7.291ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 3222.4 688" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(500,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1222.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(2222.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(500,0)" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>28</mn><mo>×</mo><mn>28</mn></math></mjx-assistive-mml></mjx-container>图像上工作。</li></ol></li><li>修改批量大小，并观察模型精度和GPU显存变化。</li><li>分析了AlexNet的计算性能。 <ol><li>在AlexNet中主要是哪部分占用显存？</li><li>在AlexNet中主要是哪部分需要更多的计算？</li><li>计算结果时显存带宽如何？</li></ol></li><li>将dropout和ReLU应用于LeNet-5，效果有提升吗？再试试预处理会怎么样？</li></ol><p>:begin_tab:<code>mxnet</code><a href="https://discuss.d2l.ai/t/1864" target="_blank" rel="noreferrer">Discussions</a> :end_tab:</p><p>:begin_tab:<code>pytorch</code><a href="https://discuss.d2l.ai/t/1863" target="_blank" rel="noreferrer">Discussions</a> :end_tab:</p><p>:begin_tab:<code>tensorflow</code><a href="https://discuss.d2l.ai/t/1862" target="_blank" rel="noreferrer">Discussions</a> :end_tab:</p><p>:begin_tab:<code>paddle</code><a href="https://discuss.d2l.ai/t/11788" target="_blank" rel="noreferrer">Discussions</a> :end_tab:</p></div></div></main><footer class="VPDocFooter" data-v-e6f2a212 data-v-1bcd8184><!--[--><!--]--><div class="edit-info" data-v-1bcd8184><!----><div class="last-updated" data-v-1bcd8184><p class="VPLastUpdated" data-v-1bcd8184 data-v-1bb0c8a8>Last updated: <time datetime="2025-09-02T16:17:19.000Z" data-v-1bb0c8a8></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-1bcd8184><span class="visually-hidden" id="doc-footer-aria-label" data-v-1bcd8184>Pager</span><div class="pager" data-v-1bcd8184><a class="VPLink link pager-link prev" href="/MyBlog/ai/DeepLearning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/use-gpu.html" data-v-1bcd8184><!--[--><span class="desc" data-v-1bcd8184>Previous page</span><span class="title" data-v-1bcd8184>use-gpu</span><!--]--></a></div><div class="pager" data-v-1bcd8184><a class="VPLink link pager-link next" href="/MyBlog/ai/DeepLearning/%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/batch-norm.html" data-v-1bcd8184><!--[--><span class="desc" data-v-1bcd8184>Next page</span><span class="title" data-v-1bcd8184>batch-norm</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-d8b57b2d data-v-566314d4><div class="container" data-v-566314d4><!----><p class="copyright" data-v-566314d4>Copyright © 2025-present Drasky Chen</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"ai_cv_index.md\":\"B5kmByve\",\"ai_deeplearning_index.md\":\"yaBeF44B\",\"ai_deeplearning_优化算法_adadelta.md\":\"CbsNYMlD\",\"ai_deeplearning_优化算法_adagrad.md\":\"HncdhpQY\",\"ai_deeplearning_优化算法_adam.md\":\"BQhf6b3Z\",\"ai_deeplearning_优化算法_convexity.md\":\"BxENDO19\",\"ai_deeplearning_优化算法_gd.md\":\"BfiWzdGe\",\"ai_deeplearning_优化算法_index.md\":\"Ct782-u-\",\"ai_deeplearning_优化算法_lr-scheduler.md\":\"crBETzCo\",\"ai_deeplearning_优化算法_minibatch-sgd.md\":\"Be8IF8pr\",\"ai_deeplearning_优化算法_momentum.md\":\"DfGrRY9_\",\"ai_deeplearning_优化算法_optimization-intro.md\":\"DHBFzF6f\",\"ai_deeplearning_优化算法_rmsprop.md\":\"9myt26Du\",\"ai_deeplearning_优化算法_sgd.md\":\"C_-Otv3a\",\"ai_deeplearning_卷积神经网络_channels.md\":\"sccO21aY\",\"ai_deeplearning_卷积神经网络_conv-layer.md\":\"BtfzPDIj\",\"ai_deeplearning_卷积神经网络_index.md\":\"BytDAWCk\",\"ai_deeplearning_卷积神经网络_lenet.md\":\"Du7sXM4q\",\"ai_deeplearning_卷积神经网络_padding-and-strides.md\":\"CMPv2iwf\",\"ai_deeplearning_卷积神经网络_pooling.md\":\"Cn_o7JXH\",\"ai_deeplearning_卷积神经网络_why-conv.md\":\"3hbkuABH\",\"ai_deeplearning_多层感知机_backprop.md\":\"CXlm1R8s\",\"ai_deeplearning_多层感知机_dropout.md\":\"dnOwu9Ju\",\"ai_deeplearning_多层感知机_environment.md\":\"wuKUW1Zk\",\"ai_deeplearning_多层感知机_index.md\":\"CN1cCF8f\",\"ai_deeplearning_多层感知机_kaggle-house-price.md\":\"JCWbqUwj\",\"ai_deeplearning_多层感知机_mlp-concise.md\":\"e3XJ9_CI\",\"ai_deeplearning_多层感知机_mlp-scratch.md\":\"C6ZKftuZ\",\"ai_deeplearning_多层感知机_mlp.md\":\"CwYXs5Al\",\"ai_deeplearning_多层感知机_numerical-stability-and-init.md\":\"DGnppwzp\",\"ai_deeplearning_多层感知机_underfit-overfit.md\":\"D1AbILg9\",\"ai_deeplearning_多层感知机_weight-decay.md\":\"ht8TZVrx\",\"ai_deeplearning_引言.md\":\"usPXbFzx\",\"ai_deeplearning_循环神经网络_bptt.md\":\"Bu3BN7Yf\",\"ai_deeplearning_循环神经网络_index.md\":\"C998TH-6\",\"ai_deeplearning_循环神经网络_language-models-and-dataset.md\":\"D_mJ98jY\",\"ai_deeplearning_循环神经网络_rnn-concise.md\":\"BIeiN_Ba\",\"ai_deeplearning_循环神经网络_rnn-scratch.md\":\"hPTLcL3O\",\"ai_deeplearning_循环神经网络_rnn.md\":\"CGrMGGhk\",\"ai_deeplearning_循环神经网络_sequence.md\":\"sukp9-p_\",\"ai_deeplearning_循环神经网络_text-preprocessing.md\":\"laZT2Xl9\",\"ai_deeplearning_注意力机制_attention-cues.md\":\"8S-Nx-sj\",\"ai_deeplearning_注意力机制_attention-scoring-functions.md\":\"B3qf_UDL\",\"ai_deeplearning_注意力机制_bahdanau-attention.md\":\"Bq1F_oj0\",\"ai_deeplearning_注意力机制_index.md\":\"0gQV7od4\",\"ai_deeplearning_注意力机制_multihead-attention.md\":\"n_JSfyMs\",\"ai_deeplearning_注意力机制_nadaraya-waston.md\":\"LD7i-SbO\",\"ai_deeplearning_注意力机制_self-attention-and-positional-encoding.md\":\"CmN18lZW\",\"ai_deeplearning_注意力机制_transformer.md\":\"DbliP0fO\",\"ai_deeplearning_深度学习计算_custom-layer.md\":\"CA6tw5Ls\",\"ai_deeplearning_深度学习计算_deferred-init.md\":\"Dl7C3t-i\",\"ai_deeplearning_深度学习计算_index.md\":\"BSuTY6RB\",\"ai_deeplearning_深度学习计算_model-construction.md\":\"BzbvW5S1\",\"ai_deeplearning_深度学习计算_parameters.md\":\"CBX128fL\",\"ai_deeplearning_深度学习计算_read-write.md\":\"DcJ2U7KI\",\"ai_deeplearning_深度学习计算_use-gpu.md\":\"3bFcYhD5\",\"ai_deeplearning_现代卷积神经网络_alexnet.md\":\"BhHdW3Hf\",\"ai_deeplearning_现代卷积神经网络_batch-norm.md\":\"BC4OMaUf\",\"ai_deeplearning_现代卷积神经网络_densenet.md\":\"D8Mu-U0l\",\"ai_deeplearning_现代卷积神经网络_googlenet.md\":\"Dph7FuxX\",\"ai_deeplearning_现代卷积神经网络_index.md\":\"BfJIioHo\",\"ai_deeplearning_现代卷积神经网络_nin.md\":\"DDLrYIj5\",\"ai_deeplearning_现代卷积神经网络_resnet.md\":\"CfXXTcjo\",\"ai_deeplearning_现代卷积神经网络_vgg.md\":\"Bwiuxj1x\",\"ai_deeplearning_现代循环神经网络_beam-search.md\":\"nZPMVrew\",\"ai_deeplearning_现代循环神经网络_bi-rnn.md\":\"nH9SmpHA\",\"ai_deeplearning_现代循环神经网络_deep-rnn.md\":\"BgRLgkzF\",\"ai_deeplearning_现代循环神经网络_encoder-decoder.md\":\"BJflHZRx\",\"ai_deeplearning_现代循环神经网络_gru.md\":\"DRDvH_fj\",\"ai_deeplearning_现代循环神经网络_index.md\":\"Bzi7fvgO\",\"ai_deeplearning_现代循环神经网络_lstm.md\":\"dPkTGdN1\",\"ai_deeplearning_现代循环神经网络_machine-translation-and-dataset.md\":\"DyDx2QQD\",\"ai_deeplearning_现代循环神经网络_seq2seq.md\":\"IiQTlrXZ\",\"ai_deeplearning_线性神经网络_image-classification-dataset.md\":\"D9cdqgOJ\",\"ai_deeplearning_线性神经网络_index.md\":\"D81VgZ5h\",\"ai_deeplearning_线性神经网络_linear-regression-concise.md\":\"P2NwDNmW\",\"ai_deeplearning_线性神经网络_linear-regression-scratch.md\":\"DItnjE_L\",\"ai_deeplearning_线性神经网络_linear-regression.md\":\"B6QKBOIw\",\"ai_deeplearning_线性神经网络_softmax-regression-concise.md\":\"BY5796Ed\",\"ai_deeplearning_线性神经网络_softmax-regression-scratch.md\":\"CnYkb5xz\",\"ai_deeplearning_线性神经网络_softmax-regression.md\":\"CRDoPLnR\",\"ai_deeplearning_自然语言处理：应用_finetuning-bert.md\":\"BPjTEB0f\",\"ai_deeplearning_自然语言处理：应用_index.md\":\"H_4diCQ3\",\"ai_deeplearning_自然语言处理：应用_natural-language-inference-and-dataset.md\":\"BNMJlp3P\",\"ai_deeplearning_自然语言处理：应用_natural-language-inference-attention.md\":\"B21VIoEy\",\"ai_deeplearning_自然语言处理：应用_natural-language-inference-bert.md\":\"Dwc18Hwy\",\"ai_deeplearning_自然语言处理：应用_sentiment-analysis-and-dataset.md\":\"BI04hczh\",\"ai_deeplearning_自然语言处理：应用_sentiment-analysis-cnn.md\":\"Du6679S2\",\"ai_deeplearning_自然语言处理：应用_sentiment-analysis-rnn.md\":\"BoQxvAjw\",\"ai_deeplearning_自然语言处理：预训练_approx-training.md\":\"BHthSzzE\",\"ai_deeplearning_自然语言处理：预训练_bert-dataset.md\":\"Cl_Uf126\",\"ai_deeplearning_自然语言处理：预训练_bert-pretraining.md\":\"DXjRvByL\",\"ai_deeplearning_自然语言处理：预训练_bert.md\":\"CdaZ5dUA\",\"ai_deeplearning_自然语言处理：预训练_glove.md\":\"CAAAE6ZQ\",\"ai_deeplearning_自然语言处理：预训练_index.md\":\"251eI_CT\",\"ai_deeplearning_自然语言处理：预训练_similarity-analogy.md\":\"DMsB5Z0H\",\"ai_deeplearning_自然语言处理：预训练_subword-embedding.md\":\"B-jG7TmX\",\"ai_deeplearning_自然语言处理：预训练_word-embedding-dataset.md\":\"CPmmFSn9\",\"ai_deeplearning_自然语言处理：预训练_word2vec-pretraining.md\":\"ciBYGLi-\",\"ai_deeplearning_自然语言处理：预训练_word2vec.md\":\"DA-95Hlf\",\"ai_deeplearning_计算性能_async-computation.md\":\"B3l9WmWp\",\"ai_deeplearning_计算性能_auto-parallelism.md\":\"wvCqWZ_1\",\"ai_deeplearning_计算性能_hardware.md\":\"BfSMQAjL\",\"ai_deeplearning_计算性能_hybridize.md\":\"2vHepORo\",\"ai_deeplearning_计算性能_index.md\":\"B1On18kr\",\"ai_deeplearning_计算性能_multiple-gpus-concise.md\":\"Z9tBFWyg\",\"ai_deeplearning_计算性能_multiple-gpus.md\":\"BKreGSJJ\",\"ai_deeplearning_计算性能_parameterserver.md\":\"eP9ScBHQ\",\"ai_deeplearning_计算机视觉_anchor.md\":\"DRXVVYC0\",\"ai_deeplearning_计算机视觉_bounding-box.md\":\"CllPeWsr\",\"ai_deeplearning_计算机视觉_fcn.md\":\"CScTRqMq\",\"ai_deeplearning_计算机视觉_fine-tuning.md\":\"DsvClRJP\",\"ai_deeplearning_计算机视觉_image-augmentation.md\":\"ByLswgpj\",\"ai_deeplearning_计算机视觉_index.md\":\"D8y7gs0r\",\"ai_deeplearning_计算机视觉_kaggle-cifar10.md\":\"CiFrksp-\",\"ai_deeplearning_计算机视觉_kaggle-dog.md\":\"CpEoAg0I\",\"ai_deeplearning_计算机视觉_multiscale-object-detection.md\":\"uc10-Avf\",\"ai_deeplearning_计算机视觉_neural-style.md\":\"C2MYor7Y\",\"ai_deeplearning_计算机视觉_object-detection-dataset.md\":\"ThCHA8zN\",\"ai_deeplearning_计算机视觉_rcnn.md\":\"DX8Dz5N1\",\"ai_deeplearning_计算机视觉_semantic-segmentation-and-dataset.md\":\"OB4PCxLD\",\"ai_deeplearning_计算机视觉_ssd.md\":\"DASu9AZu\",\"ai_deeplearning_计算机视觉_transposed-conv.md\":\"C6fgyeir\",\"ai_deeplearning_预备知识_autograd.md\":\"DpX39Wgm\",\"ai_deeplearning_预备知识_calculus.md\":\"v2AaC9i7\",\"ai_deeplearning_预备知识_index.md\":\"_Px1u1i3\",\"ai_deeplearning_预备知识_linear-algebra.md\":\"DC1OJtqY\",\"ai_deeplearning_预备知识_lookup-api.md\":\"BRkY9gmG\",\"ai_deeplearning_预备知识_ndarray.md\":\"DHq3nQlq\",\"ai_deeplearning_预备知识_pandas.md\":\"DOVe31Bf\",\"ai_deeplearning_预备知识_probability.md\":\"YTIOv30Y\",\"ai_index.md\":\"DOPGjfjG\",\"ai_llm_agent_1.agent.md\":\"CrlDhfo9\",\"ai_llm_agent_2.langchain笔记.md\":\"D2A4O2f0\",\"ai_llm_agent_3.mcp通信协议.md\":\"Dz4yRpL2\",\"ai_llm_agent_index.md\":\"fWuxlY9H\",\"ai_machinelearning_1.引言、单变量线性回归、线性代数.md\":\"DDpp5nIJ\",\"ai_machinelearning_2.多变量线性回归.md\":\"uzezgaI7\",\"ai_machinelearning_3.逻辑回归、正则化.md\":\"D2kpoxOm\",\"ai_machinelearning_4.神经网络、表述.md\":\"X21Smzeq\",\"ai_machinelearning_5.神经网络的学习.md\":\"Btumg1kO\",\"ai_machinelearning_6.学习建议、系统设计.md\":\"BAYUeReB\",\"ai_machinelearning_7.支持向量机.md\":\"D1R1EwXE\",\"ai_machinelearning_8.聚类、降维.md\":\"DCr9bmQy\",\"ai_machinelearning_9.异常检测、推荐系统.md\":\"67xR7oSY\",\"ai_machinelearning_index.md\":\"CbXanNIl\",\"ai_machinelearning_x.大规模机器学习、photo ocr、总结.md\":\"CRUaYBxX\",\"ai_nlp_index.md\":\"DtDDdvcr\",\"ai_pytorch_index.md\":\"6-4QCIFF\",\"ai_tensorflow_index.md\":\"HOKilSya\",\"backend_index.md\":\"CEctC5L4\",\"backend_java_index.md\":\"CazKlGDo\",\"backend_java_java基础.md\":\"DMa6xugx\",\"backend_java_java进阶.md\":\"CDSfqUNm\",\"backend_java_springai.md\":\"5a-2bP2F\",\"backend_java_springboot.md\":\"DZHVzcrG\",\"backend_java_ssm.md\":\"DM1zDzaz\",\"backend_mq_index.md\":\"qgA3hTF7\",\"backend_mq_kafka从入门到放弃.md\":\"Bze7obHo\",\"backend_nosql_index.md\":\"BmRYMDqX\",\"backend_nosql_mongodb技术解析.md\":\"ynish4Yb\",\"backend_python_1.python基础语法.md\":\"D9PhWN-G\",\"backend_python_2.python进阶.md\":\"BIApkA_M\",\"backend_python_3.python项目管理.md\":\"CX9Z4t-A\",\"backend_python_fastapi.md\":\"BV5eThXg\",\"backend_python_flask.md\":\"DDK_C5dz\",\"backend_python_index.md\":\"BIJUeAJF\",\"backend_rdbms_index.md\":\"BmA3K-07\",\"backend_rdbms_mysql从入门到放弃.md\":\"CKUnRvWm\",\"backend_rdbms_postgresql从入门到放弃.md\":\"CsMzOOis\",\"devops_ci_cd_github action详解.md\":\"BrEhPNJ2\",\"devops_ci_cd_index.md\":\"D6guWRwM\",\"devops_container_docker基础.md\":\"DjODkd9X\",\"devops_container_index.md\":\"DoeLMiHG\",\"devops_container_k8s简介.md\":\"BzSNVVRs\",\"devops_git_git学习笔记.md\":\"CXTQGvw-\",\"devops_git_index.md\":\"8itI03Kg\",\"devops_server_index.md\":\"DFcoTuBw\",\"devops_server_nginx详解.md\":\"CgEbSze3\",\"examples_api-examples.md\":\"SCsZDAR3\",\"examples_markdown-examples.md\":\"BKK865AB\",\"frontend_css_index.md\":\"DnhtbnvW\",\"frontend_html_1.快速入门.md\":\"BUdSd5xU\",\"frontend_html_2.常用标签.md\":\"DfeIE1mJ\",\"frontend_html_3.盒子布局.md\":\"d0p2bCXf\",\"frontend_html_index.md\":\"Cm5sPgto\",\"frontend_index.md\":\"BHJbtHMQ\",\"frontend_javascript_1.基础语法.md\":\"CIMT0wEE\",\"frontend_javascript_2.进阶.md\":\"B5yiqZzH\",\"frontend_javascript_es6_.md\":\"CwOYB3Or\",\"frontend_javascript_index.md\":\"SDaf0onj\",\"frontend_react_index.md\":\"B0y-AW4Q\",\"frontend_typescript_index.md\":\"BCbUtQZw\",\"frontend_typescript_typescript学习笔记.md\":\"B22rnB3c\",\"frontend_vue_1.vue3简介.md\":\"BTlTyQ2p\",\"frontend_vue_2.创建vue3工程.md\":\"BEH2WCIe\",\"frontend_vue_3.vue3核心语法.md\":\"DozYtE5M\",\"frontend_vue_4.路由.md\":\"B2NaEGKJ\",\"frontend_vue_5.pinia.md\":\"ALyHDZqk\",\"frontend_vue_6.组件通信.md\":\"dUG9ZDJb\",\"frontend_vue_7.其他api.md\":\"CH0YMuXq\",\"frontend_vue_8.vue3新组件.md\":\"CVdac4bT\",\"frontend_vue_index.md\":\"DEVXRaGz\",\"index.md\":\"D-_hIl13\",\"readme.md\":\"Cas71F-D\",\"self-intro.md\":\"C3cE-YH8\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"Drasky's Blog\",\"description\":\"A VitePress Site\",\"base\":\"/MyBlog/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"logo\":\"/IronMan.svg\",\"search\":{\"provider\":\"local\"},\"nav\":[{\"text\":\"主页\",\"link\":\"/\"},{\"text\":\"前端\",\"items\":[{\"text\":\"基础知识\",\"items\":[{\"text\":\"HTML\",\"link\":\"/frontend/HTML/index\"},{\"text\":\"CSS\",\"link\":\"/frontend/CSS/index\"},{\"text\":\"JavaScript\",\"link\":\"/frontend/JavaScript/index\"}]},{\"text\":\"进阶知识\",\"items\":[{\"text\":\"TypeScript\",\"link\":\"/frontend/TypeScript/index\"}]},{\"text\":\"框架技术\",\"items\":[{\"text\":\"Vue\",\"link\":\"/frontend/Vue/index\"},{\"text\":\"React\",\"link\":\"/frontend/React/index\"}]},{\"text\":\"前端工程化\",\"items\":[{\"text\":\"Webpack\",\"link\":\"/frontend/Webpack/index\"},{\"text\":\"Vite\",\"link\":\"/frontend/Vite/index\"}]},{\"text\":\"Awesome\",\"link\":\"/frontend/awesome\"}]},{\"text\":\"后端\",\"items\":[{\"text\":\"基础知识\",\"items\":[{\"text\":\"Java\",\"link\":\"/backend/Java/index\"},{\"text\":\"Python\",\"link\":\"/backend/Python/index\"}]},{\"text\":\"数据库\",\"items\":[{\"text\":\"关系型数据库 (RDBMS)\",\"link\":\"/backend/RDBMS/index\"},{\"text\":\"非关系型数据库 (NoSQL)\",\"link\":\"/backend/NoSQL/index\"}]},{\"text\":\"框架技术\",\"items\":[{\"text\":\"SpringBoot\",\"link\":\"/backend/SpringBoot/index\"},{\"text\":\"Django\",\"link\":\"/backend/Django/index\"}]},{\"text\":\"Awesome\",\"link\":\"/backend/awesome\"}]},{\"text\":\"AI\",\"items\":[{\"text\":\"基础知识\",\"items\":[{\"text\":\"机器学习\",\"link\":\"/ai/MachineLearning/index\"},{\"text\":\"深度学习\",\"link\":\"/ai/DeepLearning/index\"}]},{\"text\":\"框架技术\",\"items\":[{\"text\":\"TensorFlow\",\"link\":\"/ai/TensorFlow/index\"},{\"text\":\"PyTorch\",\"link\":\"/ai/PyTorch/index\"}]},{\"text\":\"进阶知识\",\"items\":[{\"text\":\"NLP\",\"link\":\"/ai/NLP/index\"},{\"text\":\"CV\",\"link\":\"/ai/CV/index\"}]},{\"text\":\"LLM\",\"items\":[{\"text\":\"Agent\",\"link\":\"/ai/LLM/Agent/index\"}]},{\"text\":\"Awesome\",\"link\":\"/ai/awesome\"}]},{\"text\":\"DevOps\",\"items\":[{\"text\":\"开发工具\",\"link\":\"/devops/devtools/index\"},{\"text\":\"Git\",\"link\":\"/devops/Git/index\"},{\"text\":\"CI/CD\",\"link\":\"/devops/CI_CD/index\"},{\"text\":\"容器化\",\"link\":\"/devops/container/index\"},{\"text\":\"监控与日志\",\"link\":\"/devops/mon&log/index\"},{\"text\":\"Web 服务器/反向代理\",\"link\":\"/devops/server/index\"}]}],\"sidebar\":{\"/backend/Python/\":{\"base\":\"/backend/Python/\",\"items\":[{\"text\":\"1.Python基础语法\",\"link\":\"1.Python基础语法\"},{\"text\":\"2.python进阶\",\"link\":\"2.python进阶\"},{\"text\":\"3.Python项目管理\",\"link\":\"3.Python项目管理\"},{\"text\":\"FastAPI\",\"link\":\"FastAPI\"},{\"text\":\"Flask\",\"link\":\"Flask\"}]},\"/backend/Java/\":{\"base\":\"/backend/Java/\",\"items\":[{\"text\":\"Java基础\",\"link\":\"Java基础\"},{\"text\":\"Java进阶\",\"link\":\"Java进阶\"},{\"text\":\"SpringAI\",\"link\":\"SpringAI\"},{\"text\":\"SpringBoot\",\"link\":\"SpringBoot\"},{\"text\":\"ssm\",\"link\":\"ssm\"}]},\"/backend/NoSQL/\":{\"base\":\"/backend/NoSQL/\",\"items\":[{\"text\":\"MongoDB技术解析\",\"link\":\"MongoDB技术解析\"}]},\"/frontend/HTML/\":{\"base\":\"/frontend/HTML/\",\"items\":[{\"text\":\"1.快速入门\",\"link\":\"1.快速入门\"},{\"text\":\"2.常用标签\",\"link\":\"2.常用标签\"},{\"text\":\"3.盒子布局\",\"link\":\"3.盒子布局\"}]},\"/frontend/CSS/\":{\"base\":\"/frontend/CSS/\",\"items\":[]},\"/frontend/JavaScript/\":{\"base\":\"/frontend/JavaScript/\",\"items\":[{\"text\":\"1.基础语法\",\"link\":\"1.基础语法\"},{\"text\":\"2.进阶\",\"link\":\"2.进阶\"},{\"text\":\"ES6+\",\"link\":\"ES6+\"}]},\"/frontend/TypeScript/\":{\"base\":\"/frontend/TypeScript/\",\"items\":[{\"text\":\"TypeScript学习笔记\",\"link\":\"TypeScript学习笔记\"}]},\"/frontend/Vue/\":{\"base\":\"/frontend/Vue/\",\"items\":[{\"text\":\"1.Vue3简介\",\"link\":\"1.Vue3简介\"},{\"text\":\"2.创建Vue3工程\",\"link\":\"2.创建Vue3工程\"},{\"text\":\"3.Vue3核心语法\",\"link\":\"3.Vue3核心语法\"},{\"text\":\"4.路由\",\"link\":\"4.路由\"},{\"text\":\"5.pinia\",\"link\":\"5.pinia\"},{\"text\":\"6.组件通信\",\"link\":\"6.组件通信\"},{\"text\":\"7.其他API\",\"link\":\"7.其他API\"},{\"text\":\"8.Vue3新组件\",\"link\":\"8.Vue3新组件\"}]},\"/ai/MachineLearning/\":{\"base\":\"/ai/MachineLearning/\",\"items\":[{\"text\":\"1.引言、单变量线性回归、线性代数\",\"link\":\"1.引言、单变量线性回归、线性代数\"},{\"text\":\"2.多变量线性回归\",\"link\":\"2.多变量线性回归\"},{\"text\":\"3.逻辑回归、正则化\",\"link\":\"3.逻辑回归、正则化\"},{\"text\":\"4.神经网络、表述\",\"link\":\"4.神经网络、表述\"},{\"text\":\"5.神经网络的学习\",\"link\":\"5.神经网络的学习\"},{\"text\":\"6.学习建议、系统设计\",\"link\":\"6.学习建议、系统设计\"},{\"text\":\"7.支持向量机\",\"link\":\"7.支持向量机\"},{\"text\":\"8.聚类、降维\",\"link\":\"8.聚类、降维\"},{\"text\":\"9.异常检测、推荐系统\",\"link\":\"9.异常检测、推荐系统\"},{\"text\":\"X.大规模机器学习、Photo OCR、总结\",\"link\":\"X.大规模机器学习、Photo OCR、总结\"}]},\"/ai/DeepLearning/\":{\"base\":\"/ai/DeepLearning/\",\"items\":[{\"text\":\"优化算法\",\"items\":[{\"text\":\"adadelta\",\"link\":\"优化算法/adadelta\"},{\"text\":\"adagrad\",\"link\":\"优化算法/adagrad\"},{\"text\":\"adam\",\"link\":\"优化算法/adam\"},{\"text\":\"convexity\",\"link\":\"优化算法/convexity\"},{\"text\":\"gd\",\"link\":\"优化算法/gd\"},{\"text\":\"lr-scheduler\",\"link\":\"优化算法/lr-scheduler\"},{\"text\":\"minibatch-sgd\",\"link\":\"优化算法/minibatch-sgd\"},{\"text\":\"momentum\",\"link\":\"优化算法/momentum\"},{\"text\":\"optimization-intro\",\"link\":\"优化算法/optimization-intro\"},{\"text\":\"rmsprop\",\"link\":\"优化算法/rmsprop\"},{\"text\":\"sgd\",\"link\":\"优化算法/sgd\"}]},{\"text\":\"卷积神经网络\",\"items\":[{\"text\":\"channels\",\"link\":\"卷积神经网络/channels\"},{\"text\":\"conv-layer\",\"link\":\"卷积神经网络/conv-layer\"},{\"text\":\"lenet\",\"link\":\"卷积神经网络/lenet\"},{\"text\":\"padding-and-strides\",\"link\":\"卷积神经网络/padding-and-strides\"},{\"text\":\"pooling\",\"link\":\"卷积神经网络/pooling\"},{\"text\":\"why-conv\",\"link\":\"卷积神经网络/why-conv\"}]},{\"text\":\"多层感知机\",\"items\":[{\"text\":\"backprop\",\"link\":\"多层感知机/backprop\"},{\"text\":\"dropout\",\"link\":\"多层感知机/dropout\"},{\"text\":\"environment\",\"link\":\"多层感知机/environment\"},{\"text\":\"kaggle-house-price\",\"link\":\"多层感知机/kaggle-house-price\"},{\"text\":\"mlp-concise\",\"link\":\"多层感知机/mlp-concise\"},{\"text\":\"mlp-scratch\",\"link\":\"多层感知机/mlp-scratch\"},{\"text\":\"mlp\",\"link\":\"多层感知机/mlp\"},{\"text\":\"numerical-stability-and-init\",\"link\":\"多层感知机/numerical-stability-and-init\"},{\"text\":\"underfit-overfit\",\"link\":\"多层感知机/underfit-overfit\"},{\"text\":\"weight-decay\",\"link\":\"多层感知机/weight-decay\"}]},{\"text\":\"引言\",\"link\":\"引言\"},{\"text\":\"循环神经网络\",\"items\":[{\"text\":\"bptt\",\"link\":\"循环神经网络/bptt\"},{\"text\":\"language-models-and-dataset\",\"link\":\"循环神经网络/language-models-and-dataset\"},{\"text\":\"rnn-concise\",\"link\":\"循环神经网络/rnn-concise\"},{\"text\":\"rnn-scratch\",\"link\":\"循环神经网络/rnn-scratch\"},{\"text\":\"rnn\",\"link\":\"循环神经网络/rnn\"},{\"text\":\"sequence\",\"link\":\"循环神经网络/sequence\"},{\"text\":\"text-preprocessing\",\"link\":\"循环神经网络/text-preprocessing\"}]},{\"text\":\"注意力机制\",\"items\":[{\"text\":\"attention-cues\",\"link\":\"注意力机制/attention-cues\"},{\"text\":\"attention-scoring-functions\",\"link\":\"注意力机制/attention-scoring-functions\"},{\"text\":\"bahdanau-attention\",\"link\":\"注意力机制/bahdanau-attention\"},{\"text\":\"multihead-attention\",\"link\":\"注意力机制/multihead-attention\"},{\"text\":\"nadaraya-waston\",\"link\":\"注意力机制/nadaraya-waston\"},{\"text\":\"self-attention-and-positional-encoding\",\"link\":\"注意力机制/self-attention-and-positional-encoding\"},{\"text\":\"transformer\",\"link\":\"注意力机制/transformer\"}]},{\"text\":\"深度学习计算\",\"items\":[{\"text\":\"custom-layer\",\"link\":\"深度学习计算/custom-layer\"},{\"text\":\"deferred-init\",\"link\":\"深度学习计算/deferred-init\"},{\"text\":\"model-construction\",\"link\":\"深度学习计算/model-construction\"},{\"text\":\"parameters\",\"link\":\"深度学习计算/parameters\"},{\"text\":\"read-write\",\"link\":\"深度学习计算/read-write\"},{\"text\":\"use-gpu\",\"link\":\"深度学习计算/use-gpu\"}]},{\"text\":\"现代卷积神经网络\",\"items\":[{\"text\":\"alexnet\",\"link\":\"现代卷积神经网络/alexnet\"},{\"text\":\"batch-norm\",\"link\":\"现代卷积神经网络/batch-norm\"},{\"text\":\"densenet\",\"link\":\"现代卷积神经网络/densenet\"},{\"text\":\"googlenet\",\"link\":\"现代卷积神经网络/googlenet\"},{\"text\":\"nin\",\"link\":\"现代卷积神经网络/nin\"},{\"text\":\"resnet\",\"link\":\"现代卷积神经网络/resnet\"},{\"text\":\"vgg\",\"link\":\"现代卷积神经网络/vgg\"}]},{\"text\":\"现代循环神经网络\",\"items\":[{\"text\":\"beam-search\",\"link\":\"现代循环神经网络/beam-search\"},{\"text\":\"bi-rnn\",\"link\":\"现代循环神经网络/bi-rnn\"},{\"text\":\"deep-rnn\",\"link\":\"现代循环神经网络/deep-rnn\"},{\"text\":\"encoder-decoder\",\"link\":\"现代循环神经网络/encoder-decoder\"},{\"text\":\"gru\",\"link\":\"现代循环神经网络/gru\"},{\"text\":\"lstm\",\"link\":\"现代循环神经网络/lstm\"},{\"text\":\"machine-translation-and-dataset\",\"link\":\"现代循环神经网络/machine-translation-and-dataset\"},{\"text\":\"seq2seq\",\"link\":\"现代循环神经网络/seq2seq\"}]},{\"text\":\"线性神经网络\",\"items\":[{\"text\":\"image-classification-dataset\",\"link\":\"线性神经网络/image-classification-dataset\"},{\"text\":\"linear-regression-concise\",\"link\":\"线性神经网络/linear-regression-concise\"},{\"text\":\"linear-regression-scratch\",\"link\":\"线性神经网络/linear-regression-scratch\"},{\"text\":\"linear-regression\",\"link\":\"线性神经网络/linear-regression\"},{\"text\":\"softmax-regression-concise\",\"link\":\"线性神经网络/softmax-regression-concise\"},{\"text\":\"softmax-regression-scratch\",\"link\":\"线性神经网络/softmax-regression-scratch\"},{\"text\":\"softmax-regression\",\"link\":\"线性神经网络/softmax-regression\"}]},{\"text\":\"自然语言处理：应用\",\"items\":[{\"text\":\"finetuning-bert\",\"link\":\"自然语言处理：应用/finetuning-bert\"},{\"text\":\"natural-language-inference-and-dataset\",\"link\":\"自然语言处理：应用/natural-language-inference-and-dataset\"},{\"text\":\"natural-language-inference-attention\",\"link\":\"自然语言处理：应用/natural-language-inference-attention\"},{\"text\":\"natural-language-inference-bert\",\"link\":\"自然语言处理：应用/natural-language-inference-bert\"},{\"text\":\"sentiment-analysis-and-dataset\",\"link\":\"自然语言处理：应用/sentiment-analysis-and-dataset\"},{\"text\":\"sentiment-analysis-cnn\",\"link\":\"自然语言处理：应用/sentiment-analysis-cnn\"},{\"text\":\"sentiment-analysis-rnn\",\"link\":\"自然语言处理：应用/sentiment-analysis-rnn\"}]},{\"text\":\"自然语言处理：预训练\",\"items\":[{\"text\":\"approx-training\",\"link\":\"自然语言处理：预训练/approx-training\"},{\"text\":\"bert-dataset\",\"link\":\"自然语言处理：预训练/bert-dataset\"},{\"text\":\"bert-pretraining\",\"link\":\"自然语言处理：预训练/bert-pretraining\"},{\"text\":\"bert\",\"link\":\"自然语言处理：预训练/bert\"},{\"text\":\"glove\",\"link\":\"自然语言处理：预训练/glove\"},{\"text\":\"similarity-analogy\",\"link\":\"自然语言处理：预训练/similarity-analogy\"},{\"text\":\"subword-embedding\",\"link\":\"自然语言处理：预训练/subword-embedding\"},{\"text\":\"word-embedding-dataset\",\"link\":\"自然语言处理：预训练/word-embedding-dataset\"},{\"text\":\"word2vec-pretraining\",\"link\":\"自然语言处理：预训练/word2vec-pretraining\"},{\"text\":\"word2vec\",\"link\":\"自然语言处理：预训练/word2vec\"}]},{\"text\":\"计算性能\",\"items\":[{\"text\":\"async-computation\",\"link\":\"计算性能/async-computation\"},{\"text\":\"auto-parallelism\",\"link\":\"计算性能/auto-parallelism\"},{\"text\":\"hardware\",\"link\":\"计算性能/hardware\"},{\"text\":\"hybridize\",\"link\":\"计算性能/hybridize\"},{\"text\":\"multiple-gpus-concise\",\"link\":\"计算性能/multiple-gpus-concise\"},{\"text\":\"multiple-gpus\",\"link\":\"计算性能/multiple-gpus\"},{\"text\":\"parameterserver\",\"link\":\"计算性能/parameterserver\"}]},{\"text\":\"计算机视觉\",\"items\":[{\"text\":\"anchor\",\"link\":\"计算机视觉/anchor\"},{\"text\":\"bounding-box\",\"link\":\"计算机视觉/bounding-box\"},{\"text\":\"fcn\",\"link\":\"计算机视觉/fcn\"},{\"text\":\"fine-tuning\",\"link\":\"计算机视觉/fine-tuning\"},{\"text\":\"image-augmentation\",\"link\":\"计算机视觉/image-augmentation\"},{\"text\":\"kaggle-cifar10\",\"link\":\"计算机视觉/kaggle-cifar10\"},{\"text\":\"kaggle-dog\",\"link\":\"计算机视觉/kaggle-dog\"},{\"text\":\"multiscale-object-detection\",\"link\":\"计算机视觉/multiscale-object-detection\"},{\"text\":\"neural-style\",\"link\":\"计算机视觉/neural-style\"},{\"text\":\"object-detection-dataset\",\"link\":\"计算机视觉/object-detection-dataset\"},{\"text\":\"rcnn\",\"link\":\"计算机视觉/rcnn\"},{\"text\":\"semantic-segmentation-and-dataset\",\"link\":\"计算机视觉/semantic-segmentation-and-dataset\"},{\"text\":\"ssd\",\"link\":\"计算机视觉/ssd\"},{\"text\":\"transposed-conv\",\"link\":\"计算机视觉/transposed-conv\"}]},{\"text\":\"预备知识\",\"items\":[{\"text\":\"autograd\",\"link\":\"预备知识/autograd\"},{\"text\":\"calculus\",\"link\":\"预备知识/calculus\"},{\"text\":\"linear-algebra\",\"link\":\"预备知识/linear-algebra\"},{\"text\":\"lookup-api\",\"link\":\"预备知识/lookup-api\"},{\"text\":\"ndarray\",\"link\":\"预备知识/ndarray\"},{\"text\":\"pandas\",\"link\":\"预备知识/pandas\"},{\"text\":\"probability\",\"link\":\"预备知识/probability\"}]}]},\"/ai/LLM/Agent/\":{\"base\":\"/ai/LLM/Agent/\",\"items\":[{\"text\":\"1.agent\",\"link\":\"1.agent\"},{\"text\":\"2.langchain笔记\",\"link\":\"2.langchain笔记\"},{\"text\":\"3.MCP通信协议\",\"link\":\"3.MCP通信协议\"}]},\"/devops/Git/\":{\"base\":\"/devops/Git/\",\"items\":[{\"text\":\"Git学习笔记\",\"link\":\"Git学习笔记\"}]},\"/devops/CI_CD/\":{\"base\":\"/devops/CI_CD/\",\"items\":[{\"text\":\"GitHub Action详解\",\"link\":\"GitHub Action详解\"}]},\"/devops/server/\":{\"base\":\"/devops/server/\",\"items\":[{\"text\":\"Nginx详解\",\"link\":\"Nginx详解\"}]},\"/devops/container/\":{\"base\":\"/devops/container/\",\"items\":[{\"text\":\"docker基础\",\"link\":\"docker基础\"},{\"text\":\"k8s简介\",\"link\":\"k8s简介\"}]},\"/Examples/\":{\"base\":\"/Examples/\",\"items\":[{\"text\":\"api-examples\",\"link\":\"api-examples\"},{\"text\":\"markdown-examples\",\"link\":\"markdown-examples\"}]}},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/DraskyChen\"}],\"footer\":{\"copyright\":\"Copyright © 2025-present Drasky Chen\"}},\"locales\":{\"root\":{\"label\":\"简体中文\",\"lang\":\"zh-CN\"},\"en-US\":{\"label\":\"English\",\"lang\":\"en-US\"}},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>